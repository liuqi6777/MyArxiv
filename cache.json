{"2023-03-06T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2303.03363v1","updated":"2023-03-06T18:49:09Z","published":"2023-03-06T18:49:09Z","title":"Enhancing Activity Prediction Models in Drug Discovery with the Ability\n  to Understand Human Language","summary":"  Activity and property prediction models are the central workhorses in drug\ndiscovery and materials sciences, but currently they have to be trained or\nfine-tuned for new tasks. Without training or fine-tuning, scientific language\nmodels could be used for such low-data tasks through their announced zero- and\nfew-shot capabilities. However, their predictive quality at activity prediction\nis lacking. In this work, we envision a novel type of activity prediction model\nthat is able to adapt to new prediction tasks at inference time, via\nunderstanding textual information describing the task. To this end, we propose\na new architecture with separate modules for chemical and natural language\ninputs, and a contrastive pre-training objective on data from large biochemical\ndatabases. In extensive experiments, we show that our method CLAMP yields\nimproved predictive performance on few-shot learning benchmarks and zero-shot\nproblems in drug discovery. We attribute the advances of our method to the\nmodularized architecture and to our pre-training objective.\n","authors":["Philipp Seidl","Andreu Vall","Sepp Hochreiter","Günter Klambauer"],"pdf_url":"https://arxiv.org/pdf/2303.03363v1.pdf","comment":"15 pages + 18 pages appendix"},{"id":"http://arxiv.org/abs/2203.05642v3","updated":"2023-03-06T17:57:00Z","published":"2022-03-10T21:11:37Z","title":"Parameter-Free Attentive Scoring for Speaker Verification","summary":"  This paper presents a novel study of parameter-free attentive scoring for\nspeaker verification. Parameter-free scoring provides the flexibility of\ncomparing speaker representations without the need of an accompanying\nparametric scoring model. Inspired by the attention component in Transformer\nneural networks, we propose a variant of the scaled dot product attention\nmechanism to compare enrollment and test segment representations. In addition,\nthis work explores the effect on performance of (i) different types of\nnormalization, (ii) independent versus tied query/key estimation, (iii) varying\nthe number of key-value pairs and (iv) pooling multiple enrollment utterance\nstatistics. Experimental results for a 4 task average show that a simple\nparameter-free attentive scoring mechanism can improve the average EER by 10%\nover the best cosine similarity baseline.\n","authors":["Jason Pelecanos","Quan Wang","Yiling Huang","Ignacio Lopez Moreno"],"pdf_url":"https://arxiv.org/pdf/2203.05642v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03290v1","updated":"2023-03-06T17:06:50Z","published":"2023-03-06T17:06:50Z","title":"AmQA: Amharic Question Answering Dataset","summary":"  Question Answering (QA) returns concise answers or answer lists from natural\nlanguage text given a context document. Many resources go into curating QA\ndatasets to advance robust models' development. There is a surge of QA datasets\nfor languages like English, however, this is not true for Amharic. Amharic, the\nofficial language of Ethiopia, is the second most spoken Semitic language in\nthe world. There is no published or publicly available Amharic QA dataset.\nHence, to foster the research in Amharic QA, we present the first Amharic QA\n(AmQA) dataset. We crowdsourced 2628 question-answer pairs over 378 Wikipedia\narticles. Additionally, we run an XLMR Large-based baseline model to spark\nopen-domain QA research interest. The best-performing baseline achieves an\nF-score of 69.58 and 71.74 in reader-retriever QA and reading comprehension\nsettings respectively.\n","authors":["Tilahun Abedissa","Ricardo Usbeck","Yaregal Assabie"],"pdf_url":"https://arxiv.org/pdf/2303.03290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03283v1","updated":"2023-03-06T16:53:12Z","published":"2023-03-06T16:53:12Z","title":"The AI Ghostwriter Effect: Users Do Not Perceive Ownership of\n  AI-Generated Text But Self-Declare as Authors","summary":"  Human-AI interaction in text production increases complexity in authorship.\nIn two empirical studies (n1 = 30 & n2 = 96), we investigate authorship and\nownership in human-AI collaboration for personalized language generation\nmodels. We show an AI Ghostwriter Effect: Users do not consider themselves the\nowners and authors of AI-generated text but refrain from publicly declaring AI\nauthorship. The degree of personalization did not impact the AI Ghostwriter\nEffect, and control over the model increased participants' sense of ownership.\nWe also found that the discrepancy between the sense of ownership and the\nauthorship declaration is stronger in interactions with a human ghostwriter and\nthat people use similar rationalizations for authorship in AI ghostwriters and\nhuman ghostwriters. We discuss how our findings relate to psychological\nownership and human-AI interaction to lay the foundations for adapting\nauthorship frameworks and user interfaces in AI in text-generation tasks.\n","authors":["Fiona Draxler","Anna Werner","Florian Lehmann","Matthias Hoppe","Albrecht Schmidt","Daniel Buschek","Robin Welsch"],"pdf_url":"https://arxiv.org/pdf/2303.03283v1.pdf","comment":"Pre-print; currently under review"},{"id":"http://arxiv.org/abs/2303.03278v1","updated":"2023-03-06T16:49:27Z","published":"2023-03-06T16:49:27Z","title":"Faithfulness-Aware Decoding Strategies for Abstractive Summarization","summary":"  Despite significant progress in understanding and improving faithfulness in\nabstractive summarization, the question of how decoding strategies affect\nfaithfulness is less studied. We present a systematic study of the effect of\ngeneration techniques such as beam search and nucleus sampling on faithfulness\nin abstractive summarization. We find a consistent trend where beam search with\nlarge beam sizes produces the most faithful summaries while nucleus sampling\ngenerates the least faithful ones. We propose two faithfulness-aware generation\nmethods to further improve faithfulness over current generation techniques: (1)\nranking candidates generated by beam search using automatic faithfulness\nmetrics and (2) incorporating lookahead heuristics that produce a faithfulness\nscore on the future summary. We show that both generation methods significantly\nimprove faithfulness across two datasets as evaluated by four automatic\nfaithfulness metrics and human evaluation. To reduce computational cost, we\ndemonstrate a simple distillation approach that allows the model to generate\nfaithful summaries with just greedy decoding. Our code is publicly available at\nhttps://github.com/amazon-science/faithful-summarization-generation\n","authors":["David Wan","Mengwen Liu","Kathleen McKeown","Markus Dreyer","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2303.03278v1.pdf","comment":"EACL 2023 (17 pages)"},{"id":"http://arxiv.org/abs/2207.04154v4","updated":"2023-03-06T16:37:49Z","published":"2022-07-08T23:42:56Z","title":"TalkToModel: Explaining Machine Learning Models with Interactive Natural\n  Language Conversations","summary":"  Machine Learning (ML) models are increasingly used to make critical decisions\nin real-world applications, yet they have become more complex, making them\nharder to understand. To this end, researchers have proposed several techniques\nto explain model predictions. However, practitioners struggle to use these\nexplainability techniques because they often do not know which one to choose\nand how to interpret the results of the explanations. In this work, we address\nthese challenges by introducing TalkToModel: an interactive dialogue system for\nexplaining machine learning models through conversations. Specifically,\nTalkToModel comprises of three key components: 1) a natural language interface\nfor engaging in conversations, making ML model explainability highly\naccessible, 2) a dialogue engine that adapts to any tabular model and dataset,\ninterprets natural language, maps it to appropriate explanations, and generates\ntext responses, and 3) an execution component that constructs the explanations.\nWe carried out extensive quantitative and human subject evaluations of\nTalkToModel. Overall, we found the conversational system understands user\ninputs on novel datasets and models with high accuracy, demonstrating the\nsystem's capacity to generalize to new situations. In real-world evaluations\nwith humans, 73% of healthcare workers (e.g., doctors and nurses) agreed they\nwould use TalkToModel over baseline point-and-click systems for explainability\nin a disease prediction task, and 85% of ML professionals agreed TalkToModel\nwas easier to use for computing explanations. Our findings demonstrate that\nTalkToModel is more effective for model explainability than existing systems,\nintroducing a new category of explainability tools for practitioners. Code &\ndemo released here: https://github.com/dylan-slack/TalkToModel.\n","authors":["Dylan Slack","Satyapriya Krishna","Himabindu Lakkaraju","Sameer Singh"],"pdf_url":"https://arxiv.org/pdf/2207.04154v4.pdf","comment":"Pre-print; comments welcome! Reach out to dslack@uci.edu v3 update\n  title and abstract"},{"id":"http://arxiv.org/abs/2302.05698v2","updated":"2023-03-06T15:24:56Z","published":"2023-02-11T14:02:08Z","title":"Compositional Exemplars for In-context Learning","summary":"  Large pretrained language models (LMs) have shown impressive In-Context\nLearning (ICL) ability, where the model learns to do an unseen task via a\nprompt consisting of input-output examples as the demonstration, without any\nparameter updates. The performance of ICL is highly dominated by the quality of\nthe selected in-context examples. However, previous selection methods are\nmostly based on simple heuristics, leading to sub-optimal performance. In this\nwork, we formulate in-context example selection as a subset selection problem.\nWe propose CEIL (Compositional Exemplars for In-context Learning), which is\ninstantiated by Determinantal Point Processes (DPPs) to model the interaction\nbetween the given input and in-context examples, and optimized through a\ncarefully-designed contrastive learning objective to obtain preference from\nLMs. We validate CEIL on 12 classification and generation datasets from 7\ndistinct NLP tasks, including sentiment analysis, paraphrase detection, natural\nlanguage inference, commonsense reasoning, open-domain question answering, code\ngeneration, and semantic parsing. Extensive experiments demonstrate not only\nthe state-of-the-art performance but also the transferability and\ncompositionality of CEIL, shedding new light on effective and efficient\nin-context learning. Our code is released at\nhttps://github.com/HKUNLP/icl-ceil.\n","authors":["Jiacheng Ye","Zhiyong Wu","Jiangtao Feng","Tao Yu","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2302.05698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03199v1","updated":"2023-03-06T14:58:42Z","published":"2023-03-06T14:58:42Z","title":"Choice Over Control: How Users Write with Large Language Models using\n  Diegetic and Non-Diegetic Prompting","summary":"  We propose a conceptual perspective on prompts for Large Language Models\n(LLMs) that distinguishes between (1) diegetic prompts (part of the narrative,\ne.g. \"Once upon a time, I saw a fox...\"), and (2) non-diegetic prompts\n(external, e.g. \"Write about the adventures of the fox.\"). With this lens, we\nstudy how 129 crowd workers on Prolific write short texts with different user\ninterfaces (1 vs 3 suggestions, with/out non-diegetic prompts; implemented with\nGPT-3): When the interface offered multiple suggestions and provided an option\nfor non-diegetic prompting, participants preferred choosing from multiple\nsuggestions over controlling them via non-diegetic prompts. When participants\nprovided non-diegetic prompts it was to ask for inspiration, topics or facts.\nSingle suggestions in particular were guided both with diegetic and\nnon-diegetic information. This work informs human-AI interaction with\ngenerative models by revealing that (1) writing non-diegetic prompts requires\neffort, (2) people combine diegetic and non-diegetic prompting, and (3) they\nuse their draft (i.e. diegetic information) and suggestion timing to\nstrategically guide LLMs.\n","authors":["Hai Dang","Sven Goller","Florian Lehmann","Daniel Buschek"],"pdf_url":"https://arxiv.org/pdf/2303.03199v1.pdf","comment":"17 pages, 9 figures, 3 tables, ACM CHI 2023"},{"id":"http://arxiv.org/abs/2303.03171v1","updated":"2023-03-06T14:39:54Z","published":"2023-03-06T14:39:54Z","title":"Neighborhood Contrastive Transformer for Change Captioning","summary":"  Change captioning is to describe the semantic change between a pair of\nsimilar images in natural language. It is more challenging than general image\ncaptioning, because it requires capturing fine-grained change information while\nbeing immune to irrelevant viewpoint changes, and solving syntax ambiguity in\nchange descriptions. In this paper, we propose a neighborhood contrastive\ntransformer to improve the model's perceiving ability for various changes under\ndifferent scenes and cognition ability for complex syntax structure.\nConcretely, we first design a neighboring feature aggregating to integrate\nneighboring context into each feature, which helps quickly locate the\ninconspicuous changes under the guidance of conspicuous referents. Then, we\ndevise a common feature distilling to compare two images at neighborhood level\nand extract common properties from each image, so as to learn effective\ncontrastive information between them. Finally, we introduce the explicit\ndependencies between words to calibrate the transformer decoder, which helps\nbetter understand complex syntax structure during training. Extensive\nexperimental results demonstrate that the proposed method achieves the\nstate-of-the-art performance on three public datasets with different change\nscenarios. The code is available at https://github.com/tuyunbin/NCT.\n","authors":["Yunbin Tu","Liang Li","Li Su","Ke Lu","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2303.03171v1.pdf","comment":"Accepted by IEEE TMM"},{"id":"http://arxiv.org/abs/2303.03144v1","updated":"2023-03-06T13:59:37Z","published":"2023-03-06T13:59:37Z","title":"IPA-CLIP: Integrating Phonetic Priors into Vision and Language\n  Pretraining","summary":"  Recently, large-scale Vision and Language (V\\&L) pretraining has become the\nstandard backbone of many multimedia systems. While it has shown remarkable\nperformance even in unseen situations, it often performs in ways not intuitive\nto humans. Particularly, they usually do not consider the pronunciation of the\ninput, which humans would utilize to understand language, especially when it\ncomes to unknown words. Thus, this paper inserts phonetic prior into\nContrastive Language-Image Pretraining (CLIP), one of the V\\&L pretrained\nmodels, to make it consider the pronunciation similarity among its\npronunciation inputs. To achieve this, we first propose a phoneme embedding\nthat utilizes the phoneme relationships provided by the International Phonetic\nAlphabet (IPA) chart as a phonetic prior. Next, by distilling the frozen CLIP\ntext encoder, we train a pronunciation encoder employing the IPA-based\nembedding. The proposed model named IPA-CLIP comprises this pronunciation\nencoder and the original CLIP encoders (image and text). Quantitative\nevaluation reveals that the phoneme distribution on the embedding space\nrepresents phonetic relationships more accurately when using the proposed\nphoneme embedding. Furthermore, in some multimodal retrieval tasks, we confirm\nthat the proposed pronunciation encoder enhances the performance of the text\nencoder and that the pronunciation encoder handles nonsense words in a more\nphonetic manner than the text encoder. Finally, qualitative evaluation verifies\nthe correlation between the pronunciation encoder and human perception\nregarding pronunciation similarity.\n","authors":["Chihaya Matsuhira","Marc A. Kastner","Takahiro Komamizu","Takatsugu Hirayama","Keisuke Doman","Yasutomo Kawanishi","Ichiro Ide"],"pdf_url":"https://arxiv.org/pdf/2303.03144v1.pdf","comment":"11 pages, 8 figures, 5 Tables"},{"id":"http://arxiv.org/abs/2303.03124v1","updated":"2023-03-06T13:37:59Z","published":"2023-03-06T13:37:59Z","title":"IFAN: An Explainability-Focused Interaction Framework for Humans and NLP\n  Models","summary":"  Interpretability and human oversight are fundamental pillars of deploying\ncomplex NLP models into real-world applications. However, applying\nexplainability and human-in-the-loop methods requires technical proficiency.\nDespite existing toolkits for model understanding and analysis, options to\nintegrate human feedback are still limited. We propose IFAN, a framework for\nreal-time explanation-based interaction with NLP models. Through IFAN's\ninterface, users can provide feedback to selected model explanations, which is\nthen integrated through adapter layers to align the model with human rationale.\nWe show the system to be effective in debiasing a hate speech classifier with\nminimal performance loss. IFAN also offers a visual admin system and API to\nmanage models (and datasets) as well as control access rights. A demo is live\nat https://ifan.ml/\n","authors":["Edoardo Mosca","Daryna Dementieva","Tohid Ebrahim Ajdari","Maximilian Kummeth","Kirill Gringauz","Georg Groh"],"pdf_url":"https://arxiv.org/pdf/2303.03124v1.pdf","comment":"ACL Demo 2023 Submission"},{"id":"http://arxiv.org/abs/2303.03103v1","updated":"2023-03-06T13:15:25Z","published":"2023-03-06T13:15:25Z","title":"Towards Zero-Shot Functional Compositionality of Language Models","summary":"  Large Pre-trained Language Models (PLM) have become the most desirable\nstarting point in the field of NLP, as they have become remarkably good at\nsolving many individual tasks. Despite such success, in this paper, we argue\nthat current paradigms of working with PLMs are neglecting a critical aspect of\nmodeling human intelligence: functional compositionality. Functional\ncompositionality - the ability to compose learned tasks - has been a\nlong-standing challenge in the field of AI (and many other fields) as it is\nconsidered one of the hallmarks of human intelligence. An illustrative example\nof such is cross-lingual summarization, where a bilingual person\n(English-French) could directly summarize an English document into French\nsentences without having to translate the English document or summary into\nFrench explicitly. We discuss why this matter is an important open problem that\nrequires further attention from the field. Then, we show that current PLMs\n(e.g., GPT-2 and T5) don't have functional compositionality yet and it is far\nfrom human-level generalizability. Finally, we suggest several research\ndirections that could push the field towards zero-shot functional\ncompositionality of language models.\n","authors":["Hangyeol Yu","Myeongho Jeong","Jamin Shin","Hyeongdon Moon","Juneyoung Park","Seungtaek Choi"],"pdf_url":"https://arxiv.org/pdf/2303.03103v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03053v1","updated":"2023-03-06T11:54:58Z","published":"2023-03-06T11:54:58Z","title":"Crowdsourcing on Sensitive Data with Privacy-Preserving Text Rewriting","summary":"  Most tasks in NLP require labeled data. Data labeling is often done on\ncrowdsourcing platforms due to scalability reasons. However, publishing data on\npublic platforms can only be done if no privacy-relevant information is\nincluded. Textual data often contains sensitive information like person names\nor locations. In this work, we investigate how removing personally identifiable\ninformation (PII) as well as applying differential privacy (DP) rewriting can\nenable text with privacy-relevant information to be used for crowdsourcing. We\nfind that DP-rewriting before crowdsourcing can preserve privacy while still\nleading to good label quality for certain tasks and data. PII-removal led to\ngood label quality in all examined tasks, however, there are no privacy\nguarantees given.\n","authors":["Nina Mouhammad","Johannes Daxenberger","Benjamin Schiller","Ivan Habernal"],"pdf_url":"https://arxiv.org/pdf/2303.03053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03032v1","updated":"2023-03-06T11:02:47Z","published":"2023-03-06T11:02:47Z","title":"DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only\n  Training","summary":"  Large-scale pre-trained multi-modal models (e.g., CLIP) demonstrate strong\nzero-shot transfer capability in many discriminative tasks. Their adaptation to\nzero-shot image-conditioned text generation tasks has drawn increasing\ninterest. Prior arts approach to zero-shot captioning by either utilizing the\nexisting large language models (e.g., GPT-2) or pre-training the\nencoder-decoder network in an end-to-end manner. In this work, we propose a\nsimple framework, named DeCap, for zero-shot captioning. We introduce a\nlightweight visual-aware language decoder. This decoder is both data-efficient\nand computation-efficient: 1) it only requires the text data for training,\neasing the burden on the collection of paired data. 2) it does not require\nend-to-end training. When trained with text-only data, the decoder takes the\ntext embedding extracted from the off-the-shelf CLIP encoder as a prefix\nembedding. The challenge is that the decoder is trained on the text corpus but\nat the inference stage, it needs to generate captions based on visual inputs.\nThe modality gap issue is widely observed in multi-modal contrastive models\nthat prevents us from directly taking the visual embedding as the prefix\nembedding. We propose a training-free mechanism to reduce the modality gap. We\nproject the visual embedding into the CLIP text embedding space, while the\nprojected embedding retains the information of the visual input. Taking the\nprojected embedding as the prefix embedding, the decoder generates high-quality\ndescriptions that match the visual input. The experiments show that DeCap\noutperforms other zero-shot captioning methods and unpaired captioning methods\non the typical image captioning benchmarks, i.e., MSCOCO and NoCaps.\n","authors":["Wei Li","Linchao Zhu","Longyin Wen","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2303.03032v1.pdf","comment":"Accepted by ICLR 2023. Code is available at\n  https://github.com/dhg-wei/DeCap"},{"id":"http://arxiv.org/abs/2303.03019v1","updated":"2023-03-06T10:45:24Z","published":"2023-03-06T10:45:24Z","title":"NxPlain: Web-based Tool for Discovery of Latent Concepts","summary":"  The proliferation of deep neural networks in various domains has seen an\nincreased need for the interpretability of these models, especially in\nscenarios where fairness and trust are as important as model performance. A lot\nof independent work is being carried out to: i) analyze what linguistic and\nnon-linguistic knowledge is learned within these models, and ii) highlight the\nsalient parts of the input. We present NxPlain, a web application that provides\nan explanation of a model's prediction using latent concepts. NxPlain discovers\nlatent concepts learned in a deep NLP model, provides an interpretation of the\nknowledge learned in the model, and explains its predictions based on the used\nconcepts. The application allows users to browse through the latent concepts in\nan intuitive order, letting them efficiently scan through the most salient\nconcepts with a global corpus level view and a local sentence-level view. Our\ntool is useful for debugging, unraveling model bias, and for highlighting\nspurious correlations in a model. A hosted demo is available here:\nhttps://nxplain.qcri.org.\n","authors":["Fahim Dalvi","Nadir Durrani","Hassan Sajjad","Tamim Jaban","Musab Husaini","Ummar Abbas"],"pdf_url":"https://arxiv.org/pdf/2303.03019v1.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2303.03004v1","updated":"2023-03-06T10:08:51Z","published":"2023-03-06T10:08:51Z","title":"xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code\n  Understanding, Generation, Translation and Retrieval","summary":"  The ability to solve problems is a hallmark of intelligence and has been an\nenduring goal in AI. AI systems that can create programs as solutions to\nproblems or assist developers in writing programs can increase productivity and\nmake programming more accessible. Recently, pre-trained large language models\nhave shown impressive abilities in generating new codes from natural language\ndescriptions, repairing buggy codes, translating codes between languages, and\nretrieving relevant code segments. However, the evaluation of these models has\noften been performed in a scattered way on only one or two specific tasks, in a\nfew languages, at a partial granularity (e.g., function) level and in many\ncases without proper training data. Even more concerning is that in most cases\nthe evaluation of generated codes has been done in terms of mere lexical\noverlap rather than actual execution whereas semantic similarity (or\nequivalence) of two code segments depends only on their ``execution\nsimilarity'', i.e., being able to get the same output for a given input.\n","authors":["Mohammad Abdullah Matin Khan","M Saiful Bari","Xuan Long Do","Weishi Wang","Md Rizwan Parvez","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2303.03004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02995v1","updated":"2023-03-06T09:44:01Z","published":"2023-03-06T09:44:01Z","title":"HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware\n  Attention","summary":"  The success of large-scale contrastive vision-language pretraining (CLIP) has\nbenefited both visual recognition and multimodal content understanding. The\nconcise design brings CLIP the advantage in inference efficiency against other\nvision-language models with heavier cross-attention fusion layers, making it a\npopular choice for a wide spectrum of downstream tasks. However, CLIP does not\nexplicitly capture the hierarchical nature of high-level and fine-grained\nsemantics conveyed in images and texts, which is arguably critical to\nvision-language understanding and reasoning. To this end, we equip both the\nvisual and language branches in CLIP with hierarchy-aware attentions, namely\nHierarchy-aware CLIP (HiCLIP), to progressively discover semantic hierarchies\nlayer-by-layer from both images and texts in an unsupervised manner. As a\nresult, such hierarchical aggregation significantly improves the cross-modal\nalignment. To demonstrate the advantages of HiCLIP, we conduct qualitative\nanalysis on its unsupervised hierarchy induction during inference, as well as\nextensive quantitative experiments on both visual recognition and\nvision-language downstream tasks.\n","authors":["Shijie Geng","Jianbo Yuan","Yu Tian","Yuxiao Chen","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02995v1.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.03494v7","updated":"2023-03-06T09:34:38Z","published":"2023-02-06T04:21:59Z","title":"A Categorical Archive of ChatGPT Failures","summary":"  Large language models have been demonstrated to be valuable in different\nfields. ChatGPT, developed by OpenAI, has been trained using massive amounts of\ndata and simulates human conversation by comprehending context and generating\nappropriate responses. It has garnered significant attention due to its ability\nto effectively answer a broad range of human inquiries, with fluent and\ncomprehensive answers surpassing prior public chatbots in both security and\nusefulness. However, a comprehensive analysis of ChatGPT's failures is lacking,\nwhich is the focus of this study. Eleven categories of failures, including\nreasoning, factual errors, math, coding, and bias, are presented and discussed.\nThe risks, limitations, and societal implications of ChatGPT are also\nhighlighted. The goal of this study is to assist researchers and developers in\nenhancing future language models and chatbots.\n","authors":["Ali Borji"],"pdf_url":"https://arxiv.org/pdf/2302.03494v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01912v2","updated":"2023-03-06T09:29:40Z","published":"2023-03-03T13:24:17Z","title":"Ancient Chinese Word Segmentation and Part-of-Speech Tagging Using\n  Distant Supervision","summary":"  Ancient Chinese word segmentation (WSG) and part-of-speech tagging (POS) are\nimportant to study ancient Chinese, but the amount of ancient Chinese WSG and\nPOS tagging data is still rare. In this paper, we propose a novel augmentation\nmethod of ancient Chinese WSG and POS tagging data using distant supervision\nover parallel corpus. However, there are still mislabeled and unlabeled ancient\nChinese words inevitably in distant supervision. To address this problem, we\ntake advantage of the memorization effects of deep neural networks and a small\namount of annotated data to get a model with much knowledge and a little noise,\nand then we use this model to relabel the ancient Chinese sentences in parallel\ncorpus. Experiments show that the model trained over the relabeled data\noutperforms the model trained over the data generated from distant supervision\nand the annotated data. Our code is available at\nhttps://github.com/farlit/ACDS.\n","authors":["Shuo Feng","Piji Li"],"pdf_url":"https://arxiv.org/pdf/2303.01912v2.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2202.07646v3","updated":"2023-03-06T06:28:18Z","published":"2022-02-15T18:48:31Z","title":"Quantifying Memorization Across Neural Language Models","summary":"  Large language models (LMs) have been shown to memorize parts of their\ntraining data, and when prompted appropriately, they will emit the memorized\ntraining data verbatim. This is undesirable because memorization violates\nprivacy (exposing user data), degrades utility (repeated easy-to-memorize text\nis often low quality), and hurts fairness (some texts are memorized over\nothers).\n  We describe three log-linear relationships that quantify the degree to which\nLMs emit memorized training data. Memorization significantly grows as we\nincrease (1) the capacity of a model, (2) the number of times an example has\nbeen duplicated, and (3) the number of tokens of context used to prompt the\nmodel. Surprisingly, we find the situation becomes more complicated when\ngeneralizing these results across model families. On the whole, we find that\nmemorization in LMs is more prevalent than previously believed and will likely\nget worse as models continues to scale, at least without active mitigations.\n","authors":["Nicholas Carlini","Daphne Ippolito","Matthew Jagielski","Katherine Lee","Florian Tramer","Chiyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2202.07646v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02915v1","updated":"2023-03-06T06:20:55Z","published":"2023-03-06T06:20:55Z","title":"GlobalNER: Incorporating Non-local Information into Named Entity\n  Recognition","summary":"  Nowadays, many Natural Language Processing (NLP) tasks see the demand for\nincorporating knowledge external to the local information to further improve\nthe performance. However, there is little related work on Named Entity\nRecognition (NER), which is one of the foundations of NLP. Specifically, no\nstudies were conducted on the query generation and re-ranking for retrieving\nthe related information for the purpose of improving NER. This work\ndemonstrates the effectiveness of a DNN-based query generation method and a\nmention-aware re-ranking architecture based on BERTScore particularly for NER.\nIn the end, a state-of-the-art performance of 61.56 micro-f1 score on WNUT17\ndataset is achieved.\n","authors":["Chiao-Wei Hsu","Keh-Yih Su"],"pdf_url":"https://arxiv.org/pdf/2303.02915v1.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.02913v1","updated":"2023-03-06T06:20:25Z","published":"2023-03-06T06:20:25Z","title":"OpenICL: An Open-Source Framework for In-context Learning","summary":"  In recent years, In-context Learning (ICL) has gained increasing attention\nand emerged as the new paradigm for large language model (LLM) evaluation.\nUnlike traditional fine-tuning methods, ICL instead adapts the pre-trained\nmodels to unseen tasks without any parameter updates. However, the\nimplementation of ICL is sophisticated due to the diverse retrieval and\ninference methods involved, as well as the varying pre-processing requirements\nfor different models, datasets, and tasks. A unified and flexible framework for\nICL is urgently needed to ease the implementation of the aforementioned\ncomponents. To facilitate ICL research, we introduce OpenICL, an open-source\ntoolkit for ICL and LLM evaluation. OpenICL is research-friendly with a highly\nflexible architecture that users can easily combine different components to\nsuit their needs. It also provides various state-of-the-art retrieval and\ninference methods to streamline the process of adapting ICL to cutting-edge\nresearch. The effectiveness of OpenICL has been validated on a wide range of\nNLP tasks, including classification, QA, machine translation, and semantic\nparsing. As a side-product, we found OpenICL to be an efficient yet robust tool\nfor LLMs evaluation. OpenICL is released at\nhttps://github.com/Shark-NLP/OpenICL\n","authors":["Zhenyu Wu","YaoXiang Wang","Jiacheng Ye","Jiangtao Feng","Jingjing Xu","Yu Qiao","Zhiyong Wu"],"pdf_url":"https://arxiv.org/pdf/2303.02913v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02909v1","updated":"2023-03-06T06:04:46Z","published":"2023-03-06T06:04:46Z","title":"Dynamic Prompting: A Unified Framework for Prompt Tuning","summary":"  It has been demonstrated that prompt tuning is highly effective in\nefficiently eliciting knowledge from language models (LMs). However, the prompt\ntuning still lags behind fine-tuning, especially when the LMs are small.\nP-tuning v2 (Liu et al., 2021b) makes it comparable with finetuning by adding\ncontinuous prompts for every layer of the pre-trained model. However,\nprepending fixed soft prompts for all instances, regardless of their\ndiscrepancy, is doubtful. In particular, the inserted prompt position, length,\nand the representations of prompts for diversified instances through different\ntasks could all affect the prompt tuning performance. To fill this gap, we\npropose dynamic prompting (DP): the position, length, and prompt representation\ncan all be dynamically optimized with respect to different tasks and instances.\nWe conduct comprehensive experiments on the SuperGlue benchmark to validate our\nhypothesis and demonstrate substantial improvements. We also derive a unified\nframework for supporting our dynamic prompting strategy. In particular, we use\na simple learning network and Gumble- Softmax for learning instance-dependent\nguidance. Experimental results show that simple instance-level position-aware\nsoft prompts can improve the classification accuracy of up to 6 points on\naverage on five datasets, reducing its gap with fine-tuning. Besides, we also\nprove its universal usefulness under full-data, few-shot, and multitask\nregimes. Combining them together can even further unleash the power of DP,\nnarrowing the distance between finetuning.\n","authors":["Xianjun Yang","Wei Cheng","Xujiang Zhao","Linda Petzold","Haifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2303.02909v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2303.02861v1","updated":"2023-03-06T03:25:59Z","published":"2023-03-06T03:25:59Z","title":"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning","summary":"  Prompt tuning, in which a base pretrained model is adapted to each task via\nconditioning on learned prompt vectors, has emerged as a promising approach for\nefficiently adapting large language models to multiple downstream tasks.\nHowever, existing methods typically learn soft prompt vectors from scratch, and\nit has not been clear how to exploit the rich cross-task knowledge with prompt\nvectors in a multitask learning setting. We propose multitask prompt tuning\n(MPT), which first learns a single transferable prompt by distilling knowledge\nfrom multiple task-specific source prompts. We then learn multiplicative low\nrank updates to this shared prompt to efficiently adapt it to each downstream\ntarget task. Extensive experiments on 23 NLP datasets demonstrate that our\nproposed approach outperforms the state-of-the-art methods, including the full\nfinetuning baseline in some cases, despite only tuning 0.035% as many\ntask-specific parameters.\n","authors":["Zhen Wang","Rameswar Panda","Leonid Karlinsky","Rogerio Feris","Huan Sun","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2303.02861v1.pdf","comment":"ICLR 2023. Project page: https://zhenwang9102.github.io/mpt.html"},{"id":"http://arxiv.org/abs/2303.02860v1","updated":"2023-03-06T03:25:43Z","published":"2023-03-06T03:25:43Z","title":"A Multi-Grained Self-Interpretable Symbolic-Neural Model For\n  Single/Multi-Labeled Text Classification","summary":"  Deep neural networks based on layer-stacking architectures have historically\nsuffered from poor inherent interpretability. Meanwhile, symbolic probabilistic\nmodels function with clear interpretability, but how to combine them with\nneural networks to enhance their performance remains to be explored. In this\npaper, we try to marry these two systems for text classification via a\nstructured language model. We propose a Symbolic-Neural model that can learn to\nexplicitly predict class labels of text spans from a constituency tree without\nrequiring any access to span-level gold labels. As the structured language\nmodel learns to predict constituency trees in a self-supervised manner, only\nraw texts and sentence-level labels are required as training data, which makes\nit essentially a general constituent-level self-interpretable classification\nmodel. Our experiments demonstrate that our approach could achieve good\nprediction accuracy in downstream tasks. Meanwhile, the predicted span labels\nare consistent with human rationales to a certain degree.\n","authors":["Xiang Hu","Xinyu Kong","Kewei Tu"],"pdf_url":"https://arxiv.org/pdf/2303.02860v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02846v1","updated":"2023-03-06T02:52:37Z","published":"2023-03-06T02:52:37Z","title":"Reducing Spurious Correlations for Aspect-Based Sentiment Analysis with\n  Variational Information Bottleneck and Contrastive Learning","summary":"  The literature on aspect-based sentiment analysis (ABSA) has been overwhelmed\nby deep neural networks, yielding state-of-the-art results for ABSA. However,\nthese deep models are susceptible to learning spurious correlations between\ninput features and output labels, which in general suffer from poor robustness\nand generalization. In this paper, we propose a novel Contrastive Variational\nInformation Bottleneck framework (called CVIB) to reduce spurious correlations\nfor ABSA. The proposed CVIB framework is composed of an original network and a\nself-pruned network, and these two networks are optimized simultaneously via\ncontrastive learning. Concretely, we employ the Variational Information\nBottleneck (VIB) principle to learn an informative and compressed network\n(self-pruned network) from the original network, which discards the superfluous\npatterns or spurious correlations between input features and prediction labels.\nThen, self-pruning contrastive learning is devised to pull together\nsemantically similar positive pairs and push away dissimilar pairs, where the\nrepresentations of the anchor learned by the original and self-pruned networks\nrespectively are regarded as a positive pair while the representations of two\ndifferent sentences within a mini-batch are treated as a negative pair.\nExtensive experiments on five benchmark ABSA datasets demonstrate that our CVIB\nmethod achieves better performance than the strong competitors in terms of\noverall prediction performance, robustness, and generalization.\n","authors":["Mingshan Chang","Min Yang","Qingshan Jiang","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2303.02846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02841v1","updated":"2023-03-06T02:24:48Z","published":"2023-03-06T02:24:48Z","title":"Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in\n  Finance","summary":"  Natural language understanding(NLU) is challenging for finance due to the\nlack of annotated data and the specialized language in that domain. As a\nresult, researchers have proposed to use pre-trained language model and\nmulti-task learning to learn robust representations. However, aggressive\nfine-tuning often causes over-fitting and multi-task learning may favor tasks\nwith significantly larger amounts data, etc. To address these problems, in this\npaper, we investigate model-agnostic meta-learning algorithm(MAML) in\nlow-resource financial NLU tasks. Our contribution includes: 1. we explore the\nperformance of MAML method with multiple types of tasks: GLUE datasets, SNLI,\nSci-Tail and Financial PhraseBank; 2. we study the performance of MAML method\nwith multiple single-type tasks: a real scenario stock price prediction problem\nwith twitter text data. Our models achieve the state-of-the-art performance\naccording to the experimental results, which demonstrate that our method can\nadapt fast and well to low-resource situations.\n","authors":["Bixing Yan","Shaoling Chen","Yuxuan He","Zhihan Li"],"pdf_url":"https://arxiv.org/pdf/2303.02841v1.pdf","comment":"13 pages, 6 figures, 8 tables"},{"id":"http://arxiv.org/abs/2302.10866v2","updated":"2023-03-06T01:26:15Z","published":"2023-02-21T18:29:25Z","title":"Hyena Hierarchy: Towards Larger Convolutional Language Models","summary":"  Recent advances in deep learning have relied heavily on the use of large\nTransformers due to their ability to learn at scale. However, the core building\nblock of Transformers, the attention operator, exhibits quadratic cost in\nsequence length, limiting the amount of context accessible. Existing\nsubquadratic methods based on low-rank and sparse approximations need to be\ncombined with dense attention layers to match Transformers, indicating a gap in\ncapability. In this work, we propose Hyena, a subquadratic drop-in replacement\nfor attention constructed by interleaving implicitly parametrized long\nconvolutions and data-controlled gating. In recall and reasoning tasks on\nsequences of thousands to hundreds of thousands of tokens, Hyena improves\naccuracy by more than 50 points over operators relying on state-spaces and\nother implicit and explicit methods, matching attention-based models. We set a\nnew state-of-the-art for dense-attention-free architectures on language\nmodeling in standard datasets (WikiText103 and The Pile), reaching Transformer\nquality with a 20% reduction in training compute required at sequence length\n2K. Hyena operators are twice as fast as highly optimized attention at sequence\nlength 8K, and 100x faster at sequence length 64K.\n","authors":["Michael Poli","Stefano Massaroli","Eric Nguyen","Daniel Y. Fu","Tri Dao","Stephen Baccus","Yoshua Bengio","Stefano Ermon","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2302.10866v2.pdf","comment":"Additional results (PG-19, LAMBADA)"},{"id":"http://arxiv.org/abs/2205.10475v2","updated":"2023-03-06T00:49:01Z","published":"2022-05-21T00:58:22Z","title":"DeepStruct: Pretraining of Language Models for Structure Prediction","summary":"  We introduce a method for improving the structural understanding abilities of\nlanguage models. Unlike previous approaches that finetune the models with\ntask-specific augmentation, we pretrain language models on a collection of\ntask-agnostic corpora to generate structures from text. Our structure\npretraining enables zero-shot transfer of the learned knowledge that models\nhave about the structure tasks. We study the performance of this approach on 28\ndatasets, spanning 10 structure prediction tasks including open information\nextraction, joint entity and relation extraction, named entity recognition,\nrelation classification, semantic role labeling, event extraction, coreference\nresolution, factual probe, intent detection, and dialogue state tracking. We\nfurther enhance the pretraining with the task-specific training sets. We show\nthat a 10B parameter language model transfers non-trivially to most tasks and\nobtains state-of-the-art performance on 21 of 28 datasets that we evaluate.\n","authors":["Chenguang Wang","Xiao Liu","Zui Chen","Haoyun Hong","Jie Tang","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2205.10475v2.pdf","comment":"ACL 2022"},{"id":"http://arxiv.org/abs/2303.03548v1","updated":"2023-03-06T23:16:24Z","published":"2023-03-06T23:16:24Z","title":"Large Language Models as Zero-Shot Human Models for Human-Robot\n  Interaction","summary":"  Human models play a crucial role in human-robot interaction (HRI), enabling\nrobots to consider the impact of their actions on people and plan their\nbehavior accordingly. However, crafting good human models is challenging;\ncapturing context-dependent human behavior requires significant prior knowledge\nand/or large amounts of interaction data, both of which are difficult to\nobtain. In this work, we explore the potential of large-language models (LLMs)\n-- which have consumed vast amounts of human-generated text data -- to act as\nzero-shot human models for HRI. Our experiments on three social datasets yield\npromising results; the LLMs are able to achieve performance comparable to\npurpose-built models. That said, we also discuss current limitations, such as\nsensitivity to prompts and spatial/numerical reasoning mishaps. Based on our\nfindings, we demonstrate how LLM-based human models can be integrated into a\nsocial robot's planning process and applied in HRI scenarios. Specifically, we\npresent one case study on a simulated trust-based table-clearing task and\nreplicate past results that relied on custom models. Next, we conduct a new\nrobot utensil-passing experiment (n = 65) where preliminary results show that\nplanning with a LLM-based human model can achieve gains over a basic myopic\nplan. In summary, our results show that LLMs offer a promising (but incomplete)\napproach to human modeling for HRI.\n","authors":["Bowen Zhang","Harold Soh"],"pdf_url":"https://arxiv.org/pdf/2303.03548v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2303.03542v1","updated":"2023-03-06T22:59:02Z","published":"2023-03-06T22:59:02Z","title":"Multi-resolution Interpretation and Diagnostics Tool for Natural\n  Language Classifiers","summary":"  Developing explainability methods for Natural Language Processing (NLP)\nmodels is a challenging task, for two main reasons. First, the high\ndimensionality of the data (large number of tokens) results in low coverage and\nin turn small contributions for the top tokens, compared to the overall model\nperformance. Second, owing to their textual nature, the input variables, after\nappropriate transformations, are effectively binary (presence or absence of a\ntoken in an observation), making the input-output relationship difficult to\nunderstand. Common NLP interpretation techniques do not have flexibility in\nresolution, because they usually operate at word-level and provide fully local\n(message level) or fully global (over all messages) summaries. The goal of this\npaper is to create more flexible model explainability summaries by segments of\nobservation or clusters of words that are semantically related to each other.\nIn addition, we introduce a root cause analysis method for NLP models, by\nanalyzing representative False Positive and False Negative examples from\ndifferent segments. At the end, we illustrate, using a Yelp review data set\nwith three segments (Restaurant, Hotel, and Beauty), that exploiting\ngroup/cluster structures in words and/or messages can aid in the interpretation\nof decisions made by NLP models and can be utilized to assess the model's\nsensitivity or bias towards gender, syntax, and word meanings.\n","authors":["Peyman Jalali","Nengfeng Zhou","Yufei Yu"],"pdf_url":"https://arxiv.org/pdf/2303.03542v1.pdf","comment":"16 pages, 0 figure"},{"id":"http://arxiv.org/abs/2211.02011v4","updated":"2023-03-06T22:28:30Z","published":"2022-11-03T17:26:44Z","title":"Inverse scaling can become U-shaped","summary":"  Scaling up language models has been empirically shown to improve performance\nand unlock emergent abilities. Conversely, observing worse performance as a\nfunction of scale (\"inverse scaling\") would indicate that scaling encourages\nbehaviors that are misaligned with human preferences. The Inverse Scaling Prize\n(McKenzie et al. 2022) identified eleven such inverse scaling tasks, evaluated\non models of up to 280B parameters and up to 500 zettaFLOPs of training\ncompute. This paper takes a closer look at these inverse scaling tasks. We\nevaluate models of up to 540B parameters, trained on five times more compute\nthan those evaluated in the Inverse Scaling Prize. With this increased range of\nmodel sizes and training compute, only four out of the eleven tasks remain\ninverse scaling. Six out of the eleven tasks exhibit what we call \"U-shaped\nscaling\" -- performance decreases up to a certain model size, and then\nincreases again up to the largest model evaluated (the one remaining task\ndisplays positive scaling). U-shaped scaling suggests that the inverse scaling\ntrend observed in McKenzie et al. (2022) may not continue to hold for larger\nmodels, and adds further support to the claim that sufficiently large models\nunlock emergent abilities.\n","authors":["Jason Wei","Najoung Kim","Yi Tay","Quoc V. Le"],"pdf_url":"https://arxiv.org/pdf/2211.02011v4.pdf","comment":"v4 reports correct results on Round 2 tasks and includes results for\n  additional one-shot evaluation"},{"id":"http://arxiv.org/abs/2302.09051v2","updated":"2023-03-06T21:46:08Z","published":"2023-02-17T18:31:31Z","title":"Complex QA and language models hybrid architectures, Survey","summary":"  This paper provides a survey of the state of the art of hybrid language\nmodels architectures and strategies for \"complex\" question-answering (QA, CQA,\nCPS). Very large language models are good at leveraging public data on standard\nproblems but once you want to tackle more specific complex questions or\nproblems you may need specific architecture, knowledge, skills, tasks, methods,\nsensitive data, performance, human approval and versatile feedback... This\nsurvey extends findings from the robust community edited research papers BIG,\nBLOOM and HELM which open source, benchmark and analyze limits and challenges\nof large language models in terms of tasks complexity and strict evaluation on\naccuracy (e.g. fairness, robustness, toxicity, ...). It identifies the key\nelements used with Large Language Models (LLM) to solve complex questions or\nproblems. Recent projects like ChatGPT and GALACTICA have allowed\nnon-specialists to grasp the great potential as well as the equally strong\nlimitations of language models in complex QA. Hybridizing these models with\ndifferent components could allow to overcome these different limits and go much\nfurther. We discuss some challenges associated with complex QA, including\ndomain adaptation, decomposition and efficient multi-step QA, long form QA,\nnon-factoid QA, safety and multi-sensitivity data protection, multimodal\nsearch, hallucinations, QA explainability and truthfulness, time dimension.\nTherefore we review current solutions and promising strategies, using elements\nsuch as hybrid LLM architectures, human-in-the-loop reinforcement learning,\nprompting adaptation, neuro-symbolic and structured knowledge grounding,\nprogram synthesis, and others. We analyze existing solutions and provide an\noverview of the current research and trends in the area of complex QA.\n","authors":["Xavier Daull","Patrice Bellot","Emmanuel Bruno","Vincent Martin","Elisabeth Murisasco"],"pdf_url":"https://arxiv.org/pdf/2302.09051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03510v1","updated":"2023-03-06T21:36:19Z","published":"2023-03-06T21:36:19Z","title":"Guilt Detection in Text: A Step Towards Understanding Complex Emotions","summary":"  We introduce a novel Natural Language Processing (NLP) task called Guilt\ndetection, which focuses on detecting guilt in text. We identify guilt as a\ncomplex and vital emotion that has not been previously studied in NLP, and we\naim to provide a more fine-grained analysis of it. To address the lack of\npublicly available corpora for guilt detection, we created VIC, a dataset\ncontaining 4622 texts from three existing emotion detection datasets that we\nbinarized into guilt and no-guilt classes. We experimented with traditional\nmachine learning methods using bag-of-words and term frequency-inverse document\nfrequency features, achieving a 72% f1 score with the highest-performing model.\nOur study provides a first step towards understanding guilt in text and opens\nthe door for future research in this area.\n","authors":["Abdul Gafar Manuel Meque","Nisar Hussain","Grigori Sidorov","Alexander Gelbukh"],"pdf_url":"https://arxiv.org/pdf/2303.03510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03487v1","updated":"2023-03-06T20:35:51Z","published":"2023-03-06T20:35:51Z","title":"Two-stage Pipeline for Multilingual Dialect Detection","summary":"  Dialect Identification is a crucial task for localizing various Large\nLanguage Models. This paper outlines our approach to the VarDial 2023 shared\ntask. Here we have to identify three or two dialects from three languages each\nwhich results in a 9-way classification for Track-1 and 6-way classification\nfor Track-2 respectively. Our proposed approach consists of a two-stage system\nand outperforms other participants' systems and previous works in this domain.\nWe achieve a score of 58.54% for Track-1 and 85.61% for Track-2. Our codebase\nis available publicly (https://github.com/ankit-vaidya19/EACL_VarDial2023).\n","authors":["Ankit Vaidya","Aditya Kane"],"pdf_url":"https://arxiv.org/pdf/2303.03487v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03480v1","updated":"2023-03-06T20:19:19Z","published":"2023-03-06T20:19:19Z","title":"Can an Embodied Agent Find Your \"Cat-shaped Mug\"? LLM-Based Zero-Shot\n  Object Navigation","summary":"  We present LGX, a novel algorithm for Object Goal Navigation in a\n\"language-driven, zero-shot manner\", where an embodied agent navigates to an\narbitrarily described target object in a previously unexplored environment. Our\napproach leverages the capabilities of Large Language Models (LLMs) for making\nnavigational decisions by mapping the LLMs implicit knowledge about the\nsemantic context of the environment into sequential inputs for robot motion\nplanning. Simultaneously, we also conduct generalized target object detection\nusing a pre-trained Vision-Language grounding model. We achieve\nstate-of-the-art zero-shot object navigation results on RoboTHOR with a success\nrate (SR) improvement of over 27% over the current baseline of the OWL-ViT CLIP\non Wheels (OWL CoW). Furthermore, we study the usage of LLMs for robot\nnavigation and present an analysis of the various semantic factors affecting\nmodel output. Finally, we showcase the benefits of our approach via real-world\nexperiments that indicate the superior performance of LGX when navigating to\nand detecting visually unique objects.\n","authors":["Vishnu Sashank Dorbala","James F. Mullen Jr.","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2303.03480v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2207.00056v3","updated":"2023-03-06T19:39:18Z","published":"2022-06-30T18:42:06Z","title":"MultiViz: Towards Visualizing and Understanding Multimodal Models","summary":"  The promise of multimodal models for real-world applications has inspired\nresearch in visualizing and understanding their internal mechanics with the end\ngoal of empowering stakeholders to visualize model behavior, perform model\ndebugging, and promote trust in machine learning models. However, modern\nmultimodal models are typically black-box neural networks, which makes it\nchallenging to understand their internal mechanics. How can we visualize the\ninternal modeling of multimodal interactions in these models? Our paper aims to\nfill this gap by proposing MultiViz, a method for analyzing the behavior of\nmultimodal models by scaffolding the problem of interpretability into 4 stages:\n(1) unimodal importance: how each modality contributes towards downstream\nmodeling and prediction, (2) cross-modal interactions: how different modalities\nrelate with each other, (3) multimodal representations: how unimodal and\ncross-modal interactions are represented in decision-level features, and (4)\nmultimodal prediction: how decision-level features are composed to make a\nprediction. MultiViz is designed to operate on diverse modalities, models,\ntasks, and research areas. Through experiments on 8 trained models across 6\nreal-world tasks, we show that the complementary stages in MultiViz together\nenable users to (1) simulate model predictions, (2) assign interpretable\nconcepts to features, (3) perform error analysis on model misclassifications,\nand (4) use insights from error analysis to debug models. MultiViz is publicly\navailable, will be regularly updated with new interpretation tools and metrics,\nand welcomes inputs from the community.\n","authors":["Paul Pu Liang","Yiwei Lyu","Gunjan Chhablani","Nihal Jain","Zihao Deng","Xingbo Wang","Louis-Philippe Morency","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2207.00056v3.pdf","comment":"ICLR 2023. Code available at: https://github.com/pliang279/MultiViz"},{"id":"http://arxiv.org/abs/2303.03457v1","updated":"2023-03-06T19:29:20Z","published":"2023-03-06T19:29:20Z","title":"Spelling convention sensitivity in neural language models","summary":"  We examine whether large neural language models, trained on very large\ncollections of varied English text, learn the potentially long-distance\ndependency of British versus American spelling conventions, i.e., whether\nspelling is consistently one or the other within model-generated strings. In\ncontrast to long-distance dependencies in non-surface underlying structure\n(e.g., syntax), spelling consistency is easier to measure both in LMs and the\ntext corpora used to train them, which can provide additional insight into\ncertain observed model behaviors. Using a set of probe words unique to either\nBritish or American English, we first establish that training corpora exhibit\nsubstantial (though not total) consistency. A large T5 language model does\nappear to internalize this consistency, though only with respect to observed\nlexical items (not nonce words with British/American spelling patterns). We\nfurther experiment with correcting for biases in the training data by\nfine-tuning T5 on synthetic data that has been debiased, and find that\nfinetuned T5 remains only somewhat sensitive to spelling consistency. Further\nexperiments show GPT2 to be similarly limited.\n","authors":["Elizabeth Nielsen","Christo Kirov","Brian Roark"],"pdf_url":"https://arxiv.org/pdf/2303.03457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03919v1","updated":"2023-03-06T04:22:33Z","published":"2023-03-06T04:22:33Z","title":"Data Portraits: Recording Foundation Model Training Data","summary":"  Foundation models are trained on increasingly immense and opaque datasets.\nEven while these models are now key in AI system building, it can be difficult\nto answer the straightforward question: has the model already encountered a\ngiven example during training? We therefore propose a widespread adoption of\nData Portraits: artifacts that record training data and allow for downstream\ninspection. First we outline the properties of such an artifact and discuss how\nexisting solutions can be used to increase transparency. We then propose and\nimplement a solution based on data sketching, stressing fast and space\nefficient querying. Using our tool, we document a popular large language\nmodeling corpus (the Pile) and show that our solution enables answering\nquestions about test set leakage and model plagiarism. Our tool is lightweight\nand fast, costing only 3% of the dataset size in overhead. We release a demo of\nour tools at dataportraits.org and call on dataset and model creators to\nrelease Data Portraits as a complement to current documentation practices.\n","authors":["Marc Marone","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2303.03919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05389v1","updated":"2023-03-06T20:08:07Z","published":"2023-03-06T20:08:07Z","title":"Depression Detection Using Digital Traces on Social Media: A\n  Knowledge-aware Deep Learning Approach","summary":"  Depression is a common disease worldwide. It is difficult to diagnose and\ncontinues to be underdiagnosed. Because depressed patients constantly share\ntheir symptoms, major life events, and treatments on social media, researchers\nare turning to user-generated digital traces on social media for depression\ndetection. Such methods have distinct advantages in combating depression\nbecause they can facilitate innovative approaches to fight depression and\nalleviate its social and economic burden. However, most existing studies lack\neffective means to incorporate established medical domain knowledge in\ndepression detection or suffer from feature extraction difficulties that impede\ngreater performance. Following the design science research paradigm, we propose\na Deep Knowledge-aware Depression Detection (DKDD) framework to accurately\ndetect social media users at risk of depression and explain the critical\nfactors that contribute to such detection. Extensive empirical studies with\nreal-world data demonstrate that, by incorporating domain knowledge, our method\noutperforms existing state-of-the-art methods. Our work has significant\nimplications for IS research in knowledge-aware machine learning, digital\ntraces utilization, and NLP research in IS. Practically, by providing early\ndetection and explaining the critical factors, DKDD can supplement clinical\ndepression screening and enable large-scale evaluations of a population's\nmental health status.\n","authors":["Wenli Zhang","Jiaheng Xie","Xiang Liu","Zhu Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05389v1.pdf","comment":"Presented at INFORMS 2022 Data Science Workshop"},{"id":"http://arxiv.org/abs/2303.05382v1","updated":"2023-03-06T16:36:17Z","published":"2023-03-06T16:36:17Z","title":"ChatGPT is on the horizon: Could a large language model be all we need\n  for Intelligent Transportation?","summary":"  ChatGPT, developed by OpenAI, is one of the largest Large Language Models\n(LLM) with over 175 billion parameters. ChatGPT has demonstrated the impressive\ncapabilities of LLM, particularly in the field of natural language processing\n(NLP). With the emergence of the discussion and application of LLM in various\nresearch or engineering domains, it is time to envision how LLM may\nrevolutionize the way we approach intelligent transportation systems. This\npaper explores the future applications of LLM in addressing key transportation\nproblems. By leveraging LLM and a cross-modal encoder, an intelligent system\ncan handle traffic data from various modalities and execute transportation\noperations through a single LLM. NLP, combined with cross-modal processing, is\ninvestigated with its potential applications in transportation. To demonstrate\nthis potential, a smartphone-based crash report auto-generation and analysis\nframework is presented as a use case. Despite the potential benefits,\nchallenges related to data privacy, data quality, and model bias must be\nconsidered. Overall, the use of LLM in intelligent transport systems holds\npromise for more efficient, intelligent, and sustainable transportation systems\nthat improve the lives of people around the world.\n","authors":["Ou Zheng","Mohamed Abdel-Aty","Dongdong Wang","Zijin Wang","Shengxuan Ding"],"pdf_url":"https://arxiv.org/pdf/2303.05382v1.pdf","comment":"Submitted to Nature - Machine Intelligence (13 Pages, 8 Figures)"},{"id":"http://arxiv.org/abs/2303.06026v1","updated":"2023-03-06T22:24:31Z","published":"2023-03-06T22:24:31Z","title":"wav2vec and its current potential to Automatic Speech Recognition in\n  German for the usage in Digital History: A comparative assessment of\n  available ASR-technologies for the use in cultural heritage contexts","summary":"  In this case study we trained and published a state-of-the-art open-source\nmodel for Automatic Speech Recognition (ASR) for German to evaluate the current\npotential of this technology for the use in the larger context of Digital\nHumanities and cultural heritage indexation. Along with this paper we publish\nour wav2vec2 based speech to text model while we evaluate its performance on a\ncorpus of historical recordings we assembled compared against commercial\ncloud-based and proprietary services. While our model achieves moderate\nresults, we see that proprietary cloud services fare significantly better. As\nour results show, recognition rates over 90 percent can currently be achieved,\nhowever, these numbers drop quickly once the recordings feature limited audio\nquality or use of non-every day or outworn language. A big issue is the high\nvariety of different dialects and accents in the German language. Nevertheless,\nthis paper highlights that the currently available quality of recognition is\nhigh enough to address various use cases in the Digital Humanities. We argue\nthat ASR will become a key technology for the documentation and analysis of\naudio-visual sources and identify an array of important questions that the DH\ncommunity and cultural heritage stakeholders will have to address in the near\nfuture.\n","authors":["Michael Fleck","Wolfgang Göderle"],"pdf_url":"https://arxiv.org/pdf/2303.06026v1.pdf","comment":"11 pages, 2 tables"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.03373v1","updated":"2023-03-06T18:56:26Z","published":"2023-03-06T18:56:26Z","title":"Detecting Human-Object Contact in Images","summary":"  Humans constantly contact objects to move and perform tasks. Thus, detecting\nhuman-object contact is important for building human-centered artificial\nintelligence. However, there exists no robust method to detect contact between\nthe body and the scene from an image, and there exists no dataset to learn such\na detector. We fill this gap with HOT (\"Human-Object conTact\"), a new dataset\nof human-object contacts for images. To build HOT, we use two data sources: (1)\nWe use the PROX dataset of 3D human meshes moving in 3D scenes, and\nautomatically annotate 2D image areas for contact via 3D mesh proximity and\nprojection. (2) We use the V-COCO, HAKE and Watch-n-Patch datasets, and ask\ntrained annotators to draw polygons for the 2D image areas where contact takes\nplace. We also annotate the involved body part of the human body. We use our\nHOT dataset to train a new contact detector, which takes a single color image\nas input, and outputs 2D contact heatmaps as well as the body-part labels that\nare in contact. This is a new and challenging task that extends current\nfoot-ground or hand-object contact detectors to the full generality of the\nwhole body. The detector uses a part-attention branch to guide contact\nestimation through the context of the surrounding body parts and scene. We\nevaluate our detector extensively, and quantitative results show that our model\noutperforms baselines, and that all components contribute to better\nperformance. Results on images from an online repository show reasonable\ndetections and generalizability.\n","authors":["Yixin Chen","Sai Kumar Dwivedi","Michael J. Black","Dimitrios Tzionas"],"pdf_url":"https://arxiv.org/pdf/2303.03373v1.pdf","comment":"Accepted at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.03369v1","updated":"2023-03-06T18:54:46Z","published":"2023-03-06T18:54:46Z","title":"Multimodal Prompting with Missing Modalities for Visual Recognition","summary":"  In this paper, we tackle two challenges in multimodal learning for visual\nrecognition: 1) when missing-modality occurs either during training or testing\nin real-world situations; and 2) when the computation resources are not\navailable to finetune on heavy transformer models. To this end, we propose to\nutilize prompt learning and mitigate the above two challenges together.\nSpecifically, our modality-missing-aware prompts can be plugged into multimodal\ntransformers to handle general missing-modality cases, while only requiring\nless than 1% learnable parameters compared to training the entire model. We\nfurther explore the effect of different prompt configurations and analyze the\nrobustness to missing modality. Extensive experiments are conducted to show the\neffectiveness of our prompt learning framework that improves the performance\nunder various missing-modality cases, while alleviating the requirement of\nheavy model re-training. Code is available.\n","authors":["Yi-Lun Lee","Yi-Hsuan Tsai","Wei-Chen Chiu","Chen-Yu Lee"],"pdf_url":"https://arxiv.org/pdf/2303.03369v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.03366v1","updated":"2023-03-06T18:50:06Z","published":"2023-03-06T18:50:06Z","title":"Referring Multi-Object Tracking","summary":"  Existing referring understanding tasks tend to involve the detection of a\nsingle text-referred object. In this paper, we propose a new and general\nreferring understanding task, termed referring multi-object tracking (RMOT).\nIts core idea is to employ a language expression as a semantic cue to guide the\nprediction of multi-object tracking. To the best of our knowledge, it is the\nfirst work to achieve an arbitrary number of referent object predictions in\nvideos. To push forward RMOT, we construct one benchmark with scalable\nexpressions based on KITTI, named Refer-KITTI. Specifically, it provides 18\nvideos with 818 expressions, and each expression in a video is annotated with\nan average of 10.7 objects. Further, we develop a transformer-based\narchitecture TransRMOT to tackle the new task in an online manner, which\nachieves impressive detection performance and outperforms other counterparts.\n","authors":["Dongming Wu","Wencheng Han","Tiancai Wang","Xingping Dong","Xiangyu Zhang","Jianbing Shen"],"pdf_url":"https://arxiv.org/pdf/2303.03366v1.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2303.03364v1","updated":"2023-03-06T18:49:39Z","published":"2023-03-06T18:49:39Z","title":"Leveraging Scene Embeddings for Gradient-Based Motion Planning in Latent\n  Space","summary":"  Motion planning framed as optimisation in structured latent spaces has\nrecently emerged as competitive with traditional methods in terms of planning\nsuccess while significantly outperforming them in terms of computational speed.\nHowever, the real-world applicability of recent work in this domain remains\nlimited by the need to express obstacle information directly in state-space,\ninvolving simple geometric primitives. In this work we address this challenge\nby leveraging learned scene embeddings together with a generative model of the\nrobot manipulator to drive the optimisation process. In addition, we introduce\nan approach for efficient collision checking which directly regularises the\noptimisation undertaken for planning. Using simulated as well as real-world\nexperiments, we demonstrate that our approach, AMP-LS, is able to successfully\nplan in novel, complex scenes while outperforming traditional planning\nbaselines in terms of computation speed by an order of magnitude. We show that\nthe resulting system is fast enough to enable closed-loop planning in\nreal-world dynamic scenes.\n","authors":["Jun Yamada","Chia-Man Hung","Jack Collins","Ioannis Havoutis","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2303.03364v1.pdf","comment":"Project website: https://amp-ls.github.io/"},{"id":"http://arxiv.org/abs/2303.03361v1","updated":"2023-03-06T18:48:18Z","published":"2023-03-06T18:48:18Z","title":"Nerflets: Local Radiance Fields for Efficient Structure-Aware 3D Scene\n  Representation from 2D Supervisio","summary":"  We address efficient and structure-aware 3D scene representation from images.\nNerflets are our key contribution -- a set of local neural radiance fields that\ntogether represent a scene. Each nerflet maintains its own spatial position,\norientation, and extent, within which it contributes to panoptic, density, and\nradiance reconstructions. By leveraging only photometric and inferred panoptic\nimage supervision, we can directly and jointly optimize the parameters of a set\nof nerflets so as to form a decomposed representation of the scene, where each\nobject instance is represented by a group of nerflets. During experiments with\nindoor and outdoor environments, we find that nerflets: (1) fit and approximate\nthe scene more efficiently than traditional global NeRFs, (2) allow the\nextraction of panoptic and photometric renderings from arbitrary views, and (3)\nenable tasks rare for NeRFs, such as 3D panoptic segmentation and interactive\nediting.\n","authors":["Xiaoshuai Zhang","Abhijit Kundu","Thomas Funkhouser","Leonidas Guibas","Hao Su","Kyle Genova"],"pdf_url":"https://arxiv.org/pdf/2303.03361v1.pdf","comment":"accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2209.12152v3","updated":"2023-03-06T18:28:18Z","published":"2022-09-25T05:21:59Z","title":"All are Worth Words: A ViT Backbone for Diffusion Models","summary":"  Vision transformers (ViT) have shown promise in various vision tasks while\nthe U-Net based on a convolutional neural network (CNN) remains dominant in\ndiffusion models. We design a simple and general ViT-based architecture (named\nU-ViT) for image generation with diffusion models. U-ViT is characterized by\ntreating all inputs including the time, condition and noisy image patches as\ntokens and employing long skip connections between shallow and deep layers. We\nevaluate U-ViT in unconditional and class-conditional image generation, as well\nas text-to-image generation tasks, where U-ViT is comparable if not superior to\na CNN-based U-Net of a similar size. In particular, latent diffusion models\nwith U-ViT achieve record-breaking FID scores of 2.29 in class-conditional\nimage generation on ImageNet 256x256, and 5.48 in text-to-image generation on\nMS-COCO, among methods without accessing large external datasets during the\ntraining of generative models. Our results suggest that, for diffusion-based\nimage modeling, the long skip connection is crucial while the down-sampling and\nup-sampling operators in CNN-based U-Net are not always necessary. We believe\nthat U-ViT can provide insights for future research on backbones in diffusion\nmodels and benefit generative modeling on large scale cross-modality datasets.\n","authors":["Fan Bao","Shen Nie","Kaiwen Xue","Yue Cao","Chongxuan Li","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2209.12152v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03341v1","updated":"2023-03-06T18:21:16Z","published":"2023-03-06T18:21:16Z","title":"Deep Age-Invariant Fingerprint Segmentation System","summary":"  Fingerprint-based identification systems achieve higher accuracy when a slap\ncontaining multiple fingerprints of a subject is used instead of a single\nfingerprint. However, segmenting or auto-localizing all fingerprints in a slap\nimage is a challenging task due to the different orientations of fingerprints,\nnoisy backgrounds, and the smaller size of fingertip components. The presence\nof slap images in a real-world dataset where one or more fingerprints are\nrotated makes it challenging for a biometric recognition system to localize and\nlabel the fingerprints automatically. Improper fingerprint localization and\nfinger labeling errors lead to poor matching performance. In this paper, we\nintroduce a method to generate arbitrary angled bounding boxes using a deep\nlearning-based algorithm that precisely localizes and labels fingerprints from\nboth axis-aligned and over-rotated slap images. We built a fingerprint\nsegmentation model named CRFSEG (Clarkson Rotated Fingerprint segmentation\nModel) by updating the previously proposed CFSEG model which was based on\ntraditional Faster R-CNN architecture [21]. CRFSEG improves upon the Faster\nR-CNN algorithm with arbitrarily angled bounding boxes that allow the CRFSEG to\nperform better in challenging slap images. After training the CRFSEG algorithm\non a new dataset containing slap images collected from both adult and children\nsubjects, our results suggest that the CRFSEG model was invariant across\ndifferent age groups and can handle over-rotated slap images successfully. In\nthe Combined dataset containing both normal and rotated images of adult and\nchildren subjects, we achieved a matching accuracy of 97.17%, which\noutperformed state-of-the-art VeriFinger (94.25%) and NFSEG segmentation\nsystems (80.58%).\n","authors":["M. G. Sarwar Murshed","Keivan Bahmani","Stephanie Schuckers","Faraz Hussain"],"pdf_url":"https://arxiv.org/pdf/2303.03341v1.pdf","comment":"20 Pages, 14 figures, Journal"},{"id":"http://arxiv.org/abs/2302.03956v2","updated":"2023-03-06T18:12:46Z","published":"2023-02-08T09:26:22Z","title":"Neural Congealing: Aligning Images to a Joint Semantic Atlas","summary":"  We present Neural Congealing -- a zero-shot self-supervised framework for\ndetecting and jointly aligning semantically-common content across a given set\nof images. Our approach harnesses the power of pre-trained DINO-ViT features to\nlearn: (i) a joint semantic atlas -- a 2D grid that captures the mode of\nDINO-ViT features in the input set, and (ii) dense mappings from the unified\natlas to each of the input images. We derive a new robust self-supervised\nframework that optimizes the atlas representation and mappings per image set,\nrequiring only a few real-world images as input without any additional input\ninformation (e.g., segmentation masks). Notably, we design our losses and\ntraining paradigm to account only for the shared content under severe\nvariations in appearance, pose, background clutter or other distracting\nobjects. We demonstrate results on a plethora of challenging image sets\nincluding sets of mixed domains (e.g., aligning images depicting sculpture and\nartwork of cats), sets depicting related yet different object categories (e.g.,\ndogs and tigers), or domains for which large-scale training data is scarce\n(e.g., coffee mugs). We thoroughly evaluate our method and show that our\ntest-time optimization approach performs favorably compared to a\nstate-of-the-art method that requires extensive training on large-scale\ndatasets.\n","authors":["Dolev Ofri-Amar","Michal Geyer","Yoni Kasten","Tali Dekel"],"pdf_url":"https://arxiv.org/pdf/2302.03956v2.pdf","comment":"Project page: https://neural-congealing.github.io/"},{"id":"http://arxiv.org/abs/2303.03323v1","updated":"2023-03-06T17:48:32Z","published":"2023-03-06T17:48:32Z","title":"CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive\n  Learning","summary":"  Multimodal contrastive pretraining has been utilized to train multimodal\nrepresentation models, like CLIP, on vast amounts of paired image-text data.\nHowever, previous studies have highlighted the susceptibility of such models to\nbackdoor attacks. Specifically, when training on backdoored examples, CLIP\nlearns spurious correlations between the embedded backdoor trigger and the\ntarget label, aligning their representations in the joint embedding space. With\ninjecting only a few poisoned examples e.g., 75 examples in the 3M pretraining\ndata, the model's behavior can be significantly manipulated, thus making it\nhard to detect or unlearn such correlations. To address this issue, we propose\nCleanCLIP, a finetuning framework that weakens the learned spurious\nassociations introduced by backdoor attacks by re-aligning the representations\nfor individual modalities independently. CleanCLIP can be employed for both\nunsupervised finetuning on paired image-text data and for supervised finetuning\non labeled image data. We demonstrate that unsupervised finetuning with a\ncombination of multimodal contrastive and unimodal self-supervised objectives\nfor individual modalities can significantly reduce the impact of the backdoor\nattack. Additionally, supervised finetuning on task-specific labeled data of\nthe individual modality, such as image data, removes the backdoor trigger from\nthe CLIP vision encoder. Empirically, we show that CleanCLIP maintains model\nperformance on benign examples while mitigating the impact of a range of\nbackdoor attacks on multimodal contrastive learning.\n","authors":["Hritik Bansal","Nishad Singhi","Yu Yang","Fan Yin","Aditya Grover","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03323v1.pdf","comment":"20 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2303.03315v1","updated":"2023-03-06T17:38:03Z","published":"2023-03-06T17:38:03Z","title":"MACARONS: Mapping And Coverage Anticipation with RGB Online\n  Self-Supervision","summary":"  We introduce a method that simultaneously learns to explore new large\nenvironments and to reconstruct them in 3D from color images only. This is\nclosely related to the Next Best View problem (NBV), where one has to identify\nwhere to move the camera next to improve the coverage of an unknown scene.\nHowever, most of the current NBV methods rely on depth sensors, need 3D\nsupervision and/or do not scale to large scenes. Our method requires only a\ncolor camera and no 3D supervision. It simultaneously learns in a\nself-supervised fashion to predict a \"volume occupancy field\" from color images\nand, from this field, to predict the NBV. Thanks to this approach, our method\nperforms well on new scenes as it is not biased towards any training 3D data.\nWe demonstrate this on a recent dataset made of various 3D scenes and show it\nperforms even better than recent methods requiring a depth sensor, which is not\na realistic assumption for outdoor scenes captured with a flying drone.\n","authors":["Antoine Guédon","Tom Monnier","Pascal Monasse","Vincent Lepetit"],"pdf_url":"https://arxiv.org/pdf/2303.03315v1.pdf","comment":"To appear at CVPR 2023. Project Webpage:\n  https://imagine.enpc.fr/~guedona/MACARONS/"},{"id":"http://arxiv.org/abs/2303.03307v1","updated":"2023-03-06T17:26:30Z","published":"2023-03-06T17:26:30Z","title":"Learning Efficient Coding of Natural Images with Maximum Manifold\n  Capacity Representations","summary":"  Self-supervised Learning (SSL) provides a strategy for constructing useful\nrepresentations of images without relying on hand-assigned labels. Many such\nmethods aim to map distinct views of the same scene or object to nearby points\nin the representation space, while employing some constraint to prevent\nrepresentational collapse. Here we recast the problem in terms of efficient\ncoding by adopting manifold capacity, a measure that quantifies the quality of\na representation based on the number of linearly separable object manifolds it\ncan support, as the efficiency metric to optimize. Specifically, we adapt the\nmanifold capacity for use as an objective function in a contrastive learning\nframework, yielding a Maximum Manifold Capacity Representation (MMCR). We apply\nthis method to unlabeled images, each augmented by a set of basic\ntransformations, and find that it learns meaningful features using the standard\nlinear evaluation protocol. Specifically, we find that MMCRs support\nperformance on object recognition comparable to or surpassing that of recently\ndeveloped SSL frameworks, while providing more robustness to adversarial\nattacks. Empirical analyses reveal differences between MMCRs and\nrepresentations learned by other SSL frameworks, and suggest a mechanism by\nwhich manifold compression gives rise to class separability.\n","authors":["Thomas Yerxa","Yilun Kuang","Eero Simoncelli","SueYeon Chung"],"pdf_url":"https://arxiv.org/pdf/2303.03307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08672v2","updated":"2023-03-06T17:22:50Z","published":"2022-08-18T07:11:34Z","title":"RRWaveNet: A Compact End-to-End Multi-Scale Residual CNN for Robust PPG\n  Respiratory Rate Estimation","summary":"  Respiratory rate (RR) is an important biomarker as RR changes can reflect\nsevere medical events such as heart disease, lung disease, and sleep disorders.\nUnfortunately, standard manual RR counting is prone to human error and cannot\nbe performed continuously. This study proposes a method for continuously\nestimating RR, RRWaveNet. The method is a compact end-to-end deep learning\nmodel which does not require feature engineering and can use low-cost raw\nphotoplethysmography (PPG) as input signal. RRWaveNet was tested\nsubject-independently and compared to baseline in four datasets (BIDMC,\nCapnoBase, WESAD, and SensAI) and using three window sizes (16, 32, and 64\nseconds). RRWaveNet outperformed current state-of-the-art methods with mean\nabsolute errors at optimal window size of 1.66 \\pm 1.01, 1.59 \\pm 1.08, 1.92\n\\pm 0.96 and 1.23 \\pm 0.61 breaths per minute for each dataset. In remote\nmonitoring settings, such as in the WESAD and SensAI datasets, we apply\ntransfer learning to improve the performance using two other ICU datasets as\npretraining datasets, reducing the MAE by up to 21$\\%$. This shows that this\nmodel allows accurate and practical estimation of RR on affordable and wearable\ndevices. Our study also shows feasibility of remote RR monitoring in the\ncontext of telemedicine and at home.\n","authors":["Pongpanut Osathitporn","Guntitat Sawadwuthikul","Punnawish Thuwajit","Kawisara Ueafuea","Thee Mateepithaktham","Narin Kunaseth","Tanut Choksatchawathi","Proadpran Punyabukkana","Emmanuel Mignot","Theerawit Wilaiprasitporn"],"pdf_url":"https://arxiv.org/pdf/2208.08672v2.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.03301v1","updated":"2023-03-06T17:19:28Z","published":"2023-03-06T17:19:28Z","title":"Exploring Deep Models for Practical Gait Recognition","summary":"  Gait recognition is a rapidly advancing vision technique for person\nidentification from a distance. Prior studies predominantly employed relatively\nsmall and shallow neural networks to extract subtle gait features, achieving\nimpressive successes in indoor settings. Nevertheless, experiments revealed\nthat these existing methods mostly produce unsatisfactory results when applied\nto newly released in-the-wild gait datasets. This paper presents a unified\nperspective to explore how to construct deep models for state-of-the-art\noutdoor gait recognition, including the classical CNN-based and emerging\nTransformer-based architectures. Consequently, we emphasize the importance of\nsuitable network capacity, explicit temporal modeling, and deep transformer\nstructure for discriminative gait representation learning. Our proposed\nCNN-based DeepGaitV2 series and Transformer-based SwinGait series exhibit\nsignificant performance gains in outdoor scenarios, \\textit{e.g.}, about +30\\%\nrank-1 accuracy compared with many state-of-the-art methods on the challenging\nGREW dataset. This work is expected to further boost the research and\napplication of gait recognition. Code will be available at\nhttps://github.com/ShiqiYu/OpenGait.\n","authors":["Chao Fan","Saihui Hou","Yongzhen Huang","Shiqi Yu"],"pdf_url":"https://arxiv.org/pdf/2303.03301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03281v1","updated":"2023-03-06T16:52:11Z","published":"2023-03-06T16:52:11Z","title":"Visual Place Recognition: A Tutorial","summary":"  Localization is an essential capability for mobile robots. A rapidly growing\nfield of research in this area is Visual Place Recognition (VPR), which is the\nability to recognize previously seen places in the world based solely on\nimages. This present work is the first tutorial paper on visual place\nrecognition. It unifies the terminology of VPR and complements prior research\nin two important directions: 1) It provides a systematic introduction for\nnewcomers to the field, covering topics such as the formulation of the VPR\nproblem, a general-purpose algorithmic pipeline, an evaluation methodology for\nVPR approaches, and the major challenges for VPR and how they may be addressed.\n2) As a contribution for researchers acquainted with the VPR problem, it\nexamines the intricacies of different VPR problem types regarding input, data\nprocessing, and output. The tutorial also discusses the subtleties behind the\nevaluation of VPR algorithms, e.g., the evaluation of a VPR system that has to\nfind all matching database images per query, as opposed to just a single match.\nPractical code examples in Python illustrate to prospective practitioners and\nresearchers how VPR is implemented and evaluated.\n","authors":["Stefan Schubert","Peer Neubert","Sourav Garg","Michael Milford","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2303.03281v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2303.01818v2","updated":"2023-03-06T16:34:15Z","published":"2023-03-03T09:59:25Z","title":"Word-As-Image for Semantic Typography","summary":"  A word-as-image is a semantic typography technique where a word illustration\npresents a visualization of the meaning of the word, while also preserving its\nreadability. We present a method to create word-as-image illustrations\nautomatically. This task is highly challenging as it requires semantic\nunderstanding of the word and a creative idea of where and how to depict these\nsemantics in a visually pleasing and legible manner. We rely on the remarkable\nability of recent large pretrained language-vision models to distill textual\nconcepts visually. We target simple, concise, black-and-white designs that\nconvey the semantics clearly. We deliberately do not change the color or\ntexture of the letters and do not use embellishments. Our method optimizes the\noutline of each letter to convey the desired concept, guided by a pretrained\nStable Diffusion model. We incorporate additional loss terms to ensure the\nlegibility of the text and the preservation of the style of the font. We show\nhigh quality and engaging results on numerous examples and compare to\nalternative techniques.\n","authors":["Shir Iluz","Yael Vinker","Amir Hertz","Daniel Berio","Daniel Cohen-Or","Ariel Shamir"],"pdf_url":"https://arxiv.org/pdf/2303.01818v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06930v2","updated":"2023-03-06T16:23:09Z","published":"2022-11-13T15:41:50Z","title":"PaintNet: Unstructured Multi-Path Learning from 3D Point Clouds for\n  Robotic Spray Painting","summary":"  Popular industrial robotic problems such as spray painting and welding\nrequire (i) conditioning on free-shape 3D objects and (ii) planning of multiple\ntrajectories to solve the task. Yet, existing solutions make strong assumptions\non the form of input surfaces and the nature of output paths, resulting in\nlimited approaches unable to cope with real-data variability. By leveraging on\nrecent advances in 3D deep learning, we introduce a novel framework capable of\ndealing with arbitrary 3D surfaces, and handling a variable number of unordered\noutput paths (i.e. unstructured). Our approach focuses on predicting smaller\npath segments, which can be later concatenated to reconstruct long-horizon\npaths. We extensively validate the proposed method in the context of robotic\nspray painting by releasing PaintNet, the first public dataset of expert\ndemonstrations on free-shape 3D objects collected in a real industrial\nscenario. A thorough experimental analysis demonstrates the capabilities of our\nmodel to promptly predict smooth output paths that cover up to 95% of the\nsurface of previously unseen object instances. Furthermore, we show how models\nlearned from PaintNet capture relevant features which serve as a reliable\nstarting point to improve data and time efficiency when dealing with new object\ncategories.\n","authors":["Gabriele Tiboni","Raffaello Camoriano","Tatiana Tommasi"],"pdf_url":"https://arxiv.org/pdf/2211.06930v2.pdf","comment":"Project website at https://gabrieletiboni.github.io/paintnet"},{"id":"http://arxiv.org/abs/2206.02307v2","updated":"2023-03-06T16:08:39Z","published":"2022-06-06T01:30:03Z","title":"Bootstrapping Semi-supervised Medical Image Segmentation with\n  Anatomical-aware Contrastive Distillation","summary":"  Contrastive learning has shown great promise over annotation scarcity\nproblems in the context of medical image segmentation. Existing approaches\ntypically assume a balanced class distribution for both labeled and unlabeled\nmedical images. However, medical image data in reality is commonly imbalanced\n(i.e., multi-class label imbalance), which naturally yields blurry contours and\nusually incorrectly labels rare objects. Moreover, it remains unclear whether\nall negative samples are equally negative. In this work, we present ACTION, an\nAnatomical-aware ConTrastive dIstillatiON framework, for semi-supervised\nmedical image segmentation. Specifically, we first develop an iterative\ncontrastive distillation algorithm by softly labeling the negatives rather than\nbinary supervision between positive and negative pairs. We also capture more\nsemantically similar features from the randomly chosen negative set compared to\nthe positives to enforce the diversity of the sampled data. Second, we raise a\nmore important question: Can we really handle imbalanced samples to yield\nbetter performance? Hence, the key innovation in ACTION is to learn global\nsemantic relationship across the entire dataset and local anatomical features\namong the neighbouring pixels with minimal additional memory footprint. During\nthe training, we introduce anatomical contrast by actively sampling a sparse\nset of hard negative pixels, which can generate smoother segmentation\nboundaries and more accurate predictions. Extensive experiments across two\nbenchmark datasets and different unlabeled settings show that ACTION\nsignificantly outperforms the current state-of-the-art semi-supervised methods.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2206.02307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03242v1","updated":"2023-03-06T16:01:30Z","published":"2023-03-06T16:01:30Z","title":"Evaluating the Fairness of Deep Learning Uncertainty Estimates in\n  Medical Image Analysis","summary":"  Although deep learning (DL) models have shown great success in many medical\nimage analysis tasks, deployment of the resulting models into real clinical\ncontexts requires: (1) that they exhibit robustness and fairness across\ndifferent sub-populations, and (2) that the confidence in DL model predictions\nbe accurately expressed in the form of uncertainties. Unfortunately, recent\nstudies have indeed shown significant biases in DL models across demographic\nsubgroups (e.g., race, sex, age) in the context of medical image analysis,\nindicating a lack of fairness in the models. Although several methods have been\nproposed in the ML literature to mitigate a lack of fairness in DL models, they\nfocus entirely on the absolute performance between groups without considering\ntheir effect on uncertainty estimation. In this work, we present the first\nexploration of the effect of popular fairness models on overcoming biases\nacross subgroups in medical image analysis in terms of bottom-line performance,\nand their effects on uncertainty quantification. We perform extensive\nexperiments on three different clinically relevant tasks: (i) skin lesion\nclassification, (ii) brain tumour segmentation, and (iii) Alzheimer's disease\nclinical score regression. Our results indicate that popular ML methods, such\nas data-balancing and distributionally robust optimization, succeed in\nmitigating fairness issues in terms of the model performances for some of the\ntasks. However, this can come at the cost of poor uncertainty estimates\nassociated with the model predictions. This tradeoff must be mitigated if\nfairness models are to be adopted in medical image analysis.\n","authors":["Raghav Mehta","Changjian Shui","Tal Arbel"],"pdf_url":"https://arxiv.org/pdf/2303.03242v1.pdf","comment":"Paper accepted at MIDL 2023"},{"id":"http://arxiv.org/abs/2303.03231v1","updated":"2023-03-06T15:48:33Z","published":"2023-03-06T15:48:33Z","title":"StyO: Stylize Your Face in Only One-Shot","summary":"  This paper focuses on face stylization with a single artistic target.\nExisting works for this task often fail to retain the source content while\nachieving geometry variation. Here, we present a novel StyO model, ie. Stylize\nthe face in only One-shot, to solve the above problem. In particular, StyO\nexploits a disentanglement and recombination strategy. It first disentangles\nthe content and style of source and target images into identifiers, which are\nthen recombined in a cross manner to derive the stylized face image. In this\nway, StyO decomposes complex images into independent and specific attributes,\nand simplifies one-shot face stylization as the combination of different\nattributes from input images, thus producing results better matching face\ngeometry of target image and content of source one. StyO is implemented with\nlatent diffusion models (LDM) and composed of two key modules: 1) Identifier\nDisentanglement Learner (IDL) for disentanglement phase. It represents\nidentifiers as contrastive text prompts, ie. positive and negative\ndescriptions. And it introduces a novel triple reconstruction loss to fine-tune\nthe pre-trained LDM for encoding style and content into corresponding\nidentifiers; 2) Fine-grained Content Controller (FCC) for the recombination\nphase. It recombines disentangled identifiers from IDL to form an augmented\ntext prompt for generating stylized faces. In addition, FCC also constrains the\ncross-attention maps of latent and text features to preserve source face\ndetails in results. The extensive evaluation shows that StyO produces\nhigh-quality images on numerous paintings of various styles and outperforms the\ncurrent state-of-the-art. Code will be released upon acceptance.\n","authors":["Bonan Li","Zicheng Zhang","Xuecheng Nie","Congying Han","Yinhan Hu","Tiande Guo"],"pdf_url":"https://arxiv.org/pdf/2303.03231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01592v2","updated":"2023-03-06T15:48:03Z","published":"2023-03-02T21:31:35Z","title":"Joint cortical registration of geometry and function using\n  semi-supervised learning","summary":"  Brain surface-based image registration, an important component of brain image\nanalysis, establishes spatial correspondence between cortical surfaces.\nExisting iterative and learning-based approaches focus on accurate registration\nof folding patterns of the cerebral cortex, and assume that geometry predicts\nfunction and thus functional areas will also be well aligned. However,\nstructure/functional variability of anatomically corresponding areas across\nsubjects has been widely reported. In this work, we introduce a learning-based\ncortical registration framework, JOSA, which jointly aligns folding patterns\nand functional maps while simultaneously learning an optimal atlas. We\ndemonstrate that JOSA can substantially improve registration performance in\nboth anatomical and functional domains over existing methods. By employing a\nsemi-supervised training strategy, the proposed framework obviates the need for\nfunctional data during inference, enabling its use in broad neuroscientific\ndomains where functional data may not be observed.\n","authors":["Jian Li","Greta Tuckute","Evelina Fedorenko","Brian L. Edlow","Bruce Fischl","Adrian V. Dalca"],"pdf_url":"https://arxiv.org/pdf/2303.01592v2.pdf","comment":"* co-senior authors with equal contribution"},{"id":"http://arxiv.org/abs/2210.04613v2","updated":"2023-03-06T15:45:44Z","published":"2022-10-03T13:34:11Z","title":"Enhancing Fine-Grained 3D Object Recognition using Hybrid Multi-Modal\n  Vision Transformer-CNN Models","summary":"  Robots operating in human-centered environments, such as retail stores,\nrestaurants, and households, are often required to distinguish between similar\nobjects in different contexts with a high degree of accuracy. However,\nfine-grained object recognition remains a challenge in robotics due to the high\nintra-category and low inter-category dissimilarities. In addition, the limited\nnumber of fine-grained 3D datasets poses a significant problem in addressing\nthis issue effectively. In this paper, we propose a hybrid multi-modal Vision\nTransformer (ViT) and Convolutional Neural Networks (CNN) approach to improve\nthe performance of fine-grained visual classification (FGVC). To address the\nshortage of FGVC 3D datasets, we generated two synthetic datasets. The first\ndataset consists of 20 categories related to restaurants with a total of 100\ninstances, while the second dataset contains 120 shoe instances. Our approach\nwas evaluated on both datasets, and the results indicate that it outperforms\nboth CNN-only and ViT-only baselines, achieving a recognition accuracy of 94.50\n% and 93.51 % on the restaurant and shoe datasets, respectively. Additionally,\nwe have made our FGVC RGB-D datasets available to the research community to\nenable further experimentation and advancement. Furthermore, we successfully\nintegrated our proposed method with a robot framework and demonstrated its\npotential as a fine-grained perception tool in both simulated and real-world\nrobotic scenarios.\n","authors":["Songsong Xiong","Georgios Tziafas","Hamidreza Kasaei"],"pdf_url":"https://arxiv.org/pdf/2210.04613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.02928v2","updated":"2023-03-06T15:26:24Z","published":"2022-03-06T10:14:09Z","title":"Evaluation of Interpretability Methods and Perturbation Artifacts in\n  Deep Neural Networks","summary":"  Despite excellent performance of deep neural networks (DNNs) in image\nclassification, detection, and prediction, characterizing how DNNs make a given\ndecision remains an open problem, resulting in a number of interpretability\nmethods. Post-hoc interpretability methods primarily aim to quantify the\nimportance of input features with respect to the class probabilities. However,\ndue to the lack of ground truth and the existence of interpretability methods\nwith diverse operating characteristics, evaluating these methods is a crucial\nchallenge. A popular approach to evaluate interpretability methods is to\nperturb input features deemed important for a given prediction and observe the\ndecrease in accuracy. However, perturbation itself may introduce artifacts,\nsince perturbed images may be out-of-distribution (OOD). In this paper, we have\nconducted computational experiments to estimate the contribution of\nperturbation artifacts and developed a method to estimate the fidelity of\ninterpretability methods. We demonstrate that, while perturbation artifacts\nindeed exist, we can minimize and characterize their impact on fidelity\nestimation by utilizing model accuracy curves from perturbing input features\naccording to the Most Import First (MIF) and Least Import First (LIF) orders.\nUsing the ResNet-50 trained on the ImageNet, we demonstrate the proposed\nfidelity estimation of four popular post-hoc interpretability methods.\n","authors":["Lennart Brocki","Neo Christopher Chung"],"pdf_url":"https://arxiv.org/pdf/2203.02928v2.pdf","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.03212v1","updated":"2023-03-06T15:14:16Z","published":"2023-03-06T15:14:16Z","title":"Combination of Single and Multi-frame Image Super-resolution: An\n  Analytical Perspective","summary":"  Super-resolution is the process of obtaining a high-resolution image from one\nor more low-resolution images. Single image super-resolution (SISR) and\nmulti-frame super-resolution (MFSR) methods have been evolved almost\nindependently for years. A neglected study in this field is the theoretical\nanalysis of finding the optimum combination of SISR and MFSR. To fill this gap,\nwe propose a novel theoretical analysis based on the iterative shrinkage and\nthresholding algorithm. We implement and compare several approaches for\ncombining SISR and MFSR, and simulation results support the finding of our\ntheoretical analysis, both quantitatively and qualitatively.\n","authors":["Mohammad Mahdi Afrasiabi","Reshad Hosseini","Aliazam Abbasfar"],"pdf_url":"https://arxiv.org/pdf/2303.03212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03202v1","updated":"2023-03-06T15:02:12Z","published":"2023-03-06T15:02:12Z","title":"Continuous Sign Language Recognition with Correlation Network","summary":"  Human body trajectories are a salient cue to identify actions in the video.\nSuch body trajectories are mainly conveyed by hands and face across consecutive\nframes in sign language. However, current methods in continuous sign language\nrecognition (CSLR) usually process frames independently, thus failing to\ncapture cross-frame trajectories to effectively identify a sign. To handle this\nlimitation, we propose correlation network (CorrNet) to explicitly capture and\nleverage body trajectories across frames to identify signs. In specific, a\ncorrelation module is first proposed to dynamically compute correlation maps\nbetween the current frame and adjacent frames to identify trajectories of all\nspatial patches. An identification module is then presented to dynamically\nemphasize the body trajectories within these correlation maps. As a result, the\ngenerated features are able to gain an overview of local temporal movements to\nidentify a sign. Thanks to its special attention on body trajectories, CorrNet\nachieves new state-of-the-art accuracy on four large-scale datasets, i.e.,\nPHOENIX14, PHOENIX14-T, CSL-Daily, and CSL. A comprehensive comparison with\nprevious spatial-temporal reasoning methods verifies the effectiveness of\nCorrNet. Visualizations demonstrate the effects of CorrNet on emphasizing human\nbody trajectories across adjacent frames.\n","authors":["Lianyu Hu","Liqing Gao","Zekang Liu","Wei Feng"],"pdf_url":"https://arxiv.org/pdf/2303.03202v1.pdf","comment":"CVPR2023, code: https://github.com/hulianyuyy/CorrNet. arXiv admin\n  note: text overlap with arXiv:2211.17081"},{"id":"http://arxiv.org/abs/2201.12733v4","updated":"2023-03-06T14:58:48Z","published":"2022-01-30T05:41:50Z","title":"TPC: Transformation-Specific Smoothing for Point Cloud Models","summary":"  Point cloud models with neural network architectures have achieved great\nsuccess and have been widely used in safety-critical applications, such as\nLidar-based recognition systems in autonomous vehicles. However, such models\nare shown vulnerable to adversarial attacks which aim to apply stealthy\nsemantic transformations such as rotation and tapering to mislead model\npredictions. In this paper, we propose a transformation-specific smoothing\nframework TPC, which provides tight and scalable robustness guarantees for\npoint cloud models against semantic transformation attacks. We first categorize\ncommon 3D transformations into three categories: additive (e.g., shearing),\ncomposable (e.g., rotation), and indirectly composable (e.g., tapering), and we\npresent generic robustness certification strategies for all categories\nrespectively. We then specify unique certification protocols for a range of\nspecific semantic transformations and their compositions. Extensive experiments\non several common 3D transformations show that TPC significantly outperforms\nthe state of the art. For example, our framework boosts the certified accuracy\nagainst twisting transformation along z-axis (within 20$^\\circ$) from 20.3$\\%$\nto 83.8$\\%$. Codes and models are available at\nhttps://github.com/Qianhewu/Point-Cloud-Smoothing.\n","authors":["Wenda Chu","Linyi Li","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2201.12733v4.pdf","comment":"Accepted as a conference paper at ICML 2022"},{"id":"http://arxiv.org/abs/2103.09108v4","updated":"2023-03-06T14:50:44Z","published":"2021-03-16T14:42:01Z","title":"Is it enough to optimize CNN architectures on ImageNet?","summary":"  Classification performance based on ImageNet is the de-facto standard metric\nfor CNN development. In this work we challenge the notion that CNN architecture\ndesign solely based on ImageNet leads to generally effective convolutional\nneural network (CNN) architectures that perform well on a diverse set of\ndatasets and application domains. To this end, we investigate and ultimately\nimprove ImageNet as a basis for deriving such architectures. We conduct an\nextensive empirical study for which we train $500$ CNN architectures, sampled\nfrom the broad AnyNetX design space, on ImageNet as well as $8$ additional well\nknown image classification benchmark datasets from a diverse array of\napplication domains. We observe that the performances of the architectures are\nhighly dataset dependent. Some datasets even exhibit a negative error\ncorrelation with ImageNet across all architectures. We show how to\nsignificantly increase these correlations by utilizing ImageNet subsets\nrestricted to fewer classes. These contributions can have a profound impact on\nthe way we design future CNN architectures and help alleviate the tilt we see\ncurrently in our community with respect to over-reliance on one dataset.\n","authors":["Lukas Tuggener","Jürgen Schmidhuber","Thilo Stadelmann"],"pdf_url":"https://arxiv.org/pdf/2103.09108v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03178v1","updated":"2023-03-06T14:47:38Z","published":"2023-03-06T14:47:38Z","title":"A System for Generalized 3D Multi-Object Search","summary":"  Searching for objects is a fundamental skill for robots. As such, we expect\nobject search to eventually become an off-the-shelf capability for robots,\nsimilar to e.g., object detection and SLAM. In contrast, however, no system for\n3D object search exists that generalizes across real robots and environments.\nIn this paper, building upon a recent theoretical framework that exploited the\noctree structure for representing belief in 3D, we present GenMOS (Generalized\nMulti-Object Search), the first general-purpose system for multi-object search\n(MOS) in a 3D region that is robot-independent and environment-agnostic. GenMOS\ntakes as input point cloud observations of the local region, object detection\nresults, and localization of the robot's view pose, and outputs a 6D viewpoint\nto move to through online planning. In particular, GenMOS uses point cloud\nobservations in three ways: (1) to simulate occlusion; (2) to inform occupancy\nand initialize octree belief; and (3) to sample a belief-dependent graph of\nview positions that avoid obstacles. We evaluate our system both in simulation\nand on two real robot platforms. Our system enables, for example, a Boston\nDynamics Spot robot to find a toy cat hidden underneath a couch in under one\nminute. We further integrate 3D local search with 2D global search to handle\nlarger areas, demonstrating the resulting system in a 25m$^2$ lobby area.\n","authors":["Kaiyu Zheng","Anirudha Paul","Stefanie Tellex"],"pdf_url":"https://arxiv.org/pdf/2303.03178v1.pdf","comment":"8 pages, 9 figures, 1 table. IEEE Conference on Robotics and\n  Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2303.03171v1","updated":"2023-03-06T14:39:54Z","published":"2023-03-06T14:39:54Z","title":"Neighborhood Contrastive Transformer for Change Captioning","summary":"  Change captioning is to describe the semantic change between a pair of\nsimilar images in natural language. It is more challenging than general image\ncaptioning, because it requires capturing fine-grained change information while\nbeing immune to irrelevant viewpoint changes, and solving syntax ambiguity in\nchange descriptions. In this paper, we propose a neighborhood contrastive\ntransformer to improve the model's perceiving ability for various changes under\ndifferent scenes and cognition ability for complex syntax structure.\nConcretely, we first design a neighboring feature aggregating to integrate\nneighboring context into each feature, which helps quickly locate the\ninconspicuous changes under the guidance of conspicuous referents. Then, we\ndevise a common feature distilling to compare two images at neighborhood level\nand extract common properties from each image, so as to learn effective\ncontrastive information between them. Finally, we introduce the explicit\ndependencies between words to calibrate the transformer decoder, which helps\nbetter understand complex syntax structure during training. Extensive\nexperimental results demonstrate that the proposed method achieves the\nstate-of-the-art performance on three public datasets with different change\nscenarios. The code is available at https://github.com/tuyunbin/NCT.\n","authors":["Yunbin Tu","Liang Li","Li Su","Ke Lu","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2303.03171v1.pdf","comment":"Accepted by IEEE TMM"},{"id":"http://arxiv.org/abs/2209.09616v5","updated":"2023-03-06T14:37:29Z","published":"2022-09-19T09:16:07Z","title":"Provably Uncertainty-Guided Universal Domain Adaptation","summary":"  Universal domain adaptation (UniDA) aims to transfer the knowledge of common\nclasses from source domain to target domain without any prior knowledge on the\nlabel set, which requires to distinguish the unknown samples from the known\nones in the target domain. A main challenge of UniDA is that the unequal label\nspaces of both domains causes the misalignment between two domains.To address\nthe above challenging problems, we propose a new uncertainty-guided UniDA\nframework. Firstly, we introduce an empirical estimation of the probability of\na target sample belonging to the unknown class with exploiting the distribution\nof target samples. Then, based on the estimation, we propose a novel neighbors\nsearching method in the linear subspace with a $\\delta$-filter to estimate the\nuncertainty score of a target sample and discover unknown samples. It fully\nutilizes the relationship between a target sample and its neighbors in source\ndomain to avoid the influence of domain misalignment. Secondly, this paper well\nbalances the confidence of predictions for both known and unknown samples\nthrough an uncertainty-guided margin loss based on the predictions of\ndiscovered unknown samples, which can reduce the gap between intra-class\nvariance of known classes with respect to the unknown class. Finally,\nexperiments on three public datasets demonstrate that our method significantly\noutperforms existing state-of-the-art methods.\n","authors":["Yifan Wang","Lin Zhang","Ran Song","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.09616v5.pdf","comment":"13 pages. arXiv admin note: text overlap with arXiv:2207.09280"},{"id":"http://arxiv.org/abs/2211.11635v2","updated":"2023-03-06T14:34:03Z","published":"2022-11-21T16:49:47Z","title":"Understanding and Improving Visual Prompting: A Label-Mapping\n  Perspective","summary":"  We revisit and advance visual prompting (VP), an input prompting technique\nfor vision tasks. VP can reprogram a fixed, pre-trained source model to\naccomplish downstream tasks in the target domain by simply incorporating\nuniversal prompts (in terms of input perturbation patterns) into downstream\ndata points. Yet, it remains elusive why VP stays effective even given a\nruleless label mapping (LM) between the source classes and the target classes.\nInspired by the above, we ask: How is LM interrelated with VP? And how to\nexploit such a relationship to improve its accuracy on target tasks? We peer\ninto the influence of LM on VP and provide an affirmative answer that a better\n'quality' of LM (assessed by mapping precision and explanation) can\nconsistently improve the effectiveness of VP. This is in contrast to the prior\nart where the factor of LM was missing. To optimize LM, we propose a new VP\nframework, termed ILM-VP (iterative label mapping-based visual prompting),\nwhich automatically re-maps the source labels to the target labels and\nprogressively improves the target task accuracy of VP. Further, when using a\ncontrastive language-image pretrained (CLIP) model, we propose to integrate an\nLM process to assist the text prompt selection of CLIP and to improve the\ntarget task accuracy. Extensive experiments demonstrate that our proposal\nsignificantly outperforms state-of-the-art VP methods. As highlighted below, we\nshow that when reprogramming an ImageNet-pretrained ResNet-18 to 13 target\ntasks, our method outperforms baselines by a substantial margin, e.g., 7.9% and\n6.7% accuracy improvements in transfer learning to the target Flowers102 and\nCIFAR100 datasets. Besides, our proposal on CLIP-based VP provides 13.7% and\n7.1% accuracy improvements on Flowers102 and DTD respectively. Our code is\navailable at https://github.com/OPTML-Group/ILM-VP.\n","authors":["Aochuan Chen","Yuguang Yao","Pin-Yu Chen","Yihua Zhang","Sijia Liu"],"pdf_url":"https://arxiv.org/pdf/2211.11635v2.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.03166v1","updated":"2023-03-06T14:26:56Z","published":"2023-03-06T14:26:56Z","title":"Faster Learning of Temporal Action Proposal via Sparse Multilevel\n  Boundary Generator","summary":"  Temporal action localization in videos presents significant challenges in the\nfield of computer vision. While the boundary-sensitive method has been widely\nadopted, its limitations include incomplete use of intermediate and global\ninformation, as well as an inefficient proposal feature generator. To address\nthese challenges, we propose a novel framework, Sparse Multilevel Boundary\nGenerator (SMBG), which enhances the boundary-sensitive method with boundary\nclassification and action completeness regression. SMBG features a multi-level\nboundary module that enables faster processing by gathering boundary\ninformation at different lengths. Additionally, we introduce a sparse\nextraction confidence head that distinguishes information inside and outside\nthe action, further optimizing the proposal feature generator. To improve the\nsynergy between multiple branches and balance positive and negative samples, we\npropose a global guidance loss. Our method is evaluated on two popular\nbenchmarks, ActivityNet-1.3 and THUMOS14, and is shown to achieve\nstate-of-the-art performance, with a better inference speed (2.47xBSN++,\n2.12xDBG). These results demonstrate that SMBG provides a more efficient and\nsimple solution for generating temporal action proposals. Our proposed\nframework has the potential to advance the field of computer vision and enhance\nthe accuracy and speed of temporal action localization in video analysis.The\ncode and models are made available at\n\\url{https://github.com/zhouyang-001/SMBG-for-temporal-action-proposal}.\n","authors":["Qing Song","Yang Zhou","Mengjie Hu","Chun Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03166v1.pdf","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.03131v1","updated":"2023-03-06T13:49:15Z","published":"2023-03-06T13:49:15Z","title":"Video Question Answering Using CLIP-Guided Visual-Text Attention","summary":"  Cross-modal learning of video and text plays a key role in Video Question\nAnswering (VideoQA). In this paper, we propose a visual-text attention\nmechanism to utilize the Contrastive Language-Image Pre-training (CLIP) trained\non lots of general domain language-image pairs to guide the cross-modal\nlearning for VideoQA. Specifically, we first extract video features using a\nTimeSformer and text features using a BERT from the target application domain,\nand utilize CLIP to extract a pair of visual-text features from the\ngeneral-knowledge domain through the domain-specific learning. We then propose\na Cross-domain Learning to extract the attention information between visual and\nlinguistic features across the target domain and general domain. The set of\nCLIP-guided visual-text features are integrated to predict the answer. The\nproposed method is evaluated on MSVD-QA and MSRVTT-QA datasets, and outperforms\nstate-of-the-art methods.\n","authors":["Shuhong Ye","Weikai Kong","Chenglin Yao","Jianfeng Ren","Xudong Jiang"],"pdf_url":"https://arxiv.org/pdf/2303.03131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03127v1","updated":"2023-03-06T13:39:41Z","published":"2023-03-06T13:39:41Z","title":"ST-KeyS: Self-Supervised Transformer for Keyword Spotting in Historical\n  Handwritten Documents","summary":"  Keyword spotting (KWS) in historical documents is an important tool for the\ninitial exploration of digitized collections. Nowadays, the most efficient KWS\nmethods are relying on machine learning techniques that require a large amount\nof annotated training data. However, in the case of historical manuscripts,\nthere is a lack of annotated corpus for training. To handle the data scarcity\nissue, we investigate the merits of the self-supervised learning to extract\nuseful representations of the input data without relying on human annotations\nand then using these representations in the downstream task. We propose\nST-KeyS, a masked auto-encoder model based on vision transformers where the\npretraining stage is based on the mask-and-predict paradigm, without the need\nof labeled data. In the fine-tuning stage, the pre-trained encoder is\nintegrated into a siamese neural network model that is fine-tuned to improve\nfeature embedding from the input images. We further improve the image\nrepresentation using pyramidal histogram of characters (PHOC) embedding to\ncreate and exploit an intermediate representation of images based on text\nattributes. In an exhaustive experimental evaluation on three widely used\nbenchmark datasets (Botany, Alvermann Konzilsprotokolle and George Washington),\nthe proposed approach outperforms state-of-the-art methods trained on the same\ndatasets.\n","authors":["Sana Khamekhem Jemni","Sourour Ammar","Mohamed Ali Souibgui","Yousri Kessentini","Abbas Cheddad"],"pdf_url":"https://arxiv.org/pdf/2303.03127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10772v3","updated":"2023-03-06T13:36:16Z","published":"2022-11-19T19:06:22Z","title":"DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text\n  Spotting","summary":"  End-to-end text spotting aims to integrate scene text detection and\nrecognition into a unified framework. Dealing with the relationship between the\ntwo sub-tasks plays a pivotal role in designing effective spotters. Although\nTransformer-based methods eliminate the heuristic post-processing, they still\nsuffer from the synergy issue between the sub-tasks and low training\nefficiency. In this paper, we present DeepSolo, a simple DETR-like baseline\nthat lets a single Decoder with Explicit Points Solo for text detection and\nrecognition simultaneously. Technically, for each text instance, we represent\nthe character sequence as ordered points and model them with learnable explicit\npoint queries. After passing a single decoder, the point queries have encoded\nrequisite text semantics and locations, thus can be further decoded to the\ncenter line, boundary, script, and confidence of text via very simple\nprediction heads in parallel. Besides, we also introduce a text-matching\ncriterion to deliver more accurate supervisory signals, thus enabling more\nefficient training. Quantitative experiments on public benchmarks demonstrate\nthat DeepSolo outperforms previous state-of-the-art methods and achieves better\ntraining efficiency. In addition, DeepSolo is also compatible with line\nannotations, which require much less annotation cost than polygons. The code is\navailable at https://github.com/ViTAE-Transformer/DeepSolo.\n","authors":["Maoyuan Ye","Jing Zhang","Shanshan Zhao","Juhua Liu","Tongliang Liu","Bo Du","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2211.10772v3.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2301.05499v2","updated":"2023-03-06T13:35:22Z","published":"2023-01-13T12:01:18Z","title":"CLIP the Gap: A Single Domain Generalization Approach for Object\n  Detection","summary":"  Single Domain Generalization (SDG) tackles the problem of training a model on\na single source domain so that it generalizes to any unseen target domain.\nWhile this has been well studied for image classification, the literature on\nSDG object detection remains almost non-existent. To address the challenges of\nsimultaneously learning robust object localization and representation, we\npropose to leverage a pre-trained vision-language model to introduce semantic\ndomain concepts via textual prompts. We achieve this via a semantic\naugmentation strategy acting on the features extracted by the detector\nbackbone, as well as a text-based classification loss. Our experiments evidence\nthe benefits of our approach, outperforming by 10% the only existing SDG object\ndetection method, Single-DGOD [49], on their own diverse weather-driving\nbenchmark.\n","authors":["Vidit Vidit","Martin Engilberge","Mathieu Salzmann"],"pdf_url":"https://arxiv.org/pdf/2301.05499v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03101v1","updated":"2023-03-06T13:14:10Z","published":"2023-03-06T13:14:10Z","title":"CRIN: Rotation-Invariant Point Cloud Analysis and Rotation Estimation\n  via Centrifugal Reference Frame","summary":"  Various recent methods attempt to implement rotation-invariant 3D deep\nlearning by replacing the input coordinates of points with relative distances\nand angles. Due to the incompleteness of these low-level features, they have to\nundertake the expense of losing global information. In this paper, we propose\nthe CRIN, namely Centrifugal Rotation-Invariant Network. CRIN directly takes\nthe coordinates of points as input and transforms local points into\nrotation-invariant representations via centrifugal reference frames. Aided by\ncentrifugal reference frames, each point corresponds to a discrete rotation so\nthat the information of rotations can be implicitly stored in point features.\nUnfortunately, discrete points are far from describing the whole rotation\nspace. We further introduce a continuous distribution for 3D rotations based on\npoints. Furthermore, we propose an attention-based down-sampling strategy to\nsample points invariant to rotations. A relation module is adopted at last for\nreinforcing the long-range dependencies between sampled points and predicts the\nanchor point for unsupervised rotation estimation. Extensive experiments show\nthat our method achieves rotation invariance, accurately estimates the object\nrotation, and obtains state-of-the-art results on rotation-augmented\nclassification and part segmentation. Ablation studies validate the\neffectiveness of the network design.\n","authors":["Yujing Lou","Zelin Ye","Yang You","Nianjuan Jiang","Jiangbo Lu","Weiming Wang","Lizhuang Ma","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2303.03101v1.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2303.03056v1","updated":"2023-03-06T11:59:13Z","published":"2023-03-06T11:59:13Z","title":"MOISST: Multi-modal Optimization of Implicit Scene for SpatioTemporal\n  calibration","summary":"  With the recent advances in autonomous driving and the decreasing cost of\nLiDARs, the use of multi-modal sensor systems is on the rise. However, in order\nto make use of the information provided by a variety of complimentary sensors,\nit is necessary to accurately calibrate them. We take advantage of recent\nadvances in computer graphics and implicit volumetric scene representation to\ntackle the problem of multi-sensor spatial and temporal calibration. Thanks to\na new formulation of the implicit model optimization, we are able to jointly\noptimize calibration parameters along with scene representation based on\nradiometric and geometric measurements. Our method enables accurate and robust\ncalibration from data captured in uncontrolled and unstructured urban\nenvironments, making our solution more scalable than existing calibration\nsolutions. We demonstrate the accuracy and robustness of our method in urban\nscenes typically encountered in autonomous driving scenarios.\n","authors":["Quentin Herau","Nathan Piasco","Moussab Bennehar","Luis Roldão","Dzmitry Tsishkou","Cyrille Migniot","Pascal Vasseur","Cédric Demonceaux"],"pdf_url":"https://arxiv.org/pdf/2303.03056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03052v1","updated":"2023-03-06T11:51:28Z","published":"2023-03-06T11:51:28Z","title":"Masked Images Are Counterfactual Samples for Robust Fine-tuning","summary":"  Deep learning models are challenged by the distribution shift between the\ntraining data and test data. Recently, the large models pre-trained on diverse\ndata demonstrate unprecedented robustness to various distribution shifts.\nHowever, fine-tuning on these models can lead to a trade-off between\nin-distribution (ID) performance and out-of-distribution (OOD) robustness.\nExisting methods for tackling this trade-off do not explicitly address the OOD\nrobustness problem. In this paper, based on causal analysis on the\naforementioned problems, we propose a novel fine-tuning method, which use\nmasked images as counterfactual samples that help improving the robustness of\nthe fine-tuning model. Specifically, we mask either the semantics-related or\nsemantics-unrelated patches of the images based on class activation map to\nbreak the spurious correlation, and refill the masked patches with patches from\nother images. The resulting counterfactual samples are used in feature-based\ndistillation with the pre-trained model. Extensive experiments verify that\nregularizing the fine-tuning with the proposed masked images can achieve a\nbetter trade-off between ID and OOD, surpassing previous methods on the OOD\nperformance. Our code will be publicly available.\n","authors":["Yao Xiao","Ziyi Tang","Pengxu Wei","Cong Liu","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2303.03052v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2212.02931v2","updated":"2023-03-06T11:48:02Z","published":"2022-12-06T12:40:45Z","title":"Leveraging Different Learning Styles for Improved Knowledge Distillation","summary":"  Learning style refers to a type of training mechanism adopted by an\nindividual to gain new knowledge. As suggested by the VARK model, humans have\ndifferent learning preferences like visual, auditory, etc., for acquiring and\neffectively processing information. Inspired by this concept, our work explores\nthe idea of mixed information sharing with model compression in the context of\nKnowledge Distillation (KD) and Mutual Learning (ML). Unlike conventional\ntechniques that share the same type of knowledge with all networks, we propose\nto train individual networks with different forms of information to enhance the\nlearning process. We formulate a combined KD and ML framework with one teacher\nand two student networks that share or exchange information in the form of\npredictions and feature maps. Our comprehensive experiments with benchmark\nclassification and segmentation datasets demonstrate that with 15% compression,\nthe ensemble performance of networks trained with diverse forms of knowledge\noutperforms the conventional techniques both quantitatively and qualitatively.\n","authors":["Usma Niyaz","Deepti R. Bathula"],"pdf_url":"https://arxiv.org/pdf/2212.02931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03050v1","updated":"2023-03-06T11:46:58Z","published":"2023-03-06T11:46:58Z","title":"MABNet: Master Assistant Buddy Network with Hybrid Learning for Image\n  Retrieval","summary":"  Image retrieval has garnered growing interest in recent times. The current\napproaches are either supervised or self-supervised. These methods do not\nexploit the benefits of hybrid learning using both supervision and\nself-supervision. We present a novel Master Assistant Buddy Network (MABNet)\nfor image retrieval which incorporates both learning mechanisms. MABNet\nconsists of master and assistant blocks, both learning independently through\nsupervision and collectively via self-supervision. The master guides the\nassistant by providing its knowledge base as a reference for self-supervision\nand the assistant reports its knowledge back to the master by weight transfer.\nWe perform extensive experiments on public datasets with and without\npost-processing.\n","authors":["Rohit Agarwal","Gyanendra Das","Saksham Aggarwal","Alexander Horsch","Dilip K. Prasad"],"pdf_url":"https://arxiv.org/pdf/2303.03050v1.pdf","comment":"Accepted at International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP) 2023"},{"id":"http://arxiv.org/abs/2212.05729v3","updated":"2023-03-06T11:44:24Z","published":"2022-12-12T06:38:35Z","title":"ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient\n  Self-Supervised Monocular Depth Estimation","summary":"  The exploration of mutual-benefit cross-domains has shown great potential\ntoward accurate self-supervised depth estimation. In this work, we revisit\nfeature fusion between depth and semantic information and propose an efficient\nlocal adaptive attention method for geometric aware representation enhancement.\nInstead of building global connections or deforming attention across the\nfeature space without restraint, we bound the spatial interaction within a\nlearnable region of interest. In particular, we leverage geometric cues from\nsemantic information to learn local adaptive bounding boxes to guide\nunsupervised feature aggregation. The local areas preclude most irrelevant\nreference points from attention space, yielding more selective feature learning\nand faster convergence. We naturally extend the paradigm into a multi-head and\nhierarchic way to enable the information distillation in different semantic\nlevels and improve the feature discriminative ability for fine-grained depth\nestimation. Extensive experiments on the KITTI dataset show that our proposed\nmethod establishes a new state-of-the-art in self-supervised monocular depth\nestimation task, demonstrating the effectiveness of our approach over former\nTransformer variants.\n","authors":["Daitao Xing","Jinglin Shen","Chiuman Ho","Anthony Tzes"],"pdf_url":"https://arxiv.org/pdf/2212.05729v3.pdf","comment":"Camera Ready for AAAI 2023"},{"id":"http://arxiv.org/abs/2206.05751v3","updated":"2023-03-06T11:18:59Z","published":"2022-06-12T14:45:11Z","title":"Consistent Attack: Universal Adversarial Perturbation on Embodied Vision\n  Navigation","summary":"  Embodied agents in vision navigation coupled with deep neural networks have\nattracted increasing attention. However, deep neural networks have been shown\nvulnerable to malicious adversarial noises, which may potentially cause\ncatastrophic failures in Embodied Vision Navigation. Among different\nadversarial noises, universal adversarial perturbations (UAP), i.e., a constant\nimage-agnostic perturbation applied on every input frame of the agent, play a\ncritical role in Embodied Vision Navigation since they are\ncomputation-efficient and application-practical during the attack. However,\nexisting UAP methods ignore the system dynamics of Embodied Vision Navigation\nand might be sub-optimal. In order to extend UAP to the sequential decision\nsetting, we formulate the disturbed environment under the universal noise\n$\\delta$, as a $\\delta$-disturbed Markov Decision Process ($\\delta$-MDP). Based\non the formulation, we analyze the properties of $\\delta$-MDP and propose two\nnovel Consistent Attack methods, named Reward UAP and Trajectory UAP, for\nattacking Embodied agents, which consider the dynamic of the MDP and calculate\nuniversal noises by estimating the disturbed distribution and the disturbed Q\nfunction. For various victim models, our Consistent Attack can cause a\nsignificant drop in their performance in the PointGoal task in Habitat with\ndifferent datasets and different scenes. Extensive experimental results\nindicate that there exist serious potential risks for applying Embodied Vision\nNavigation methods to the real world.\n","authors":["Chengyang Ying","You Qiaoben","Xinning Zhou","Hang Su","Wenbo Ding","Jianyong Ai"],"pdf_url":"https://arxiv.org/pdf/2206.05751v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03041v1","updated":"2023-03-06T11:13:23Z","published":"2023-03-06T11:13:23Z","title":"Automatic detection of aerial survey ground control points based on\n  Yolov5-OBB","summary":"  The use of ground control points (GCPs) for georeferencing is the most common\nstrategy in unmanned aerial vehicle (UAV) photogrammetry, but at the same time\ntheir collection represents the most time-consuming and expensive part of UAV\ncampaigns. Recently, deep learning has been rapidly developed in the field of\nsmall object detection. In this letter, to automatically extract coordinates\ninformation of ground control points (GCPs) by detecting GCP-markers in UAV\nimages, we propose a solution that uses a deep learning-based architecture,\nYOLOv5-OBB, combined with a confidence threshold filtering algorithm and an\noptimal ranking algorithm. We applied our proposed method to a dataset\ncollected by DJI Phantom 4 Pro drone and obtained good detection performance\nwith the mean Average Precision (AP) of 0.832 and the highest AP of 0.982 for\nthe cross-type GCP-markers. The proposed method can be a promising tool for\nfuture implementation of the end-to-end aerial triangulation process.\n","authors":["Cheng Chuanxiang","Yang Jia","Wang Chao","Zheng Zhi","Li Xiaopeng","Dong Di","Chang Mengxia","Zhuang Zhiheng"],"pdf_url":"https://arxiv.org/pdf/2303.03041v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.03037v1","updated":"2023-03-06T11:07:11Z","published":"2023-03-06T11:07:11Z","title":"EvCenterNet: Uncertainty Estimation for Object Detection using\n  Evidential Learning","summary":"  Uncertainty estimation is crucial in safety-critical settings such as\nautomated driving as it provides valuable information for several downstream\ntasks including high-level decision-making and path planning. In this work, we\npropose EvCenterNet, a novel uncertainty-aware 2D object detection framework\nutilizing evidential learning to directly estimate both classification and\nregression uncertainties. To employ evidential learning for object detection,\nwe devise a combination of evidential and focal loss functions for the sparse\nheatmap inputs. We introduce class-balanced weighting for regression and\nheatmap prediction to tackle the class imbalance encountered by evidential\nlearning. Moreover, we propose a learning scheme to actively utilize the\npredicted heatmap uncertainties to improve the detection performance by\nfocusing on the most uncertain points. We train our model on the KITTI dataset\nand evaluate it on challenging out-of-distribution datasets including BDD100K\nand nuImages. Our experiments demonstrate that our approach improves the\nprecision and minimizes the execution time loss in relation to the base model.\n","authors":["Monish R. Nallapareddy","Kshitij Sirohi","Paulo L. J. Drews-Jr","Wolfram Burgard","Chih-Hong Cheng","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2303.03037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03032v1","updated":"2023-03-06T11:02:47Z","published":"2023-03-06T11:02:47Z","title":"DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only\n  Training","summary":"  Large-scale pre-trained multi-modal models (e.g., CLIP) demonstrate strong\nzero-shot transfer capability in many discriminative tasks. Their adaptation to\nzero-shot image-conditioned text generation tasks has drawn increasing\ninterest. Prior arts approach to zero-shot captioning by either utilizing the\nexisting large language models (e.g., GPT-2) or pre-training the\nencoder-decoder network in an end-to-end manner. In this work, we propose a\nsimple framework, named DeCap, for zero-shot captioning. We introduce a\nlightweight visual-aware language decoder. This decoder is both data-efficient\nand computation-efficient: 1) it only requires the text data for training,\neasing the burden on the collection of paired data. 2) it does not require\nend-to-end training. When trained with text-only data, the decoder takes the\ntext embedding extracted from the off-the-shelf CLIP encoder as a prefix\nembedding. The challenge is that the decoder is trained on the text corpus but\nat the inference stage, it needs to generate captions based on visual inputs.\nThe modality gap issue is widely observed in multi-modal contrastive models\nthat prevents us from directly taking the visual embedding as the prefix\nembedding. We propose a training-free mechanism to reduce the modality gap. We\nproject the visual embedding into the CLIP text embedding space, while the\nprojected embedding retains the information of the visual input. Taking the\nprojected embedding as the prefix embedding, the decoder generates high-quality\ndescriptions that match the visual input. The experiments show that DeCap\noutperforms other zero-shot captioning methods and unpaired captioning methods\non the typical image captioning benchmarks, i.e., MSCOCO and NoCaps.\n","authors":["Wei Li","Linchao Zhu","Longyin Wen","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2303.03032v1.pdf","comment":"Accepted by ICLR 2023. Code is available at\n  https://github.com/dhg-wei/DeCap"},{"id":"http://arxiv.org/abs/2303.03028v1","updated":"2023-03-06T10:59:45Z","published":"2023-03-06T10:59:45Z","title":"RQAT-INR: Improved Implicit Neural Image Compression","summary":"  Deep variational autoencoders for image and video compression have gained\nsignificant attraction in the recent years, due to their potential to offer\ncompetitive or better compression rates compared to the decades long\ntraditional codecs such as AVC, HEVC or VVC. However, because of complexity and\nenergy consumption, these approaches are still far away from practical usage in\nindustry. More recently, implicit neural representation (INR) based codecs have\nemerged, and have lower complexity and energy usage to classical approaches at\ndecoding. However, their performances are not in par at the moment with\nstate-of-the-art methods. In this research, we first show that INR based image\ncodec has a lower complexity than VAE based approaches, then we propose several\nimprovements for INR-based image codec and outperformed baseline model by a\nlarge margin.\n","authors":["Bharath Bhushan Damodaran","Muhammet Balcilar","Franck Galpin","Pierre Hellier"],"pdf_url":"https://arxiv.org/pdf/2303.03028v1.pdf","comment":"Accepted as oral at Data compression conference 2023"},{"id":"http://arxiv.org/abs/2303.03023v1","updated":"2023-03-06T10:50:25Z","published":"2023-03-06T10:50:25Z","title":"Guiding Energy-based Models via Contrastive Latent Variables","summary":"  An energy-based model (EBM) is a popular generative framework that offers\nboth explicit density and architectural flexibility, but training them is\ndifficult since it is often unstable and time-consuming. In recent years,\nvarious training techniques have been developed, e.g., better divergence\nmeasures or stabilization in MCMC sampling, but there often exists a large gap\nbetween EBMs and other generative frameworks like GANs in terms of generation\nquality. In this paper, we propose a novel and effective framework for\nimproving EBMs via contrastive representation learning (CRL). To be specific,\nwe consider representations learned by contrastive methods as the true\nunderlying latent variable. This contrastive latent variable could guide EBMs\nto understand the data structure better, so it can improve and accelerate EBM\ntraining significantly. To enable the joint training of EBM and CRL, we also\ndesign a new class of latent-variable EBMs for learning the joint density of\ndata and the contrastive latent variable. Our experimental results demonstrate\nthat our scheme achieves lower FID scores, compared to prior-art EBM methods\n(e.g., additionally using variational autoencoders or diffusion techniques),\neven with significantly faster and more memory-efficient training. We also show\nconditional and compositional generation abilities of our latent-variable EBMs\nas their additional benefits, even without explicit conditional training. The\ncode is available at https://github.com/hankook/CLEL.\n","authors":["Hankook Lee","Jongheon Jeong","Sejun Park","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2303.03023v1.pdf","comment":"Accepted to ICLR 2023 (Spotlight). The code is available at\n  https://github.com/hankook/CLEL"},{"id":"http://arxiv.org/abs/2012.01321v6","updated":"2023-03-06T10:41:29Z","published":"2020-12-02T16:49:51Z","title":"Red Blood Cell Segmentation with Overlapping Cell Separation and\n  Classification on Imbalanced Dataset","summary":"  Automated red blood cell (RBC) classification on blood smear images helps\nhematologists to analyze RBC lab results in a reduced time and cost. However,\noverlapping cells can cause incorrect predicted results, and so they have to be\nseparated into multiple single RBCs before classifying. To classify multiple\nclasses with deep learning, imbalance problems are common in medical imaging\nbecause normal samples are always higher than rare disease samples. This paper\npresents a new method to segment and classify RBCs from blood smear images,\nspecifically to tackle cell overlapping and data imbalance problems. Focusing\non overlapping cell separation, our segmentation process first estimates\nellipses to represent RBCs. The method detects the concave points and then\nfinds the ellipses using directed ellipse fitting. The accuracy from 20 blood\nsmear images was 0.889. Classification requires balanced training datasets.\nHowever, some RBC types are rare. The imbalance ratio of this dataset was\n34.538 for 12 RBC classes from 20,875 individual RBC samples. The use of\nmachine learning for RBC classification with an imbalanced dataset is hence\nmore challenging than many other applications. We analyzed techniques to deal\nwith this problem. The best accuracy and F1-score were 0.921 and 0.8679,\nrespectively, using EfficientNet-B1 with augmentation. Experimental results\nshowed that the weight balancing technique with augmentation had the potential\nto deal with imbalance problems by improving the F1-score on minority classes,\nwhile data augmentation significantly improved the overall classification\nperformance.\n","authors":["Korranat Naruenatthanaset","Thanarat H. Chalidabhongse","Duangdao Palasuwan","Nantheera Anantrasirichai","Attakorn Palasuwan"],"pdf_url":"https://arxiv.org/pdf/2012.01321v6.pdf","comment":"This work has been submitted to Intelligent Systems with Applications\n  (ISWA) for possible publication. Copyright may be transferred without notice,\n  after which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2207.05921v2","updated":"2023-03-06T10:11:53Z","published":"2022-07-13T02:01:07Z","title":"Texture-guided Saliency Distilling for Unsupervised Salient Object\n  Detection","summary":"  Deep Learning-based Unsupervised Salient Object Detection (USOD) mainly\nrelies on the noisy saliency pseudo labels that have been generated from\ntraditional handcraft methods or pre-trained networks. To cope with the noisy\nlabels problem, a class of methods focus on only easy samples with reliable\nlabels but ignore valuable knowledge in hard samples. In this paper, we propose\na novel USOD method to mine rich and accurate saliency knowledge from both easy\nand hard samples. First, we propose a Confidence-aware Saliency Distilling\n(CSD) strategy that scores samples conditioned on samples' confidences, which\nguides the model to distill saliency knowledge from easy samples to hard\nsamples progressively. Second, we propose a Boundary-aware Texture Matching\n(BTM) strategy to refine the boundaries of noisy labels by matching the\ntextures around the predicted boundary. Extensive experiments on RGB, RGB-D,\nRGB-T, and video SOD benchmarks prove that our method achieves state-of-the-art\nUSOD performance.\n","authors":["Huajun Zhou","Bo Qiao","Lingxiao Yang","Jianhuang Lai","Xiaohua Xie"],"pdf_url":"https://arxiv.org/pdf/2207.05921v2.pdf","comment":"8 pages, accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.03003v1","updated":"2023-03-06T10:04:50Z","published":"2023-03-06T10:04:50Z","title":"Efficient Large-scale Scene Representation with a Hybrid of\n  High-resolution Grid and Plane Features","summary":"  Existing neural radiance fields (NeRF) methods for large-scale scene modeling\nrequire days of training using multiple GPUs, hindering their applications in\nscenarios with limited computing resources. Despite fast optimization NeRF\nvariants have been proposed based on the explicit dense or hash grid features,\ntheir effectivenesses are mainly demonstrated in object-scale scene\nrepresentation. In this paper, we point out that the low feature resolution in\nexplicit representation is the bottleneck for large-scale unbounded scene\nrepresentation. To address this problem, we introduce a new and efficient\nhybrid feature representation for NeRF that fuses the 3D hash-grids and\nhigh-resolution 2D dense plane features. Compared with the dense-grid\nrepresentation, the resolution of a dense 2D plane can be scaled up more\nefficiently. Based on this hybrid representation, we propose a fast\noptimization NeRF variant, called GP-NeRF, that achieves better rendering\nresults while maintaining a compact model size. Extensive experiments on\nmultiple large-scale unbounded scene datasets show that our model can converge\nin 1.5 hours using a single GPU while achieving results comparable to or even\nbetter than the existing method that requires about one day's training with 8\nGPUs.\n","authors":["Yuqi Zhang","Guanying Chen","Shuguang Cui"],"pdf_url":"https://arxiv.org/pdf/2303.03003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00722v2","updated":"2023-03-06T10:03:01Z","published":"2022-10-03T05:38:20Z","title":"GenDexGrasp: Generalizable Dexterous Grasping","summary":"  Generating dexterous grasping has been a long-standing and challenging\nrobotic task. Despite recent progress, existing methods primarily suffer from\ntwo issues. First, most prior arts focus on a specific type of robot hand,\nlacking the generalizable capability of handling unseen ones. Second, prior\narts oftentimes fail to rapidly generate diverse grasps with a high success\nrate. To jointly tackle these challenges with a unified solution, we propose\nGenDexGrasp, a novel hand-agnostic grasping algorithm for generalizable\ngrasping. GenDexGrasp is trained on our proposed large-scale multi-hand\ngrasping dataset MultiDex synthesized with force closure optimization. By\nleveraging the contact map as a hand-agnostic intermediate representation,\nGenDexGrasp efficiently generates diverse and plausible grasping poses with a\nhigh success rate and can transfer among diverse multi-fingered robotic hands.\nCompared with previous methods, GenDexGrasp achieves a three-way trade-off\namong success rate, inference speed, and diversity. Code is available at\nhttps://github.com/tengyu-liu/GenDexGrasp.\n","authors":["Puhao Li","Tengyu Liu","Yuyang Li","Yiran Geng","Yixin Zhu","Yaodong Yang","Siyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2210.00722v2.pdf","comment":"Accepted to ICRA 2023 (camera-ready version)"},{"id":"http://arxiv.org/abs/2207.04242v2","updated":"2023-03-06T09:54:55Z","published":"2022-07-09T10:35:44Z","title":"PI-Trans: Parallel-ConvMLP and Implicit-Transformation Based GAN for\n  Cross-View Image Translation","summary":"  For semantic-guided cross-view image translation, it is crucial to learn\nwhere to sample pixels from the source view image and where to reallocate them\nguided by the target view semantic map, especially when there is little overlap\nor drastic view difference between the source and target images. Hence, one not\nonly needs to encode the long-range dependencies among pixels in both the\nsource view image and target view semantic map but also needs to translate\nthese learned dependencies. To this end, we propose a novel generative\nadversarial network, PI-Trans, which mainly consists of a novel\nParallel-ConvMLP module and an Implicit Transformation module at multiple\nsemantic levels. Extensive experimental results show that PI-Trans achieves the\nbest qualitative and quantitative performance by a large margin compared to the\nstate-of-the-art methods on two challenging datasets. The source code is\navailable at https://github.com/Amazingren/PI-Trans.\n","authors":["Bin Ren","Hao Tang","Yiming Wang","Xia Li","Wei Wang","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2207.04242v2.pdf","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.02998v1","updated":"2023-03-06T09:54:15Z","published":"2023-03-06T09:54:15Z","title":"Pseudo-label Correction and Learning For Semi-Supervised Object\n  Detection","summary":"  Pseudo-Labeling has emerged as a simple yet effective technique for\nsemi-supervised object detection (SSOD). However, the inevitable noise problem\nin pseudo-labels significantly degrades the performance of SSOD methods. Recent\nadvances effectively alleviate the classification noise in SSOD, while the\nlocalization noise which is a non-negligible part of SSOD is not\nwell-addressed. In this paper, we analyse the localization noise from the\ngeneration and learning phases, and propose two strategies, namely pseudo-label\ncorrection and noise-unaware learning. For pseudo-label correction, we\nintroduce a multi-round refining method and a multi-vote weighting method. The\nformer iteratively refines the pseudo boxes to improve the stability of\npredictions, while the latter smoothly self-corrects pseudo boxes by weighing\nthe scores of surrounding jittered boxes. For noise-unaware learning, we\nintroduce a loss weight function that is negatively correlated with the\nIntersection over Union (IoU) in the regression task, which pulls the predicted\nboxes closer to the object and improves localization accuracy. Our proposed\nmethod, Pseudo-label Correction and Learning (PCL), is extensively evaluated on\nthe MS COCO and PASCAL VOC benchmarks. On MS COCO, PCL outperforms the\nsupervised baseline by 12.16, 12.11, and 9.57 mAP and the recent SOTA\n(SoftTeacher) by 3.90, 2.54, and 2.43 mAP under 1\\%, 5\\%, and 10\\% labeling\nratios, respectively. On PASCAL VOC, PCL improves the supervised baseline by\n5.64 mAP and the recent SOTA (Unbiased Teacherv2) by 1.04 mAP on AP$^{50}$.\n","authors":["Yulin He","Wei Chen","Ke Liang","Yusong Tan","Zhengfa Liang","Yulan Guo"],"pdf_url":"https://arxiv.org/pdf/2303.02998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.14465v3","updated":"2023-03-06T09:45:11Z","published":"2022-07-29T04:10:04Z","title":"Fine-grained Retrieval Prompt Tuning","summary":"  Fine-grained object retrieval aims to learn discriminative representation to\nretrieve visually similar objects. However, existing top-performing works\nusually impose pairwise similarities on the semantic embedding spaces or design\na localization sub-network to continually fine-tune the entire model in limited\ndata scenarios, thus resulting in convergence to suboptimal solutions. In this\npaper, we develop Fine-grained Retrieval Prompt Tuning (FRPT), which steers a\nfrozen pre-trained model to perform the fine-grained retrieval task from the\nperspectives of sample prompting and feature adaptation. Specifically, FRPT\nonly needs to learn fewer parameters in the prompt and adaptation instead of\nfine-tuning the entire model, thus solving the issue of convergence to\nsuboptimal solutions caused by fine-tuning the entire model. Technically, a\ndiscriminative perturbation prompt (DPP) is introduced and deemed as a sample\nprompting process, which amplifies and even exaggerates some discriminative\nelements contributing to category prediction via a content-aware inhomogeneous\nsampling operation. In this way, DPP can make the fine-grained retrieval task\naided by the perturbation prompts close to the solved task during the original\npre-training. Thereby, it preserves the generalization and discrimination of\nrepresentation extracted from input samples. Besides, a category-specific\nawareness head is proposed and regarded as feature adaptation, which removes\nthe species discrepancies in features extracted by the pre-trained model using\ncategory-guided instance normalization. And thus, it makes the optimized\nfeatures only include the discrepancies among subcategories. Extensive\nexperiments demonstrate that our FRPT with fewer learnable parameters achieves\nthe state-of-the-art performance on three widely-used fine-grained datasets.\n","authors":["Shijie Wang","Jianlong Chang","Zhihui Wang","Haojie Li","Wanli Ouyang","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2207.14465v3.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.02995v1","updated":"2023-03-06T09:44:01Z","published":"2023-03-06T09:44:01Z","title":"HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware\n  Attention","summary":"  The success of large-scale contrastive vision-language pretraining (CLIP) has\nbenefited both visual recognition and multimodal content understanding. The\nconcise design brings CLIP the advantage in inference efficiency against other\nvision-language models with heavier cross-attention fusion layers, making it a\npopular choice for a wide spectrum of downstream tasks. However, CLIP does not\nexplicitly capture the hierarchical nature of high-level and fine-grained\nsemantics conveyed in images and texts, which is arguably critical to\nvision-language understanding and reasoning. To this end, we equip both the\nvisual and language branches in CLIP with hierarchy-aware attentions, namely\nHierarchy-aware CLIP (HiCLIP), to progressively discover semantic hierarchies\nlayer-by-layer from both images and texts in an unsupervised manner. As a\nresult, such hierarchical aggregation significantly improves the cross-modal\nalignment. To demonstrate the advantages of HiCLIP, we conduct qualitative\nanalysis on its unsupervised hierarchy induction during inference, as well as\nextensive quantitative experiments on both visual recognition and\nvision-language downstream tasks.\n","authors":["Shijie Geng","Jianbo Yuan","Yu Tian","Yuxiao Chen","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02995v1.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02994v1","updated":"2023-03-06T09:41:40Z","published":"2023-03-06T09:41:40Z","title":"Fighting noise and imbalance in Action Unit detection problems","summary":"  Action Unit (AU) detection aims at automatically caracterizing facial\nexpressions with the muscular activations they involve. Its main interest is to\nprovide a low-level face representation that can be used to assist higher level\naffective computing tasks learning. Yet, it is a challenging task. Indeed, the\navailable databases display limited face variability and are imbalanced toward\nneutral expressions. Furthermore, as AU involve subtle face movements they are\ndifficult to annotate so that some of the few provided datapoints may be\nmislabeled. In this work, we aim at exploiting label smoothing ability to\nmitigate noisy examples impact by reducing confidence [1]. However, applying\nlabel smoothing as it is may aggravate imbalance-based pre-existing\nunder-confidence issue and degrade performance. To circumvent this issue, we\npropose Robin Hood Label Smoothing (RHLS). RHLS principle is to restrain label\nsmoothing confidence reduction to the majority class. In that extent, it\nalleviates both the imbalance-based over-confidence issue and the negative\nimpact of noisy majority class examples. From an experimental standpoint, we\nshow that RHLS provides a free performance improvement in AU detection. In\nparticular, by applying it on top of a modern multi-task baseline we get\npromising results on BP4D and outperform state-of-the-art methods on DISFA.\n","authors":["Gauthier Tallec","Arnaud Dapogny","Kevin Bailly"],"pdf_url":"https://arxiv.org/pdf/2303.02994v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09098v2","updated":"2023-03-06T09:33:17Z","published":"2022-12-18T14:51:46Z","title":"Mask-FPAN: Semi-Supervised Face Parsing in the Wild With De-Occlusion\n  and UV GAN","summary":"  Fine-grained semantic segmentation of a person's face and head, including\nfacial parts and head components, has progressed a great deal in recent years.\nHowever, it remains a challenging task, whereby considering ambiguous\nocclusions and large pose variations are particularly difficult. To overcome\nthese difficulties, we propose a novel framework termed Mask-FPAN. It uses a\nde-occlusion module that learns to parse occluded faces in a semi-supervised\nway. In particular, face landmark localization, face occlusionstimations, and\ndetected head poses are taken into account. A 3D morphable face model combined\nwith the UV GAN improves the robustness of 2D face parsing. In addition, we\nintroduce two new datasets named FaceOccMask-HQ and CelebAMaskOcc-HQ for face\nparing work. The proposed Mask-FPAN framework addresses the face parsing\nproblem in the wild and shows significant performance improvements with MIOU\nfrom 0.7353 to 0.9013 compared to the state-of-the-art on challenging face\ndatasets.\n","authors":["Lei Li","Tianfang Zhang","Stefan Oehmcke","Fabian Gieseke","Christian Igel"],"pdf_url":"https://arxiv.org/pdf/2212.09098v2.pdf","comment":"renew later"},{"id":"http://arxiv.org/abs/2303.02984v1","updated":"2023-03-06T09:23:14Z","published":"2023-03-06T09:23:14Z","title":"Learning multi-scale local conditional probability models of images","summary":"  Deep neural networks can learn powerful prior probability models for images,\nas evidenced by the high-quality generations obtained with recent score-based\ndiffusion methods. But the means by which these networks capture complex global\nstatistical structure, apparently without suffering from the curse of\ndimensionality, remain a mystery. To study this, we incorporate diffusion\nmethods into a multi-scale decomposition, reducing dimensionality by assuming a\nstationary local Markov model for wavelet coefficients conditioned on\ncoarser-scale coefficients. We instantiate this model using convolutional\nneural networks (CNNs) with local receptive fields, which enforce both the\nstationarity and Markov properties. Global structures are captured using a CNN\nwith receptive fields covering the entire (but small) low-pass image. We test\nthis model on a dataset of face images, which are highly non-stationary and\ncontain large-scale geometric structures. Remarkably, denoising,\nsuper-resolution, and image synthesis results all demonstrate that these\nstructures can be captured with significantly smaller conditioning\nneighborhoods than required by a Markov model implemented in the pixel domain.\nOur results show that score estimation for large complex images can be reduced\nto low-dimensional Markov conditional models across scales, alleviating the\ncurse of dimensionality.\n","authors":["Zahra Kadkhodaie","Florentin Guth","Stéphane Mallat","Eero P Simoncelli"],"pdf_url":"https://arxiv.org/pdf/2303.02984v1.pdf","comment":"16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.02982v1","updated":"2023-03-06T09:17:47Z","published":"2023-03-06T09:17:47Z","title":"CLIP-guided Prototype Modulating for Few-shot Action Recognition","summary":"  Learning from large-scale contrastive language-image pre-training like CLIP\nhas shown remarkable success in a wide range of downstream tasks recently, but\nit is still under-explored on the challenging few-shot action recognition\n(FSAR) task. In this work, we aim to transfer the powerful multimodal knowledge\nof CLIP to alleviate the inaccurate prototype estimation issue due to data\nscarcity, which is a critical problem in low-shot regimes. To this end, we\npresent a CLIP-guided prototype modulating framework called CLIP-FSAR, which\nconsists of two key components: a video-text contrastive objective and a\nprototype modulation. Specifically, the former bridges the task discrepancy\nbetween CLIP and the few-shot video task by contrasting videos and\ncorresponding class text descriptions. The latter leverages the transferable\ntextual concepts from CLIP to adaptively refine visual prototypes with a\ntemporal Transformer. By this means, CLIP-FSAR can take full advantage of the\nrich semantic priors in CLIP to obtain reliable prototypes and achieve accurate\nfew-shot classification. Extensive experiments on five commonly used benchmarks\ndemonstrate the effectiveness of our proposed method, and CLIP-FSAR\nsignificantly outperforms existing state-of-the-art methods under various\nsettings. The source code and models will be publicly available at\nhttps://github.com/alibaba-mmai-research/CLIP-FSAR.\n","authors":["Xiang Wang","Shiwei Zhang","Jun Cen","Changxin Gao","Yingya Zhang","Deli Zhao","Nong Sang"],"pdf_url":"https://arxiv.org/pdf/2303.02982v1.pdf","comment":"This work has been submitted to the Springer for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible"},{"id":"http://arxiv.org/abs/2303.02978v1","updated":"2023-03-06T09:10:55Z","published":"2023-03-06T09:10:55Z","title":"System for 3D Acquisition and 3D Reconstruction using Structured Light\n  for Sewer Line Inspection","summary":"  The assessment of sewer pipe systems is a highly important, but at the same\ntime cumbersome and error-prone task. We introduce an innovative system based\non single-shot structured light modules that facilitates the detection and\nclassification of spatial defects like jutting intrusions, spallings, or\nmisaligned joints. This system creates highly accurate 3D measurements with\nsub-millimeter resolution of pipe surfaces and fuses them into a holistic 3D\nmodel. The benefit of such a holistic 3D model is twofold: on the one hand, it\nfacilitates the accurate manual sewer pipe assessment, on the other, it\nsimplifies the detection of defects in downstream automatic systems as it\nendows the input with highly accurate depth information. In this work, we\nprovide an extensive overview of the system and give valuable insights into our\ndesign choices.\n","authors":["Johannes Künzel","Darko Vehar","Rico Nestler","Karl-Heinz Franke","Anna Hilsmann","Peter Eisert"],"pdf_url":"https://arxiv.org/pdf/2303.02978v1.pdf","comment":"10 pages, published at VISAPP 2023, Lisbon, Portugal"},{"id":"http://arxiv.org/abs/2202.00446v2","updated":"2023-03-06T09:06:49Z","published":"2022-02-01T14:58:21Z","title":"Multi-Order Networks for Action Unit Detection","summary":"  Action Units (AU) are muscular activations used to describe facial\nexpressions. Therefore accurate AU recognition unlocks unbiaised face\nrepresentation which can improve face-based affective computing applications.\nFrom a learning standpoint AU detection is a multi-task problem with strong\ninter-task dependencies. To solve such problem, most approaches either rely on\nweight sharing, or add explicit dependency modelling by decomposing the joint\ntask distribution using Bayes chain rule. If the latter strategy yields\ncomprehensive inter-task relationships modelling, it requires imposing an\narbitrary order into an unordered task set. Crucially, this ordering choice has\nbeen identified as a source of performance variations. In this paper, we\npresent Multi-Order Network (MONET), a multi-task method with joint task order\noptimization. MONET uses a differentiable order selection to jointly learn\ntask-wise modules with their optimal chaining order. Furthermore, we introduce\nwarmup and order dropout to enhance order selection by encouraging order\nexploration. Experimentally, we first demonstrate MONET capacity to retrieve\nthe optimal order in a toy environment. Second, we validate MONET architecture\nby showing that MONET outperforms existing multi-task baselines on multiple\nattribute detection problems chosen for their wide range of dependency\nsettings. More importantly, we demonstrate that MONET significantly extends\nstate-of-the-art performance in AU detection.\n","authors":["Gauthier Tallec","Arnaud Dapogny","Kevin Bailly"],"pdf_url":"https://arxiv.org/pdf/2202.00446v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02975v1","updated":"2023-03-06T09:06:49Z","published":"2023-03-06T09:06:49Z","title":"Histogram-based Deep Learning for Automotive Radar","summary":"  There are various automotive applications that rely on correctly interpreting\npoint cloud data recorded with radar sensors. We present a deep learning\napproach for histogram-based processing of such point clouds. Compared to\nexisting methods, the design of our approach is extremely simple: it boils down\nto computing a point cloud histogram and passing it through a multi-layer\nperceptron. Our approach matches and surpasses state-of-the-art approaches on\nthe task of automotive radar object type classification. It is also robust to\nnoise that often corrupts radar measurements, and can deal with missing\nfeatures of single radar reflections. Finally, the design of our approach makes\nit more interpretable than existing methods, allowing insightful analysis of\nits decisions.\n","authors":["Maxim Tatarchenko","Kilian Rambach"],"pdf_url":"https://arxiv.org/pdf/2303.02975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06961v2","updated":"2023-03-06T09:01:36Z","published":"2023-02-14T10:40:20Z","title":"Bilateral-Fuser: A Novel Multi-cue Fusion Architecture with\n  Anatomical-aware Tokens for Fovea Localization","summary":"  Accurate localization of the fovea is a crucial initial step in analyzing\nretinal diseases since it helps prevent irreversible vision loss. Although\ncurrent deep learning-based methods achieve better performance than traditional\nmethods, they still face challenges such as inadequate utilization of\nanatomical landmarks, sensitivity to diseased retinal images, and various image\nconditions. In this paper, we propose a novel transformer-based architecture\n(Bilateral-Fuser) for multi-cue fusion. The Bilateral-Fuser explicitly\nincorporates long-range connections and global features using retina and vessel\ndistributions to achieve robust fovea localization. We introduce a spatial\nattention mechanism in the dual-stream encoder to extract and fuse self-learned\nanatomical information. This design focuses more on features distributed along\nblood vessels and significantly reduces computational costs by reducing token\nnumbers. Our comprehensive experiments demonstrate that the proposed\narchitecture achieves state-of-the-art performance on two public datasets and\none large-scale private dataset. Moreover, we show that the Bilateral-Fuser is\nmore robust on both normal and diseased retina images and has better\ngeneralization capacity in cross-dataset experiments.\n","authors":["Sifan Song","Jinfeng Wang","Zilong Wang","Shaopeng Wang","Jionglong Su","Xiaowei Ding","Kang Dang"],"pdf_url":"https://arxiv.org/pdf/2302.06961v2.pdf","comment":"This paper is prepared for IEEE Transactions on Medical Imaging"},{"id":"http://arxiv.org/abs/2303.02081v2","updated":"2023-03-06T08:58:43Z","published":"2023-03-03T16:55:44Z","title":"Unproportional mosaicing","summary":"  Data shift is a gap between data distribution used for training and data\ndistribution encountered in the real-world. Data augmentations help narrow the\ngap by generating new data samples, increasing data variability, and data space\ncoverage. We present a new data augmentation: Unproportional mosaicing\n(Unprop). Our augmentation randomly splits an image into various-sized blocks\nand swaps its content (pixels) while maintaining block sizes. Our method\nachieves a lower error rate when combined with other state-of-the-art\naugmentations.\n","authors":["Vojtech Molek","Petr Hurtik","Pavel Vlasanek","David Adamczyk"],"pdf_url":"https://arxiv.org/pdf/2303.02081v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02970v1","updated":"2023-03-06T08:54:18Z","published":"2023-03-06T08:54:18Z","title":"Rethinking Confidence Calibration for Failure Prediction","summary":"  Reliable confidence estimation for the predictions is important in many\nsafety-critical applications. However, modern deep neural networks are often\noverconfident for their incorrect predictions. Recently, many calibration\nmethods have been proposed to alleviate the overconfidence problem. With\ncalibrated confidence, a primary and practical purpose is to detect\nmisclassification errors by filtering out low-confidence predictions (known as\nfailure prediction). In this paper, we find a general, widely-existed but\nactually-neglected phenomenon that most confidence calibration methods are\nuseless or harmful for failure prediction. We investigate this problem and\nreveal that popular confidence calibration methods often lead to worse\nconfidence separation between correct and incorrect samples, making it more\ndifficult to decide whether to trust a prediction or not. Finally, inspired by\nthe natural connection between flat minima and confidence separation, we\npropose a simple hypothesis: flat minima is beneficial for failure prediction.\nWe verify this hypothesis via extensive experiments and further boost the\nperformance by combining two different flat minima techniques. Our code is\navailable at https://github.com/Impression2805/FMFP\n","authors":["Fei Zhu","Zhen Cheng","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02970v1.pdf","comment":"Accepted to ECCV 2022. Code is available at\n  https://github.com/Impression2805/FMFP"},{"id":"http://arxiv.org/abs/2303.02968v1","updated":"2023-03-06T08:53:22Z","published":"2023-03-06T08:53:22Z","title":"DwinFormer: Dual Window Transformers for End-to-End Monocular Depth\n  Estimation","summary":"  Depth estimation from a single image is of paramount importance in the realm\nof computer vision, with a multitude of applications. Conventional methods\nsuffer from the trade-off between consistency and fine-grained details due to\nthe local-receptive field limiting their practicality. This lack of long-range\ndependency inherently comes from the convolutional neural network part of the\narchitecture. In this paper, a dual window transformer-based network, namely\nDwinFormer, is proposed, which utilizes both local and global features for\nend-to-end monocular depth estimation. The DwinFormer consists of dual window\nself-attention and cross-attention transformers, Dwin-SAT and Dwin-CAT,\nrespectively. The Dwin-SAT seamlessly extracts intricate, locally aware\nfeatures while concurrently capturing global context. It harnesses the power of\nlocal and global window attention to adeptly capture both short-range and\nlong-range dependencies, obviating the need for complex and computationally\nexpensive operations, such as attention masking or window shifting. Moreover,\nDwin-SAT introduces inductive biases which provide desirable properties, such\nas translational equvariance and less dependence on large-scale data.\nFurthermore, conventional decoding methods often rely on skip connections which\nmay result in semantic discrepancies and a lack of global context when fusing\nencoder and decoder features. In contrast, the Dwin-CAT employs both local and\nglobal window cross-attention to seamlessly fuse encoder and decoder features\nwith both fine-grained local and contextually aware global information,\neffectively amending semantic gap. Empirical evidence obtained through\nextensive experimentation on the NYU-Depth-V2 and KITTI datasets demonstrates\nthe superiority of the proposed method, consistently outperforming existing\napproaches across both indoor and outdoor environments.\n","authors":["Md Awsafur Rahman","Shaikh Anowarul Fattah"],"pdf_url":"https://arxiv.org/pdf/2303.02968v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02967v1","updated":"2023-03-06T08:51:01Z","published":"2023-03-06T08:51:01Z","title":"Automated Peripancreatic Vessel Segmentation and Labeling Based on\n  Iterative Trunk Growth and Weakly Supervised Mechanism","summary":"  Peripancreatic vessel segmentation and anatomical labeling play extremely\nimportant roles to assist the early diagnosis, surgery planning and prognosis\nfor patients with pancreatic tumors. However, most current techniques cannot\nachieve satisfactory segmentation performance for peripancreatic veins and\nusually make predictions with poor integrity and connectivity. Besides,\nunsupervised labeling algorithms cannot deal with complex anatomical variation\nwhile fully supervised methods require a large number of voxel-wise annotations\nfor training, which is very labor-intensive and time-consuming. To address\nthese problems, we propose our Automated Peripancreatic vEssel Segmentation and\nlAbeling (APESA) framework, to not only highly improve the segmentation\nperformance for peripancreatic veins, but also efficiently identify the\nperipancreatic artery branches. There are two core modules in our proposed\nAPESA framework: iterative trunk growth module (ITGM) for vein segmentation and\nweakly supervised labeling mechanism (WSLM) for artery branch identification.\nOur proposed ITGM is composed of a series of trunk growth modules, each of\nwhich chooses the most reliable trunk of a basic vessel prediction by the\nlargest connected constraint, and seeks for the possible growth branches by\nbranch proposal network. Our designed iterative process guides the raw trunk to\nbe more complete and fully connected. Our proposed WSLM consists of an\nunsupervised rule-based preprocessing for generating pseudo branch annotations,\nand an anatomical labeling network to learn the branch distribution voxel by\nvoxel. We achieve Dice of 94.01% for vein segmentation on our collected\ndataset, which boosts the accuracy by nearly 10% compared with the\nstate-of-the-art methods. Additionally, we also achieve Dice of 97.01% on\nsegmentation and competitive performance on anatomical labeling for\nperipancreatic arteries.\n","authors":["Liwen Zou","Zhenghua Cai","Liang Mao","Ziwei Nie","Yudong Qiu","Xiaoping Yang"],"pdf_url":"https://arxiv.org/pdf/2303.02967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02961v1","updated":"2023-03-06T08:32:50Z","published":"2023-03-06T08:32:50Z","title":"Models See Hallucinations: Evaluating the Factuality in Video Captioning","summary":"  Video captioning aims to describe events in a video with natural language. In\nrecent years, many works have focused on improving captioning models'\nperformance. However, like other text generation tasks, it risks introducing\nfactual errors not supported by the input video. These factual errors can\nseriously affect the quality of the generated text, sometimes making it\ncompletely unusable. Although factual consistency has received much research\nattention in text-to-text tasks (e.g., summarization), it is less studied in\nthe context of vision-based text generation. In this work, we conduct a\ndetailed human evaluation of the factuality in video captioning and collect two\nannotated factuality datasets. We find that 57.0% of the model-generated\nsentences have factual errors, indicating it is a severe problem in this field.\nHowever, existing evaluation metrics are mainly based on n-gram matching and\nshow little correlation with human factuality annotation. We further propose a\nweakly-supervised, model-based factuality metric FactVC, which outperforms\nprevious metrics on factuality evaluation of video captioning. The datasets and\nmetrics will be released to promote future research for video captioning.\n","authors":["Hui Liu","Xiaojun Wan"],"pdf_url":"https://arxiv.org/pdf/2303.02961v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2303.02959v1","updated":"2023-03-06T08:19:15Z","published":"2023-03-06T08:19:15Z","title":"Butterfly: Multiple Reference Frames Feature Propagation Mechanism for\n  Neural Video Compression","summary":"  Using more reference frames can significantly improve the compression\nefficiency in neural video compression. However, in low-latency scenarios, most\nexisting neural video compression frameworks usually use the previous one frame\nas reference. Or a few frameworks which use the previous multiple frames as\nreference only adopt a simple multi-reference frames propagation mechanism. In\nthis paper, we present a more reasonable multi-reference frames propagation\nmechanism for neural video compression, called butterfly multi-reference frame\npropagation mechanism (Butterfly), which allows a more effective feature fusion\nof multi-reference frames. By this, we can generate more accurate temporal\ncontext conditional prior for Contextual Coding Module. Besides, when the\nnumber of decoded frames does not meet the required number of reference frames,\nwe duplicate the nearest reference frame to achieve the requirement, which is\nbetter than duplicating the furthest one. Experiment results show that our\nmethod can significantly outperform the previous state-of-the-art (SOTA), and\nour neural codec can achieve -7.6% bitrate save on HEVC Class D dataset when\ncompares with our base single-reference frame model with the same compression\nconfiguration.\n","authors":["Feng Wang","Haihang Ruan","Fei Xiong","Jiayu Yang","Litian Li","Ronggang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.02959v1.pdf","comment":"Accepted by DCC 2023"},{"id":"http://arxiv.org/abs/2303.02954v1","updated":"2023-03-06T07:54:37Z","published":"2023-03-06T07:54:37Z","title":"Centroid Distance Distillation for Effective Rehearsal in Continual\n  Learning","summary":"  Rehearsal, retraining on a stored small data subset of old tasks, has been\nproven effective in solving catastrophic forgetting in continual learning.\nHowever, due to the sampled data may have a large bias towards the original\ndataset, retraining them is susceptible to driving continual domain drift of\nold tasks in feature space, resulting in forgetting. In this paper, we focus on\ntackling the continual domain drift problem with centroid distance\ndistillation. First, we propose a centroid caching mechanism for sampling data\npoints based on constructed centroids to reduce the sample bias in rehearsal.\nThen, we present a centroid distance distillation that only stores the centroid\ndistance to reduce the continual domain drift. The experiments on four\ncontinual learning datasets show the superiority of the proposed method, and\nthe continual domain drift can be reduced.\n","authors":["Daofeng Liu","Fan Lyu","Linyan Li","Zhenping Xia","Fuyuan Hu"],"pdf_url":"https://arxiv.org/pdf/2303.02954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08024v2","updated":"2023-03-06T07:38:08Z","published":"2022-11-15T10:15:21Z","title":"NAR-Former: Neural Architecture Representation Learning towards Holistic\n  Attributes Prediction","summary":"  With the wide and deep adoption of deep learning models in real applications,\nthere is an increasing need to model and learn the representations of the\nneural networks themselves. These models can be used to estimate attributes of\ndifferent neural network architectures such as the accuracy and latency,\nwithout running the actual training or inference tasks. In this paper, we\npropose a neural architecture representation model that can be used to estimate\nthese attributes holistically. Specifically, we first propose a simple and\neffective tokenizer to encode both the operation and topology information of a\nneural network into a single sequence. Then, we design a multi-stage fusion\ntransformer to build a compact vector representation from the converted\nsequence. For efficient model training, we further propose an information flow\nconsistency augmentation and correspondingly design an architecture consistency\nloss, which brings more benefits with less augmentation samples compared with\nprevious random augmentation strategies. Experiment results on NAS-Bench-101,\nNAS-Bench-201, DARTS search space and NNLQP show that our proposed framework\ncan be used to predict the aforementioned latency and accuracy attributes of\nboth cell architectures and whole deep neural networks, and achieves promising\nperformance.\n","authors":["Yun Yi","Haokui Zhang","Wenze Hu","Nannan Wang","Xiaoyu Wang"],"pdf_url":"https://arxiv.org/pdf/2211.08024v2.pdf","comment":"9 pages, 4 figures, 7 tables. Accepted by Computer Vision and Pattern\n  Recognition (CVPR)2023. The code will be released soon"},{"id":"http://arxiv.org/abs/2211.11425v2","updated":"2023-03-06T07:37:49Z","published":"2022-11-21T13:12:07Z","title":"Data Leakage and Evaluation Issues in Micro-Expression Analysis","summary":"  Micro-expressions have drawn increasing interest lately due to various\npotential applications. The task is, however, difficult as it incorporates many\nchallenges from the fields of computer vision, machine learning and emotional\nsciences. Due to the spontaneous and subtle characteristics of\nmicro-expressions, the available training and testing data are limited, which\nmake evaluation complex. We show that data leakage and fragmented evaluation\nprotocols are issues among the micro-expression literature. We find that fixing\ndata leaks can drastically reduce model performance, in some cases even making\nthe models perform similarly to a random classifier. To this end, we go through\ncommon pitfalls, propose a new standardized evaluation protocol using facial\naction units with over 2000 micro-expression samples, and provide an open\nsource library that implements the evaluation protocols in a standardized\nmanner. Code is publicly available in \\url{https://github.com/tvaranka/meb}.\n","authors":["Tuomas Varanka","Yante Li","Wei Peng","Guoying Zhao"],"pdf_url":"https://arxiv.org/pdf/2211.11425v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02944v1","updated":"2023-03-06T07:31:01Z","published":"2023-03-06T07:31:01Z","title":"CTG-Net: An Efficient Cascaded Framework Driven by Terminal Guidance\n  Mechanism for Dilated Pancreatic Duct Segmentation","summary":"  Pancreatic duct dilation indicates a high risk of various pancreatic\ndiseases. Segmentation of dilated pancreatic ducts on computed tomography (CT)\nimages shows the potential to assist the early diagnosis, surgical planning and\nprognosis. Because of the ducts' tiny sizes, slender tubular structures and the\nsurrounding distractions, most current researches on pancreatic duct\nsegmentation achieve low accuracy and always have segmentation errors on the\nterminal parts of the ducts. To address these problems, we propose a terminal\nguidance mechanism called cascaded terminal guidance network (CTG-Net).\nFirstly, a terminal attention mechanism is established on the skeletons\nextracted from the coarse predictions. Then, to get fine terminal segmentation,\na subnetwork is designed for jointly learning the local intensity from the\noriginal images, feature cues from coarse predictions and global anatomy\ninformation from the pancreas distance transform maps. Finally, a terminal\ndistraction attention module which explicitly learns the distribution of the\nterminal distraction is proposed to reduce the false positive and false\nnegative predictions. We also propose a new metric called tDice to measure the\nterminal segmentation accuracy for targets with tubular structures and two\nsegmentation metrics for distractions. We collect our dilated pancreatic duct\nsegmentation dataset with 150 CT scans from patients with 5 types of pancreatic\ntumors. Experimental results on our dataset show that our proposed approach\nboosts dilated pancreatic duct segmentation accuracy by nearly 20% compared\nwith the existing results, and achieves more than 9% improvement for the\nterminal segmentation accuracy compared with the state-of-the-art methods.\n","authors":["Liwen Zou","Zhenghua Cai","Yudong Qiu","Luying Gui","Liang Mao","Xiaoping Yang"],"pdf_url":"https://arxiv.org/pdf/2303.02944v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02943v1","updated":"2023-03-06T07:30:53Z","published":"2023-03-06T07:30:53Z","title":"Adaptive Texture Filtering for Single-Domain Generalized Segmentation","summary":"  Domain generalization in semantic segmentation aims to alleviate the\nperformance degradation on unseen domains through learning domain-invariant\nfeatures. Existing methods diversify images in the source domain by adding\ncomplex or even abnormal textures to reduce the sensitivity to domain specific\nfeatures. However, these approaches depend heavily on the richness of the\ntexture bank, and training them can be time-consuming. In contrast to importing\ntextures arbitrarily or augmenting styles randomly, we focus on the single\nsource domain itself to achieve generalization. In this paper, we present a\nnovel adaptive texture filtering mechanism to suppress the influence of texture\nwithout using augmentation, thus eliminating the interference of\ndomain-specific features. Further, we design a hierarchical guidance\ngeneralization network equipped with structure-guided enhancement modules,\nwhich purpose is to learn the domain-invariant generalized knowledge. Extensive\nexperiments together with ablation studies on widely-used datasets are\nconducted to verify the effectiveness of the proposed model, and reveal its\nsuperiority over other state-of-the-art alternatives.\n","authors":["Xinhui Li","Mingjia Li","Yaxing Wang","Chuan-Xian Ren","Xiaojie Guo"],"pdf_url":"https://arxiv.org/pdf/2303.02943v1.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.02936v1","updated":"2023-03-06T07:10:07Z","published":"2023-03-06T07:10:07Z","title":"UniHCP: A Unified Model for Human-Centric Perceptions","summary":"  Human-centric perceptions (e.g., pose estimation, human parsing, pedestrian\ndetection, person re-identification, etc.) play a key role in industrial\napplications of visual models. While specific human-centric tasks have their\nown relevant semantic aspect to focus on, they also share the same underlying\nsemantic structure of the human body. However, few works have attempted to\nexploit such homogeneity and design a general-propose model for human-centric\ntasks. In this work, we revisit a broad range of human-centric tasks and unify\nthem in a minimalist manner. We propose UniHCP, a Unified Model for\nHuman-Centric Perceptions, which unifies a wide range of human-centric tasks in\na simplified end-to-end manner with the plain vision transformer architecture.\nWith large-scale joint training on 33 human-centric datasets, UniHCP can\noutperform strong baselines on several in-domain and downstream tasks by direct\nevaluation. When adapted to a specific task, UniHCP achieves new SOTAs on a\nwide range of human-centric tasks, e.g., 69.8 mIoU on CIHP for human parsing,\n86.18 mA on PA-100K for attribute prediction, 90.3 mAP on Market1501 for ReID,\nand 85.8 JI on CrowdHuman for pedestrian detection, performing better than\nspecialized models tailored for each task.\n","authors":["Yuanzheng Ci","Yizhou Wang","Meilin Chen","Shixiang Tang","Lei Bai","Feng Zhu","Rui Zhao","Fengwei Yu","Donglian Qi","Wanli Ouyang"],"pdf_url":"https://arxiv.org/pdf/2303.02936v1.pdf","comment":"Accepted for publication at the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition 2023 (CVPR 2023)"},{"id":"http://arxiv.org/abs/2303.02930v1","updated":"2023-03-06T06:52:00Z","published":"2023-03-06T06:52:00Z","title":"Scapegoat Generation for Privacy Protection from Deepfake","summary":"  To protect privacy and prevent malicious use of deepfake, current studies\npropose methods that interfere with the generation process, such as detection\nand destruction approaches. However, these methods suffer from sub-optimal\ngeneralization performance to unseen models and add undesirable noise to the\noriginal image. To address these problems, we propose a new problem formulation\nfor deepfake prevention: generating a ``scapegoat image'' by modifying the\nstyle of the original input in a way that is recognizable as an avatar by the\nuser, but impossible to reconstruct the real face. Even in the case of\nmalicious deepfake, the privacy of the users is still protected. To achieve\nthis, we introduce an optimization-based editing method that utilizes GAN\ninversion to discourage deepfake models from generating similar scapegoats. We\nvalidate the effectiveness of our proposed method through quantitative and user\nstudies.\n","authors":["Gido Kato","Yoshihiro Fukuhara","Mariko Isogawa","Hideki Tsunashima","Hirokatsu Kataoka","Shigeo Morishima"],"pdf_url":"https://arxiv.org/pdf/2303.02930v1.pdf","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2203.09287v2","updated":"2023-03-06T06:50:31Z","published":"2022-03-17T12:30:17Z","title":"HybridCap: Inertia-aid Monocular Capture of Challenging Human Motions","summary":"  Monocular 3D motion capture (mocap) is beneficial to many applications. The\nuse of a single camera, however, often fails to handle occlusions of different\nbody parts and hence it is limited to capture relatively simple movements. We\npresent a light-weight, hybrid mocap technique called HybridCap that augments\nthe camera with only 4 Inertial Measurement Units (IMUs) in a\nlearning-and-optimization framework. We first employ a weakly-supervised and\nhierarchical motion inference module based on cooperative Gated Recurrent Unit\n(GRU) blocks that serve as limb, body and root trackers as well as an inverse\nkinematics solver. Our network effectively narrows the search space of\nplausible motions via coarse-to-fine pose estimation and manages to tackle\nchallenging movements with high efficiency. We further develop a hybrid\noptimization scheme that combines inertial feedback and visual cues to improve\ntracking accuracy. Extensive experiments on various datasets demonstrate\nHybridCap can robustly handle challenging movements ranging from fitness\nactions to Latin dance. It also achieves real-time performance up to 60 fps\nwith state-of-the-art accuracy.\n","authors":["Han Liang","Yannan He","Chengfeng Zhao","Mutian Li","Jingya Wang","Jingyi Yu","Lan Xu"],"pdf_url":"https://arxiv.org/pdf/2203.09287v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02922v1","updated":"2023-03-06T06:40:13Z","published":"2023-03-06T06:40:13Z","title":"SurfNN: Joint Reconstruction of Multiple Cortical Surfaces from Magnetic\n  Resonance Images","summary":"  To achieve fast, robust, and accurate reconstruction of the human cortical\nsurfaces from 3D magnetic resonance images (MRIs), we develop a novel deep\nlearning-based framework, referred to as SurfNN, to reconstruct simultaneously\nboth inner (between white matter and gray matter) and outer (pial) surfaces\nfrom MRIs. Different from existing deep learning-based cortical surface\nreconstruction methods that either reconstruct the cortical surfaces separately\nor neglect the interdependence between the inner and outer surfaces, SurfNN\nreconstructs both the inner and outer cortical surfaces jointly by training a\nsingle network to predict a midthickness surface that lies at the center of the\ninner and outer cortical surfaces. The input of SurfNN consists of a 3D MRI and\nan initialization of the midthickness surface that is represented both\nimplicitly as a 3D distance map and explicitly as a triangular mesh with\nspherical topology, and its output includes both the inner and outer cortical\nsurfaces, as well as the midthickness surface. The method has been evaluated on\na large-scale MRI dataset and demonstrated competitive cortical surface\nreconstruction performance.\n","authors":["Hao Zheng","Hongming Li","Yong Fan"],"pdf_url":"https://arxiv.org/pdf/2303.02922v1.pdf","comment":"ISBI 2023"},{"id":"http://arxiv.org/abs/2210.04432v2","updated":"2023-03-06T06:29:13Z","published":"2022-10-10T04:36:50Z","title":"Spectral Geometric Verification: Re-Ranking Point Cloud Retrieval for\n  Metric Localization","summary":"  In large-scale metric localization, an incorrect result during retrieval will\nlead to an incorrect pose estimate or loop closure. Re-ranking methods propose\nto take into account all the top retrieval candidates and re-order them to\nincrease the likelihood of the top candidate being correct. However,\nstate-of-the-art re-ranking methods are inefficient when re-ranking many\npotential candidates due to their need for resource intensive point cloud\nregistration between the query and each candidate. In this work, we propose an\nefficient spectral method for geometric verification (named SpectralGV) that\ndoes not require registration. We demonstrate how the optimal inter-cluster\nscore of the correspondence compatibility graph of two point clouds represents\na robust fitness score measuring their spatial consistency. This score takes\ninto account the subtle geometric differences between structurally similar\npoint clouds and therefore can be used to identify the correct candidate among\npotential matches retrieved by global similarity search. SpectralGV is\ndeterministic, robust to outlier correspondences, and can be computed in\nparallel for all potential candidates. We conduct extensive experiments on 5\nlarge-scale datasets to demonstrate that SpectralGV outperforms other\nstate-of-the-art re-ranking methods and show that it consistently improves the\nrecall and pose estimation of 3 state-of-the-art metric localization\narchitectures while having a negligible effect on their runtime. The\nopen-source implementation and trained models are available at:\nhttps://github.com/csiro-robotics/SpectralGV.\n","authors":["Kavisha Vidanapathirana","Peyman Moghadam","Sridha Sridharan","Clinton Fookes"],"pdf_url":"https://arxiv.org/pdf/2210.04432v2.pdf","comment":"Accepted for publication in IEEE RA-L (2023)"},{"id":"http://arxiv.org/abs/2302.14589v2","updated":"2023-03-06T06:27:07Z","published":"2023-02-28T14:16:32Z","title":"Focus On Details: Online Multi-object Tracking with Diverse Fine-grained\n  Representation","summary":"  Discriminative representation is essential to keep a unique identifier for\neach target in Multiple object tracking (MOT). Some recent MOT methods extract\nfeatures of the bounding box region or the center point as identity embeddings.\nHowever, when targets are occluded, these coarse-grained global representations\nbecome unreliable. To this end, we propose exploring diverse fine-grained\nrepresentation, which describes appearance comprehensively from global and\nlocal perspectives. This fine-grained representation requires high feature\nresolution and precise semantic information. To effectively alleviate the\nsemantic misalignment caused by indiscriminate contextual information\naggregation, Flow Alignment FPN (FAFPN) is proposed for multi-scale feature\nalignment aggregation. It generates semantic flow among feature maps from\ndifferent resolutions to transform their pixel positions. Furthermore, we\npresent a Multi-head Part Mask Generator (MPMG) to extract fine-grained\nrepresentation based on the aligned feature maps. Multiple parallel branches of\nMPMG allow it to focus on different parts of targets to generate local masks\nwithout label supervision. The diverse details in target masks facilitate\nfine-grained representation. Eventually, benefiting from a Shuffle-Group\nSampling (SGS) training strategy with positive and negative samples balanced,\nwe achieve state-of-the-art performance on MOT17 and MOT20 test sets. Even on\nDanceTrack, where the appearance of targets is extremely similar, our method\nsignificantly outperforms ByteTrack by 5.0% on HOTA and 5.6% on IDF1. Extensive\nexperiments have proved that diverse fine-grained representation makes Re-ID\ngreat again in MOT.\n","authors":["Hao Ren","Shoudong Han","Huilin Ding","Ziwen Zhang","Hongwei Wang","Faquan Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14589v2.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2303.02906v1","updated":"2023-03-06T05:52:13Z","published":"2023-03-06T05:52:13Z","title":"MotionVideoGAN: A Novel Video Generator Based on the Motion Space\n  Learned from Image Pairs","summary":"  Video generation has achieved rapid progress benefiting from high-quality\nrenderings provided by powerful image generators. We regard the video synthesis\ntask as generating a sequence of images sharing the same contents but varying\nin motions. However, most previous video synthesis frameworks based on\npre-trained image generators treat content and motion generation separately,\nleading to unrealistic generated videos. Therefore, we design a novel framework\nto build the motion space, aiming to achieve content consistency and fast\nconvergence for video generation. We present MotionVideoGAN, a novel video\ngenerator synthesizing videos based on the motion space learned by pre-trained\nimage pair generators. Firstly, we propose an image pair generator named\nMotionStyleGAN to generate image pairs sharing the same contents and producing\nvarious motions. Then we manage to acquire motion codes to edit one image in\nthe generated image pairs and keep the other unchanged. The motion codes help\nus edit images within the motion space since the edited image shares the same\ncontents with the other unchanged one in image pairs. Finally, we introduce a\nlatent code generator to produce latent code sequences using motion codes for\nvideo generation. Our approach achieves state-of-the-art performance on the\nmost complex video dataset ever used for unconditional video generation\nevaluation, UCF101.\n","authors":["Jingyuan Zhu","Huimin Ma","Jiansheng Chen","Jian Yuan"],"pdf_url":"https://arxiv.org/pdf/2303.02906v1.pdf","comment":"Accepted by IEEE Transactions on Multimedia as a regular paper"},{"id":"http://arxiv.org/abs/2206.03452v2","updated":"2023-03-06T05:51:33Z","published":"2022-06-07T17:17:07Z","title":"Can CNNs Be More Robust Than Transformers?","summary":"  The recent success of Vision Transformers is shaking the long dominance of\nConvolutional Neural Networks (CNNs) in image recognition for a decade.\nSpecifically, in terms of robustness on out-of-distribution samples, recent\nresearch finds that Transformers are inherently more robust than CNNs,\nregardless of different training setups. Moreover, it is believed that such\nsuperiority of Transformers should largely be credited to their\nself-attention-like architectures per se. In this paper, we question that\nbelief by closely examining the design of Transformers. Our findings lead to\nthree highly effective architecture designs for boosting robustness, yet simple\nenough to be implemented in several lines of code, namely a) patchifying input\nimages, b) enlarging kernel size, and c) reducing activation layers and\nnormalization layers. Bringing these components together, we are able to build\npure CNN architectures without any attention-like operations that are as robust\nas, or even more robust than, Transformers. We hope this work can help the\ncommunity better understand the design of robust neural architectures. The code\nis publicly available at https://github.com/UCSC-VLAA/RobustCNN.\n","authors":["Zeyu Wang","Yutong Bai","Yuyin Zhou","Cihang Xie"],"pdf_url":"https://arxiv.org/pdf/2206.03452v2.pdf","comment":"ICLR2023. Code is available at https://github.com/UCSC-VLAA/RobustCNN"},{"id":"http://arxiv.org/abs/2210.15858v3","updated":"2023-03-06T05:00:57Z","published":"2022-10-28T02:56:47Z","title":"Vox-Fusion: Dense Tracking and Mapping with Voxel-based Neural Implicit\n  Representation","summary":"  In this work, we present a dense tracking and mapping system named\nVox-Fusion, which seamlessly fuses neural implicit representations with\ntraditional volumetric fusion methods. Our approach is inspired by the recently\ndeveloped implicit mapping and positioning system and further extends the idea\nso that it can be freely applied to practical scenarios. Specifically, we\nleverage a voxel-based neural implicit surface representation to encode and\noptimize the scene inside each voxel. Furthermore, we adopt an octree-based\nstructure to divide the scene and support dynamic expansion, enabling our\nsystem to track and map arbitrary scenes without knowing the environment like\nin previous works. Moreover, we proposed a high-performance multi-process\nframework to speed up the method, thus supporting some applications that\nrequire real-time performance. The evaluation results show that our methods can\nachieve better accuracy and completeness than previous methods. We also show\nthat our Vox-Fusion can be used in augmented reality and virtual reality\napplications. Our source code is publicly available at\nhttps://github.com/zju3dv/Vox-Fusion.\n","authors":["Xingrui Yang","Hai Li","Hongjia Zhai","Yuhang Ming","Yuqian Liu","Guofeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.15858v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06323v3","updated":"2023-03-06T05:00:50Z","published":"2022-10-12T15:42:40Z","title":"AISFormer: Amodal Instance Segmentation with Transformer","summary":"  Amodal Instance Segmentation (AIS) aims to segment the region of both visible\nand possible occluded parts of an object instance. While Mask R-CNN-based AIS\napproaches have shown promising results, they are unable to model high-level\nfeatures coherence due to the limited receptive field. The most recent\ntransformer-based models show impressive performance on vision tasks, even\nbetter than Convolution Neural Networks (CNN). In this work, we present\nAISFormer, an AIS framework, with a Transformer-based mask head. AISFormer\nexplicitly models the complex coherence between occluder, visible, amodal, and\ninvisible masks within an object's regions of interest by treating them as\nlearnable queries. Specifically, AISFormer contains four modules: (i) feature\nencoding: extract ROI and learn both short-range and long-range visual\nfeatures. (ii) mask transformer decoding: generate the occluder, visible, and\namodal mask query embeddings by a transformer decoder (iii) invisible mask\nembedding: model the coherence between the amodal and visible masks, and (iv)\nmask predicting: estimate output masks including occluder, visible, amodal and\ninvisible. We conduct extensive experiments and ablation studies on three\nchallenging benchmarks i.e. KINS, D2SA, and COCOA-cls to evaluate the\neffectiveness of AISFormer. The code is available at:\nhttps://github.com/UARK-AICV/AISFormer\n","authors":["Minh Tran","Khoa Vo","Kashu Yamazaki","Arthur Fernandes","Michael Kidd","Ngan Le"],"pdf_url":"https://arxiv.org/pdf/2210.06323v3.pdf","comment":"Accepted to BMVC2022"},{"id":"http://arxiv.org/abs/2303.02885v1","updated":"2023-03-06T04:32:34Z","published":"2023-03-06T04:32:34Z","title":"Improving Transformer-based Image Matching by Cascaded Capturing\n  Spatially Informative Keypoints","summary":"  Learning robust local image feature matching is a fundamental low-level\nvision task, which has been widely explored in the past few years. Recently,\ndetector-free local feature matchers based on transformers have shown promising\nresults, which largely outperform pure Convolutional Neural Network (CNN) based\nones. But correlations produced by transformer-based methods are spatially\nlimited to the center of source views' coarse patches, because of the costly\nattention learning. In this work, we rethink this issue and find that such\nmatching formulation degrades pose estimation, especially for low-resolution\nimages. So we propose a transformer-based cascade matching model -- Cascade\nfeature Matching TRansformer (CasMTR), to efficiently learn dense feature\ncorrelations, which allows us to choose more reliable matching pairs for the\nrelative pose estimation. Instead of re-training a new detector, we use a\nsimple yet effective Non-Maximum Suppression (NMS) post-process to filter\nkeypoints through the confidence map, and largely improve the matching\nprecision. CasMTR achieves state-of-the-art performance in indoor and outdoor\npose estimation as well as visual localization. Moreover, thorough ablations\nshow the efficacy of the proposed components and techniques.\n","authors":["Chenjie Cao","Yanwei Fu"],"pdf_url":"https://arxiv.org/pdf/2303.02885v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02881v1","updated":"2023-03-06T04:17:29Z","published":"2023-03-06T04:17:29Z","title":"KBNet: Kernel Basis Network for Image Restoration","summary":"  How to aggregate spatial information plays an essential role in\nlearning-based image restoration. Most existing CNN-based networks adopt static\nconvolutional kernels to encode spatial information, which cannot aggregate\nspatial information adaptively. Recent transformer-based architectures achieve\nadaptive spatial aggregation. But they lack desirable inductive biases of\nconvolutions and require heavy computational costs. In this paper, we propose a\nkernel basis attention (KBA) module, which introduces learnable kernel bases to\nmodel representative image patterns for spatial information aggregation.\nDifferent kernel bases are trained to model different local structures. At each\nspatial location, they are linearly and adaptively fused by predicted\npixel-wise coefficients to obtain aggregation weights. Based on the KBA module,\nwe further design a multi-axis feature fusion (MFF) block to encode and fuse\nchannel-wise, spatial-invariant, and pixel-adaptive features for image\nrestoration. Our model, named kernel basis network (KBNet), achieves\nstate-of-the-art performances on more than ten benchmarks over image denoising,\nderaining, and deblurring tasks while requiring less computational cost than\nprevious SOTA methods.\n","authors":["Yi Zhang","Dasong Li","Xiaoyu Shi","Dailan He","Kangning Song","Xiaogang Wang","Hongwei Qin","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2303.02881v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02880v1","updated":"2023-03-06T04:15:29Z","published":"2023-03-06T04:15:29Z","title":"Spatiotemporal Capsule Neural Network for Vehicle Trajectory Prediction","summary":"  Through advancement of the Vehicle-to-Everything (V2X) network, road safety,\nenergy consumption, and traffic efficiency can be significantly improved. An\naccurate vehicle trajectory prediction benefits communication traffic\nmanagement and network resource allocation for the real-time application of the\nV2X network. Recurrent neural networks and their variants have been reported in\nrecent research to predict vehicle mobility. However, the spatial attribute of\nvehicle movement behavior has been overlooked, resulting in incomplete\ninformation utilization. To bridge this gap, we put forward for the first time\na hierarchical trajectory prediction structure using the capsule neural network\n(CapsNet) with three sequential components. First, the geographic information\nis transformed into a grid map presentation, describing vehicle mobility\ndistribution spatially and temporally. Second, CapsNet serves as the core model\nto embed local temporal and global spatial correlation through hierarchical\ncapsules. Finally, extensive experiments conducted on actual taxi mobility data\ncollected in Porto city (Portugal) and Singapore show that the proposed method\noutperforms the state-of-the-art methods.\n","authors":["Yan Qin","Yong Liang Guan","Chau Yuen"],"pdf_url":"https://arxiv.org/pdf/2303.02880v1.pdf","comment":"IEEE TVT has accepted this paper"},{"id":"http://arxiv.org/abs/2303.02879v1","updated":"2023-03-06T04:14:04Z","published":"2023-03-06T04:14:04Z","title":"A Review of Deep Learning-Powered Mesh Reconstruction Methods","summary":"  With the recent advances in hardware and rendering techniques, 3D models have\nemerged everywhere in our life. Yet creating 3D shapes is arduous and requires\nsignificant professional knowledge. Meanwhile, Deep learning has enabled\nhigh-quality 3D shape reconstruction from various sources, making it a viable\napproach to acquiring 3D shapes with minimal effort. Importantly, to be used in\ncommon 3D applications, the reconstructed shapes need to be represented as\npolygonal meshes, which is a challenge for neural networks due to the\nirregularity of mesh tessellations. In this survey, we provide a comprehensive\nreview of mesh reconstruction methods that are powered by machine learning. We\nfirst describe various representations for 3D shapes in the deep learning\ncontext. Then we review the development of 3D mesh reconstruction methods from\nvoxels, point clouds, single images, and multi-view images. Finally, we\nidentify several challenges in this field and propose potential future\ndirections.\n","authors":["Zhiqin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.02879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.10907v2","updated":"2023-03-06T03:54:48Z","published":"2022-09-22T10:29:17Z","title":"DRKF: Distilled Rotated Kernel Fusion for Efficient Rotation Invariant\n  Descriptors in Local Feature Matching","summary":"  The performance of local feature descriptors degrades in the presence of\nlarge rotation variations. To address this issue, we present an efficient\napproach to learning rotation invariant descriptors. Specifically, we propose\nRotated Kernel Fusion (RKF) which imposes rotations on each convolution kernel\nand improves the inherent nature of CNN. Since RKF can be processed by the\nsubsequent re-parameterization, no extra computational costs will be introduced\nin the inference stage. Moreover, we present Multi-oriented Feature Aggregation\n(MOFA) which ensembles features extracted from multiple rotated versions of\ninput images and can provide auxiliary information for the training of RKF by\nleveraging the knowledge distillation strategy. We refer to the distilled RKF\nmodel as DRKF. Besides the evaluation on a rotation-augmented version of the\npublic dataset HPatches, we also contribute a new dataset named DiverseBEV\nwhich consists of bird's eye view images with large viewpoint changes and\ncamera rotations. Extensive experiments show that our method can outperform\nother state-of-the-art techniques when exposed to large rotation variations.\n","authors":["Ranran Huang","Jiancheng Cai","Chao Li","Zhuoyuan Wu","Xinmin Liu","Zhenhua Chai"],"pdf_url":"https://arxiv.org/pdf/2209.10907v2.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.01904v2","updated":"2023-03-06T03:51:39Z","published":"2023-03-03T13:05:30Z","title":"EcoTTA: Memory-Efficient Continual Test-time Adaptation via\n  Self-distilled Regularization","summary":"  This paper presents a simple yet effective approach that improves continual\ntest-time adaptation (TTA) in a memory-efficient manner. TTA may primarily be\nconducted on edge devices with limited memory, so reducing memory is crucial\nbut has been overlooked in previous TTA studies. In addition, long-term\nadaptation often leads to catastrophic forgetting and error accumulation, which\nhinders applying TTA in real-world deployments. Our approach consists of two\ncomponents to address these issues. First, we present lightweight meta networks\nthat can adapt the frozen original networks to the target domain. This novel\narchitecture minimizes memory consumption by decreasing the size of\nintermediate activations required for backpropagation. Second, our novel\nself-distilled regularization controls the output of the meta networks not to\ndeviate significantly from the output of the frozen original networks, thereby\npreserving well-trained knowledge from the source domain. Without additional\nmemory, this regularization prevents error accumulation and catastrophic\nforgetting, resulting in stable performance even in long-term test-time\nadaptation. We demonstrate that our simple yet effective strategy outperforms\nother state-of-the-art methods on various benchmarks for image classification\nand semantic segmentation tasks. Notably, our proposed method with ResNet-50\nand WideResNet-40 takes 86% and 80% less memory than the recent\nstate-of-the-art method, CoTTA.\n","authors":["Junha Song","Jungsoo Lee","In So Kweon","Sungha Choi"],"pdf_url":"https://arxiv.org/pdf/2303.01904v2.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.02869v1","updated":"2023-03-06T03:37:43Z","published":"2023-03-06T03:37:43Z","title":"Enhancing Border Security and Countering Terrorism Through Computer\n  Vision: a Field of Artificial Intelligence","summary":"  Border security had been a persistent problem in international border\nespecially when it get to the issue of preventing illegal movement of weapons,\ncontraband, drugs, and combating issue of illegal or undocumented immigrant\nwhile at the same time ensuring that lawful trade, economic prosperity coupled\nwith national sovereignty across the border is maintained. In this research\nwork, we used open source computer vision (Open CV) and adaboost algorithm to\ndevelop a model which can detect a moving object a far off, classify it,\nautomatically snap full image and face of the individual separately, and then\nrun a background check on them against worldwide databases while making a\nprediction about an individual being a potential threat, intending immigrant,\npotential terrorists or extremist and then raise sound alarm. Our model can be\ndeployed on any camera device and be mounted at any international border. There\nare two stages involved, we first developed a model based on open CV computer\nvision algorithm, with the ability to detect human movement from afar, it will\nautomatically snap both the face and the full image of the person separately,\nand the second stage is the automatic triggering of background check against\nthe moving object. This ensures it check the moving object against several\ndatabases worldwide and is able to determine the admissibility of the person\nafar off. If the individual is inadmissible, it will automatically alert the\nborder officials with the image of the person and other details, and if the\nbypass the border officials, the system is able to detect and alert the\nauthority with his images and other details. All these operations will be done\nafar off by the AI powered camera before the individual reach the border\n","authors":["Tosin Ige","Abosede Kolade","Olukunle Kolade"],"pdf_url":"https://arxiv.org/pdf/2303.02869v1.pdf","comment":"10 pages, 8 figures, Conference publication"},{"id":"http://arxiv.org/abs/2303.02867v1","updated":"2023-03-06T03:36:06Z","published":"2023-03-06T03:36:06Z","title":"Dual Feedback Attention Framework via Boundary-Aware Auxiliary and\n  Progressive Semantic Optimization for Salient Object Detection in Optical\n  Remote Sensing Imagery","summary":"  Salient object detection in optical remote sensing image (ORSI-SOD) has\ngradually attracted attention thanks to the development of deep learning (DL)\nand salient object detection in natural scene image (NSI-SOD). However, NSI and\nORSI are different in many aspects, such as large coverage, complex background,\nand large differences in target types and scales. Therefore, a new dedicated\nmethod is needed for ORSI-SOD. In addition, existing methods do not pay\nsufficient attention to the boundary of the object, and the completeness of the\nfinal saliency map still needs improvement. To address these issues, we propose\na novel method called Dual Feedback Attention Framework via Boundary-Aware\nAuxiliary and Progressive Semantic Optimization (DFA-BASO). First, Boundary\nProtection Calibration (BPC) module is proposed to reduce the loss of edge\nposition information during forward propagation and suppress noise in low-level\nfeatures. Second, a Dual Feature Feedback Complementary (DFFC) module is\nproposed based on BPC module. It aggregates boundary-semantic dual features and\nprovides effective feedback to coordinate features across different layers.\nFinally, a Strong Semantic Feedback Refinement (SSFR) module is proposed to\nobtain more complete saliency maps. This module further refines feature\nrepresentation and eliminates feature differences through a unique feedback\nmechanism. Extensive experiments on two public datasets show that DFA-BASO\noutperforms 15 state-of-the-art methods. Furthermore, this paper strongly\ndemonstrates the true contribution of DFA-BASO to ORSI-SOD by in-depth analysis\nof the visualization figure. All codes can be found at\nhttps://github.com/YUHsss/DFA-BASO.\n","authors":["Dejun Feng","Hongyu Chen","Suning Liu","Xingyu Shen","Ziyang Liao","Yakun Xie","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.02867v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02862v1","updated":"2023-03-06T03:27:17Z","published":"2023-03-06T03:27:17Z","title":"EvHandPose: Event-based 3D Hand Pose Estimation with Sparse Supervision","summary":"  Event camera shows great potential in 3D hand pose estimation, especially\naddressing the challenges of fast motion and high dynamic range in a low-power\nway. However, due to the asynchronous differential imaging mechanism, it is\nchallenging to design event representation to encode hand motion information\nespecially when the hands are not moving (causing motion ambiguity), and it is\ninfeasible to fully annotate the temporally dense event stream. In this paper,\nwe propose EvHandPose with novel hand flow representations in Event-to-Pose\nmodule for accurate hand pose estimation and alleviating the motion ambiguity\nissue. To solve the problem under sparse annotation, we design contrast\nmaximization and edge constraints in Pose-to-IWE (Image with Warped Events)\nmodule and formulate EvHandPose in a self-supervision framework. We further\nbuild EvRealHands, the first large-scale real-world event-based hand pose\ndataset on several challenging scenes to bridge the domain gap due to relying\non synthetic data and facilitate future research. Experiments on EvRealHands\ndemonstrate that EvHandPose outperforms previous event-based method under all\nevaluation scenes with 15 $\\sim$ 20 mm lower MPJPE and achieves accurate and\nstable hand pose estimation in fast motion and strong light scenes compared\nwith RGB-based methods. Furthermore, EvHandPose demonstrates 3D hand pose\nestimation at 120 fps or higher.\n","authors":["Jianping Jiang","Jiahe Li","Baowen Zhang","Xiaoming Deng","Boxin Shi"],"pdf_url":"https://arxiv.org/pdf/2303.02862v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02110v2","updated":"2023-03-06T03:26:43Z","published":"2023-03-03T17:51:08Z","title":"Need for Objective Task-based Evaluation of Deep Learning-Based\n  Denoising Methods: A Study in the Context of Myocardial Perfusion SPECT","summary":"  Artificial intelligence-based methods have generated substantial interest in\nnuclear medicine. An area of significant interest has been using deep-learning\n(DL)-based approaches for denoising images acquired with lower doses, shorter\nacquisition times, or both. Objective evaluation of these approaches is\nessential for clinical application. DL-based approaches for denoising\nnuclear-medicine images have typically been evaluated using fidelity-based\nfigures of merit (FoMs) such as RMSE and SSIM. However, these images are\nacquired for clinical tasks and thus should be evaluated based on their\nperformance in these tasks. Our objectives were to (1) investigate whether\nevaluation with these FoMs is consistent with objective clinical-task-based\nevaluation; (2) provide a theoretical analysis for determining the impact of\ndenoising on signal-detection tasks; (3) demonstrate the utility of virtual\nclinical trials (VCTs) to evaluate DL-based methods. A VCT to evaluate a\nDL-based method for denoising myocardial perfusion SPECT (MPS) images was\nconducted. The impact of DL-based denoising was evaluated using fidelity-based\nFoMs and AUC, which quantified performance on detecting perfusion defects in\nMPS images as obtained using a model observer with anthropomorphic channels.\nBased on fidelity-based FoMs, denoising using the considered DL-based method\nled to significantly superior performance. However, based on ROC analysis,\ndenoising did not improve, and in fact, often degraded detection-task\nperformance. The results motivate the need for objective task-based evaluation\nof DL-based denoising approaches. Further, this study shows how VCTs provide a\nmechanism to conduct such evaluations using VCTs. Finally, our theoretical\ntreatment reveals insights into the reasons for the limited performance of the\ndenoising approach.\n","authors":["Zitong Yu","Md Ashequr Rahman","Richard Laforest","Thomas H. Schindler","Robert J. Gropler","Richard L. Wahl","Barry A. Siegel","Abhinav K. Jha"],"pdf_url":"https://arxiv.org/pdf/2303.02110v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02857v1","updated":"2023-03-06T03:17:48Z","published":"2023-03-06T03:17:48Z","title":"Weakly Supervised Realtime Dynamic Background Subtraction","summary":"  Background subtraction is a fundamental task in computer vision with numerous\nreal-world applications, ranging from object tracking to video surveillance.\nDynamic backgrounds poses a significant challenge here. Supervised deep\nlearning-based techniques are currently considered state-of-the-art for this\ntask. However, these methods require pixel-wise ground-truth labels, which can\nbe time-consuming and expensive. In this work, we propose a weakly supervised\nframework that can perform background subtraction without requiring per-pixel\nground-truth labels. Our framework is trained on a moving object-free sequence\nof images and comprises two networks. The first network is an autoencoder that\ngenerates background images and prepares dynamic background images for training\nthe second network. The dynamic background images are obtained by thresholding\nthe background-subtracted images. The second network is a U-Net that uses the\nsame object-free video for training and the dynamic background images as\npixel-wise ground-truth labels. During the test phase, the input images are\nprocessed by the autoencoder and U-Net, which generate background and dynamic\nbackground images, respectively. The dynamic background image helps remove\ndynamic motion from the background-subtracted image, enabling us to obtain a\nforeground image that is free of dynamic artifacts. To demonstrate the\neffectiveness of our method, we conducted experiments on selected categories of\nthe CDnet 2014 dataset and the I2R dataset. Our method outperformed all\ntop-ranked unsupervised methods. We also achieved better results than one of\nthe two existing weakly supervised methods, and our performance was similar to\nthe other. Our proposed method is online, real-time, efficient, and requires\nminimal frame-level annotation, making it suitable for a wide range of\nreal-world applications.\n","authors":["Fateme Bahri","Nilanjan Ray"],"pdf_url":"https://arxiv.org/pdf/2303.02857v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2205.07062v2","updated":"2023-03-06T03:00:48Z","published":"2022-05-14T13:36:27Z","title":"An Interpretable MRI Reconstruction Network with Two-grid-cycle\n  Correction and Geometric Prior Distillation","summary":"  Although existing deep learning compressed-sensing-based Magnetic Resonance\nImaging (CS-MRI) methods have achieved considerably impressive performance,\nexplainability and generalizability continue to be challenging for such methods\nsince the transition from mathematical analysis to network design not always\nnatural enough, often most of them are not flexible enough to handle\nmulti-sampling-ratio reconstruction assignments. {In this work, to tackle\nexplainability and generalizability, we propose a unifying deep unfolding\nmulti-sampling-ratio interpretable CS-MRI framework.} The combined approach\noffers more generalizability than previous works whereas deep learning gains\nexplainability through a geometric prior module. Inspired by the multigrid\nalgorithm, we first embed the CS-MRI-based optimization algorithm into\ncorrection-distillation scheme that consists of three ingredients:\npre-relaxation module, correction module and geometric prior distillation\nmodule. Furthermore, we employ a condition module to learn adaptively\nstep-length and noise level, which enables the proposed framework to jointly\ntrain multi-ratio tasks through a single model. { The proposed model not only\ncompensates for the lost contextual information of reconstructed image which is\nrefined from low frequency error in geometric characteristic k-space}, but also\nintegrates the theoretical guarantee of model-based methods and the superior\nreconstruction performances of deep learning-based methods. Therefore, it can\ngive us a novel perspective to design biomedical imaging networks. { Numerical\nexperiments show that our framework outperforms state-of-the-art methods in\nterms of qualitative and quantitative evaluations.} {Our method achieves 3.18\ndB improvement at low CS ratio 10\\% and average 1.42 dB improvement over other\ncomparison methods on brain dataset using Cartesian sampling mask.\n","authors":["Xiaohong Fan","Yin Yang","Ke Chen","Jianping Zhang","Ke Dong"],"pdf_url":"https://arxiv.org/pdf/2205.07062v2.pdf","comment":"14 pages, accepted to Biomedical Signal Processing and Control,March,\n  2023"},{"id":"http://arxiv.org/abs/2301.01970v3","updated":"2023-03-06T02:55:57Z","published":"2023-01-05T09:11:16Z","title":"CAT: LoCalization and IdentificAtion Cascade Detection Transformer for\n  Open-World Object Detection","summary":"  Open-world object detection (OWOD), as a more general and challenging goal,\nrequires the model trained from data on known objects to detect both known and\nunknown objects and incrementally learn to identify these unknown objects. The\nexisting works which employ standard detection framework and fixed\npseudo-labelling mechanism (PLM) have the following problems: (i) The inclusion\nof detecting unknown objects substantially reduces the model's ability to\ndetect known ones. (ii) The PLM does not adequately utilize the priori\nknowledge of inputs. (iii) The fixed selection manner of PLM cannot guarantee\nthat the model is trained in the right direction. We observe that humans\nsubconsciously prefer to focus on all foreground objects and then identify each\none in detail, rather than localize and identify a single object\nsimultaneously, for alleviating the confusion. This motivates us to propose a\nnovel solution called CAT: LoCalization and IdentificAtion Cascade Detection\nTransformer which decouples the detection process via the shared decoder in the\ncascade decoding way. In the meanwhile, we propose the self-adaptive\npseudo-labelling mechanism which combines the model-driven with input-driven\nPLM and self-adaptively generates robust pseudo-labels for unknown objects,\nsignificantly improving the ability of CAT to retrieve unknown objects.\nComprehensive experiments on two benchmark datasets, i.e., MS-COCO and PASCAL\nVOC, show that our model outperforms the state-of-the-art in terms of all\nmetrics in the task of OWOD, incremental object detection (IOD) and open-set\ndetection.\n","authors":["Shuailei Ma","Yuefeng Wang","Jiaqi Fan","Ying Wei","Thomas H. Li","Hongli Liu","Fanbing Lv"],"pdf_url":"https://arxiv.org/pdf/2301.01970v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.05631v2","updated":"2023-03-06T02:31:54Z","published":"2022-11-02T15:39:19Z","title":"Backdoor Defense via Suppressing Model Shortcuts","summary":"  Recent studies have demonstrated that deep neural networks (DNNs) are\nvulnerable to backdoor attacks during the training process. Specifically, the\nadversaries intend to embed hidden backdoors in DNNs so that malicious model\npredictions can be activated through pre-defined trigger patterns. In this\npaper, we explore the backdoor mechanism from the angle of the model structure.\nWe select the skip connection for discussions, inspired by the understanding\nthat it helps the learning of model `shortcuts' where backdoor triggers are\nusually easier to be learned. Specifically, we demonstrate that the attack\nsuccess rate (ASR) decreases significantly when reducing the outputs of some\nkey skip connections. Based on this observation, we design a simple yet\neffective backdoor removal method by suppressing the skip connections in\ncritical layers selected by our method. We also implement fine-tuning on these\nlayers to recover high benign accuracy and to further reduce ASR. Extensive\nexperiments on benchmark datasets verify the effectiveness of our method.\n","authors":["Sheng Yang","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.05631v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2211.01806v2","updated":"2023-03-06T02:26:40Z","published":"2022-11-02T16:03:43Z","title":"BATT: Backdoor Attack with Transformation-based Triggers","summary":"  Deep neural networks (DNNs) are vulnerable to backdoor attacks. The backdoor\nadversaries intend to maliciously control the predictions of attacked DNNs by\ninjecting hidden backdoors that can be activated by adversary-specified trigger\npatterns during the training process. One recent research revealed that most of\nthe existing attacks failed in the real physical world since the trigger\ncontained in the digitized test samples may be different from that of the one\nused for training. Accordingly, users can adopt spatial transformations as the\nimage pre-processing to deactivate hidden backdoors. In this paper, we explore\nthe previous findings from another side. We exploit classical spatial\ntransformations (i.e. rotation and translation) with the specific parameter as\ntrigger patterns to design a simple yet effective poisoning-based backdoor\nattack. For example, only images rotated to a particular angle can activate the\nembedded backdoor of attacked DNNs. Extensive experiments are conducted,\nverifying the effectiveness of our attack under both digital and physical\nsettings and its resistance to existing backdoor defenses.\n","authors":["Tong Xu","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.01806v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2211.05638v2","updated":"2023-03-06T02:20:32Z","published":"2022-11-02T17:05:45Z","title":"Untargeted Backdoor Attack against Object Detection","summary":"  Recent studies revealed that deep neural networks (DNNs) are exposed to\nbackdoor threats when training with third-party resources (such as training\nsamples or backbones). The backdoored model has promising performance in\npredicting benign samples, whereas its predictions can be maliciously\nmanipulated by adversaries based on activating its backdoors with pre-defined\ntrigger patterns. Currently, most of the existing backdoor attacks were\nconducted on the image classification under the targeted manner. In this paper,\nwe reveal that these threats could also happen in object detection, posing\nthreatening risks to many mission-critical applications ($e.g.$, pedestrian\ndetection and intelligent surveillance systems). Specifically, we design a\nsimple yet effective poison-only backdoor attack in an untargeted manner, based\non task characteristics. We show that, once the backdoor is embedded into the\ntarget model by our attack, it can trick the model to lose detection of any\nobject stamped with our trigger patterns. We conduct extensive experiments on\nthe benchmark dataset, showing its effectiveness in both digital and\nphysical-world settings and its resistance to potential defenses.\n","authors":["Chengxiao Luo","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.05638v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2303.01869v2","updated":"2023-03-06T02:15:57Z","published":"2023-03-03T11:52:21Z","title":"Intrinsic Physical Concepts Discovery with Object-Centric Predictive\n  Models","summary":"  The ability to discover abstract physical concepts and understand how they\nwork in the world through observing lies at the core of human intelligence. The\nacquisition of this ability is based on compositionally perceiving the\nenvironment in terms of objects and relations in an unsupervised manner. Recent\napproaches learn object-centric representations and capture visually observable\nconcepts of objects, e.g., shape, size, and location. In this paper, we take a\nstep forward and try to discover and represent intrinsic physical concepts such\nas mass and charge. We introduce the PHYsical Concepts Inference NEtwork\n(PHYCINE), a system that infers physical concepts in different abstract levels\nwithout supervision. The key insights underlining PHYCINE are two-fold,\ncommonsense knowledge emerges with prediction, and physical concepts of\ndifferent abstract levels should be reasoned in a bottom-up fashion. Empirical\nevaluation demonstrates that variables inferred by our system work in\naccordance with the properties of the corresponding physical concepts. We also\nshow that object representations containing the discovered physical concepts\nvariables could help achieve better performance in causal reasoning tasks,\ni.e., ComPhy.\n","authors":["Qu Tang","XiangYu Zhu","Zhen Lei","ZhaoXiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.01869v2.pdf","comment":"Accepted to Computer Vision and Pattern Recognition (CVPR)2023"},{"id":"http://arxiv.org/abs/2303.02835v1","updated":"2023-03-06T02:05:14Z","published":"2023-03-06T02:05:14Z","title":"Traffic Scene Parsing through the TSP6K Dataset","summary":"  Traffic scene parsing is one of the most important tasks to achieve\nintelligent cities. So far, little effort has been spent on constructing\ndatasets specifically for the task of traffic scene parsing. To fill this gap,\nhere we introduce the TSP6K dataset, containing 6,000 urban traffic images and\nspanning hundreds of street scenes under various weather conditions. In\ncontrast to most previous traffic scene datasets collected from a driving\nplatform, the images in our dataset are from the shooting platform high-hanging\non the street. Such traffic images can capture more crowded street scenes with\nseveral times more traffic participants than the driving scenes. Each image in\nthe TSP6K dataset is provided with high-quality pixel-level and instance-level\nannotations. We perform a detailed analysis for the dataset and comprehensively\nevaluate the state-of-the-art scene parsing methods. Considering the vast\ndifference in instance sizes, we propose a detail refining decoder, which\nrecovers the details of different semantic regions in traffic scenes.\nExperiments have shown its effectiveness in parsing high-hanging traffic\nscenes. Code and dataset will be made publicly available.\n","authors":["Peng-Tao Jiang","Yuqi Yang","Yang Cao","Qibin Hou","Ming-Ming Cheng","Chunhua Shen"],"pdf_url":"https://arxiv.org/pdf/2303.02835v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2209.08723v2","updated":"2023-03-06T02:00:56Z","published":"2022-09-19T02:47:48Z","title":"Ensembles of Compact, Region-specific & Regularized Spiking Neural\n  Networks for Scalable Place Recognition","summary":"  Spiking neural networks have significant potential utility in robotics due to\ntheir high energy efficiency on specialized hardware, but proof-of-concept\nimplementations have not yet typically achieved competitive performance or\ncapability with conventional approaches. In this paper, we tackle one of the\nkey practical challenges of scalability by introducing a novel modular ensemble\nnetwork approach, where compact, localized spiking networks each learn and are\nsolely responsible for recognizing places in a local region of the environment\nonly. This modular approach creates a highly scalable system. However, it comes\nwith a high-performance cost where a lack of global regularization at\ndeployment time leads to hyperactive neurons that erroneously respond to places\noutside their learned region. Our second contribution introduces a\nregularization approach that detects and removes these problematic hyperactive\nneurons during the initial environmental learning phase. We evaluate this new\nscalable modular system on benchmark localization datasets Nordland and Oxford\nRobotCar, with comparisons to standard techniques NetVLAD, DenseVLAD, and SAD,\nand a previous spiking neural network system. Our system substantially\noutperforms the previous SNN system on its small dataset, but also maintains\nperformance on 27 times larger benchmark datasets where the operation of the\nprevious system is computationally infeasible, and performs competitively with\nthe conventional localization systems.\n","authors":["Somayeh Hussaini","Michael Milford","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2209.08723v2.pdf","comment":"8 pages, 6 figures, accepted to the IEEE International Conference on\n  Robotics and Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2303.01894v2","updated":"2023-03-06T01:49:30Z","published":"2023-03-03T12:47:30Z","title":"T360RRD: A dataset for 360 degree rotated rectangular box table\n  detection","summary":"  To address the problem of scarcity and high annotation costs of rotated image\ntable detection datasets, this paper proposes a method for building a rotated\nimage table detection dataset. Based on the ICDAR2019MTD modern table detection\ndataset, we refer to the annotation format of the DOTA dataset to create the\nTRR360D rotated table detection dataset. The training set contains 600 rotated\nimages and 977 annotated instances, and the test set contains 240 rotated\nimages and 499 annotated instances. The AP50(T<90) evaluation metric is\ndefined, and this dataset is available for future researchers to study rotated\ntable detection algorithms and promote the development of table detection\ntechnology. The TRR360D rotated table detection dataset was created by\nconstraining the starting point and annotation direction, and is publicly\navailable at https://github.com/vansin/TRR360D.\n","authors":["Wenxing Hu","Minglei Tong"],"pdf_url":"https://arxiv.org/pdf/2303.01894v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02828v1","updated":"2023-03-06T01:45:32Z","published":"2023-03-06T01:45:32Z","title":"Robust Autoencoders for Collective Corruption Removal","summary":"  Robust PCA is a standard tool for learning a linear subspace in the presence\nof sparse corruption or rare outliers. What about robustly learning manifolds\nthat are more realistic models for natural data, such as images? There have\nbeen several recent attempts to generalize robust PCA to manifold settings. In\nthis paper, we propose $\\ell_1$- and scaling-invariant $\\ell_1/\\ell_2$-robust\nautoencoders based on a surprisingly compact formulation built on the intuition\nthat deep autoencoders perform manifold learning. We demonstrate on several\nstandard image datasets that the proposed formulation significantly outperforms\nall previous methods in collectively removing sparse corruption, without clean\nimages for training. Moreover, we also show that the learned manifold\nstructures can be generalized to unseen data samples effectively.\n","authors":["Taihui Li","Hengkang Wang","Peng Le","XianE Tang","Ju Sun"],"pdf_url":"https://arxiv.org/pdf/2303.02828v1.pdf","comment":"This paper has been accepted to ICASSP2023"},{"id":"http://arxiv.org/abs/2211.07740v3","updated":"2023-03-06T01:35:21Z","published":"2022-11-14T20:35:11Z","title":"Denoising diffusion models for out-of-distribution detection","summary":"  Out-of-distribution detection is crucial to the safe deployment of machine\nlearning systems. Currently, unsupervised out-of-distribution detection is\ndominated by generative-based approaches that make use of estimates of the\nlikelihood or other measurements from a generative model. Reconstruction-based\nmethods offer an alternative approach, in which a measure of reconstruction\nerror is used to determine if a sample is out-of-distribution. However,\nreconstruction-based approaches are less favoured, as they require careful\ntuning of the model's information bottleneck - such as the size of the latent\ndimension - to produce good results. In this work, we exploit the view of\ndenoising diffusion probabilistic models (DDPM) as denoising autoencoders where\nthe bottleneck is controlled externally, by means of the amount of noise\napplied. We propose to use DDPMs to reconstruct an input that has been noised\nto a range of noise levels, and use the resulting multi-dimensional\nreconstruction error to classify out-of-distribution inputs. We validate our\napproach both on standard computer-vision datasets and on higher dimension\nmedical datasets. Our approach outperforms not only reconstruction-based\nmethods, but also state-of-the-art generative-based approaches.\n","authors":["Mark S. Graham","Walter H. L. Pinaya","Petru-Daniel Tudosiu","Parashkev Nachev","Sebastien Ourselin","M. Jorge Cardoso"],"pdf_url":"https://arxiv.org/pdf/2211.07740v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02814v1","updated":"2023-03-06T01:01:56Z","published":"2023-03-06T01:01:56Z","title":"Visual Analytics of Neuron Vulnerability to Adversarial Attacks on\n  Convolutional Neural Networks","summary":"  Adversarial attacks on a convolutional neural network (CNN) -- injecting\nhuman-imperceptible perturbations into an input image -- could fool a\nhigh-performance CNN into making incorrect predictions. The success of\nadversarial attacks raises serious concerns about the robustness of CNNs, and\nprevents them from being used in safety-critical applications, such as medical\ndiagnosis and autonomous driving. Our work introduces a visual analytics\napproach to understanding adversarial attacks by answering two questions: (1)\nwhich neurons are more vulnerable to attacks and (2) which image features do\nthese vulnerable neurons capture during the prediction? For the first question,\nwe introduce multiple perturbation-based measures to break down the attacking\nmagnitude into individual CNN neurons and rank the neurons by their\nvulnerability levels. For the second, we identify image features (e.g., cat\nears) that highly stimulate a user-selected neuron to augment and validate the\nneuron's responsibility. Furthermore, we support an interactive exploration of\na large number of neurons by aiding with hierarchical clustering based on the\nneurons' roles in the prediction. To this end, a visual analytics system is\ndesigned to incorporate visual reasoning for interpreting adversarial attacks.\nWe validate the effectiveness of our system through multiple case studies as\nwell as feedback from domain experts.\n","authors":["Yiran Li","Junpeng Wang","Takanori Fujiwara","Kwan-Liu Ma"],"pdf_url":"https://arxiv.org/pdf/2303.02814v1.pdf","comment":"Accepted by the Special Issue on Human-Centered Explainable AI, ACM\n  Transactions on Interactive Intelligent Systems"},{"id":"http://arxiv.org/abs/2102.04615v2","updated":"2023-03-06T00:29:14Z","published":"2021-02-09T02:50:29Z","title":"Benford's law: what does it say on adversarial images?","summary":"  Convolutional neural networks (CNNs) are fragile to small perturbations in\nthe input images. These networks are thus prone to malicious attacks that\nperturb the inputs to force a misclassification. Such slightly manipulated\nimages aimed at deceiving the classifier are known as adversarial images. In\nthis work, we investigate statistical differences between natural images and\nadversarial ones. More precisely, we show that employing a proper image\ntransformation and for a class of adversarial attacks, the distribution of the\nleading digit of the pixels in adversarial images deviates from Benford's law.\nThe stronger the attack, the more distant the resulting distribution is from\nBenford's law. Our analysis provides a detailed investigation of this new\napproach that can serve as a basis for alternative adversarial example\ndetection methods that do not need to modify the original CNN classifier\nneither work on the raw high-dimensional pixels as features to defend against\nattacks.\n","authors":["João G. Zago","Fabio L. Baldissera","Eric A. Antonelo","Rodrigo T. Saad"],"pdf_url":"https://arxiv.org/pdf/2102.04615v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.04220v3","updated":"2023-03-06T00:22:57Z","published":"2022-07-09T08:01:11Z","title":"Rethinking Persistent Homology for Visual Recognition","summary":"  Persistent topological properties of an image serve as an additional\ndescriptor providing an insight that might not be discovered by traditional\nneural networks. The existing research in this area focuses primarily on\nefficiently integrating topological properties of the data in the learning\nprocess in order to enhance the performance. However, there is no existing\nstudy to demonstrate all possible scenarios where introducing topological\nproperties can boost or harm the performance. This paper performs a detailed\nanalysis of the effectiveness of topological properties for image\nclassification in various training scenarios, defined by: the number of\ntraining samples, the complexity of the training data and the complexity of the\nbackbone network. We identify the scenarios that benefit the most from\ntopological features, e.g., training simple networks on small datasets.\nAdditionally, we discuss the problem of topological consistency of the datasets\nwhich is one of the major bottlenecks for using topological features for\nclassification. We further demonstrate how the topological inconsistency can\nharm the performance for certain scenarios.\n","authors":["Ekaterina Khramtsova","Guido Zuccon","Xi Wang","Mahsa Baktashmotlagh"],"pdf_url":"https://arxiv.org/pdf/2207.04220v3.pdf","comment":"ICML 2022 Workshop on Topology, Algebra, and Geometry in Machine\n  Learning"},{"id":"http://arxiv.org/abs/2303.03555v1","updated":"2023-03-06T23:50:24Z","published":"2023-03-06T23:50:24Z","title":"Hyperspectral Compressive Wavefront Sensing","summary":"  Presented is a novel way to combine snapshot compressive imaging and lateral\nshearing interferometry in order to capture the spatio-spectral phase of an\nultrashort laser pulse in a single shot. A deep unrolling algorithm is utilised\nfor the snapshot compressive imaging reconstruction due to its parameter\nefficiency and superior speed relative to other methods, potentially allowing\nfor online reconstruction. The algorithm's regularisation term is represented\nusing neural network with 3D convolutional layers, to exploit the\nspatio-spectral correlations that exist in laser wavefronts. Compressed sensing\nis not typically applied to modulated signals, but we demonstrate its success\nhere. Furthermore, we train a neural network to predict the wavefronts from a\nlateral shearing interferogram in terms of Zernike polynomials, which again\nincreases the speed of our technique without sacrificing fidelity. This method\nis supported with simulation-based results. While applied to the example of\nlateral shearing interferometry, the methods presented here are generally\napplicable to a wide range of signals, including Shack-Hartmann-type sensors.\nThe results may be of interest beyond the context of laser wavefront\ncharacterization, including within quantitative phase imaging.\n","authors":["Sunny Howard","Jannik Esslinger","Robin H. W. Wang","Peter Norreys","Andreas Doepp"],"pdf_url":"https://arxiv.org/pdf/2303.03555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.00182v3","updated":"2023-03-06T23:30:28Z","published":"2022-02-01T02:06:54Z","title":"Semi-supervised 3D Object Detection via Temporal Graph Neural Networks","summary":"  3D object detection plays an important role in autonomous driving and other\nrobotics applications. However, these detectors usually require training on\nlarge amounts of annotated data that is expensive and time-consuming to\ncollect. Instead, we propose leveraging large amounts of unlabeled point cloud\nvideos by semi-supervised learning of 3D object detectors via temporal graph\nneural networks. Our insight is that temporal smoothing can create more\naccurate detection results on unlabeled data, and these smoothed detections can\nthen be used to retrain the detector. We learn to perform this temporal\nreasoning with a graph neural network, where edges represent the relationship\nbetween candidate detections in different time frames. After semi-supervised\nlearning, our method achieves state-of-the-art detection performance on the\nchallenging nuScenes and H3D benchmarks, compared to baselines trained on the\nsame amount of labeled data. Project and code are released at\nhttps://www.jianrenw.com/SOD-TGNN/.\n","authors":["Jianren Wang","Haiming Gang","Siddharth Ancha","Yi-Ting Chen","David Held"],"pdf_url":"https://arxiv.org/pdf/2202.00182v3.pdf","comment":"3DV 2021"},{"id":"http://arxiv.org/abs/2209.14860v2","updated":"2023-03-06T23:19:17Z","published":"2022-09-29T15:24:47Z","title":"Bridging the Gap to Real-World Object-Centric Learning","summary":"  Humans naturally decompose their environment into entities at the appropriate\nlevel of abstraction to act in the world. Allowing machine learning algorithms\nto derive this decomposition in an unsupervised way has become an important\nline of research. However, current methods are restricted to simulated data or\nrequire additional information in the form of motion or depth in order to\nsuccessfully discover objects. In this work, we overcome this limitation by\nshowing that reconstructing features from models trained in a self-supervised\nmanner is a sufficient training signal for object-centric representations to\narise in a fully unsupervised way. Our approach, DINOSAUR, significantly\nout-performs existing image-based object-centric learning models on simulated\ndata and is the first unsupervised object-centric model that scales to\nreal-world datasets such as COCO and PASCAL VOC. DINOSAUR is conceptually\nsimple and shows competitive performance compared to more involved pipelines\nfrom the computer vision literature.\n","authors":["Maximilian Seitzer","Max Horn","Andrii Zadaianchuk","Dominik Zietlow","Tianjun Xiao","Carl-Johann Simon-Gabriel","Tong He","Zheng Zhang","Bernhard Schölkopf","Thomas Brox","Francesco Locatello"],"pdf_url":"https://arxiv.org/pdf/2209.14860v2.pdf","comment":"ICLR 2023 camera-ready version"},{"id":"http://arxiv.org/abs/2303.03508v1","updated":"2023-03-06T21:29:45Z","published":"2023-03-06T21:29:45Z","title":"Memory Maps for Video Object Detection and Tracking on UAVs","summary":"  This paper introduces a novel approach to video object detection detection\nand tracking on Unmanned Aerial Vehicles (UAVs). By incorporating metadata, the\nproposed approach creates a memory map of object locations in actual world\ncoordinates, providing a more robust and interpretable representation of object\nlocations in both, image space and the real world. We use this representation\nto boost confidences, resulting in improved performance for several temporal\ncomputer vision tasks, such as video object detection, short and long-term\nsingle and multi-object tracking, and video anomaly detection. These findings\nconfirm the benefits of metadata in enhancing the capabilities of UAVs in the\nfield of temporal computer vision and pave the way for further advancements in\nthis area.\n","authors":["Benjamin Kiefer","Yitong Quan","Andreas Zell"],"pdf_url":"https://arxiv.org/pdf/2303.03508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.12458v3","updated":"2023-03-06T21:26:26Z","published":"2022-06-24T18:30:26Z","title":"Bag of Tricks for Long-Tail Visual Recognition of Animal Species in\n  Camera-Trap Images","summary":"  Camera traps are a method for monitoring wildlife and they collect a large\nnumber of pictures. The number of images collected of each species usually\nfollows a long-tail distribution, i.e., a few classes have a large number of\ninstances, while a lot of species have just a small percentage. Although in\nmost cases these rare species are the ones of interest to ecologists, they are\noften neglected when using deep-learning models because these models require a\nlarge number of images for the training. In this work, a simple and effective\nframework called Square-Root Sampling Branch (SSB) is proposed, which combines\ntwo classification branches that are trained using square-root sampling and\ninstance sampling to improve long-tail visual recognition, and this is compared\nto state-of-the-art methods for handling this task: square-root sampling,\nclass-balanced focal loss, and balanced group softmax. To achieve a more\ngeneral conclusion, the methods for handling long-tail visual recognition were\nsystematically evaluated in four families of computer vision models (ResNet,\nMobileNetV3, EfficientNetV2, and Swin Transformer) and four camera-trap\ndatasets with different characteristics. Initially, a robust baseline with the\nmost recent training tricks was prepared and, then, the methods for improving\nlong-tail recognition were applied. Our experiments show that square-root\nsampling was the method that most improved the performance for minority classes\nby around 15%; however, this was at the cost of reducing the majority classes'\naccuracy by at least 3%. Our proposed framework (SSB) demonstrated itself to be\ncompetitive with the other methods and achieved the best or the second-best\nresults for most of the cases for the tail classes; but, unlike the square-root\nsampling, the loss in the performance of the head classes was minimal, thus\nachieving the best trade-off among all the evaluated methods.\n","authors":["Fagner Cunha","Eulanda M. dos Santos","Juan G. Colonna"],"pdf_url":"https://arxiv.org/pdf/2206.12458v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.01565v4","updated":"2023-03-06T21:16:01Z","published":"2022-01-05T12:10:42Z","title":"User Evaluation of Culture-to-Culture Image Translation with Generative\n  Adversarial Nets","summary":"  The article introduces the concept of image ``culturization,\" i.e., defined\nas the process of altering the ``brushstroke of cultural features\" that make\nobjects perceived as belonging to a given culture while preserving their\nfunctionalities. First, we defined a pipeline for translating objects' images\nfrom a source to a target cultural domain based on state-of-the-art Generative\nAdversarial Networks. Then, we gathered data through an online questionnaire to\ntest four hypotheses concerning the impact of images belonging to different\ncultural domains on Italian participants. As expected, results depend on\nindividual tastes and preferences: however, they align with our conjecture that\nsome people, during the interaction with an intelligent system, will prefer to\nbe shown images modified to match their cultural background.\n","authors":["Giulia Zaino","Carmine Tommaso Recchiuto","Antonio Sgorbissa"],"pdf_url":"https://arxiv.org/pdf/2201.01565v4.pdf","comment":"40 pages (bibliography excluded), 5 figures, 6 Tables"},{"id":"http://arxiv.org/abs/2302.03573v2","updated":"2023-03-06T21:03:39Z","published":"2023-02-07T16:37:19Z","title":"Local Neural Descriptor Fields: Locally Conditioned Object\n  Representations for Manipulation","summary":"  A robot operating in a household environment will see a wide range of unique\nand unfamiliar objects. While a system could train on many of these, it is\ninfeasible to predict all the objects a robot will see. In this paper, we\npresent a method to generalize object manipulation skills acquired from a\nlimited number of demonstrations, to novel objects from unseen shape\ncategories. Our approach, Local Neural Descriptor Fields (L-NDF), utilizes\nneural descriptors defined on the local geometry of the object to effectively\ntransfer manipulation demonstrations to novel objects at test time. In doing\nso, we leverage the local geometry shared between objects to produce a more\ngeneral manipulation framework. We illustrate the efficacy of our approach in\nmanipulating novel objects in novel poses -- both in simulation and in the real\nworld.\n","authors":["Ethan Chun","Yilun Du","Anthony Simeonov","Tomas Lozano-Perez","Leslie Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2302.03573v2.pdf","comment":"ICRA 2023, Project Page: https://elchun.github.io/lndf/"},{"id":"http://arxiv.org/abs/2104.02206v6","updated":"2023-03-06T20:32:23Z","published":"2021-04-06T00:53:01Z","title":"Tuned Compositional Feature Replays for Efficient Stream Learning","summary":"  Our brains extract durable, generalizable knowledge from transient\nexperiences of the world. Artificial neural networks come nowhere close: when\ntasked with learning to classify objects by training on non-repeating video\nframes in temporal order (online stream learning), models that learn well from\nshuffled datasets catastrophically forget old knowledge upon learning new\nstimuli. We propose a new continual learning algorithm, Compositional Replay\nUsing Memory Blocks (CRUMB), which mitigates forgetting by replaying feature\nmaps reconstructed by recombining generic parts. Just as crumbs together form a\nloaf of bread, we concatenate trainable and re-usable \"memory block\" vectors to\ncompositionally reconstruct feature map tensors in convolutional neural\nnetworks. CRUMB stores the indices of memory blocks used to reconstruct new\nstimuli, enabling replay of specific memories during later tasks. CRUMB's\nmemory blocks are tuned to enhance replay: a single feature map stored,\nreconstructed, and replayed by CRUMB mitigates forgetting during video stream\nlearning more effectively than an entire image, even though it occupies only\n3.6% as much memory. We stress-tested CRUMB alongside 13 competing methods on 5\nchallenging datasets. To address the limited number of existing online stream\nlearning datasets, we introduce 2 new benchmarks by adapting existing datasets\nfor stream learning. With about 4% of the memory and 20% of the runtime, CRUMB\nmitigates catastrophic forgetting more effectively than the prior\nstate-of-the-art. Our code is available at\nhttps://github.com/MorganBDT/crumb.git.\n","authors":["Morgan B. Talbot","Rushikesh Zawar","Rohil Badkundri","Mengmi Zhang","Gabriel Kreiman"],"pdf_url":"https://arxiv.org/pdf/2104.02206v6.pdf","comment":"Copyright 2023 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2303.03471v1","updated":"2023-03-06T19:53:50Z","published":"2023-03-06T19:53:50Z","title":"Refining 3D Human Texture Estimation from a Single Image","summary":"  Estimating 3D human texture from a single image is essential in graphics and\nvision. It requires learning a mapping function from input images of humans\nwith diverse poses into the parametric (UV) space and reasonably hallucinating\ninvisible parts. To achieve a high-quality 3D human texture estimation, we\npropose a framework that adaptively samples the input by a deformable\nconvolution where offsets are learned via a deep neural network. Additionally,\nwe describe a novel cycle consistency loss that improves view generalization.\nWe further propose to train our framework with an uncertainty-based pixel-level\nimage reconstruction loss, which enhances color fidelity. We compare our method\nagainst the state-of-the-art approaches and show significant qualitative and\nquantitative improvements.\n","authors":["Said Fahri Altindis","Adil Meric","Yusuf Dalva","Ugur Gudukbay","Aysegul Dundar"],"pdf_url":"https://arxiv.org/pdf/2303.03471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04500v2","updated":"2023-03-06T19:44:59Z","published":"2022-12-08T18:59:59Z","title":"Masked Video Distillation: Rethinking Masked Feature Modeling for\n  Self-supervised Video Representation Learning","summary":"  Benefiting from masked visual modeling, self-supervised video representation\nlearning has achieved remarkable progress. However, existing methods focus on\nlearning representations from scratch through reconstructing low-level features\nlike raw pixel RGB values. In this paper, we propose masked video distillation\n(MVD), a simple yet effective two-stage masked feature modeling framework for\nvideo representation learning: firstly we pretrain an image (or video) model by\nrecovering low-level features of masked patches, then we use the resulting\nfeatures as targets for masked feature modeling. For the choice of teacher\nmodels, we observe that students taught by video teachers perform better on\ntemporally-heavy video tasks, while image teachers transfer stronger spatial\nrepresentations for spatially-heavy video tasks. Visualization analysis also\nindicates different teachers produce different learned patterns for students.\nMotivated by this observation, we design a spatial-temporal co-teaching method\nfor MVD. Specifically, we distill student models from both video teachers and\nimage teachers by masked feature modeling. Extensive experimental results\ndemonstrate that video transformers pretrained with spatial-temporal\nco-teaching outperform models distilled with a single teacher on a multitude of\nvideo datasets. Our MVD with vanilla ViT achieves state-of-the-art performance\ncompared with previous supervised or self-supervised methods on several\nchallenging video downstream tasks. For example, with the ViT-Large model, our\nMVD achieves 86.4% and 76.7% Top-1 accuracy on Kinetics-400 and\nSomething-Something-v2, outperforming VideoMAE by 1.2% and 2.4% respectively.\nWhen a larger ViT-Huge model is adopted, MVD achieves the state-of-the-art\nperformance with 77.3% Top-1 accuracy on Something-Something-v2 and 41.1 mAP on\nAVA v2.2. Code will be available at \\url{https://github.com/ruiwang2021/mvd}.\n","authors":["Rui Wang","Dongdong Chen","Zuxuan Wu","Yinpeng Chen","Xiyang Dai","Mengchen Liu","Lu Yuan","Yu-Gang Jiang"],"pdf_url":"https://arxiv.org/pdf/2212.04500v2.pdf","comment":"CVPR 2023, code will be available at\n  https://github.com/ruiwang2021/mvd"},{"id":"http://arxiv.org/abs/2207.00056v3","updated":"2023-03-06T19:39:18Z","published":"2022-06-30T18:42:06Z","title":"MultiViz: Towards Visualizing and Understanding Multimodal Models","summary":"  The promise of multimodal models for real-world applications has inspired\nresearch in visualizing and understanding their internal mechanics with the end\ngoal of empowering stakeholders to visualize model behavior, perform model\ndebugging, and promote trust in machine learning models. However, modern\nmultimodal models are typically black-box neural networks, which makes it\nchallenging to understand their internal mechanics. How can we visualize the\ninternal modeling of multimodal interactions in these models? Our paper aims to\nfill this gap by proposing MultiViz, a method for analyzing the behavior of\nmultimodal models by scaffolding the problem of interpretability into 4 stages:\n(1) unimodal importance: how each modality contributes towards downstream\nmodeling and prediction, (2) cross-modal interactions: how different modalities\nrelate with each other, (3) multimodal representations: how unimodal and\ncross-modal interactions are represented in decision-level features, and (4)\nmultimodal prediction: how decision-level features are composed to make a\nprediction. MultiViz is designed to operate on diverse modalities, models,\ntasks, and research areas. Through experiments on 8 trained models across 6\nreal-world tasks, we show that the complementary stages in MultiViz together\nenable users to (1) simulate model predictions, (2) assign interpretable\nconcepts to features, (3) perform error analysis on model misclassifications,\nand (4) use insights from error analysis to debug models. MultiViz is publicly\navailable, will be regularly updated with new interpretation tools and metrics,\nand welcomes inputs from the community.\n","authors":["Paul Pu Liang","Yiwei Lyu","Gunjan Chhablani","Nihal Jain","Zihao Deng","Xingbo Wang","Louis-Philippe Morency","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2207.00056v3.pdf","comment":"ICLR 2023. Code available at: https://github.com/pliang279/MultiViz"},{"id":"http://arxiv.org/abs/2303.03462v1","updated":"2023-03-06T19:37:01Z","published":"2023-03-06T19:37:01Z","title":"Towards Composable Distributions of Latent Space Augmentations","summary":"  We propose a composable framework for latent space image augmentation that\nallows for easy combination of multiple augmentations. Image augmentation has\nbeen shown to be an effective technique for improving the performance of a wide\nvariety of image classification and generation tasks. Our framework is based on\nthe Variational Autoencoder architecture and uses a novel approach for\naugmentation via linear transformation within the latent space itself. We\nexplore losses and augmentation latent geometry to enforce the transformations\nto be composable and involuntary, thus allowing the transformations to be\nreadily combined or inverted. Finally, we show these properties are better\nperforming with certain pairs of augmentations, but we can transfer the latent\nspace to other sets of augmentations to modify performance, effectively\nconstraining the VAE's bottleneck to preserve the variance of specific\naugmentations and features of the image which we care about. We demonstrate the\neffectiveness of our approach with initial results on the MNIST dataset against\nboth a standard VAE and a Conditional VAE. This latent augmentation method\nallows for much greater control and geometric interpretability of the latent\nspace, making it a valuable tool for researchers and practitioners in the\nfield.\n","authors":["Omead Pooladzandi","Jeffrey Jiang","Sunay Bhat","Gregory Pottie"],"pdf_url":"https://arxiv.org/pdf/2303.03462v1.pdf","comment":"Accepted at 2023 Information Theory and Applications Workshop (Feb,\n  San Diego)"},{"id":"http://arxiv.org/abs/2303.03458v1","updated":"2023-03-06T19:30:43Z","published":"2023-03-06T19:30:43Z","title":"Learning Differential Invariants of Planar Curves","summary":"  We propose a learning paradigm for the numerical approximation of\ndifferential invariants of planar curves. Deep neural-networks' (DNNs)\nuniversal approximation properties are utilized to estimate geometric measures.\nThe proposed framework is shown to be a preferable alternative to axiomatic\nconstructions. Specifically, we show that DNNs can learn to overcome\ninstabilities and sampling artifacts and produce consistent signatures for\ncurves subject to a given group of transformations in the plane. We compare the\nproposed schemes to alternative state-of-the-art axiomatic constructions of\ndifferential invariants. We evaluate our models qualitatively and\nquantitatively and propose a benchmark dataset to evaluate approximation models\nof differential invariants of planar curves.\n","authors":["Roy Velich","Ron Kimmel"],"pdf_url":"https://arxiv.org/pdf/2303.03458v1.pdf","comment":"SSVM 2023. arXiv admin note: substantial text overlap with\n  arXiv:2202.05922"},{"id":"http://arxiv.org/abs/2303.03432v1","updated":"2023-03-06T19:00:59Z","published":"2023-03-06T19:00:59Z","title":"Polar Prediction of Natural Videos","summary":"  Observer motion and continuous deformations of objects and surfaces imbue\nnatural videos with distinct temporal structures, enabling partial prediction\nof future frames from past ones. Conventional methods first estimate local\nmotion, or optic flow, and then use it to predict future frames by warping or\ncopying content. Here, we explore a more direct methodology, in which each\nframe is mapped into a learned representation space where the structure of\ntemporal evolution is more readily accessible. Motivated by the geometry of the\nFourier shift theorem and its group-theoretic generalization, we formulate a\nsimple architecture that represents video frames in learned local polar\ncoordinates. Specifically, we construct networks in which pairs of\nconvolutional channel coefficients are treated as complex-valued, and are\noptimized to evolve with slowly varying amplitudes and linearly advancing\nphases. We train these models on next-frame prediction in natural videos, and\ncompare their performance with that of conventional methods using optic flow as\nwell as predictive neural networks. We find that the polar predictor achieves\nbetter performance while remaining interpretable and fast, thereby\ndemonstrating the potential of a flow-free video processing methodology that is\ntrained end-to-end to predict natural video content.\n","authors":["Pierre-Étienne H. Fiquet","Eero P. Simoncelli"],"pdf_url":"https://arxiv.org/pdf/2303.03432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03405v1","updated":"2023-03-06T16:57:45Z","published":"2023-03-06T16:57:45Z","title":"Neural Style Transfer for Vector Graphics","summary":"  Neural style transfer draws researchers' attention, but the interest focuses\non bitmap images. Various models have been developed for bitmap image\ngeneration both online and offline with arbitrary and pre-trained styles.\nHowever, the style transfer between vector images has not almost been\nconsidered. Our research shows that applying standard content and style losses\ninsignificantly changes the vector image drawing style because the structure of\nvector primitives differs a lot from pixels. To handle this problem, we\nintroduce new loss functions. We also develop a new method based on\ndifferentiable rasterization that uses these loss functions and can change the\ncolor and shape parameters of the content image corresponding to the drawing of\nthe style image. Qualitative experiments demonstrate the effectiveness of the\nproposed VectorNST method compared with the state-of-the-art neural style\ntransfer approaches for bitmap images and the only existing approach for\nstylizing vector images, DiffVG. Although the proposed model does not achieve\nthe quality and smoothness of style transfer between bitmap images, we consider\nour work an important early step in this area. VectorNST code and demo service\nare available at https://github.com/IzhanVarsky/VectorNST.\n","authors":["Valeria Efimova","Artyom Chebykin","Ivan Jarsky","Evgenii Prosvirnin","Andrey Filchenkov"],"pdf_url":"https://arxiv.org/pdf/2303.03405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01592v2","updated":"2023-03-06T15:48:03Z","published":"2023-03-02T21:31:35Z","title":"Joint cortical registration of geometry and function using\n  semi-supervised learning","summary":"  Brain surface-based image registration, an important component of brain image\nanalysis, establishes spatial correspondence between cortical surfaces.\nExisting iterative and learning-based approaches focus on accurate registration\nof folding patterns of the cerebral cortex, and assume that geometry predicts\nfunction and thus functional areas will also be well aligned. However,\nstructure/functional variability of anatomically corresponding areas across\nsubjects has been widely reported. In this work, we introduce a learning-based\ncortical registration framework, JOSA, which jointly aligns folding patterns\nand functional maps while simultaneously learning an optimal atlas. We\ndemonstrate that JOSA can substantially improve registration performance in\nboth anatomical and functional domains over existing methods. By employing a\nsemi-supervised training strategy, the proposed framework obviates the need for\nfunctional data during inference, enabling its use in broad neuroscientific\ndomains where functional data may not be observed.\n","authors":["Jian Li","Greta Tuckute","Evelina Fedorenko","Brian L. Edlow","Bruce Fischl","Adrian V. Dalca"],"pdf_url":"https://arxiv.org/pdf/2303.01592v2.pdf","comment":"B. Fischl and A. V. Dalca are co-senior authors with equal\n  contributions"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2303.03321v1","updated":"2023-03-06T17:48:27Z","published":"2023-03-06T17:48:27Z","title":"Implementation of a noisy hyperlink removal system: A semantic and\n  relatedness approach","summary":"  As the volume of data on the web grows, the web structure graph, which is a\ngraph representation of the web, continues to evolve. The structure of this\ngraph has gradually shifted from content-based to non-content-based.\nFurthermore, spam data, such as noisy hyperlinks, in the web structure graph\nadversely affect the speed and efficiency of information retrieval and link\nmining algorithms. Previous works in this area have focused on removing noisy\nhyperlinks using structural and string approaches. However, these approaches\nmay incorrectly remove useful links or be unable to detect noisy hyperlinks in\ncertain circumstances. In this paper, a data collection of hyperlinks is\ninitially constructed using an interactive crawler. The semantic and\nrelatedness structure of the hyperlinks is then studied through semantic web\napproaches and tools such as the DBpedia ontology. Finally, the removal process\nof noisy hyperlinks is carried out using a reasoner on the DBpedia ontology.\nOur experiments demonstrate the accuracy and ability of semantic web\ntechnologies to remove noisy hyperlinks\n","authors":["Kazem Taghandiki","Elnaz Rezaei Ehsan"],"pdf_url":"https://arxiv.org/pdf/2303.03321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03290v1","updated":"2023-03-06T17:06:50Z","published":"2023-03-06T17:06:50Z","title":"AmQA: Amharic Question Answering Dataset","summary":"  Question Answering (QA) returns concise answers or answer lists from natural\nlanguage text given a context document. Many resources go into curating QA\ndatasets to advance robust models' development. There is a surge of QA datasets\nfor languages like English, however, this is not true for Amharic. Amharic, the\nofficial language of Ethiopia, is the second most spoken Semitic language in\nthe world. There is no published or publicly available Amharic QA dataset.\nHence, to foster the research in Amharic QA, we present the first Amharic QA\n(AmQA) dataset. We crowdsourced 2628 question-answer pairs over 378 Wikipedia\narticles. Additionally, we run an XLMR Large-based baseline model to spark\nopen-domain QA research interest. The best-performing baseline achieves an\nF-score of 69.58 and 71.74 in reader-retriever QA and reading comprehension\nsettings respectively.\n","authors":["Tilahun Abedissa","Ricardo Usbeck","Yaregal Assabie"],"pdf_url":"https://arxiv.org/pdf/2303.03290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03229v1","updated":"2023-03-06T15:47:45Z","published":"2023-03-06T15:47:45Z","title":"LongEval-Retrieval: French-English Dynamic Test Collection for\n  Continuous Web Search Evaluation","summary":"  LongEval-Retrieval is a Web document retrieval benchmark that focuses on\ncontinuous retrieval evaluation. This test collection is intended to be used to\nstudy the temporal persistence of Information Retrieval systems and will be\nused as the test collection in the Longitudinal Evaluation of Model Performance\nTrack (LongEval) at CLEF 2023. This benchmark simulates an evolving information\nsystem environment - such as the one a Web search engine operates in - where\nthe document collection, the query distribution, and relevance all move\ncontinuously, while following the Cranfield paradigm for offline evaluation. To\ndo that, we introduce the concept of a dynamic test collection that is composed\nof successive sub-collections each representing the state of an information\nsystem at a given time step. In LongEval-Retrieval, each sub-collection\ncontains a set of queries, documents, and soft relevance assessments built from\nclick models. The data comes from Qwant, a privacy-preserving Web search engine\nthat primarily focuses on the French market. LongEval-Retrieval also provides a\n'mirror' collection: it is initially constructed in the French language to\nbenefit from the majority of Qwant's traffic, before being translated to\nEnglish. This paper presents the creation process of LongEval-Retrieval and\nprovides baseline runs and analysis.\n","authors":["Petra Galuščáková","Romain Deveaud","Gabriela Gonzalez-Saez","Philippe Mulhem","Lorraine Goeuriot","Florina Piroi","Martin Popel"],"pdf_url":"https://arxiv.org/pdf/2303.03229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03050v1","updated":"2023-03-06T11:46:58Z","published":"2023-03-06T11:46:58Z","title":"MABNet: Master Assistant Buddy Network with Hybrid Learning for Image\n  Retrieval","summary":"  Image retrieval has garnered growing interest in recent times. The current\napproaches are either supervised or self-supervised. These methods do not\nexploit the benefits of hybrid learning using both supervision and\nself-supervision. We present a novel Master Assistant Buddy Network (MABNet)\nfor image retrieval which incorporates both learning mechanisms. MABNet\nconsists of master and assistant blocks, both learning independently through\nsupervision and collectively via self-supervision. The master guides the\nassistant by providing its knowledge base as a reference for self-supervision\nand the assistant reports its knowledge back to the master by weight transfer.\nWe perform extensive experiments on public datasets with and without\npost-processing.\n","authors":["Rohit Agarwal","Gyanendra Das","Saksham Aggarwal","Alexander Horsch","Dilip K. Prasad"],"pdf_url":"https://arxiv.org/pdf/2303.03050v1.pdf","comment":"Accepted at International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP) 2023"},{"id":"http://arxiv.org/abs/2303.02916v1","updated":"2023-03-06T06:21:20Z","published":"2023-03-06T06:21:20Z","title":"Privacy-Preserving Fair Item Ranking","summary":"  Users worldwide access massive amounts of curated data in the form of\nrankings on a daily basis. The societal impact of this ease of access has been\nstudied and work has been done to propose and enforce various notions of\nfairness in rankings. Current computational methods for fair item ranking rely\non disclosing user data to a centralized server, which gives rise to privacy\nconcerns for the users. This work is the first to advance research at the\nconjunction of producer (item) fairness and consumer (user) privacy in rankings\nby exploring the incorporation of privacy-preserving techniques; specifically,\ndifferential privacy and secure multi-party computation. Our work extends the\nequity of amortized attention ranking mechanism to be privacy-preserving, and\nwe evaluate its effects with respect to privacy, fairness, and ranking quality.\nOur results using real-world datasets show that we are able to effectively\npreserve the privacy of users and mitigate unfairness of items without making\nadditional sacrifices to the quality of rankings in comparison to the ranking\nmechanism in the clear.\n","authors":["Jia Ao Sun","Sikha Pentyala","Martine De Cock","Golnoosh Farnadi"],"pdf_url":"https://arxiv.org/pdf/2303.02916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02867v1","updated":"2023-03-06T03:36:06Z","published":"2023-03-06T03:36:06Z","title":"Dual Feedback Attention Framework via Boundary-Aware Auxiliary and\n  Progressive Semantic Optimization for Salient Object Detection in Optical\n  Remote Sensing Imagery","summary":"  Salient object detection in optical remote sensing image (ORSI-SOD) has\ngradually attracted attention thanks to the development of deep learning (DL)\nand salient object detection in natural scene image (NSI-SOD). However, NSI and\nORSI are different in many aspects, such as large coverage, complex background,\nand large differences in target types and scales. Therefore, a new dedicated\nmethod is needed for ORSI-SOD. In addition, existing methods do not pay\nsufficient attention to the boundary of the object, and the completeness of the\nfinal saliency map still needs improvement. To address these issues, we propose\na novel method called Dual Feedback Attention Framework via Boundary-Aware\nAuxiliary and Progressive Semantic Optimization (DFA-BASO). First, Boundary\nProtection Calibration (BPC) module is proposed to reduce the loss of edge\nposition information during forward propagation and suppress noise in low-level\nfeatures. Second, a Dual Feature Feedback Complementary (DFFC) module is\nproposed based on BPC module. It aggregates boundary-semantic dual features and\nprovides effective feedback to coordinate features across different layers.\nFinally, a Strong Semantic Feedback Refinement (SSFR) module is proposed to\nobtain more complete saliency maps. This module further refines feature\nrepresentation and eliminates feature differences through a unique feedback\nmechanism. Extensive experiments on two public datasets show that DFA-BASO\noutperforms 15 state-of-the-art methods. Furthermore, this paper strongly\ndemonstrates the true contribution of DFA-BASO to ORSI-SOD by in-depth analysis\nof the visualization figure. All codes can be found at\nhttps://github.com/YUHsss/DFA-BASO.\n","authors":["Dejun Feng","Hongyu Chen","Suning Liu","Xingyu Shen","Ziyang Liao","Yakun Xie","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.02867v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02851v1","updated":"2023-03-06T03:10:38Z","published":"2023-03-06T03:10:38Z","title":"A Survey on Incremental Update for Neural Recommender Systems","summary":"  Recommender Systems (RS) aim to provide personalized suggestions of items for\nusers against consumer over-choice. Although extensive research has been\nconducted to address different aspects and challenges of RS, there still exists\na gap between academic research and industrial applications. Specifically, most\nof the existing models still work in an offline manner, in which the\nrecommender is trained on a large static training set and evaluated on a very\nrestrictive testing set in a one-time process. RS will stay unchanged until the\nnext batch retrain is performed. We frame such RS as Batch Update Recommender\nSystems (BURS). In reality, they have to face the challenges where RS are\nexpected to be instantly updated with new data streaming in, and generate\nupdated recommendations for current user activities based on the newly arrived\ndata. We frame such RS as Incremental Update Recommender Systems (IURS).\n  In this article, we offer a systematic survey of incremental update for\nneural recommender systems. We begin the survey by introducing key concepts and\nformulating the task of IURS. We then illustrate the challenges in IURS\ncompared with traditional BURS. Afterwards, we detail the introduction of\nexisting literature and evaluation issues. We conclude the survey by outlining\nsome prominent open research issues in this area.\n","authors":["Peiyan Zhang","Sunghun Kim"],"pdf_url":"https://arxiv.org/pdf/2303.02851v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2110.11248v2","updated":"2023-03-06T21:47:50Z","published":"2021-10-21T16:17:40Z","title":"Learning to Recommend Using Non-Uniform Data","summary":"  Learning user preferences for products based on their past purchases or\nreviews is at the cornerstone of modern recommendation engines. One\ncomplication in this learning task is that some users are more likely to\npurchase products or review them, and some products are more likely to be\npurchased or reviewed by the users. This non-uniform pattern degrades the power\nof many existing recommendation algorithms, as they assume that the observed\ndata are sampled uniformly at random among user-product pairs. In addition,\nexisting literature on modeling non-uniformity either assume user interests are\nindependent of the products, or lack theoretical understanding. In this paper,\nwe first model the user-product preferences as a partially observed matrix with\nnon-uniform observation pattern. Next, building on the literature about\nlow-rank matrix estimation, we introduce a new weighted trace-norm penalized\nregression to predict unobserved values of the matrix. We then prove an upper\nbound for the prediction error of our proposed approach. Our upper bound is a\nfunction of a number of parameters that are based on a certain weight matrix\nthat depends on the joint distribution of users and products. Utilizing this\nobservation, we introduce a new optimization problem to select a weight matrix\nthat minimizes the upper bound on the prediction error. The final product is a\nnew estimator, NU-Recommend, that outperforms existing methods in both\nsynthetic and real datasets. Our approach aims at accurate predictions for all\nusers while prioritizing fairness. To achieve this, we employ a bias-variance\ntradeoff mechanism that ensures good overall prediction performance without\ncompromising the predictive accuracy for less active users.\n","authors":["Wanning Chen","Mohsen Bayati"],"pdf_url":"https://arxiv.org/pdf/2110.11248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09051v2","updated":"2023-03-06T21:46:08Z","published":"2023-02-17T18:31:31Z","title":"Complex QA and language models hybrid architectures, Survey","summary":"  This paper provides a survey of the state of the art of hybrid language\nmodels architectures and strategies for \"complex\" question-answering (QA, CQA,\nCPS). Very large language models are good at leveraging public data on standard\nproblems but once you want to tackle more specific complex questions or\nproblems you may need specific architecture, knowledge, skills, tasks, methods,\nsensitive data, performance, human approval and versatile feedback... This\nsurvey extends findings from the robust community edited research papers BIG,\nBLOOM and HELM which open source, benchmark and analyze limits and challenges\nof large language models in terms of tasks complexity and strict evaluation on\naccuracy (e.g. fairness, robustness, toxicity, ...). It identifies the key\nelements used with Large Language Models (LLM) to solve complex questions or\nproblems. Recent projects like ChatGPT and GALACTICA have allowed\nnon-specialists to grasp the great potential as well as the equally strong\nlimitations of language models in complex QA. Hybridizing these models with\ndifferent components could allow to overcome these different limits and go much\nfurther. We discuss some challenges associated with complex QA, including\ndomain adaptation, decomposition and efficient multi-step QA, long form QA,\nnon-factoid QA, safety and multi-sensitivity data protection, multimodal\nsearch, hallucinations, QA explainability and truthfulness, time dimension.\nTherefore we review current solutions and promising strategies, using elements\nsuch as hybrid LLM architectures, human-in-the-loop reinforcement learning,\nprompting adaptation, neuro-symbolic and structured knowledge grounding,\nprogram synthesis, and others. We analyze existing solutions and provide an\noverview of the current research and trends in the area of complex QA.\n","authors":["Xavier Daull","Patrice Bellot","Emmanuel Bruno","Vincent Martin","Elisabeth Murisasco"],"pdf_url":"https://arxiv.org/pdf/2302.09051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03445v1","updated":"2023-03-06T19:08:51Z","published":"2023-03-06T19:08:51Z","title":"How Auditing Methodologies Can Impact Our Understanding of YouTube's\n  Recommendation Systems","summary":"  Data generated by audits of social media websites have formed the basis of\nour understanding of the biases presented in algorithmic content recommendation\nsystems. As legislators around the world are beginning to consider regulating\nthe algorithmic systems that drive online platforms, it is critical to ensure\nthe correctness of these inferred biases. However, as we will show in this\npaper, doing so is a challenging task for a variety of reasons related to the\ncomplexity of configuration parameters associated with the audits that gather\ndata from a specific platform.\n  Focusing specifically on YouTube, we show that conducting audits to make\ninferences about YouTube's recommendation systems is more methodologically\nchallenging than one might expect. There are many methodological decisions that\nneed to be considered in order to obtain scientifically valid results, and each\nof these decisions incur costs. For example, should an auditor use (expensive\nto obtain) logged-in YouTube accounts while gathering recommendations from the\nalgorithm to obtain more accurate inferences? We explore the impact of this and\nmany other decisions and make some startling discoveries about the\nmethodological choices that impact YouTube's recommendations. Taken all\ntogether, our research suggests auditing configuration compromises that YouTube\nauditors and researchers can use to reduce audit overhead, both economically\nand computationally, without sacrificing accuracy of their inferences.\nSimilarly, we also identify several configuration parameters that have a\nsignificant impact on the accuracy of measured inferences and should be\ncarefully considered.\n","authors":["Sarmad Chandio","Daniyal Pirwani Dar","Rishab Nithyanand"],"pdf_url":"https://arxiv.org/pdf/2303.03445v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2303.03384v1","updated":"2023-03-06T18:59:19Z","published":"2023-03-06T18:59:19Z","title":"Restoration-Degradation Beyond Linear Diffusions: A Non-Asymptotic\n  Analysis For DDIM-Type Samplers","summary":"  We develop a framework for non-asymptotic analysis of deterministic samplers\nused for diffusion generative modeling. Several recent works have analyzed\nstochastic samplers using tools like Girsanov's theorem and a chain rule\nvariant of the interpolation argument. Unfortunately, these techniques give\nvacuous bounds when applied to deterministic samplers. We give a new\noperational interpretation for deterministic sampling by showing that one step\nalong the probability flow ODE can be expressed as two steps: 1) a restoration\nstep that runs gradient ascent on the conditional log-likelihood at some\ninfinitesimally previous time, and 2) a degradation step that runs the forward\nprocess using noise pointing back towards the current iterate. This perspective\nallows us to extend denoising diffusion implicit models to general, non-linear\nforward processes. We then develop the first polynomial convergence bounds for\nthese samplers under mild conditions on the data distribution.\n","authors":["Sitan Chen","Giannis Daras","Alexandros G. Dimakis"],"pdf_url":"https://arxiv.org/pdf/2303.03384v1.pdf","comment":"29 pages"},{"id":"http://arxiv.org/abs/2303.03382v1","updated":"2023-03-06T18:59:13Z","published":"2023-03-06T18:59:13Z","title":"Globally Optimal Training of Neural Networks with Threshold Activation\n  Functions","summary":"  Threshold activation functions are highly preferable in neural networks due\nto their efficiency in hardware implementations. Moreover, their mode of\noperation is more interpretable and resembles that of biological neurons.\nHowever, traditional gradient based algorithms such as Gradient Descent cannot\nbe used to train the parameters of neural networks with threshold activations\nsince the activation function has zero gradient except at a single\nnon-differentiable point. To this end, we study weight decay regularized\ntraining problems of deep neural networks with threshold activations. We first\nshow that regularized deep threshold network training problems can be\nequivalently formulated as a standard convex optimization problem, which\nparallels the LASSO method, provided that the last hidden layer width exceeds a\ncertain threshold. We also derive a simplified convex optimization formulation\nwhen the dataset can be shattered at a certain layer of the network. We\ncorroborate our theoretical results with various numerical experiments.\n","authors":["Tolga Ergen","Halil Ibrahim Gulluk","Jonathan Lacotte","Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2303.03382v1.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03381v1","updated":"2023-03-06T18:59:09Z","published":"2023-03-06T18:59:09Z","title":"Learning Humanoid Locomotion with Transformers","summary":"  We present a sim-to-real learning-based approach for real-world humanoid\nlocomotion. Our controller is a causal Transformer trained by autoregressive\nprediction of future actions from the history of observations and actions. We\nhypothesize that the observation-action history contains useful information\nabout the world that a powerful Transformer model can use to adapt its behavior\nin-context, without updating its weights. We do not use state estimation,\ndynamics models, trajectory optimization, reference trajectories, or\npre-computed gait libraries. Our controller is trained with large-scale\nmodel-free reinforcement learning on an ensemble of randomized environments in\nsimulation and deployed to the real world in a zero-shot fashion. We evaluate\nour approach in high-fidelity simulation and successfully deploy it to the real\nrobot as well. To the best of our knowledge, this is the first demonstration of\na fully learning-based method for real-world full-sized humanoid locomotion.\n","authors":["Ilija Radosavovic","Tete Xiao","Bike Zhang","Trevor Darrell","Jitendra Malik","Koushil Sreenath"],"pdf_url":"https://arxiv.org/pdf/2303.03381v1.pdf","comment":"Project page: https://humanoid-transformer.github.io"},{"id":"http://arxiv.org/abs/2303.03379v1","updated":"2023-03-06T18:58:13Z","published":"2023-03-06T18:58:13Z","title":"SUREL+: Moving from Walks to Sets for Scalable Subgraph-based Graph\n  Representation Learning","summary":"  Subgraph-based graph representation learning (SGRL) has recently emerged as a\npowerful tool in many prediction tasks on graphs due to its advantages in model\nexpressiveness and generalization ability. Most previous SGRL models face\ncomputational issues associated with the high cost of extracting subgraphs for\neach training or testing query. Recently, SUREL has been proposed as a new\nframework to accelerate SGRL, which samples random walks offline and joins\nthese walks as subgraphs online for prediction. Due to the reusability of\nsampled walks across different queries, SUREL achieves state-of-the-art\nperformance in both scalability and prediction accuracy. However, SUREL still\nsuffers from high computational overhead caused by node redundancy in sampled\nwalks. In this work, we propose a novel framework SUREL+ that upgrades SUREL by\nusing node sets instead of walks to represent subgraphs. This set-based\nrepresentation avoids node duplication by definition, but the sizes of node\nsets can be irregular. To address this issue, we design a dedicated sparse data\nstructure to efficiently store and fast index node sets, and provide a\nspecialized operator to join them in parallel batches. SUREL+ is modularized to\nsupport multiple types of set samplers, structural features, and neural\nencoders to complement the loss of structural information due to the reduction\nfrom walks to sets. Extensive experiments have been performed to validate\nSUREL+ in the prediction tasks of links, relation types, and higher-order\npatterns. SUREL+ achieves 3-11$\\times$ speedups of SUREL while maintaining\ncomparable or even better prediction performance; compared to other SGRL\nbaselines, SUREL+ achieves $\\sim$20$\\times$ speedups and significantly improves\nthe prediction accuracy.\n","authors":["Haoteng Yin","Muhan Zhang","Jianguo Wang","Pan Li"],"pdf_url":"https://arxiv.org/pdf/2303.03379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03378v1","updated":"2023-03-06T18:58:06Z","published":"2023-03-06T18:58:06Z","title":"PaLM-E: An Embodied Multimodal Language Model","summary":"  Large language models excel at a wide range of complex tasks. However,\nenabling general inference in the real world, e.g., for robotics problems,\nraises the challenge of grounding. We propose embodied language models to\ndirectly incorporate real-world continuous sensor modalities into language\nmodels and thereby establish the link between words and percepts. Input to our\nembodied language model are multi-modal sentences that interleave visual,\ncontinuous state estimation, and textual input encodings. We train these\nencodings end-to-end, in conjunction with a pre-trained large language model,\nfor multiple embodied tasks including sequential robotic manipulation planning,\nvisual question answering, and captioning. Our evaluations show that PaLM-E, a\nsingle large embodied multimodal model, can address a variety of embodied\nreasoning tasks, from a variety of observation modalities, on multiple\nembodiments, and further, exhibits positive transfer: the model benefits from\ndiverse joint training across internet-scale language, vision, and\nvisual-language domains. Our largest model, PaLM-E-562B with 562B parameters,\nin addition to being trained on robotics tasks, is a visual-language generalist\nwith state-of-the-art performance on OK-VQA, and retains generalist language\ncapabilities with increasing scale.\n","authors":["Danny Driess","Fei Xia","Mehdi S. M. Sajjadi","Corey Lynch","Aakanksha Chowdhery","Brian Ichter","Ayzaan Wahid","Jonathan Tompson","Quan Vuong","Tianhe Yu","Wenlong Huang","Yevgen Chebotar","Pierre Sermanet","Daniel Duckworth","Sergey Levine","Vincent Vanhoucke","Karol Hausman","Marc Toussaint","Klaus Greff","Andy Zeng","Igor Mordatch","Pete Florence"],"pdf_url":"https://arxiv.org/pdf/2303.03378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16750v2","updated":"2023-03-06T18:57:42Z","published":"2022-11-30T05:33:29Z","title":"Score-based Continuous-time Discrete Diffusion Models","summary":"  Score-based modeling through stochastic differential equations (SDEs) has\nprovided a new perspective on diffusion models, and demonstrated superior\nperformance on continuous data. However, the gradient of the log-likelihood\nfunction, i.e., the score function, is not properly defined for discrete\nspaces. This makes it non-trivial to adapt \\textcolor{\\cdiff}{the score-based\nmodeling} to categorical data. In this paper, we extend diffusion models to\ndiscrete variables by introducing a stochastic jump process where the reverse\nprocess denoises via a continuous-time Markov chain. This formulation admits an\nanalytical simulation during backward sampling. To learn the reverse process,\nwe extend score matching to general categorical data and show that an unbiased\nestimator can be obtained via simple matching of the conditional marginal\ndistributions. We demonstrate the effectiveness of the proposed method on a set\nof synthetic and real-world music and image benchmarks.\n","authors":["Haoran Sun","Lijun Yu","Bo Dai","Dale Schuurmans","Hanjun Dai"],"pdf_url":"https://arxiv.org/pdf/2211.16750v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03376v1","updated":"2023-03-06T18:57:41Z","published":"2023-03-06T18:57:41Z","title":"MAESTRO: Open-Ended Environment Design for Multi-Agent Reinforcement\n  Learning","summary":"  Open-ended learning methods that automatically generate a curriculum of\nincreasingly challenging tasks serve as a promising avenue toward generally\ncapable reinforcement learning agents. Existing methods adapt curricula\nindependently over either environment parameters (in single-agent settings) or\nco-player policies (in multi-agent settings). However, the strengths and\nweaknesses of co-players can manifest themselves differently depending on\nenvironmental features. It is thus crucial to consider the dependency between\nthe environment and co-player when shaping a curriculum in multi-agent domains.\nIn this work, we use this insight and extend Unsupervised Environment Design\n(UED) to multi-agent environments. We then introduce Multi-Agent Environment\nDesign Strategist for Open-Ended Learning (MAESTRO), the first multi-agent UED\napproach for two-player zero-sum settings. MAESTRO efficiently produces\nadversarial, joint curricula over both environments and co-players and attains\nminimax-regret guarantees at Nash equilibrium. Our experiments show that\nMAESTRO outperforms a number of strong baselines on competitive two-player\ngames, spanning discrete and continuous control settings.\n","authors":["Mikayel Samvelyan","Akbir Khan","Michael Dennis","Minqi Jiang","Jack Parker-Holder","Jakob Foerster","Roberta Raileanu","Tim Rocktäschel"],"pdf_url":"https://arxiv.org/pdf/2303.03376v1.pdf","comment":"International Conference on Learning Representations (ICLR) 2023"},{"id":"http://arxiv.org/abs/2211.05952v3","updated":"2023-03-06T18:56:44Z","published":"2022-11-11T01:59:12Z","title":"Efficient Domain Coverage for Vehicles with Second-Order Dynamics via\n  Multi-Agent Reinforcement Learning","summary":"  Collaborative autonomous multi-agent systems covering a specified area have\nmany potential applications, such as UAV search and rescue, forest fire\nfighting, and real-time high-resolution monitoring. Traditional approaches for\nsuch coverage problems involve designing a model-based control policy based on\nsensor data. However, designing model-based controllers is challenging, and the\nstate-of-the-art classical control policy still exhibits a large degree of\nsub-optimality. In this paper, we present a reinforcement learning (RL)\napproach for the multi-agent efficient domain coverage problem involving agents\nwith second-order dynamics. Our approach is based on the Multi-Agent Proximal\nPolicy Optimization Algorithm (MAPPO). Our proposed network architecture\nincludes the incorporation of LSTM and self-attention, which allows the trained\npolicy to adapt to a variable number of agents. Our trained policy\nsignificantly outperforms the state-of-the-art classical control policy. We\ndemonstrate our proposed method in a variety of simulated experiments.\n","authors":["Xinyu Zhao","Razvan C. Fetecau","Mo Chen"],"pdf_url":"https://arxiv.org/pdf/2211.05952v3.pdf","comment":"This version is submitted to IEEE / RSJ International Conference on\n  Intelligent Robots and Systems, 2023"},{"id":"http://arxiv.org/abs/2303.03374v1","updated":"2023-03-06T18:56:39Z","published":"2023-03-06T18:56:39Z","title":"To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in\n  Transfer Learning","summary":"  Transfer learning and ensembling are two popular techniques for improving the\nperformance and robustness of neural networks. Due to the high cost of\npre-training, ensembles of models fine-tuned from a single pre-trained\ncheckpoint are often used in practice. Such models end up in the same basin of\nthe loss landscape and thus have limited diversity. In this work, we study if\nit is possible to improve ensembles trained from a single pre-trained\ncheckpoint by better exploring the pre-train basin or a close vicinity outside\nof it. We show that while exploration of the pre-train basin may be beneficial\nfor the ensemble, leaving the basin results in losing the benefits of transfer\nlearning and degradation of the ensemble quality.\n","authors":["Ildus Sadrtdinov","Dmitrii Pozdeev","Dmitry Vetrov","Ekaterina Lobacheva"],"pdf_url":"https://arxiv.org/pdf/2303.03374v1.pdf","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2303.03372v1","updated":"2023-03-06T18:55:58Z","published":"2023-03-06T18:55:58Z","title":"ALMOST: Adversarial Learning to Mitigate Oracle-less ML Attacks via\n  Synthesis Tuning","summary":"  Oracle-less machine learning (ML) attacks have broken various logic locking\nschemes. Regular synthesis, which is tailored for area-power-delay\noptimization, yields netlists where key-gate localities are vulnerable to\nlearning. Thus, we call for security-aware logic synthesis. We propose ALMOST,\na framework for adversarial learning to mitigate oracle-less ML attacks via\nsynthesis tuning. ALMOST uses a simulated-annealing-based synthesis recipe\ngenerator, employing adversarially trained models that can predict\nstate-of-the-art attacks' accuracies over wide ranges of recipes and key-gate\nlocalities. Experiments on ISCAS benchmarks confirm the attacks' accuracies\ndrops to around 50\\% for ALMOST-synthesized circuits, all while not undermining\ndesign optimization.\n","authors":["Animesh Basak Chowdhury","Lilas Alrahis","Luca Collini","Johann Knechtel","Ramesh Karri","Siddharth Garg","Ozgur Sinanoglu","Benjamin Tan"],"pdf_url":"https://arxiv.org/pdf/2303.03372v1.pdf","comment":"Accepted at Design Automation Conference (DAC 2023)"},{"id":"http://arxiv.org/abs/2209.14977v4","updated":"2023-03-06T18:54:56Z","published":"2022-09-29T17:45:25Z","title":"Transformer Meets Boundary Value Inverse Problems","summary":"  A Transformer-based deep direct sampling method is proposed for electrical\nimpedance tomography, a well-known severely ill-posed nonlinear boundary value\ninverse problem. A real-time reconstruction is achieved by evaluating the\nlearned inverse operator between carefully designed data and the reconstructed\nimages. An effort is made to give a specific example to a fundamental question:\nwhether and how one can benefit from the theoretical structure of a\nmathematical problem to develop task-oriented and structure-conforming deep\nneural networks? Specifically, inspired by direct sampling methods for inverse\nproblems, the 1D boundary data in different frequencies are preprocessed by a\npartial differential equation-based feature map to yield 2D harmonic extensions\nas different input channels. Then, by introducing learnable non-local kernels,\nthe direct sampling is recast to a modified attention mechanism. The new method\nachieves superior accuracy over its predecessors and contemporary operator\nlearners and shows robustness to noises in benchmarks. This research shall\nstrengthen the insights that, despite being invented for natural language\nprocessing tasks, the attention mechanism offers great flexibility to be\nmodified in conformity with the a priori mathematical knowledge, which\nultimately leads to the design of more physics-compatible neural architectures.\n","authors":["Ruchi Guo","Shuhao Cao","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2209.14977v4.pdf","comment":"30 pages, 10 figures. Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03365v1","updated":"2023-03-06T18:49:59Z","published":"2023-03-06T18:49:59Z","title":"Efficient Skill Acquisition for Complex Manipulation Tasks in Obstructed\n  Environments","summary":"  Data efficiency in robotic skill acquisition is crucial for operating robots\nin varied small-batch assembly settings. To operate in such environments,\nrobots must have robust obstacle avoidance and versatile goal conditioning\nacquired from only a few simple demonstrations. Existing approaches, however,\nfall short of these requirements. Deep reinforcement learning (RL) enables a\nrobot to learn complex manipulation tasks but is often limited to small task\nspaces in the real world due to sample inefficiency and safety concerns. Motion\nplanning (MP) can generate collision-free paths in obstructed environments, but\ncannot solve complex manipulation tasks and requires goal states often\nspecified by a user or object-specific pose estimator. In this work, we propose\na system for efficient skill acquisition that leverages an object-centric\ngenerative model (OCGM) for versatile goal identification to specify a goal for\nMP combined with RL to solve complex manipulation tasks in obstructed\nenvironments. Specifically, OCGM enables one-shot target object identification\nand re-identification in new scenes, allowing MP to guide the robot to the\ntarget object while avoiding obstacles. This is combined with a skill\ntransition network, which bridges the gap between terminal states of MP and\nfeasible start states of a sample-efficient RL policy. The experiments\ndemonstrate that our OCGM-based one-shot goal identification provides\ncompetitive accuracy to other baseline approaches and that our modular\nframework outperforms competitive baselines, including a state-of-the-art RL\nalgorithm, by a significant margin for complex manipulation tasks in obstructed\nenvironments.\n","authors":["Jun Yamada","Jack Collins","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2303.03365v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.03364v1","updated":"2023-03-06T18:49:39Z","published":"2023-03-06T18:49:39Z","title":"Leveraging Scene Embeddings for Gradient-Based Motion Planning in Latent\n  Space","summary":"  Motion planning framed as optimisation in structured latent spaces has\nrecently emerged as competitive with traditional methods in terms of planning\nsuccess while significantly outperforming them in terms of computational speed.\nHowever, the real-world applicability of recent work in this domain remains\nlimited by the need to express obstacle information directly in state-space,\ninvolving simple geometric primitives. In this work we address this challenge\nby leveraging learned scene embeddings together with a generative model of the\nrobot manipulator to drive the optimisation process. In addition, we introduce\nan approach for efficient collision checking which directly regularises the\noptimisation undertaken for planning. Using simulated as well as real-world\nexperiments, we demonstrate that our approach, AMP-LS, is able to successfully\nplan in novel, complex scenes while outperforming traditional planning\nbaselines in terms of computation speed by an order of magnitude. We show that\nthe resulting system is fast enough to enable closed-loop planning in\nreal-world dynamic scenes.\n","authors":["Jun Yamada","Chia-Man Hung","Jack Collins","Ioannis Havoutis","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2303.03364v1.pdf","comment":"Project website: https://amp-ls.github.io/"},{"id":"http://arxiv.org/abs/2303.03363v1","updated":"2023-03-06T18:49:09Z","published":"2023-03-06T18:49:09Z","title":"Enhancing Activity Prediction Models in Drug Discovery with the Ability\n  to Understand Human Language","summary":"  Activity and property prediction models are the central workhorses in drug\ndiscovery and materials sciences, but currently they have to be trained or\nfine-tuned for new tasks. Without training or fine-tuning, scientific language\nmodels could be used for such low-data tasks through their announced zero- and\nfew-shot capabilities. However, their predictive quality at activity prediction\nis lacking. In this work, we envision a novel type of activity prediction model\nthat is able to adapt to new prediction tasks at inference time, via\nunderstanding textual information describing the task. To this end, we propose\na new architecture with separate modules for chemical and natural language\ninputs, and a contrastive pre-training objective on data from large biochemical\ndatabases. In extensive experiments, we show that our method CLAMP yields\nimproved predictive performance on few-shot learning benchmarks and zero-shot\nproblems in drug discovery. We attribute the advances of our method to the\nmodularized architecture and to our pre-training objective.\n","authors":["Philipp Seidl","Andreu Vall","Sepp Hochreiter","Günter Klambauer"],"pdf_url":"https://arxiv.org/pdf/2303.03363v1.pdf","comment":"15 pages + 18 pages appendix"},{"id":"http://arxiv.org/abs/2303.03348v1","updated":"2023-03-06T18:35:16Z","published":"2023-03-06T18:35:16Z","title":"Thompson Sampling for Linear Bandit Problems with Normal-Gamma Priors","summary":"  We consider Thompson sampling for linear bandit problems with finitely many\nindependent arms, where rewards are sampled from normal distributions that are\nlinearly dependent on unknown parameter vectors and with unknown variance.\nSpecifically, with a Bayesian formulation we consider multivariate normal-gamma\npriors to represent environment uncertainty for all involved parameters. We\nshow that our chosen sampling prior is a conjugate prior to the reward model\nand derive a Bayesian regret bound for Thompson sampling under the condition\nthat the 5/2-moment of the variance distribution exist.\n","authors":["Björn Lindenberg","Karl-Olof Lindahl"],"pdf_url":"https://arxiv.org/pdf/2303.03348v1.pdf","comment":"27 pages, 2 figures"},{"id":"http://arxiv.org/abs/2209.12152v3","updated":"2023-03-06T18:28:18Z","published":"2022-09-25T05:21:59Z","title":"All are Worth Words: A ViT Backbone for Diffusion Models","summary":"  Vision transformers (ViT) have shown promise in various vision tasks while\nthe U-Net based on a convolutional neural network (CNN) remains dominant in\ndiffusion models. We design a simple and general ViT-based architecture (named\nU-ViT) for image generation with diffusion models. U-ViT is characterized by\ntreating all inputs including the time, condition and noisy image patches as\ntokens and employing long skip connections between shallow and deep layers. We\nevaluate U-ViT in unconditional and class-conditional image generation, as well\nas text-to-image generation tasks, where U-ViT is comparable if not superior to\na CNN-based U-Net of a similar size. In particular, latent diffusion models\nwith U-ViT achieve record-breaking FID scores of 2.29 in class-conditional\nimage generation on ImageNet 256x256, and 5.48 in text-to-image generation on\nMS-COCO, among methods without accessing large external datasets during the\ntraining of generative models. Our results suggest that, for diffusion-based\nimage modeling, the long skip connection is crucial while the down-sampling and\nup-sampling operators in CNN-based U-Net are not always necessary. We believe\nthat U-ViT can provide insights for future research on backbones in diffusion\nmodels and benefit generative modeling on large scale cross-modality datasets.\n","authors":["Fan Bao","Shen Nie","Kaiwen Xue","Yue Cao","Chongxuan Li","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2209.12152v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.07681v3","updated":"2023-03-06T18:25:52Z","published":"2022-08-16T11:42:28Z","title":"Generating a Terrain-Robustness Benchmark for Legged Locomotion: A\n  Prototype via Terrain Authoring and Active Learning","summary":"  Terrain-aware locomotion has become an emerging topic in legged robotics.\nHowever, it is hard to generate diverse, challenging, and realistic\nunstructured terrains in simulation, which limits the way researchers evaluate\ntheir locomotion policies. In this paper, we prototype the generation of a\nterrain dataset via terrain authoring and active learning, and the learned\nsamplers can stably generate diverse high-quality terrains. We expect the\ngenerated dataset to make a terrain-robustness benchmark for legged locomotion.\nThe dataset, the code implementation, and some policy evaluations are released\nat https://bit.ly/3bn4j7f.\n","authors":["Chong Zhang","Lizhi Yang"],"pdf_url":"https://arxiv.org/pdf/2208.07681v3.pdf","comment":"7 pages, 7 figures. IEEE ICRA 2023"},{"id":"http://arxiv.org/abs/2207.09572v2","updated":"2023-03-06T18:18:20Z","published":"2022-07-19T22:00:41Z","title":"Robust Multivariate Time-Series Forecasting: Adversarial Attacks and\n  Defense Mechanisms","summary":"  This work studies the threats of adversarial attack on multivariate\nprobabilistic forecasting models and viable defense mechanisms. Our studies\ndiscover a new attack pattern that negatively impact the forecasting of a\ntarget time series via making strategic, sparse (imperceptible) modifications\nto the past observations of a small number of other time series. To mitigate\nthe impact of such attack, we have developed two defense strategies. First, we\nextend a previously developed randomized smoothing technique in classification\nto multivariate forecasting scenarios. Second, we develop an adversarial\ntraining algorithm that learns to create adversarial examples and at the same\ntime optimizes the forecasting model to improve its robustness against such\nadversarial simulation. Extensive experiments on real-world datasets confirm\nthat our attack schemes are powerful and our defense algorithms are more\neffective compared with baseline defense mechanisms.\n","authors":["Linbo Liu","Youngsuk Park","Trong Nghia Hoang","Hilaf Hasson","Jun Huan"],"pdf_url":"https://arxiv.org/pdf/2207.09572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03340v1","updated":"2023-03-06T18:13:14Z","published":"2023-03-06T18:13:14Z","title":"Symbolic Synthesis of Neural Networks","summary":"  Neural networks adapt very well to distributed and continuous\nrepresentations, but struggle to learn and generalize from small amounts of\ndata. Symbolic systems commonly achieve data efficient generalization by\nexploiting modularity to benefit from local and discrete features of a\nrepresentation. These features allow symbolic programs to be improved one\nmodule at a time and to experience combinatorial growth in the values they can\nsuccessfully process. However, it is difficult to design components that can be\nused to form symbolic abstractions and which are highly-overparametrized like\nneural networks, as the adjustment of parameters makes the semantics of modules\nunstable. I present Graph-based Symbolically Synthesized Neural Networks\n(G-SSNNs), a form of neural network whose topology and parameters are informed\nby the output of a symbolic program. I demonstrate that by developing symbolic\nabstractions at a population level, and applying gradient-based optimization to\nsuch neural models at an individual level, I can elicit reliable patterns of\nimproved generalization with small quantities of data known to contain local\nand discrete features. The paradigm embodied by G-SSNNs offers a route towards\nthe communal development of compact and composable abstractions which can be\nflexibly repurposed for a variety of tasks and high-dimensional media. In\nfuture work, I hope to pursue these benefits by exploring more ambitious G-SSNN\ndesigns based on more complex classes of symbolic programs. The code and data\nassociated with the reported results are publicly available at\nhttps://github.com/shlomenu/symbolically_synthesized_networks .\n","authors":["Eli Whitehouse"],"pdf_url":"https://arxiv.org/pdf/2303.03340v1.pdf","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2302.03917v2","updated":"2023-03-06T18:09:56Z","published":"2023-02-08T07:27:27Z","title":"Noise2Music: Text-conditioned Music Generation with Diffusion Models","summary":"  We introduce Noise2Music, where a series of diffusion models is trained to\ngenerate high-quality 30-second music clips from text prompts. Two types of\ndiffusion models, a generator model, which generates an intermediate\nrepresentation conditioned on text, and a cascader model, which generates\nhigh-fidelity audio conditioned on the intermediate representation and possibly\nthe text, are trained and utilized in succession to generate high-fidelity\nmusic. We explore two options for the intermediate representation, one using a\nspectrogram and the other using audio with lower fidelity. We find that the\ngenerated audio is not only able to faithfully reflect key elements of the text\nprompt such as genre, tempo, instruments, mood, and era, but goes beyond to\nground fine-grained semantics of the prompt. Pretrained large language models\nplay a key role in this story -- they are used to generate paired text for the\naudio of the training set and to extract embeddings of the text prompts\ningested by the diffusion models.\n  Generated examples: https://google-research.github.io/noise2music\n","authors":["Qingqing Huang","Daniel S. Park","Tao Wang","Timo I. Denk","Andy Ly","Nanxin Chen","Zhengdong Zhang","Zhishuai Zhang","Jiahui Yu","Christian Frank","Jesse Engel","Quoc V. Le","William Chan","Zhifeng Chen","Wei Han"],"pdf_url":"https://arxiv.org/pdf/2302.03917v2.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2303.03327v1","updated":"2023-03-06T17:54:33Z","published":"2023-03-06T17:54:33Z","title":"Lower Bounds for $γ$-Regret via the Decision-Estimation Coefficient","summary":"  In this note, we give a new lower bound for the $\\gamma$-regret in bandit\nproblems, the regret which arises when comparing against a benchmark that is\n$\\gamma$ times the optimal solution, i.e., $\\mathsf{Reg}_{\\gamma}(T) = \\sum_{t\n= 1}^T \\gamma \\max_{\\pi} f(\\pi) - f(\\pi_t)$. The $\\gamma$-regret arises in\nstructured bandit problems where finding an exact optimum of $f$ is\nintractable. Our lower bound is given in terms of a modification of the\nconstrained Decision-Estimation Coefficient (DEC) of~\\citet{foster2023tight}\n(and closely related to the original offset DEC of\n\\citet{foster2021statistical}), which we term the $\\gamma$-DEC. When restricted\nto the traditional regret setting where $\\gamma = 1$, our result removes the\nlogarithmic factors in the lower bound of \\citet{foster2023tight}.\n","authors":["Margalit Glasgow","Alexander Rakhlin"],"pdf_url":"https://arxiv.org/pdf/2303.03327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03326v1","updated":"2023-03-06T17:53:42Z","published":"2023-03-06T17:53:42Z","title":"Keep It Simple: CNN Model Complexity Studies for Interference\n  Classification Tasks","summary":"  The growing number of devices using the wireless spectrum makes it important\nto find ways to minimize interference and optimize the use of the spectrum.\nDeep learning models, such as convolutional neural networks (CNNs), have been\nwidely utilized to identify, classify, or mitigate interference due to their\nability to learn from the data directly. However, there have been limited\nresearch on the complexity of such deep learning models. The major focus of\ndeep learning-based wireless classification literature has been on improving\nclassification accuracy, often at the expense of model complexity. This may not\nbe practical for many wireless devices, such as, internet of things (IoT)\ndevices, which usually have very limited computational resources and cannot\nhandle very complex models. Thus, it becomes important to account for model\ncomplexity when designing deep learning-based models for interference\nclassification. To address this, we conduct an analysis of CNN based wireless\nclassification that explores the trade-off amongst dataset size, CNN model\ncomplexity, and classification accuracy under various levels of classification\ndifficulty: namely, interference classification, heterogeneous transmitter\nclassification, and homogeneous transmitter classification. Our study, based on\nthree wireless datasets, shows that a simpler CNN model with fewer parameters\ncan perform just as well as a more complex model, providing important insights\ninto the use of CNNs in computationally constrained applications.\n","authors":["Taiwo Oyedare","Vijay K. Shah","Daniel J. Jakubisin","Jeffrey H. Reed"],"pdf_url":"https://arxiv.org/pdf/2303.03326v1.pdf","comment":"6 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.03324v1","updated":"2023-03-06T17:52:35Z","published":"2023-03-06T17:52:35Z","title":"Time series anomaly detection with sequence reconstruction based\n  state-space model","summary":"  Recent advances in digitization has led to availability of multivariate time\nseries data in various domains, in order to monitor operations in real time.\nIdentifying abnormal data pattern and detect potential failures in these\nscenarios are important yet rather difficult tasks. We propose a novel\nunsupervised anomaly detection method for time series data. Our approach uses\nsequence encoder and decoder to represent the mapping between time series and\nhidden state, and learns bidirectional dynamics simultaneously by leveraging\nbackward and forward temporal information in the training process. We further\nregularize the state space to place constraints on states of normal samples,\nand use Mahalanobis distance to evaluate abnormality level. Results on\nsynthetic and real-world datasets show the superiority of the proposed method.\n","authors":["Fan Wang","Keli Wang","Boyu Yao"],"pdf_url":"https://arxiv.org/pdf/2303.03324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13708v3","updated":"2023-03-06T17:48:32Z","published":"2022-09-27T21:47:23Z","title":"Falsification before Extrapolation in Causal Effect Estimation","summary":"  Randomized Controlled Trials (RCTs) represent a gold standard when developing\npolicy guidelines. However, RCTs are often narrow, and lack data on broader\npopulations of interest. Causal effects in these populations are often\nestimated using observational datasets, which may suffer from unobserved\nconfounding and selection bias. Given a set of observational estimates (e.g.\nfrom multiple studies), we propose a meta-algorithm that attempts to reject\nobservational estimates that are biased. We do so using validation effects,\ncausal effects that can be inferred from both RCT and observational data. After\nrejecting estimators that do not pass this test, we generate conservative\nconfidence intervals on the extrapolated causal effects for subgroups not\nobserved in the RCT. Under the assumption that at least one observational\nestimator is asymptotically normal and consistent for both the validation and\nextrapolated effects, we provide guarantees on the coverage probability of the\nintervals output by our algorithm. To facilitate hypothesis testing in settings\nwhere causal effect transportation across datasets is necessary, we give\nconditions under which a doubly-robust estimator of group average treatment\neffects is asymptotically normal, even when flexible machine learning methods\nare used for estimation of nuisance parameters. We illustrate the properties of\nour approach on semi-synthetic and real world datasets, and show that it\ncompares favorably to standard meta-analysis techniques.\n","authors":["Zeshan Hussain","Michael Oberst","Ming-Chieh Shih","David Sontag"],"pdf_url":"https://arxiv.org/pdf/2209.13708v3.pdf","comment":"Conference on Neural Information Processing Systems, 2022"},{"id":"http://arxiv.org/abs/2303.03323v1","updated":"2023-03-06T17:48:32Z","published":"2023-03-06T17:48:32Z","title":"CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive\n  Learning","summary":"  Multimodal contrastive pretraining has been utilized to train multimodal\nrepresentation models, like CLIP, on vast amounts of paired image-text data.\nHowever, previous studies have highlighted the susceptibility of such models to\nbackdoor attacks. Specifically, when training on backdoored examples, CLIP\nlearns spurious correlations between the embedded backdoor trigger and the\ntarget label, aligning their representations in the joint embedding space. With\ninjecting only a few poisoned examples e.g., 75 examples in the 3M pretraining\ndata, the model's behavior can be significantly manipulated, thus making it\nhard to detect or unlearn such correlations. To address this issue, we propose\nCleanCLIP, a finetuning framework that weakens the learned spurious\nassociations introduced by backdoor attacks by re-aligning the representations\nfor individual modalities independently. CleanCLIP can be employed for both\nunsupervised finetuning on paired image-text data and for supervised finetuning\non labeled image data. We demonstrate that unsupervised finetuning with a\ncombination of multimodal contrastive and unimodal self-supervised objectives\nfor individual modalities can significantly reduce the impact of the backdoor\nattack. Additionally, supervised finetuning on task-specific labeled data of\nthe individual modality, such as image data, removes the backdoor trigger from\nthe CLIP vision encoder. Empirically, we show that CleanCLIP maintains model\nperformance on benign examples while mitigating the impact of a range of\nbackdoor attacks on multimodal contrastive learning.\n","authors":["Hritik Bansal","Nishad Singhi","Yu Yang","Fan Yin","Aditya Grover","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03323v1.pdf","comment":"20 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2303.03320v1","updated":"2023-03-06T17:47:04Z","published":"2023-03-06T17:47:04Z","title":"Learning to Backdoor Federated Learning","summary":"  In a federated learning (FL) system, malicious participants can easily embed\nbackdoors into the aggregated model while maintaining the model's performance\non the main task. To this end, various defenses, including training stage\naggregation-based defenses and post-training mitigation defenses, have been\nproposed recently. While these defenses obtain reasonable performance against\nexisting backdoor attacks, which are mainly heuristics based, we show that they\nare insufficient in the face of more advanced attacks. In particular, we\npropose a general reinforcement learning-based backdoor attack framework where\nthe attacker first trains a (non-myopic) attack policy using a simulator built\nupon its local data and common knowledge on the FL system, which is then\napplied during actual FL training. Our attack framework is both adaptive and\nflexible and achieves strong attack performance and durability even under\nstate-of-the-art defenses.\n","authors":["Henger Li","Chen Wu","Senchun Zhu","Zizhan Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.03320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.03669v3","updated":"2023-03-06T17:32:15Z","published":"2022-06-08T04:09:13Z","title":"Toward Certified Robustness Against Real-World Distribution Shifts","summary":"  We consider the problem of certifying the robustness of deep neural networks\nagainst real-world distribution shifts. To do so, we bridge the gap between\nhand-crafted specifications and realistic deployment settings by proposing a\nnovel neural-symbolic verification framework, in which we train a generative\nmodel to learn perturbations from data and define specifications with respect\nto the output of the learned model. A unique challenge arising from this\nsetting is that existing verifiers cannot tightly approximate sigmoid\nactivations, which are fundamental to many state-of-the-art generative models.\nTo address this challenge, we propose a general meta-algorithm for handling\nsigmoid activations which leverages classical notions of counter-example-guided\nabstraction refinement. The key idea is to \"lazily\" refine the abstraction of\nsigmoid functions to exclude spurious counter-examples found in the previous\nabstraction, thus guaranteeing progress in the verification process while\nkeeping the state-space small. Experiments on the MNIST and CIFAR-10 datasets\nshow that our framework significantly outperforms existing methods on a range\nof challenging distribution shifts.\n","authors":["Haoze Wu","Teruhiro Tagomori","Alexander Robey","Fengjun Yang","Nikolai Matni","George Pappas","Hamed Hassani","Corina Pasareanu","Clark Barrett"],"pdf_url":"https://arxiv.org/pdf/2206.03669v3.pdf","comment":"SatML'23. Keywords: certified robustness, distribution shift,\n  generative models, S-shaped activations, CEGAR"},{"id":"http://arxiv.org/abs/2303.01693v2","updated":"2023-03-06T17:26:25Z","published":"2023-03-03T03:17:53Z","title":"Cross-domain Transfer Learning and State Inference for Soft Robots via a\n  Semi-supervised Sequential Variational Bayes Framework","summary":"  Recently, data-driven models such as deep neural networks have shown to be\npromising tools for modelling and state inference in soft robots. However,\nvoluminous amounts of data are necessary for deep models to perform\neffectively, which requires exhaustive and quality data collection,\nparticularly of state labels. Consequently, obtaining labelled state data for\nsoft robotic systems is challenged for various reasons, including difficulty in\nthe sensorization of soft robots and the inconvenience of collecting data in\nunstructured environments. To address this challenge, in this paper, we propose\na semi-supervised sequential variational Bayes (DSVB) framework for transfer\nlearning and state inference in soft robots with missing state labels on\ncertain robot configurations. Considering that soft robots may exhibit distinct\ndynamics under different robot configurations, a feature space transfer\nstrategy is also incorporated to promote the adaptation of latent features\nacross multiple configurations. Unlike existing transfer learning approaches,\nour proposed DSVB employs a recurrent neural network to model the nonlinear\ndynamics and temporal coherence in soft robot data. The proposed framework is\nvalidated on multiple setup configurations of a pneumatic-based soft robot\nfinger. Experimental results on four transfer scenarios demonstrate that DSVB\nperforms effective transfer learning and accurate state inference amidst\nmissing state labels.\n","authors":["Shageenderan Sapai","Junn Yong Loo","Ze Yang Ding","Chee Pin Tan","Raphael CW Phan","Vishnu Monn Baskaran","Surya Girinatha Nurzaman"],"pdf_url":"https://arxiv.org/pdf/2303.01693v2.pdf","comment":"Accepted at the International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2208.08672v2","updated":"2023-03-06T17:22:50Z","published":"2022-08-18T07:11:34Z","title":"RRWaveNet: A Compact End-to-End Multi-Scale Residual CNN for Robust PPG\n  Respiratory Rate Estimation","summary":"  Respiratory rate (RR) is an important biomarker as RR changes can reflect\nsevere medical events such as heart disease, lung disease, and sleep disorders.\nUnfortunately, standard manual RR counting is prone to human error and cannot\nbe performed continuously. This study proposes a method for continuously\nestimating RR, RRWaveNet. The method is a compact end-to-end deep learning\nmodel which does not require feature engineering and can use low-cost raw\nphotoplethysmography (PPG) as input signal. RRWaveNet was tested\nsubject-independently and compared to baseline in four datasets (BIDMC,\nCapnoBase, WESAD, and SensAI) and using three window sizes (16, 32, and 64\nseconds). RRWaveNet outperformed current state-of-the-art methods with mean\nabsolute errors at optimal window size of 1.66 \\pm 1.01, 1.59 \\pm 1.08, 1.92\n\\pm 0.96 and 1.23 \\pm 0.61 breaths per minute for each dataset. In remote\nmonitoring settings, such as in the WESAD and SensAI datasets, we apply\ntransfer learning to improve the performance using two other ICU datasets as\npretraining datasets, reducing the MAE by up to 21$\\%$. This shows that this\nmodel allows accurate and practical estimation of RR on affordable and wearable\ndevices. Our study also shows feasibility of remote RR monitoring in the\ncontext of telemedicine and at home.\n","authors":["Pongpanut Osathitporn","Guntitat Sawadwuthikul","Punnawish Thuwajit","Kawisara Ueafuea","Thee Mateepithaktham","Narin Kunaseth","Tanut Choksatchawathi","Proadpran Punyabukkana","Emmanuel Mignot","Theerawit Wilaiprasitporn"],"pdf_url":"https://arxiv.org/pdf/2208.08672v2.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.03300v1","updated":"2023-03-06T17:19:23Z","published":"2023-03-06T17:19:23Z","title":"Weight Perturbation Can Help Fairness under Distribution Shift","summary":"  Fairness in machine learning has attracted increasing attention in recent\nyears. The fairness methods improving algorithmic fairness for in-distribution\ndata may not perform well under distribution shift. In this paper, we first\ntheoretically demonstrate the inherent connection between distribution shift,\ndata perturbation, and weight perturbation. Subsequently, we analyze the\nsufficient conditions to guarantee fairness (i.e., low demographic parity) for\nthe target dataset, including fairness for the source dataset, and low\nprediction difference between the source and target dataset for each sensitive\nattribute group. Motivated by these sufficient conditions, we propose robust\nfairness regularization (RFR) by considering the worst case within the weight\nperturbation ball for each sensitive attribute group. In this way, the\nmaximization problem can be simplified as two forward and two backward\npropagations for each update of model parameters. We evaluate the effectiveness\nof our proposed RFR algorithm on synthetic and real distribution shifts across\nvarious datasets. Experimental results demonstrate that RFR achieves better\nfairness-accuracy trade-off performance compared with several baselines.\n","authors":["Zhimeng Jiang","Xiaotian Han","Hongye Jin","Guanchu Wang","Na Zou","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2303.03300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13133v2","updated":"2023-03-06T17:18:03Z","published":"2023-01-30T18:16:16Z","title":"Falsification of Internal and External Validity in Observational Studies\n  via Conditional Moment Restrictions","summary":"  Randomized Controlled Trials (RCT)s are relied upon to assess new treatments,\nbut suffer from limited power to guide personalized treatment decisions. On the\nother hand, observational (i.e., non-experimental) studies have large and\ndiverse populations, but are prone to various biases (e.g. residual\nconfounding). To safely leverage the strengths of observational studies, we\nfocus on the problem of falsification, whereby RCTs are used to validate causal\neffect estimates learned from observational data. In particular, we show that,\ngiven data from both an RCT and an observational study, assumptions on internal\nand external validity have an observable, testable implication in the form of a\nset of Conditional Moment Restrictions (CMRs). Further, we show that expressing\nthese CMRs with respect to the causal effect, or \"causal contrast\", as opposed\nto individual counterfactual means, provides a more reliable falsification\ntest. In addition to giving guarantees on the asymptotic properties of our\ntest, we demonstrate superior power and type I error of our approach on\nsemi-synthetic and real world datasets. Our approach is interpretable, allowing\na practitioner to visualize which subgroups in the population lead to\nfalsification of an observational study.\n","authors":["Zeshan Hussain","Ming-Chieh Shih","Michael Oberst","Ilker Demirel","David Sontag"],"pdf_url":"https://arxiv.org/pdf/2301.13133v2.pdf","comment":"Artificial Intelligence and Statistics 2023"},{"id":"http://arxiv.org/abs/2303.03293v1","updated":"2023-03-06T17:09:48Z","published":"2023-03-06T17:09:48Z","title":"HiGeN: Hierarchical Multi-Resolution Graph Generative Networks","summary":"  In real world domains, most graphs naturally exhibit a hierarchical\nstructure. However, data-driven graph generation is yet to effectively capture\nsuch structures. To address this, we propose a novel approach that recursively\ngenerates community structures at multiple resolutions, with the generated\nstructures conforming to training data distribution at each level of the\nhierarchy. The graphs generation is designed as a sequence of coarse-to-fine\ngenerative models allowing for parallel generation of all sub-structures,\nresulting in a high degree of scalability. Furthermore, we model the output\ndistribution of edges with a more expressive multinomial distribution and\nderive a recursive factorization for this distribution, making it a suitable\nchoice for graph generative models. This allows for the generation of graphs\nwith integer-valued edge weights. Our method achieves state-of-the-art\nperformance in both accuracy and efficiency on multiple datasets.\n","authors":["Mahdi Karami","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2303.03293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03284v1","updated":"2023-03-06T16:59:14Z","published":"2023-03-06T16:59:14Z","title":"The Wasserstein Believer: Learning Belief Updates for Partially\n  Observable Environments through Reliable Latent Space Models","summary":"  Partially Observable Markov Decision Processes (POMDPs) are useful tools to\nmodel environments where the full state cannot be perceived by an agent. As\nsuch the agent needs to reason taking into account the past observations and\nactions. However, simply remembering the full history is generally intractable\ndue to the exponential growth in the history space. Keeping a probability\ndistribution that models the belief over what the true state is can be used as\na sufficient statistic of the history, but its computation requires access to\nthe model of the environment and is also intractable. Current state-of-the-art\nalgorithms use Recurrent Neural Networks (RNNs) to compress the\nobservation-action history aiming to learn a sufficient statistic, but they\nlack guarantees of success and can lead to suboptimal policies. To overcome\nthis, we propose the Wasserstein-Belief-Updater (WBU), an RL algorithm that\nlearns a latent model of the POMDP and an approximation of the belief update.\nOur approach comes with theoretical guarantees on the quality of our\napproximation ensuring that our outputted beliefs allow for learning the\noptimal value function.\n","authors":["Raphael Avalos","Florent Delgrange","Ann Nowé","Guillermo A. Pérez","Diederik M. Roijers"],"pdf_url":"https://arxiv.org/pdf/2303.03284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01704v2","updated":"2023-03-06T16:52:19Z","published":"2023-03-03T04:12:04Z","title":"Model Explanation Disparities as a Fairness Diagnostic","summary":"  In recent years, there has been a flurry of research focusing on the fairness\nof machine learning models, and in particular on quantifying and eliminating\nbias against protected subgroups. One line of work generalizes the notion of\nprotected subgroups beyond simple discrete classes by introducing the notion of\na \"rich subgroup\", and seeks to train models that are calibrated or equalize\nerror rates with respect to these richer subgroup classes. Largely\northogonally, local model explanation methods have been developed that given a\nclassifier h and test point x, attribute influence for the prediction h(x) to\nthe individual features of x. This raises a natural question: Do local model\nexplanation methods attribute different feature importance values on average\nacross different protected subgroups, and can we detect these disparities\nefficiently? If the model places high weight on a given feature in a specific\nprotected subgroup, but not on the dataset overall (or vice versa), this could\nbe a potential indicator of bias in the predictive model or the underlying data\ngenerating process, and is at the very least a useful diagnostic that signals\nthe need for a domain expert to delve deeper. In this paper, we formally\nintroduce the notion of feature importance disparity (FID) in the context of\nrich subgroups, design oracle-efficent algorithms to identify large FID\nsubgroups, and conduct a thorough empirical analysis that establishes auditing\nfor FID as an important method to investigate dataset bias. Our experiments\nshow that across 4 datasets and 4 common feature importance methods our\nalgorithms find (feature, subgroup) pairs that simultaneously: (i) have\nsubgroup feature importance that is often an order of magnitude different than\nthe importance on the dataset as a whole (ii) generalize out of sample, and\n(iii) yield interesting discussions about potential bias inherent in these\ndatasets.\n","authors":["Peter W. Chang","Leor Fishman","Seth Neel"],"pdf_url":"https://arxiv.org/pdf/2303.01704v2.pdf","comment":"13 pages, 6 figures. Appendix: 8 pages, 4 figures. Replacement info:\n  minor changes to match metadata abstract to paper abstract"},{"id":"http://arxiv.org/abs/2303.03278v1","updated":"2023-03-06T16:49:27Z","published":"2023-03-06T16:49:27Z","title":"Faithfulness-Aware Decoding Strategies for Abstractive Summarization","summary":"  Despite significant progress in understanding and improving faithfulness in\nabstractive summarization, the question of how decoding strategies affect\nfaithfulness is less studied. We present a systematic study of the effect of\ngeneration techniques such as beam search and nucleus sampling on faithfulness\nin abstractive summarization. We find a consistent trend where beam search with\nlarge beam sizes produces the most faithful summaries while nucleus sampling\ngenerates the least faithful ones. We propose two faithfulness-aware generation\nmethods to further improve faithfulness over current generation techniques: (1)\nranking candidates generated by beam search using automatic faithfulness\nmetrics and (2) incorporating lookahead heuristics that produce a faithfulness\nscore on the future summary. We show that both generation methods significantly\nimprove faithfulness across two datasets as evaluated by four automatic\nfaithfulness metrics and human evaluation. To reduce computational cost, we\ndemonstrate a simple distillation approach that allows the model to generate\nfaithful summaries with just greedy decoding. Our code is publicly available at\nhttps://github.com/amazon-science/faithful-summarization-generation\n","authors":["David Wan","Mengwen Liu","Kathleen McKeown","Markus Dreyer","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2303.03278v1.pdf","comment":"EACL 2023 (17 pages)"},{"id":"http://arxiv.org/abs/2303.03192v1","updated":"2023-03-06T16:47:59Z","published":"2023-03-06T16:47:59Z","title":"Deep symbolic regression for physics guided by units constraints: toward\n  the automated discovery of physical laws","summary":"  Symbolic Regression is the study of algorithms that automate the search for\nanalytic expressions that fit data. While recent advances in deep learning have\ngenerated renewed interest in such approaches, efforts have not been focused on\nphysics, where we have important additional constraints due to the units\nassociated with our data. Here we present $\\Phi$-SO, a Physical Symbolic\nOptimization framework for recovering analytical symbolic expressions from\nphysics data using deep reinforcement learning techniques by learning units\nconstraints. Our system is built, from the ground up, to propose solutions\nwhere the physical units are consistent by construction. This is useful not\nonly in eliminating physically impossible solutions, but because it restricts\nenormously the freedom of the equation generator, thus vastly improving\nperformance. The algorithm can be used to fit noiseless data, which can be\nuseful for instance when attempting to derive an analytical property of a\nphysical model, and it can also be used to obtain analytical approximations to\nnoisy data. We showcase our machinery on a panel of examples from astrophysics.\n","authors":["Wassim Tenachi","Rodrigo Ibata","Foivos I. Diakogiannis"],"pdf_url":"https://arxiv.org/pdf/2303.03192v1.pdf","comment":"16 pages, 6 figures, 2 tables. Submitted to ApJ"},{"id":"http://arxiv.org/abs/2303.03272v1","updated":"2023-03-06T16:41:57Z","published":"2023-03-06T16:41:57Z","title":"Accelerated Rates between Stochastic and Adversarial Online Convex\n  Optimization","summary":"  Stochastic and adversarial data are two widely studied settings in online\nlearning. But many optimization tasks are neither i.i.d. nor fully adversarial,\nwhich makes it of fundamental interest to get a better theoretical\nunderstanding of the world between these extremes. In this work we establish\nnovel regret bounds for online convex optimization in a setting that\ninterpolates between stochastic i.i.d. and fully adversarial losses. By\nexploiting smoothness of the expected losses, these bounds replace a dependence\non the maximum gradient length by the variance of the gradients, which was\npreviously known only for linear losses. In addition, they weaken the i.i.d.\nassumption by allowing, for example, adversarially poisoned rounds, which were\npreviously considered in the related expert and bandit settings. In the fully\ni.i.d. case, our regret bounds match the rates one would expect from results in\nstochastic acceleration, and we also recover the optimal stochastically\naccelerated rates via online-to-batch conversion. In the fully adversarial case\nour bounds gracefully deteriorate to match the minimax regret. We further\nprovide lower bounds showing that our regret upper bounds are tight for all\nintermediate regimes in terms of the stochastic variance and the adversarial\nvariation of the loss gradients.\n","authors":["Sarah Sachs","Hedi Hadiji","Tim van Erven","Cristobal Guzman"],"pdf_url":"https://arxiv.org/pdf/2303.03272v1.pdf","comment":"Extended version of 'Between Stochastic and Adversarial Online Convex\n  Optimization: Improved Regret Bounds via Smoothness' by the same authors.\n  arXiv admin note: text overlap with arXiv:2202.07554"},{"id":"http://arxiv.org/abs/2207.04154v4","updated":"2023-03-06T16:37:49Z","published":"2022-07-08T23:42:56Z","title":"TalkToModel: Explaining Machine Learning Models with Interactive Natural\n  Language Conversations","summary":"  Machine Learning (ML) models are increasingly used to make critical decisions\nin real-world applications, yet they have become more complex, making them\nharder to understand. To this end, researchers have proposed several techniques\nto explain model predictions. However, practitioners struggle to use these\nexplainability techniques because they often do not know which one to choose\nand how to interpret the results of the explanations. In this work, we address\nthese challenges by introducing TalkToModel: an interactive dialogue system for\nexplaining machine learning models through conversations. Specifically,\nTalkToModel comprises of three key components: 1) a natural language interface\nfor engaging in conversations, making ML model explainability highly\naccessible, 2) a dialogue engine that adapts to any tabular model and dataset,\ninterprets natural language, maps it to appropriate explanations, and generates\ntext responses, and 3) an execution component that constructs the explanations.\nWe carried out extensive quantitative and human subject evaluations of\nTalkToModel. Overall, we found the conversational system understands user\ninputs on novel datasets and models with high accuracy, demonstrating the\nsystem's capacity to generalize to new situations. In real-world evaluations\nwith humans, 73% of healthcare workers (e.g., doctors and nurses) agreed they\nwould use TalkToModel over baseline point-and-click systems for explainability\nin a disease prediction task, and 85% of ML professionals agreed TalkToModel\nwas easier to use for computing explanations. Our findings demonstrate that\nTalkToModel is more effective for model explainability than existing systems,\nintroducing a new category of explainability tools for practitioners. Code &\ndemo released here: https://github.com/dylan-slack/TalkToModel.\n","authors":["Dylan Slack","Satyapriya Krishna","Himabindu Lakkaraju","Sameer Singh"],"pdf_url":"https://arxiv.org/pdf/2207.04154v4.pdf","comment":"Pre-print; comments welcome! Reach out to dslack@uci.edu v3 update\n  title and abstract"},{"id":"http://arxiv.org/abs/2303.03254v1","updated":"2023-03-06T16:17:19Z","published":"2023-03-06T16:17:19Z","title":"An Online Algorithm for Chance Constrained Resource Allocation","summary":"  This paper studies the online stochastic resource allocation problem (RAP)\nwith chance constraints. The online RAP is a 0-1 integer linear programming\nproblem where the resource consumption coefficients are revealed column by\ncolumn along with the corresponding revenue coefficients. When a column is\nrevealed, the corresponding decision variables are determined instantaneously\nwithout future information. Moreover, in online applications, the resource\nconsumption coefficients are often obtained by prediction. To model their\nuncertainties, we take the chance constraints into the consideration. To the\nbest of our knowledge, this is the first time chance constraints are introduced\nin the online RAP problem. Assuming that the uncertain variables have known\nGaussian distributions, the stochastic RAP can be transformed into a\ndeterministic but nonlinear problem with integer second-order cone constraints.\nNext, we linearize this nonlinear problem and analyze the performance of\nvanilla online primal-dual algorithm for solving the linearized stochastic RAP.\nUnder mild technical assumptions, the optimality gap and constraint violation\nare both on the order of $\\sqrt{n}$. Then, to further improve the performance\nof the algorithm, several modified online primal-dual algorithms with heuristic\ncorrections are proposed. Finally, extensive numerical experiments on both\nsynthetic and real data demonstrate the applicability and effectiveness of our\nmethods.\n","authors":["Yuwei Chen","Zengde Deng","Yinzhi Zhou","Zaiyi Chen","Yujie Chen","Haoyuan Hu"],"pdf_url":"https://arxiv.org/pdf/2303.03254v1.pdf","comment":"5 pages, 5 figures. Accepted to ICASSP 2023. arXiv admin note:\n  substantial text overlap with arXiv:2203.16818"},{"id":"http://arxiv.org/abs/2206.02307v2","updated":"2023-03-06T16:08:39Z","published":"2022-06-06T01:30:03Z","title":"Bootstrapping Semi-supervised Medical Image Segmentation with\n  Anatomical-aware Contrastive Distillation","summary":"  Contrastive learning has shown great promise over annotation scarcity\nproblems in the context of medical image segmentation. Existing approaches\ntypically assume a balanced class distribution for both labeled and unlabeled\nmedical images. However, medical image data in reality is commonly imbalanced\n(i.e., multi-class label imbalance), which naturally yields blurry contours and\nusually incorrectly labels rare objects. Moreover, it remains unclear whether\nall negative samples are equally negative. In this work, we present ACTION, an\nAnatomical-aware ConTrastive dIstillatiON framework, for semi-supervised\nmedical image segmentation. Specifically, we first develop an iterative\ncontrastive distillation algorithm by softly labeling the negatives rather than\nbinary supervision between positive and negative pairs. We also capture more\nsemantically similar features from the randomly chosen negative set compared to\nthe positives to enforce the diversity of the sampled data. Second, we raise a\nmore important question: Can we really handle imbalanced samples to yield\nbetter performance? Hence, the key innovation in ACTION is to learn global\nsemantic relationship across the entire dataset and local anatomical features\namong the neighbouring pixels with minimal additional memory footprint. During\nthe training, we introduce anatomical contrast by actively sampling a sparse\nset of hard negative pixels, which can generate smoother segmentation\nboundaries and more accurate predictions. Extensive experiments across two\nbenchmark datasets and different unlabeled settings show that ACTION\nsignificantly outperforms the current state-of-the-art semi-supervised methods.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2206.02307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08529v2","updated":"2023-03-06T16:08:29Z","published":"2022-06-17T03:24:45Z","title":"Accelerating Shapley Explanation via Contributive Cooperator Selection","summary":"  Even though Shapley value provides an effective explanation for a DNN model\nprediction, the computation relies on the enumeration of all possible input\nfeature coalitions, which leads to the exponentially growing complexity. To\naddress this problem, we propose a novel method SHEAR to significantly\naccelerate the Shapley explanation for DNN models, where only a few coalitions\nof input features are involved in the computation. The selection of the feature\ncoalitions follows our proposed Shapley chain rule to minimize the absolute\nerror from the ground-truth Shapley values, such that the computation can be\nboth efficient and accurate. To demonstrate the effectiveness, we\ncomprehensively evaluate SHEAR across multiple metrics including the absolute\nerror from the ground-truth Shapley value, the faithfulness of the\nexplanations, and running speed. The experimental results indicate SHEAR\nconsistently outperforms state-of-the-art baseline methods across different\nevaluation metrics, which demonstrates its potentials in real-world\napplications where the computational resource is limited.\n","authors":["Guanchu Wang","Yu-Neng Chuang","Mengnan Du","Fan Yang","Quan Zhou","Pushkar Tripathi","Xuanting Cai","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2206.08529v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03242v1","updated":"2023-03-06T16:01:30Z","published":"2023-03-06T16:01:30Z","title":"Evaluating the Fairness of Deep Learning Uncertainty Estimates in\n  Medical Image Analysis","summary":"  Although deep learning (DL) models have shown great success in many medical\nimage analysis tasks, deployment of the resulting models into real clinical\ncontexts requires: (1) that they exhibit robustness and fairness across\ndifferent sub-populations, and (2) that the confidence in DL model predictions\nbe accurately expressed in the form of uncertainties. Unfortunately, recent\nstudies have indeed shown significant biases in DL models across demographic\nsubgroups (e.g., race, sex, age) in the context of medical image analysis,\nindicating a lack of fairness in the models. Although several methods have been\nproposed in the ML literature to mitigate a lack of fairness in DL models, they\nfocus entirely on the absolute performance between groups without considering\ntheir effect on uncertainty estimation. In this work, we present the first\nexploration of the effect of popular fairness models on overcoming biases\nacross subgroups in medical image analysis in terms of bottom-line performance,\nand their effects on uncertainty quantification. We perform extensive\nexperiments on three different clinically relevant tasks: (i) skin lesion\nclassification, (ii) brain tumour segmentation, and (iii) Alzheimer's disease\nclinical score regression. Our results indicate that popular ML methods, such\nas data-balancing and distributionally robust optimization, succeed in\nmitigating fairness issues in terms of the model performances for some of the\ntasks. However, this can come at the cost of poor uncertainty estimates\nassociated with the model predictions. This tradeoff must be mitigated if\nfairness models are to be adopted in medical image analysis.\n","authors":["Raghav Mehta","Changjian Shui","Tal Arbel"],"pdf_url":"https://arxiv.org/pdf/2303.03242v1.pdf","comment":"Paper accepted at MIDL 2023"},{"id":"http://arxiv.org/abs/2212.00424v2","updated":"2023-03-06T16:00:25Z","published":"2022-12-01T10:55:22Z","title":"Multi-Source Survival Domain Adaptation","summary":"  Survival analysis is the branch of statistics that studies the relation\nbetween the characteristics of living entities and their respective survival\ntimes, taking into account the partial information held by censored cases. A\ngood analysis can, for example, determine whether one medical treatment for a\ngroup of patients is better than another. With the rise of machine learning,\nsurvival analysis can be modeled as learning a function that maps studied\npatients to their survival times. To succeed with that, there are three crucial\nissues to be tackled. First, some patient data is censored: we do not know the\ntrue survival times for all patients. Second, data is scarce, which led past\nresearch to treat different illness types as domains in a multi-task setup.\nThird, there is the need for adaptation to new or extremely rare illness types,\nwhere little or no labels are available. In contrast to previous multi-task\nsetups, we want to investigate how to efficiently adapt to a new survival\ntarget domain from multiple survival source domains. For this, we introduce a\nnew survival metric and the corresponding discrepancy measure between survival\ndistributions. These allow us to define domain adaptation for survival analysis\nwhile incorporating censored data, which would otherwise have to be dropped.\nOur experiments on two cancer data sets reveal a superb performance on target\ndomains, a better treatment recommendation, and a weight matrix with a\nplausible explanation.\n","authors":["Ammar Shaker","Carolin Lawrence"],"pdf_url":"https://arxiv.org/pdf/2212.00424v2.pdf","comment":"37th AAAI Conference on Artificial Intelligence, 2023. Includes\n  Appendix"},{"id":"http://arxiv.org/abs/2303.03237v1","updated":"2023-03-06T15:53:44Z","published":"2023-03-06T15:53:44Z","title":"Convergence Rates for Non-Log-Concave Sampling and Log-Partition\n  Estimation","summary":"  Sampling from Gibbs distributions $p(x) \\propto \\exp(-V(x)/\\varepsilon)$ and\ncomputing their log-partition function are fundamental tasks in statistics,\nmachine learning, and statistical physics. However, while efficient algorithms\nare known for convex potentials $V$, the situation is much more difficult in\nthe non-convex case, where algorithms necessarily suffer from the curse of\ndimensionality in the worst case. For optimization, which can be seen as a\nlow-temperature limit of sampling, it is known that smooth functions $V$ allow\nfaster convergence rates. Specifically, for $m$-times differentiable functions\nin $d$ dimensions, the optimal rate for algorithms with $n$ function\nevaluations is known to be $O(n^{-m/d})$, where the constant can potentially\ndepend on $m, d$ and the function to be optimized. Hence, the curse of\ndimensionality can be alleviated for smooth functions at least in terms of the\nconvergence rate. Recently, it has been shown that similarly fast rates can\nalso be achieved with polynomial runtime $O(n^{3.5})$, where the exponent $3.5$\nis independent of $m$ or $d$. Hence, it is natural to ask whether similar rates\nfor sampling and log-partition computation are possible, and whether they can\nbe realized in polynomial time with an exponent independent of $m$ and $d$. We\nshow that the optimal rates for sampling and log-partition computation are\nsometimes equal and sometimes faster than for optimization. We then analyze\nvarious polynomial-time sampling algorithms, including an extension of a recent\npromising optimization approach, and find that they sometimes exhibit\ninteresting behavior but no near-optimal rates. Our results also give further\ninsights on the relation between sampling, log-partition, and optimization\nproblems.\n","authors":["David Holzmüller","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2303.03237v1.pdf","comment":"Plots can be reproduced using the code at\n  https://github.com/dholzmueller/sampling_experiments"},{"id":"http://arxiv.org/abs/2301.09604v2","updated":"2023-03-06T15:52:24Z","published":"2023-01-23T18:10:22Z","title":"FedExP: Speeding Up Federated Averaging via Extrapolation","summary":"  Federated Averaging (FedAvg) remains the most popular algorithm for Federated\nLearning (FL) optimization due to its simple implementation, stateless nature,\nand privacy guarantees combined with secure aggregation. Recent work has sought\nto generalize the vanilla averaging in FedAvg to a generalized gradient descent\nstep by treating client updates as pseudo-gradients and using a server step\nsize. While the use of a server step size has been shown to provide performance\nimprovement theoretically, the practical benefit of the server step size has\nnot been seen in most existing works. In this work, we present FedExP, a method\nto adaptively determine the server step size in FL based on dynamically varying\npseudo-gradients throughout the FL process. We begin by considering the\noverparameterized convex regime, where we reveal an interesting similarity\nbetween FedAvg and the Projection Onto Convex Sets (POCS) algorithm. We then\nshow how FedExP can be motivated as a novel extension to the extrapolation\nmechanism that is used to speed up POCS. Our theoretical analysis later also\ndiscusses the implications of FedExP in underparameterized and non-convex\nsettings. Experimental results show that FedExP consistently converges faster\nthan FedAvg and competing baselines on a range of realistic FL datasets.\n","authors":["Divyansh Jhunjhunwala","Shiqiang Wang","Gauri Joshi"],"pdf_url":"https://arxiv.org/pdf/2301.09604v2.pdf","comment":"Accepted to ICLR 2023. V2 fixes minor typos and cleans up proofs"},{"id":"http://arxiv.org/abs/2303.03227v1","updated":"2023-03-06T15:45:28Z","published":"2023-03-06T15:45:28Z","title":"Parallel Hybrid Networks: an interplay between quantum and classical\n  neural networks","summary":"  Quantum neural networks represent a new machine learning paradigm that has\nrecently attracted much attention due to its potential promise. Under certain\nconditions, these models approximate the distribution of their dataset with a\ntruncated Fourier series. The trigonometric nature of this fit could result in\nangle-embedded quantum neural networks struggling to fit the non-harmonic\nfeatures in a given dataset. Moreover, the interpretability of neural networks\nremains a challenge. In this work, we introduce a new, interpretable class of\nhybrid quantum neural networks that pass the inputs of the dataset in parallel\nto 1) a classical multi-layered perceptron and 2) a variational quantum\ncircuit, and then the outputs of the two are linearly combined. We observe that\nthe quantum neural network creates a smooth sinusoidal foundation base on the\ntraining set, and then the classical perceptrons fill the non-harmonic gaps in\nthe landscape. We demonstrate this claim on two synthetic datasets sampled from\nperiodic distributions with added protrusions as noise. The training results\nindicate that the parallel hybrid network architecture could improve the\nsolution optimality on periodic datasets with additional noise.\n","authors":["Mohammad Kordzanganeh","Daria Kosichkina","Alexey Melnikov"],"pdf_url":"https://arxiv.org/pdf/2303.03227v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.03226v1","updated":"2023-03-06T15:43:41Z","published":"2023-03-06T15:43:41Z","title":"Safe Reinforcement Learning via Probabilistic Logic Shields","summary":"  Safe Reinforcement learning (Safe RL) aims at learning optimal policies while\nstaying safe. A popular solution to Safe RL is shielding, which uses a logical\nsafety specification to prevent an RL agent from taking unsafe actions.\nHowever, traditional shielding techniques are difficult to integrate with\ncontinuous, end-to-end deep RL methods. To this end, we introduce Probabilistic\nLogic Policy Gradient (PLPG). PLPG is a model-based Safe RL technique that uses\nprobabilistic logic programming to model logical safety constraints as\ndifferentiable functions. Therefore, PLPG can be seamlessly applied to any\npolicy gradient algorithm while still providing the same convergence\nguarantees. In our experiments, we show that PLPG learns safer and more\nrewarding policies compared to other state-of-the-art shielding techniques.\n","authors":["Wen-Chi Yang","Giuseppe Marra","Gavin Rens","Luc De Raedt"],"pdf_url":"https://arxiv.org/pdf/2303.03226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14028v3","updated":"2023-03-06T15:37:40Z","published":"2022-11-25T11:02:33Z","title":"Automata Cascades: Expressivity and Sample Complexity","summary":"  Every automaton can be decomposed into a cascade of basic prime automata.\nThis is the Prime Decomposition Theorem by Krohn and Rhodes. Guided by this\ntheory, we propose automata cascades as a structured, modular, way to describe\nautomata as complex systems made of many components, each implementing a\nspecific functionality. Any automaton can serve as a component; using specific\ncomponents allows for a fine-grained control of the expressivity of the\nresulting class of automata; using prime automata as components implies\nspecific expressivity guarantees. Moreover, specifying automata as cascades\nallows for describing the sample complexity of automata in terms of their\ncomponents. We show that the sample complexity is linear in the number of\ncomponents and the maximum complexity of a single component, modulo logarithmic\nfactors. This opens to the possibility of learning automata representing large\ndynamical systems consisting of many parts interacting with each other. It is\nin sharp contrast with the established understanding of the sample complexity\nof automata, described in terms of the overall number of states and input\nletters, which implies that it is only possible to learn automata where the\nnumber of states is linear in the amount of data available. Instead our results\nshow that one can learn automata with a number of states that is exponential in\nthe amount of data available.\n","authors":["Alessandro Ronca","Nadezda Alexandrovna Knorozova","Giuseppe De Giacomo"],"pdf_url":"https://arxiv.org/pdf/2211.14028v3.pdf","comment":"Full version with appendix of a paper with the same title that\n  appears in the proceedings of AAAI 2023"},{"id":"http://arxiv.org/abs/2203.02928v2","updated":"2023-03-06T15:26:24Z","published":"2022-03-06T10:14:09Z","title":"Evaluation of Interpretability Methods and Perturbation Artifacts in\n  Deep Neural Networks","summary":"  Despite excellent performance of deep neural networks (DNNs) in image\nclassification, detection, and prediction, characterizing how DNNs make a given\ndecision remains an open problem, resulting in a number of interpretability\nmethods. Post-hoc interpretability methods primarily aim to quantify the\nimportance of input features with respect to the class probabilities. However,\ndue to the lack of ground truth and the existence of interpretability methods\nwith diverse operating characteristics, evaluating these methods is a crucial\nchallenge. A popular approach to evaluate interpretability methods is to\nperturb input features deemed important for a given prediction and observe the\ndecrease in accuracy. However, perturbation itself may introduce artifacts,\nsince perturbed images may be out-of-distribution (OOD). In this paper, we have\nconducted computational experiments to estimate the contribution of\nperturbation artifacts and developed a method to estimate the fidelity of\ninterpretability methods. We demonstrate that, while perturbation artifacts\nindeed exist, we can minimize and characterize their impact on fidelity\nestimation by utilizing model accuracy curves from perturbing input features\naccording to the Most Import First (MIF) and Least Import First (LIF) orders.\nUsing the ResNet-50 trained on the ImageNet, we demonstrate the proposed\nfidelity estimation of four popular post-hoc interpretability methods.\n","authors":["Lennart Brocki","Neo Christopher Chung"],"pdf_url":"https://arxiv.org/pdf/2203.02928v2.pdf","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2302.05698v2","updated":"2023-03-06T15:24:56Z","published":"2023-02-11T14:02:08Z","title":"Compositional Exemplars for In-context Learning","summary":"  Large pretrained language models (LMs) have shown impressive In-Context\nLearning (ICL) ability, where the model learns to do an unseen task via a\nprompt consisting of input-output examples as the demonstration, without any\nparameter updates. The performance of ICL is highly dominated by the quality of\nthe selected in-context examples. However, previous selection methods are\nmostly based on simple heuristics, leading to sub-optimal performance. In this\nwork, we formulate in-context example selection as a subset selection problem.\nWe propose CEIL (Compositional Exemplars for In-context Learning), which is\ninstantiated by Determinantal Point Processes (DPPs) to model the interaction\nbetween the given input and in-context examples, and optimized through a\ncarefully-designed contrastive learning objective to obtain preference from\nLMs. We validate CEIL on 12 classification and generation datasets from 7\ndistinct NLP tasks, including sentiment analysis, paraphrase detection, natural\nlanguage inference, commonsense reasoning, open-domain question answering, code\ngeneration, and semantic parsing. Extensive experiments demonstrate not only\nthe state-of-the-art performance but also the transferability and\ncompositionality of CEIL, shedding new light on effective and efficient\nin-context learning. Our code is released at\nhttps://github.com/HKUNLP/icl-ceil.\n","authors":["Jiacheng Ye","Zhiyong Wu","Jiangtao Feng","Tao Yu","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2302.05698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13924v2","updated":"2023-03-06T15:24:28Z","published":"2022-05-27T12:04:07Z","title":"Lifting the Information Ratio: An Information-Theoretic Analysis of\n  Thompson Sampling for Contextual Bandits","summary":"  We study the Bayesian regret of the renowned Thompson Sampling algorithm in\ncontextual bandits with binary losses and adversarially-selected contexts. We\nadapt the information-theoretic perspective of \\cite{RvR16} to the contextual\nsetting by considering a lifted version of the information ratio defined in\nterms of the unknown model parameter instead of the optimal action or optimal\npolicy as done in previous works on the same setting. This allows us to bound\nthe regret in terms of the entropy of the prior distribution through a\nremarkably simple proof, and with no structural assumptions on the likelihood\nor the prior. The extension to priors with infinite entropy only requires a\nLipschitz assumption on the log-likelihood. An interesting special case is that\nof logistic bandits with $d$-dimensional parameters, $K$ actions, and Lipschitz\nlogits, for which we provide a $\\widetilde{O}(\\sqrt{dKT})$ regret upper-bound\nthat does not depend on the smallest slope of the sigmoid link function.\n","authors":["Gergely Neu","Julia Olkhovskaya","Matteo Papini","Ludovic Schwartz"],"pdf_url":"https://arxiv.org/pdf/2205.13924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.07340v2","updated":"2023-03-06T15:09:17Z","published":"2021-09-15T14:52:44Z","title":"Distribution-free Contextual Dynamic Pricing","summary":"  Contextual dynamic pricing aims to set personalized prices based on\nsequential interactions with customers. At each time period, a customer who is\ninterested in purchasing a product comes to the platform. The customer's\nvaluation for the product is a linear function of contexts, including product\nand customer features, plus some random market noise. The seller does not\nobserve the customer's true valuation, but instead needs to learn the valuation\nby leveraging contextual information and historical binary purchase feedbacks.\nExisting models typically assume full or partial knowledge of the random noise\ndistribution. In this paper, we consider contextual dynamic pricing with\nunknown random noise in the valuation model. Our distribution-free pricing\npolicy learns both the contextual function and the market noise simultaneously.\nA key ingredient of our method is a novel perturbed linear bandit framework,\nwhere a modified linear upper confidence bound algorithm is proposed to balance\nthe exploration of market noise and the exploitation of the current knowledge\nfor better pricing. We establish the regret upper bound and a matching lower\nbound of our policy in the perturbed linear bandit framework and prove a\nsub-linear regret bound in the considered pricing problem. Finally, we\ndemonstrate the superior performance of our policy on simulations and a\nreal-life auto-loan dataset.\n","authors":["Yiyun Luo","Will Wei Sun","and Yufeng Liu"],"pdf_url":"https://arxiv.org/pdf/2109.07340v2.pdf","comment":"Accepted by Mathematics of Operations Research"},{"id":"http://arxiv.org/abs/2201.12733v4","updated":"2023-03-06T14:58:48Z","published":"2022-01-30T05:41:50Z","title":"TPC: Transformation-Specific Smoothing for Point Cloud Models","summary":"  Point cloud models with neural network architectures have achieved great\nsuccess and have been widely used in safety-critical applications, such as\nLidar-based recognition systems in autonomous vehicles. However, such models\nare shown vulnerable to adversarial attacks which aim to apply stealthy\nsemantic transformations such as rotation and tapering to mislead model\npredictions. In this paper, we propose a transformation-specific smoothing\nframework TPC, which provides tight and scalable robustness guarantees for\npoint cloud models against semantic transformation attacks. We first categorize\ncommon 3D transformations into three categories: additive (e.g., shearing),\ncomposable (e.g., rotation), and indirectly composable (e.g., tapering), and we\npresent generic robustness certification strategies for all categories\nrespectively. We then specify unique certification protocols for a range of\nspecific semantic transformations and their compositions. Extensive experiments\non several common 3D transformations show that TPC significantly outperforms\nthe state of the art. For example, our framework boosts the certified accuracy\nagainst twisting transformation along z-axis (within 20$^\\circ$) from 20.3$\\%$\nto 83.8$\\%$. Codes and models are available at\nhttps://github.com/Qianhewu/Point-Cloud-Smoothing.\n","authors":["Wenda Chu","Linyi Li","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2201.12733v4.pdf","comment":"Accepted as a conference paper at ICML 2022"},{"id":"http://arxiv.org/abs/2208.08221v2","updated":"2023-03-06T14:51:07Z","published":"2022-08-17T11:06:44Z","title":"Which Factors are associated with Open Access Publishing? A Springer\n  Nature Case Study","summary":"  Open Access (OA) facilitates access to articles. But, authors or funders\noften must pay the publishing costs preventing authors who do not receive\nfinancial support from participating in OA publishing and citation advantage\nfor OA articles. OA may exacerbate existing inequalities in the publication\nsystem rather than overcome them. To investigate this, we studied 522,411\narticles published by Springer Nature. Employing correlation and regression\nanalyses, we describe the relationship between authors affiliated with\ncountries from different income levels, their choice of publishing model, and\nthe citation impact of their papers. A machine learning classification method\nhelped us to explore the importance of different features in predicting the\npublishing model. The results show that authors eligible for APC waivers\npublish more in gold-OA journals than others. In contrast, authors eligible for\nan APC discount have the lowest ratio of OA publications, leading to the\nassumption that this discount insufficiently motivates authors to publish in\ngold-OA journals. We found a strong correlation between the journal rank and\nthe publishing model in gold-OA journals, whereas the OA option is mostly\navoided in hybrid journals. Also, results show that the countries' income\nlevel, seniority, and experience with OA publications are the most predictive\nfactors for OA publishing in hybrid journals.\n","authors":["Fakhri Momeni","Stefan Dietze","Philipp Mayr","Kristin Biesenbender","Isabella Peters"],"pdf_url":"https://arxiv.org/pdf/2208.08221v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.09108v4","updated":"2023-03-06T14:50:44Z","published":"2021-03-16T14:42:01Z","title":"Is it enough to optimize CNN architectures on ImageNet?","summary":"  Classification performance based on ImageNet is the de-facto standard metric\nfor CNN development. In this work we challenge the notion that CNN architecture\ndesign solely based on ImageNet leads to generally effective convolutional\nneural network (CNN) architectures that perform well on a diverse set of\ndatasets and application domains. To this end, we investigate and ultimately\nimprove ImageNet as a basis for deriving such architectures. We conduct an\nextensive empirical study for which we train $500$ CNN architectures, sampled\nfrom the broad AnyNetX design space, on ImageNet as well as $8$ additional well\nknown image classification benchmark datasets from a diverse array of\napplication domains. We observe that the performances of the architectures are\nhighly dataset dependent. Some datasets even exhibit a negative error\ncorrelation with ImageNet across all architectures. We show how to\nsignificantly increase these correlations by utilizing ImageNet subsets\nrestricted to fewer classes. These contributions can have a profound impact on\nthe way we design future CNN architectures and help alleviate the tilt we see\ncurrently in our community with respect to over-reliance on one dataset.\n","authors":["Lukas Tuggener","Jürgen Schmidhuber","Thilo Stadelmann"],"pdf_url":"https://arxiv.org/pdf/2103.09108v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03187v1","updated":"2023-03-06T14:49:59Z","published":"2023-03-06T14:49:59Z","title":"Boosting Differentiable Causal Discovery via Adaptive Sample Reweighting","summary":"  Under stringent model type and variable distribution assumptions,\ndifferentiable score-based causal discovery methods learn a directed acyclic\ngraph (DAG) from observational data by evaluating candidate graphs over an\naverage score function. Despite great success in low-dimensional linear\nsystems, it has been observed that these approaches overly exploit\neasier-to-fit samples, thus inevitably learning spurious edges. Worse still,\ninherent mostly in these methods the common homogeneity assumption can be\neasily violated, due to the widespread existence of heterogeneous data in the\nreal world, resulting in performance vulnerability when noise distributions\nvary. We propose a simple yet effective model-agnostic framework to boost\ncausal discovery performance by dynamically learning the adaptive weights for\nthe Reweighted Score function, ReScore for short, where the weights tailor\nquantitatively to the importance degree of each sample. Intuitively, we\nleverage the bilevel optimization scheme to \\wx{alternately train a standard\nDAG learner and reweight samples -- that is, upweight the samples the learner\nfails to fit and downweight the samples that the learner easily extracts the\nspurious information from. Extensive experiments on both synthetic and\nreal-world datasets are carried out to validate the effectiveness of ReScore.\nWe observe consistent and significant boosts in structure learning performance.\nFurthermore, we visualize that ReScore concurrently mitigates the influence of\nspurious edges and generalizes to heterogeneous data. Finally, we perform the\ntheoretical analysis to guarantee the structure identifiability and the weight\nadaptive properties of ReScore in linear systems. Our codes are available at\nhttps://github.com/anzhang314/ReScore.\n","authors":["An Zhang","Fangfu Liu","Wenchang Ma","Zhibo Cai","Xiang Wang","Tat-seng Chua"],"pdf_url":"https://arxiv.org/pdf/2303.03187v1.pdf","comment":"In proceedings of ICLR 2023"},{"id":"http://arxiv.org/abs/2110.11216v5","updated":"2023-03-06T14:49:13Z","published":"2021-10-21T15:50:05Z","title":"User-friendly introduction to PAC-Bayes bounds","summary":"  Aggregated predictors are obtained by making a set of basic predictors vote\naccording to some weights, that is, to some probability distribution.\n  Randomized predictors are obtained by sampling in a set of basic predictors,\naccording to some prescribed probability distribution.\n  Thus, aggregated and randomized predictors have in common that they are not\ndefined by a minimization problem, but by a probability distribution on the set\nof predictors. In statistical learning theory, there is a set of tools designed\nto understand the generalization ability of such procedures: PAC-Bayesian or\nPAC-Bayes bounds.\n  Since the original PAC-Bayes bounds of D. McAllester, these tools have been\nconsiderably improved in many directions (we will for example describe a\nsimplified version of the localization technique of O. Catoni that was missed\nby the community, and later rediscovered as \"mutual information bounds\"). Very\nrecently, PAC-Bayes bounds received a considerable attention: for example there\nwas workshop on PAC-Bayes at NIPS 2017, \"(Almost) 50 Shades of Bayesian\nLearning: PAC-Bayesian trends and insights\", organized by B. Guedj, F. Bach and\nP. Germain. One of the reason of this recent success is the successful\napplication of these bounds to neural networks by G. Dziugaite and D. Roy.\n  An elementary introduction to PAC-Bayes theory is still missing. This is an\nattempt to provide such an introduction.\n","authors":["Pierre Alquier"],"pdf_url":"https://arxiv.org/pdf/2110.11216v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03181v1","updated":"2023-03-06T14:48:30Z","published":"2023-03-06T14:48:30Z","title":"MetaPhysiCa: OOD Robustness in Physics-informed Machine Learning","summary":"  A fundamental challenge in physics-informed machine learning (PIML) is the\ndesign of robust PIML methods for out-of-distribution (OOD) forecasting tasks.\nThese OOD tasks require learning-to-learn from observations of the same (ODE)\ndynamical system with different unknown ODE parameters, and demand accurate\nforecasts even under out-of-support initial conditions and out-of-support ODE\nparameters. In this work we propose a solution for such tasks, which we define\nas a meta-learning procedure for causal structure discovery (including\ninvariant risk minimization). Using three different OOD tasks, we empirically\nobserve that the proposed approach significantly outperforms existing\nstate-of-the-art PIML and deep learning methods.\n","authors":["S Chandra Mouli","Muhammad Ashraful Alam","Bruno Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2303.03181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13941v2","updated":"2023-03-06T14:44:40Z","published":"2023-02-27T16:45:04Z","title":"A Reinforcement Learning Approach for Scheduling Problems With Improved\n  Generalization Through Order Swapping","summary":"  The scheduling of production resources (such as associating jobs to machines)\nplays a vital role for the manufacturing industry not only for saving energy\nbut also for increasing the overall efficiency. Among the different job\nscheduling problems, the JSSP is addressed in this work. JSSP falls into the\ncategory of NP-hard COP, in which solving the problem through exhaustive search\nbecomes unfeasible. Simple heuristics such as FIFO, LPT and metaheuristics such\nas Taboo search are often adopted to solve the problem by truncating the search\nspace. The viability of the methods becomes inefficient for large problem sizes\nas it is either far from the optimum or time consuming. In recent years, the\nresearch towards using DRL to solve COP has gained interest and has shown\npromising results in terms of solution quality and computational efficiency. In\nthis work, we provide an novel approach to solve the JSSP examining the\nobjectives generalization and solution effectiveness using DRL. In particular,\nwe employ the PPO algorithm that adopts the policy-gradient paradigm that is\nfound to perform well in the constrained dispatching of jobs. We incorporated\nan OSM in the environment to achieve better generalized learning of the\nproblem. The performance of the presented approach is analyzed in depth by\nusing a set of available benchmark instances and comparing our results with the\nwork of other groups.\n","authors":["Deepak Vivekanandan","Samuel Wirth","Patrick Karlbauer","Noah Klarmann"],"pdf_url":"https://arxiv.org/pdf/2302.13941v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03169v1","updated":"2023-03-06T14:31:09Z","published":"2023-03-06T14:31:09Z","title":"A Unified Algebraic Perspective on Lipschitz Neural Networks","summary":"  Important research efforts have focused on the design and training of neural\nnetworks with a controlled Lipschitz constant. The goal is to increase and\nsometimes guarantee the robustness against adversarial attacks. Recent\npromising techniques draw inspirations from different backgrounds to design\n1-Lipschitz neural networks, just to name a few: convex potential layers derive\nfrom the discretization of continuous dynamical systems,\nAlmost-Orthogonal-Layer proposes a tailored method for matrix rescaling.\nHowever, it is today important to consider the recent and promising\ncontributions in the field under a common theoretical lens to better design new\nand improved layers. This paper introduces a novel algebraic perspective\nunifying various types of 1-Lipschitz neural networks, including the ones\npreviously mentioned, along with methods based on orthogonality and spectral\nmethods. Interestingly, we show that many existing techniques can be derived\nand generalized via finding analytical solutions of a common semidefinite\nprogramming (SDP) condition. We also prove that AOL biases the scaled weight to\nthe ones which are close to the set of orthogonal matrices in a certain\nmathematical manner. Moreover, our algebraic condition, combined with the\nGershgorin circle theorem, readily leads to new and diverse parameterizations\nfor 1-Lipschitz network layers. Our approach, called SDP-based Lipschitz Layers\n(SLL), allows us to design non-trivial yet efficient generalization of convex\npotential layers. Finally, the comprehensive set of experiments on image\nclassification shows that SLLs outperform previous approaches on certified\nrobust accuracy. Code is available at\nhttps://github.com/araujoalexandre/Lipschitz-SLL-Networks.\n","authors":["Alexandre Araujo","Aaron Havens","Blaise Delattre","Alexandre Allauzen","Bin Hu"],"pdf_url":"https://arxiv.org/pdf/2303.03169v1.pdf","comment":"ICLR 2023. Spotlight paper"},{"id":"http://arxiv.org/abs/2303.03157v1","updated":"2023-03-06T14:21:42Z","published":"2023-03-06T14:21:42Z","title":"Data-Driven Control with Inherent Lyapunov Stability","summary":"  Recent advances in learning-based control leverage deep function\napproximators, such as neural networks, to model the evolution of controlled\ndynamical systems over time. However, the problem of learning a dynamics model\nand a stabilizing controller persists, since the synthesis of a stabilizing\nfeedback law for known nonlinear systems is a difficult task, let alone for\ncomplex parametric representations that must be fit to data. To this end, we\npropose a method for jointly learning parametric representations of a nonlinear\ndynamics model and a stabilizing controller from data. To do this, our approach\nsimultaneously learns a parametric Lyapunov function which intrinsically\nconstrains the dynamics model to be stabilizable by the learned controller. In\naddition to the stabilizability of the learned dynamics guaranteed by our novel\nconstruction, we show that the learned controller stabilizes the true dynamics\nunder certain assumptions on the fidelity of the learned dynamics. Finally, we\ndemonstrate the efficacy of our method on a variety of simulated nonlinear\ndynamical systems.\n","authors":["Youngjae Min","Spencer M. Richards","Navid Azizan"],"pdf_url":"https://arxiv.org/pdf/2303.03157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12108v2","updated":"2023-03-06T13:59:42Z","published":"2022-10-21T17:04:17Z","title":"Adversarial Permutation Invariant Training for Universal Sound\n  Separation","summary":"  Universal sound separation consists of separating mixes with arbitrary sounds\nof different types, and permutation invariant training (PIT) is used to train\nsource agnostic models that do so. In this work, we complement PIT with\nadversarial losses but find it challenging with the standard formulation used\nin speech source separation. We overcome this challenge with a novel\nI-replacement context-based adversarial loss, and by training with multiple\ndiscriminators. Our experiments show that by simply improving the loss (keeping\nthe same model and dataset) we obtain a non-negligible improvement of 1.4 dB\nSI-SNRi in the reverberant FUSS dataset. We also find adversarial PIT to be\neffective at reducing spectral holes, ubiquitous in mask-based separation\nmodels, which highlights the potential relevance of adversarial losses for\nsource separation.\n","authors":["Emilian Postolache","Jordi Pons","Santiago Pascual","Joan Serrà"],"pdf_url":"https://arxiv.org/pdf/2210.12108v2.pdf","comment":"Demo page: http://jordipons.me/apps/adversarialPIT/, Accepted at\n  ICASSP-23"},{"id":"http://arxiv.org/abs/2303.03132v1","updated":"2023-03-06T13:49:41Z","published":"2023-03-06T13:49:41Z","title":"SC-Block: Supervised Contrastive Blocking within Entity Resolution\n  Pipelines","summary":"  The goal of entity resolution is to identify records in multiple datasets\nthat represent the same real-world entity. However, comparing all records\nacross datasets can be computationally intensive, leading to long runtimes. To\nreduce these runtimes, entity resolution pipelines are constructed of two\nparts: a blocker that applies a computationally cheap method to select\ncandidate record pairs, and a matcher that afterwards identifies matching pairs\nfrom this set using more expensive methods. This paper presents SC-Block, a\nblocking method that utilizes supervised contrastive learning for positioning\nrecords in the embedding space, and nearest neighbour search for candidate set\nbuilding. We benchmark SC-Block against eight state-of-the-art blocking\nmethods. In order to relate the training time of SC-Block to the reduction of\nthe overall runtime of the entity resolution pipeline, we combine SC-Block with\nfour matching methods into complete pipelines. For measuring the overall\nruntime, we determine candidate sets with 98% pair completeness and pass them\nto the matcher. The results show that SC-Block is able to create smaller\ncandidate sets and pipelines with SC-Block execute 1.5 to 2 times faster\ncompared to pipelines with other blockers, without sacrificing F1 score.\nBlockers are often evaluated using relatively small datasets which might lead\nto runtime effects resulting from a large vocabulary size being overlooked. In\norder to measure runtimes in a more challenging setting, we introduce a new\nbenchmark dataset that requires large numbers of product offers to be blocked.\nOn this large-scale benchmark dataset, pipelines utilizing SC-Block and the\nbest-performing matcher execute 8 times faster than pipelines utilizing another\nblocker with the same matcher reducing the runtime from 2.5 hours to 18\nminutes, clearly compensating for the 5 minutes required for training SC-Block.\n","authors":["Alexander Brinkmann","Roee Shraga","Christian Bizer"],"pdf_url":"https://arxiv.org/pdf/2303.03132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2001.05670v4","updated":"2023-03-06T13:42:11Z","published":"2020-01-16T06:27:50Z","title":"Optimization of Convolutional Neural Network Using the Linearly\n  Decreasing Weight Particle Swarm Optimization","summary":"  Convolutional neural network (CNN) is one of the most frequently used deep\nlearning techniques. Various forms of models have been proposed and im-proved\nfor learning at CNN. When learning with CNN, it is necessary to determine the\noptimal hyperparameters. However, the number of hyperparameters is so large\nthat it is difficult to do it manually, so much research has been done on\nautomation. A method that uses metaheuristic algorithms is attracting attention\nin research on hyperparameter optimization. Metaheuristic algorithms are\nnaturally inspired and include evolution strategies, genetic algorithms,\nantcolony optimization and particle swarm optimization. In particular, particle\nswarm optimization converges faster than genetic algorithms, and various models\nhave been proposed. In this paper, we pro-pose CNN hyperparameter optimization\nwith linearly decreasing weight particle swarm optimization (LDWPSO). In the\nexperiment, the MNIST data set and CIFAR-10 data set, which are often used as\nbenchmark data sets, are used. By opti-mizing CNN hyperparameters with LDWPSO,\nlearning the MNIST and CIFAR-10 datasets, we compare the accuracy with a\nstandard CNN based on LeNet-5. As a result, when using the MNIST dataset, the\nbaseline CNN is 94.02% at the 5th epoch, compared to 98.95% for LDWPSO CNN,\nwhich improves accuracy. When using the CIFAR-10 dataset, the Baseline CNN is\n28.07% at the 10th epoch, compared to 69.37% for the LDWPSO CNN, which greatly\nimproves accuracy. This paper is presented at the 36th Annual Conference of the\nJapanese Society for Artificial In-telligence. The final version is available\nat the following URL: https://doi.org/10.11517/pjsai.JSAI2022.0_2S4IS2b03\n","authors":["T. Serizawa","H. Fujita"],"pdf_url":"https://arxiv.org/pdf/2001.05670v4.pdf","comment":"This paper is presented at the 36th Annual Conference of the Japanese\n  Society for Artificial In-telligence"},{"id":"http://arxiv.org/abs/2106.03056v3","updated":"2023-03-06T13:39:15Z","published":"2021-06-06T07:39:01Z","title":"MURANA: A Generic Framework for Stochastic Variance-Reduced Optimization","summary":"  We propose a generic variance-reduced algorithm, which we call MUltiple\nRANdomized Algorithm (MURANA), for minimizing a sum of several smooth functions\nplus a regularizer, in a sequential or distributed manner. Our method is\nformulated with general stochastic operators, which allow us to model various\nstrategies for reducing the computational complexity. For example, MURANA\nsupports sparse activation of the gradients, and also reduction of the\ncommunication load via compression of the update vectors. This versatility\nallows MURANA to cover many existing randomization mechanisms within a unified\nframework, which also makes it possible to design new methods as special cases.\n","authors":["Laurent Condat","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2106.03056v3.pdf","comment":"3rd Annual Conference on Mathematical and Scientific Machine Learning\n  (MSML), Aug. 2022. PMLR 190:81-96"},{"id":"http://arxiv.org/abs/2302.10248v2","updated":"2023-03-06T13:38:57Z","published":"2023-02-20T19:27:14Z","title":"VoxSRC 2022: The Fourth VoxCeleb Speaker Recognition Challenge","summary":"  This paper summarises the findings from the VoxCeleb Speaker Recognition\nChallenge 2022 (VoxSRC-22), which was held in conjunction with INTERSPEECH\n2022. The goal of this challenge was to evaluate how well state-of-the-art\nspeaker recognition systems can diarise and recognise speakers from speech\nobtained \"in the wild\". The challenge consisted of: (i) the provision of\npublicly available speaker recognition and diarisation data from YouTube videos\ntogether with ground truth annotation and standardised evaluation software; and\n(ii) a public challenge and hybrid workshop held at INTERSPEECH 2022. We\ndescribe the four tracks of our challenge along with the baselines, methods,\nand results. We conclude with a discussion on the new domain-transfer focus of\nVoxSRC-22, and on the progression of the challenge from the previous three\neditions.\n","authors":["Jaesung Huh","Andrew Brown","Jee-weon Jung","Joon Son Chung","Arsha Nagrani","Daniel Garcia-Romero","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2302.10248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.14527v5","updated":"2023-03-06T13:19:14Z","published":"2021-04-29T17:45:27Z","title":"Online certification of preference-based fairness for personalized\n  recommender systems","summary":"  Recommender systems are facing scrutiny because of their growing impact on\nthe opportunities we have access to. Current audits for fairness are limited to\ncoarse-grained parity assessments at the level of sensitive groups. We propose\nto audit for envy-freeness, a more granular criterion aligned with individual\npreferences: every user should prefer their recommendations to those of other\nusers. Since auditing for envy requires to estimate the preferences of users\nbeyond their existing recommendations, we cast the audit as a new pure\nexploration problem in multi-armed bandits. We propose a sample-efficient\nalgorithm with theoretical guarantees that it does not deteriorate user\nexperience. We also study the trade-offs achieved on real-world recommendation\ndatasets.\n","authors":["Virginie Do","Sam Corbett-Davies","Jamal Atif","Nicolas Usunier"],"pdf_url":"https://arxiv.org/pdf/2104.14527v5.pdf","comment":"AAAI 2022"},{"id":"http://arxiv.org/abs/2303.03094v1","updated":"2023-03-06T13:12:43Z","published":"2023-03-06T13:12:43Z","title":"Benchmark of Data Preprocessing Methods for Imbalanced Classification","summary":"  Severe class imbalance is one of the main conditions that make machine\nlearning in cybersecurity difficult. A variety of dataset preprocessing methods\nhave been introduced over the years. These methods modify the training dataset\nby oversampling, undersampling or a combination of both to improve the\npredictive performance of classifiers trained on this dataset. Although these\nmethods are used in cybersecurity occasionally, a comprehensive, unbiased\nbenchmark comparing their performance over a variety of cybersecurity problems\nis missing. This paper presents a benchmark of 16 preprocessing methods on six\ncybersecurity datasets together with 17 public imbalanced datasets from other\ndomains. We test the methods under multiple hyperparameter configurations and\nuse an AutoML system to train classifiers on the preprocessed datasets, which\nreduces potential bias from specific hyperparameter or classifier choices.\nSpecial consideration is also given to evaluating the methods using appropriate\nperformance measures that are good proxies for practical performance in\nreal-world cybersecurity systems. The main findings of our study are: 1) Most\nof the time, a data preprocessing method that improves classification\nperformance exists. 2) Baseline approach of doing nothing outperformed a large\nportion of methods in the benchmark. 3) Oversampling methods generally\noutperform undersampling methods. 4) The most significant performance gains are\nbrought by the standard SMOTE algorithm and more complicated methods provide\nmainly incremental improvements at the cost of often worse computational\nperformance.\n","authors":["Radovan Haluška","Jan Brabec","Tomáš Komárek"],"pdf_url":"https://arxiv.org/pdf/2303.03094v1.pdf","comment":"Published at 2022 IEEE International Conference on Big Data (Big\n  Data) 2022. Extended version with full results in appendix"},{"id":"http://arxiv.org/abs/2303.03092v1","updated":"2023-03-06T13:10:54Z","published":"2023-03-06T13:10:54Z","title":"Environment Invariant Linear Least Squares","summary":"  This paper considers a multiple environments linear regression model in which\ndata from multiple experimental settings are collected. The joint distribution\nof the response variable and covariate may vary across different environments,\nyet the conditional expectation of $y$ given the unknown set of important\nvariables are invariant across environments. Such a statistical model is\nrelated to the problem of endogeneity, causal inference, and transfer learning.\nThe motivation behind it is illustrated by how the goals of prediction and\nattribution are inherent in estimating the true parameter and the important\nvariable set. We construct a novel {\\it environment invariant linear least\nsquares (EILLS)} objective function, a multiple-environment version of linear\nleast squares that leverages the above conditional expectation invariance\nstructure and heterogeneity among different environments to determine the true\nparameter. Our proposed method is applicable without any additional structural\nknowledge and can identify the true parameter under a near-minimal\nidentification condition. We establish non-asymptotic $\\ell_2$ error bounds on\nthe estimation error for the EILLS estimator in the presence of spurious\nvariables. Moreover, we further show that the EILLS estimator is able to\neliminate all endogenous variables and the $\\ell_0$ penalized EILLS estimator\ncan achieve variable selection consistency in high-dimensional regimes. These\nnon-asymptotic results demonstrate the sample efficiency of the EILLS estimator\nand its capability to circumvent the curse of endogeneity in an algorithmic\nmanner without any prior structural knowledge.\n","authors":["Jianqing Fan","Cong Fang","Yihong Gu","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.03092v1.pdf","comment":"65 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.03084v1","updated":"2023-03-06T12:55:38Z","published":"2023-03-06T12:55:38Z","title":"On Regression in Extreme Regions","summary":"  In the classic regression problem, the value of a real-valued random variable\n$Y$ is to be predicted based on the observation of a random vector $X$, taking\nits values in $\\mathbb{R}^d$ with $d\\geq 1$ say. The statistical learning\nproblem consists in building a predictive function $\\hat{f}:\\mathbb{R}^d\\to\n\\mathbb{R}$ based on independent copies of the pair $(X,Y)$ so that $Y$ is\napproximated by $\\hat{f}(X)$ with minimum error in the mean-squared sense.\nMotivated by various applications, ranging from environmental sciences to\nfinance or insurance, special attention is paid here to the case of extreme\n(i.e. very large) observations $X$. Because of their rarity, they contribute in\na negligible manner to the (empirical) error and the predictive performance of\nempirical quadratic risk minimizers can be consequently very poor in extreme\nregions. In this paper, we develop a general framework for regression in the\nextremes. It is assumed that $X$'s conditional distribution given $Y$ belongs\nto a non parametric class of heavy-tailed probability distributions. It is then\nshown that an asymptotic notion of risk can be tailored to summarize\nappropriately predictive performance in extreme regions of the input space. It\nis also proved that minimization of an empirical and non asymptotic version of\nthis 'extreme risk', based on a fraction of the largest observations solely,\nyields regression functions with good generalization capacity. In addition,\nnumerical results providing strong empirical evidence of the relevance of the\napproach proposed are displayed.\n","authors":["Nathan Huet","Stephan Clémençon","Anne Sabourin"],"pdf_url":"https://arxiv.org/pdf/2303.03084v1.pdf","comment":"10 pages (main paper), 10 pages (appendix)"},{"id":"http://arxiv.org/abs/2205.04180v4","updated":"2023-03-06T12:46:17Z","published":"2022-05-09T10:44:23Z","title":"EF-BV: A Unified Theory of Error Feedback and Variance Reduction\n  Mechanisms for Biased and Unbiased Compression in Distributed Optimization","summary":"  In distributed or federated optimization and learning, communication between\nthe different computing units is often the bottleneck and gradient compression\nis widely used to reduce the number of bits sent within each communication\nround of iterative methods. There are two classes of compression operators and\nseparate algorithms making use of them. In the case of unbiased random\ncompressors with bounded variance (e.g., rand-k), the DIANA algorithm of\nMishchenko et al. (2019), which implements a variance reduction technique for\nhandling the variance introduced by compression, is the current state of the\nart. In the case of biased and contractive compressors (e.g., top-k), the EF21\nalgorithm of Richt\\'arik et al. (2021), which instead implements an\nerror-feedback mechanism, is the current state of the art. These two classes of\ncompression schemes and algorithms are distinct, with different analyses and\nproof techniques. In this paper, we unify them into a single framework and\npropose a new algorithm, recovering DIANA and EF21 as particular cases. Our\ngeneral approach works with a new, larger class of compressors, which has two\nparameters, the bias and the variance, and includes unbiased and biased\ncompressors as particular cases. This allows us to inherit the best of the two\nworlds: like EF21 and unlike DIANA, biased compressors, like top-k, whose good\nperformance in practice is recognized, can be used. And like DIANA and unlike\nEF21, independent randomness at the compressors allows to mitigate the effects\nof compression, with the convergence rate improving when the number of parallel\nworkers is large. This is the first time that an algorithm with all these\nfeatures is proposed. We prove its linear convergence under certain conditions.\nOur approach takes a step towards better understanding of two so-far distinct\nworlds of communication-efficient distributed learning.\n","authors":["Laurent Condat","Kai Yi","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2205.04180v4.pdf","comment":"Conference NeurIPS 2022"},{"id":"http://arxiv.org/abs/2303.03073v1","updated":"2023-03-06T12:31:19Z","published":"2023-03-06T12:31:19Z","title":"A neural network based model for multi-dimensional nonlinear Hawkes\n  processes","summary":"  This paper introduces the Neural Network for Nonlinear Hawkes processes\n(NNNH), a non-parametric method based on neural networks to fit nonlinear\nHawkes processes. Our method is suitable for analyzing large datasets in which\nevents exhibit both mutually-exciting and inhibitive patterns. The NNNH\napproach models the individual kernels and the base intensity of the nonlinear\nHawkes process using feed forward neural networks and jointly calibrates the\nparameters of the networks by maximizing the log-likelihood function. We\nutilize Stochastic Gradient Descent to search for the optimal parameters and\npropose an unbiased estimator for the gradient, as well as an efficient\ncomputation method. We demonstrate the flexibility and accuracy of our method\nthrough numerical experiments on both simulated and real-world data, and\ncompare it with state-of-the-art methods. Our results highlight the\neffectiveness of the NNNH method in accurately capturing the complexities of\nnonlinear Hawkes processes.\n","authors":["Sobin Joseph","Shashi Jain"],"pdf_url":"https://arxiv.org/pdf/2303.03073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03068v1","updated":"2023-03-06T12:23:23Z","published":"2023-03-06T12:23:23Z","title":"Reinforcement Learning Based Self-play and State Stacking Techniques for\n  Noisy Air Combat Environment","summary":"  Reinforcement learning (RL) has recently proven itself as a powerful\ninstrument for solving complex problems and even surpassed human performance in\nseveral challenging applications. This signifies that RL algorithms can be used\nin the autonomous air combat problem, which has been studied for many years.\nThe complexity of air combat arises from aggressive close-range maneuvers and\nagile enemy behaviors. In addition to these complexities, there may be\nuncertainties in real-life scenarios due to sensor errors, which prevent\nestimation of the actual position of the enemy. In this case, autonomous\naircraft should be successful even in the noisy environments. In this study, we\ndeveloped an air combat simulation, which provides noisy observations to the\nagents, therefore, make the air combat problem even more challenging. Thus, we\npresent a state stacking method for noisy RL environments as a noise reduction\ntechnique. In our extensive set of experiments, the proposed method\nsignificantly outperforms the baseline algorithms in terms of the winning\nratio, where the performance improvement is even more pronounced in the high\nnoise levels. In addition, we incorporate a self-play scheme to our training\nprocess by periodically updating the enemy with a frozen copy of the training\nagent. By this way, the training agent performs air combat simulations to an\nenemy with smarter strategies, which improves the performance and robustness of\nthe agents. In our simulations, we demonstrate that the self-play scheme\nprovides important performance gains compared to the classical RL training.\n","authors":["Ahmet Semih Tasbas","Safa Onur Sahin","Nazim Kemal Ure"],"pdf_url":"https://arxiv.org/pdf/2303.03068v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.03052v1","updated":"2023-03-06T11:51:28Z","published":"2023-03-06T11:51:28Z","title":"Masked Images Are Counterfactual Samples for Robust Fine-tuning","summary":"  Deep learning models are challenged by the distribution shift between the\ntraining data and test data. Recently, the large models pre-trained on diverse\ndata demonstrate unprecedented robustness to various distribution shifts.\nHowever, fine-tuning on these models can lead to a trade-off between\nin-distribution (ID) performance and out-of-distribution (OOD) robustness.\nExisting methods for tackling this trade-off do not explicitly address the OOD\nrobustness problem. In this paper, based on causal analysis on the\naforementioned problems, we propose a novel fine-tuning method, which use\nmasked images as counterfactual samples that help improving the robustness of\nthe fine-tuning model. Specifically, we mask either the semantics-related or\nsemantics-unrelated patches of the images based on class activation map to\nbreak the spurious correlation, and refill the masked patches with patches from\nother images. The resulting counterfactual samples are used in feature-based\ndistillation with the pre-trained model. Extensive experiments verify that\nregularizing the fine-tuning with the proposed masked images can achieve a\nbetter trade-off between ID and OOD, surpassing previous methods on the OOD\nperformance. Our code will be publicly available.\n","authors":["Yao Xiao","Ziyi Tang","Pengxu Wei","Cong Liu","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2303.03052v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2212.02931v2","updated":"2023-03-06T11:48:02Z","published":"2022-12-06T12:40:45Z","title":"Leveraging Different Learning Styles for Improved Knowledge Distillation","summary":"  Learning style refers to a type of training mechanism adopted by an\nindividual to gain new knowledge. As suggested by the VARK model, humans have\ndifferent learning preferences like visual, auditory, etc., for acquiring and\neffectively processing information. Inspired by this concept, our work explores\nthe idea of mixed information sharing with model compression in the context of\nKnowledge Distillation (KD) and Mutual Learning (ML). Unlike conventional\ntechniques that share the same type of knowledge with all networks, we propose\nto train individual networks with different forms of information to enhance the\nlearning process. We formulate a combined KD and ML framework with one teacher\nand two student networks that share or exchange information in the form of\npredictions and feature maps. Our comprehensive experiments with benchmark\nclassification and segmentation datasets demonstrate that with 15% compression,\nthe ensemble performance of networks trained with diverse forms of knowledge\noutperforms the conventional techniques both quantitatively and qualitatively.\n","authors":["Usma Niyaz","Deepti R. Bathula"],"pdf_url":"https://arxiv.org/pdf/2212.02931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.05751v3","updated":"2023-03-06T11:18:59Z","published":"2022-06-12T14:45:11Z","title":"Consistent Attack: Universal Adversarial Perturbation on Embodied Vision\n  Navigation","summary":"  Embodied agents in vision navigation coupled with deep neural networks have\nattracted increasing attention. However, deep neural networks have been shown\nvulnerable to malicious adversarial noises, which may potentially cause\ncatastrophic failures in Embodied Vision Navigation. Among different\nadversarial noises, universal adversarial perturbations (UAP), i.e., a constant\nimage-agnostic perturbation applied on every input frame of the agent, play a\ncritical role in Embodied Vision Navigation since they are\ncomputation-efficient and application-practical during the attack. However,\nexisting UAP methods ignore the system dynamics of Embodied Vision Navigation\nand might be sub-optimal. In order to extend UAP to the sequential decision\nsetting, we formulate the disturbed environment under the universal noise\n$\\delta$, as a $\\delta$-disturbed Markov Decision Process ($\\delta$-MDP). Based\non the formulation, we analyze the properties of $\\delta$-MDP and propose two\nnovel Consistent Attack methods, named Reward UAP and Trajectory UAP, for\nattacking Embodied agents, which consider the dynamic of the MDP and calculate\nuniversal noises by estimating the disturbed distribution and the disturbed Q\nfunction. For various victim models, our Consistent Attack can cause a\nsignificant drop in their performance in the PointGoal task in Habitat with\ndifferent datasets and different scenes. Extensive experimental results\nindicate that there exist serious potential risks for applying Embodied Vision\nNavigation methods to the real world.\n","authors":["Chengyang Ying","You Qiaoben","Xinning Zhou","Hang Su","Wenbo Ding","Jianyong Ai"],"pdf_url":"https://arxiv.org/pdf/2206.05751v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03042v1","updated":"2023-03-06T11:14:59Z","published":"2023-03-06T11:14:59Z","title":"Convolutional Neural Networks as 2-D systems","summary":"  This paper introduces a novel representation of convolutional Neural Networks\n(CNNs) in terms of 2-D dynamical systems. To this end, the usual description of\nconvolutional layers with convolution kernels, i.e., the impulse responses of\nlinear filters, is realized in state space as a linear time-invariant 2-D\nsystem. The overall convolutional Neural Network composed of convolutional\nlayers and nonlinear activation functions is then viewed as a 2-D version of a\nLur'e system, i.e., a linear dynamical system interconnected with static\nnonlinear components. One benefit of this 2-D Lur'e system perspective on CNNs\nis that we can use robust control theory much more efficiently for Lipschitz\nconstant estimation than previously possible.\n","authors":["Dennis Gramlich","Patricia Pauli","Carsten W. Scherer","Frank Allgöwer","Christian Ebenbauer"],"pdf_url":"https://arxiv.org/pdf/2303.03042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08516v2","updated":"2023-03-06T11:06:39Z","published":"2022-06-17T02:36:23Z","title":"MetaFed: Federated Learning among Federations with Cyclic Knowledge\n  Distillation for Personalized Healthcare","summary":"  Federated learning has attracted increasing attention to building models\nwithout accessing the raw user data, especially in healthcare. In real\napplications, different federations can seldom work together due to possible\nreasons such as data heterogeneity and distrust/inexistence of the central\nserver. In this paper, we propose a novel framework called MetaFed to\nfacilitate trustworthy FL between different federations. MetaFed obtains a\npersonalized model for each federation without a central server via the\nproposed Cyclic Knowledge Distillation. Specifically, MetaFed treats each\nfederation as a meta distribution and aggregates knowledge of each federation\nin a cyclic manner. The training is split into two parts: common knowledge\naccumulation and personalization. Comprehensive experiments on three benchmarks\ndemonstrate that MetaFed without a server achieves better accuracy compared to\nstate-of-the-art methods (e.g., 10%+ accuracy improvement compared to the\nbaseline for PAMAP2) with fewer communication costs.\n","authors":["Yiqiang Chen","Wang Lu","Xin Qin","Jindong Wang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2206.08516v2.pdf","comment":"IJCAI'22 FTL workshop innovation award; Extended version (12 pages)\n  with more experiments and extensions; code at\n  https://github.com/microsoft/PersonalizedFL"},{"id":"http://arxiv.org/abs/2303.03036v1","updated":"2023-03-06T11:05:21Z","published":"2023-03-06T11:05:21Z","title":"Deep Clustering with a Constraint for Topological Invariance based on\n  Symmetric InfoNCE","summary":"  We consider the scenario of deep clustering, in which the available prior\nknowledge is limited. In this scenario, few existing state-of-the-art deep\nclustering methods can perform well for both non-complex topology and complex\ntopology datasets. To address the problem, we propose a constraint utilizing\nsymmetric InfoNCE, which helps an objective of deep clustering method in the\nscenario train the model so as to be efficient for not only non-complex\ntopology but also complex topology datasets. Additionally, we provide several\ntheoretical explanations of the reason why the constraint can enhances\nperformance of deep clustering methods. To confirm the effectiveness of the\nproposed constraint, we introduce a deep clustering method named MIST, which is\na combination of an existing deep clustering method and our constraint. Our\nnumerical experiments via MIST demonstrate that the constraint is effective. In\naddition, MIST outperforms other state-of-the-art deep clustering methods for\nmost of the commonly used ten benchmark datasets.\n","authors":["Yuhui Zhang","Yuichiro Wada","Hiroki Waida","Kaito Goto","Yusaku Hino","Takafumi Kanamori"],"pdf_url":"https://arxiv.org/pdf/2303.03036v1.pdf","comment":"48 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.03027v1","updated":"2023-03-06T10:56:14Z","published":"2023-03-06T10:56:14Z","title":"Critical Points and Convergence Analysis of Generative Deep Linear\n  Networks Trained with Bures-Wasserstein Loss","summary":"  We consider a deep matrix factorization model of covariance matrices trained\nwith the Bures-Wasserstein distance. While recent works have made important\nadvances in the study of the optimization problem for overparametrized low-rank\nmatrix approximation, much emphasis has been placed on discriminative settings\nand the square loss. In contrast, our model considers another interesting type\nof loss and connects with the generative setting. We characterize the critical\npoints and minimizers of the Bures-Wasserstein distance over the space of\nrank-bounded matrices. For low-rank matrices the Hessian of this loss can\ntheoretically blow up, which creates challenges to analyze convergence of\noptimizaton methods. We establish convergence results for gradient flow using a\nsmooth perturbative version of the loss and convergence results for finite step\nsize gradient descent under certain assumptions on the initial weights.\n","authors":["Pierre Bréchet","Katerina Papagiannouli","Jing An","Guido Montúfar"],"pdf_url":"https://arxiv.org/pdf/2303.03027v1.pdf","comment":"35 pages, 1 figure"},{"id":"http://arxiv.org/abs/2210.09171v2","updated":"2023-03-06T10:52:25Z","published":"2022-10-17T15:19:26Z","title":"Data-driven Modeling of Mach-Zehnder Interferometer-based Optical Matrix\n  Multipliers","summary":"  Photonic integrated circuits are facilitating the development of optical\nneural networks, which have the potential to be both faster and more energy\nefficient than their electronic counterparts since optical signals are\nespecially well-suited for implementing matrix multiplications. However,\naccurate programming of photonic chips for optical matrix multiplication\nremains a difficult challenge. Here, we describe both simple analytical models\nand data-driven models for offline training of optical matrix multipliers. We\ntrain and evaluate the models using experimental data obtained from a\nfabricated chip featuring a Mach-Zehnder interferometer mesh implementing\n3-by-3 matrix multiplication. The neural network-based models outperform the\nsimple physics-based models in terms of prediction error. Furthermore, the\nneural network models are also able to predict the spectral variations in the\nmatrix weights for up to 100 frequency channels covering the C-band. The use of\nneural network models for programming the chip for optical matrix\nmultiplication yields increased performance on multiple machine learning tasks.\n","authors":["Ali Cem","Siqi Yan","Yunhong Ding","Darko Zibar","Francesco Da Ros"],"pdf_url":"https://arxiv.org/pdf/2210.09171v2.pdf","comment":"12 pages, 17 figures, submitted to Jorunal of Lightwave Technology"},{"id":"http://arxiv.org/abs/2303.03023v1","updated":"2023-03-06T10:50:25Z","published":"2023-03-06T10:50:25Z","title":"Guiding Energy-based Models via Contrastive Latent Variables","summary":"  An energy-based model (EBM) is a popular generative framework that offers\nboth explicit density and architectural flexibility, but training them is\ndifficult since it is often unstable and time-consuming. In recent years,\nvarious training techniques have been developed, e.g., better divergence\nmeasures or stabilization in MCMC sampling, but there often exists a large gap\nbetween EBMs and other generative frameworks like GANs in terms of generation\nquality. In this paper, we propose a novel and effective framework for\nimproving EBMs via contrastive representation learning (CRL). To be specific,\nwe consider representations learned by contrastive methods as the true\nunderlying latent variable. This contrastive latent variable could guide EBMs\nto understand the data structure better, so it can improve and accelerate EBM\ntraining significantly. To enable the joint training of EBM and CRL, we also\ndesign a new class of latent-variable EBMs for learning the joint density of\ndata and the contrastive latent variable. Our experimental results demonstrate\nthat our scheme achieves lower FID scores, compared to prior-art EBM methods\n(e.g., additionally using variational autoencoders or diffusion techniques),\neven with significantly faster and more memory-efficient training. We also show\nconditional and compositional generation abilities of our latent-variable EBMs\nas their additional benefits, even without explicit conditional training. The\ncode is available at https://github.com/hankook/CLEL.\n","authors":["Hankook Lee","Jongheon Jeong","Sejun Park","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2303.03023v1.pdf","comment":"Accepted to ICLR 2023 (Spotlight). The code is available at\n  https://github.com/hankook/CLEL"},{"id":"http://arxiv.org/abs/2302.07684v2","updated":"2023-03-06T10:48:05Z","published":"2023-02-15T14:21:31Z","title":"A Federated Learning Benchmark for Drug-Target Interaction","summary":"  Aggregating pharmaceutical data in the drug-target interaction (DTI) domain\nhas the potential to deliver life-saving breakthroughs. It is, however,\nnotoriously difficult due to regulatory constraints and commercial interests.\nThis work proposes the application of federated learning, which we argue to be\nreconcilable with the industry's constraints, as it does not require sharing of\nany information that would reveal the entities' data or any other high-level\nsummary of it. When used on a representative GraphDTA model and the KIBA\ndataset it achieves up to 15% improved performance relative to the best\navailable non-privacy preserving alternative. Our extensive battery of\nexperiments shows that, unlike in other domains, the non-IID data distribution\nin the DTI datasets does not deteriorate FL performance. Additionally, we\nidentify a material trade-off between the benefits of adding new data, and the\ncost of adding more clients.\n","authors":["Gianluca Mittone","Filip Svoboda","Marco Aldinucci","Nicholas D. Lane","Pietro Lio"],"pdf_url":"https://arxiv.org/pdf/2302.07684v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03005v1","updated":"2023-03-06T10:15:14Z","published":"2023-03-06T10:15:14Z","title":"Scaling strategies for on-device low-complexity source separation with\n  Conv-Tasnet","summary":"  Recently, several very effective neural approaches for single-channel speech\nseparation have been presented in the literature. However, due to the size and\ncomplexity of these models, their use on low-resource devices, e.g. for hearing\naids, and earphones, is still a challenge and established solutions are not\navailable yet. Although approaches based on either pruning or compressing\nneural models have been proposed, the design of a model architecture suitable\nfor a certain application domain often requires heuristic procedures not easily\nportable to different low-resource platforms. Given the modular nature of the\nwell-known Conv-Tasnet speech separation architecture, in this paper we\nconsider three parameters that directly control the overall size of the model,\nnamely: the number of residual blocks, the number of repetitions of the\nseparation blocks and the number of channels in the depth-wise convolutions,\nand experimentally evaluate how they affect the speech separation performance.\nIn particular, experiments carried out on the Libri2Mix show that the number of\ndilated 1D-Conv blocks is the most critical parameter and that the usage of\nextra-dilation in the residual blocks allows reducing the performance drop.\n","authors":["Mohamed Nabih Ali","Francesco Paissan","Daniele Falavigna","Alessio Brutti"],"pdf_url":"https://arxiv.org/pdf/2303.03005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00815v2","updated":"2023-03-06T10:10:19Z","published":"2023-01-01T12:48:12Z","title":"NeuroExplainer: Fine-Grained Attention Decoding to Uncover Cortical\n  Development Patterns of Preterm Infants","summary":"  Deploying reliable deep learning techniques in interdisciplinary applications\nneeds learned models to output accurate and ({even more importantly})\nexplainable predictions. Existing approaches typically explicate network\noutputs in a post-hoc fashion, under an implicit assumption that faithful\nexplanations come from accurate predictions/classifications. We have an\nopposite claim that explanations boost (or even determine) classification. That\nis, end-to-end learning of explanation factors to augment discriminative\nrepresentation extraction could be a more intuitive strategy to inversely\nassure fine-grained explainability, e.g., in those neuroimaging and\nneuroscience studies with high-dimensional data containing noisy, redundant,\nand task-irrelevant information. In this paper, we propose such an explainable\ngeometric deep network dubbed as NeuroExplainer, with applications to uncover\naltered infant cortical development patterns associated with preterm birth.\nGiven fundamental cortical attributes as network input, our NeuroExplainer\nadopts a hierarchical attention-decoding framework to learn fine-grained\nattentions and respective discriminative representations to accurately\nrecognize preterm infants from term-born infants at term-equivalent age.\nNeuroExplainer learns the hierarchical attention-decoding modules under\nsubject-level weak supervision coupled with targeted regularizers deduced from\ndomain knowledge regarding brain development. These prior-guided constraints\nimplicitly maximizes the explainability metrics (i.e., fidelity, sparsity, and\nstability) in network training, driving the learned network to output detailed\nexplanations and accurate classifications. Experimental results on the public\ndHCP benchmark suggest that NeuroExplainer led to quantitatively reliable\nexplanation results that are qualitatively consistent with representative\nneuroimaging studies.\n","authors":["Chenyu Xue","Fan Wang","Yuanzhuo Zhu","Hui Li","Deyu Meng","Dinggang Shen","Chunfeng Lian"],"pdf_url":"https://arxiv.org/pdf/2301.00815v2.pdf","comment":"Some parts of the thesis are still being revised"},{"id":"http://arxiv.org/abs/2303.01954v2","updated":"2023-03-06T10:01:27Z","published":"2023-03-03T14:28:45Z","title":"Synthetic Data Generator for Adaptive Interventions in Global Health","summary":"  Artificial Intelligence and digital health have the potential to transform\nglobal health. However, having access to representative data to test and\nvalidate algorithms in realistic production environments is essential. We\nintroduce HealthSyn, an open-source synthetic data generator of user behavior\nfor testing reinforcement learning algorithms in the context of mobile health\ninterventions. The generator utilizes Markov processes to generate diverse user\nactions, with individual user behavioral patterns that can change in reaction\nto personalized interventions (i.e., reminders, recommendations, and\nincentives). These actions are translated into actual logs using an ML-purposed\ndata schema specific to the mobile health application functionality included\nwith HealthKit, and open-source SDK. The logs can be fed to pipelines to obtain\nuser metrics. The generated data, which is based on real-world behaviors and\nsimulation techniques, can be used to develop, test, and evaluate, both ML\nalgorithms in research and end-to-end operational RL-based intervention\ndelivery frameworks.\n","authors":["Aditya Rastogi","Juan Francisco Garamendi","Ana Fernández del Río","Anna Guitart","Moiz Hassan Khan","Dexian Tang","África Periáñez"],"pdf_url":"https://arxiv.org/pdf/2303.01954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11776v2","updated":"2023-03-06T10:00:40Z","published":"2022-12-22T15:12:29Z","title":"Fixed-budget online adaptive learning for physics-informed neural\n  networks. Towards parameterized problem inference","summary":"  Physics-Informed Neural Networks (PINNs) have gained much attention in\nvarious fields of engineering thanks to their capability of incorporating\nphysical laws into the models. PINNs integrate the physical constraints by\nminimizing the partial differential equations (PDEs) residuals on a set of\ncollocation points. The distribution of these collocation points appears to\nhave a huge impact on the performance of PINNs and the assessment of the\nsampling methods for these points is still an active topic. In this paper, we\npropose a Fixed-Budget Online Adaptive Learning (FBOAL) method, which\ndecomposes the domain into sub-domains, for training collocation points based\non local maxima and local minima of the PDEs residuals. The effectiveness of\nFBOAL is demonstrated for non-parameterized and parameterized problems. The\ncomparison with other adaptive sampling methods is also illustrated. The\nnumerical results demonstrate important gains in terms of the accuracy and\ncomputational cost of PINNs with FBOAL over the classical PINNs with\nnon-adaptive collocation points. We also apply FBOAL in a complex industrial\napplication involving coupling between mechanical and thermal fields. We show\nthat FBOAL is able to identify the high-gradient locations and even give better\npredictions for some physical fields than the classical PINNs with collocation\npoints sampled on a pre-adapted finite element mesh built thanks to numerical\nexpert knowledge. From the present study, it is expected that the use of FBOAL\nwill help to improve the conventional numerical solver in the construction of\nthe mesh.\n","authors":["Thi Nguyen Khoa Nguyen","Thibault Dairay","Raphaël Meunier","Christophe Millet","Mathilde Mougeot"],"pdf_url":"https://arxiv.org/pdf/2212.11776v2.pdf","comment":"22 pages, 30 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.02995v1","updated":"2023-03-06T09:44:01Z","published":"2023-03-06T09:44:01Z","title":"HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware\n  Attention","summary":"  The success of large-scale contrastive vision-language pretraining (CLIP) has\nbenefited both visual recognition and multimodal content understanding. The\nconcise design brings CLIP the advantage in inference efficiency against other\nvision-language models with heavier cross-attention fusion layers, making it a\npopular choice for a wide spectrum of downstream tasks. However, CLIP does not\nexplicitly capture the hierarchical nature of high-level and fine-grained\nsemantics conveyed in images and texts, which is arguably critical to\nvision-language understanding and reasoning. To this end, we equip both the\nvisual and language branches in CLIP with hierarchy-aware attentions, namely\nHierarchy-aware CLIP (HiCLIP), to progressively discover semantic hierarchies\nlayer-by-layer from both images and texts in an unsupervised manner. As a\nresult, such hierarchical aggregation significantly improves the cross-modal\nalignment. To demonstrate the advantages of HiCLIP, we conduct qualitative\nanalysis on its unsupervised hierarchy induction during inference, as well as\nextensive quantitative experiments on both visual recognition and\nvision-language downstream tasks.\n","authors":["Shijie Geng","Jianbo Yuan","Yu Tian","Yuxiao Chen","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02995v1.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2205.14962v3","updated":"2023-03-06T09:36:15Z","published":"2022-05-30T10:00:59Z","title":"Sampling-free Inference for Ab-Initio Potential Energy Surface Networks","summary":"  Recently, it has been shown that neural networks not only approximate the\nground-state wave functions of a single molecular system well but can also\ngeneralize to multiple geometries. While such generalization significantly\nspeeds up training, each energy evaluation still requires Monte Carlo\nintegration which limits the evaluation to a few geometries. In this work, we\naddress the inference shortcomings by proposing the Potential learning from\nab-initio Networks (PlaNet) framework, in which we simultaneously train a\nsurrogate model in addition to the neural wave function. At inference time, the\nsurrogate avoids expensive Monte-Carlo integration by directly estimating the\nenergy, accelerating the process from hours to milliseconds. In this way, we\ncan accurately model high-resolution multi-dimensional energy surfaces for\nlarger systems that previously were unobtainable via neural wave functions.\nFinally, we explore an additional inductive bias by introducing\nphysically-motivated restricted neural wave function models. We implement such\na function with several additional improvements in the new PESNet++ model. In\nour experimental evaluation, PlaNet accelerates inference by 7 orders of\nmagnitude for larger molecules like ethanol while preserving accuracy. Compared\nto previous energy surface networks, PESNet++ reduces energy errors by up to\n74%.\n","authors":["Nicholas Gao","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2205.14962v3.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.03494v7","updated":"2023-03-06T09:34:38Z","published":"2023-02-06T04:21:59Z","title":"A Categorical Archive of ChatGPT Failures","summary":"  Large language models have been demonstrated to be valuable in different\nfields. ChatGPT, developed by OpenAI, has been trained using massive amounts of\ndata and simulates human conversation by comprehending context and generating\nappropriate responses. It has garnered significant attention due to its ability\nto effectively answer a broad range of human inquiries, with fluent and\ncomprehensive answers surpassing prior public chatbots in both security and\nusefulness. However, a comprehensive analysis of ChatGPT's failures is lacking,\nwhich is the focus of this study. Eleven categories of failures, including\nreasoning, factual errors, math, coding, and bias, are presented and discussed.\nThe risks, limitations, and societal implications of ChatGPT are also\nhighlighted. The goal of this study is to assist researchers and developers in\nenhancing future language models and chatbots.\n","authors":["Ali Borji"],"pdf_url":"https://arxiv.org/pdf/2302.03494v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.10080v3","updated":"2023-03-06T09:33:50Z","published":"2022-09-21T02:46:13Z","title":"Deep Double Descent via Smooth Interpolation","summary":"  The ability of overparameterized deep networks to interpolate noisy data,\nwhile at the same time showing good generalization performance, has been\nrecently characterized in terms of the double descent curve for the test error.\nCommon intuition from polynomial regression suggests that overparameterized\nnetworks are able to sharply interpolate noisy data, without considerably\ndeviating from the ground-truth signal, thus preserving their generalization\nability. At present, a precise characterization of the relationship between\ninterpolation and generalization for deep networks is missing. In this work, we\nquantify sharpness of fit of the training data interpolated by neural network\nfunctions, by studying the loss landscape w.r.t.\\ to the input variable locally\nto each training point, over volumes around cleanly- and noisily-labelled\ntraining samples, as we systematically increase the number of model parameters\nand training epochs. Our findings show that loss sharpness in the input space\nfollows both model- and epoch-wise double descent, with worse peaks observed\naround noisy labels. While small interpolating models sharply fit both clean\nand noisy data, large interpolating models express a smooth loss landscape,\nwhere noisy targets are predicted over large volumes around training data\npoints, in contrast to existing intuition.\n","authors":["Matteo Gamba","Erik Englesson","Mårten Björkman","Hossein Azizpour"],"pdf_url":"https://arxiv.org/pdf/2209.10080v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02988v1","updated":"2023-03-06T09:31:42Z","published":"2023-03-06T09:31:42Z","title":"Searching for Effective Neural Network Architectures for Heart Murmur\n  Detection from Phonocardiogram","summary":"  Aim: The George B. Moody PhysioNet Challenge 2022 raised problems of heart\nmurmur detection and related abnormal cardiac function identification from\nphonocardiograms (PCGs). This work describes the novel approaches developed by\nour team, Revenger, to solve these problems.\n  Methods: PCGs were resampled to 1000 Hz, then filtered with a Butterworth\nband-pass filter of order 3, cutoff frequencies 25 - 400 Hz, and z-score\nnormalized. We used the multi-task learning (MTL) method via hard parameter\nsharing to train one neural network (NN) model for all the Challenge tasks. We\nperformed neural architecture searching among a set of network backbones,\nincluding multi-branch convolutional neural networks (CNNs), SE-ResNets,\nTResNets, simplified wav2vec2, etc.\n  Based on a stratified splitting of the subjects, 20% of the public data was\nleft out as a validation set for model selection. The AdamW optimizer was\nadopted, along with the OneCycle scheduler, to optimize the model weights.\n  Results: Our murmur detection classifier received a weighted accuracy score\nof 0.736 (ranked 14th out of 40 teams) and a Challenge cost score of 12944\n(ranked 19th out of 39 teams) on the hidden validation set.\n  Conclusion: We provided a practical solution to the problems of detecting\nheart murmurs and providing clinical diagnosis suggestions from PCGs.\n","authors":["Hao Wen","Jingsu Kang"],"pdf_url":"https://arxiv.org/pdf/2303.02988v1.pdf","comment":"4 pages, 5 figures, Computing in Cardiology 2022, URL:\n  https://github.com/DeepPSP/cinc2022"},{"id":"http://arxiv.org/abs/2303.02984v1","updated":"2023-03-06T09:23:14Z","published":"2023-03-06T09:23:14Z","title":"Learning multi-scale local conditional probability models of images","summary":"  Deep neural networks can learn powerful prior probability models for images,\nas evidenced by the high-quality generations obtained with recent score-based\ndiffusion methods. But the means by which these networks capture complex global\nstatistical structure, apparently without suffering from the curse of\ndimensionality, remain a mystery. To study this, we incorporate diffusion\nmethods into a multi-scale decomposition, reducing dimensionality by assuming a\nstationary local Markov model for wavelet coefficients conditioned on\ncoarser-scale coefficients. We instantiate this model using convolutional\nneural networks (CNNs) with local receptive fields, which enforce both the\nstationarity and Markov properties. Global structures are captured using a CNN\nwith receptive fields covering the entire (but small) low-pass image. We test\nthis model on a dataset of face images, which are highly non-stationary and\ncontain large-scale geometric structures. Remarkably, denoising,\nsuper-resolution, and image synthesis results all demonstrate that these\nstructures can be captured with significantly smaller conditioning\nneighborhoods than required by a Markov model implemented in the pixel domain.\nOur results show that score estimation for large complex images can be reduced\nto low-dimensional Markov conditional models across scales, alleviating the\ncurse of dimensionality.\n","authors":["Zahra Kadkhodaie","Florentin Guth","Stéphane Mallat","Eero P Simoncelli"],"pdf_url":"https://arxiv.org/pdf/2303.02984v1.pdf","comment":"16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.02980v1","updated":"2023-03-06T09:15:28Z","published":"2023-03-06T09:15:28Z","title":"KDSM: An uplift modeling framework based on knowledge distillation and\n  sample matching","summary":"  Uplift modeling aims to estimate the treatment effect on individuals, widely\napplied in the e-commerce platform to target persuadable customers and maximize\nthe return of marketing activities. Among the existing uplift modeling methods,\ntree-based methods are adept at fitting increment and generalization, while\nneural-network-based models excel at predicting absolute value and precision,\nand these advantages have not been fully explored and combined. Also, the lack\nof counterfactual sample pairs is the root challenge in uplift modeling. In\nthis paper, we proposed an uplift modeling framework based on Knowledge\nDistillation and Sample Matching (KDSM). The teacher model is the uplift\ndecision tree (UpliftDT), whose structure is exploited to construct\ncounterfactual sample pairs, and the pairwise incremental prediction is treated\nas another objective for the student model. Under the idea of multitask\nlearning, the student model can achieve better performance on generalization\nand even surpass the teacher. Extensive offline experiments validate the\nuniversality of different combinations of teachers and student models and the\nsuperiority of KDSM measured against the baselines. In online A/B testing, the\ncost of each incremental room night is reduced by 6.5\\%.\n","authors":["Chang Sun","Qianying Li","Guanxiang Wang","Sihao Xu","Yitong Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02970v1","updated":"2023-03-06T08:54:18Z","published":"2023-03-06T08:54:18Z","title":"Rethinking Confidence Calibration for Failure Prediction","summary":"  Reliable confidence estimation for the predictions is important in many\nsafety-critical applications. However, modern deep neural networks are often\noverconfident for their incorrect predictions. Recently, many calibration\nmethods have been proposed to alleviate the overconfidence problem. With\ncalibrated confidence, a primary and practical purpose is to detect\nmisclassification errors by filtering out low-confidence predictions (known as\nfailure prediction). In this paper, we find a general, widely-existed but\nactually-neglected phenomenon that most confidence calibration methods are\nuseless or harmful for failure prediction. We investigate this problem and\nreveal that popular confidence calibration methods often lead to worse\nconfidence separation between correct and incorrect samples, making it more\ndifficult to decide whether to trust a prediction or not. Finally, inspired by\nthe natural connection between flat minima and confidence separation, we\npropose a simple hypothesis: flat minima is beneficial for failure prediction.\nWe verify this hypothesis via extensive experiments and further boost the\nperformance by combining two different flat minima techniques. Our code is\navailable at https://github.com/Impression2805/FMFP\n","authors":["Fei Zhu","Zhen Cheng","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02970v1.pdf","comment":"Accepted to ECCV 2022. Code is available at\n  https://github.com/Impression2805/FMFP"},{"id":"http://arxiv.org/abs/2303.02966v1","updated":"2023-03-06T08:51:00Z","published":"2023-03-06T08:51:00Z","title":"Non-Parametric Outlier Synthesis","summary":"  Out-of-distribution (OOD) detection is indispensable for safely deploying\nmachine learning models in the wild. One of the key challenges is that models\nlack supervision signals from unknown data, and as a result, can produce\noverconfident predictions on OOD data. Recent work on outlier synthesis modeled\nthe feature space as parametric Gaussian distribution, a strong and restrictive\nassumption that might not hold in reality. In this paper, we propose a novel\nframework, Non-Parametric Outlier Synthesis (NPOS), which generates artificial\nOOD training data and facilitates learning a reliable decision boundary between\nID and OOD data. Importantly, our proposed synthesis approach does not make any\ndistributional assumption on the ID embeddings, thereby offering strong\nflexibility and generality. We show that our synthesis approach can be\nmathematically interpreted as a rejection sampling framework. Extensive\nexperiments show that NPOS can achieve superior OOD detection performance,\noutperforming the competitive rivals by a significant margin. Code is publicly\navailable at https://github.com/deeplearning-wisc/npos.\n","authors":["Leitian Tao","Xuefeng Du","Xiaojin Zhu","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2303.02966v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02957v1","updated":"2023-03-06T08:05:08Z","published":"2023-03-06T08:05:08Z","title":"Primal and Dual Analysis of Entropic Fictitious Play for Finite-sum\n  Problems","summary":"  The entropic fictitious play (EFP) is a recently proposed algorithm that\nminimizes the sum of a convex functional and entropy in the space of measures\n-- such an objective naturally arises in the optimization of a two-layer neural\nnetwork in the mean-field regime. In this work, we provide a concise\nprimal-dual analysis of EFP in the setting where the learning problem exhibits\na finite-sum structure. We establish quantitative global convergence guarantees\nfor both the continuous-time and discrete-time dynamics based on properties of\na proximal Gibbs measure introduced in Nitanda et al. (2022). Furthermore, our\nprimal-dual framework entails a memory-efficient particle-based implementation\nof the EFP update, and also suggests a connection to gradient boosting methods.\nWe illustrate the efficiency of our novel implementation in experiments\nincluding neural network optimization and image synthesis.\n","authors":["Atsushi Nitanda","Kazusato Oko","Denny Wu","Nobuhito Takenouchi","Taiji Suzuki"],"pdf_url":"https://arxiv.org/pdf/2303.02957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02954v1","updated":"2023-03-06T07:54:37Z","published":"2023-03-06T07:54:37Z","title":"Centroid Distance Distillation for Effective Rehearsal in Continual\n  Learning","summary":"  Rehearsal, retraining on a stored small data subset of old tasks, has been\nproven effective in solving catastrophic forgetting in continual learning.\nHowever, due to the sampled data may have a large bias towards the original\ndataset, retraining them is susceptible to driving continual domain drift of\nold tasks in feature space, resulting in forgetting. In this paper, we focus on\ntackling the continual domain drift problem with centroid distance\ndistillation. First, we propose a centroid caching mechanism for sampling data\npoints based on constructed centroids to reduce the sample bias in rehearsal.\nThen, we present a centroid distance distillation that only stores the centroid\ndistance to reduce the continual domain drift. The experiments on four\ncontinual learning datasets show the superiority of the proposed method, and\nthe continual domain drift can be reduced.\n","authors":["Daofeng Liu","Fan Lyu","Linyan Li","Zhenping Xia","Fuyuan Hu"],"pdf_url":"https://arxiv.org/pdf/2303.02954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03390v2","updated":"2023-03-06T07:11:19Z","published":"2023-02-07T10:51:53Z","title":"Learning Discretized Neural Networks under Ricci Flow","summary":"  In this paper, we consider Discretized Neural Networks (DNNs) consisting of\nlow-precision weights and activations, which suffer from either infinite or\nzero gradients caused by the non-differentiable discrete function in the\ntraining process. In this case, most training-based DNNs use the standard\nStraight-Through Estimator (STE) to approximate the gradient w.r.t. discrete\nvalues. However, the STE will cause the problem of gradient mismatch, which\nimplies that the approximated gradient is with perturbations. We propose an\nanalysis that this mismatch can be viewed as a metric perturbation in a\nRiemannian manifold through the lens of duality theory. To address this\nproblem, based on the information geometry, we construct the Linearly Nearly\nEuclidean (LNE) manifold for DNNs as a background to deal with perturbations.\nBy introducing a partial differential equation on metrics, the Ricci flow, we\nprove the dynamical stability and convergence of the LNE metric with the\n$L^2$-norm perturbation. And unlike the previous perturbation theory which\ngives the rate of convergence is the fractional powers, we yield the metric\nperturbation under the Ricci flow can be exponentially decayed in the LNE\nmanifold. The experimental results on various datasets demonstrate that our\nmethod achieves better and more stable performance for DNNs than other\nrepresentative training-based methods.\n","authors":["Jun Chen","Hanwen Chen","Mengmeng Wang","Guang Dai","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2302.03390v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02918v1","updated":"2023-03-06T06:28:20Z","published":"2023-03-06T06:28:20Z","title":"Graph Positional Encoding via Random Feature Propagation","summary":"  Two main families of node feature augmentation schemes have been explored for\nenhancing GNNs: random features and spectral positional encoding. Surprisingly,\nhowever, there is still no clear understanding of the relation between these\ntwo augmentation schemes. Here we propose a novel family of positional encoding\nschemes which draws a link between the above two approaches and improves over\nboth. The new approach, named Random Feature Propagation (RFP), is inspired by\nthe power iteration method and its generalizations. It concatenates several\nintermediate steps of an iterative algorithm for computing the dominant\neigenvectors of a propagation matrix, starting from random node features.\nNotably, these propagation steps are based on graph-dependent propagation\noperators that can be either predefined or learned. We explore the theoretical\nand empirical benefits of RFP. First, we provide theoretical justifications for\nusing random features, for incorporating early propagation steps, and for using\nmultiple random initializations. Then, we empirically demonstrate that RFP\nsignificantly outperforms both spectral PE and random features in multiple node\nclassification and graph classification benchmarks.\n","authors":["Moshe Eliasof","Fabrizio Frasca","Beatrice Bevilacqua","Eran Treister","Gal Chechik","Haggai Maron"],"pdf_url":"https://arxiv.org/pdf/2303.02918v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07646v3","updated":"2023-03-06T06:28:18Z","published":"2022-02-15T18:48:31Z","title":"Quantifying Memorization Across Neural Language Models","summary":"  Large language models (LMs) have been shown to memorize parts of their\ntraining data, and when prompted appropriately, they will emit the memorized\ntraining data verbatim. This is undesirable because memorization violates\nprivacy (exposing user data), degrades utility (repeated easy-to-memorize text\nis often low quality), and hurts fairness (some texts are memorized over\nothers).\n  We describe three log-linear relationships that quantify the degree to which\nLMs emit memorized training data. Memorization significantly grows as we\nincrease (1) the capacity of a model, (2) the number of times an example has\nbeen duplicated, and (3) the number of tokens of context used to prompt the\nmodel. Surprisingly, we find the situation becomes more complicated when\ngeneralizing these results across model families. On the whole, we find that\nmemorization in LMs is more prevalent than previously believed and will likely\nget worse as models continues to scale, at least without active mitigations.\n","authors":["Nicholas Carlini","Daphne Ippolito","Matthew Jagielski","Katherine Lee","Florian Tramer","Chiyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2202.07646v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10550v2","updated":"2023-03-06T06:28:05Z","published":"2022-06-21T17:27:27Z","title":"(Certified!!) Adversarial Robustness for Free!","summary":"  In this paper we show how to achieve state-of-the-art certified adversarial\nrobustness to 2-norm bounded perturbations by relying exclusively on\noff-the-shelf pretrained models. To do so, we instantiate the denoised\nsmoothing approach of Salman et al. 2020 by combining a pretrained denoising\ndiffusion probabilistic model and a standard high-accuracy classifier. This\nallows us to certify 71% accuracy on ImageNet under adversarial perturbations\nconstrained to be within an 2-norm of 0.5, an improvement of 14 percentage\npoints over the prior certified SoTA using any approach, or an improvement of\n30 percentage points over denoised smoothing. We obtain these results using\nonly pretrained diffusion models and image classifiers, without requiring any\nfine tuning or retraining of model parameters.\n","authors":["Nicholas Carlini","Florian Tramer","Krishnamurthy Dj Dvijotham","Leslie Rice","Mingjie Sun","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2206.10550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02902v1","updated":"2023-03-06T05:38:13Z","published":"2023-03-06T05:38:13Z","title":"A Topological Distance Measure between Multi-Fields for Classification\n  and Analysis of Shapes and Data","summary":"  Distance measures play an important role in shape classification and data\nanalysis problems. Topological distances based on Reeb graphs and persistence\ndiagrams have been employed to obtain effective algorithms in shape matching\nand scalar data analysis. In the current paper, we propose an improved distance\nmeasure between two multi-fields by computing a multi-dimensional Reeb graph\n(MDRG) each of which captures the topology of a multi-field through a hierarchy\nof Reeb graphs in different dimensions. A hierarchy of persistence diagrams is\nthen constructed by computing a persistence diagram corresponding to each Reeb\ngraph of the MDRG. Based on this representation, we propose a novel distance\nmeasure between two MDRGs by extending the bottleneck distance between two Reeb\ngraphs. We show that the proposed measure satisfies the pseudo-metric and\nstability properties. We examine the effectiveness of the proposed multi-field\ntopology-based measure on two different applications: (1) shape classification\nand (2) detection of topological features in a time-varying multi-field data.\nIn the shape classification problem, the performance of the proposed measure is\ncompared with the well-known topology-based measures in shape matching. In the\nsecond application, we consider a time-varying volumetric multi-field data from\nthe field of computational chemistry where the goal is to detect the site of\nstable bond formation between Pt and CO molecules. We demonstrate the ability\nof the proposed distance in classifying each of the sites as occurring before\nand after the bond stabilization.\n","authors":["Yashwanth Ramamurthi","Amit Chattopadhyay"],"pdf_url":"https://arxiv.org/pdf/2303.02902v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02901v1","updated":"2023-03-06T05:35:32Z","published":"2023-03-06T05:35:32Z","title":"The $α$-divergence Improves the Entropy Production Estimation via\n  Machine Learning","summary":"  Recent years have seen a surge of interest in the algorithmic estimation of\nstochastic entropy production (EP) from the trajectory data via machine\nlearning. A crucial element of such algorithms is the identification of a loss\nfunction whose minimization guarantees the accurate EP estimation. In this\nstudy, we show that there exists a host of loss functions, namely those\nimplementing a variational representation of the $\\alpha$-divergence, which can\nbe used for the EP estimation. Among these loss functions, the one\ncorresponding to $\\alpha = -0.5$ exhibits the most robust performance against\nstrong nonequilibrium driving or slow dynamics, which adversely affects the\nexisting method based on the Kullback-Leibler divergence ($\\alpha = 0$). To\ncorroborate our findings, we present an exactly solvable simplification of the\nEP estimation problem, whose loss function landscape and stochastic properties\ndemonstrate the optimality of $\\alpha = -0.5$.\n","authors":["Euijoon Kwon","Yongjoo Baek"],"pdf_url":"https://arxiv.org/pdf/2303.02901v1.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.02898v1","updated":"2023-03-06T05:23:44Z","published":"2023-03-06T05:23:44Z","title":"Stabilizing the Maximal Entropy Moment Method for Rarefied Gas Dynamics\n  at Single-Precision","summary":"  Developing extended hydrodynamics equations valid for both dense and rarefied\ngases remains a great challenge. A systematical solution for this challenge is\nthe moment method describing both dense and rarefied gas behaviors with moments\nof gas molecule velocity distributions. Among moment methods, the maximal\nentropy moment method (MEM) stands out for its well-posedness and stability,\nwhich utilizes velocity distributions with maximized entropy. However, finding\nsuch distributions requires solving an ill-conditioned and\ncomputation-demanding optimization problem. This problem causes numerical\noverflow and breakdown when the numerical precision is insufficient, especially\nfor flows like high-speed shock waves. It also prevents modern GPUs from\naccelerating optimization with their enormous single floating-point precision\ncomputation power. This paper aims to stabilize MEM, making it practical for\nsimulating very strong normal shock waves on modern GPUs at single precision.\nWe propose the gauge transformations for MEM, making the optimization less\nill-conditioned. We also tackle numerical overflow and breakdown by adopting\nthe canonical form of distribution and Newton's modified optimization method.\nWith these techniques, we achieved a single-precision GPU simulation of a Mach\n10 shock wave with 35 moments MEM, surpassing the previous double-precision\nresults of Mach 4. Moreover, we argued that over-refined spatial mesh degrades\nboth the accuracy and stability of MEM. Overall, this paper makes the maximal\nentropy moment method practical for simulating very strong normal shock waves\non modern GPUs at single-precision, with significant stability improvement\ncompared to previous methods.\n","authors":["Candi Zheng","Wang Yang","Shiyi Chen"],"pdf_url":"https://arxiv.org/pdf/2303.02898v1.pdf","comment":"25 pages, 5 figures"},{"id":"http://arxiv.org/abs/2210.15809v2","updated":"2023-03-06T04:54:25Z","published":"2022-10-28T00:14:00Z","title":"Coverage-centric Coreset Selection for High Pruning Rates","summary":"  One-shot coreset selection aims to select a representative subset of the\ntraining data, given a pruning rate, that can later be used to train future\nmodels while retaining high accuracy. State-of-the-art coreset selection\nmethods pick the highest importance examples based on an importance metric and\nare found to perform well at low pruning rates. However, at high pruning rates,\nthey suffer from a catastrophic accuracy drop, performing worse than even\nrandom sampling. This paper explores the reasons behind this accuracy drop both\ntheoretically and empirically. We first propose a novel metric to measure the\ncoverage of a dataset on a specific distribution by extending the classical\ngeometric set cover problem to a distribution cover problem. This metric helps\nexplain why coresets selected by SOTA methods at high pruning rates perform\npoorly compared to random sampling because of worse data coverage. We then\npropose a novel one-shot coreset selection method, Coverage-centric Coreset\nSelection (CCS), that jointly considers overall data coverage upon a\ndistribution as well as the importance of each example. We evaluate CCS on five\ndatasets and show that, at high pruning rates (e.g., 90%), it achieves\nsignificantly better accuracy than previous SOTA methods (e.g., at least 19.56%\nhigher on CIFAR10) as well as random selection (e.g., 7.04% higher on CIFAR10)\nand comparable accuracy at low pruning rates. We make our code publicly\navailable at\nhttps://github.com/haizhongzheng/Coverage-centric-coreset-selection.\n","authors":["Haizhong Zheng","Rui Liu","Fan Lai","Atul Prakash"],"pdf_url":"https://arxiv.org/pdf/2210.15809v2.pdf","comment":"International Conference on Learning Representations (ICLR) 2023"},{"id":"http://arxiv.org/abs/2303.02891v1","updated":"2023-03-06T04:49:38Z","published":"2023-03-06T04:49:38Z","title":"Perspectives on the Social Impacts of Reinforcement Learning with Human\n  Feedback","summary":"  Is it possible for machines to think like humans? And if it is, how should we\ngo about teaching them to do so? As early as 1950, Alan Turing stated that we\nought to teach machines in the way of teaching a child. Reinforcement learning\nwith human feedback (RLHF) has emerged as a strong candidate toward allowing\nagents to learn from human feedback in a naturalistic manner. RLHF is distinct\nfrom traditional reinforcement learning as it provides feedback from a human\nteacher in addition to a reward signal. It has been catapulted into public view\nby multiple high-profile AI applications, including OpenAI's ChatGPT,\nDeepMind's Sparrow, and Anthropic's Claude. These highly capable chatbots are\nalready overturning our understanding of how AI interacts with humanity. The\nwide applicability and burgeoning success of RLHF strongly motivate the need to\nevaluate its social impacts. In light of recent developments, this paper\nconsiders an important question: can RLHF be developed and used without\nnegatively affecting human societies? Our objectives are threefold: to provide\na systematic study of the social effects of RLHF; to identify key social and\nethical issues of RLHF; and to discuss social impacts for stakeholders.\nAlthough text-based applications of RLHF have received much attention, it is\ncrucial to consider when evaluating its social implications the diverse range\nof areas to which it may be deployed. We describe seven primary ways in which\nRLHF-based technologies will affect society by positively transforming human\nexperiences with AI. This paper ultimately proposes that RLHF has potential to\nnet positively impact areas of misinformation, AI value-alignment, bias, AI\naccess, cross-cultural dialogue, industry, and workforce. As RLHF raises\nconcerns that echo those of existing AI technologies, it will be important for\nall to be aware and intentional in the adoption of RLHF.\n","authors":["Gabrielle Kaili-May Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02890v1","updated":"2023-03-06T04:45:53Z","published":"2023-03-06T04:45:53Z","title":"An Analysis of Physics-Informed Neural Networks","summary":"  Whilst the partial differential equations that govern the dynamics of our\nworld have been studied in great depth for centuries, solving them for complex,\nhigh-dimensional conditions and domains still presents an incredibly large\nmathematical and computational challenge. Analytical methods can be cumbersome\nto utilise, and numerical methods can lead to errors and inaccuracies. On top\nof this, sometimes we lack the information or knowledge to pose the problem\nwell enough to apply these kinds of methods. Here, we present a new approach to\napproximating the solution to physical systems - physics-informed neural\nnetworks. The concept of artificial neural networks is introduced, the\nobjective function is defined, and optimisation strategies are discussed. The\npartial differential equation is then included as a constraint in the loss\nfunction for the optimisation problem, giving the network access to knowledge\nof the dynamics of the physical system it is modelling. Some intuitive examples\nare displayed, and more complex applications are considered to showcase the\npower of physics informed neural networks, such as in seismic imaging. Solution\nerror is analysed, and suggestions are made to improve convergence and/or\nsolution precision. Problems and limitations are also touched upon in the\nconclusions, as well as some thoughts as to where physics informed neural\nnetworks are most useful, and where they could go next.\n","authors":["Edward Small"],"pdf_url":"https://arxiv.org/pdf/2303.02890v1.pdf","comment":"56 pages"},{"id":"http://arxiv.org/abs/2303.02884v1","updated":"2023-03-06T04:31:36Z","published":"2023-03-06T04:31:36Z","title":"Model Sketching: Centering Concepts in Early-Stage Machine Learning\n  Model Design","summary":"  Machine learning practitioners often end up tunneling on low-level technical\ndetails like model architectures and performance metrics. Could early model\ndevelopment instead focus on high-level questions of which factors a model\nought to pay attention to? Inspired by the practice of sketching in design,\nwhich distills ideas to their minimal representation, we introduce model\nsketching: a technical framework for iteratively and rapidly authoring\nfunctional approximations of a machine learning model's decision-making logic.\nModel sketching refocuses practitioner attention on composing high-level,\nhuman-understandable concepts that the model is expected to reason over (e.g.,\nprofanity, racism, or sarcasm in a content moderation task) using zero-shot\nconcept instantiation. In an evaluation with 17 ML practitioners, model\nsketching reframed thinking from implementation to higher-level exploration,\nprompted iteration on a broader range of model designs, and helped identify\ngaps in the problem formulation$\\unicode{x2014}$all in a fraction of the time\nordinarily required to build a model.\n","authors":["Michelle S. Lam","Zixian Ma","Anne Li","Izequiel Freitas","Dakuo Wang","James A. Landay","Michael S. Bernstein"],"pdf_url":"https://arxiv.org/pdf/2303.02884v1.pdf","comment":"To appear at CHI 2023"},{"id":"http://arxiv.org/abs/2303.02883v1","updated":"2023-03-06T04:29:30Z","published":"2023-03-06T04:29:30Z","title":"Very fast, approximate counterfactual explanations for decision forests","summary":"  We consider finding a counterfactual explanation for a classification or\nregression forest, such as a random forest. This requires solving an\noptimization problem to find the closest input instance to a given instance for\nwhich the forest outputs a desired value. Finding an exact solution has a cost\nthat is exponential on the number of leaves in the forest. We propose a simple\nbut very effective approach: we constrain the optimization to only those input\nspace regions defined by the forest that are populated by actual data points.\nThe problem reduces to a form of nearest-neighbor search using a certain\ndistance on a certain dataset. This has two advantages: first, the solution can\nbe found very quickly, scaling to large forests and high-dimensional data, and\nenabling interactive use. Second, the solution found is more likely to be\nrealistic in that it is guided towards high-density areas of input space.\n","authors":["Miguel Á. Carreira-Perpiñán","Suryabhan Singh Hada"],"pdf_url":"https://arxiv.org/pdf/2303.02883v1.pdf","comment":"A shorter version of this paper appears in AAAI 2023"},{"id":"http://arxiv.org/abs/2303.02880v1","updated":"2023-03-06T04:15:29Z","published":"2023-03-06T04:15:29Z","title":"Spatiotemporal Capsule Neural Network for Vehicle Trajectory Prediction","summary":"  Through advancement of the Vehicle-to-Everything (V2X) network, road safety,\nenergy consumption, and traffic efficiency can be significantly improved. An\naccurate vehicle trajectory prediction benefits communication traffic\nmanagement and network resource allocation for the real-time application of the\nV2X network. Recurrent neural networks and their variants have been reported in\nrecent research to predict vehicle mobility. However, the spatial attribute of\nvehicle movement behavior has been overlooked, resulting in incomplete\ninformation utilization. To bridge this gap, we put forward for the first time\na hierarchical trajectory prediction structure using the capsule neural network\n(CapsNet) with three sequential components. First, the geographic information\nis transformed into a grid map presentation, describing vehicle mobility\ndistribution spatially and temporally. Second, CapsNet serves as the core model\nto embed local temporal and global spatial correlation through hierarchical\ncapsules. Finally, extensive experiments conducted on actual taxi mobility data\ncollected in Porto city (Portugal) and Singapore show that the proposed method\noutperforms the state-of-the-art methods.\n","authors":["Yan Qin","Yong Liang Guan","Chau Yuen"],"pdf_url":"https://arxiv.org/pdf/2303.02880v1.pdf","comment":"IEEE TVT has accepted this paper"},{"id":"http://arxiv.org/abs/2303.02879v1","updated":"2023-03-06T04:14:04Z","published":"2023-03-06T04:14:04Z","title":"A Review of Deep Learning-Powered Mesh Reconstruction Methods","summary":"  With the recent advances in hardware and rendering techniques, 3D models have\nemerged everywhere in our life. Yet creating 3D shapes is arduous and requires\nsignificant professional knowledge. Meanwhile, Deep learning has enabled\nhigh-quality 3D shape reconstruction from various sources, making it a viable\napproach to acquiring 3D shapes with minimal effort. Importantly, to be used in\ncommon 3D applications, the reconstructed shapes need to be represented as\npolygonal meshes, which is a challenge for neural networks due to the\nirregularity of mesh tessellations. In this survey, we provide a comprehensive\nreview of mesh reconstruction methods that are powered by machine learning. We\nfirst describe various representations for 3D shapes in the deep learning\ncontext. Then we review the development of 3D mesh reconstruction methods from\nvoxels, point clouds, single images, and multi-view images. Finally, we\nidentify several challenges in this field and propose potential future\ndirections.\n","authors":["Zhiqin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.02879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01240v2","updated":"2023-03-06T04:10:12Z","published":"2023-03-01T11:37:43Z","title":"The Point to Which Soft Actor-Critic Converges","summary":"  Soft actor-critic is a successful successor over soft Q-learning. While lived\nunder maximum entropy framework, their relationship is still unclear. In this\npaper, we prove that in the limit they converge to the same solution. This is\nappealing since it translates the optimization from an arduous to an easier\nway. The same justification can also be applied to other regularizers such as\nKL divergence.\n","authors":["Jianfei Ma"],"pdf_url":"https://arxiv.org/pdf/2303.01240v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02876v1","updated":"2023-03-06T04:04:19Z","published":"2023-03-06T04:04:19Z","title":"Finding metastable skyrmionic structures via a metaheuristic\n  perturbation-driven neural network","summary":"  Topological magnetic textures observed in experiments can, in principle, be\npredicted by theoretical calculations and numerical simulations. However, such\ncalculations are, in general, hampered by difficulties in distinguishing\nbetween local and global energy minima. This becomes particularly problematic\nfor magnetic materials that allow for a multitude of topological charges.\nFinding solutions to such problems by means of classical numerical methods can\nbe challenging because either a good initial guess or a gigantic amount of\nrandom sampling is required. In this study, we demonstrate an efficient way to\nidentify those metastable configurations by leveraging the power of gradient\ndescent-based optimization within the framework of a feedforward neural network\ncombined with a heuristic meta-search, which is driven by a random perturbation\nof the neural network's input. We exemplify the power of the method by an\nanalysis of the Pd/Fe/Ir(111) system, an experimentally well characterized\nsystem.\n","authors":["Qichen Xu","I. P. Miranda","Manuel Pereiro","Filipp N. Rybakov","Danny Thonig","Erik Sjöqvist","Pavel Bessarab","Anders Bergman","Olle Eriksson","Pawel Herman","Anna Delin"],"pdf_url":"https://arxiv.org/pdf/2303.02876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02875v1","updated":"2023-03-06T04:01:28Z","published":"2023-03-06T04:01:28Z","title":"DR-Label: Improving GNN Models for Catalysis Systems by Label\n  Deconstruction and Reconstruction","summary":"  Attaining the equilibrium state of a catalyst-adsorbate system is key to\nfundamentally assessing its effective properties, such as adsorption energy.\nMachine learning methods with finer supervision strategies have been applied to\nboost and guide the relaxation process of an atomic system and better predict\nits properties at the equilibrium state. In this paper, we present a novel\ngraph neural network (GNN) supervision and prediction strategy DR-Label. The\nmethod enhances the supervision signal, reduces the multiplicity of solutions\nin edge representation, and encourages the model to provide node predictions\nthat are graph structural variation robust. DR-Label first Deconstructs\nfiner-grained equilibrium state information to the model by projecting the\nnode-level supervision signal to each edge. Reversely, the model Reconstructs a\nmore robust equilibrium state prediction by transforming edge-level predictions\nto node-level with a sphere-fitting algorithm. The DR-Label strategy was\napplied to three radically distinct models, each of which displayed consistent\nperformance enhancements. Based on the DR-Label strategy, we further proposed\nDRFormer, which achieved a new state-of-the-art performance on the Open\nCatalyst 2020 (OC20) dataset and the Cu-based single-atom-alloyed CO adsorption\n(SAA) dataset. We expect that our work will highlight crucial steps for the\ndevelopment of a more accurate model in equilibrium state property prediction\nof a catalysis system.\n","authors":["Bowen Wang","Chen Liang","Jiaze Wang","Furui Liu","Shaogang Hao","Dong Li","Jianye Hao","Guangyong Chen","Xiaolong Zou","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2303.02875v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.02874v1","updated":"2023-03-06T03:55:37Z","published":"2023-03-06T03:55:37Z","title":"Adversarial Sampling for Fairness Testing in Deep Neural Network","summary":"  In this research, we focus on the usage of adversarial sampling to test for\nthe fairness in the prediction of deep neural network model across different\nclasses of image in a given dataset. While several framework had been proposed\nto ensure robustness of machine learning model against adversarial attack, some\nof which includes adversarial training algorithm. There is still the pitfall\nthat adversarial training algorithm tends to cause disparity in accuracy and\nrobustness among different group. Our research is aimed at using adversarial\nsampling to test for fairness in the prediction of deep neural network model\nacross different classes or categories of image in a given dataset. We\nsuccessfully demonstrated a new method of ensuring fairness across various\ngroup of input in deep neural network classifier. We trained our neural network\nmodel on the original image, and without training our model on the perturbed or\nattacked image. When we feed the adversarial samplings to our model, it was\nable to predict the original category/ class of the image the adversarial\nsample belongs to. We also introduced and used the separation of concern\nconcept from software engineering whereby there is an additional standalone\nfilter layer that filters perturbed image by heavily removing the noise or\nattack before automatically passing it to the network for classification, we\nwere able to have accuracy of 93.3%. Cifar-10 dataset have ten categories of\ndataset, and so, in order to account for fairness, we applied our hypothesis\nacross each categories of dataset and were able to get a consistent result and\naccuracy.\n","authors":["Tosin Ige","William Marfo","Justin Tonkinson","Sikiru Adewale","Bolanle Hafiz Matti"],"pdf_url":"https://arxiv.org/pdf/2303.02874v1.pdf","comment":"7 pages, 5 figures, International Journal of Advanced Computer\n  Science and Application"},{"id":"http://arxiv.org/abs/2206.08289v2","updated":"2023-03-06T03:54:50Z","published":"2022-06-16T16:46:32Z","title":"Switchable Representation Learning Framework with Self-compatibility","summary":"  Real-world visual search systems involve deployments on multiple platforms\nwith different computing and storage resources. Deploying a unified model that\nsuits the minimal-constrain platforms leads to limited accuracy. It is expected\nto deploy models with different capacities adapting to the resource\nconstraints, which requires features extracted by these models to be aligned in\nthe metric space. The method to achieve feature alignments is called\n``compatible learning''. Existing research mainly focuses on the one-to-one\ncompatible paradigm, which is limited in learning compatibility among multiple\nmodels. We propose a \\textbf{S}witchable representation learning Framework with\nSelf-Compatibility (SFSC). SFSC generates a series of compatible sub-models\nwith different capacities through one training process. The optimization of\nsub-models faces gradients conflict, and we mitigate this problem from the\nperspective of the magnitude and direction. We adjust the priorities of\nsub-models dynamically through uncertainty estimation to co-optimize sub-models\nproperly. Besides, the gradients with conflicting directions are projected to\navoid mutual interference. SFSC achieves state-of-the-art performance on the\nevaluated datasets.\n","authors":["Shengsen Wu","Yan Bai","Yihang Lou","Xiongkun Linghu","Jianzhong He","Ling-Yu Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08289v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01506v2","updated":"2023-03-06T03:41:17Z","published":"2023-03-02T04:50:05Z","title":"Understanding and Unifying Fourteen Attribution Methods with Taylor\n  Interactions","summary":"  Various attribution methods have been developed to explain deep neural\nnetworks (DNNs) by inferring the attribution/importance/contribution score of\neach input variable to the final output. However, existing attribution methods\nare often built upon different heuristics. There remains a lack of a unified\ntheoretical understanding of why these methods are effective and how they are\nrelated. To this end, for the first time, we formulate core mechanisms of\nfourteen attribution methods, which were designed on different heuristics, into\nthe same mathematical system, i.e., the system of Taylor interactions.\nSpecifically, we prove that attribution scores estimated by fourteen\nattribution methods can all be reformulated as the weighted sum of two types of\neffects, i.e., independent effects of each individual input variable and\ninteraction effects between input variables. The essential difference among the\nfourteen attribution methods mainly lies in the weights of allocating different\neffects. Based on the above findings, we propose three principles for a fair\nallocation of effects to evaluate the faithfulness of the fourteen attribution\nmethods.\n","authors":["Huiqi Deng","Na Zou","Mengnan Du","Weifu Chen","Guocan Feng","Ziwei Yang","Zheyang Li","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.01506v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02868v1","updated":"2023-03-06T03:36:26Z","published":"2023-03-06T03:36:26Z","title":"Angel-PTM: A Scalable and Economical Large-scale Pre-training System in\n  Tencent","summary":"  Recent years have witnessed the unprecedented achievements of large-scale\npre-trained models, especially the Transformer models. Many products and\nservices in Tencent Inc., such as WeChat, QQ, and Tencent Advertisement, have\nbeen opted in to gain the power of pre-trained models. In this work, we present\nAngel-PTM, a productive deep learning system designed for pre-training and\nfine-tuning Transformer models. Angel-PTM can train extremely large-scale\nmodels with hierarchical memory efficiently. The key designs of Angel-PTM are\nthe fine-grained memory management via the Page abstraction and a unified\nscheduling method that coordinate the computations, data movements, and\ncommunications. Furthermore, Angel-PTM supports extreme model scaling with SSD\nstorage and implements the lock-free updating mechanism to address the SSD I/O\nbandwidth bottlenecks. Experimental results demonstrate that Angel-PTM\noutperforms existing systems by up to 114.8% in terms of maximum model scale as\nwell as up to 88.9% in terms of training throughput. Additionally, experiments\non GPT3-175B and T5-MoE-1.2T models utilizing hundreds of GPUs verify the\nstrong scalability of Angel-PTM.\n","authors":["Xiaonan Nie","Yi Liu","Fangcheng Fu","Jinbao Xue","Dian Jiao","Xupeng Miao","Yangyu Tao","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2303.02868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02110v2","updated":"2023-03-06T03:26:43Z","published":"2023-03-03T17:51:08Z","title":"Need for Objective Task-based Evaluation of Deep Learning-Based\n  Denoising Methods: A Study in the Context of Myocardial Perfusion SPECT","summary":"  Artificial intelligence-based methods have generated substantial interest in\nnuclear medicine. An area of significant interest has been using deep-learning\n(DL)-based approaches for denoising images acquired with lower doses, shorter\nacquisition times, or both. Objective evaluation of these approaches is\nessential for clinical application. DL-based approaches for denoising\nnuclear-medicine images have typically been evaluated using fidelity-based\nfigures of merit (FoMs) such as RMSE and SSIM. However, these images are\nacquired for clinical tasks and thus should be evaluated based on their\nperformance in these tasks. Our objectives were to (1) investigate whether\nevaluation with these FoMs is consistent with objective clinical-task-based\nevaluation; (2) provide a theoretical analysis for determining the impact of\ndenoising on signal-detection tasks; (3) demonstrate the utility of virtual\nclinical trials (VCTs) to evaluate DL-based methods. A VCT to evaluate a\nDL-based method for denoising myocardial perfusion SPECT (MPS) images was\nconducted. The impact of DL-based denoising was evaluated using fidelity-based\nFoMs and AUC, which quantified performance on detecting perfusion defects in\nMPS images as obtained using a model observer with anthropomorphic channels.\nBased on fidelity-based FoMs, denoising using the considered DL-based method\nled to significantly superior performance. However, based on ROC analysis,\ndenoising did not improve, and in fact, often degraded detection-task\nperformance. The results motivate the need for objective task-based evaluation\nof DL-based denoising approaches. Further, this study shows how VCTs provide a\nmechanism to conduct such evaluations using VCTs. Finally, our theoretical\ntreatment reveals insights into the reasons for the limited performance of the\ndenoising approach.\n","authors":["Zitong Yu","Md Ashequr Rahman","Richard Laforest","Thomas H. Schindler","Robert J. Gropler","Richard L. Wahl","Barry A. Siegel","Abhinav K. Jha"],"pdf_url":"https://arxiv.org/pdf/2303.02110v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02860v1","updated":"2023-03-06T03:25:43Z","published":"2023-03-06T03:25:43Z","title":"A Multi-Grained Self-Interpretable Symbolic-Neural Model For\n  Single/Multi-Labeled Text Classification","summary":"  Deep neural networks based on layer-stacking architectures have historically\nsuffered from poor inherent interpretability. Meanwhile, symbolic probabilistic\nmodels function with clear interpretability, but how to combine them with\nneural networks to enhance their performance remains to be explored. In this\npaper, we try to marry these two systems for text classification via a\nstructured language model. We propose a Symbolic-Neural model that can learn to\nexplicitly predict class labels of text spans from a constituency tree without\nrequiring any access to span-level gold labels. As the structured language\nmodel learns to predict constituency trees in a self-supervised manner, only\nraw texts and sentence-level labels are required as training data, which makes\nit essentially a general constituent-level self-interpretable classification\nmodel. Our experiments demonstrate that our approach could achieve good\nprediction accuracy in downstream tasks. Meanwhile, the predicted span labels\nare consistent with human rationales to a certain degree.\n","authors":["Xiang Hu","Xinyu Kong","Kewei Tu"],"pdf_url":"https://arxiv.org/pdf/2303.02860v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02859v1","updated":"2023-03-06T03:25:30Z","published":"2023-03-06T03:25:30Z","title":"Bayesian inference with finitely wide neural networks","summary":"  The analytic inference, e.g. predictive distribution being in closed form,\nmay be an appealing benefit for machine learning practitioners when they treat\nwide neural networks as Gaussian process in Bayesian setting. The realistic\nwidths, however, are finite and cause weak deviation from the Gaussianity under\nwhich partial marginalization of random variables in a model is\nstraightforward. On the basis of multivariate Edgeworth expansion, we propose a\nnon-Gaussian distribution in differential form to model a finite set of outputs\nfrom a random neural network, and derive the corresponding marginal and\nconditional properties. Thus, we are able to derive the non-Gaussian posterior\ndistribution in Bayesian regression task. In addition, in the bottlenecked deep\nneural networks, a weight space representation of deep Gaussian process, the\nnon-Gaussianity is investigated through the marginal kernel.\n","authors":["Chi-Ken Lu"],"pdf_url":"https://arxiv.org/pdf/2303.02859v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2302.13221v2","updated":"2023-03-06T02:56:19Z","published":"2023-02-26T03:18:45Z","title":"Data-Centric AI: Deep Generative Differentiable Feature Selection via\n  Discrete Subsetting as Continuous Embedding Space Optimization","summary":"  Feature Selection (FS), such as filter, wrapper, and embedded methods, aims\nto find the optimal feature subset for a given downstream task. However, in\nmany real-world practices, 1) the criteria of FS vary across domains; 2) FS is\nbrittle when data is a high-dimensional and small sample size. Can selected\nfeature subsets be more generalized, accurate, and input dimensionality\nagnostic? We generalize this problem into a deep differentiable feature\nselection task and propose a new perspective: discrete feature subsetting as\ncontinuous embedding space optimization. We develop a generic and principled\nframework including a deep feature subset encoder, accuracy evaluator, decoder,\nand gradient ascent optimizer. This framework implements four steps: 1)\nfeatures-accuracy training data preparation; 2) deep feature subset embedding;\n3) gradient-optimized search; 4) feature subset reconstruction. We develop new\ntechnical insights: reinforcement as a training data generator, ensembles of\ndiverse peer and exploratory feature selector knowledge for generalization, an\neffective embedding from feature subsets to continuous space along with joint\noptimizing reconstruction and accuracy losses to select accurate features.\nExperimental results demonstrate the effectiveness of the proposed method.\n","authors":["Meng Xiao","Dongjie Wang","Min Wu","Pengfei Wang","Yuanchun Zhou","Yanjie Fu"],"pdf_url":"https://arxiv.org/pdf/2302.13221v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2203.01850v3","updated":"2023-03-06T02:49:45Z","published":"2022-03-03T16:58:54Z","title":"T-Cal: An optimal test for the calibration of predictive models","summary":"  The prediction accuracy of machine learning methods is steadily increasing,\nbut the calibration of their uncertainty predictions poses a significant\nchallenge. Numerous works focus on obtaining well-calibrated predictive models,\nbut less is known about reliably assessing model calibration. This limits our\nability to know when algorithms for improving calibration have a real effect,\nand when their improvements are merely artifacts due to random noise in finite\ndatasets. In this work, we consider detecting mis-calibration of predictive\nmodels using a finite validation dataset as a hypothesis testing problem. The\nnull hypothesis is that the predictive model is calibrated, while the\nalternative hypothesis is that the deviation from calibration is sufficiently\nlarge.\n  We find that detecting mis-calibration is only possible when the conditional\nprobabilities of the classes are sufficiently smooth functions of the\npredictions. When the conditional class probabilities are H\\\"older continuous,\nwe propose T-Cal, a minimax optimal test for calibration based on a debiased\nplug-in estimator of the $\\ell_2$-Expected Calibration Error (ECE). We further\npropose Adaptive T-Cal, a version that is adaptive to unknown smoothness. We\nverify our theoretical findings with a broad range of experiments, including\nwith several popular deep neural net architectures and several standard\npost-hoc calibration methods. T-Cal is a practical general-purpose tool, which\n-- combined with classical tests for discrete-valued predictors -- can be used\nto test the calibration of virtually any probabilistic classification method.\n","authors":["Donghwan Lee","Xinmeng Huang","Hamed Hassani","Edgar Dobriban"],"pdf_url":"https://arxiv.org/pdf/2203.01850v3.pdf","comment":"The implementation of T-Cal is available at\n  https://github.com/dh7401/T-Cal"},{"id":"http://arxiv.org/abs/2303.02844v1","updated":"2023-03-06T02:47:31Z","published":"2023-03-06T02:47:31Z","title":"Knowledge-embedded meta-learning model for lift coefficient prediction\n  of airfoils","summary":"  Aerodynamic performance evaluation is an important part of the aircraft\naerodynamic design optimization process; however, traditional methods are\ncostly and time-consuming. Despite the fact that various machine learning\nmethods can achieve high accuracy, their application in engineering is still\ndifficult due to their poor generalization performance and \"black box\" nature.\nIn this paper, a knowledge-embedded meta learning model, which fully integrates\ndata with the theoretical knowledge of the lift curve, is developed to obtain\nthe lift coefficients of an arbitrary supercritical airfoil under various angle\nof attacks. In the proposed model, a primary network is responsible for\nrepresenting the relationship between the lift and angle of attack, while the\ngeometry information is encoded into a hyper network to predict the unknown\nparameters involved in the primary network. Specifically, three models with\ndifferent architectures are trained to provide various interpretations.\nCompared to the ordinary neural network, our proposed model can exhibit better\ngeneralization capability with competitive prediction accuracy. Afterward,\ninterpretable analysis is performed based on the Integrated Gradients and\nSaliency methods. Results show that the proposed model can tend to assess the\ninfluence of airfoil geometry to the physical characteristics. Furthermore, the\nexceptions and shortcomings caused by the proposed model are analysed and\ndiscussed in detail.\n","authors":["Hairun Xie","Jing Wang","Miao Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.08345v2","updated":"2023-03-06T02:46:59Z","published":"2022-10-15T17:36:04Z","title":"Augmentation-Free Graph Contrastive Learning of Invariant-Discriminative\n  Representations","summary":"  The pretasks are mainly built on mutual information estimation, which\nrequires data augmentation to construct positive samples with similar semantics\nto learn invariant signals and negative samples with dissimilar semantics in\norder to empower representation discriminability. However, an appropriate data\naugmentation configuration depends heavily on lots of empirical trials such as\nchoosing the compositions of data augmentation techniques and the corresponding\nhyperparameter settings. We propose an augmentation-free graph contrastive\nlearning method, invariant-discriminative graph contrastive learning (iGCL),\nthat does not intrinsically require negative samples. iGCL designs the\ninvariant-discriminative loss (ID loss) to learn invariant and discriminative\nrepresentations. On the one hand, ID loss learns invariant signals by directly\nminimizing the mean square error between the target samples and positive\nsamples in the representation space. On the other hand, ID loss ensures that\nthe representations are discriminative by an orthonormal constraint forcing the\ndifferent dimensions of representations to be independent of each other. This\nprevents representations from collapsing to a point or subspace. Our\ntheoretical analysis explains the effectiveness of ID loss from the\nperspectives of the redundancy reduction criterion, canonical correlation\nanalysis, and information bottleneck principle. The experimental results\ndemonstrate that iGCL outperforms all baselines on 5 node classification\nbenchmark datasets. iGCL also shows superior performance for different label\nratios and is capable of resisting graph attacks, which indicates that iGCL has\nexcellent generalization and robustness. The source code is available at\nhttps://github.com/lehaifeng/T-GCN/tree/master/iGCL.\n","authors":["Haifeng Li","Jun Cao","Jiawei Zhu","Qinyao Luo","Silu He","Xuyin Wang"],"pdf_url":"https://arxiv.org/pdf/2210.08345v2.pdf","comment":"11 pages 8 figs"},{"id":"http://arxiv.org/abs/2211.05631v2","updated":"2023-03-06T02:31:54Z","published":"2022-11-02T15:39:19Z","title":"Backdoor Defense via Suppressing Model Shortcuts","summary":"  Recent studies have demonstrated that deep neural networks (DNNs) are\nvulnerable to backdoor attacks during the training process. Specifically, the\nadversaries intend to embed hidden backdoors in DNNs so that malicious model\npredictions can be activated through pre-defined trigger patterns. In this\npaper, we explore the backdoor mechanism from the angle of the model structure.\nWe select the skip connection for discussions, inspired by the understanding\nthat it helps the learning of model `shortcuts' where backdoor triggers are\nusually easier to be learned. Specifically, we demonstrate that the attack\nsuccess rate (ASR) decreases significantly when reducing the outputs of some\nkey skip connections. Based on this observation, we design a simple yet\neffective backdoor removal method by suppressing the skip connections in\ncritical layers selected by our method. We also implement fine-tuning on these\nlayers to recover high benign accuracy and to further reduce ASR. Extensive\nexperiments on benchmark datasets verify the effectiveness of our method.\n","authors":["Sheng Yang","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.05631v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2211.01806v2","updated":"2023-03-06T02:26:40Z","published":"2022-11-02T16:03:43Z","title":"BATT: Backdoor Attack with Transformation-based Triggers","summary":"  Deep neural networks (DNNs) are vulnerable to backdoor attacks. The backdoor\nadversaries intend to maliciously control the predictions of attacked DNNs by\ninjecting hidden backdoors that can be activated by adversary-specified trigger\npatterns during the training process. One recent research revealed that most of\nthe existing attacks failed in the real physical world since the trigger\ncontained in the digitized test samples may be different from that of the one\nused for training. Accordingly, users can adopt spatial transformations as the\nimage pre-processing to deactivate hidden backdoors. In this paper, we explore\nthe previous findings from another side. We exploit classical spatial\ntransformations (i.e. rotation and translation) with the specific parameter as\ntrigger patterns to design a simple yet effective poisoning-based backdoor\nattack. For example, only images rotated to a particular angle can activate the\nembedded backdoor of attacked DNNs. Extensive experiments are conducted,\nverifying the effectiveness of our attack under both digital and physical\nsettings and its resistance to existing backdoor defenses.\n","authors":["Tong Xu","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.01806v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2303.02841v1","updated":"2023-03-06T02:24:48Z","published":"2023-03-06T02:24:48Z","title":"Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in\n  Finance","summary":"  Natural language understanding(NLU) is challenging for finance due to the\nlack of annotated data and the specialized language in that domain. As a\nresult, researchers have proposed to use pre-trained language model and\nmulti-task learning to learn robust representations. However, aggressive\nfine-tuning often causes over-fitting and multi-task learning may favor tasks\nwith significantly larger amounts data, etc. To address these problems, in this\npaper, we investigate model-agnostic meta-learning algorithm(MAML) in\nlow-resource financial NLU tasks. Our contribution includes: 1. we explore the\nperformance of MAML method with multiple types of tasks: GLUE datasets, SNLI,\nSci-Tail and Financial PhraseBank; 2. we study the performance of MAML method\nwith multiple single-type tasks: a real scenario stock price prediction problem\nwith twitter text data. Our models achieve the state-of-the-art performance\naccording to the experimental results, which demonstrate that our method can\nadapt fast and well to low-resource situations.\n","authors":["Bixing Yan","Shaoling Chen","Yuxuan He","Zhihan Li"],"pdf_url":"https://arxiv.org/pdf/2303.02841v1.pdf","comment":"13 pages, 6 figures, 8 tables"},{"id":"http://arxiv.org/abs/2211.05638v2","updated":"2023-03-06T02:20:32Z","published":"2022-11-02T17:05:45Z","title":"Untargeted Backdoor Attack against Object Detection","summary":"  Recent studies revealed that deep neural networks (DNNs) are exposed to\nbackdoor threats when training with third-party resources (such as training\nsamples or backbones). The backdoored model has promising performance in\npredicting benign samples, whereas its predictions can be maliciously\nmanipulated by adversaries based on activating its backdoors with pre-defined\ntrigger patterns. Currently, most of the existing backdoor attacks were\nconducted on the image classification under the targeted manner. In this paper,\nwe reveal that these threats could also happen in object detection, posing\nthreatening risks to many mission-critical applications ($e.g.$, pedestrian\ndetection and intelligent surveillance systems). Specifically, we design a\nsimple yet effective poison-only backdoor attack in an untargeted manner, based\non task characteristics. We show that, once the backdoor is embedded into the\ntarget model by our attack, it can trick the model to lose detection of any\nobject stamped with our trigger patterns. We conduct extensive experiments on\nthe benchmark dataset, showing its effectiveness in both digital and\nphysical-world settings and its resistance to potential defenses.\n","authors":["Chengxiao Luo","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.05638v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2103.01400v4","updated":"2023-03-06T02:05:31Z","published":"2021-03-02T01:27:16Z","title":"Smoothness Analysis of Adversarial Training","summary":"  Deep neural networks are vulnerable to adversarial attacks. Recent studies\nabout adversarial robustness focus on the loss landscape in the parameter space\nsince it is related to optimization and generalization performance. These\nstudies conclude that the difficulty of adversarial training is caused by the\nnon-smoothness of the loss function: i.e., its gradient is not Lipschitz\ncontinuous. However, this analysis ignores the dependence of adversarial\nattacks on model parameters. Since adversarial attacks are optimized for\nmodels, they should depend on the parameters. Considering this dependence, we\nanalyze the smoothness of the loss function of adversarial training using the\noptimal attacks for the model parameter in more detail. We reveal that the\nconstraint of adversarial attacks is one cause of the non-smoothness and that\nthe smoothness depends on the types of the constraints. Specifically, the\n$L_\\infty$ constraint can cause non-smoothness more than the $L_2$ constraint.\nMoreover, our analysis implies that if we flatten the loss function with\nrespect to input data, the Lipschitz constant of the gradient of adversarial\nloss tends to increase. To address the non-smoothness, we show that EntropySGD\nsmoothens the non-smooth loss and improves the performance of adversarial\ntraining.\n","authors":["Sekitoshi Kanai","Masanori Yamada","Hiroshi Takahashi","Yuki Yamanaka","Yasutoshi Ida"],"pdf_url":"https://arxiv.org/pdf/2103.01400v4.pdf","comment":"The latest version of this article is published in IEEE Transactions\n  on Neural Networks and Learning Systems (DOI: 10.1109/TNNLS.2023.3244172). 22\n  pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.02833v1","updated":"2023-03-06T01:59:45Z","published":"2023-03-06T01:59:45Z","title":"eCDANs: Efficient Temporal Causal Discovery from Autocorrelated and\n  Non-stationary Data (Student Abstract)","summary":"  Conventional temporal causal discovery (CD) methods suffer from high\ndimensionality, fail to identify lagged causal relationships, and often ignore\ndynamics in relations. In this study, we present a novel constraint-based CD\napproach for autocorrelated and non-stationary time series data (eCDANs)\ncapable of detecting lagged and contemporaneous causal relationships along with\ntemporal changes. eCDANs addresses high dimensionality by optimizing the\nconditioning sets while conducting conditional independence (CI) tests and\nidentifies the changes in causal relations by introducing a surrogate variable\nto represent time dependency. Experiments on synthetic and real-world data show\nthat eCDANs can identify time influence and outperform the baselines.\n","authors":["Muhammad Hasan Ferdous","Uzma Hasan","Md Osman Gani"],"pdf_url":"https://arxiv.org/pdf/2303.02833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12987v2","updated":"2023-03-06T01:54:22Z","published":"2023-01-30T15:29:40Z","title":"The Optimal Choice of Hypothesis Is the Weakest, Not the Shortest","summary":"  If $A$ and $B$ are sets such that $A \\subset B$, generalisation may be\nunderstood as the inference from $A$ of a hypothesis sufficient to construct\n$B$. One might infer any number of hypotheses from $A$, yet only some of those\nmay generalise to $B$. How can one know which are likely to generalise? One\nstrategy is to choose the shortest, equating the ability to compress\ninformation with the ability to generalise (a proxy for intelligence). We\nexamine this in the context of a mathematical formalism of enactive cognition.\nWe show that compression is neither necessary nor sufficient to maximise\nperformance (measured in terms of the probability of a hypothesis\ngeneralising). We formulate a proxy unrelated to length or simplicity, called\nweakness. We show that if tasks are uniformly distributed, then there is no\nchoice of proxy that performs at least as well as weakness maximisation in all\ntasks while performing strictly better in at least one. In other words,\nweakness is the pareto optimal choice of proxy. In experiments comparing\nmaximum weakness and minimum description length in the context of binary\narithmetic, the former generalised at between $1.1$ and $5$ times the rate of\nthe latter. We argue this demonstrates that weakness is a far better proxy, and\nexplains why Deepmind's Apperception Engine is able to generalise effectively.\n","authors":["Michael Timothy Bennett"],"pdf_url":"https://arxiv.org/pdf/2301.12987v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02829v1","updated":"2023-03-06T01:46:51Z","published":"2023-03-06T01:46:51Z","title":"Attribution-Scores and Causal Counterfactuals as Explanations in\n  Artificial Intelligence","summary":"  In this expository article we highlight the relevance of explanations for\nartificial intelligence, in general, and for the newer developments in {\\em\nexplainable AI}, referring to origins and connections of and among different\napproaches. We describe in simple terms, explanations in data management and\nmachine learning that are based on attribution-scores, and counterfactuals as\nfound in the area of causality. We elaborate on the importance of logical\nreasoning when dealing with counterfactuals, and their use for score\ncomputation.\n","authors":["Leopoldo Bertossi"],"pdf_url":"https://arxiv.org/pdf/2303.02829v1.pdf","comment":"Submitted as chapter contribution"},{"id":"http://arxiv.org/abs/2303.02828v1","updated":"2023-03-06T01:45:32Z","published":"2023-03-06T01:45:32Z","title":"Robust Autoencoders for Collective Corruption Removal","summary":"  Robust PCA is a standard tool for learning a linear subspace in the presence\nof sparse corruption or rare outliers. What about robustly learning manifolds\nthat are more realistic models for natural data, such as images? There have\nbeen several recent attempts to generalize robust PCA to manifold settings. In\nthis paper, we propose $\\ell_1$- and scaling-invariant $\\ell_1/\\ell_2$-robust\nautoencoders based on a surprisingly compact formulation built on the intuition\nthat deep autoencoders perform manifold learning. We demonstrate on several\nstandard image datasets that the proposed formulation significantly outperforms\nall previous methods in collectively removing sparse corruption, without clean\nimages for training. Moreover, we also show that the learned manifold\nstructures can be generalized to unseen data samples effectively.\n","authors":["Taihui Li","Hengkang Wang","Peng Le","XianE Tang","Ju Sun"],"pdf_url":"https://arxiv.org/pdf/2303.02828v1.pdf","comment":"This paper has been accepted to ICASSP2023"},{"id":"http://arxiv.org/abs/2211.07740v3","updated":"2023-03-06T01:35:21Z","published":"2022-11-14T20:35:11Z","title":"Denoising diffusion models for out-of-distribution detection","summary":"  Out-of-distribution detection is crucial to the safe deployment of machine\nlearning systems. Currently, unsupervised out-of-distribution detection is\ndominated by generative-based approaches that make use of estimates of the\nlikelihood or other measurements from a generative model. Reconstruction-based\nmethods offer an alternative approach, in which a measure of reconstruction\nerror is used to determine if a sample is out-of-distribution. However,\nreconstruction-based approaches are less favoured, as they require careful\ntuning of the model's information bottleneck - such as the size of the latent\ndimension - to produce good results. In this work, we exploit the view of\ndenoising diffusion probabilistic models (DDPM) as denoising autoencoders where\nthe bottleneck is controlled externally, by means of the amount of noise\napplied. We propose to use DDPMs to reconstruct an input that has been noised\nto a range of noise levels, and use the resulting multi-dimensional\nreconstruction error to classify out-of-distribution inputs. We validate our\napproach both on standard computer-vision datasets and on higher dimension\nmedical datasets. Our approach outperforms not only reconstruction-based\nmethods, but also state-of-the-art generative-based approaches.\n","authors":["Mark S. Graham","Walter H. L. Pinaya","Petru-Daniel Tudosiu","Parashkev Nachev","Sebastien Ourselin","M. Jorge Cardoso"],"pdf_url":"https://arxiv.org/pdf/2211.07740v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10866v2","updated":"2023-03-06T01:26:15Z","published":"2023-02-21T18:29:25Z","title":"Hyena Hierarchy: Towards Larger Convolutional Language Models","summary":"  Recent advances in deep learning have relied heavily on the use of large\nTransformers due to their ability to learn at scale. However, the core building\nblock of Transformers, the attention operator, exhibits quadratic cost in\nsequence length, limiting the amount of context accessible. Existing\nsubquadratic methods based on low-rank and sparse approximations need to be\ncombined with dense attention layers to match Transformers, indicating a gap in\ncapability. In this work, we propose Hyena, a subquadratic drop-in replacement\nfor attention constructed by interleaving implicitly parametrized long\nconvolutions and data-controlled gating. In recall and reasoning tasks on\nsequences of thousands to hundreds of thousands of tokens, Hyena improves\naccuracy by more than 50 points over operators relying on state-spaces and\nother implicit and explicit methods, matching attention-based models. We set a\nnew state-of-the-art for dense-attention-free architectures on language\nmodeling in standard datasets (WikiText103 and The Pile), reaching Transformer\nquality with a 20% reduction in training compute required at sequence length\n2K. Hyena operators are twice as fast as highly optimized attention at sequence\nlength 8K, and 100x faster at sequence length 64K.\n","authors":["Michael Poli","Stefano Massaroli","Eric Nguyen","Daniel Y. Fu","Tri Dao","Stephen Baccus","Yoshua Bengio","Stefano Ermon","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2302.10866v2.pdf","comment":"Additional results (PG-19, LAMBADA)"},{"id":"http://arxiv.org/abs/2210.05367v2","updated":"2023-03-06T01:23:14Z","published":"2022-10-10T16:49:49Z","title":"Learning Explicit Credit Assignment for Cooperative Multi-Agent\n  Reinforcement Learning via Polarization Policy Gradient","summary":"  Cooperative multi-agent policy gradient (MAPG) algorithms have recently\nattracted wide attention and are regarded as a general scheme for the\nmulti-agent system. Credit assignment plays an important role in MAPG and can\ninduce cooperation among multiple agents. However, most MAPG algorithms cannot\nachieve good credit assignment because of the game-theoretic pathology known as\n\\textit{centralized-decentralized mismatch}. To address this issue, this paper\npresents a novel method, \\textit{\\underline{M}ulti-\\underline{A}gent\n\\underline{P}olarization \\underline{P}olicy \\underline{G}radient} (MAPPG).\nMAPPG takes a simple but efficient polarization function to transform the\noptimal consistency of joint and individual actions into easily realized\nconstraints, thus enabling efficient credit assignment in MAPG. Theoretically,\nwe prove that individual policies of MAPPG can converge to the global optimum.\nEmpirically, we evaluate MAPPG on the well-known matrix game and differential\ngame, and verify that MAPPG can converge to the global optimum for both\ndiscrete and continuous action spaces. We also evaluate MAPPG on a set of\nStarCraft II micromanagement tasks and demonstrate that MAPPG outperforms the\nstate-of-the-art MAPG algorithms.\n","authors":["Wubing Chen","Wenbin Li","Xiao Liu","Shangdong Yang","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2210.05367v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02814v1","updated":"2023-03-06T01:01:56Z","published":"2023-03-06T01:01:56Z","title":"Visual Analytics of Neuron Vulnerability to Adversarial Attacks on\n  Convolutional Neural Networks","summary":"  Adversarial attacks on a convolutional neural network (CNN) -- injecting\nhuman-imperceptible perturbations into an input image -- could fool a\nhigh-performance CNN into making incorrect predictions. The success of\nadversarial attacks raises serious concerns about the robustness of CNNs, and\nprevents them from being used in safety-critical applications, such as medical\ndiagnosis and autonomous driving. Our work introduces a visual analytics\napproach to understanding adversarial attacks by answering two questions: (1)\nwhich neurons are more vulnerable to attacks and (2) which image features do\nthese vulnerable neurons capture during the prediction? For the first question,\nwe introduce multiple perturbation-based measures to break down the attacking\nmagnitude into individual CNN neurons and rank the neurons by their\nvulnerability levels. For the second, we identify image features (e.g., cat\nears) that highly stimulate a user-selected neuron to augment and validate the\nneuron's responsibility. Furthermore, we support an interactive exploration of\na large number of neurons by aiding with hierarchical clustering based on the\nneurons' roles in the prediction. To this end, a visual analytics system is\ndesigned to incorporate visual reasoning for interpreting adversarial attacks.\nWe validate the effectiveness of our system through multiple case studies as\nwell as feedback from domain experts.\n","authors":["Yiran Li","Junpeng Wang","Takanori Fujiwara","Kwan-Liu Ma"],"pdf_url":"https://arxiv.org/pdf/2303.02814v1.pdf","comment":"Accepted by the Special Issue on Human-Centered Explainable AI, ACM\n  Transactions on Interactive Intelligent Systems"},{"id":"http://arxiv.org/abs/2206.01874v2","updated":"2023-03-06T01:00:13Z","published":"2022-06-04T01:59:31Z","title":"An Unpooling Layer for Graph Generation","summary":"  We propose a novel and trainable graph unpooling layer for effective graph\ngeneration. Given a graph with features, the unpooling layer enlarges this\ngraph and learns its desired new structure and features. Since this unpooling\nlayer is trainable, it can be applied to graph generation either in the decoder\nof a variational autoencoder or in the generator of a generative adversarial\nnetwork (GAN). We prove that the unpooled graph remains connected and any\nconnected graph can be sequentially unpooled from a 3-nodes graph. We apply the\nunpooling layer within the GAN generator. Since the most studied instance of\ngraph generation is molecular generation, we test our ideas in this context.\nUsing the QM9 and ZINC datasets, we demonstrate the improvement obtained by\nusing the unpooling layer instead of an adjacency-matrix-based approach.\n","authors":["Yinglong Guo","Dongmian Zou","Gilad Lerman"],"pdf_url":"https://arxiv.org/pdf/2206.01874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.10475v2","updated":"2023-03-06T00:49:01Z","published":"2022-05-21T00:58:22Z","title":"DeepStruct: Pretraining of Language Models for Structure Prediction","summary":"  We introduce a method for improving the structural understanding abilities of\nlanguage models. Unlike previous approaches that finetune the models with\ntask-specific augmentation, we pretrain language models on a collection of\ntask-agnostic corpora to generate structures from text. Our structure\npretraining enables zero-shot transfer of the learned knowledge that models\nhave about the structure tasks. We study the performance of this approach on 28\ndatasets, spanning 10 structure prediction tasks including open information\nextraction, joint entity and relation extraction, named entity recognition,\nrelation classification, semantic role labeling, event extraction, coreference\nresolution, factual probe, intent detection, and dialogue state tracking. We\nfurther enhance the pretraining with the task-specific training sets. We show\nthat a 10B parameter language model transfers non-trivially to most tasks and\nobtains state-of-the-art performance on 21 of 28 datasets that we evaluate.\n","authors":["Chenguang Wang","Xiao Liu","Zui Chen","Haoyun Hong","Jie Tang","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2205.10475v2.pdf","comment":"ACL 2022"},{"id":"http://arxiv.org/abs/2102.04615v2","updated":"2023-03-06T00:29:14Z","published":"2021-02-09T02:50:29Z","title":"Benford's law: what does it say on adversarial images?","summary":"  Convolutional neural networks (CNNs) are fragile to small perturbations in\nthe input images. These networks are thus prone to malicious attacks that\nperturb the inputs to force a misclassification. Such slightly manipulated\nimages aimed at deceiving the classifier are known as adversarial images. In\nthis work, we investigate statistical differences between natural images and\nadversarial ones. More precisely, we show that employing a proper image\ntransformation and for a class of adversarial attacks, the distribution of the\nleading digit of the pixels in adversarial images deviates from Benford's law.\nThe stronger the attack, the more distant the resulting distribution is from\nBenford's law. Our analysis provides a detailed investigation of this new\napproach that can serve as a basis for alternative adversarial example\ndetection methods that do not need to modify the original CNN classifier\nneither work on the raw high-dimensional pixels as features to defend against\nattacks.\n","authors":["João G. Zago","Fabio L. Baldissera","Eric A. Antonelo","Rodrigo T. Saad"],"pdf_url":"https://arxiv.org/pdf/2102.04615v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01275v2","updated":"2023-03-06T00:26:43Z","published":"2023-02-02T18:05:27Z","title":"ReLOAD: Reinforcement Learning with Optimistic Ascent-Descent for\n  Last-Iterate Convergence in Constrained MDPs","summary":"  In recent years, Reinforcement Learning (RL) has been applied to real-world\nproblems with increasing success. Such applications often require to put\nconstraints on the agent's behavior. Existing algorithms for constrained RL\n(CRL) rely on gradient descent-ascent, but this approach comes with a caveat.\nWhile these algorithms are guaranteed to converge on average, they do not\nguarantee last-iterate convergence, i.e., the current policy of the agent may\nnever converge to the optimal solution. In practice, it is often observed that\nthe policy alternates between satisfying the constraints and maximizing the\nreward, rarely accomplishing both objectives simultaneously. Here, we address\nthis problem by introducing Reinforcement Learning with Optimistic\nAscent-Descent (ReLOAD), a principled CRL method with guaranteed last-iterate\nconvergence. We demonstrate its empirical effectiveness on a wide variety of\nCRL problems including discrete MDPs and continuous control. In the process we\nestablish a benchmark of challenging CRL problems.\n","authors":["Ted Moskovitz","Brendan O'Donoghue","Vivek Veeriah","Sebastian Flennerhag","Satinder Singh","Tom Zahavy"],"pdf_url":"https://arxiv.org/pdf/2302.01275v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12495v2","updated":"2023-03-06T23:49:42Z","published":"2023-01-29T17:18:59Z","title":"Time-Series Pattern Recognition in Smart Manufacturing Systems: A\n  Literature Review and Ontology","summary":"  Since the inception of Industry 4.0 in 2012, emerging technologies have\nenabled the acquisition of vast amounts of data from diverse sources such as\nmachine tools, robust and affordable sensor systems with advanced information\nmodels, and other sources within Smart Manufacturing Systems (SMS). As a\nresult, the amount of data that is available in manufacturing settings has\nexploded, allowing data-hungry tools such as Artificial Intelligence (AI) and\nMachine Learning (ML) to be leveraged. Time-series analytics has been\nsuccessfully applied in a variety of industries, and that success is now being\nmigrated to pattern recognition applications in manufacturing to support higher\nquality products, zero defect manufacturing, and improved customer\nsatisfaction. However, the diverse landscape of manufacturing presents a\nchallenge for successfully solving problems in industry using time-series\npattern recognition. The resulting research gap of understanding and applying\nthe subject matter of time-series pattern recognition in manufacturing is a\nmajor limiting factor for adoption in industry. The purpose of this paper is to\nprovide a structured perspective of the current state of time-series pattern\nrecognition in manufacturing with a problem-solving focus. By using an ontology\nto classify and define concepts, how they are structured, their properties, the\nrelationships between them, and considerations when applying them, this paper\naims to provide practical and actionable guidelines for application and\nrecommendations for advancing time-series analytics.\n","authors":["Mojtaba A. Farahani","M. R. McCormick","Robert Gianinny","Frank Hudacheck","Ramy Harik","Zhichao Liu","Thorsten Wuest"],"pdf_url":"https://arxiv.org/pdf/2301.12495v2.pdf","comment":"40 pages, 35 figures, 21 tables, submitted to Elsevier"},{"id":"http://arxiv.org/abs/2303.03553v1","updated":"2023-03-06T23:37:58Z","published":"2023-03-06T23:37:58Z","title":"Robust Dominant Periodicity Detection for Time Series with Missing Data","summary":"  Periodicity detection is an important task in time series analysis, but still\na challenging problem due to the diverse characteristics of time series data\nlike abrupt trend change, outlier, noise, and especially block missing data. In\nthis paper, we propose a robust and effective periodicity detection algorithm\nfor time series with block missing data. We first design a robust trend filter\nto remove the interference of complicated trend patterns under missing data.\nThen, we propose a robust autocorrelation function (ACF) that can handle\nmissing values and outliers effectively. We rigorously prove that the proposed\nrobust ACF can still work well when the length of the missing block is less\nthan $1/3$ of the period length. Last, by combining the time-frequency\ninformation, our algorithm can generate the period length accurately. The\nexperimental results demonstrate that our algorithm outperforms existing\nperiodicity detection algorithms on real-world time series datasets.\n","authors":["Qingsong Wen","Linxiao Yang","Liang Sun"],"pdf_url":"https://arxiv.org/pdf/2303.03553v1.pdf","comment":"Accepted by 2023 IEEE International Conference on Acoustics, Speech\n  and Signal Processing (ICASSP 2023)"},{"id":"http://arxiv.org/abs/2107.14317v2","updated":"2023-03-06T23:34:18Z","published":"2021-07-29T20:31:03Z","title":"Temporal Dependencies in Feature Importance for Time Series Predictions","summary":"  Time series data introduces two key challenges for explainability methods:\nfirstly, observations of the same feature over subsequent time steps are not\nindependent, and secondly, the same feature can have varying importance to\nmodel predictions over time. In this paper, we propose Windowed Feature\nImportance in Time (WinIT), a feature removal based explainability approach to\naddress these issues. Unlike existing feature removal explanation methods,\nWinIT explicitly accounts for the temporal dependence between different\nobservations of the same feature in the construction of its importance score.\nFurthermore, WinIT captures the varying importance of a feature over time, by\nsummarizing its importance over a window of past time steps. We conduct an\nextensive empirical study on synthetic and real-world data, compare against a\nwide range of leading explainability methods, and explore the impact of various\nevaluation strategies. Our results show that WinIT achieves significant gains\nover existing methods, with more consistent performance across different\nevaluation metrics. The code for our work is publicly available at\n\\url{https://github.com/layer6ai-labs/WinIT}.\n","authors":["Kin Kwan Leung","Clayton Rooke","Jonathan Smith","Saba Zuberi","Maksims Volkovs"],"pdf_url":"https://arxiv.org/pdf/2107.14317v2.pdf","comment":"International Conference on Learning Representations 2023 (ICLR'23)"},{"id":"http://arxiv.org/abs/2112.12542v5","updated":"2023-03-06T23:26:47Z","published":"2021-12-22T05:41:50Z","title":"How Much Space Has Been Explored? Measuring the Chemical Space Covered\n  by Databases and Machine-Generated Molecules","summary":"  Forming a molecular candidate set that contains a wide range of potentially\neffective compounds is crucial to the success of drug discovery. While most\ndatabases and machine-learning-based generation models aim to optimize\nparticular chemical properties, there is limited literature on how to properly\nmeasure the coverage of the chemical space by those candidates included or\ngenerated. This problem is challenging due to the lack of formal criteria to\nselect good measures of the chemical space. In this paper, we propose a novel\nevaluation framework for measures of the chemical space based on two analyses:\nan axiomatic analysis with three intuitive axioms that a good measure should\nobey, and an empirical analysis on the correlation between a measure and a\nproxy gold standard. Using this framework, we are able to identify #Circles, a\nnew measure of chemical space coverage, which is superior to existing measures\nboth analytically and empirically. We further evaluate how well the existing\ndatabases and generation models cover the chemical space in terms of #Circles.\nThe results suggest that many generation models fail to explore a larger space\nover existing databases, which leads to new opportunities for improving\ngeneration models by encouraging exploration.\n","authors":["Yutong Xie","Ziqiao Xu","Jiaqi Ma","Qiaozhu Mei"],"pdf_url":"https://arxiv.org/pdf/2112.12542v5.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2209.14860v2","updated":"2023-03-06T23:19:17Z","published":"2022-09-29T15:24:47Z","title":"Bridging the Gap to Real-World Object-Centric Learning","summary":"  Humans naturally decompose their environment into entities at the appropriate\nlevel of abstraction to act in the world. Allowing machine learning algorithms\nto derive this decomposition in an unsupervised way has become an important\nline of research. However, current methods are restricted to simulated data or\nrequire additional information in the form of motion or depth in order to\nsuccessfully discover objects. In this work, we overcome this limitation by\nshowing that reconstructing features from models trained in a self-supervised\nmanner is a sufficient training signal for object-centric representations to\narise in a fully unsupervised way. Our approach, DINOSAUR, significantly\nout-performs existing image-based object-centric learning models on simulated\ndata and is the first unsupervised object-centric model that scales to\nreal-world datasets such as COCO and PASCAL VOC. DINOSAUR is conceptually\nsimple and shows competitive performance compared to more involved pipelines\nfrom the computer vision literature.\n","authors":["Maximilian Seitzer","Max Horn","Andrii Zadaianchuk","Dominik Zietlow","Tianjun Xiao","Carl-Johann Simon-Gabriel","Tong He","Zheng Zhang","Bernhard Schölkopf","Thomas Brox","Francesco Locatello"],"pdf_url":"https://arxiv.org/pdf/2209.14860v2.pdf","comment":"ICLR 2023 camera-ready version"},{"id":"http://arxiv.org/abs/2303.03548v1","updated":"2023-03-06T23:16:24Z","published":"2023-03-06T23:16:24Z","title":"Large Language Models as Zero-Shot Human Models for Human-Robot\n  Interaction","summary":"  Human models play a crucial role in human-robot interaction (HRI), enabling\nrobots to consider the impact of their actions on people and plan their\nbehavior accordingly. However, crafting good human models is challenging;\ncapturing context-dependent human behavior requires significant prior knowledge\nand/or large amounts of interaction data, both of which are difficult to\nobtain. In this work, we explore the potential of large-language models (LLMs)\n-- which have consumed vast amounts of human-generated text data -- to act as\nzero-shot human models for HRI. Our experiments on three social datasets yield\npromising results; the LLMs are able to achieve performance comparable to\npurpose-built models. That said, we also discuss current limitations, such as\nsensitivity to prompts and spatial/numerical reasoning mishaps. Based on our\nfindings, we demonstrate how LLM-based human models can be integrated into a\nsocial robot's planning process and applied in HRI scenarios. Specifically, we\npresent one case study on a simulated trust-based table-clearing task and\nreplicate past results that relied on custom models. Next, we conduct a new\nrobot utensil-passing experiment (n = 65) where preliminary results show that\nplanning with a LLM-based human model can achieve gains over a basic myopic\nplan. In summary, our results show that LLMs offer a promising (but incomplete)\napproach to human modeling for HRI.\n","authors":["Bowen Zhang","Harold Soh"],"pdf_url":"https://arxiv.org/pdf/2303.03548v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2212.06132v2","updated":"2023-03-06T23:13:30Z","published":"2022-12-12T18:58:59Z","title":"Nearly Minimax Optimal Reinforcement Learning for Linear Markov Decision\n  Processes","summary":"  We study reinforcement learning (RL) with linear function approximation. For\nepisodic time-inhomogeneous linear Markov decision processes (linear MDPs)\nwhose transition dynamic can be parameterized as a linear function of a given\nfeature mapping, we propose the first computationally efficient algorithm that\nachieves the nearly minimax optimal regret $\\tilde O(d\\sqrt{H^3K})$, where $d$\nis the dimension of the feature mapping, $H$ is the planning horizon, and $K$\nis the number of episodes. Our algorithm is based on a weighted linear\nregression scheme with a carefully designed weight, which depends on a new\nvariance estimator that (1) directly estimates the variance of the\n\\emph{optimal} value function, (2) monotonically decreases with respect to the\nnumber of episodes to ensure a better estimation accuracy, and (3) uses a\nrare-switching policy to update the value function estimator to control the\ncomplexity of the estimated value function class. Our work provides a complete\nanswer to optimal RL with linear MDPs, and the developed algorithm and\ntheoretical tools may be of independent interest.\n","authors":["Jiafan He","Heyang Zhao","Dongruo Zhou","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2212.06132v2.pdf","comment":"44 pages, 1 table"},{"id":"http://arxiv.org/abs/2302.00845v2","updated":"2023-03-06T23:04:27Z","published":"2023-02-02T03:15:29Z","title":"Scale up with Order: Finding Good Data Permutations for Distributed\n  Training","summary":"  Gradient Balancing (GraB) is a recently proposed technique that finds\nprovably better data permutations when training models with multiple epochs\nover a finite dataset. It converges at a faster rate than the widely adopted\nRandom Reshuffling, by minimizing the discrepancy of the gradients on\nadjacently selected examples. However, GraB only operates under critical\nassumptions such as small batch sizes and centralized data, leaving open the\nquestion of how to order examples at large scale -- i.e. distributed learning\nwith decentralized data. To alleviate the limitation, in this paper we propose\nD-GraB, an algorithm that orders the examples in a parallel setting with\nnegligible overhead, which enjoys linear speed up at rate\n$\\tilde{O}((mnT)^{-2/3})$ on smooth non-convex objectives and\n$\\tilde{O}((mnT)^{-2})$ under PL condition, where $n$ denotes the number of\nparallel workers, $m$ denotes the number of examples per worker and $T$ denotes\nthe number of epochs. D-GraB benefits from both data ordering and parallelism.\nEmpirically, we show on various applications including GLUE, CIFAR10 and\nWikiText-2 that D-GraB outperforms naive parallel GraB and Distributed Random\nReshuffling in terms of both training and validation performance.\n","authors":["Wentao Guo","Khiem Pham","Yucheng Lu","Tiancheng Yuan","Charlie F. Ruan","Christopher De Sa"],"pdf_url":"https://arxiv.org/pdf/2302.00845v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03544v1","updated":"2023-03-06T23:01:53Z","published":"2023-03-06T23:01:53Z","title":"Expressivity of Shallow and Deep Neural Networks for Polynomial\n  Approximation","summary":"  We analyze the number of neurons that a ReLU neural network needs to\napproximate multivariate monomials. We establish an exponential lower bound for\nthe complexity of any shallow network that approximates the product function\n$\\vec{x} \\to \\prod_{i=1}^d x_i$ on a general compact domain. Furthermore, we\nprove that this lower bound does not hold for normalized O(1)-Lipschitz\nmonomials (or equivalently, by restricting to the unit cube). These results\nsuggest shallow ReLU networks suffer from the curse of dimensionality when\nexpressing functions with a Lipschitz parameter scaling with the dimension of\nthe input, and that the expressive power of neural networks lies in their depth\nrather than the overall complexity.\n","authors":["Itai Shapira"],"pdf_url":"https://arxiv.org/pdf/2303.03544v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2303.03543v1","updated":"2023-03-06T23:01:43Z","published":"2023-03-06T23:01:43Z","title":"3D Equivariant Diffusion for Target-Aware Molecule Generation and\n  Affinity Prediction","summary":"  Rich data and powerful machine learning models allow us to design drugs for a\nspecific protein target \\textit{in silico}. Recently, the inclusion of 3D\nstructures during targeted drug design shows superior performance to other\ntarget-free models as the atomic interaction in the 3D space is explicitly\nmodeled. However, current 3D target-aware models either rely on the voxelized\natom densities or the autoregressive sampling process, which are not\nequivariant to rotation or easily violate geometric constraints resulting in\nunrealistic structures. In this work, we develop a 3D equivariant diffusion\nmodel to solve the above challenges. To achieve target-aware molecule design,\nour method learns a joint generative process of both continuous atom\ncoordinates and categorical atom types with a SE(3)-equivariant network.\nMoreover, we show that our model can serve as an unsupervised feature extractor\nto estimate the binding affinity under proper parameterization, which provides\nan effective way for drug screening. To evaluate our model, we propose a\ncomprehensive framework to evaluate the quality of sampled molecules from\ndifferent dimensions. Empirical studies show our model could generate molecules\nwith more realistic 3D structures and better affinities towards the protein\ntargets, and improve binding affinity ranking and prediction without\nretraining.\n","authors":["Jiaqi Guan","Wesley Wei Qian","Xingang Peng","Yufeng Su","Jian Peng","Jianzhu Ma"],"pdf_url":"https://arxiv.org/pdf/2303.03543v1.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2206.02914v2","updated":"2023-03-06T22:55:36Z","published":"2022-06-06T21:31:32Z","title":"Training Subset Selection for Weak Supervision","summary":"  Existing weak supervision approaches use all the data covered by weak signals\nto train a classifier. We show both theoretically and empirically that this is\nnot always optimal. Intuitively, there is a tradeoff between the amount of\nweakly-labeled data and the precision of the weak labels. We explore this\ntradeoff by combining pretrained data representations with the cut statistic\n(Muhlenbach et al., 2004) to select (hopefully) high-quality subsets of the\nweakly-labeled training data. Subset selection applies to any label model and\nclassifier and is very simple to plug in to existing weak supervision\npipelines, requiring just a few lines of code. We show our subset selection\nmethod improves the performance of weak supervision for a wide range of label\nmodels, classifiers, and datasets. Using less weakly-labeled data improves the\naccuracy of weak supervision pipelines by up to 19% (absolute) on benchmark\ntasks.\n","authors":["Hunter Lang","Aravindan Vijayaraghavan","David Sontag"],"pdf_url":"https://arxiv.org/pdf/2206.02914v2.pdf","comment":"NeurIPS 2022"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2303.03378v1","updated":"2023-03-06T18:58:06Z","published":"2023-03-06T18:58:06Z","title":"PaLM-E: An Embodied Multimodal Language Model","summary":"  Large language models excel at a wide range of complex tasks. However,\nenabling general inference in the real world, e.g., for robotics problems,\nraises the challenge of grounding. We propose embodied language models to\ndirectly incorporate real-world continuous sensor modalities into language\nmodels and thereby establish the link between words and percepts. Input to our\nembodied language model are multi-modal sentences that interleave visual,\ncontinuous state estimation, and textual input encodings. We train these\nencodings end-to-end, in conjunction with a pre-trained large language model,\nfor multiple embodied tasks including sequential robotic manipulation planning,\nvisual question answering, and captioning. Our evaluations show that PaLM-E, a\nsingle large embodied multimodal model, can address a variety of embodied\nreasoning tasks, from a variety of observation modalities, on multiple\nembodiments, and further, exhibits positive transfer: the model benefits from\ndiverse joint training across internet-scale language, vision, and\nvisual-language domains. Our largest model, PaLM-E-562B with 562B parameters,\nin addition to being trained on robotics tasks, is a visual-language generalist\nwith state-of-the-art performance on OK-VQA, and retains generalist language\ncapabilities with increasing scale.\n","authors":["Danny Driess","Fei Xia","Mehdi S. M. Sajjadi","Corey Lynch","Aakanksha Chowdhery","Brian Ichter","Ayzaan Wahid","Jonathan Tompson","Quan Vuong","Tianhe Yu","Wenlong Huang","Yevgen Chebotar","Pierre Sermanet","Daniel Duckworth","Sergey Levine","Vincent Vanhoucke","Karol Hausman","Marc Toussaint","Klaus Greff","Andy Zeng","Igor Mordatch","Pete Florence"],"pdf_url":"https://arxiv.org/pdf/2303.03378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03349v1","updated":"2023-03-06T18:35:34Z","published":"2023-03-06T18:35:34Z","title":"Scenario-Agnostic Zero-Trust Defense with Explainable Threshold Policy:\n  A Meta-Learning Approach","summary":"  The increasing connectivity and intricate remote access environment have made\ntraditional perimeter-based network defense vulnerable. Zero trust becomes a\npromising approach to provide defense policies based on agent-centric trust\nevaluation. However, the limited observations of the agent's trace bring\ninformation asymmetry in the decision-making. To facilitate the human\nunderstanding of the policy and the technology adoption, one needs to create a\nzero-trust defense that is explainable to humans and adaptable to different\nattack scenarios. To this end, we propose a scenario-agnostic zero-trust\ndefense based on Partially Observable Markov Decision Processes (POMDP) and\nfirst-order Meta-Learning using only a handful of sample scenarios. The\nframework leads to an explainable and generalizable trust-threshold defense\npolicy. To address the distribution shift between empirical security datasets\nand reality, we extend the model to a robust zero-trust defense minimizing the\nworst-case loss. We use case studies and real-world attacks to corroborate the\nresults.\n","authors":["Yunfei Ge","Tao Li","Quanyan Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.03349v1.pdf","comment":"GY and TL contributed equally to this work; 7 figures, three tables;\n  accepted to INFOCOM AidTSP 2023"},{"id":"http://arxiv.org/abs/2303.03348v1","updated":"2023-03-06T18:35:16Z","published":"2023-03-06T18:35:16Z","title":"Thompson Sampling for Linear Bandit Problems with Normal-Gamma Priors","summary":"  We consider Thompson sampling for linear bandit problems with finitely many\nindependent arms, where rewards are sampled from normal distributions that are\nlinearly dependent on unknown parameter vectors and with unknown variance.\nSpecifically, with a Bayesian formulation we consider multivariate normal-gamma\npriors to represent environment uncertainty for all involved parameters. We\nshow that our chosen sampling prior is a conjugate prior to the reward model\nand derive a Bayesian regret bound for Thompson sampling under the condition\nthat the 5/2-moment of the variance distribution exist.\n","authors":["Björn Lindenberg","Karl-Olof Lindahl"],"pdf_url":"https://arxiv.org/pdf/2303.03348v1.pdf","comment":"27 pages, 2 figures"},{"id":"http://arxiv.org/abs/2209.12152v3","updated":"2023-03-06T18:28:18Z","published":"2022-09-25T05:21:59Z","title":"All are Worth Words: A ViT Backbone for Diffusion Models","summary":"  Vision transformers (ViT) have shown promise in various vision tasks while\nthe U-Net based on a convolutional neural network (CNN) remains dominant in\ndiffusion models. We design a simple and general ViT-based architecture (named\nU-ViT) for image generation with diffusion models. U-ViT is characterized by\ntreating all inputs including the time, condition and noisy image patches as\ntokens and employing long skip connections between shallow and deep layers. We\nevaluate U-ViT in unconditional and class-conditional image generation, as well\nas text-to-image generation tasks, where U-ViT is comparable if not superior to\na CNN-based U-Net of a similar size. In particular, latent diffusion models\nwith U-ViT achieve record-breaking FID scores of 2.29 in class-conditional\nimage generation on ImageNet 256x256, and 5.48 in text-to-image generation on\nMS-COCO, among methods without accessing large external datasets during the\ntraining of generative models. Our results suggest that, for diffusion-based\nimage modeling, the long skip connection is crucial while the down-sampling and\nup-sampling operators in CNN-based U-Net are not always necessary. We believe\nthat U-ViT can provide insights for future research on backbones in diffusion\nmodels and benefit generative modeling on large scale cross-modality datasets.\n","authors":["Fan Bao","Shen Nie","Kaiwen Xue","Yue Cao","Chongxuan Li","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2209.12152v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03341v1","updated":"2023-03-06T18:21:16Z","published":"2023-03-06T18:21:16Z","title":"Deep Age-Invariant Fingerprint Segmentation System","summary":"  Fingerprint-based identification systems achieve higher accuracy when a slap\ncontaining multiple fingerprints of a subject is used instead of a single\nfingerprint. However, segmenting or auto-localizing all fingerprints in a slap\nimage is a challenging task due to the different orientations of fingerprints,\nnoisy backgrounds, and the smaller size of fingertip components. The presence\nof slap images in a real-world dataset where one or more fingerprints are\nrotated makes it challenging for a biometric recognition system to localize and\nlabel the fingerprints automatically. Improper fingerprint localization and\nfinger labeling errors lead to poor matching performance. In this paper, we\nintroduce a method to generate arbitrary angled bounding boxes using a deep\nlearning-based algorithm that precisely localizes and labels fingerprints from\nboth axis-aligned and over-rotated slap images. We built a fingerprint\nsegmentation model named CRFSEG (Clarkson Rotated Fingerprint segmentation\nModel) by updating the previously proposed CFSEG model which was based on\ntraditional Faster R-CNN architecture [21]. CRFSEG improves upon the Faster\nR-CNN algorithm with arbitrarily angled bounding boxes that allow the CRFSEG to\nperform better in challenging slap images. After training the CRFSEG algorithm\non a new dataset containing slap images collected from both adult and children\nsubjects, our results suggest that the CRFSEG model was invariant across\ndifferent age groups and can handle over-rotated slap images successfully. In\nthe Combined dataset containing both normal and rotated images of adult and\nchildren subjects, we achieved a matching accuracy of 97.17%, which\noutperformed state-of-the-art VeriFinger (94.25%) and NFSEG segmentation\nsystems (80.58%).\n","authors":["M. G. Sarwar Murshed","Keivan Bahmani","Stephanie Schuckers","Faraz Hussain"],"pdf_url":"https://arxiv.org/pdf/2303.03341v1.pdf","comment":"20 Pages, 14 figures, Journal"},{"id":"http://arxiv.org/abs/2303.03338v1","updated":"2023-03-06T18:10:00Z","published":"2023-03-06T18:10:00Z","title":"Optimizing L1 cache for embedded systems through grammatical evolution","summary":"  Nowadays, embedded systems are provided with cache memories that are large\nenough to influence in both performance and energy consumption as never\noccurred before in this kind of systems. In addition, the cache memory system\nhas been identified as a component that improves those metrics by adapting its\nconfiguration according to the memory access patterns of the applications being\nrun. However, given that cache memories have many parameters which may be set\nto a high number of different values, designers face to a wide and\ntime-consuming exploration space. In this paper we propose an optimization\nframework based on Grammatical Evolution (GE) which is able to efficiently find\nthe best cache configurations for a given set of benchmark applications. This\nmetaheuristic allows an important reduction of the optimization runtime\nobtaining good results in a low number of generations. Besides, this reduction\nis also increased due to the efficient storage of evaluated caches. Moreover,\nwe selected GE because the plasticity of the grammar eases the creation of\nphenotypes that form the call to the cache simulator required for the\nevaluation of the different configurations. Experimental results for the\nMediabench suite show that our proposal is able to find cache configurations\nthat obtain an average improvement of $62\\%$ versus a real world baseline\nconfiguration.\n","authors":["Josefa Díaz Álvarez","J. Manuel Colmenar","José L. Risco-Martín","Juan Lanchares","Oscar Garnica"],"pdf_url":"https://arxiv.org/pdf/2303.03338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03324v1","updated":"2023-03-06T17:52:35Z","published":"2023-03-06T17:52:35Z","title":"Time series anomaly detection with sequence reconstruction based\n  state-space model","summary":"  Recent advances in digitization has led to availability of multivariate time\nseries data in various domains, in order to monitor operations in real time.\nIdentifying abnormal data pattern and detect potential failures in these\nscenarios are important yet rather difficult tasks. We propose a novel\nunsupervised anomaly detection method for time series data. Our approach uses\nsequence encoder and decoder to represent the mapping between time series and\nhidden state, and learns bidirectional dynamics simultaneously by leveraging\nbackward and forward temporal information in the training process. We further\nregularize the state space to place constraints on states of normal samples,\nand use Mahalanobis distance to evaluate abnormality level. Results on\nsynthetic and real-world datasets show the superiority of the proposed method.\n","authors":["Fan Wang","Keli Wang","Boyu Yao"],"pdf_url":"https://arxiv.org/pdf/2303.03324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03323v1","updated":"2023-03-06T17:48:32Z","published":"2023-03-06T17:48:32Z","title":"CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive\n  Learning","summary":"  Multimodal contrastive pretraining has been utilized to train multimodal\nrepresentation models, like CLIP, on vast amounts of paired image-text data.\nHowever, previous studies have highlighted the susceptibility of such models to\nbackdoor attacks. Specifically, when training on backdoored examples, CLIP\nlearns spurious correlations between the embedded backdoor trigger and the\ntarget label, aligning their representations in the joint embedding space. With\ninjecting only a few poisoned examples e.g., 75 examples in the 3M pretraining\ndata, the model's behavior can be significantly manipulated, thus making it\nhard to detect or unlearn such correlations. To address this issue, we propose\nCleanCLIP, a finetuning framework that weakens the learned spurious\nassociations introduced by backdoor attacks by re-aligning the representations\nfor individual modalities independently. CleanCLIP can be employed for both\nunsupervised finetuning on paired image-text data and for supervised finetuning\non labeled image data. We demonstrate that unsupervised finetuning with a\ncombination of multimodal contrastive and unimodal self-supervised objectives\nfor individual modalities can significantly reduce the impact of the backdoor\nattack. Additionally, supervised finetuning on task-specific labeled data of\nthe individual modality, such as image data, removes the backdoor trigger from\nthe CLIP vision encoder. Empirically, we show that CleanCLIP maintains model\nperformance on benign examples while mitigating the impact of a range of\nbackdoor attacks on multimodal contrastive learning.\n","authors":["Hritik Bansal","Nishad Singhi","Yu Yang","Fan Yin","Aditya Grover","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03323v1.pdf","comment":"20 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2303.03321v1","updated":"2023-03-06T17:48:27Z","published":"2023-03-06T17:48:27Z","title":"Implementation of a noisy hyperlink removal system: A semantic and\n  relatedness approach","summary":"  As the volume of data on the web grows, the web structure graph, which is a\ngraph representation of the web, continues to evolve. The structure of this\ngraph has gradually shifted from content-based to non-content-based.\nFurthermore, spam data, such as noisy hyperlinks, in the web structure graph\nadversely affect the speed and efficiency of information retrieval and link\nmining algorithms. Previous works in this area have focused on removing noisy\nhyperlinks using structural and string approaches. However, these approaches\nmay incorrectly remove useful links or be unable to detect noisy hyperlinks in\ncertain circumstances. In this paper, a data collection of hyperlinks is\ninitially constructed using an interactive crawler. The semantic and\nrelatedness structure of the hyperlinks is then studied through semantic web\napproaches and tools such as the DBpedia ontology. Finally, the removal process\nof noisy hyperlinks is carried out using a reasoner on the DBpedia ontology.\nOur experiments demonstrate the accuracy and ability of semantic web\ntechnologies to remove noisy hyperlinks\n","authors":["Kazem Taghandiki","Elnaz Rezaei Ehsan"],"pdf_url":"https://arxiv.org/pdf/2303.03321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03315v1","updated":"2023-03-06T17:38:03Z","published":"2023-03-06T17:38:03Z","title":"MACARONS: Mapping And Coverage Anticipation with RGB Online\n  Self-Supervision","summary":"  We introduce a method that simultaneously learns to explore new large\nenvironments and to reconstruct them in 3D from color images only. This is\nclosely related to the Next Best View problem (NBV), where one has to identify\nwhere to move the camera next to improve the coverage of an unknown scene.\nHowever, most of the current NBV methods rely on depth sensors, need 3D\nsupervision and/or do not scale to large scenes. Our method requires only a\ncolor camera and no 3D supervision. It simultaneously learns in a\nself-supervised fashion to predict a \"volume occupancy field\" from color images\nand, from this field, to predict the NBV. Thanks to this approach, our method\nperforms well on new scenes as it is not biased towards any training 3D data.\nWe demonstrate this on a recent dataset made of various 3D scenes and show it\nperforms even better than recent methods requiring a depth sensor, which is not\na realistic assumption for outdoor scenes captured with a flying drone.\n","authors":["Antoine Guédon","Tom Monnier","Pascal Monasse","Vincent Lepetit"],"pdf_url":"https://arxiv.org/pdf/2303.03315v1.pdf","comment":"To appear at CVPR 2023. Project Webpage:\n  https://imagine.enpc.fr/~guedona/MACARONS/"},{"id":"http://arxiv.org/abs/2206.03669v3","updated":"2023-03-06T17:32:15Z","published":"2022-06-08T04:09:13Z","title":"Toward Certified Robustness Against Real-World Distribution Shifts","summary":"  We consider the problem of certifying the robustness of deep neural networks\nagainst real-world distribution shifts. To do so, we bridge the gap between\nhand-crafted specifications and realistic deployment settings by proposing a\nnovel neural-symbolic verification framework, in which we train a generative\nmodel to learn perturbations from data and define specifications with respect\nto the output of the learned model. A unique challenge arising from this\nsetting is that existing verifiers cannot tightly approximate sigmoid\nactivations, which are fundamental to many state-of-the-art generative models.\nTo address this challenge, we propose a general meta-algorithm for handling\nsigmoid activations which leverages classical notions of counter-example-guided\nabstraction refinement. The key idea is to \"lazily\" refine the abstraction of\nsigmoid functions to exclude spurious counter-examples found in the previous\nabstraction, thus guaranteeing progress in the verification process while\nkeeping the state-space small. Experiments on the MNIST and CIFAR-10 datasets\nshow that our framework significantly outperforms existing methods on a range\nof challenging distribution shifts.\n","authors":["Haoze Wu","Teruhiro Tagomori","Alexander Robey","Fengjun Yang","Nikolai Matni","George Pappas","Hamed Hassani","Corina Pasareanu","Clark Barrett"],"pdf_url":"https://arxiv.org/pdf/2206.03669v3.pdf","comment":"SatML'23. Keywords: certified robustness, distribution shift,\n  generative models, S-shaped activations, CEGAR"},{"id":"http://arxiv.org/abs/2209.08212v3","updated":"2023-03-06T17:24:33Z","published":"2022-09-17T01:20:59Z","title":"Compose & Embellish: Well-Structured Piano Performance Generation via A\n  Two-Stage Approach","summary":"  Even with strong sequence models like Transformers, generating expressive\npiano performances with long-range musical structures remains challenging.\nMeanwhile, methods to compose well-structured melodies or lead sheets (melody +\nchords), i.e., simpler forms of music, gained more success. Observing the\nabove, we devise a two-stage Transformer-based framework that Composes a lead\nsheet first, and then Embellishes it with accompaniment and expressive touches.\nSuch a factorization also enables pretraining on non-piano data. Our objective\nand subjective experiments show that Compose & Embellish shrinks the gap in\nstructureness between a current state of the art and real performances by half,\nand improves other musical aspects such as richness and coherence as well.\n","authors":["Shih-Lun Wu","Yi-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2209.08212v3.pdf","comment":"Accepted to International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP) 2023"},{"id":"http://arxiv.org/abs/2208.08672v2","updated":"2023-03-06T17:22:50Z","published":"2022-08-18T07:11:34Z","title":"RRWaveNet: A Compact End-to-End Multi-Scale Residual CNN for Robust PPG\n  Respiratory Rate Estimation","summary":"  Respiratory rate (RR) is an important biomarker as RR changes can reflect\nsevere medical events such as heart disease, lung disease, and sleep disorders.\nUnfortunately, standard manual RR counting is prone to human error and cannot\nbe performed continuously. This study proposes a method for continuously\nestimating RR, RRWaveNet. The method is a compact end-to-end deep learning\nmodel which does not require feature engineering and can use low-cost raw\nphotoplethysmography (PPG) as input signal. RRWaveNet was tested\nsubject-independently and compared to baseline in four datasets (BIDMC,\nCapnoBase, WESAD, and SensAI) and using three window sizes (16, 32, and 64\nseconds). RRWaveNet outperformed current state-of-the-art methods with mean\nabsolute errors at optimal window size of 1.66 \\pm 1.01, 1.59 \\pm 1.08, 1.92\n\\pm 0.96 and 1.23 \\pm 0.61 breaths per minute for each dataset. In remote\nmonitoring settings, such as in the WESAD and SensAI datasets, we apply\ntransfer learning to improve the performance using two other ICU datasets as\npretraining datasets, reducing the MAE by up to 21$\\%$. This shows that this\nmodel allows accurate and practical estimation of RR on affordable and wearable\ndevices. Our study also shows feasibility of remote RR monitoring in the\ncontext of telemedicine and at home.\n","authors":["Pongpanut Osathitporn","Guntitat Sawadwuthikul","Punnawish Thuwajit","Kawisara Ueafuea","Thee Mateepithaktham","Narin Kunaseth","Tanut Choksatchawathi","Proadpran Punyabukkana","Emmanuel Mignot","Theerawit Wilaiprasitporn"],"pdf_url":"https://arxiv.org/pdf/2208.08672v2.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.03290v1","updated":"2023-03-06T17:06:50Z","published":"2023-03-06T17:06:50Z","title":"AmQA: Amharic Question Answering Dataset","summary":"  Question Answering (QA) returns concise answers or answer lists from natural\nlanguage text given a context document. Many resources go into curating QA\ndatasets to advance robust models' development. There is a surge of QA datasets\nfor languages like English, however, this is not true for Amharic. Amharic, the\nofficial language of Ethiopia, is the second most spoken Semitic language in\nthe world. There is no published or publicly available Amharic QA dataset.\nHence, to foster the research in Amharic QA, we present the first Amharic QA\n(AmQA) dataset. We crowdsourced 2628 question-answer pairs over 378 Wikipedia\narticles. Additionally, we run an XLMR Large-based baseline model to spark\nopen-domain QA research interest. The best-performing baseline achieves an\nF-score of 69.58 and 71.74 in reader-retriever QA and reading comprehension\nsettings respectively.\n","authors":["Tilahun Abedissa","Ricardo Usbeck","Yaregal Assabie"],"pdf_url":"https://arxiv.org/pdf/2303.03290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03284v1","updated":"2023-03-06T16:59:14Z","published":"2023-03-06T16:59:14Z","title":"The Wasserstein Believer: Learning Belief Updates for Partially\n  Observable Environments through Reliable Latent Space Models","summary":"  Partially Observable Markov Decision Processes (POMDPs) are useful tools to\nmodel environments where the full state cannot be perceived by an agent. As\nsuch the agent needs to reason taking into account the past observations and\nactions. However, simply remembering the full history is generally intractable\ndue to the exponential growth in the history space. Keeping a probability\ndistribution that models the belief over what the true state is can be used as\na sufficient statistic of the history, but its computation requires access to\nthe model of the environment and is also intractable. Current state-of-the-art\nalgorithms use Recurrent Neural Networks (RNNs) to compress the\nobservation-action history aiming to learn a sufficient statistic, but they\nlack guarantees of success and can lead to suboptimal policies. To overcome\nthis, we propose the Wasserstein-Belief-Updater (WBU), an RL algorithm that\nlearns a latent model of the POMDP and an approximation of the belief update.\nOur approach comes with theoretical guarantees on the quality of our\napproximation ensuring that our outputted beliefs allow for learning the\noptimal value function.\n","authors":["Raphael Avalos","Florent Delgrange","Ann Nowé","Guillermo A. Pérez","Diederik M. Roijers"],"pdf_url":"https://arxiv.org/pdf/2303.03284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03278v1","updated":"2023-03-06T16:49:27Z","published":"2023-03-06T16:49:27Z","title":"Faithfulness-Aware Decoding Strategies for Abstractive Summarization","summary":"  Despite significant progress in understanding and improving faithfulness in\nabstractive summarization, the question of how decoding strategies affect\nfaithfulness is less studied. We present a systematic study of the effect of\ngeneration techniques such as beam search and nucleus sampling on faithfulness\nin abstractive summarization. We find a consistent trend where beam search with\nlarge beam sizes produces the most faithful summaries while nucleus sampling\ngenerates the least faithful ones. We propose two faithfulness-aware generation\nmethods to further improve faithfulness over current generation techniques: (1)\nranking candidates generated by beam search using automatic faithfulness\nmetrics and (2) incorporating lookahead heuristics that produce a faithfulness\nscore on the future summary. We show that both generation methods significantly\nimprove faithfulness across two datasets as evaluated by four automatic\nfaithfulness metrics and human evaluation. To reduce computational cost, we\ndemonstrate a simple distillation approach that allows the model to generate\nfaithful summaries with just greedy decoding. Our code is publicly available at\nhttps://github.com/amazon-science/faithful-summarization-generation\n","authors":["David Wan","Mengwen Liu","Kathleen McKeown","Markus Dreyer","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2303.03278v1.pdf","comment":"EACL 2023 (17 pages)"},{"id":"http://arxiv.org/abs/2207.04154v4","updated":"2023-03-06T16:37:49Z","published":"2022-07-08T23:42:56Z","title":"TalkToModel: Explaining Machine Learning Models with Interactive Natural\n  Language Conversations","summary":"  Machine Learning (ML) models are increasingly used to make critical decisions\nin real-world applications, yet they have become more complex, making them\nharder to understand. To this end, researchers have proposed several techniques\nto explain model predictions. However, practitioners struggle to use these\nexplainability techniques because they often do not know which one to choose\nand how to interpret the results of the explanations. In this work, we address\nthese challenges by introducing TalkToModel: an interactive dialogue system for\nexplaining machine learning models through conversations. Specifically,\nTalkToModel comprises of three key components: 1) a natural language interface\nfor engaging in conversations, making ML model explainability highly\naccessible, 2) a dialogue engine that adapts to any tabular model and dataset,\ninterprets natural language, maps it to appropriate explanations, and generates\ntext responses, and 3) an execution component that constructs the explanations.\nWe carried out extensive quantitative and human subject evaluations of\nTalkToModel. Overall, we found the conversational system understands user\ninputs on novel datasets and models with high accuracy, demonstrating the\nsystem's capacity to generalize to new situations. In real-world evaluations\nwith humans, 73% of healthcare workers (e.g., doctors and nurses) agreed they\nwould use TalkToModel over baseline point-and-click systems for explainability\nin a disease prediction task, and 85% of ML professionals agreed TalkToModel\nwas easier to use for computing explanations. Our findings demonstrate that\nTalkToModel is more effective for model explainability than existing systems,\nintroducing a new category of explainability tools for practitioners. Code &\ndemo released here: https://github.com/dylan-slack/TalkToModel.\n","authors":["Dylan Slack","Satyapriya Krishna","Himabindu Lakkaraju","Sameer Singh"],"pdf_url":"https://arxiv.org/pdf/2207.04154v4.pdf","comment":"Pre-print; comments welcome! Reach out to dslack@uci.edu v3 update\n  title and abstract"},{"id":"http://arxiv.org/abs/2303.01818v2","updated":"2023-03-06T16:34:15Z","published":"2023-03-03T09:59:25Z","title":"Word-As-Image for Semantic Typography","summary":"  A word-as-image is a semantic typography technique where a word illustration\npresents a visualization of the meaning of the word, while also preserving its\nreadability. We present a method to create word-as-image illustrations\nautomatically. This task is highly challenging as it requires semantic\nunderstanding of the word and a creative idea of where and how to depict these\nsemantics in a visually pleasing and legible manner. We rely on the remarkable\nability of recent large pretrained language-vision models to distill textual\nconcepts visually. We target simple, concise, black-and-white designs that\nconvey the semantics clearly. We deliberately do not change the color or\ntexture of the letters and do not use embellishments. Our method optimizes the\noutline of each letter to convey the desired concept, guided by a pretrained\nStable Diffusion model. We incorporate additional loss terms to ensure the\nlegibility of the text and the preservation of the style of the font. We show\nhigh quality and engaging results on numerous examples and compare to\nalternative techniques.\n","authors":["Shir Iluz","Yael Vinker","Amir Hertz","Daniel Berio","Daniel Cohen-Or","Ariel Shamir"],"pdf_url":"https://arxiv.org/pdf/2303.01818v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02307v2","updated":"2023-03-06T16:08:39Z","published":"2022-06-06T01:30:03Z","title":"Bootstrapping Semi-supervised Medical Image Segmentation with\n  Anatomical-aware Contrastive Distillation","summary":"  Contrastive learning has shown great promise over annotation scarcity\nproblems in the context of medical image segmentation. Existing approaches\ntypically assume a balanced class distribution for both labeled and unlabeled\nmedical images. However, medical image data in reality is commonly imbalanced\n(i.e., multi-class label imbalance), which naturally yields blurry contours and\nusually incorrectly labels rare objects. Moreover, it remains unclear whether\nall negative samples are equally negative. In this work, we present ACTION, an\nAnatomical-aware ConTrastive dIstillatiON framework, for semi-supervised\nmedical image segmentation. Specifically, we first develop an iterative\ncontrastive distillation algorithm by softly labeling the negatives rather than\nbinary supervision between positive and negative pairs. We also capture more\nsemantically similar features from the randomly chosen negative set compared to\nthe positives to enforce the diversity of the sampled data. Second, we raise a\nmore important question: Can we really handle imbalanced samples to yield\nbetter performance? Hence, the key innovation in ACTION is to learn global\nsemantic relationship across the entire dataset and local anatomical features\namong the neighbouring pixels with minimal additional memory footprint. During\nthe training, we introduce anatomical contrast by actively sampling a sparse\nset of hard negative pixels, which can generate smoother segmentation\nboundaries and more accurate predictions. Extensive experiments across two\nbenchmark datasets and different unlabeled settings show that ACTION\nsignificantly outperforms the current state-of-the-art semi-supervised methods.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2206.02307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08529v2","updated":"2023-03-06T16:08:29Z","published":"2022-06-17T03:24:45Z","title":"Accelerating Shapley Explanation via Contributive Cooperator Selection","summary":"  Even though Shapley value provides an effective explanation for a DNN model\nprediction, the computation relies on the enumeration of all possible input\nfeature coalitions, which leads to the exponentially growing complexity. To\naddress this problem, we propose a novel method SHEAR to significantly\naccelerate the Shapley explanation for DNN models, where only a few coalitions\nof input features are involved in the computation. The selection of the feature\ncoalitions follows our proposed Shapley chain rule to minimize the absolute\nerror from the ground-truth Shapley values, such that the computation can be\nboth efficient and accurate. To demonstrate the effectiveness, we\ncomprehensively evaluate SHEAR across multiple metrics including the absolute\nerror from the ground-truth Shapley value, the faithfulness of the\nexplanations, and running speed. The experimental results indicate SHEAR\nconsistently outperforms state-of-the-art baseline methods across different\nevaluation metrics, which demonstrates its potentials in real-world\napplications where the computational resource is limited.\n","authors":["Guanchu Wang","Yu-Neng Chuang","Mengnan Du","Fan Yang","Quan Zhou","Pushkar Tripathi","Xuanting Cai","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2206.08529v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.00424v2","updated":"2023-03-06T16:00:25Z","published":"2022-12-01T10:55:22Z","title":"Multi-Source Survival Domain Adaptation","summary":"  Survival analysis is the branch of statistics that studies the relation\nbetween the characteristics of living entities and their respective survival\ntimes, taking into account the partial information held by censored cases. A\ngood analysis can, for example, determine whether one medical treatment for a\ngroup of patients is better than another. With the rise of machine learning,\nsurvival analysis can be modeled as learning a function that maps studied\npatients to their survival times. To succeed with that, there are three crucial\nissues to be tackled. First, some patient data is censored: we do not know the\ntrue survival times for all patients. Second, data is scarce, which led past\nresearch to treat different illness types as domains in a multi-task setup.\nThird, there is the need for adaptation to new or extremely rare illness types,\nwhere little or no labels are available. In contrast to previous multi-task\nsetups, we want to investigate how to efficiently adapt to a new survival\ntarget domain from multiple survival source domains. For this, we introduce a\nnew survival metric and the corresponding discrepancy measure between survival\ndistributions. These allow us to define domain adaptation for survival analysis\nwhile incorporating censored data, which would otherwise have to be dropped.\nOur experiments on two cancer data sets reveal a superb performance on target\ndomains, a better treatment recommendation, and a weight matrix with a\nplausible explanation.\n","authors":["Ammar Shaker","Carolin Lawrence"],"pdf_url":"https://arxiv.org/pdf/2212.00424v2.pdf","comment":"37th AAAI Conference on Artificial Intelligence, 2023. Includes\n  Appendix"},{"id":"http://arxiv.org/abs/2303.03235v1","updated":"2023-03-06T15:51:30Z","published":"2023-03-06T15:51:30Z","title":"On the Visualisation of Argumentation Graphs to Support Text\n  Interpretation","summary":"  The recent evolution in Natural Language Processing (NLP) methods, in\nparticular in the field of argumentation mining, has the potential to transform\nthe way we interact with text, supporting the interpretation and analysis of\ncomplex discourse and debates. Can a graphic visualisation of complex\nargumentation enable a more critical interpretation of the arguments? This\nstudy focuses on analysing the impact of argumentation graphs (AGs) compared\nwith regular texts for supporting argument interpretation. We found that AGs\noutperformed the extrinsic metrics throughout most UEQ scales as well as the\nNASA-TLX workload in all the terms but not in temporal or physical demand. The\nAG model was liked by a more significant number of participants, despite the\nfact that both the text-based and AG models yielded comparable outcomes in the\ncritical interpretation in terms of working memory and altering participants\ndecisions. The interpretation process involves reference to argumentation\nschemes (linked to critical questions (CQs)) in AGs. Interestingly, we found\nthat the participants chose more CQs (using argument schemes in AGs) when they\nwere less familiar with the argument topics, making AG schemes on some scales\n(relatively) supportive of the interpretation process. Therefore, AGs were\nconsidered to deliver a more critical approach to argument interpretation,\nespecially with unfamiliar topics. Based on the 25 participants conducted in\nthis study, it appears that AG has demonstrated an overall positive effect on\nthe argument interpretation process.\n","authors":["Hanadi Mardah","Oskar Wysocki","Markel Vigo","Andre Freitas"],"pdf_url":"https://arxiv.org/pdf/2303.03235v1.pdf","comment":"35 pages"},{"id":"http://arxiv.org/abs/2210.04613v2","updated":"2023-03-06T15:45:44Z","published":"2022-10-03T13:34:11Z","title":"Enhancing Fine-Grained 3D Object Recognition using Hybrid Multi-Modal\n  Vision Transformer-CNN Models","summary":"  Robots operating in human-centered environments, such as retail stores,\nrestaurants, and households, are often required to distinguish between similar\nobjects in different contexts with a high degree of accuracy. However,\nfine-grained object recognition remains a challenge in robotics due to the high\nintra-category and low inter-category dissimilarities. In addition, the limited\nnumber of fine-grained 3D datasets poses a significant problem in addressing\nthis issue effectively. In this paper, we propose a hybrid multi-modal Vision\nTransformer (ViT) and Convolutional Neural Networks (CNN) approach to improve\nthe performance of fine-grained visual classification (FGVC). To address the\nshortage of FGVC 3D datasets, we generated two synthetic datasets. The first\ndataset consists of 20 categories related to restaurants with a total of 100\ninstances, while the second dataset contains 120 shoe instances. Our approach\nwas evaluated on both datasets, and the results indicate that it outperforms\nboth CNN-only and ViT-only baselines, achieving a recognition accuracy of 94.50\n% and 93.51 % on the restaurant and shoe datasets, respectively. Additionally,\nwe have made our FGVC RGB-D datasets available to the research community to\nenable further experimentation and advancement. Furthermore, we successfully\nintegrated our proposed method with a robot framework and demonstrated its\npotential as a fine-grained perception tool in both simulated and real-world\nrobotic scenarios.\n","authors":["Songsong Xiong","Georgios Tziafas","Hamidreza Kasaei"],"pdf_url":"https://arxiv.org/pdf/2210.04613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03226v1","updated":"2023-03-06T15:43:41Z","published":"2023-03-06T15:43:41Z","title":"Safe Reinforcement Learning via Probabilistic Logic Shields","summary":"  Safe Reinforcement learning (Safe RL) aims at learning optimal policies while\nstaying safe. A popular solution to Safe RL is shielding, which uses a logical\nsafety specification to prevent an RL agent from taking unsafe actions.\nHowever, traditional shielding techniques are difficult to integrate with\ncontinuous, end-to-end deep RL methods. To this end, we introduce Probabilistic\nLogic Policy Gradient (PLPG). PLPG is a model-based Safe RL technique that uses\nprobabilistic logic programming to model logical safety constraints as\ndifferentiable functions. Therefore, PLPG can be seamlessly applied to any\npolicy gradient algorithm while still providing the same convergence\nguarantees. In our experiments, we show that PLPG learns safer and more\nrewarding policies compared to other state-of-the-art shielding techniques.\n","authors":["Wen-Chi Yang","Giuseppe Marra","Gavin Rens","Luc De Raedt"],"pdf_url":"https://arxiv.org/pdf/2303.03226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14028v3","updated":"2023-03-06T15:37:40Z","published":"2022-11-25T11:02:33Z","title":"Automata Cascades: Expressivity and Sample Complexity","summary":"  Every automaton can be decomposed into a cascade of basic prime automata.\nThis is the Prime Decomposition Theorem by Krohn and Rhodes. Guided by this\ntheory, we propose automata cascades as a structured, modular, way to describe\nautomata as complex systems made of many components, each implementing a\nspecific functionality. Any automaton can serve as a component; using specific\ncomponents allows for a fine-grained control of the expressivity of the\nresulting class of automata; using prime automata as components implies\nspecific expressivity guarantees. Moreover, specifying automata as cascades\nallows for describing the sample complexity of automata in terms of their\ncomponents. We show that the sample complexity is linear in the number of\ncomponents and the maximum complexity of a single component, modulo logarithmic\nfactors. This opens to the possibility of learning automata representing large\ndynamical systems consisting of many parts interacting with each other. It is\nin sharp contrast with the established understanding of the sample complexity\nof automata, described in terms of the overall number of states and input\nletters, which implies that it is only possible to learn automata where the\nnumber of states is linear in the amount of data available. Instead our results\nshow that one can learn automata with a number of states that is exponential in\nthe amount of data available.\n","authors":["Alessandro Ronca","Nadezda Alexandrovna Knorozova","Giuseppe De Giacomo"],"pdf_url":"https://arxiv.org/pdf/2211.14028v3.pdf","comment":"Full version with appendix of a paper with the same title that\n  appears in the proceedings of AAAI 2023"},{"id":"http://arxiv.org/abs/2302.05698v2","updated":"2023-03-06T15:24:56Z","published":"2023-02-11T14:02:08Z","title":"Compositional Exemplars for In-context Learning","summary":"  Large pretrained language models (LMs) have shown impressive In-Context\nLearning (ICL) ability, where the model learns to do an unseen task via a\nprompt consisting of input-output examples as the demonstration, without any\nparameter updates. The performance of ICL is highly dominated by the quality of\nthe selected in-context examples. However, previous selection methods are\nmostly based on simple heuristics, leading to sub-optimal performance. In this\nwork, we formulate in-context example selection as a subset selection problem.\nWe propose CEIL (Compositional Exemplars for In-context Learning), which is\ninstantiated by Determinantal Point Processes (DPPs) to model the interaction\nbetween the given input and in-context examples, and optimized through a\ncarefully-designed contrastive learning objective to obtain preference from\nLMs. We validate CEIL on 12 classification and generation datasets from 7\ndistinct NLP tasks, including sentiment analysis, paraphrase detection, natural\nlanguage inference, commonsense reasoning, open-domain question answering, code\ngeneration, and semantic parsing. Extensive experiments demonstrate not only\nthe state-of-the-art performance but also the transferability and\ncompositionality of CEIL, shedding new light on effective and efficient\nin-context learning. Our code is released at\nhttps://github.com/HKUNLP/icl-ceil.\n","authors":["Jiacheng Ye","Zhiyong Wu","Jiangtao Feng","Tao Yu","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2302.05698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03211v1","updated":"2023-03-06T15:13:35Z","published":"2023-03-06T15:13:35Z","title":"Using a Variational Autoencoder to Learn Valid Search Spaces of Safely\n  Monitored Autonomous Robots for Last-Mile Delivery","summary":"  The use of autonomous robots for delivery of goods to customers is an\nexciting new way to provide a reliable and sustainable service. However, in the\nreal world, autonomous robots still require human supervision for safety\nreasons. We tackle the realworld problem of optimizing autonomous robot timings\nto maximize deliveries, while ensuring that there are never too many robots\nrunning simultaneously so that they can be monitored safely. We assess the use\nof a recent hybrid machine-learningoptimization approach COIL (constrained\noptimization in learned latent space) and compare it with a baseline genetic\nalgorithm for the purposes of exploring variations of this problem. We also\ninvestigate new methods for improving the speed and efficiency of COIL. We show\nthat only COIL can find valid solutions where appropriate numbers of robots run\nsimultaneously for all problem variations tested. We also show that when COIL\nhas learned its latent representation, it can optimize 10% faster than the GA,\nmaking it a good choice for daily re-optimization of robots where delivery\nrequests for each day are allocated to robots while maintaining safe numbers of\nrobots running at once.\n","authors":["Peter J. Bentley","Soo Ling Lim","Paolo Arcaini","Fuyuki Ishikawa"],"pdf_url":"https://arxiv.org/pdf/2303.03211v1.pdf","comment":"10 pages including 1 page supplemental"},{"id":"http://arxiv.org/abs/2303.03178v1","updated":"2023-03-06T14:47:38Z","published":"2023-03-06T14:47:38Z","title":"A System for Generalized 3D Multi-Object Search","summary":"  Searching for objects is a fundamental skill for robots. As such, we expect\nobject search to eventually become an off-the-shelf capability for robots,\nsimilar to e.g., object detection and SLAM. In contrast, however, no system for\n3D object search exists that generalizes across real robots and environments.\nIn this paper, building upon a recent theoretical framework that exploited the\noctree structure for representing belief in 3D, we present GenMOS (Generalized\nMulti-Object Search), the first general-purpose system for multi-object search\n(MOS) in a 3D region that is robot-independent and environment-agnostic. GenMOS\ntakes as input point cloud observations of the local region, object detection\nresults, and localization of the robot's view pose, and outputs a 6D viewpoint\nto move to through online planning. In particular, GenMOS uses point cloud\nobservations in three ways: (1) to simulate occlusion; (2) to inform occupancy\nand initialize octree belief; and (3) to sample a belief-dependent graph of\nview positions that avoid obstacles. We evaluate our system both in simulation\nand on two real robot platforms. Our system enables, for example, a Boston\nDynamics Spot robot to find a toy cat hidden underneath a couch in under one\nminute. We further integrate 3D local search with 2D global search to handle\nlarger areas, demonstrating the resulting system in a 25m$^2$ lobby area.\n","authors":["Kaiyu Zheng","Anirudha Paul","Stefanie Tellex"],"pdf_url":"https://arxiv.org/pdf/2303.03178v1.pdf","comment":"8 pages, 9 figures, 1 table. IEEE Conference on Robotics and\n  Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2302.13941v2","updated":"2023-03-06T14:44:40Z","published":"2023-02-27T16:45:04Z","title":"A Reinforcement Learning Approach for Scheduling Problems With Improved\n  Generalization Through Order Swapping","summary":"  The scheduling of production resources (such as associating jobs to machines)\nplays a vital role for the manufacturing industry not only for saving energy\nbut also for increasing the overall efficiency. Among the different job\nscheduling problems, the JSSP is addressed in this work. JSSP falls into the\ncategory of NP-hard COP, in which solving the problem through exhaustive search\nbecomes unfeasible. Simple heuristics such as FIFO, LPT and metaheuristics such\nas Taboo search are often adopted to solve the problem by truncating the search\nspace. The viability of the methods becomes inefficient for large problem sizes\nas it is either far from the optimum or time consuming. In recent years, the\nresearch towards using DRL to solve COP has gained interest and has shown\npromising results in terms of solution quality and computational efficiency. In\nthis work, we provide an novel approach to solve the JSSP examining the\nobjectives generalization and solution effectiveness using DRL. In particular,\nwe employ the PPO algorithm that adopts the policy-gradient paradigm that is\nfound to perform well in the constrained dispatching of jobs. We incorporated\nan OSM in the environment to achieve better generalized learning of the\nproblem. The performance of the presented approach is analyzed in depth by\nusing a set of available benchmark instances and comparing our results with the\nwork of other groups.\n","authors":["Deepak Vivekanandan","Samuel Wirth","Patrick Karlbauer","Noah Klarmann"],"pdf_url":"https://arxiv.org/pdf/2302.13941v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03174v1","updated":"2023-03-06T14:42:05Z","published":"2023-03-06T14:42:05Z","title":"Both eyes open: Vigilant Incentives help Regulatory Markets improve AI\n  Safety","summary":"  In the context of rapid discoveries by leaders in AI, governments must\nconsider how to design regulation that matches the increasing pace of new AI\ncapabilities. Regulatory Markets for AI is a proposal designed with\nadaptability in mind. It involves governments setting outcome-based targets for\nAI companies to achieve, which they can show by purchasing services from a\nmarket of private regulators. We use an evolutionary game theory model to\nexplore the role governments can play in building a Regulatory Market for AI\nsystems that deters reckless behaviour. We warn that it is alarmingly easy to\nstumble on incentives which would prevent Regulatory Markets from achieving\nthis goal. These 'Bounty Incentives' only reward private regulators for\ncatching unsafe behaviour. We argue that AI companies will likely learn to\ntailor their behaviour to how much effort regulators invest, discouraging\nregulators from innovating. Instead, we recommend that governments always\nreward regulators, except when they find that those regulators failed to detect\nunsafe behaviour that they should have. These 'Vigilant Incentives' could\nencourage private regulators to find innovative ways to evaluate cutting-edge\nAI systems.\n","authors":["Paolo Bova","Alessandro Di Stefano","The Anh Han"],"pdf_url":"https://arxiv.org/pdf/2303.03174v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03166v1","updated":"2023-03-06T14:26:56Z","published":"2023-03-06T14:26:56Z","title":"Faster Learning of Temporal Action Proposal via Sparse Multilevel\n  Boundary Generator","summary":"  Temporal action localization in videos presents significant challenges in the\nfield of computer vision. While the boundary-sensitive method has been widely\nadopted, its limitations include incomplete use of intermediate and global\ninformation, as well as an inefficient proposal feature generator. To address\nthese challenges, we propose a novel framework, Sparse Multilevel Boundary\nGenerator (SMBG), which enhances the boundary-sensitive method with boundary\nclassification and action completeness regression. SMBG features a multi-level\nboundary module that enables faster processing by gathering boundary\ninformation at different lengths. Additionally, we introduce a sparse\nextraction confidence head that distinguishes information inside and outside\nthe action, further optimizing the proposal feature generator. To improve the\nsynergy between multiple branches and balance positive and negative samples, we\npropose a global guidance loss. Our method is evaluated on two popular\nbenchmarks, ActivityNet-1.3 and THUMOS14, and is shown to achieve\nstate-of-the-art performance, with a better inference speed (2.47xBSN++,\n2.12xDBG). These results demonstrate that SMBG provides a more efficient and\nsimple solution for generating temporal action proposals. Our proposed\nframework has the potential to advance the field of computer vision and enhance\nthe accuracy and speed of temporal action localization in video analysis.The\ncode and models are made available at\n\\url{https://github.com/zhouyang-001/SMBG-for-temporal-action-proposal}.\n","authors":["Qing Song","Yang Zhou","Mengjie Hu","Chun Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03166v1.pdf","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.03140v1","updated":"2023-03-06T13:55:57Z","published":"2023-03-06T13:55:57Z","title":"Cybersecurity of AI medical devices: risks, legislation, and challenges","summary":"  Medical devices and artificial intelligence systems rapidly transform\nhealthcare provisions. At the same time, due to their nature, AI in or as\nmedical devices might get exposed to cyberattacks, leading to patient safety\nand security risks. This book chapter is divided into three parts. The first\npart starts by setting the scene where we explain the role of cybersecurity in\nhealthcare. Then, we briefly define what we refer to when we talk about AI that\nis considered a medical device by itself or supports one. To illustrate the\nrisks such medical devices pose, we provide three examples: the poisoning of\ndatasets, social engineering, and data or source code extraction. In the second\npart, the paper provides an overview of the European Union's regulatory\nframework relevant for ensuring the cybersecurity of AI as or in medical\ndevices (MDR, NIS Directive, Cybersecurity Act, GDPR, the AI Act proposal and\nthe NIS 2 Directive proposal). Finally, the third part of the paper examines\npossible challenges stemming from the EU regulatory framework. In particular,\nwe look toward the challenges deriving from the two legislative proposals and\ntheir interaction with the existing legislation concerning AI medical devices'\ncybersecurity. They are structured as answers to the following questions: (1)\nhow will the AI Act interact with the MDR regarding the cybersecurity and\nsafety requirements?; (2) how should we interpret incident notification\nrequirements from the NIS 2 Directive proposal and MDR?; and (3) what are the\nconsequences of the evolving term of critical infrastructures?\n  [This is a draft chapter. The final version will be available in Research\nHandbook on Health, AI and the Law edited by Barry Solaiman & I. Glenn Cohen,\nforthcoming 2023, Edward Elgar Publishing Ltd]\n","authors":["Elisabetta Biasin","Erik Kamenjasevic","Kaspar Rosager Ludvigsen"],"pdf_url":"https://arxiv.org/pdf/2303.03140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03139v1","updated":"2023-03-06T13:55:42Z","published":"2023-03-06T13:55:42Z","title":"Low impact agency: review and discussion","summary":"  Powerful artificial intelligence poses an existential threat if the AI\ndecides to drastically change the world in pursuit of its goals. The hope of\nlow-impact artificial intelligence is to incentivize AI to not do that just\nbecause this causes a large impact in the world. In this work, we first review\nthe concept of low-impact agency and previous proposals to approach the\nproblem, and then propose future research directions in the topic, with the\ngoal to ensure low-impactedness is useful in making AI safe.\n","authors":["Danilo Naiff","Shashwat Goel"],"pdf_url":"https://arxiv.org/pdf/2303.03139v1.pdf","comment":"Work done as part of the SERIMATS 3.0 training program"},{"id":"http://arxiv.org/abs/2303.03131v1","updated":"2023-03-06T13:49:15Z","published":"2023-03-06T13:49:15Z","title":"Video Question Answering Using CLIP-Guided Visual-Text Attention","summary":"  Cross-modal learning of video and text plays a key role in Video Question\nAnswering (VideoQA). In this paper, we propose a visual-text attention\nmechanism to utilize the Contrastive Language-Image Pre-training (CLIP) trained\non lots of general domain language-image pairs to guide the cross-modal\nlearning for VideoQA. Specifically, we first extract video features using a\nTimeSformer and text features using a BERT from the target application domain,\nand utilize CLIP to extract a pair of visual-text features from the\ngeneral-knowledge domain through the domain-specific learning. We then propose\na Cross-domain Learning to extract the attention information between visual and\nlinguistic features across the target domain and general domain. The set of\nCLIP-guided visual-text features are integrated to predict the answer. The\nproposed method is evaluated on MSVD-QA and MSRVTT-QA datasets, and outperforms\nstate-of-the-art methods.\n","authors":["Shuhong Ye","Weikai Kong","Chenglin Yao","Jianfeng Ren","Xudong Jiang"],"pdf_url":"https://arxiv.org/pdf/2303.03131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03124v1","updated":"2023-03-06T13:37:59Z","published":"2023-03-06T13:37:59Z","title":"IFAN: An Explainability-Focused Interaction Framework for Humans and NLP\n  Models","summary":"  Interpretability and human oversight are fundamental pillars of deploying\ncomplex NLP models into real-world applications. However, applying\nexplainability and human-in-the-loop methods requires technical proficiency.\nDespite existing toolkits for model understanding and analysis, options to\nintegrate human feedback are still limited. We propose IFAN, a framework for\nreal-time explanation-based interaction with NLP models. Through IFAN's\ninterface, users can provide feedback to selected model explanations, which is\nthen integrated through adapter layers to align the model with human rationale.\nWe show the system to be effective in debiasing a hate speech classifier with\nminimal performance loss. IFAN also offers a visual admin system and API to\nmanage models (and datasets) as well as control access rights. A demo is live\nat https://ifan.ml/\n","authors":["Edoardo Mosca","Daryna Dementieva","Tohid Ebrahim Ajdari","Maximilian Kummeth","Kirill Gringauz","Georg Groh"],"pdf_url":"https://arxiv.org/pdf/2303.03124v1.pdf","comment":"ACL Demo 2023 Submission"},{"id":"http://arxiv.org/abs/2104.14527v5","updated":"2023-03-06T13:19:14Z","published":"2021-04-29T17:45:27Z","title":"Online certification of preference-based fairness for personalized\n  recommender systems","summary":"  Recommender systems are facing scrutiny because of their growing impact on\nthe opportunities we have access to. Current audits for fairness are limited to\ncoarse-grained parity assessments at the level of sensitive groups. We propose\nto audit for envy-freeness, a more granular criterion aligned with individual\npreferences: every user should prefer their recommendations to those of other\nusers. Since auditing for envy requires to estimate the preferences of users\nbeyond their existing recommendations, we cast the audit as a new pure\nexploration problem in multi-armed bandits. We propose a sample-efficient\nalgorithm with theoretical guarantees that it does not deteriorate user\nexperience. We also study the trade-offs achieved on real-world recommendation\ndatasets.\n","authors":["Virginie Do","Sam Corbett-Davies","Jamal Atif","Nicolas Usunier"],"pdf_url":"https://arxiv.org/pdf/2104.14527v5.pdf","comment":"AAAI 2022"},{"id":"http://arxiv.org/abs/2303.03103v1","updated":"2023-03-06T13:15:25Z","published":"2023-03-06T13:15:25Z","title":"Towards Zero-Shot Functional Compositionality of Language Models","summary":"  Large Pre-trained Language Models (PLM) have become the most desirable\nstarting point in the field of NLP, as they have become remarkably good at\nsolving many individual tasks. Despite such success, in this paper, we argue\nthat current paradigms of working with PLMs are neglecting a critical aspect of\nmodeling human intelligence: functional compositionality. Functional\ncompositionality - the ability to compose learned tasks - has been a\nlong-standing challenge in the field of AI (and many other fields) as it is\nconsidered one of the hallmarks of human intelligence. An illustrative example\nof such is cross-lingual summarization, where a bilingual person\n(English-French) could directly summarize an English document into French\nsentences without having to translate the English document or summary into\nFrench explicitly. We discuss why this matter is an important open problem that\nrequires further attention from the field. Then, we show that current PLMs\n(e.g., GPT-2 and T5) don't have functional compositionality yet and it is far\nfrom human-level generalizability. Finally, we suggest several research\ndirections that could push the field towards zero-shot functional\ncompositionality of language models.\n","authors":["Hangyeol Yu","Myeongho Jeong","Jamin Shin","Hyeongdon Moon","Juneyoung Park","Seungtaek Choi"],"pdf_url":"https://arxiv.org/pdf/2303.03103v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14889v2","updated":"2023-03-06T11:50:26Z","published":"2022-10-24T17:40:07Z","title":"Perfectly Secure Steganography Using Minimum Entropy Coupling","summary":"  Steganography is the practice of encoding secret information into innocuous\ncontent in such a manner that an adversarial third party would not realize that\nthere is hidden meaning. While this problem has classically been studied in\nsecurity literature, recent advances in generative models have led to a shared\ninterest among security and machine learning researchers in developing scalable\nsteganography techniques. In this work, we show that a steganography procedure\nis perfectly secure under \\citet{cachin_perfect}'s information theoretic-model\nof steganography if and only if it is induced by a coupling. Furthermore, we\nshow that, among perfectly secure procedures, a procedure is maximally\nefficient if and only if it is induced by a minimum entropy coupling. These\ninsights yield what are, to the best of our knowledge, the first steganography\nalgorithms to achieve perfect security guarantees with non-trivial efficiency;\nadditionally, these algorithms are highly scalable. To provide empirical\nvalidation, we compare a minimum entropy coupling-based approach to three\nmodern baselines -- arithmetic coding, Meteor, and adaptive dynamic grouping --\nusing GPT-2 and WaveRNN as communication channels. We find that the minimum\nentropy coupling-based approach yields superior encoding efficiency, despite\nits stronger security constraints. In aggregate, these results suggest that it\nmay be natural to view information-theoretic steganography through the lens of\nminimum entropy coupling.\n","authors":["Christian Schroeder de Witt","Samuel Sokota","J. Zico Kolter","Jakob Foerster","Martin Strohmeier"],"pdf_url":"https://arxiv.org/pdf/2210.14889v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03050v1","updated":"2023-03-06T11:46:58Z","published":"2023-03-06T11:46:58Z","title":"MABNet: Master Assistant Buddy Network with Hybrid Learning for Image\n  Retrieval","summary":"  Image retrieval has garnered growing interest in recent times. The current\napproaches are either supervised or self-supervised. These methods do not\nexploit the benefits of hybrid learning using both supervision and\nself-supervision. We present a novel Master Assistant Buddy Network (MABNet)\nfor image retrieval which incorporates both learning mechanisms. MABNet\nconsists of master and assistant blocks, both learning independently through\nsupervision and collectively via self-supervision. The master guides the\nassistant by providing its knowledge base as a reference for self-supervision\nand the assistant reports its knowledge back to the master by weight transfer.\nWe perform extensive experiments on public datasets with and without\npost-processing.\n","authors":["Rohit Agarwal","Gyanendra Das","Saksham Aggarwal","Alexander Horsch","Dilip K. Prasad"],"pdf_url":"https://arxiv.org/pdf/2303.03050v1.pdf","comment":"Accepted at International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP) 2023"},{"id":"http://arxiv.org/abs/2210.12896v2","updated":"2023-03-06T11:37:38Z","published":"2022-10-24T00:54:59Z","title":"Classifying Ambiguous Identities in Hidden-Role Stochastic Games with\n  Multi-Agent Reinforcement Learning","summary":"  Multi-agent reinforcement learning (MARL) is a prevalent learning paradigm\nfor solving stochastic games. In most MARL studies, agents in a game are\ndefined as teammates or enemies beforehand, and the relationships among the\nagents remain fixed throughout the game. However, in real-world problems, the\nagent relationships are commonly unknown in advance or dynamically changing.\nMany multi-party interactions start off by asking: who is on my team? This\nquestion arises whether it is the first day at the stock exchange or the\nkindergarten. Therefore, training policies for such situations in the face of\nimperfect information and ambiguous identities is an important problem that\nneeds to be addressed. In this work, we develop a novel identity detection\nreinforcement learning (IDRL) framework that allows an agent to dynamically\ninfer the identities of nearby agents and select an appropriate policy to\naccomplish the task. In the IDRL framework, a relation network is constructed\nto deduce the identities of other agents by observing the behaviors of the\nagents. A danger network is optimized to estimate the risk of false-positive\nidentifications. Beyond that, we propose an intrinsic reward that balances the\nneed to maximize external rewards and accurate identification. After\nidentifying the cooperation-competition pattern among the agents, IDRL applies\none of the off-the-shelf MARL methods to learn the policy. To evaluate the\nproposed method, we conduct experiments on Red-10 card-shedding game, and the\nresults show that IDRL achieves superior performance over other\nstate-of-the-art MARL methods. Impressively, the relation network has the par\nperformance to identify the identities of agents with top human players; the\ndanger network reasonably avoids the risk of imperfect identification. The code\nto reproduce all the reported results is available online at\nhttps://github.com/MR-BENjie/IDRL.\n","authors":["Shijie Han","Siyuan Li","Bo An","Wei Zhao","Peng Liu"],"pdf_url":"https://arxiv.org/pdf/2210.12896v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03041v1","updated":"2023-03-06T11:13:23Z","published":"2023-03-06T11:13:23Z","title":"Automatic detection of aerial survey ground control points based on\n  Yolov5-OBB","summary":"  The use of ground control points (GCPs) for georeferencing is the most common\nstrategy in unmanned aerial vehicle (UAV) photogrammetry, but at the same time\ntheir collection represents the most time-consuming and expensive part of UAV\ncampaigns. Recently, deep learning has been rapidly developed in the field of\nsmall object detection. In this letter, to automatically extract coordinates\ninformation of ground control points (GCPs) by detecting GCP-markers in UAV\nimages, we propose a solution that uses a deep learning-based architecture,\nYOLOv5-OBB, combined with a confidence threshold filtering algorithm and an\noptimal ranking algorithm. We applied our proposed method to a dataset\ncollected by DJI Phantom 4 Pro drone and obtained good detection performance\nwith the mean Average Precision (AP) of 0.832 and the highest AP of 0.982 for\nthe cross-type GCP-markers. The proposed method can be a promising tool for\nfuture implementation of the end-to-end aerial triangulation process.\n","authors":["Cheng Chuanxiang","Yang Jia","Wang Chao","Zheng Zhi","Li Xiaopeng","Dong Di","Chang Mengxia","Zhuang Zhiheng"],"pdf_url":"https://arxiv.org/pdf/2303.03041v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.03037v1","updated":"2023-03-06T11:07:11Z","published":"2023-03-06T11:07:11Z","title":"EvCenterNet: Uncertainty Estimation for Object Detection using\n  Evidential Learning","summary":"  Uncertainty estimation is crucial in safety-critical settings such as\nautomated driving as it provides valuable information for several downstream\ntasks including high-level decision-making and path planning. In this work, we\npropose EvCenterNet, a novel uncertainty-aware 2D object detection framework\nutilizing evidential learning to directly estimate both classification and\nregression uncertainties. To employ evidential learning for object detection,\nwe devise a combination of evidential and focal loss functions for the sparse\nheatmap inputs. We introduce class-balanced weighting for regression and\nheatmap prediction to tackle the class imbalance encountered by evidential\nlearning. Moreover, we propose a learning scheme to actively utilize the\npredicted heatmap uncertainties to improve the detection performance by\nfocusing on the most uncertain points. We train our model on the KITTI dataset\nand evaluate it on challenging out-of-distribution datasets including BDD100K\nand nuImages. Our experiments demonstrate that our approach improves the\nprecision and minimizes the execution time loss in relation to the base model.\n","authors":["Monish R. Nallapareddy","Kshitij Sirohi","Paulo L. J. Drews-Jr","Wolfram Burgard","Chih-Hong Cheng","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2303.03037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03032v1","updated":"2023-03-06T11:02:47Z","published":"2023-03-06T11:02:47Z","title":"DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only\n  Training","summary":"  Large-scale pre-trained multi-modal models (e.g., CLIP) demonstrate strong\nzero-shot transfer capability in many discriminative tasks. Their adaptation to\nzero-shot image-conditioned text generation tasks has drawn increasing\ninterest. Prior arts approach to zero-shot captioning by either utilizing the\nexisting large language models (e.g., GPT-2) or pre-training the\nencoder-decoder network in an end-to-end manner. In this work, we propose a\nsimple framework, named DeCap, for zero-shot captioning. We introduce a\nlightweight visual-aware language decoder. This decoder is both data-efficient\nand computation-efficient: 1) it only requires the text data for training,\neasing the burden on the collection of paired data. 2) it does not require\nend-to-end training. When trained with text-only data, the decoder takes the\ntext embedding extracted from the off-the-shelf CLIP encoder as a prefix\nembedding. The challenge is that the decoder is trained on the text corpus but\nat the inference stage, it needs to generate captions based on visual inputs.\nThe modality gap issue is widely observed in multi-modal contrastive models\nthat prevents us from directly taking the visual embedding as the prefix\nembedding. We propose a training-free mechanism to reduce the modality gap. We\nproject the visual embedding into the CLIP text embedding space, while the\nprojected embedding retains the information of the visual input. Taking the\nprojected embedding as the prefix embedding, the decoder generates high-quality\ndescriptions that match the visual input. The experiments show that DeCap\noutperforms other zero-shot captioning methods and unpaired captioning methods\non the typical image captioning benchmarks, i.e., MSCOCO and NoCaps.\n","authors":["Wei Li","Linchao Zhu","Longyin Wen","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2303.03032v1.pdf","comment":"Accepted by ICLR 2023. Code is available at\n  https://github.com/dhg-wei/DeCap"},{"id":"http://arxiv.org/abs/2303.01954v2","updated":"2023-03-06T10:01:27Z","published":"2023-03-03T14:28:45Z","title":"Synthetic Data Generator for Adaptive Interventions in Global Health","summary":"  Artificial Intelligence and digital health have the potential to transform\nglobal health. However, having access to representative data to test and\nvalidate algorithms in realistic production environments is essential. We\nintroduce HealthSyn, an open-source synthetic data generator of user behavior\nfor testing reinforcement learning algorithms in the context of mobile health\ninterventions. The generator utilizes Markov processes to generate diverse user\nactions, with individual user behavioral patterns that can change in reaction\nto personalized interventions (i.e., reminders, recommendations, and\nincentives). These actions are translated into actual logs using an ML-purposed\ndata schema specific to the mobile health application functionality included\nwith HealthKit, and open-source SDK. The logs can be fed to pipelines to obtain\nuser metrics. The generated data, which is based on real-world behaviors and\nsimulation techniques, can be used to develop, test, and evaluate, both ML\nalgorithms in research and end-to-end operational RL-based intervention\ndelivery frameworks.\n","authors":["Aditya Rastogi","Juan Francisco Garamendi","Ana Fernández del Río","Anna Guitart","Moiz Hassan Khan","Dexian Tang","África Periáñez"],"pdf_url":"https://arxiv.org/pdf/2303.01954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03494v7","updated":"2023-03-06T09:34:38Z","published":"2023-02-06T04:21:59Z","title":"A Categorical Archive of ChatGPT Failures","summary":"  Large language models have been demonstrated to be valuable in different\nfields. ChatGPT, developed by OpenAI, has been trained using massive amounts of\ndata and simulates human conversation by comprehending context and generating\nappropriate responses. It has garnered significant attention due to its ability\nto effectively answer a broad range of human inquiries, with fluent and\ncomprehensive answers surpassing prior public chatbots in both security and\nusefulness. However, a comprehensive analysis of ChatGPT's failures is lacking,\nwhich is the focus of this study. Eleven categories of failures, including\nreasoning, factual errors, math, coding, and bias, are presented and discussed.\nThe risks, limitations, and societal implications of ChatGPT are also\nhighlighted. The goal of this study is to assist researchers and developers in\nenhancing future language models and chatbots.\n","authors":["Ali Borji"],"pdf_url":"https://arxiv.org/pdf/2302.03494v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02980v1","updated":"2023-03-06T09:15:28Z","published":"2023-03-06T09:15:28Z","title":"KDSM: An uplift modeling framework based on knowledge distillation and\n  sample matching","summary":"  Uplift modeling aims to estimate the treatment effect on individuals, widely\napplied in the e-commerce platform to target persuadable customers and maximize\nthe return of marketing activities. Among the existing uplift modeling methods,\ntree-based methods are adept at fitting increment and generalization, while\nneural-network-based models excel at predicting absolute value and precision,\nand these advantages have not been fully explored and combined. Also, the lack\nof counterfactual sample pairs is the root challenge in uplift modeling. In\nthis paper, we proposed an uplift modeling framework based on Knowledge\nDistillation and Sample Matching (KDSM). The teacher model is the uplift\ndecision tree (UpliftDT), whose structure is exploited to construct\ncounterfactual sample pairs, and the pairwise incremental prediction is treated\nas another objective for the student model. Under the idea of multitask\nlearning, the student model can achieve better performance on generalization\nand even surpass the teacher. Extensive offline experiments validate the\nuniversality of different combinations of teachers and student models and the\nsuperiority of KDSM measured against the baselines. In online A/B testing, the\ncost of each incremental room night is reduced by 6.5\\%.\n","authors":["Chang Sun","Qianying Li","Guanxiang Wang","Sihao Xu","Yitong Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01230v2","updated":"2023-03-06T09:09:17Z","published":"2023-03-01T16:35:33Z","title":"What Is Synthetic Data? The Good, The Bad, and The Ugly","summary":"  Sharing data can often enable compelling applications and analytics. However,\nmore often than not, valuable datasets contain information of sensitive nature,\nand thus sharing them can endanger the privacy of users and organizations. A\npossible alternative gaining momentum in the research community is to share\nsynthetic data instead. The idea is to release artificially generated datasets\nthat resemble the actual data -- more precisely, having similar statistical\nproperties.\n  So how do you generate synthetic data? What is that useful for? What are the\nbenefits and the risks? What are the open research questions that remain\nunanswered? In this article, we provide a gentle introduction to synthetic data\nand discuss its use cases, the privacy challenges that are still unaddressed,\nand its inherent limitations as an effective privacy-enhancing technology.\n","authors":["Emiliano De Cristofaro"],"pdf_url":"https://arxiv.org/pdf/2303.01230v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06961v2","updated":"2023-03-06T09:01:36Z","published":"2023-02-14T10:40:20Z","title":"Bilateral-Fuser: A Novel Multi-cue Fusion Architecture with\n  Anatomical-aware Tokens for Fovea Localization","summary":"  Accurate localization of the fovea is a crucial initial step in analyzing\nretinal diseases since it helps prevent irreversible vision loss. Although\ncurrent deep learning-based methods achieve better performance than traditional\nmethods, they still face challenges such as inadequate utilization of\nanatomical landmarks, sensitivity to diseased retinal images, and various image\nconditions. In this paper, we propose a novel transformer-based architecture\n(Bilateral-Fuser) for multi-cue fusion. The Bilateral-Fuser explicitly\nincorporates long-range connections and global features using retina and vessel\ndistributions to achieve robust fovea localization. We introduce a spatial\nattention mechanism in the dual-stream encoder to extract and fuse self-learned\nanatomical information. This design focuses more on features distributed along\nblood vessels and significantly reduces computational costs by reducing token\nnumbers. Our comprehensive experiments demonstrate that the proposed\narchitecture achieves state-of-the-art performance on two public datasets and\none large-scale private dataset. Moreover, we show that the Bilateral-Fuser is\nmore robust on both normal and diseased retina images and has better\ngeneralization capacity in cross-dataset experiments.\n","authors":["Sifan Song","Jinfeng Wang","Zilong Wang","Shaopeng Wang","Jionglong Su","Xiaowei Ding","Kang Dang"],"pdf_url":"https://arxiv.org/pdf/2302.06961v2.pdf","comment":"This paper is prepared for IEEE Transactions on Medical Imaging"},{"id":"http://arxiv.org/abs/2303.02966v1","updated":"2023-03-06T08:51:00Z","published":"2023-03-06T08:51:00Z","title":"Non-Parametric Outlier Synthesis","summary":"  Out-of-distribution (OOD) detection is indispensable for safely deploying\nmachine learning models in the wild. One of the key challenges is that models\nlack supervision signals from unknown data, and as a result, can produce\noverconfident predictions on OOD data. Recent work on outlier synthesis modeled\nthe feature space as parametric Gaussian distribution, a strong and restrictive\nassumption that might not hold in reality. In this paper, we propose a novel\nframework, Non-Parametric Outlier Synthesis (NPOS), which generates artificial\nOOD training data and facilitates learning a reliable decision boundary between\nID and OOD data. Importantly, our proposed synthesis approach does not make any\ndistributional assumption on the ID embeddings, thereby offering strong\nflexibility and generality. We show that our synthesis approach can be\nmathematically interpreted as a rejection sampling framework. Extensive\nexperiments show that NPOS can achieve superior OOD detection performance,\noutperforming the competitive rivals by a significant margin. Code is publicly\navailable at https://github.com/deeplearning-wisc/npos.\n","authors":["Leitian Tao","Xuefeng Du","Xiaojin Zhu","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2303.02966v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02962v1","updated":"2023-03-06T08:33:04Z","published":"2023-03-06T08:33:04Z","title":"New Era in Cultural Heritage Preservation: Cooperative Aerial Autonomy","summary":"  Digital documentation of large interiors of historical buildings is an\nexhausting task since most of the areas of interest are beyond typical human\nreach. We advocate the use of autonomous teams of multi-rotor Unmanned Aerial\nVehicles (UAVs) to speed up the documentation process by several orders of\nmagnitude while allowing for a repeatable, accurate, and condition-independent\nsolution capable of precise collision-free operation at great heights. The\nproposed multi-robot approach allows for performing tasks requiring dynamic\nscene illumination in large-scale real-world scenarios, a process previously\napplicable only in small-scale laboratory-like conditions. Extensive\nexperimental analyses range from single-UAV imaging to specialized lighting\ntechniques requiring accurate coordination of multiple UAVs. The system's\nrobustness is demonstrated in more than two hundred autonomous flights in\nfifteen historical monuments requiring superior safety while lacking access to\nexternal localization. This unique experimental campaign, cooperated with\nrestorers and conservators, brought numerous lessons transferable to other\nsafety-critical robotic missions in documentation and inspection tasks.\n","authors":["Pavel Petracek","Vit Kratky","Tomas Baca","Matej Petrlik","Martin Saska"],"pdf_url":"https://arxiv.org/pdf/2303.02962v1.pdf","comment":"Published as Early Access on February 28, 2023. Supported by\n  multimedia available at http://mrs.felk.cvut.cz/ram2022dronument"},{"id":"http://arxiv.org/abs/2210.09566v2","updated":"2023-03-06T08:23:59Z","published":"2022-10-18T03:49:13Z","title":"Simple Emergent Action Representations from Multi-Task Policy Training","summary":"  The low-level sensory and motor signals in deep reinforcement learning, which\nexist in high-dimensional spaces such as image observations or motor torques,\nare inherently challenging to understand or utilize directly for downstream\ntasks. While sensory representations have been extensively studied, the\nrepresentations of motor actions are still an area of active exploration. Our\nwork reveals that a space containing meaningful action representations emerges\nwhen a multi-task policy network takes as inputs both states and task\nembeddings. Moderate constraints are added to improve its representation\nability. Therefore, interpolated or composed embeddings can function as a\nhigh-level interface within this space, providing instructions to the agent for\nexecuting meaningful action sequences. Empirical results demonstrate that the\nproposed action representations are effective for intra-action interpolation\nand inter-action composition with limited or no additional learning.\nFurthermore, our approach exhibits superior task adaptation ability compared to\nstrong baselines in Mujoco locomotion tasks. Our work sheds light on the\npromising direction of learning action representations for efficient,\nadaptable, and composable RL, forming the basis of abstract action planning and\nthe understanding of motor signal space. Project page:\nhttps://sites.google.com/view/emergent-action-representation/\n","authors":["Pu Hua","Yubei Chen","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2210.09566v2.pdf","comment":"22 pages, 14 figures, 18 tables, Accepeted by ICLR2023"},{"id":"http://arxiv.org/abs/2211.08024v2","updated":"2023-03-06T07:38:08Z","published":"2022-11-15T10:15:21Z","title":"NAR-Former: Neural Architecture Representation Learning towards Holistic\n  Attributes Prediction","summary":"  With the wide and deep adoption of deep learning models in real applications,\nthere is an increasing need to model and learn the representations of the\nneural networks themselves. These models can be used to estimate attributes of\ndifferent neural network architectures such as the accuracy and latency,\nwithout running the actual training or inference tasks. In this paper, we\npropose a neural architecture representation model that can be used to estimate\nthese attributes holistically. Specifically, we first propose a simple and\neffective tokenizer to encode both the operation and topology information of a\nneural network into a single sequence. Then, we design a multi-stage fusion\ntransformer to build a compact vector representation from the converted\nsequence. For efficient model training, we further propose an information flow\nconsistency augmentation and correspondingly design an architecture consistency\nloss, which brings more benefits with less augmentation samples compared with\nprevious random augmentation strategies. Experiment results on NAS-Bench-101,\nNAS-Bench-201, DARTS search space and NNLQP show that our proposed framework\ncan be used to predict the aforementioned latency and accuracy attributes of\nboth cell architectures and whole deep neural networks, and achieves promising\nperformance.\n","authors":["Yun Yi","Haokui Zhang","Wenze Hu","Nannan Wang","Xiaoyu Wang"],"pdf_url":"https://arxiv.org/pdf/2211.08024v2.pdf","comment":"9 pages, 4 figures, 7 tables. Accepted by Computer Vision and Pattern\n  Recognition (CVPR)2023. The code will be released soon"},{"id":"http://arxiv.org/abs/2303.02927v1","updated":"2023-03-06T06:47:22Z","published":"2023-03-06T06:47:22Z","title":"LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations\n  and Infographics using Large Language Models","summary":"  Systems that support users in the automatic creation of visualizations must\naddress several subtasks - understand the semantics of data, enumerate relevant\nvisualization goals and generate visualization specifications. In this work, we\npose visualization generation as a multi-stage generation problem and argue\nthat well-orchestrated pipelines based on large language models (LLMs) and\nimage generation models (IGMs) are suitable to addressing these tasks. We\npresent LIDA, a novel tool for generating grammar-agnostic visualizations and\ninfographics. LIDA comprises of 4 modules - A SUMMARIZER that converts data\ninto a rich but compact natural language summary, a GOAL EXPLORER that\nenumerates visualization goals given the data, a VISGENERATOR that generates,\nrefines, executes and filters visualization code and an INFOGRAPHER module that\nyields data-faithful stylized graphics using IGMs. LIDA provides a python api,\nand a hybrid user interface (direct manipulation and natural language) for\ninteractive chart, infographics and data story generation.\n","authors":["Victor Dibia"],"pdf_url":"https://arxiv.org/pdf/2303.02927v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.05424v4","updated":"2023-03-06T06:43:14Z","published":"2021-05-12T04:30:45Z","title":"Transitioning to human interaction with AI systems: New challenges and\n  opportunities for HCI professionals to enable human-centered AI","summary":"  While AI has benefited humans, it may also harm humans if not appropriately\ndeveloped. The focus of HCI work is transiting from conventional human\ninteraction with non-AI computing systems to interaction with AI systems. We\nconducted a high-level literature review and a holistic analysis of current\nwork in developing AI systems from an HCI perspective. Our review and analysis\nhighlight the new changes introduced by AI technology and the new challenges\nthat HCI professionals face when applying the human-centered AI (HCAI) approach\nin the development of AI systems. We also identified seven main issues in human\ninteraction with AI systems, which HCI professionals did not encounter when\ndeveloping non-AI computing systems. To further enable the implementation of\nthe HCAI approach, we identified new HCI opportunities tied to specific\nHCAI-driven design goals to guide HCI professionals in addressing these new\nissues. Finally, our assessment of current HCI methods shows the limitations of\nthese methods in support of developing AI systems. We propose alternative\nmethods that can help overcome these limitations and effectively help HCI\nprofessionals apply the HCAI approach to the development of AI systems. We also\noffer strategic recommendations for HCI professionals to effectively influence\nthe development of AI systems with the HCAI approach, eventually developing\nHCAI systems.\n","authors":["Wei Xu","Marvin J. Dainoff","Liezhong Ge","Zaifeng Gao"],"pdf_url":"https://arxiv.org/pdf/2105.05424v4.pdf","comment":"72 pages"},{"id":"http://arxiv.org/abs/2303.02920v1","updated":"2023-03-06T06:37:50Z","published":"2023-03-06T06:37:50Z","title":"Requirements Framework for Engineering Human-centered Artificial\n  Intelligence-Based Software Systems","summary":"  [Context] Artificial intelligence (AI) components used in building software\nsolutions have substantially increased in recent years. However, many of these\nsolutions end up focusing on technical aspects and ignore critical\nhuman-centered aspects. [Objective] Including human-centered aspects during\nrequirements engineering (RE) when building AI-based software can help achieve\nmore responsible, unbiased, and inclusive AI-based software solutions. [Method]\nIn this paper, we present a new framework developed based on human-centered AI\nguidelines and a user survey to aid in collecting requirements for\nhuman-centered AI-based software. We provide a catalog to elicit these\nrequirements and a conceptual model to present them visually. [Results] The\nframework is applied to a case study to elicit and model requirements for\nenhancing the quality of 360 degree~videos intended for virtual reality (VR)\nusers. [Conclusion] We found that our proposed approach helped the project team\nfully understand the needs of the project to deliver. Furthermore, the\nframework helped to understand what requirements need to be captured at the\ninitial stages against later stages in the engineering process of AI-based\nsoftware.\n","authors":["Khlood Ahmad","Mohamed Abdelrazek","Chetan Arora","Arbind Agrahari Baniya","Muneera Bano","John Grundy"],"pdf_url":"https://arxiv.org/pdf/2303.02920v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02915v1","updated":"2023-03-06T06:20:55Z","published":"2023-03-06T06:20:55Z","title":"GlobalNER: Incorporating Non-local Information into Named Entity\n  Recognition","summary":"  Nowadays, many Natural Language Processing (NLP) tasks see the demand for\nincorporating knowledge external to the local information to further improve\nthe performance. However, there is little related work on Named Entity\nRecognition (NER), which is one of the foundations of NLP. Specifically, no\nstudies were conducted on the query generation and re-ranking for retrieving\nthe related information for the purpose of improving NER. This work\ndemonstrates the effectiveness of a DNN-based query generation method and a\nmention-aware re-ranking architecture based on BERTScore particularly for NER.\nIn the end, a state-of-the-art performance of 61.56 micro-f1 score on WNUT17\ndataset is achieved.\n","authors":["Chiao-Wei Hsu","Keh-Yih Su"],"pdf_url":"https://arxiv.org/pdf/2303.02915v1.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.06681v4","updated":"2023-03-06T06:05:43Z","published":"2023-02-13T20:41:04Z","title":"User-Centered Design (IX): A \"User Experience 3.0\" Paradigm Framework in\n  the Intelligence Era","summary":"  The field of user experience (UX) based on the design philosophy of\n\"user-centered design\" is moving towards the intelligence era. Still, the\nexisting UX paradigm mainly aims at non-intelligent systems and lacks a\nsystematic approach to UX for intelligent systems. Throughout the development\nof UX, the UX paradigm shows the evolution characteristics of the\ncross-technology era. At present, the intelligence era has put forward new\ndemands on the UX paradigm. For this reason, this paper proposes a \"UX 3.0\"\nparadigm framework and the corresponding UX methodology system in the\nintelligence era. The \"UX 3.0\" paradigm framework includes five categories of\nUX methods: ecological experience, innovation-enabled experience, AI-enabled\nexperience, human-AI interaction-based experience, and human-AI\ncollaboration-based experience methods, each of which includes corresponding\nmultiple UX paradigmatic orientations. The proposal of the \"UX 3.0\" paradigm\nhelps improve the existing UX methods and provides methodological support for\nthe research and application of UX in developing intelligent systems. Finally,\nthis paper looks forward to future research and application of the \"UX 3.0\"\nparadigm.\n","authors":["Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2302.06681v4.pdf","comment":"in Chinese language"},{"id":"http://arxiv.org/abs/2303.02909v1","updated":"2023-03-06T06:04:46Z","published":"2023-03-06T06:04:46Z","title":"Dynamic Prompting: A Unified Framework for Prompt Tuning","summary":"  It has been demonstrated that prompt tuning is highly effective in\nefficiently eliciting knowledge from language models (LMs). However, the prompt\ntuning still lags behind fine-tuning, especially when the LMs are small.\nP-tuning v2 (Liu et al., 2021b) makes it comparable with finetuning by adding\ncontinuous prompts for every layer of the pre-trained model. However,\nprepending fixed soft prompts for all instances, regardless of their\ndiscrepancy, is doubtful. In particular, the inserted prompt position, length,\nand the representations of prompts for diversified instances through different\ntasks could all affect the prompt tuning performance. To fill this gap, we\npropose dynamic prompting (DP): the position, length, and prompt representation\ncan all be dynamically optimized with respect to different tasks and instances.\nWe conduct comprehensive experiments on the SuperGlue benchmark to validate our\nhypothesis and demonstrate substantial improvements. We also derive a unified\nframework for supporting our dynamic prompting strategy. In particular, we use\na simple learning network and Gumble- Softmax for learning instance-dependent\nguidance. Experimental results show that simple instance-level position-aware\nsoft prompts can improve the classification accuracy of up to 6 points on\naverage on five datasets, reducing its gap with fine-tuning. Besides, we also\nprove its universal usefulness under full-data, few-shot, and multitask\nregimes. Combining them together can even further unleash the power of DP,\nnarrowing the distance between finetuning.\n","authors":["Xianjun Yang","Wei Cheng","Xujiang Zhao","Linda Petzold","Haifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2303.02909v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2210.15809v2","updated":"2023-03-06T04:54:25Z","published":"2022-10-28T00:14:00Z","title":"Coverage-centric Coreset Selection for High Pruning Rates","summary":"  One-shot coreset selection aims to select a representative subset of the\ntraining data, given a pruning rate, that can later be used to train future\nmodels while retaining high accuracy. State-of-the-art coreset selection\nmethods pick the highest importance examples based on an importance metric and\nare found to perform well at low pruning rates. However, at high pruning rates,\nthey suffer from a catastrophic accuracy drop, performing worse than even\nrandom sampling. This paper explores the reasons behind this accuracy drop both\ntheoretically and empirically. We first propose a novel metric to measure the\ncoverage of a dataset on a specific distribution by extending the classical\ngeometric set cover problem to a distribution cover problem. This metric helps\nexplain why coresets selected by SOTA methods at high pruning rates perform\npoorly compared to random sampling because of worse data coverage. We then\npropose a novel one-shot coreset selection method, Coverage-centric Coreset\nSelection (CCS), that jointly considers overall data coverage upon a\ndistribution as well as the importance of each example. We evaluate CCS on five\ndatasets and show that, at high pruning rates (e.g., 90%), it achieves\nsignificantly better accuracy than previous SOTA methods (e.g., at least 19.56%\nhigher on CIFAR10) as well as random selection (e.g., 7.04% higher on CIFAR10)\nand comparable accuracy at low pruning rates. We make our code publicly\navailable at\nhttps://github.com/haizhongzheng/Coverage-centric-coreset-selection.\n","authors":["Haizhong Zheng","Rui Liu","Fan Lai","Atul Prakash"],"pdf_url":"https://arxiv.org/pdf/2210.15809v2.pdf","comment":"International Conference on Learning Representations (ICLR) 2023"},{"id":"http://arxiv.org/abs/2303.02891v1","updated":"2023-03-06T04:49:38Z","published":"2023-03-06T04:49:38Z","title":"Perspectives on the Social Impacts of Reinforcement Learning with Human\n  Feedback","summary":"  Is it possible for machines to think like humans? And if it is, how should we\ngo about teaching them to do so? As early as 1950, Alan Turing stated that we\nought to teach machines in the way of teaching a child. Reinforcement learning\nwith human feedback (RLHF) has emerged as a strong candidate toward allowing\nagents to learn from human feedback in a naturalistic manner. RLHF is distinct\nfrom traditional reinforcement learning as it provides feedback from a human\nteacher in addition to a reward signal. It has been catapulted into public view\nby multiple high-profile AI applications, including OpenAI's ChatGPT,\nDeepMind's Sparrow, and Anthropic's Claude. These highly capable chatbots are\nalready overturning our understanding of how AI interacts with humanity. The\nwide applicability and burgeoning success of RLHF strongly motivate the need to\nevaluate its social impacts. In light of recent developments, this paper\nconsiders an important question: can RLHF be developed and used without\nnegatively affecting human societies? Our objectives are threefold: to provide\na systematic study of the social effects of RLHF; to identify key social and\nethical issues of RLHF; and to discuss social impacts for stakeholders.\nAlthough text-based applications of RLHF have received much attention, it is\ncrucial to consider when evaluating its social implications the diverse range\nof areas to which it may be deployed. We describe seven primary ways in which\nRLHF-based technologies will affect society by positively transforming human\nexperiences with AI. This paper ultimately proposes that RLHF has potential to\nnet positively impact areas of misinformation, AI value-alignment, bias, AI\naccess, cross-cultural dialogue, industry, and workforce. As RLHF raises\nconcerns that echo those of existing AI technologies, it will be important for\nall to be aware and intentional in the adoption of RLHF.\n","authors":["Gabrielle Kaili-May Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02884v1","updated":"2023-03-06T04:31:36Z","published":"2023-03-06T04:31:36Z","title":"Model Sketching: Centering Concepts in Early-Stage Machine Learning\n  Model Design","summary":"  Machine learning practitioners often end up tunneling on low-level technical\ndetails like model architectures and performance metrics. Could early model\ndevelopment instead focus on high-level questions of which factors a model\nought to pay attention to? Inspired by the practice of sketching in design,\nwhich distills ideas to their minimal representation, we introduce model\nsketching: a technical framework for iteratively and rapidly authoring\nfunctional approximations of a machine learning model's decision-making logic.\nModel sketching refocuses practitioner attention on composing high-level,\nhuman-understandable concepts that the model is expected to reason over (e.g.,\nprofanity, racism, or sarcasm in a content moderation task) using zero-shot\nconcept instantiation. In an evaluation with 17 ML practitioners, model\nsketching reframed thinking from implementation to higher-level exploration,\nprompted iteration on a broader range of model designs, and helped identify\ngaps in the problem formulation$\\unicode{x2014}$all in a fraction of the time\nordinarily required to build a model.\n","authors":["Michelle S. Lam","Zixian Ma","Anne Li","Izequiel Freitas","Dakuo Wang","James A. Landay","Michael S. Bernstein"],"pdf_url":"https://arxiv.org/pdf/2303.02884v1.pdf","comment":"To appear at CHI 2023"},{"id":"http://arxiv.org/abs/2303.02876v1","updated":"2023-03-06T04:04:19Z","published":"2023-03-06T04:04:19Z","title":"Finding metastable skyrmionic structures via a metaheuristic\n  perturbation-driven neural network","summary":"  Topological magnetic textures observed in experiments can, in principle, be\npredicted by theoretical calculations and numerical simulations. However, such\ncalculations are, in general, hampered by difficulties in distinguishing\nbetween local and global energy minima. This becomes particularly problematic\nfor magnetic materials that allow for a multitude of topological charges.\nFinding solutions to such problems by means of classical numerical methods can\nbe challenging because either a good initial guess or a gigantic amount of\nrandom sampling is required. In this study, we demonstrate an efficient way to\nidentify those metastable configurations by leveraging the power of gradient\ndescent-based optimization within the framework of a feedforward neural network\ncombined with a heuristic meta-search, which is driven by a random perturbation\nof the neural network's input. We exemplify the power of the method by an\nanalysis of the Pd/Fe/Ir(111) system, an experimentally well characterized\nsystem.\n","authors":["Qichen Xu","I. P. Miranda","Manuel Pereiro","Filipp N. Rybakov","Danny Thonig","Erik Sjöqvist","Pavel Bessarab","Anders Bergman","Olle Eriksson","Pawel Herman","Anna Delin"],"pdf_url":"https://arxiv.org/pdf/2303.02876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08289v2","updated":"2023-03-06T03:54:50Z","published":"2022-06-16T16:46:32Z","title":"Switchable Representation Learning Framework with Self-compatibility","summary":"  Real-world visual search systems involve deployments on multiple platforms\nwith different computing and storage resources. Deploying a unified model that\nsuits the minimal-constrain platforms leads to limited accuracy. It is expected\nto deploy models with different capacities adapting to the resource\nconstraints, which requires features extracted by these models to be aligned in\nthe metric space. The method to achieve feature alignments is called\n``compatible learning''. Existing research mainly focuses on the one-to-one\ncompatible paradigm, which is limited in learning compatibility among multiple\nmodels. We propose a \\textbf{S}witchable representation learning Framework with\nSelf-Compatibility (SFSC). SFSC generates a series of compatible sub-models\nwith different capacities through one training process. The optimization of\nsub-models faces gradients conflict, and we mitigate this problem from the\nperspective of the magnitude and direction. We adjust the priorities of\nsub-models dynamically through uncertainty estimation to co-optimize sub-models\nproperly. Besides, the gradients with conflicting directions are projected to\navoid mutual interference. SFSC achieves state-of-the-art performance on the\nevaluated datasets.\n","authors":["Shengsen Wu","Yan Bai","Yihang Lou","Xiongkun Linghu","Jianzhong He","Ling-Yu Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08289v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02871v1","updated":"2023-03-06T03:43:14Z","published":"2023-03-06T03:43:14Z","title":"Naming Objects for Vision-and-Language Manipulation","summary":"  Robot manipulation tasks by natural language instructions need common\nunderstanding of the target object between human and the robot. However, the\ninstructions often have an interpretation ambiguity, because the instruction\nlacks important information, or does not express the target object correctly to\ncomplete the task. To solve this ambiguity problem, we hypothesize that\n\"naming\" the target objects in advance will reduce the ambiguity of natural\nlanguage instructions. We propose a robot system and method that incorporates\nnaming with appearance of the objects in advance, so that in the later\nmanipulation task, instruction can be performed with its unique name to\ndisambiguate the objects easily. To demonstrate the effectiveness of our\napproach, we build a system that can memorize the target objects, and show that\nnaming the objects facilitates detection of the target objects and improves the\nsuccess rate of manipulation instructions. With this method, the success rate\nof object manipulation task increases by 31% in ambiguous instructions.\n","authors":["Tokuhiro Nishikawa","Kazumi Aoyama","Shunichi Sekiguchi","Takayoshi Takayanagi","Jianing Wu","Yu Ishihara","Tamaki Kojima","Jerry Jun Yokono"],"pdf_url":"https://arxiv.org/pdf/2303.02871v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.01506v2","updated":"2023-03-06T03:41:17Z","published":"2023-03-02T04:50:05Z","title":"Understanding and Unifying Fourteen Attribution Methods with Taylor\n  Interactions","summary":"  Various attribution methods have been developed to explain deep neural\nnetworks (DNNs) by inferring the attribution/importance/contribution score of\neach input variable to the final output. However, existing attribution methods\nare often built upon different heuristics. There remains a lack of a unified\ntheoretical understanding of why these methods are effective and how they are\nrelated. To this end, for the first time, we formulate core mechanisms of\nfourteen attribution methods, which were designed on different heuristics, into\nthe same mathematical system, i.e., the system of Taylor interactions.\nSpecifically, we prove that attribution scores estimated by fourteen\nattribution methods can all be reformulated as the weighted sum of two types of\neffects, i.e., independent effects of each individual input variable and\ninteraction effects between input variables. The essential difference among the\nfourteen attribution methods mainly lies in the weights of allocating different\neffects. Based on the above findings, we propose three principles for a fair\nallocation of effects to evaluate the faithfulness of the fourteen attribution\nmethods.\n","authors":["Huiqi Deng","Na Zou","Mengnan Du","Weifu Chen","Guocan Feng","Ziwei Yang","Zheyang Li","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.01506v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09425v2","updated":"2023-03-06T03:27:37Z","published":"2023-02-18T21:30:44Z","title":"An Approach for Solving Tasks on the Abstract Reasoning Corpus","summary":"  The Abstract Reasoning Corpus (ARC) is an intelligence tests for measuring\nfluid intelligence in artificial intelligence systems and humans alike. In this\npaper we present a system for reasoning about and solving ARC tasks. Our system\nrelies on a program synthesis approach that searches a space of potential\nprograms for ones that can solve tasks from the ARC. Programs are in a domain\nspecific language, and in some instances our search algorithm is guided by\ninsights from a corpus of ground truth programs. In particular: We describe an\nimperative style domain specific language, called Visual Imagery Reasoning\nLanguage (VIMRL), for reasoning about tasks in the ARC. We also demonstrate an\ninnovative approach for how large search spaces can be decomposed using special\nhigh level functions that determine their own arguments through local searches\non a given task item. Finally, we share our results obtained on the publicly\navailable ARC items as well as our system's strong performance on a private\ntest, recently tying for 4th place on the global ARCathon 2022 challenge.\n","authors":["James Ainooson","Deepayan Sanyal","Joel P. Michelson","Yuan Yang","Maithilee Kunda"],"pdf_url":"https://arxiv.org/pdf/2302.09425v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02862v1","updated":"2023-03-06T03:27:17Z","published":"2023-03-06T03:27:17Z","title":"EvHandPose: Event-based 3D Hand Pose Estimation with Sparse Supervision","summary":"  Event camera shows great potential in 3D hand pose estimation, especially\naddressing the challenges of fast motion and high dynamic range in a low-power\nway. However, due to the asynchronous differential imaging mechanism, it is\nchallenging to design event representation to encode hand motion information\nespecially when the hands are not moving (causing motion ambiguity), and it is\ninfeasible to fully annotate the temporally dense event stream. In this paper,\nwe propose EvHandPose with novel hand flow representations in Event-to-Pose\nmodule for accurate hand pose estimation and alleviating the motion ambiguity\nissue. To solve the problem under sparse annotation, we design contrast\nmaximization and edge constraints in Pose-to-IWE (Image with Warped Events)\nmodule and formulate EvHandPose in a self-supervision framework. We further\nbuild EvRealHands, the first large-scale real-world event-based hand pose\ndataset on several challenging scenes to bridge the domain gap due to relying\non synthetic data and facilitate future research. Experiments on EvRealHands\ndemonstrate that EvHandPose outperforms previous event-based method under all\nevaluation scenes with 15 $\\sim$ 20 mm lower MPJPE and achieves accurate and\nstable hand pose estimation in fast motion and strong light scenes compared\nwith RGB-based methods. Furthermore, EvHandPose demonstrates 3D hand pose\nestimation at 120 fps or higher.\n","authors":["Jianping Jiang","Jiahe Li","Baowen Zhang","Xiaoming Deng","Boxin Shi"],"pdf_url":"https://arxiv.org/pdf/2303.02862v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13221v2","updated":"2023-03-06T02:56:19Z","published":"2023-02-26T03:18:45Z","title":"Data-Centric AI: Deep Generative Differentiable Feature Selection via\n  Discrete Subsetting as Continuous Embedding Space Optimization","summary":"  Feature Selection (FS), such as filter, wrapper, and embedded methods, aims\nto find the optimal feature subset for a given downstream task. However, in\nmany real-world practices, 1) the criteria of FS vary across domains; 2) FS is\nbrittle when data is a high-dimensional and small sample size. Can selected\nfeature subsets be more generalized, accurate, and input dimensionality\nagnostic? We generalize this problem into a deep differentiable feature\nselection task and propose a new perspective: discrete feature subsetting as\ncontinuous embedding space optimization. We develop a generic and principled\nframework including a deep feature subset encoder, accuracy evaluator, decoder,\nand gradient ascent optimizer. This framework implements four steps: 1)\nfeatures-accuracy training data preparation; 2) deep feature subset embedding;\n3) gradient-optimized search; 4) feature subset reconstruction. We develop new\ntechnical insights: reinforcement as a training data generator, ensembles of\ndiverse peer and exploratory feature selector knowledge for generalization, an\neffective embedding from feature subsets to continuous space along with joint\noptimizing reconstruction and accuracy losses to select accurate features.\nExperimental results demonstrate the effectiveness of the proposed method.\n","authors":["Meng Xiao","Dongjie Wang","Min Wu","Pengfei Wang","Yuanchun Zhou","Yanjie Fu"],"pdf_url":"https://arxiv.org/pdf/2302.13221v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2303.02846v1","updated":"2023-03-06T02:52:37Z","published":"2023-03-06T02:52:37Z","title":"Reducing Spurious Correlations for Aspect-Based Sentiment Analysis with\n  Variational Information Bottleneck and Contrastive Learning","summary":"  The literature on aspect-based sentiment analysis (ABSA) has been overwhelmed\nby deep neural networks, yielding state-of-the-art results for ABSA. However,\nthese deep models are susceptible to learning spurious correlations between\ninput features and output labels, which in general suffer from poor robustness\nand generalization. In this paper, we propose a novel Contrastive Variational\nInformation Bottleneck framework (called CVIB) to reduce spurious correlations\nfor ABSA. The proposed CVIB framework is composed of an original network and a\nself-pruned network, and these two networks are optimized simultaneously via\ncontrastive learning. Concretely, we employ the Variational Information\nBottleneck (VIB) principle to learn an informative and compressed network\n(self-pruned network) from the original network, which discards the superfluous\npatterns or spurious correlations between input features and prediction labels.\nThen, self-pruning contrastive learning is devised to pull together\nsemantically similar positive pairs and push away dissimilar pairs, where the\nrepresentations of the anchor learned by the original and self-pruned networks\nrespectively are regarded as a positive pair while the representations of two\ndifferent sentences within a mini-batch are treated as a negative pair.\nExtensive experiments on five benchmark ABSA datasets demonstrate that our CVIB\nmethod achieves better performance than the strong competitors in terms of\noverall prediction performance, robustness, and generalization.\n","authors":["Mingshan Chang","Min Yang","Qingshan Jiang","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2303.02846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.08345v2","updated":"2023-03-06T02:46:59Z","published":"2022-10-15T17:36:04Z","title":"Augmentation-Free Graph Contrastive Learning of Invariant-Discriminative\n  Representations","summary":"  The pretasks are mainly built on mutual information estimation, which\nrequires data augmentation to construct positive samples with similar semantics\nto learn invariant signals and negative samples with dissimilar semantics in\norder to empower representation discriminability. However, an appropriate data\naugmentation configuration depends heavily on lots of empirical trials such as\nchoosing the compositions of data augmentation techniques and the corresponding\nhyperparameter settings. We propose an augmentation-free graph contrastive\nlearning method, invariant-discriminative graph contrastive learning (iGCL),\nthat does not intrinsically require negative samples. iGCL designs the\ninvariant-discriminative loss (ID loss) to learn invariant and discriminative\nrepresentations. On the one hand, ID loss learns invariant signals by directly\nminimizing the mean square error between the target samples and positive\nsamples in the representation space. On the other hand, ID loss ensures that\nthe representations are discriminative by an orthonormal constraint forcing the\ndifferent dimensions of representations to be independent of each other. This\nprevents representations from collapsing to a point or subspace. Our\ntheoretical analysis explains the effectiveness of ID loss from the\nperspectives of the redundancy reduction criterion, canonical correlation\nanalysis, and information bottleneck principle. The experimental results\ndemonstrate that iGCL outperforms all baselines on 5 node classification\nbenchmark datasets. iGCL also shows superior performance for different label\nratios and is capable of resisting graph attacks, which indicates that iGCL has\nexcellent generalization and robustness. The source code is available at\nhttps://github.com/lehaifeng/T-GCN/tree/master/iGCL.\n","authors":["Haifeng Li","Jun Cao","Jiawei Zhu","Qinyao Luo","Silu He","Xuyin Wang"],"pdf_url":"https://arxiv.org/pdf/2210.08345v2.pdf","comment":"11 pages 8 figs"},{"id":"http://arxiv.org/abs/2211.01806v2","updated":"2023-03-06T02:26:40Z","published":"2022-11-02T16:03:43Z","title":"BATT: Backdoor Attack with Transformation-based Triggers","summary":"  Deep neural networks (DNNs) are vulnerable to backdoor attacks. The backdoor\nadversaries intend to maliciously control the predictions of attacked DNNs by\ninjecting hidden backdoors that can be activated by adversary-specified trigger\npatterns during the training process. One recent research revealed that most of\nthe existing attacks failed in the real physical world since the trigger\ncontained in the digitized test samples may be different from that of the one\nused for training. Accordingly, users can adopt spatial transformations as the\nimage pre-processing to deactivate hidden backdoors. In this paper, we explore\nthe previous findings from another side. We exploit classical spatial\ntransformations (i.e. rotation and translation) with the specific parameter as\ntrigger patterns to design a simple yet effective poisoning-based backdoor\nattack. For example, only images rotated to a particular angle can activate the\nembedded backdoor of attacked DNNs. Extensive experiments are conducted,\nverifying the effectiveness of our attack under both digital and physical\nsettings and its resistance to existing backdoor defenses.\n","authors":["Tong Xu","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.01806v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2303.02841v1","updated":"2023-03-06T02:24:48Z","published":"2023-03-06T02:24:48Z","title":"Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in\n  Finance","summary":"  Natural language understanding(NLU) is challenging for finance due to the\nlack of annotated data and the specialized language in that domain. As a\nresult, researchers have proposed to use pre-trained language model and\nmulti-task learning to learn robust representations. However, aggressive\nfine-tuning often causes over-fitting and multi-task learning may favor tasks\nwith significantly larger amounts data, etc. To address these problems, in this\npaper, we investigate model-agnostic meta-learning algorithm(MAML) in\nlow-resource financial NLU tasks. Our contribution includes: 1. we explore the\nperformance of MAML method with multiple types of tasks: GLUE datasets, SNLI,\nSci-Tail and Financial PhraseBank; 2. we study the performance of MAML method\nwith multiple single-type tasks: a real scenario stock price prediction problem\nwith twitter text data. Our models achieve the state-of-the-art performance\naccording to the experimental results, which demonstrate that our method can\nadapt fast and well to low-resource situations.\n","authors":["Bixing Yan","Shaoling Chen","Yuxuan He","Zhihan Li"],"pdf_url":"https://arxiv.org/pdf/2303.02841v1.pdf","comment":"13 pages, 6 figures, 8 tables"},{"id":"http://arxiv.org/abs/2211.05638v2","updated":"2023-03-06T02:20:32Z","published":"2022-11-02T17:05:45Z","title":"Untargeted Backdoor Attack against Object Detection","summary":"  Recent studies revealed that deep neural networks (DNNs) are exposed to\nbackdoor threats when training with third-party resources (such as training\nsamples or backbones). The backdoored model has promising performance in\npredicting benign samples, whereas its predictions can be maliciously\nmanipulated by adversaries based on activating its backdoors with pre-defined\ntrigger patterns. Currently, most of the existing backdoor attacks were\nconducted on the image classification under the targeted manner. In this paper,\nwe reveal that these threats could also happen in object detection, posing\nthreatening risks to many mission-critical applications ($e.g.$, pedestrian\ndetection and intelligent surveillance systems). Specifically, we design a\nsimple yet effective poison-only backdoor attack in an untargeted manner, based\non task characteristics. We show that, once the backdoor is embedded into the\ntarget model by our attack, it can trick the model to lose detection of any\nobject stamped with our trigger patterns. We conduct extensive experiments on\nthe benchmark dataset, showing its effectiveness in both digital and\nphysical-world settings and its resistance to potential defenses.\n","authors":["Chengxiao Luo","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.05638v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2103.01400v4","updated":"2023-03-06T02:05:31Z","published":"2021-03-02T01:27:16Z","title":"Smoothness Analysis of Adversarial Training","summary":"  Deep neural networks are vulnerable to adversarial attacks. Recent studies\nabout adversarial robustness focus on the loss landscape in the parameter space\nsince it is related to optimization and generalization performance. These\nstudies conclude that the difficulty of adversarial training is caused by the\nnon-smoothness of the loss function: i.e., its gradient is not Lipschitz\ncontinuous. However, this analysis ignores the dependence of adversarial\nattacks on model parameters. Since adversarial attacks are optimized for\nmodels, they should depend on the parameters. Considering this dependence, we\nanalyze the smoothness of the loss function of adversarial training using the\noptimal attacks for the model parameter in more detail. We reveal that the\nconstraint of adversarial attacks is one cause of the non-smoothness and that\nthe smoothness depends on the types of the constraints. Specifically, the\n$L_\\infty$ constraint can cause non-smoothness more than the $L_2$ constraint.\nMoreover, our analysis implies that if we flatten the loss function with\nrespect to input data, the Lipschitz constant of the gradient of adversarial\nloss tends to increase. To address the non-smoothness, we show that EntropySGD\nsmoothens the non-smooth loss and improves the performance of adversarial\ntraining.\n","authors":["Sekitoshi Kanai","Masanori Yamada","Hiroshi Takahashi","Yuki Yamanaka","Yasutoshi Ida"],"pdf_url":"https://arxiv.org/pdf/2103.01400v4.pdf","comment":"The latest version of this article is published in IEEE Transactions\n  on Neural Networks and Learning Systems (DOI: 10.1109/TNNLS.2023.3244172). 22\n  pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.14208v2","updated":"2023-03-06T02:04:39Z","published":"2023-02-28T00:05:48Z","title":"Methods and Mechanisms for Interactive Novelty Handling in Adversarial\n  Environments","summary":"  Learning to detect, characterize and accommodate novelties is a challenge\nthat agents operating in open-world domains need to address to be able to\nguarantee satisfactory task performance. Certain novelties (e.g., changes in\nenvironment dynamics) can interfere with the performance or prevent agents from\naccomplishing task goals altogether. In this paper, we introduce general\nmethods and architectural mechanisms for detecting and characterizing different\ntypes of novelties, and for building an appropriate adaptive model to\naccommodate them utilizing logical representations and reasoning methods. We\ndemonstrate the effectiveness of the proposed methods in evaluations performed\nby a third party in the adversarial multi-agent board game Monopoly. The\nresults show high novelty detection and accommodation rates across a variety of\nnovelty types, including changes to the rules of the game, as well as changes\nto the agent's action capabilities.\n","authors":["Tung Thai","Ming Shen","Mayank Garg","Ayush Kalani","Nakul Vaidya","Utkarsh Soni","Mudit Verma","Sriram Gopalakrishnan","Neeraj Varshney","Chitta Baral","Subbarao Kambhampati","Jivko Sinapov","Matthias Scheutz"],"pdf_url":"https://arxiv.org/pdf/2302.14208v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02833v1","updated":"2023-03-06T01:59:45Z","published":"2023-03-06T01:59:45Z","title":"eCDANs: Efficient Temporal Causal Discovery from Autocorrelated and\n  Non-stationary Data (Student Abstract)","summary":"  Conventional temporal causal discovery (CD) methods suffer from high\ndimensionality, fail to identify lagged causal relationships, and often ignore\ndynamics in relations. In this study, we present a novel constraint-based CD\napproach for autocorrelated and non-stationary time series data (eCDANs)\ncapable of detecting lagged and contemporaneous causal relationships along with\ntemporal changes. eCDANs addresses high dimensionality by optimizing the\nconditioning sets while conducting conditional independence (CI) tests and\nidentifies the changes in causal relations by introducing a surrogate variable\nto represent time dependency. Experiments on synthetic and real-world data show\nthat eCDANs can identify time influence and outperform the baselines.\n","authors":["Muhammad Hasan Ferdous","Uzma Hasan","Md Osman Gani"],"pdf_url":"https://arxiv.org/pdf/2303.02833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12987v2","updated":"2023-03-06T01:54:22Z","published":"2023-01-30T15:29:40Z","title":"The Optimal Choice of Hypothesis Is the Weakest, Not the Shortest","summary":"  If $A$ and $B$ are sets such that $A \\subset B$, generalisation may be\nunderstood as the inference from $A$ of a hypothesis sufficient to construct\n$B$. One might infer any number of hypotheses from $A$, yet only some of those\nmay generalise to $B$. How can one know which are likely to generalise? One\nstrategy is to choose the shortest, equating the ability to compress\ninformation with the ability to generalise (a proxy for intelligence). We\nexamine this in the context of a mathematical formalism of enactive cognition.\nWe show that compression is neither necessary nor sufficient to maximise\nperformance (measured in terms of the probability of a hypothesis\ngeneralising). We formulate a proxy unrelated to length or simplicity, called\nweakness. We show that if tasks are uniformly distributed, then there is no\nchoice of proxy that performs at least as well as weakness maximisation in all\ntasks while performing strictly better in at least one. In other words,\nweakness is the pareto optimal choice of proxy. In experiments comparing\nmaximum weakness and minimum description length in the context of binary\narithmetic, the former generalised at between $1.1$ and $5$ times the rate of\nthe latter. We argue this demonstrates that weakness is a far better proxy, and\nexplains why Deepmind's Apperception Engine is able to generalise effectively.\n","authors":["Michael Timothy Bennett"],"pdf_url":"https://arxiv.org/pdf/2301.12987v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02829v1","updated":"2023-03-06T01:46:51Z","published":"2023-03-06T01:46:51Z","title":"Attribution-Scores and Causal Counterfactuals as Explanations in\n  Artificial Intelligence","summary":"  In this expository article we highlight the relevance of explanations for\nartificial intelligence, in general, and for the newer developments in {\\em\nexplainable AI}, referring to origins and connections of and among different\napproaches. We describe in simple terms, explanations in data management and\nmachine learning that are based on attribution-scores, and counterfactuals as\nfound in the area of causality. We elaborate on the importance of logical\nreasoning when dealing with counterfactuals, and their use for score\ncomputation.\n","authors":["Leopoldo Bertossi"],"pdf_url":"https://arxiv.org/pdf/2303.02829v1.pdf","comment":"Submitted as chapter contribution"},{"id":"http://arxiv.org/abs/2303.02828v1","updated":"2023-03-06T01:45:32Z","published":"2023-03-06T01:45:32Z","title":"Robust Autoencoders for Collective Corruption Removal","summary":"  Robust PCA is a standard tool for learning a linear subspace in the presence\nof sparse corruption or rare outliers. What about robustly learning manifolds\nthat are more realistic models for natural data, such as images? There have\nbeen several recent attempts to generalize robust PCA to manifold settings. In\nthis paper, we propose $\\ell_1$- and scaling-invariant $\\ell_1/\\ell_2$-robust\nautoencoders based on a surprisingly compact formulation built on the intuition\nthat deep autoencoders perform manifold learning. We demonstrate on several\nstandard image datasets that the proposed formulation significantly outperforms\nall previous methods in collectively removing sparse corruption, without clean\nimages for training. Moreover, we also show that the learned manifold\nstructures can be generalized to unseen data samples effectively.\n","authors":["Taihui Li","Hengkang Wang","Peng Le","XianE Tang","Ju Sun"],"pdf_url":"https://arxiv.org/pdf/2303.02828v1.pdf","comment":"This paper has been accepted to ICASSP2023"},{"id":"http://arxiv.org/abs/2303.02819v1","updated":"2023-03-06T01:19:25Z","published":"2023-03-06T01:19:25Z","title":"Artificial Intelligence: 70 Years Down the Road","summary":"  Artificial intelligence (AI) has a history of nearly a century from its\ninception to the present day. We have summarized the development trends and\ndiscovered universal rules, including both success and failure. We have\nanalyzed the reasons from both technical and philosophical perspectives to help\nunderstand the reasons behind the past failures and current successes of AI,\nand to provide a basis for thinking and exploring future development.\nSpecifically, we have found that the development of AI in different fields,\nincluding computer vision, natural language processing, and machine learning,\nfollows a pattern from rules to statistics to data-driven methods. In the face\nof past failures and current successes, we need to think systematically about\nthe reasons behind them. Given the unity of AI between natural and social\nsciences, it is necessary to incorporate philosophical thinking to understand\nand solve AI problems, and we believe that starting from the dialectical method\nof Marx is a feasible path. We have concluded that the sustainable development\ndirection of AI should be human-machine collaboration and a technology path\ncentered on computing power. Finally, we have summarized the impact of AI on\nsociety from this trend.\n","authors":["Lin Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02810v1","updated":"2023-03-06T00:50:23Z","published":"2023-03-06T00:50:23Z","title":"A System's Approach Taxonomy for User-Centred XAI: A Survey","summary":"  Recent advancements in AI have coincided with ever-increasing efforts in the\nresearch community to investigate, classify and evaluate various methods aimed\nat making AI models explainable. However, most of existing attempts present a\nmethod-centric view of eXplainable AI (XAI) which is typically meaningful only\nfor domain experts. There is an apparent lack of a robust qualitative and\nquantitative performance framework that evaluates the suitability of\nexplanations for different types of users. We survey relevant efforts, and\nthen, propose a unified, inclusive and user-centred taxonomy for XAI based on\nthe principles of General System's Theory, which serves us as a basis for\nevaluating the appropriateness of XAI approaches for all user types, including\nboth developers and end users.\n","authors":["Ehsan Emamirad","Pouya Ghiasnezhad Omran","Armin Haller","Shirley Gregor"],"pdf_url":"https://arxiv.org/pdf/2303.02810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.10475v2","updated":"2023-03-06T00:49:01Z","published":"2022-05-21T00:58:22Z","title":"DeepStruct: Pretraining of Language Models for Structure Prediction","summary":"  We introduce a method for improving the structural understanding abilities of\nlanguage models. Unlike previous approaches that finetune the models with\ntask-specific augmentation, we pretrain language models on a collection of\ntask-agnostic corpora to generate structures from text. Our structure\npretraining enables zero-shot transfer of the learned knowledge that models\nhave about the structure tasks. We study the performance of this approach on 28\ndatasets, spanning 10 structure prediction tasks including open information\nextraction, joint entity and relation extraction, named entity recognition,\nrelation classification, semantic role labeling, event extraction, coreference\nresolution, factual probe, intent detection, and dialogue state tracking. We\nfurther enhance the pretraining with the task-specific training sets. We show\nthat a 10B parameter language model transfers non-trivially to most tasks and\nobtains state-of-the-art performance on 21 of 28 datasets that we evaluate.\n","authors":["Chenguang Wang","Xiao Liu","Zui Chen","Haoyun Hong","Jie Tang","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2205.10475v2.pdf","comment":"ACL 2022"},{"id":"http://arxiv.org/abs/2302.03189v2","updated":"2023-03-06T00:40:42Z","published":"2023-02-07T01:41:23Z","title":"Emergent Causality & the Foundation of Consciousness","summary":"  To make accurate inferences in an interactive setting, an agent must not\nconfuse passive observation of events with having intervened to cause those\nevents. The do operator formalises interventions so that we may reason about\ntheir effect. Yet there exist pareto optimal mathematical formalisms of general\nintelligence in an interactive setting which, presupposing no explicit\nrepresentation of intervention, make maximally accurate inferences. We examine\none such formalism. We show that in the absence of an operator, an intervention\ncan still be represented by a variable. Furthermore, the need to explicitly\nrepresent interventions in advance arises only because we presuppose\nabstractions. The aforementioned formalism avoids this and so, initial\nconditions permitting, representations of relevant causal interventions will\nemerge through induction. These emergent abstractions function as\nrepresentations of one`s self and of any other object, inasmuch as the\ninterventions of those objects impact the satisfaction of goals. We argue (with\nreference to theory of mind) that this explains how one might reason about\none's own identity and intent, those of others, of one`s own as perceived by\nothers and so on. In a narrow sense this describes what it is to be aware, and\nis a mechanistic explanation of aspects of consciousness.\n","authors":["Michael Timothy Bennett"],"pdf_url":"https://arxiv.org/pdf/2302.03189v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.04615v2","updated":"2023-03-06T00:29:14Z","published":"2021-02-09T02:50:29Z","title":"Benford's law: what does it say on adversarial images?","summary":"  Convolutional neural networks (CNNs) are fragile to small perturbations in\nthe input images. These networks are thus prone to malicious attacks that\nperturb the inputs to force a misclassification. Such slightly manipulated\nimages aimed at deceiving the classifier are known as adversarial images. In\nthis work, we investigate statistical differences between natural images and\nadversarial ones. More precisely, we show that employing a proper image\ntransformation and for a class of adversarial attacks, the distribution of the\nleading digit of the pixels in adversarial images deviates from Benford's law.\nThe stronger the attack, the more distant the resulting distribution is from\nBenford's law. Our analysis provides a detailed investigation of this new\napproach that can serve as a basis for alternative adversarial example\ndetection methods that do not need to modify the original CNN classifier\nneither work on the raw high-dimensional pixels as features to defend against\nattacks.\n","authors":["João G. Zago","Fabio L. Baldissera","Eric A. Antonelo","Rodrigo T. Saad"],"pdf_url":"https://arxiv.org/pdf/2102.04615v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.00182v3","updated":"2023-03-06T23:30:28Z","published":"2022-02-01T02:06:54Z","title":"Semi-supervised 3D Object Detection via Temporal Graph Neural Networks","summary":"  3D object detection plays an important role in autonomous driving and other\nrobotics applications. However, these detectors usually require training on\nlarge amounts of annotated data that is expensive and time-consuming to\ncollect. Instead, we propose leveraging large amounts of unlabeled point cloud\nvideos by semi-supervised learning of 3D object detectors via temporal graph\nneural networks. Our insight is that temporal smoothing can create more\naccurate detection results on unlabeled data, and these smoothed detections can\nthen be used to retrain the detector. We learn to perform this temporal\nreasoning with a graph neural network, where edges represent the relationship\nbetween candidate detections in different time frames. After semi-supervised\nlearning, our method achieves state-of-the-art detection performance on the\nchallenging nuScenes and H3D benchmarks, compared to baselines trained on the\nsame amount of labeled data. Project and code are released at\nhttps://www.jianrenw.com/SOD-TGNN/.\n","authors":["Jianren Wang","Haiming Gang","Siddharth Ancha","Yi-Ting Chen","David Held"],"pdf_url":"https://arxiv.org/pdf/2202.00182v3.pdf","comment":"3DV 2021"},{"id":"http://arxiv.org/abs/2303.03542v1","updated":"2023-03-06T22:59:02Z","published":"2023-03-06T22:59:02Z","title":"Multi-resolution Interpretation and Diagnostics Tool for Natural\n  Language Classifiers","summary":"  Developing explainability methods for Natural Language Processing (NLP)\nmodels is a challenging task, for two main reasons. First, the high\ndimensionality of the data (large number of tokens) results in low coverage and\nin turn small contributions for the top tokens, compared to the overall model\nperformance. Second, owing to their textual nature, the input variables, after\nappropriate transformations, are effectively binary (presence or absence of a\ntoken in an observation), making the input-output relationship difficult to\nunderstand. Common NLP interpretation techniques do not have flexibility in\nresolution, because they usually operate at word-level and provide fully local\n(message level) or fully global (over all messages) summaries. The goal of this\npaper is to create more flexible model explainability summaries by segments of\nobservation or clusters of words that are semantically related to each other.\nIn addition, we introduce a root cause analysis method for NLP models, by\nanalyzing representative False Positive and False Negative examples from\ndifferent segments. At the end, we illustrate, using a Yelp review data set\nwith three segments (Restaurant, Hotel, and Beauty), that exploiting\ngroup/cluster structures in words and/or messages can aid in the interpretation\nof decisions made by NLP models and can be utilized to assess the model's\nsensitivity or bias towards gender, syntax, and word meanings.\n","authors":["Peyman Jalali","Nengfeng Zhou","Yufei Yu"],"pdf_url":"https://arxiv.org/pdf/2303.03542v1.pdf","comment":"16 pages, 0 figure"},{"id":"http://arxiv.org/abs/2206.02914v2","updated":"2023-03-06T22:55:36Z","published":"2022-06-06T21:31:32Z","title":"Training Subset Selection for Weak Supervision","summary":"  Existing weak supervision approaches use all the data covered by weak signals\nto train a classifier. We show both theoretically and empirically that this is\nnot always optimal. Intuitively, there is a tradeoff between the amount of\nweakly-labeled data and the precision of the weak labels. We explore this\ntradeoff by combining pretrained data representations with the cut statistic\n(Muhlenbach et al., 2004) to select (hopefully) high-quality subsets of the\nweakly-labeled training data. Subset selection applies to any label model and\nclassifier and is very simple to plug in to existing weak supervision\npipelines, requiring just a few lines of code. We show our subset selection\nmethod improves the performance of weak supervision for a wide range of label\nmodels, classifiers, and datasets. Using less weakly-labeled data improves the\naccuracy of weak supervision pipelines by up to 19% (absolute) on benchmark\ntasks.\n","authors":["Hunter Lang","Aravindan Vijayaraghavan","David Sontag"],"pdf_url":"https://arxiv.org/pdf/2206.02914v2.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2303.03538v1","updated":"2023-03-06T22:47:40Z","published":"2023-03-06T22:47:40Z","title":"Evolutionary Deep Nets for Non-Intrusive Load Monitoring","summary":"  Non-Intrusive Load Monitoring (NILM) is an energy efficiency technique to\ntrack electricity consumption of an individual appliance in a household by one\naggregated single, such as building level meter readings. The goal of NILM is\nto disaggregate the appliance from the aggregated singles by computational\nmethod. In this work, deep learning approaches are implemented to operate the\ndesegregations. Deep neural networks, convolutional neural networks, and\nrecurrent neural networks are employed for this operation. Additionally, sparse\nevolutionary training is applied to accelerate training efficiency of each deep\nlearning model. UK-Dale dataset is used for this work.\n","authors":["Jinsong Wang","Kenneth A. Loparo"],"pdf_url":"https://arxiv.org/pdf/2303.03538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03533v1","updated":"2023-03-06T22:39:20Z","published":"2023-03-06T22:39:20Z","title":"Value Guided Exploration with Sub-optimal Controllers for Learning\n  Dexterous Manipulation","summary":"  Recently, reinforcement learning has allowed dexterous manipulation skills\nwith increasing complexity. Nonetheless, learning these skills in simulation\nstill exhibits poor sample-efficiency which stems from the fact these skills\nare learned from scratch without the benefit of any domain expertise. In this\nwork, we aim to improve the sample-efficiency of learning dexterous in-hand\nmanipulation skills using sub-optimal controllers available via domain\nknowledge. Our framework optimally queries the sub-optimal controllers and\nguides exploration toward state-space relevant to the task thereby\ndemonstrating improved sample complexity. We show that our framework allows\nlearning from highly sub-optimal controllers and we are the first to\ndemonstrate learning hard-to-explore finger-gaiting in-hand manipulation skills\nwithout the use of an exploratory reset distribution.\n","authors":["Gagan Khandate","Cameron Mehlman","Xingsheng Wei","Matei Ciocarlie"],"pdf_url":"https://arxiv.org/pdf/2303.03533v1.pdf","comment":"7 pages, 6 figures, submitted to International Conference on\n  Intelligent Robots & Systems 2023"},{"id":"http://arxiv.org/abs/2302.09051v2","updated":"2023-03-06T21:46:08Z","published":"2023-02-17T18:31:31Z","title":"Complex QA and language models hybrid architectures, Survey","summary":"  This paper provides a survey of the state of the art of hybrid language\nmodels architectures and strategies for \"complex\" question-answering (QA, CQA,\nCPS). Very large language models are good at leveraging public data on standard\nproblems but once you want to tackle more specific complex questions or\nproblems you may need specific architecture, knowledge, skills, tasks, methods,\nsensitive data, performance, human approval and versatile feedback... This\nsurvey extends findings from the robust community edited research papers BIG,\nBLOOM and HELM which open source, benchmark and analyze limits and challenges\nof large language models in terms of tasks complexity and strict evaluation on\naccuracy (e.g. fairness, robustness, toxicity, ...). It identifies the key\nelements used with Large Language Models (LLM) to solve complex questions or\nproblems. Recent projects like ChatGPT and GALACTICA have allowed\nnon-specialists to grasp the great potential as well as the equally strong\nlimitations of language models in complex QA. Hybridizing these models with\ndifferent components could allow to overcome these different limits and go much\nfurther. We discuss some challenges associated with complex QA, including\ndomain adaptation, decomposition and efficient multi-step QA, long form QA,\nnon-factoid QA, safety and multi-sensitivity data protection, multimodal\nsearch, hallucinations, QA explainability and truthfulness, time dimension.\nTherefore we review current solutions and promising strategies, using elements\nsuch as hybrid LLM architectures, human-in-the-loop reinforcement learning,\nprompting adaptation, neuro-symbolic and structured knowledge grounding,\nprogram synthesis, and others. We analyze existing solutions and provide an\noverview of the current research and trends in the area of complex QA.\n","authors":["Xavier Daull","Patrice Bellot","Emmanuel Bruno","Vincent Martin","Elisabeth Murisasco"],"pdf_url":"https://arxiv.org/pdf/2302.09051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03511v1","updated":"2023-03-06T21:40:51Z","published":"2023-03-06T21:40:51Z","title":"Applying Artificial Intelligence to Clinical Decision Support in Mental\n  Health: What Have We Learned?","summary":"  Clinical decision support systems (CDSS) augmented with artificial\nintelligence (AI) models are emerging as potentially valuable tools in\nhealthcare. Despite their promise, the development and implementation of these\nsystems typically encounter several barriers, hindering the potential for\nwidespread adoption. Here we present a case study of a recently developed\nAI-CDSS, Aifred Health, aimed at supporting the selection and management of\ntreatment in major depressive disorder. We consider both the principles\nespoused during development and testing of this AI-CDSS, as well as the\npractical solutions developed to facilitate implementation. We also propose\nrecommendations to consider throughout the building, validation, training, and\nimplementation process of an AI-CDSS. These recommendations include:\nidentifying the key problem, selecting the type of machine learning approach\nbased on this problem, determining the type of data required, determining the\nformat required for a CDSS to provide clinical utility, gathering physician and\npatient feedback, and validating the tool across multiple settings. Finally, we\nexplore the potential benefits of widespread adoption of these systems, while\nbalancing these against implementation challenges such as ensuring systems do\nnot disrupt the clinical workflow, and designing systems in a manner that\nengenders trust on the part of end users.\n","authors":["Grace Golden","Christina Popescu","Sonia Israel","Kelly Perlman","Caitrin Armstrong","Robert Fratila","Myriam Tanguay-Sela","David Benrimoh"],"pdf_url":"https://arxiv.org/pdf/2303.03511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14701v4","updated":"2023-03-06T21:39:58Z","published":"2022-11-27T01:56:58Z","title":"Spatio-Temporal Meta-Graph Learning for Traffic Forecasting","summary":"  Traffic forecasting as a canonical task of multivariate time series\nforecasting has been a significant research topic in AI community. To address\nthe spatio-temporal heterogeneity and non-stationarity implied in the traffic\nstream, in this study, we propose Spatio-Temporal Meta-Graph Learning as a\nnovel Graph Structure Learning mechanism on spatio-temporal data. Specifically,\nwe implement this idea into Meta-Graph Convolutional Recurrent Network\n(MegaCRN) by plugging the Meta-Graph Learner powered by a Meta-Node Bank into\nGCRN encoder-decoder. We conduct a comprehensive evaluation on two benchmark\ndatasets (i.e., METR-LA and PEMS-BAY) and a new large-scale traffic speed\ndataset called EXPY-TKY that covers 1843 expressway road links in Tokyo. Our\nmodel outperformed the state-of-the-arts on all three datasets. Besides,\nthrough a series of qualitative evaluations, we demonstrate that our model can\nexplicitly disentangle the road links and time slots with different patterns\nand be robustly adaptive to any anomalous traffic situations. Codes and\ndatasets are available at https://github.com/deepkashiwa20/MegaCRN.\n","authors":["Renhe Jiang","Zhaonan Wang","Jiawei Yong","Puneet Jeph","Quanjun Chen","Yasumasa Kobayashi","Xuan Song","Shintaro Fukushima","Toyotaro Suzumura"],"pdf_url":"https://arxiv.org/pdf/2211.14701v4.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.03508v1","updated":"2023-03-06T21:29:45Z","published":"2023-03-06T21:29:45Z","title":"Memory Maps for Video Object Detection and Tracking on UAVs","summary":"  This paper introduces a novel approach to video object detection detection\nand tracking on Unmanned Aerial Vehicles (UAVs). By incorporating metadata, the\nproposed approach creates a memory map of object locations in actual world\ncoordinates, providing a more robust and interpretable representation of object\nlocations in both, image space and the real world. We use this representation\nto boost confidences, resulting in improved performance for several temporal\ncomputer vision tasks, such as video object detection, short and long-term\nsingle and multi-object tracking, and video anomaly detection. These findings\nconfirm the benefits of metadata in enhancing the capabilities of UAVs in the\nfield of temporal computer vision and pave the way for further advancements in\nthis area.\n","authors":["Benjamin Kiefer","Yitong Quan","Andreas Zell"],"pdf_url":"https://arxiv.org/pdf/2303.03508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03573v2","updated":"2023-03-06T21:03:39Z","published":"2023-02-07T16:37:19Z","title":"Local Neural Descriptor Fields: Locally Conditioned Object\n  Representations for Manipulation","summary":"  A robot operating in a household environment will see a wide range of unique\nand unfamiliar objects. While a system could train on many of these, it is\ninfeasible to predict all the objects a robot will see. In this paper, we\npresent a method to generalize object manipulation skills acquired from a\nlimited number of demonstrations, to novel objects from unseen shape\ncategories. Our approach, Local Neural Descriptor Fields (L-NDF), utilizes\nneural descriptors defined on the local geometry of the object to effectively\ntransfer manipulation demonstrations to novel objects at test time. In doing\nso, we leverage the local geometry shared between objects to produce a more\ngeneral manipulation framework. We illustrate the efficacy of our approach in\nmanipulating novel objects in novel poses -- both in simulation and in the real\nworld.\n","authors":["Ethan Chun","Yilun Du","Anthony Simeonov","Tomas Lozano-Perez","Leslie Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2302.03573v2.pdf","comment":"ICRA 2023, Project Page: https://elchun.github.io/lndf/"},{"id":"http://arxiv.org/abs/2303.03488v1","updated":"2023-03-06T20:36:47Z","published":"2023-03-06T20:36:47Z","title":"A Comparison of Methods for Neural Network Aggregation","summary":"  Deep learning has been successful in the theoretical aspect. For deep\nlearning to succeed in industry, we need to have algorithms capable of handling\nmany inconsistencies appearing in real data. These inconsistencies can have\nlarge effects on the implementation of a deep learning algorithm. Artificial\nIntelligence is currently changing the medical industry. However, receiving\nauthorization to use medical data for training machine learning algorithms is a\nhuge hurdle. A possible solution is sharing the data without sharing the\npatient information. We propose a multi-party computation protocol for the deep\nlearning algorithm. The protocol enables to conserve both the privacy and the\nsecurity of the training data. Three approaches of neural networks assembly are\nanalyzed: transfer learning, average ensemble learning, and series network\nlearning. The results are compared to approaches based on data-sharing in\ndifferent experiments. We analyze the security issues of the proposed protocol.\nAlthough the analysis is based on medical data, the results of multi-party\ncomputation of machine learning training are theoretical and can be implemented\nin multiple research areas.\n","authors":["John Pomerat","Aviv Segev"],"pdf_url":"https://arxiv.org/pdf/2303.03488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.01821v3","updated":"2023-03-06T20:36:43Z","published":"2022-03-03T16:26:36Z","title":"Intention Aware Robot Crowd Navigation with Attention-Based Interaction\n  Graph","summary":"  We study the problem of safe and intention-aware robot navigation in dense\nand interactive crowds. Most previous reinforcement learning (RL) based methods\nfail to consider different types of interactions among all agents or ignore the\nintentions of people, which results in performance degradation. In this paper,\nwe propose a novel recurrent graph neural network with attention mechanisms to\ncapture heterogeneous interactions among agents through space and time. To\nencourage longsighted robot behaviors, we infer the intentions of dynamic\nagents by predicting their future trajectories for several timesteps. The\npredictions are incorporated into a model-free RL framework to prevent the\nrobot from intruding into the intended paths of other agents. We demonstrate\nthat our method enables the robot to achieve good navigation performance and\nnon-invasiveness in challenging crowd navigation scenarios. We successfully\ntransfer the policy learned in simulation to a real-world TurtleBot 2i. Our\ncode and videos are available at\nhttps://sites.google.com/view/intention-aware-crowdnav/home.\n","authors":["Shuijing Liu","Peixin Chang","Zhe Huang","Neeloy Chakraborty","Kaiwen Hong","Weihang Liang","D. Livingston McPherson","Junyi Geng","Katherine Driggs-Campbell"],"pdf_url":"https://arxiv.org/pdf/2203.01821v3.pdf","comment":"Published as a conference paper in IEEE International Conference on\n  Robotics and Automation (ICRA), 2023"},{"id":"http://arxiv.org/abs/2303.03487v1","updated":"2023-03-06T20:35:51Z","published":"2023-03-06T20:35:51Z","title":"Two-stage Pipeline for Multilingual Dialect Detection","summary":"  Dialect Identification is a crucial task for localizing various Large\nLanguage Models. This paper outlines our approach to the VarDial 2023 shared\ntask. Here we have to identify three or two dialects from three languages each\nwhich results in a 9-way classification for Track-1 and 6-way classification\nfor Track-2 respectively. Our proposed approach consists of a two-stage system\nand outperforms other participants' systems and previous works in this domain.\nWe achieve a score of 58.54% for Track-1 and 85.61% for Track-2. Our codebase\nis available publicly (https://github.com/ankit-vaidya19/EACL_VarDial2023).\n","authors":["Ankit Vaidya","Aditya Kane"],"pdf_url":"https://arxiv.org/pdf/2303.03487v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.02206v6","updated":"2023-03-06T20:32:23Z","published":"2021-04-06T00:53:01Z","title":"Tuned Compositional Feature Replays for Efficient Stream Learning","summary":"  Our brains extract durable, generalizable knowledge from transient\nexperiences of the world. Artificial neural networks come nowhere close: when\ntasked with learning to classify objects by training on non-repeating video\nframes in temporal order (online stream learning), models that learn well from\nshuffled datasets catastrophically forget old knowledge upon learning new\nstimuli. We propose a new continual learning algorithm, Compositional Replay\nUsing Memory Blocks (CRUMB), which mitigates forgetting by replaying feature\nmaps reconstructed by recombining generic parts. Just as crumbs together form a\nloaf of bread, we concatenate trainable and re-usable \"memory block\" vectors to\ncompositionally reconstruct feature map tensors in convolutional neural\nnetworks. CRUMB stores the indices of memory blocks used to reconstruct new\nstimuli, enabling replay of specific memories during later tasks. CRUMB's\nmemory blocks are tuned to enhance replay: a single feature map stored,\nreconstructed, and replayed by CRUMB mitigates forgetting during video stream\nlearning more effectively than an entire image, even though it occupies only\n3.6% as much memory. We stress-tested CRUMB alongside 13 competing methods on 5\nchallenging datasets. To address the limited number of existing online stream\nlearning datasets, we introduce 2 new benchmarks by adapting existing datasets\nfor stream learning. With about 4% of the memory and 20% of the runtime, CRUMB\nmitigates catastrophic forgetting more effectively than the prior\nstate-of-the-art. Our code is available at\nhttps://github.com/MorganBDT/crumb.git.\n","authors":["Morgan B. Talbot","Rushikesh Zawar","Rohil Badkundri","Mengmi Zhang","Gabriel Kreiman"],"pdf_url":"https://arxiv.org/pdf/2104.02206v6.pdf","comment":"Copyright 2023 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2302.09120v2","updated":"2023-03-06T20:19:43Z","published":"2023-02-17T20:08:59Z","title":"Robot path planning using deep reinforcement learning","summary":"  Autonomous navigation is challenging for mobile robots, especially in an\nunknown environment. Commonly, the robot requires multiple sensors to map the\nenvironment, locate itself, and make a plan to reach the target. However,\nreinforcement learning methods offer an alternative to map-free navigation\ntasks by learning the optimal actions to take. In this article, deep\nreinforcement learning agents are implemented using variants of the deep Q\nnetworks method, the D3QN and rainbow algorithms, for both the obstacle\navoidance and the goal-oriented navigation task. The agents are trained and\nevaluated in a simulated environment. Furthermore, an analysis of the changes\nin the behaviour and performance of the agents caused by modifications in the\nreward function is conducted.\n","authors":["Miguel Quinones-Ramirez","Jorge Rios-Martinez","Victor Uc-Cetina"],"pdf_url":"https://arxiv.org/pdf/2302.09120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03480v1","updated":"2023-03-06T20:19:19Z","published":"2023-03-06T20:19:19Z","title":"Can an Embodied Agent Find Your \"Cat-shaped Mug\"? LLM-Based Zero-Shot\n  Object Navigation","summary":"  We present LGX, a novel algorithm for Object Goal Navigation in a\n\"language-driven, zero-shot manner\", where an embodied agent navigates to an\narbitrarily described target object in a previously unexplored environment. Our\napproach leverages the capabilities of Large Language Models (LLMs) for making\nnavigational decisions by mapping the LLMs implicit knowledge about the\nsemantic context of the environment into sequential inputs for robot motion\nplanning. Simultaneously, we also conduct generalized target object detection\nusing a pre-trained Vision-Language grounding model. We achieve\nstate-of-the-art zero-shot object navigation results on RoboTHOR with a success\nrate (SR) improvement of over 27% over the current baseline of the OWL-ViT CLIP\non Wheels (OWL CoW). Furthermore, we study the usage of LLMs for robot\nnavigation and present an analysis of the various semantic factors affecting\nmodel output. Finally, we showcase the benefits of our approach via real-world\nexperiments that indicate the superior performance of LGX when navigating to\nand detecting visually unique objects.\n","authors":["Vishnu Sashank Dorbala","James F. Mullen Jr.","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2303.03480v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2303.03475v1","updated":"2023-03-06T20:07:05Z","published":"2023-03-06T20:07:05Z","title":"Rolling Horizon based Temporal Decomposition for the Offline Pickup and\n  Delivery Problem with Time Windows","summary":"  The offline pickup and delivery problem with time windows (PDPTW) is a\nclassical combinatorial optimization problem in the transportation community,\nwhich has proven to be very challenging computationally. Due to the complexity\nof the problem, practical problem instances can be solved only via heuristics,\nwhich trade-off solution quality for computational tractability. Among the\nvarious heuristics, a common strategy is problem decomposition, that is, the\nreduction of a large-scale problem into a collection of smaller sub-problems,\nwith spatial and temporal decompositions being two natural approaches. While\nspatial decomposition has been successful in certain settings, effective\ntemporal decomposition has been challenging due to the difficulty of stitching\ntogether the sub-problem solutions across the decomposition boundaries. In this\nwork, we introduce a novel temporal decomposition scheme for solving a class of\nPDPTWs that have narrow time windows, for which it is able to provide both fast\nand high-quality solutions. We utilize techniques that have been popularized\nrecently in the context of online dial-a-ride problems along with the general\nidea of rolling horizon optimization. To the best of our knowledge, this is the\nfirst attempt to solve offline PDPTWs using such an approach. To show the\nperformance and scalability of our framework, we use the optimization of\nparatransit services as a motivating example. We compare our results with an\noffline heuristic algorithm using Google OR-Tools. In smaller problem\ninstances, the baseline approach is as competitive as our framework. However,\nin larger problem instances, our framework is more scalable and can provide\ngood solutions to problem instances of varying degrees of difficulty, while the\nbaseline algorithm often fails to find a feasible solution within comparable\ncompute times.\n","authors":["Youngseo Kim","Danushka Edirimanna","Michael Wilbur","Philip Pugliese","Aron Laszka","Abhishek Dubey","Samitha Samaranayake"],"pdf_url":"https://arxiv.org/pdf/2303.03475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02753v2","updated":"2023-03-06T20:00:40Z","published":"2022-12-06T05:05:15Z","title":"Safe Inverse Reinforcement Learning via Control Barrier Function","summary":"  Learning from Demonstration (LfD) is a powerful method for enabling robots to\nperform novel tasks as it is often more tractable for a non-roboticist end-user\nto demonstrate the desired skill and for the robot to efficiently learn from\nthe associated data than for a human to engineer a reward function for the\nrobot to learn the skill via reinforcement learning (RL). Safety issues arise\nin modern LfD techniques, e.g., Inverse Reinforcement Learning (IRL), just as\nthey do for RL; yet, safe learning in LfD has received little attention. In the\ncontext of agile robots, safety is especially vital due to the possibility of\nrobot-environment collision, robot-human collision, and damage to the robot. In\nthis paper, we propose a safe IRL framework, CBFIRL, that leverages the Control\nBarrier Function (CBF) to enhance the safety of the IRL policy. The core idea\nof CBFIRL is to combine a loss function inspired by CBF requirements with the\nobjective in an IRL method, both of which are jointly optimized via gradient\ndescent. In the experiments, we show our framework performs safer compared to\nIRL methods without CBF, that is $\\sim15\\%$ and $\\sim20\\%$ improvement for two\nlevels of difficulty of a 2D racecar domain and $\\sim 50\\%$ improvement for a\n3D drone domain.\n","authors":["Yue Yang","Letian Chen","Matthew Gombolay"],"pdf_url":"https://arxiv.org/pdf/2212.02753v2.pdf","comment":"6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2207.00056v3","updated":"2023-03-06T19:39:18Z","published":"2022-06-30T18:42:06Z","title":"MultiViz: Towards Visualizing and Understanding Multimodal Models","summary":"  The promise of multimodal models for real-world applications has inspired\nresearch in visualizing and understanding their internal mechanics with the end\ngoal of empowering stakeholders to visualize model behavior, perform model\ndebugging, and promote trust in machine learning models. However, modern\nmultimodal models are typically black-box neural networks, which makes it\nchallenging to understand their internal mechanics. How can we visualize the\ninternal modeling of multimodal interactions in these models? Our paper aims to\nfill this gap by proposing MultiViz, a method for analyzing the behavior of\nmultimodal models by scaffolding the problem of interpretability into 4 stages:\n(1) unimodal importance: how each modality contributes towards downstream\nmodeling and prediction, (2) cross-modal interactions: how different modalities\nrelate with each other, (3) multimodal representations: how unimodal and\ncross-modal interactions are represented in decision-level features, and (4)\nmultimodal prediction: how decision-level features are composed to make a\nprediction. MultiViz is designed to operate on diverse modalities, models,\ntasks, and research areas. Through experiments on 8 trained models across 6\nreal-world tasks, we show that the complementary stages in MultiViz together\nenable users to (1) simulate model predictions, (2) assign interpretable\nconcepts to features, (3) perform error analysis on model misclassifications,\nand (4) use insights from error analysis to debug models. MultiViz is publicly\navailable, will be regularly updated with new interpretation tools and metrics,\nand welcomes inputs from the community.\n","authors":["Paul Pu Liang","Yiwei Lyu","Gunjan Chhablani","Nihal Jain","Zihao Deng","Xingbo Wang","Louis-Philippe Morency","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2207.00056v3.pdf","comment":"ICLR 2023. Code available at: https://github.com/pliang279/MultiViz"},{"id":"http://arxiv.org/abs/2303.03462v1","updated":"2023-03-06T19:37:01Z","published":"2023-03-06T19:37:01Z","title":"Towards Composable Distributions of Latent Space Augmentations","summary":"  We propose a composable framework for latent space image augmentation that\nallows for easy combination of multiple augmentations. Image augmentation has\nbeen shown to be an effective technique for improving the performance of a wide\nvariety of image classification and generation tasks. Our framework is based on\nthe Variational Autoencoder architecture and uses a novel approach for\naugmentation via linear transformation within the latent space itself. We\nexplore losses and augmentation latent geometry to enforce the transformations\nto be composable and involuntary, thus allowing the transformations to be\nreadily combined or inverted. Finally, we show these properties are better\nperforming with certain pairs of augmentations, but we can transfer the latent\nspace to other sets of augmentations to modify performance, effectively\nconstraining the VAE's bottleneck to preserve the variance of specific\naugmentations and features of the image which we care about. We demonstrate the\neffectiveness of our approach with initial results on the MNIST dataset against\nboth a standard VAE and a Conditional VAE. This latent augmentation method\nallows for much greater control and geometric interpretability of the latent\nspace, making it a valuable tool for researchers and practitioners in the\nfield.\n","authors":["Omead Pooladzandi","Jeffrey Jiang","Sunay Bhat","Gregory Pottie"],"pdf_url":"https://arxiv.org/pdf/2303.03462v1.pdf","comment":"Accepted at 2023 Information Theory and Applications Workshop (Feb,\n  San Diego)"},{"id":"http://arxiv.org/abs/2111.10832v2","updated":"2023-03-06T19:34:55Z","published":"2021-11-21T14:57:11Z","title":"Automated Controller Calibration by Kalman Filtering","summary":"  This paper proposes a method for calibrating control parameters. Examples of\nsuch control parameters are gains of PID controllers, weights of a cost\nfunction for optimal control, filter coefficients, the sliding surface of a\nsliding mode controller, or weights of a neural network. Hence, the proposed\nmethod can be applied to a wide range of controllers. The method uses a Kalman\nfilter that estimates control parameters, using data of closed-loop system\noperation. The control parameter calibration is driven by a training objective,\nwhich encompasses specifications on the performance of the dynamical system.\nThe performance-driven calibration method tunes the parameters online and\nrobustly, is computationally efficient, has low data storage requirements, and\nis easy to implement making it appealing for many real-time applications.\nSimulation results show that the method is able to learn control parameters\nquickly, is able to tune the parameters to compensate for disturbances, and is\nrobust to noise. A simulation study with the high-fidelity vehicle simulator\nCarSim shows that the method can calibrate controllers of a complex dynamical\nsystem online, which indicates its applicability to a real-world system. We\nalso verify the real-time feasibility on an embedded platform with\nautomotive-grade processors by implementing our method on a dSPACE\nMicroAutoBox-II rapid prototyping unit.\n","authors":["Marcel Menner","Karl Berntorp","Stefano Di Cairano"],"pdf_url":"https://arxiv.org/pdf/2111.10832v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00633v2","updated":"2023-03-06T19:25:48Z","published":"2023-03-01T16:36:25Z","title":"An Information-Theoretic Perspective on Variance-Invariance-Covariance\n  Regularization","summary":"  In this paper, we provide an information-theoretic perspective on\nVariance-Invariance-Covariance Regularization (VICReg) for self-supervised\nlearning. To do so, we first demonstrate how information-theoretic quantities\ncan be obtained for deterministic networks as an alternative to the commonly\nused unrealistic stochastic networks assumption. Next, we relate the VICReg\nobjective to mutual information maximization and use it to highlight the\nunderlying assumptions of the objective. Based on this relationship, we derive\na generalization bound for VICReg, providing generalization guarantees for\ndownstream supervised learning tasks and present new self-supervised learning\nmethods, derived from a mutual information maximization objective, that\noutperform existing methods in terms of performance. This work provides a new\ninformation-theoretic perspective on self-supervised learning and\nVariance-Invariance-Covariance Regularization in particular and guides the way\nfor improved transfer learning via information-theoretic self-supervised\nlearning objectives.\n","authors":["Ravid Shwartz-Ziv","Randall Balestriero","Kenji Kawaguchi","Tim G. J. Rudner","Yann LeCun"],"pdf_url":"https://arxiv.org/pdf/2303.00633v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03942v1","updated":"2023-03-06T18:55:00Z","published":"2023-03-06T18:55:00Z","title":"Learning Position From Vehicle Vibration Using an Inertial Measurement\n  Unit","summary":"  This paper presents a novel approach to vehicle positioning that operates\nwithout reliance on the global navigation satellite system (GNSS). Traditional\nGNSS approaches are vulnerable to interference in certain environments,\nrendering them unreliable in situations such as urban canyons, under flyovers,\nor in low reception areas. This study proposes a vehicle positioning method\nbased on learning the road signature from accelerometer and gyroscope\nmeasurements obtained by an inertial measurement unit (IMU) sensor. In our\napproach, the route is divided into segments, each with a distinct signature\nthat the IMU can detect through the vibrations of a vehicle in response to\nsubtle changes in the road surface. The study presents two different\ndata-driven methods for learning the road segment from IMU measurements. One\nmethod is based on convolutional neural networks and the other on ensemble\nrandom forest applied to handcrafted features. Additionally, the authors\npresent an algorithm to deduce the position of a vehicle in real-time using the\nlearned road segment. The approach was applied in two positioning tasks: (i) a\ncar along a 6[km] route in a dense urban area; (ii) an e-scooter on a 1[km]\nroute that combined road and pavement surfaces. The mean error between the\nproposed method's position and the ground truth was approximately 50[m] for the\ncar and 30[m] for the e-scooter. Compared to a solution based on time\nintegration of the IMU measurements, the proposed approach has a mean error of\nmore than 5 times better for e-scooters and 20 times better for cars.\n","authors":["Barak Or","Nimrod Segol","Areej Eweida","Maxim Freydin"],"pdf_url":"https://arxiv.org/pdf/2303.03942v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2303.03400v1","updated":"2023-03-06T09:58:39Z","published":"2023-03-06T09:58:39Z","title":"Testing the Channels of Convolutional Neural Networks","summary":"  Neural networks have complex structures, and thus it is hard to understand\ntheir inner workings and ensure correctness. To understand and debug\nconvolutional neural networks (CNNs) we propose techniques for testing the\nchannels of CNNs. We design FtGAN, an extension to GAN, that can generate test\ndata with varying the intensity (i.e., sum of the neurons) of a channel of a\ntarget CNN. We also proposed a channel selection algorithm to find\nrepresentative channels for testing. To efficiently inspect the target CNN's\ninference computations, we define unexpectedness score, which estimates how\nsimilar the inference computation of the test data is to that of the training\ndata. We evaluated FtGAN with five public datasets and showed that our\ntechniques successfully identify defective channels in five different CNN\nmodels.\n","authors":["Kang Choi","Donghyun Son","Younghoon Kim","Jiwon Seo"],"pdf_url":"https://arxiv.org/pdf/2303.03400v1.pdf","comment":"7pages, AAAI2023"},{"id":"http://arxiv.org/abs/2303.03933v1","updated":"2023-03-06T07:21:21Z","published":"2023-03-06T07:21:21Z","title":"DEDGAT: Dual Embedding of Directed Graph Attention Networks for\n  Detecting Financial Risk","summary":"  Graph representation plays an important role in the field of financial risk\ncontrol, where the relationship among users can be constructed in a graph\nmanner. In practical scenarios, the relationships between nodes in risk control\ntasks are bidirectional, e.g., merchants having both revenue and expense\nbehaviors. Graph neural networks designed for undirected graphs usually\naggregate discriminative node or edge representations with an attention\nstrategy, but cannot fully exploit the out-degree information when used for the\ntasks built on directed graph, which leads to the problem of a directional\nbias. To tackle this problem, we propose a Directed Graph ATtention network\ncalled DGAT, which explicitly takes out-degree into attention calculation. In\naddition to having directional requirements, the same node might have different\nrepresentations of its input and output, and thus we further propose a dual\nembedding of DGAT, referred to as DEDGAT. Specifically, DEDGAT assigns\nin-degree and out-degree representations to each node and uses these two\nembeddings to calculate the attention weights of in-degree and out-degree\nnodes, respectively. Experiments performed on the benchmark datasets show that\nDGAT and DEDGAT obtain better classification performance compared to undirected\nGAT. Also,the visualization results demonstrate that our methods can fully use\nboth in-degree and out-degree information.\n","authors":["Jiafu Wu","Mufeng Yao","Dong Wu","Mingmin Chi","Baokun Wang","Ruofan Wu","Xin Fu","Changhua Meng","Weiqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03933v1.pdf","comment":null}]},"2023-03-05T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.09908v2","updated":"2023-03-05T23:10:24Z","published":"2023-02-20T11:09:37Z","title":"A Sidecar Separator Can Convert a Single-Talker Speech Recognition\n  System to a Multi-Talker One","summary":"  Although automatic speech recognition (ASR) can perform well in common\nnon-overlapping environments, sustaining performance in multi-talker\noverlapping speech recognition remains challenging. Recent research revealed\nthat ASR model's encoder captures different levels of information with\ndifferent layers -- the lower layers tend to have more acoustic information,\nand the upper layers more linguistic. This inspires us to develop a Sidecar\nseparator to empower a well-trained ASR model for multi-talker scenarios by\nseparating the mixed speech embedding between two suitable layers. We\nexperimented with a wav2vec 2.0-based ASR model with a Sidecar mounted. By\nfreezing the parameters of the original model and training only the Sidecar\n(8.7 M, 8.4% of all parameters), the proposed approach outperforms the previous\nstate-of-the-art by a large margin for the 2-speaker mixed LibriMix dataset,\nreaching a word error rate (WER) of 10.36%; and obtains comparable results\n(7.56%) for LibriSpeechMix dataset when limited training.\n","authors":["Lingwei Meng","Jiawen Kang","Mingyu Cui","Yuejiao Wang","Xixin Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2302.09908v2.pdf","comment":"Accepted by IEEE International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), 2023"},{"id":"http://arxiv.org/abs/2303.02758v1","updated":"2023-03-05T19:45:42Z","published":"2023-03-05T19:45:42Z","title":"WADER at SemEval-2023 Task 9: A Weak-labelling framework for Data\n  augmentation in tExt Regression Tasks","summary":"  Intimacy is an essential element of human relationships and language is a\ncrucial means of conveying it. Textual intimacy analysis can reveal social\nnorms in different contexts and serve as a benchmark for testing computational\nmodels' ability to understand social information. In this paper, we propose a\nnovel weak-labeling strategy for data augmentation in text regression tasks\ncalled WADER. WADER uses data augmentation to address the problems of data\nimbalance and data scarcity and provides a method for data augmentation in\ncross-lingual, zero-shot tasks. We benchmark the performance of\nState-of-the-Art pre-trained multilingual language models using WADER and\nanalyze the use of sampling techniques to mitigate bias in data and optimally\nselect augmentation candidates. Our results show that WADER outperforms the\nbaseline model and provides a direction for mitigating data imbalance and\nscarcity in text regression tasks.\n","authors":["Manan Suri","Aaryak Garg","Divya Chaudhary","Ian Gorton","Bijendra Kumar"],"pdf_url":"https://arxiv.org/pdf/2303.02758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15432v2","updated":"2023-03-05T19:21:25Z","published":"2022-11-28T15:18:07Z","title":"E2E Segmentation in a Two-Pass Cascaded Encoder ASR Model","summary":"  We explore unifying a neural segmenter with two-pass cascaded encoder ASR\ninto a single model. A key challenge is allowing the segmenter (which runs in\nreal-time, synchronously with the decoder) to finalize the 2nd pass (which runs\n900 ms behind real-time) without introducing user-perceived latency or deletion\nerrors during inference. We propose a design where the neural segmenter is\nintegrated with the causal 1st pass decoder to emit a end-of-segment (EOS)\nsignal in real-time. The EOS signal is then used to finalize the non-causal 2nd\npass. We experiment with different ways to finalize the 2nd pass, and find that\na novel dummy frame injection strategy allows for simultaneous high quality 2nd\npass results and low finalization latency. On a real-world long-form captioning\ntask (YouTube), we achieve 2.4% relative WER and 140 ms EOS latency gains over\na baseline VAD-based segmenter with the same cascaded encoder.\n","authors":["W. Ronny Huang","Shuo-Yiin Chang","Tara N. Sainath","Yanzhang He","David Rybach","Robert David","Rohit Prabhavalkar","Cyril Allauzen","Cal Peyser","Trevor D. Strohman"],"pdf_url":"https://arxiv.org/pdf/2211.15432v2.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.02707v1","updated":"2023-03-05T16:17:56Z","published":"2023-03-05T16:17:56Z","title":"FQP 2.0: Industry Trend Analysis via Hierarchical Financial Data","summary":"  Analyzing trends across industries is critical to maintaining a healthy and\nstable economy. Previous research has mainly analyzed official statistics,\nwhich are more accurate but not necessarily real-time. In this paper, we\npropose a method for analyzing industry trends using stock market data. The\ndifficulty of this task is that the raw data is relatively noisy, which affects\nthe accuracy of statistical analysis. In addition, textual data for industry\nanalysis needs to be better understood through language models. For this\nreason, we introduce the method of industry trend analysis from two\nperspectives of explicit analysis and implicit analysis. For the explicit\nanalysis, we introduce a hierarchical data (industry and listed company)\nanalysis method to reduce the impact of noise. For implicit analysis, we\nfurther pre-train GPT-2 to analyze industry trends with current affairs\nbackground as input, making full use of the knowledge learned in the\npre-training corpus. We conduct experiments based on the proposed method and\nachieve good industry trend analysis results.\n","authors":["Hongyin Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.02707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02677v1","updated":"2023-03-05T14:25:05Z","published":"2023-03-05T14:25:05Z","title":"Mining both Commonality and Specificity from Multiple Documents for\n  Multi-Document Summarization","summary":"  The multi-document summarization task requires the designed summarizer to\ngenerate a short text that covers the important information of original\ndocuments and satisfies content diversity. This paper proposes a multi-document\nsummarization approach based on hierarchical clustering of documents. It\nutilizes the constructed class tree of documents to extract both the sentences\nreflecting the commonality of all documents and the sentences reflecting the\nspecificity of some subclasses of these documents for generating a summary, so\nas to satisfy the coverage and diversity requirements of multi-document\nsummarization. Comparative experiments with different variant approaches on\nDUC'2002-2004 datasets prove the effectiveness of mining both the commonality\nand specificity of documents for multi-document summarization. Experiments on\nDUC'2004 and Multi-News datasets show that our approach achieves competitive\nperformance compared to the state-of-the-art unsupervised and supervised\napproaches.\n","authors":["Bing Ma"],"pdf_url":"https://arxiv.org/pdf/2303.02677v1.pdf","comment":"10 pages, 1 figure"},{"id":"http://arxiv.org/abs/2302.11466v2","updated":"2023-03-05T11:29:10Z","published":"2023-02-22T16:00:27Z","title":"Advancements in Federated Learning: Models, Methods, and Privacy","summary":"  Federated learning (FL) is a promising technique for addressing the rising\nprivacy and security issues. Its main ingredient is to cooperatively learn the\nmodel among the distributed clients without uploading any sensitive data. In\nthis paper, we conducted a thorough review of the related works, following the\ndevelopment context and deeply mining the key technologies behind FL from both\ntheoretical and practical perspectives. Specifically, we first classify the\nexisting works in FL architecture based on the network topology of FL systems\nwith detailed analysis and summarization. Next, we abstract the current\napplication problems, summarize the general techniques and frame the\napplication problems into the general paradigm of FL base models. Moreover, we\nprovide our proposed solutions for model training via FL. We have summarized\nand analyzed the existing FedOpt algorithms, and deeply revealed the\nalgorithmic development principles of many first-order algorithms in depth,\nproposing a more generalized algorithm design framework. Based on these\nframeworks, we have instantiated FedOpt algorithms. As privacy and security is\nthe fundamental requirement in FL, we provide the existing attack scenarios and\nthe defense methods. To the best of our knowledge, we are among the first tier\nto review the theoretical methodology and propose our strategies since there\nare very few works surveying the theoretical approaches. Our survey targets\nmotivating the development of high-performance, privacy-preserving, and secure\nmethods to integrate FL into real-world applications.\n","authors":["Huiming Chen","Huandong Wang","Qingyue Long","Depeng Jin","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2302.11466v2.pdf","comment":"35 pages, submitted to ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2208.05309v2","updated":"2023-03-05T09:28:23Z","published":"2022-08-10T12:44:13Z","title":"Looking for a Needle in a Haystack: A Comprehensive Study of\n  Hallucinations in Neural Machine Translation","summary":"  Although the problem of hallucinations in neural machine translation (NMT)\nhas received some attention, research on this highly pathological phenomenon\nlacks solid ground. Previous work has been limited in several ways: it often\nresorts to artificial settings where the problem is amplified, it disregards\nsome (common) types of hallucinations, and it does not validate adequacy of\ndetection heuristics. In this paper, we set foundations for the study of NMT\nhallucinations. First, we work in a natural setting, i.e., in-domain data\nwithout artificial noise neither in training nor in inference. Next, we\nannotate a dataset of over 3.4k sentences indicating different kinds of\ncritical errors and hallucinations. Then, we turn to detection methods and both\nrevisit methods used previously and propose using glass-box uncertainty-based\ndetectors. Overall, we show that for preventive settings, (i) previously used\nmethods are largely inadequate, (ii) sequence log-probability works best and\nperforms on par with reference-based methods. Finally, we propose\nDeHallucinator, a simple method for alleviating hallucinations at test time\nthat significantly reduces the hallucinatory rate. To ease future research, we\nrelease our annotated dataset for WMT18 German-English data, along with the\nmodel, training data, and code.\n","authors":["Nuno M. Guerreiro","Elena Voita","André F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2208.05309v2.pdf","comment":"Accepted at EACL23 (main)"},{"id":"http://arxiv.org/abs/2209.15352v2","updated":"2023-03-05T09:14:16Z","published":"2022-09-30T10:17:05Z","title":"AudioGen: Textually Guided Audio Generation","summary":"  We tackle the problem of generating audio samples conditioned on descriptive\ntext captions. In this work, we propose AaudioGen, an auto-regressive\ngenerative model that generates audio samples conditioned on text inputs.\nAudioGen operates on a learnt discrete audio representation. The task of\ntext-to-audio generation poses multiple challenges. Due to the way audio\ntravels through a medium, differentiating ``objects'' can be a difficult task\n(e.g., separating multiple people simultaneously speaking). This is further\ncomplicated by real-world recording conditions (e.g., background noise,\nreverberation, etc.). Scarce text annotations impose another constraint,\nlimiting the ability to scale models. Finally, modeling high-fidelity audio\nrequires encoding audio at high sampling rate, leading to extremely long\nsequences. To alleviate the aforementioned challenges we propose an\naugmentation technique that mixes different audio samples, driving the model to\ninternally learn to separate multiple sources. We curated 10 datasets\ncontaining different types of audio and text annotations to handle the scarcity\nof text-audio data points. For faster inference, we explore the use of\nmulti-stream modeling, allowing the use of shorter sequences while maintaining\na similar bitrate and perceptual quality. We apply classifier-free guidance to\nimprove adherence to text. Comparing to the evaluated baselines, AudioGen\noutperforms over both objective and subjective metrics. Finally, we explore the\nability of the proposed method to generate audio continuation conditionally and\nunconditionally. Samples: https://felixkreuk.github.io/audiogen\n","authors":["Felix Kreuk","Gabriel Synnaeve","Adam Polyak","Uriel Singer","Alexandre Défossez","Jade Copet","Devi Parikh","Yaniv Taigman","Yossi Adi"],"pdf_url":"https://arxiv.org/pdf/2209.15352v2.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2302.02676v5","updated":"2023-03-05T08:31:34Z","published":"2023-02-06T10:28:16Z","title":"Chain of Hindsight Aligns Language Models with Feedback","summary":"  Learning from human preferences is important for language models to be\nhelpful and useful for humans, and to align with human and social values. Prior\nwork have achieved remarkable successes by learning from human feedback to\nunderstand and follow instructions. Nonetheless, these methods are either\nfounded on hand-picked model generations that are favored by human annotators,\nrendering them ineffective in terms of data utilization and challenging to\napply in general, or they depend on reward functions and reinforcement\nlearning, which are prone to imperfect reward function and extremely\nchallenging to optimize. In this work, we propose a novel technique, Chain of\nHindsight, that is easy to optimize and can learn from any form of feedback,\nregardless of its polarity. Our idea is inspired by how humans learn from\nextensive feedback presented in the form of languages. We convert all types of\nfeedback into sentences, which are then used to fine-tune the model, allowing\nus to take advantage of the language comprehension capabilities of language\nmodels. We condition the model on a sequence of model generations paired with\nfeedback. By doing so, models are trained to generate outputs based on\nfeedback, and models can learn to identify and correct negative attributes or\nerrors. Applying our method to large language models, we observed that Chain of\nHindsight significantly surpasses previous methods in aligning language models\nwith human preferences. We observed significant improvements on summarization\nand dialogue tasks and our approach is markedly preferred in human evaluations.\n","authors":["Hao Liu","Carmelo Sferrazza","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.02676v5.pdf","comment":"Included a comprehensive list of templates"},{"id":"http://arxiv.org/abs/2303.02601v1","updated":"2023-03-05T08:00:30Z","published":"2023-03-05T08:00:30Z","title":"Knowledge-Based Counterfactual Queries for Visual Question Answering","summary":"  Visual Question Answering (VQA) has been a popular task that combines vision\nand language, with numerous relevant implementations in literature. Even though\nthere are some attempts that approach explainability and robustness issues in\nVQA models, very few of them employ counterfactuals as a means of probing such\nchallenges in a model-agnostic way. In this work, we propose a systematic\nmethod for explaining the behavior and investigating the robustness of VQA\nmodels through counterfactual perturbations. For this reason, we exploit\nstructured knowledge bases to perform deterministic, optimal and controllable\nword-level replacements targeting the linguistic modality, and we then evaluate\nthe model's response against such counterfactual inputs. Finally, we\nqualitatively extract local and global explanations based on counterfactual\nresponses, which are ultimately proven insightful towards interpreting VQA\nmodel behaviors. By performing a variety of perturbation types, targeting\ndifferent parts of speech of the input question, we gain insights to the\nreasoning of the model, through the comparison of its responses in different\nadversarial circumstances. Overall, we reveal possible biases in the\ndecision-making process of the model, as well as expected and unexpected\npatterns, which impact its performance quantitatively and qualitatively, as\nindicated by our analysis.\n","authors":["Theodoti Stoikou","Maria Lymperaiou","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2303.02601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02577v1","updated":"2023-03-05T04:12:17Z","published":"2023-03-05T04:12:17Z","title":"Effectiveness of Data Augmentation for Prefix Tuning with Limited Data","summary":"  Recent work has demonstrated that tuning continuous prompts on large, frozen\npretrained language models (i.e., prefix tuning or P-tuning) can yield\nperformance that is comparable or superior to fine-tuning. Nevertheless, the\neffectiveness of such methods under the context of data augmentation, which has\nbeen considered a common strategy to improve learning under low data regimes,\nhas not be studied. In this paper, we examine several popular task-agnostic\ndata augmentation techniques, i.e., EDA, Back Translation, and Mixup, when\nusing prefix tuning under data scarcity. We show that data augmentation can be\nused to boost the performance of prefix tuning models, but the effectiveness of\neach technique varies and certain methods can lead to a notable degradation in\nperformance, particularly when using larger models and on harder tasks. To help\nunderstand the above behaviour, we run experiments which reveal how prefix\ntuning generally presents a limited ability to separate the sentence embeddings\nfrom different classes of augmented data, and displays poorer performance on\nheavily altered data in particular. We also demonstrate that by adding a simple\ncontrastive loss we can help mitigate such issues for prefix tuning, resulting\nin an improvement to augmented data performance.\n","authors":["Stephen Obadinma","Hongyu Guo","Xiaodan Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.02577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02563v1","updated":"2023-03-05T03:18:56Z","published":"2023-03-05T03:18:56Z","title":"FinXABSA:Explainable Finance through Aspect-Based Sentiment Analysis","summary":"  This paper presents a novel approach for explainability in financial analysis\nby utilizing the Pearson correlation coefficient to establish a relationship\nbetween aspect-based sentiment analysis and stock prices. The proposed\nmethodology involves constructing an aspect list from financial news articles\nand analyzing sentiment intensity scores for each aspect. These scores are then\ncompared to the stock prices for the relevant companies using the Pearson\ncoefficient to determine any significant correlations. The results indicate\nthat the proposed approach provides a more detailed and accurate understanding\nof the relationship between sentiment analysis and stock prices, which can be\nuseful for investors and financial analysts in making informed decisions.\nAdditionally, this methodology offers a transparent and interpretable way to\nexplain the sentiment analysis results and their impact on stock prices.\nOverall, the findings of this paper demonstrate the importance of\nexplainability in financial analysis and highlight the potential benefits of\nutilizing the Pearson coefficient for analyzing aspect-based sentiment analysis\nand stock prices. The proposed approach offers a valuable tool for\nunderstanding the complex relationships between financial news sentiment and\nstock prices, providing a new perspective on the financial market and aiding in\nmaking informed investment decisions.\n","authors":["Keane Ong","Wihan van der Heever","Ranjan Satapathy","Gianmarco Mengaldo","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2303.02563v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2205.15361v2","updated":"2023-03-05T23:42:50Z","published":"2022-05-30T18:10:33Z","title":"TubeFormer-DeepLab: Video Mask Transformer","summary":"  We present TubeFormer-DeepLab, the first attempt to tackle multiple core\nvideo segmentation tasks in a unified manner. Different video segmentation\ntasks (e.g., video semantic/instance/panoptic segmentation) are usually\nconsidered as distinct problems. State-of-the-art models adopted in the\nseparate communities have diverged, and radically different approaches dominate\nin each task. By contrast, we make a crucial observation that video\nsegmentation tasks could be generally formulated as the problem of assigning\ndifferent predicted labels to video tubes (where a tube is obtained by linking\nsegmentation masks along the time axis) and the labels may encode different\nvalues depending on the target task. The observation motivates us to develop\nTubeFormer-DeepLab, a simple and effective video mask transformer model that is\nwidely applicable to multiple video segmentation tasks. TubeFormer-DeepLab\ndirectly predicts video tubes with task-specific labels (either pure semantic\ncategories, or both semantic categories and instance identities), which not\nonly significantly simplifies video segmentation models, but also advances\nstate-of-the-art results on multiple video segmentation benchmarks\n","authors":["Dahun Kim","Jun Xie","Huiyu Wang","Siyuan Qiao","Qihang Yu","Hong-Seok Kim","Hartwig Adam","In So Kweon","Liang-Chieh Chen"],"pdf_url":"https://arxiv.org/pdf/2205.15361v2.pdf","comment":"CVPR 2022; arXiv v2: add results on VIPSeg val/test sets and VSPW new\n  test set"},{"id":"http://arxiv.org/abs/2209.07590v2","updated":"2023-03-05T23:30:15Z","published":"2022-09-15T19:57:16Z","title":"Prediction of Gender from Longitudinal MRI data via Deep Learning on\n  Adolescent Data Reveals Unique Patterns Associated with Brain Structure and\n  Change over a Two-year Period","summary":"  Deep learning algorithms for predicting neuroimaging data have shown\nconsiderable promise in various applications. Prior work has demonstrated that\ndeep learning models that take advantage of the data's 3D structure can\noutperform standard machine learning on several learning tasks. However, most\nprior research in this area has focused on neuroimaging data from adults.\nWithin the Adolescent Brain and Cognitive Development (ABCD) dataset, a large\nlongitudinal development study, we examine structural MRI data to predict\ngender and identify gender-related changes in brain structure. Results\ndemonstrate that gender prediction accuracy is exceptionally high (>97%) with\ntraining epochs >200 and that this accuracy increases with age. Brain regions\nidentified as the most discriminative in the task under study include\npredominantly frontal areas and the temporal lobe. When evaluating gender\npredictive changes specific to a two-year increase in age, a broader set of\nvisual, cingulate, and insular regions are revealed. Our findings show a robust\ngender-related structural brain change pattern, even over a small age range.\nThis suggests that it might be possible to study how the brain changes during\nadolescence by looking at how these changes are related to different behavioral\nand environmental factors.\n","authors":["Yuda Bi","Anees Abrol","Zening Fu","Jiayu Chen","Jingyu Liu","Vince Calhoun"],"pdf_url":"https://arxiv.org/pdf/2209.07590v2.pdf","comment":"I submitted the wrong paper"},{"id":"http://arxiv.org/abs/2211.06726v2","updated":"2023-03-05T23:21:41Z","published":"2022-11-12T19:07:25Z","title":"MultiCrossViT: Multimodal Vision Transformer for Schizophrenia\n  Prediction using Structural MRI and Functional Network Connectivity Data","summary":"  Vision Transformer (ViT) is a pioneering deep learning framework that can\naddress real-world computer vision issues, such as image classification and\nobject recognition. Importantly, ViTs are proven to outperform traditional deep\nlearning models, such as convolutional neural networks (CNNs). Relatively\nrecently, a number of ViT mutations have been transplanted into the field of\nmedical imaging, thereby resolving a variety of critical classification and\nsegmentation challenges, especially in terms of brain imaging data. In this\nwork, we provide a novel multimodal deep learning pipeline, MultiCrossViT,\nwhich is capable of analyzing both structural MRI (sMRI) and static functional\nnetwork connectivity (sFNC) data for the prediction of schizophrenia disease.\nOn a dataset with minimal training subjects, our novel model can achieve an AUC\nof 0.832. Finally, we visualize multiple brain regions and covariance patterns\nmost relevant to schizophrenia based on the resulting ViT attention maps by\nextracting features from transformer encoders.\n","authors":["Yuda Bi","Anees Abrol","Zening Fu","Vince Calhoun"],"pdf_url":"https://arxiv.org/pdf/2211.06726v2.pdf","comment":"I submitted the wrong paper"},{"id":"http://arxiv.org/abs/2303.02165v1","updated":"2023-03-05T21:31:49Z","published":"2023-03-05T21:31:49Z","title":"DeepMAD: Mathematical Architecture Design for Deep Convolutional Neural\n  Network","summary":"  The rapid advances in Vision Transformer (ViT) refresh the state-of-the-art\nperformances in various vision tasks, overshadowing the conventional CNN-based\nmodels. This ignites a few recent striking-back research in the CNN world\nshowing that pure CNN models can achieve as good performance as ViT models when\ncarefully tuned. While encouraging, designing such high-performance CNN models\nis challenging, requiring non-trivial prior knowledge of network design. To\nthis end, a novel framework termed Mathematical Architecture Design for Deep\nCNN (DeepMAD) is proposed to design high-performance CNN models in a principled\nway. In DeepMAD, a CNN network is modeled as an information processing system\nwhose expressiveness and effectiveness can be analytically formulated by their\nstructural parameters. Then a constrained mathematical programming (MP) problem\nis proposed to optimize these structural parameters. The MP problem can be\neasily solved by off-the-shelf MP solvers on CPUs with a small memory\nfootprint. In addition, DeepMAD is a pure mathematical framework: no GPU or\ntraining data is required during network design. The superiority of DeepMAD is\nvalidated on multiple large-scale computer vision benchmark datasets. Notably\non ImageNet-1k, only using conventional convolutional layers, DeepMAD achieves\n0.7% and 1.5% higher top-1 accuracy than ConvNeXt and Swin on Tiny level, and\n0.8% and 0.9% higher on Small level.\n","authors":["Xuan Shen","Yaohua Wang","Ming Lin","Yilun Huang","Hao Tang","Xiuyu Sun","Yanzhi Wang"],"pdf_url":"https://arxiv.org/pdf/2303.02165v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.02776v1","updated":"2023-03-05T21:30:49Z","published":"2023-03-05T21:30:49Z","title":"A Low-Cost Portable Apparatus to Analyze Oral Fluid Droplets and\n  Quantify the Efficacy of Masks","summary":"  Every year, about 4 million people die from upper respiratory infections.\nMask-wearing is crucial in preventing the spread of pathogen-containing\ndroplets, which is the primary cause of these illnesses. However, most\ntechniques for mask efficacy evaluation are expensive to set up and complex to\noperate. In this work, a novel, low-cost, and quantitative metrology to\nvisualize, track, and analyze orally-generated fluid droplets is developed. The\nproject has four stages: setup optimization, data collection, data analysis,\nand application development. The metrology was initially developed in a dark\ncloset as a proof of concept using common household materials and was\nsubsequently implemented into a portable apparatus. Tonic water and UV\ndarklight tube lights are selected to visualize fluorescent droplet and aerosol\npropagation with automated analysis developed using open-source software. The\ndependencies of oral fluid droplet generation and propagation on various\nfactors are studied in detail and established using this metrology.\nAdditionally, the smallest detectable droplet size was mathematically\ncorrelated to height and airborne time. The efficacy of different types of\nmasks is evaluated and associated with fabric microstructures. It is found that\nmasks with smaller-sized pores and thicker material are more effective. This\ntechnique can easily be constructed at home using materials that total to a\ncost of below \\$60, thereby enabling a low-cost and accurate metrology.\n","authors":["Ava Tan Bhowmik"],"pdf_url":"https://arxiv.org/pdf/2303.02776v1.pdf","comment":"13 pages, 15 figures. arXiv admin note: substantial text overlap with\n  arXiv:2201.03993"},{"id":"http://arxiv.org/abs/2101.02530v2","updated":"2023-03-05T21:16:18Z","published":"2021-01-07T13:08:44Z","title":"MSED: a multi-modal sleep event detection model for clinical sleep\n  analysis","summary":"  Clinical sleep analysis require manual analysis of sleep patterns for correct\ndiagnosis of sleep disorders. However, several studies have shown significant\nvariability in manual scoring of clinically relevant discrete sleep events,\nsuch as arousals, leg movements, and sleep disordered breathing (apneas and\nhypopneas). We investigated whether an automatic method could be used for event\ndetection and if a model trained on all events (joint model) performed better\nthan corresponding event-specific models (single-event models). We trained a\ndeep neural network event detection model on 1653 individual recordings and\ntested the optimized model on 1000 separate hold-out recordings. F1 scores for\nthe optimized joint detection model were 0.70, 0.63, and 0.62 for arousals, leg\nmovements, and sleep disordered breathing, respectively, compared to 0.65,\n0.61, and 0.60 for the optimized single-event models. Index values computed\nfrom detected events correlated positively with manual annotations ($r^2$ =\n0.73, $r^2$ = 0.77, $r^2$ = 0.78, respectively). We furthermore quantified\nmodel accuracy based on temporal difference metrics, which improved overall by\nusing the joint model compared to single-event models. Our automatic model\njointly detects arousals, leg movements and sleep disordered breathing events\nwith high correlation with human annotations. Finally, we benchmark against\nprevious state-of-the-art multi-event detection models and found an overall\nincrease in F1 score with our proposed model despite a 97.5% reduction in model\nsize. Source code for training and inference is available at\nhttps://github.com/neergaard/msed.git.\n","authors":["Alexander Neergaard Olesen","Poul Jennum","Emmanuel Mignot","Helge B. D. Sorensen"],"pdf_url":"https://arxiv.org/pdf/2101.02530v2.pdf","comment":"10 pages, 4 figures. Accepted for publication in IEEE Transactions on\n  Biomedical Engineering"},{"id":"http://arxiv.org/abs/2303.02761v1","updated":"2023-03-05T20:06:19Z","published":"2023-03-05T20:06:19Z","title":"A Study of Augmentation Methods for Handwritten Stenography Recognition","summary":"  One of the factors limiting the performance of handwritten text recognition\n(HTR) for stenography is the small amount of annotated training data. To\nalleviate the problem of data scarcity, modern HTR methods often employ data\naugmentation. However, due to specifics of the stenographic script, such\nsettings may not be directly applicable for stenography recognition. In this\nwork, we study 22 classical augmentation techniques, most of which are commonly\nused for HTR of other scripts, such as Latin handwriting. Through extensive\nexperiments, we identify a group of augmentations, including for example\ncontained ranges of random rotation, shifts and scaling, that are beneficial to\nthe use case of stenography recognition. Furthermore, a number of augmentation\napproaches, leading to a decrease in recognition performance, are identified.\nOur results are supported by statistical hypothesis testing. Links to the\npublicly available dataset and codebase are provided.\n","authors":["Raphaela Heil","Eva Breznik"],"pdf_url":"https://arxiv.org/pdf/2303.02761v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02760v1","updated":"2023-03-05T20:05:21Z","published":"2023-03-05T20:05:21Z","title":"Human-Art: A Versatile Human-Centric Dataset Bridging Natural and\n  Artificial Scenes","summary":"  Humans have long been recorded in a variety of forms since antiquity. For\nexample, sculptures and paintings were the primary media for depicting human\nbeings before the invention of cameras. However, most current human-centric\ncomputer vision tasks like human pose estimation and human image generation\nfocus exclusively on natural images in the real world. Artificial humans, such\nas those in sculptures, paintings, and cartoons, are commonly neglected, making\nexisting models fail in these scenarios. As an abstraction of life, art\nincorporates humans in both natural and artificial scenes. We take advantage of\nit and introduce the Human-Art dataset to bridge related tasks in natural and\nartificial scenarios. Specifically, Human-Art contains 50k high-quality images\nwith over 123k person instances from 5 natural and 15 artificial scenarios,\nwhich are annotated with bounding boxes, keypoints, self-contact points, and\ntext information for humans represented in both 2D and 3D. It is, therefore,\ncomprehensive and versatile for various downstream tasks. We also provide a\nrich set of baseline results and detailed analyses for related tasks, including\nhuman detection, 2D and 3D human pose estimation, image generation, and motion\ntransfer. As a challenging dataset, we hope Human-Art can provide insights for\nrelevant research and open up new research questions.\n","authors":["Xuan Ju","Ailing Zeng","Jianan Wang","Qiang Xu","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02760v1.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2207.03333v3","updated":"2023-03-05T19:44:47Z","published":"2022-07-06T05:57:24Z","title":"FewSOL: A Dataset for Few-Shot Object Learning in Robotic Environments","summary":"  We introduce the Few-Shot Object Learning (FewSOL) dataset for object\nrecognition with a few images per object. We captured 336 real-world objects\nwith 9 RGB-D images per object from different views. Object segmentation masks,\nobject poses and object attributes are provided. In addition, synthetic images\ngenerated using 330 3D object models are used to augment the dataset. We\ninvestigated (i) few-shot object classification and (ii) joint object\nsegmentation and few-shot classification with the state-of-the-art methods for\nfew-shot learning and meta-learning using our dataset. The evaluation results\nshow that there is still a large margin to be improved for few-shot object\nclassification in robotic environments. Our dataset can be used to study a set\nof few-shot object recognition problems such as classification, detection and\nsegmentation, shape reconstruction, pose estimation, keypoint correspondences\nand attribute recognition. The dataset and code are available at\nhttps://irvlutd.github.io/FewSOL.\n","authors":["Jishnu Jaykumar P","Yu-Wei Chao","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2207.03333v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02753v1","updated":"2023-03-05T19:20:55Z","published":"2023-03-05T19:20:55Z","title":"Frequency-domain Blind Quality Assessment of Blurred and\n  Blocking-artefact Images using Gaussian Process Regression model","summary":"  Most of the standard image and video codecs are block-based and depending\nupon the compression ratio the compressed images/videos suffer from different\ndistortions. At low ratios, blurriness is observed and as compression increases\nblocking artifacts occur. Generally, in order to reduce blockiness, images are\nlow-pass filtered which leads to more blurriness. Also, in bokeh mode images\nthey are commonly seen: blurriness as a result of intentional blurred\nbackground while blocking artifact and global blurriness arising due to\ncompression. Therefore, such visual media suffer from both blockiness and\nblurriness distortions. Along with this, noise is also commonly encountered\ndistortion. Most of the existing works on quality assessment quantify these\ndistortions individually. This paper proposes a methodology to blindly measure\noverall quality of an image suffering from these distortions, individually as\nwell as jointly. This is achieved by considering the sum of absolute values of\nlow and high-frequency Discrete Frequency Transform (DFT) coefficients defined\nas sum magnitudes. The number of blocks lying in specific ranges of sum\nmagnitudes including zero-valued AC coefficients and mean of 100 maximum and\n100 minimum values of these sum magnitudes are used as feature vectors. These\nfeatures are then fed to the Machine Learning (ML) based Gaussian Process\nRegression (GPR) model, which quantifies the image quality. The simulation\nresults show that the proposed method can estimate the quality of images\ndistorted with the blockiness, blurriness, noise and their combinations. It is\nrelatively fast compared to many state-of-art methods, and therefore is\nsuitable for real-time quality monitoring applications.\n","authors":["Maryam Viqar","Athar A. Moinuddin","Ekram Khan","M. Ghanbari"],"pdf_url":"https://arxiv.org/pdf/2303.02753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02741v1","updated":"2023-03-05T18:16:34Z","published":"2023-03-05T18:16:34Z","title":"IDA: Informed Domain Adaptive Semantic Segmentation","summary":"  Mixup-based data augmentation has been validated to be a critical stage in\nthe self-training framework for unsupervised domain adaptive semantic\nsegmentation (UDA-SS), which aims to transfer knowledge from a well-annotated\n(source) domain to an unlabeled (target) domain. Existing self-training methods\nusually adopt the popular region-based mixup techniques with a random sampling\nstrategy, which unfortunately ignores the dynamic evolution of different\nsemantics across various domains as training proceeds. To improve the UDA-SS\nperformance, we propose an Informed Domain Adaptation (IDA) model, a\nself-training framework that mixes the data based on class-level segmentation\nperformance, which aims to emphasize small-region semantics during mixup. In\nour IDA model, the class-level performance is tracked by an expected confidence\nscore (ECS). We then use a dynamic schedule to determine the mixing ratio for\ndata in different domains. Extensive experimental results reveal that our\nproposed method is able to outperform the state-of-the-art UDA-SS method by a\nmargin of 1.1 mIoU in the adaptation of GTA-V to Cityscapes and of 0.9 mIoU in\nthe adaptation of SYNTHIA to Cityscapes.\n","authors":["Zheng Chen","Zhengming Ding","Jason M. Gregory","Lantao Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.00063v2","updated":"2023-03-05T18:08:42Z","published":"2021-10-29T19:50:48Z","title":"Polyline Generative Navigable Space Segmentation for Autonomous Visual\n  Navigation","summary":"  Detecting navigable space is a fundamental capability for mobile robots\nnavigating in unknown or unmapped environments. In this work, we treat visual\nnavigable space segmentation as a scene decomposition problem and propose\nPolyline Segmentation Variational autoencoder Network (PSV-Net), a\nrepresentation learning-based framework for learning the navigable space\nsegmentation in a self-supervised manner. Current segmentation techniques\nheavily rely on fully-supervised learning strategies which demand a large\namount of pixel-level annotated images. In this work, we propose a framework\nleveraging a Variational AutoEncoder (VAE) and an AutoEncoder (AE) to learn a\npolyline representation that compactly outlines the desired navigable space\nboundary. Through extensive experiments, we validate that the proposed PSV-Net\ncan learn the visual navigable space with no or few labels, producing an\naccuracy comparable to fully-supervised state-of-the-art methods that use all\navailable labels. In addition, we show that integrating the proposed navigable\nspace segmentation model with a visual planner can achieve efficient mapless\nnavigation in real environments.\n","authors":["Zheng Chen","Zhengming Ding","David Crandall","Lantao Liu"],"pdf_url":"https://arxiv.org/pdf/2111.00063v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02737v1","updated":"2023-03-05T18:04:28Z","published":"2023-03-05T18:04:28Z","title":"SePaint: Semantic Map Inpainting via Multinomial Diffusion","summary":"  Prediction beyond partial observations is crucial for robots to navigate in\nunknown environments because it can provide extra information regarding the\nsurroundings beyond the current sensing range or resolution. In this work, we\nconsider the inpainting of semantic Bird's-Eye-View maps. We propose SePaint,\nan inpainting model for semantic data based on generative multinomial\ndiffusion. To maintain semantic consistency, we need to condition the\nprediction for the missing regions on the known regions. We propose a novel and\nefficient condition strategy, Look-Back Condition (LB-Con), which performs\none-step look-back operations during the reverse diffusion process. By doing\nso, we are able to strengthen the harmonization between unknown and known\nparts, leading to better completion performance. We have conducted extensive\nexperiments on different datasets, showing our proposed model outperforms\ncommonly used interpolation methods in various robotic applications.\n","authors":["Zheng Chen","Deepak Duggirala","David Crandall","Lei Jiang","Lantao Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02735v1","updated":"2023-03-05T18:02:54Z","published":"2023-03-05T18:02:54Z","title":"Scalable Object Detection on Embedded Devices Using Weight Pruning and\n  Singular Value Decomposition","summary":"  This paper presents a method for optimizing object detection models by\ncombining weight pruning and singular value decomposition (SVD). The proposed\nmethod was evaluated on a custom dataset of street work images obtained from\nhttps://universe.roboflow.com/roboflow-100/street-work. The dataset consists of\n611 training images, 175 validation images, and 87 test images with 7 classes.\nWe compared the performance of the optimized models with the original\nunoptimized model in terms of frame rate, mean average precision (mAP@50), and\nweight size. The results show that the weight pruning + SVD model achieved a\n0.724 mAP@50 with a frame rate of 1.48 FPS and a weight size of 12.1 MB,\noutperforming the original model (0.717 mAP@50, 1.50 FPS, and 12.3 MB).\nPrecision-recall curves were also plotted for all models. Our work demonstrates\nthat the proposed method can effectively optimize object detection models while\nbalancing accuracy, speed, and model size.\n","authors":["Dohyun Ham","Jaeyeop Jeong","June-Kyoo Park","Raehyeon Jeong","Seungmin Jeon","Hyeongjun Jeon","Yewon Lim"],"pdf_url":"https://arxiv.org/pdf/2303.02735v1.pdf","comment":"8 pages, 3 figures. A report of the project done as part of the\n  Yonsei-Roboin project for the 2nd semester, 2022"},{"id":"http://arxiv.org/abs/2303.02733v1","updated":"2023-03-05T17:57:33Z","published":"2023-03-05T17:57:33Z","title":"Reparameterization through Spatial Gradient Scaling","summary":"  Reparameterization aims to improve the generalization of deep neural networks\nby transforming convolutional layers into equivalent multi-branched structures\nduring training. However, there exists a gap in understanding how\nreparameterization may change and benefit the learning process of neural\nnetworks. In this paper, we present a novel spatial gradient scaling method to\nredistribute learning focus among weights in convolutional networks. We prove\nthat spatial gradient scaling achieves the same learning dynamics as a branched\nreparameterization yet without introducing structural changes into the network.\nWe further propose an analytical approach that dynamically learns scalings for\neach convolutional layer based on the spatial characteristics of its input\nfeature map gauged by mutual information. Experiments on CIFAR-10, CIFAR-100,\nand ImageNet show that without searching for reparameterized structures, our\nproposed scaling method outperforms the state-of-the-art reparameterization\nstrategies at a lower computational cost.\n","authors":["Alexander Detkov","Mohammad Salameh","Muhammad Fetrat Qharabagh","Jialin Zhang","Wei Lui","Shangling Jui","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2303.02733v1.pdf","comment":"Published at ICLR 2023. Code available\n  $\\href{https://github.com/Ascend-Research/Reparameterization}{here}$"},{"id":"http://arxiv.org/abs/2303.02731v1","updated":"2023-03-05T17:55:15Z","published":"2023-03-05T17:55:15Z","title":"Vision based Virtual Guidance for Navigation","summary":"  This paper explores the impact of virtual guidance on mid-level\nrepresentation-based navigation, where an agent performs navigation tasks based\nsolely on visual observations. Instead of providing distance measures or\nnumerical directions to guide the agent, which may be difficult for it to\ninterpret visually, the paper investigates the potential of different forms of\nvirtual guidance schemes on navigation performance. Three schemes of virtual\nguidance signals are explored: virtual navigation path, virtual waypoints, and\na combination of both. The experiments were conducted using a virtual city\nbuilt with the Unity engine to train the agents while avoiding obstacles. The\nresults show that virtual guidance provides the agent with more meaningful\nnavigation information and achieves better performance in terms of path\ncompletion rates and navigation efficiency. In addition, a set of analyses were\nprovided to investigate the failure cases and the navigated trajectories, and a\npilot study was conducted for the real-world scenarios.\n","authors":["Hsuan-Kung Yang","Yu-Ying Chen","Tsung-Chih Chiang","Chia-Chuan Hsu","Chun-Chia Huang","Chun-Wei Huang","Jou-Min Liu","Ting-Ru Liu","Tsu-Ching Hsiao","Chun-Yi Lee"],"pdf_url":"https://arxiv.org/pdf/2303.02731v1.pdf","comment":"Yu-Ying Chen, Tsung-Chih Chiang, Chia-Chuan Hsu, Chun-Chia Huang,\n  Chun-Wei Huang, Jou-Min Liu, and Ting-Ru Liu contributed equally to this\n  work, names listed in alphabetical order; This work has been submitted to the\n  IEEE for possible publication"},{"id":"http://arxiv.org/abs/2303.02717v1","updated":"2023-03-05T17:12:50Z","published":"2023-03-05T17:12:50Z","title":"Learning to Localize in Unseen Scenes with Relative Pose Regressors","summary":"  Relative pose regressors (RPRs) localize a camera by estimating its relative\ntranslation and rotation to a pose-labelled reference. Unlike scene coordinate\nregression and absolute pose regression methods, which learn absolute scene\nparameters, RPRs can (theoretically) localize in unseen environments, since\nthey only learn the residual pose between camera pairs. In practice, however,\nthe performance of RPRs is significantly degraded in unseen scenes. In this\nwork, we propose to aggregate paired feature maps into latent codes, instead of\noperating on global image descriptors, in order to improve the generalization\nof RPRs. We implement aggregation with concatenation, projection, and attention\noperations (Transformer Encoders) and learn to regress the relative pose\nparameters from the resulting latent codes. We further make use of a recently\nproposed continuous representation of rotation matrices, which alleviates the\nlimitations of the commonly used quaternions. Compared to state-of-the-art\nRPRs, our model is shown to localize significantly better in unseen\nenvironments, across both indoor and outdoor benchmarks, while maintaining\ncompetitive performance in seen scenes. We validate our findings and\narchitecture design through multiple ablations. Our code and pretrained models\nis publicly available.\n","authors":["Ofer Idan","Yoli Shavit","Yosi Keller"],"pdf_url":"https://arxiv.org/pdf/2303.02717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02409v2","updated":"2023-03-05T17:08:58Z","published":"2022-12-05T16:47:19Z","title":"Decoding natural image stimuli from fMRI data with a surface-based\n  convolutional network","summary":"  Due to the low signal-to-noise ratio and limited resolution of functional MRI\ndata, and the high complexity of natural images, reconstructing a visual\nstimulus from human brain fMRI measurements is a challenging task. In this\nwork, we propose a novel approach for this task, which we call Cortex2Image, to\ndecode visual stimuli with high semantic fidelity and rich fine-grained detail.\nIn particular, we train a surface-based convolutional network model that maps\nfrom brain response to semantic image features first (Cortex2Semantic). We then\ncombine this model with a high-quality image generator (Instance-Conditioned\nGAN) to train another mapping from brain response to fine-grained image\nfeatures using a variational approach (Cortex2Detail). Image reconstructions\nobtained by our proposed method achieve state-of-the-art semantic fidelity,\nwhile yielding good fine-grained similarity with the ground-truth stimulus. Our\ncode is available at: https://github.com/zijin-gu/meshconv-decoding.git.\n","authors":["Zijin Gu","Keith Jamison","Amy Kuceyeski","Mert Sabuncu"],"pdf_url":"https://arxiv.org/pdf/2212.02409v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02715v1","updated":"2023-03-05T17:06:40Z","published":"2023-03-05T17:06:40Z","title":"Deep Learning in the Field of Biometric Template Protection: An Overview","summary":"  Today, deep learning represents the most popular and successful form of\nmachine learning. Deep learning has revolutionised the field of pattern\nrecognition, including biometric recognition. Biometric systems utilising deep\nlearning have been shown to achieve auspicious recognition accuracy, surpassing\nhuman performance. Apart from said breakthrough advances in terms of biometric\nperformance, the use of deep learning was reported to impact different\ncovariates of biometrics such as algorithmic fairness, vulnerability to\nattacks, or template protection. Technologies of biometric template protection\nare designed to enable a secure and privacy-preserving deployment of\nbiometrics. In the recent past, deep learning techniques have been frequently\napplied in biometric template protection systems for various purposes. This\nwork provides an overview of how advances in deep learning take influence on\nthe field of biometric template protection. The interrelation between improved\nbiometric performance rates and security in biometric template protection is\nelaborated. Further, the use of deep learning for obtaining feature\nrepresentations that are suitable for biometric template protection is\ndiscussed. Novel methods that apply deep learning to achieve various goals of\nbiometric template protection are surveyed along with deep learning-based\nattacks.\n","authors":["Christian Rathgeb","Jascha Kolberg","Andreas Uhl","Christoph Busch"],"pdf_url":"https://arxiv.org/pdf/2303.02715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12228v3","updated":"2023-03-05T15:48:51Z","published":"2023-02-23T18:46:41Z","title":"Encoder-based Domain Tuning for Fast Personalization of Text-to-Image\n  Models","summary":"  Text-to-image personalization aims to teach a pre-trained diffusion model to\nreason about novel, user provided concepts, embedding them into new scenes\nguided by natural language prompts. However, current personalization approaches\nstruggle with lengthy training times, high storage requirements or loss of\nidentity. To overcome these limitations, we propose an encoder-based\ndomain-tuning approach. Our key insight is that by underfitting on a large set\nof concepts from a given domain, we can improve generalization and create a\nmodel that is more amenable to quickly adding novel concepts from the same\ndomain. Specifically, we employ two components: First, an encoder that takes as\nan input a single image of a target concept from a given domain, e.g. a\nspecific face, and learns to map it into a word-embedding representing the\nconcept. Second, a set of regularized weight-offsets for the text-to-image\nmodel that learn how to effectively ingest additional concepts. Together, these\ncomponents are used to guide the learning of unseen concepts, allowing us to\npersonalize a model using only a single image and as few as 5 training steps -\naccelerating personalization from dozens of minutes to seconds, while\npreserving quality.\n","authors":["Rinon Gal","Moab Arar","Yuval Atzmon","Amit H. Bermano","Gal Chechik","Daniel Cohen-Or"],"pdf_url":"https://arxiv.org/pdf/2302.12228v3.pdf","comment":"Project page at https://tuning-encoder.github.io/"},{"id":"http://arxiv.org/abs/2303.02700v1","updated":"2023-03-05T15:28:13Z","published":"2023-03-05T15:28:13Z","title":"HairStep: Transfer Synthetic to Real Using Strand and Depth Maps for\n  Single-View 3D Hair Modeling","summary":"  In this work, we tackle the challenging problem of learning-based single-view\n3D hair modeling. Due to the great difficulty of collecting paired real image\nand 3D hair data, using synthetic data to provide prior knowledge for real\ndomain becomes a leading solution. This unfortunately introduces the challenge\nof domain gap. Due to the inherent difficulty of realistic hair rendering,\nexisting methods typically use orientation maps instead of hair images as input\nto bridge the gap. We firmly think an intermediate representation is essential,\nbut we argue that orientation map using the dominant filtering-based methods is\nsensitive to uncertain noise and far from a competent representation. Thus, we\nfirst raise this issue up and propose a novel intermediate representation,\ntermed as HairStep, which consists of a strand map and a depth map. It is found\nthat HairStep not only provides sufficient information for accurate 3D hair\nmodeling, but also is feasible to be inferred from real images. Specifically,\nwe collect a dataset of 1,250 portrait images with two types of annotations. A\nlearning framework is further designed to transfer real images to the strand\nmap and depth map. It is noted that, an extra bonus of our new dataset is the\nfirst quantitative metric for 3D hair modeling. Our experiments show that\nHairStep narrows the domain gap between synthetic and real and achieves\nstate-of-the-art performance on single-view 3D hair reconstruction.\n","authors":["Yujian Zheng","Zirong Jin","Moran Li","Haibin Huang","Chongyang Ma","Shuguang Cui","Xiaoguang Han"],"pdf_url":"https://arxiv.org/pdf/2303.02700v1.pdf","comment":"CVPR 2023, project page:\n  https://paulyzheng.github.io/research/hairstep/"},{"id":"http://arxiv.org/abs/2303.02698v1","updated":"2023-03-05T15:27:24Z","published":"2023-03-05T15:27:24Z","title":"Robust affine feature matching via quadratic assignment on Grassmannians","summary":"  GraNNI (Grassmannians for Nearest Neighbours Identification) a new algorithm\nto solve the problem of affine registration is proposed. The algorithm is based\non the Grassmannian of $k$--dimensional planes in $\\mathbb{R}^n$ and minimizing\nthe Frobenius norm between the two elements of the Grassmannian. The Quadratic\nAssignment Problem (QAP) is used to find the matching. The results of the\nexperiments show that the algorithm is more robust to noise and point\ndiscrepancy in point clouds than previous approaches.\n","authors":["Alexander Kolpakov","Michael Werman"],"pdf_url":"https://arxiv.org/pdf/2303.02698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02693v1","updated":"2023-03-05T15:11:53Z","published":"2023-03-05T15:11:53Z","title":"Maximizing Spatio-Temporal Entropy of Deep 3D CNNs for Efficient Video\n  Recognition","summary":"  3D convolution neural networks (CNNs) have been the prevailing option for\nvideo recognition. To capture the temporal information, 3D convolutions are\ncomputed along the sequences, leading to cubically growing and expensive\ncomputations. To reduce the computational cost, previous methods resort to\nmanually designed 3D/2D CNN structures with approximations or automatic search,\nwhich sacrifice the modeling ability or make training time-consuming. In this\nwork, we propose to automatically design efficient 3D CNN architectures via a\nnovel training-free neural architecture search approach tailored for 3D CNNs\nconsidering the model complexity. To measure the expressiveness of 3D CNNs\nefficiently, we formulate a 3D CNN as an information system and derive an\nanalytic entropy score, based on the Maximum Entropy Principle. Specifically,\nwe propose a spatio-temporal entropy score (STEntr-Score) with a refinement\nfactor to handle the discrepancy of visual information in spatial and temporal\ndimensions, through dynamically leveraging the correlation between the feature\nmap size and kernel size depth-wisely. Highly efficient and expressive 3D CNN\narchitectures, \\ie entropy-based 3D CNNs (E3D family), can then be efficiently\nsearched by maximizing the STEntr-Score under a given computational budget, via\nan evolutionary algorithm without training the network parameters. Extensive\nexperiments on Something-Something V1\\&V2 and Kinetics400 demonstrate that the\nE3D family achieves state-of-the-art performance with higher computational\nefficiency. Code is available at\nhttps://github.com/alibaba/lightweight-neural-architecture-search.\n","authors":["Junyan Wang","Zhenhong Sun","Yichen Qian","Dong Gong","Xiuyu Sun","Ming Lin","Maurice Pagnucco","Yang Song"],"pdf_url":"https://arxiv.org/pdf/2303.02693v1.pdf","comment":"This manuscript has been accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02688v1","updated":"2023-03-05T15:06:54Z","published":"2023-03-05T15:06:54Z","title":"Text2Face: A Multi-Modal 3D Face Model","summary":"  We present the first 3D morphable modelling approach, whereby 3D face shape\ncan be directly and completely defined using a textual prompt. Building on work\nin multi-modal learning, we extend the FLAME head model to a common\nimage-and-text latent space. This allows for direct 3D Morphable Model (3DMM)\nparameter generation and therefore shape manipulation from textual\ndescriptions. Our method, Text2Face, has many applications; for example:\ngenerating police photofits where the input is already in natural language. It\nfurther enables multi-modal 3DMM image fitting to sketches and sculptures, as\nwell as images.\n","authors":["Will Rowan","Patrik Huber","Nick Pears","Andrew Keeling"],"pdf_url":"https://arxiv.org/pdf/2303.02688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02672v1","updated":"2023-03-05T13:48:20Z","published":"2023-03-05T13:48:20Z","title":"Continuous-Time Gaussian Process Motion-Compensation for Event-vision\n  Pattern Tracking with Distance Fields","summary":"  This work addresses the issue of motion compensation and pattern tracking in\nevent camera data. An event camera generates asynchronous streams of events\ntriggered independently by each of the pixels upon changes in the observed\nintensity. Providing great advantages in low-light and rapid-motion scenarios,\nsuch unconventional data present significant research challenges as traditional\nvision algorithms are not directly applicable to this sensing modality. The\nproposed method decomposes the tracking problem into a local SE(2)\nmotion-compensation step followed by a homography registration of small\nmotion-compensated event batches. The first component relies on Gaussian\nProcess (GP) theory to model the continuous occupancy field of the events in\nthe image plane and embed the camera trajectory in the covariance kernel\nfunction. In doing so, estimating the trajectory is done similarly to GP\nhyperparameter learning by maximising the log marginal likelihood of the data.\nThe continuous occupancy fields are turned into distance fields and used as\ntemplates for homography-based registration. By benchmarking the proposed\nmethod against other state-of-the-art techniques, we show that our open-source\nimplementation performs high-accuracy motion compensation and produces\nhigh-quality tracks in real-world scenarios.\n","authors":["Cedric Le Gentil","Ignacio Alzugaray","Teresa Vidal-Calleja"],"pdf_url":"https://arxiv.org/pdf/2303.02672v1.pdf","comment":"Accepted for presentation at the 2023 IEEE International Conference\n  on Robotics and Automation"},{"id":"http://arxiv.org/abs/2303.02666v1","updated":"2023-03-05T13:15:28Z","published":"2023-03-05T13:15:28Z","title":"Learned Lossless Compression for JPEG via Frequency-Domain Prediction","summary":"  JPEG images can be further compressed to enhance the storage and transmission\nof large-scale image datasets. Existing learned lossless compressors for RGB\nimages cannot be well transferred to JPEG images due to the distinguishing\ndistribution of DCT coefficients and raw pixels. In this paper, we propose a\nnovel framework for learned lossless compression of JPEG images that achieves\nend-to-end optimized prediction of the distribution of decoded DCT\ncoefficients. To enable learning in the frequency domain, DCT coefficients are\npartitioned into groups to utilize implicit local redundancy. An\nautoencoder-like architecture is designed based on the weight-shared blocks to\nrealize entropy modeling of grouped DCT coefficients and independently compress\nthe priors. We attempt to realize learned lossless compression of JPEG images\nin the frequency domain. Experimental results demonstrate that the proposed\nframework achieves superior or comparable performance in comparison to most\nrecent lossless compressors with handcrafted context modeling for JPEG images.\n","authors":["Jixiang Luo","Shaohui Li","Wenrui Dai","Chenglin Li","Junni Zou","Hongkai Xiong"],"pdf_url":"https://arxiv.org/pdf/2303.02666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02660v1","updated":"2023-03-05T12:35:58Z","published":"2023-03-05T12:35:58Z","title":"SynthASpoof: Developing Face Presentation Attack Detection Based on\n  Privacy-friendly Synthetic Data","summary":"  Recently, significant progress has been made in face presentation attack\ndetection (PAD), which aims to secure face recognition systems against\npresentation attacks, owing to the availability of several face PAD datasets.\nHowever, all available datasets are based on privacy and legally-sensitive\nauthentic biometric data with a limited number of subjects. To target these\nlegal and technical challenges, this work presents the first synthetic-based\nface PAD dataset, named SynthASpoof, as a large-scale PAD development dataset.\nThe bona fide samples in SynthASpoof are synthetically generated and the attack\nsamples are collected by presenting such synthetic data to capture systems in a\nreal attack scenario. The experimental results demonstrate the feasibility of\nusing SynthASpoof for the development of face PAD. Moreover, we boost the\nperformance of such a solution by incorporating the domain generalization tool\nMixStyle into the PAD solutions. Additionally, we showed the viability of using\nsynthetic data as a supplement to enrich the diversity of limited authentic\ntraining data and consistently enhance PAD performances. The SynthASpoof\ndataset, containing 25,000 bona fide and 78,800 attack samples, the\nimplementation, and the pre-trained weights are made publicly available.\n","authors":["Meiling Fang","Marco Huber","Naser Damer"],"pdf_url":"https://arxiv.org/pdf/2303.02660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.10368v3","updated":"2023-03-05T12:26:16Z","published":"2022-09-21T14:03:08Z","title":"Improving the Safety of 3D Object Detectors in Autonomous Driving using\n  IoGT and Distance Measures","summary":"  State-of-the-art object detectors are commonly evaluated based on accuracy\nmetrics such as mean Average Precision (mAP). In this paper, inspired by the\nfact that mAP is not a direct safety indicator, we propose a straightforward\nsafety metric, especially for 3D object detectors in Autonomous Driving\ncontexts, by combining the Intersection-over-Ground-Truth (IoGT) measure and a\ndistance ratio. Subsequently, we formulate a safety-aware loss function by\namending IoGT to commonly used accuracy-oriented loss functions. Our\nexperiments using models from the MMDetection3D library, the nuScenes dataset,\nand an in-house simulation dataset demonstrate that the object detector trained\nwith our loss function significantly reduces unsafe predictions while staying\nperformant on accuracy and maintaining good stability in the learning process.\n","authors":["Hsuan-Cheng Liao","Chih-Hong Cheng","Hasan Esen","Alois Knoll"],"pdf_url":"https://arxiv.org/pdf/2209.10368v3.pdf","comment":"8 pages (IEEE double column format), 8 figures, revised with clearer\n  presentation and resubmitted to IROS 2023"},{"id":"http://arxiv.org/abs/2202.13133v2","updated":"2023-03-05T12:16:33Z","published":"2022-02-26T13:02:32Z","title":"Automation of reversible steganographic coding with nonlinear discrete\n  optimisation","summary":"  Authentication mechanisms are at the forefront of defending the world from\nvarious types of cybercrime. Steganography can serve as an authentication\nsolution through the use of a digital signature embedded in a carrier object to\nensure the integrity of the object and simultaneously lighten the burden of\nmetadata management. Nevertheless, despite being generally imperceptible to\nhuman sensory systems, any degree of steganographic distortion might be\ninadmissible in fidelity-sensitive situations such as forensic science, legal\nproceedings, medical diagnosis and military reconnaissance. This has led to the\ndevelopment of reversible steganography. A fundamental element of reversible\nsteganography is predictive analytics, for which powerful neural network models\nhave been effectively deployed. Another core element is reversible\nsteganographic coding. Contemporary coding is based primarily on heuristics,\nwhich offers a shortcut towards sufficient, but not necessarily optimal,\ncapacity--distortion performance. While attempts have been made to realise\nautomatic coding with neural networks, perfect reversibility is unattainable\nvia such learning machinery. Instead of relying on heuristics and machine\nlearning, we aim to derive optimal coding by means of mathematical\noptimisation. In this study, we formulate reversible steganographic coding as a\nnonlinear discrete optimisation problem with a logarithmic capacity constraint\nand a quadratic distortion objective. Linearisation techniques are developed to\nenable iterative mixed-integer linear programming. Experimental results\nvalidate the near-optimality of the proposed optimisation algorithm when\nbenchmarked against a brute-force method.\n","authors":["Ching-Chun Chang"],"pdf_url":"https://arxiv.org/pdf/2202.13133v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08712v2","updated":"2023-03-05T12:12:53Z","published":"2022-11-16T07:02:12Z","title":"Improving Feature-based Visual Localization by Geometry-Aided Matching","summary":"  Feature matching is crucial in visual localization, where 2D-3D\ncorrespondence plays a major role in determining the accuracy of camera pose. A\nsufficient number of well-distributed 2D-3D correspondences is essential for\naccurate pose estimation due to noise. However, existing 2D-3D feature matching\nmethods rely on finding nearest neighbors in the feature space and removing\noutliers using hand-crafted heuristics, which may lead to potential matches\nbeing missed or the correct matches being filtered out. In this work, we\npropose a novel method called Geometry-Aided Matching (GAM), which incorporates\nboth appearance information and geometric context to address this issue and to\nimprove 2D-3D feature matching. GAM can greatly boost the recall of 2D-3D\nmatches while maintaining high precision. We apply GAM to a new hierarchical\nvisual localization pipeline and show that GAM can effectively improve the\nrobustness and accuracy of localization. Extensive experiments show that GAM\ncan find more real matches than hand-crafted heuristics and learning baselines.\nOur proposed localization method achieves state-of-the-art results on multiple\nvisual localization datasets. Experiments on Cambridge Landmarks dataset show\nthat our method outperforms the existing state-of-the-art methods and is six\ntimes faster than the top-performed method. The source code is available at\nhttps://github.com/openxrlab/xrlocalization.\n","authors":["Hailin Yu","Youji Feng","Weicai Ye","Mingxuan Jiang","Hujun Bao","Guofeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.08712v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02655v1","updated":"2023-03-05T12:09:37Z","published":"2023-03-05T12:09:37Z","title":"On Modifying a Neural Network's Perception","summary":"  Artificial neural networks have proven to be extremely useful models that\nhave allowed for multiple recent breakthroughs in the field of Artificial\nIntelligence and many others. However, they are typically regarded as black\nboxes, given how difficult it is for humans to interpret how these models reach\ntheir results. In this work, we propose a method which allows one to modify\nwhat an artificial neural network is perceiving regarding specific\nhuman-defined concepts, enabling the generation of hypothetical scenarios that\ncould help understand and even debug the neural network model. Through\nempirical evaluation, in a synthetic dataset and in the ImageNet dataset, we\ntest the proposed method on different models, assessing whether the performed\nmanipulations are well interpreted by the models, and analyzing how they react\nto them.\n","authors":["Manuel de Sousa Ribeiro","João Leite"],"pdf_url":"https://arxiv.org/pdf/2303.02655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02648v1","updated":"2023-03-05T11:45:53Z","published":"2023-03-05T11:45:53Z","title":"Comparative study of Transformer and LSTM Network with attention\n  mechanism on Image Captioning","summary":"  In a globalized world at the present epoch of generative intelligence, most\nof the manual labour tasks are automated with increased efficiency. This can\nsupport businesses to save time and money. A crucial component of generative\nintelligence is the integration of vision and language. Consequently, image\ncaptioning become an intriguing area of research. There have been multiple\nattempts by the researchers to solve this problem with different deep learning\narchitectures, although the accuracy has increased, but the results are still\nnot up to standard. This study buckles down to the comparison of Transformer\nand LSTM with attention block model on MS-COCO dataset, which is a standard\ndataset for image captioning. For both the models we have used pretrained\nInception-V3 CNN encoder for feature extraction of the images. The Bilingual\nEvaluation Understudy score (BLEU) is used to checked the accuracy of caption\ngenerated by both models. Along with the transformer and LSTM with attention\nblock models,CLIP-diffusion model, M2-Transformer model and the X-Linear\nAttention model have been discussed with state of the art accuracy.\n","authors":["Pranav Dandwate","Chaitanya Shahane","Vandana Jagtap","Shridevi C. Karande"],"pdf_url":"https://arxiv.org/pdf/2303.02648v1.pdf","comment":"13 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2303.02641v1","updated":"2023-03-05T11:06:20Z","published":"2023-03-05T11:06:20Z","title":"CueCAn: Cue Driven Contextual Attention For Identifying Missing Traffic\n  Signs on Unconstrained Roads","summary":"  Unconstrained Asian roads often involve poor infrastructure, affecting\noverall road safety. Missing traffic signs are a regular part of such roads.\nMissing or non-existing object detection has been studied for locating missing\ncurbs and estimating reasonable regions for pedestrians on road scene images.\nSuch methods involve analyzing task-specific single object cues. In this paper,\nwe present the first and most challenging video dataset for missing objects,\nwith multiple types of traffic signs for which the cues are visible without the\nsigns in the scenes. We refer to it as the Missing Traffic Signs Video Dataset\n(MTSVD). MTSVD is challenging compared to the previous works in two aspects i)\nThe traffic signs are generally not present in the vicinity of their cues, ii)\nThe traffic signs cues are diverse and unique. Also, MTSVD is the first\npublicly available missing object dataset. To train the models for identifying\nmissing signs, we complement our dataset with 10K traffic sign tracks, with 40\npercent of the traffic signs having cues visible in the scenes. For identifying\nmissing signs, we propose the Cue-driven Contextual Attention units (CueCAn),\nwhich we incorporate in our model encoder. We first train the encoder to\nclassify the presence of traffic sign cues and then train the entire\nsegmentation model end-to-end to localize missing traffic signs. Quantitative\nand qualitative analysis shows that CueCAn significantly improves the\nperformance of base models.\n","authors":["Varun Gupta","Anbumani Subramanian","C. V. Jawahar","Rohit Saluja"],"pdf_url":"https://arxiv.org/pdf/2303.02641v1.pdf","comment":"International Conference on Robotics and Automation (ICRA'23)"},{"id":"http://arxiv.org/abs/2205.12551v2","updated":"2023-03-05T11:04:12Z","published":"2022-05-25T07:56:18Z","title":"Masked Jigsaw Puzzle: A Versatile Position Embedding for Vision\n  Transformers","summary":"  Position Embeddings (PEs), an arguably indispensable component in Vision\nTransformers (ViTs), have been shown to improve the performance of ViTs on many\nvision tasks. However, PEs have a potentially high risk of privacy leakage\nsince the spatial information of the input patches is exposed. This caveat\nnaturally raises a series of interesting questions about the impact of PEs on\nthe accuracy, privacy, prediction consistency, etc. To tackle these issues, we\npropose a Masked Jigsaw Puzzle (MJP) position embedding method. In particular,\nMJP first shuffles the selected patches via our block-wise random jigsaw puzzle\nshuffle algorithm, and their corresponding PEs are occluded. Meanwhile, for the\nnon-occluded patches, the PEs remain the original ones but their spatial\nrelation is strengthened via our dense absolute localization regressor. The\nexperimental results reveal that 1) PEs explicitly encode the 2D spatial\nrelationship and lead to severe privacy leakage problems under gradient\ninversion attack; 2) Training ViTs with the naively shuffled patches can\nalleviate the problem, but it harms the accuracy; 3) Under a certain shuffle\nratio, the proposed MJP not only boosts the performance and robustness on\nlarge-scale datasets (i.e., ImageNet-1K and ImageNet-C, -A/O) but also improves\nthe privacy preservation ability under typical gradient attacks by a large\nmargin. The source code and trained models are available\nat~\\url{https://github.com/yhlleo/MJP}.\n","authors":["Bin Ren","Yahui Liu","Yue Song","Wei Bi","Rita Cucchiara","Nicu Sebe","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2205.12551v2.pdf","comment":"Accepted to CVPR2023"},{"id":"http://arxiv.org/abs/2303.02635v1","updated":"2023-03-05T10:32:26Z","published":"2023-03-05T10:32:26Z","title":"VTQA: Visual Text Question Answering via Entity Alignment and\n  Cross-Media Reasoning","summary":"  The ideal form of Visual Question Answering requires understanding, grounding\nand reasoning in the joint space of vision and language and serves as a proxy\nfor the AI task of scene understanding. However, most existing VQA benchmarks\nare limited to just picking the answer from a pre-defined set of options and\nlack attention to text. We present a new challenge with a dataset that contains\n23,781 questions based on 10124 image-text pairs. Specifically, the task\nrequires the model to align multimedia representations of the same entity to\nimplement multi-hop reasoning between image and text and finally use natural\nlanguage to answer the question. The aim of this challenge is to develop and\nbenchmark models that are capable of multimedia entity alignment, multi-step\nreasoning and open-ended answer generation.\n","authors":["Kang Chen","Xiangqian Wu"],"pdf_url":"https://arxiv.org/pdf/2303.02635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02632v1","updated":"2023-03-05T10:17:10Z","published":"2023-03-05T10:17:10Z","title":"Deep-Learning-based Counting Methods, Datasets, and Applications in\n  Agriculture -- A Review","summary":"  The number of objects is considered an important factor in a variety of tasks\nin the agricultural domain. Automated counting can improve farmers decisions\nregarding yield estimation, stress detection, disease prevention, and more. In\nrecent years, deep learning has been increasingly applied to many\nagriculture-related applications, complementing conventional computer-vision\nalgorithms for counting agricultural objects. This article reviews progress in\nthe past decade and the state of the art for counting methods in agriculture,\nfocusing on deep-learning methods. It presents an overview of counting\nalgorithms, metrics, platforms, and sensors, a list of all publicly available\ndatasets, and an in-depth discussion of various deep-learning methods used for\ncounting. Finally, it discusses open challenges in object counting using deep\nlearning and gives a glimpse into new directions and future perspectives for\ncounting research. The review reveals a major leap forward in object counting\nin agriculture in the past decade, led by the penetration of deep learning\nmethods into counting platforms.\n","authors":["Guy Farjon","Liu Huijun","Yael Edan"],"pdf_url":"https://arxiv.org/pdf/2303.02632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02136v2","updated":"2023-03-05T10:09:11Z","published":"2023-02-04T09:14:18Z","title":"Efficient End-to-End Video Question Answering with Pyramidal Multimodal\n  Transformer","summary":"  This paper presents a new method for end-to-end Video Question Answering\n(VideoQA), aside from the current popularity of using large-scale pre-training\nwith huge feature extractors. We achieve this with a pyramidal multimodal\ntransformer (PMT) model, which simply incorporates a learnable word embedding\nlayer, a few convolutional and transformer layers. We use the anisotropic\npyramid to fulfill video-language interactions across different spatio-temporal\nscales. In addition to the canonical pyramid, which includes both bottom-up and\ntop-down pathways with lateral connections, novel strategies are proposed to\ndecompose the visual feature stream into spatial and temporal sub-streams at\ndifferent scales and implement their interactions with the linguistic semantics\nwhile preserving the integrity of local and global semantics. We demonstrate\nbetter or on-par performances with high computational efficiency against\nstate-of-the-art methods on five VideoQA benchmarks. Our ablation study shows\nthe scalability of our model that achieves competitive results for\ntext-to-video retrieval by leveraging feature extractors with reusable\npre-trained weights, and also the effectiveness of the pyramid.\n","authors":["Min Peng","Chongyang Wang","Yu Shi","Xiang-Dong Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.02136v2.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2206.12455v2","updated":"2023-03-05T10:08:01Z","published":"2022-06-24T18:27:30Z","title":"Ev-NeRF: Event Based Neural Radiance Field","summary":"  We present Ev-NeRF, a Neural Radiance Field derived from event data. While\nevent cameras can measure subtle brightness changes in high frame rates, the\nmeasurements in low lighting or extreme motion suffer from significant domain\ndiscrepancy with complex noise. As a result, the performance of event-based\nvision tasks does not transfer to challenging environments, where the event\ncameras are expected to thrive over normal cameras. We find that the multi-view\nconsistency of NeRF provides a powerful self-supervision signal for eliminating\nthe spurious measurements and extracting the consistent underlying structure\ndespite highly noisy input. Instead of posed images of the original NeRF, the\ninput to Ev-NeRF is the event measurements accompanied by the movements of the\nsensors. Using the loss function that reflects the measurement model of the\nsensor, Ev-NeRF creates an integrated neural volume that summarizes the\nunstructured and sparse data points captured for about 2-4 seconds. The\ngenerated neural volume can also produce intensity images from novel views with\nreasonable depth estimates, which can serve as a high-quality input to various\nvision-based tasks. Our results show that Ev-NeRF achieves competitive\nperformance for intensity image reconstruction under extreme noise conditions\nand high-dynamic-range imaging.\n","authors":["Inwoo Hwang","Junho Kim","Young Min Kim"],"pdf_url":"https://arxiv.org/pdf/2206.12455v2.pdf","comment":"Accepted to WACV 2023"},{"id":"http://arxiv.org/abs/2203.08382v4","updated":"2023-03-05T09:35:06Z","published":"2022-03-16T04:10:45Z","title":"Dual Diffusion Implicit Bridges for Image-to-Image Translation","summary":"  Common image-to-image translation methods rely on joint training over data\nfrom both source and target domains. The training process requires concurrent\naccess to both datasets, which hinders data separation and privacy protection;\nand existing models cannot be easily adapted for translation of new domain\npairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation\nmethod based on diffusion models, that circumvents training on domain pairs.\nImage translation with DDIBs relies on two diffusion models trained\nindependently on each domain, and is a two-step process: DDIBs first obtain\nlatent encodings for source images with the source diffusion model, and then\ndecode such encodings using the target model to construct target images. Both\nsteps are defined via ordinary differential equations (ODEs), thus the process\nis cycle consistent only up to discretization errors of the ODE solvers.\nTheoretically, we interpret DDIBs as concatenation of source to latent, and\nlatent to target Schrodinger Bridges, a form of entropy-regularized optimal\ntransport, to explain the efficacy of the method. Experimentally, we apply\nDDIBs on synthetic and high-resolution image datasets, to demonstrate their\nutility in a wide variety of translation tasks and their inherent optimal\ntransport properties.\n","authors":["Xuan Su","Jiaming Song","Chenlin Meng","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2203.08382v4.pdf","comment":"18 pages, 12 figures, in the Eleventh International Conference on\n  Learning Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2208.09686v2","updated":"2023-03-05T09:22:53Z","published":"2022-08-20T14:12:06Z","title":"YOLOV: Making Still Image Object Detectors Great at Video Object\n  Detection","summary":"  Video object detection (VID) is challenging because of the high variation of\nobject appearance as well as the diverse deterioration in some frames. On the\npositive side, the detection in a certain frame of a video, compared with that\nin a still image, can draw support from other frames. Hence, how to aggregate\nfeatures across different frames is pivotal to VID problem. Most of existing\naggregation algorithms are customized for two-stage detectors. However, these\ndetectors are usually computationally expensive due to their two-stage nature.\nThis work proposes a simple yet effective strategy to address the above\nconcerns, which costs marginal overheads with significant gains in accuracy.\nConcretely, different from traditional two-stage pipeline, we select important\nregions after the one-stage detection to avoid processing massive low-quality\ncandidates. Besides, we evaluate the relationship between a target frame and\nreference frames to guide the aggregation. We conduct extensive experiments and\nablation studies to verify the efficacy of our design, and reveal its\nsuperiority over other state-of-the-art VID approaches in both effectiveness\nand efficiency. Our YOLOX-based model can achieve promising performance\n(\\emph{e.g.}, 87.5\\% AP50 at over 30 FPS on the ImageNet VID dataset on a\nsingle 2080Ti GPU), making it attractive for large-scale or real-time\napplications. The implementation is simple, we have made the demo codes and\nmodels available at \\url{https://github.com/YuHengsss/YOLOV}.\n","authors":["Yuheng Shi","Naiyan Wang","Xiaojie Guo"],"pdf_url":"https://arxiv.org/pdf/2208.09686v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.08368v5","updated":"2023-03-05T09:08:51Z","published":"2022-03-16T03:23:50Z","title":"Mixed-Precision Neural Network Quantization via Learned Layer-wise\n  Importance","summary":"  The exponentially large discrete search space in mixed-precision quantization\n(MPQ) makes it hard to determine the optimal bit-width for each layer. Previous\nworks usually resort to iterative search methods on the training set, which\nconsume hundreds or even thousands of GPU-hours. In this study, we reveal that\nsome unique learnable parameters in quantization, namely the scale factors in\nthe quantizer, can serve as importance indicators of a layer, reflecting the\ncontribution of that layer to the final accuracy at certain bit-widths. These\nimportance indicators naturally perceive the numerical transformation during\nquantization-aware training, which can precisely provide quantization\nsensitivity metrics of layers. However, a deep network always contains hundreds\nof such indicators, and training them one by one would lead to an excessive\ntime cost. To overcome this issue, we propose a joint training scheme that can\nobtain all indicators at once. It considerably speeds up the indicators\ntraining process by parallelizing the original sequential training processes.\nWith these learned importance indicators, we formulate the MPQ search problem\nas a one-time integer linear programming (ILP) problem. That avoids the\niterative search and significantly reduces search time without limiting the\nbit-width search space. For example, MPQ search on ResNet18 with our indicators\ntakes only 0.06 s, which improves time efficiency exponentially compared to\niterative search methods. Also, extensive experiments show our approach can\nachieve SOTA accuracy on ImageNet for far-ranging models with various\nconstraints (e.g., BitOps, compress rate). Code is available on\nhttps://github.com/1hunters/LIMPQ.\n","authors":["Chen Tang","Kai Ouyang","Zhi Wang","Yifei Zhu","Yaowei Wang","Wen Ji","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2203.08368v5.pdf","comment":"Published on ECCV 2022, code is available on\n  https://github.com/1hunters/LIMPQ"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2209.07590v2","updated":"2023-03-05T23:30:15Z","published":"2022-09-15T19:57:16Z","title":"Prediction of Gender from Longitudinal MRI data via Deep Learning on\n  Adolescent Data Reveals Unique Patterns Associated with Brain Structure and\n  Change over a Two-year Period","summary":"  Deep learning algorithms for predicting neuroimaging data have shown\nconsiderable promise in various applications. Prior work has demonstrated that\ndeep learning models that take advantage of the data's 3D structure can\noutperform standard machine learning on several learning tasks. However, most\nprior research in this area has focused on neuroimaging data from adults.\nWithin the Adolescent Brain and Cognitive Development (ABCD) dataset, a large\nlongitudinal development study, we examine structural MRI data to predict\ngender and identify gender-related changes in brain structure. Results\ndemonstrate that gender prediction accuracy is exceptionally high (>97%) with\ntraining epochs >200 and that this accuracy increases with age. Brain regions\nidentified as the most discriminative in the task under study include\npredominantly frontal areas and the temporal lobe. When evaluating gender\npredictive changes specific to a two-year increase in age, a broader set of\nvisual, cingulate, and insular regions are revealed. Our findings show a robust\ngender-related structural brain change pattern, even over a small age range.\nThis suggests that it might be possible to study how the brain changes during\nadolescence by looking at how these changes are related to different behavioral\nand environmental factors.\n","authors":["Yuda Bi","Anees Abrol","Zening Fu","Jiayu Chen","Jingyu Liu","Vince Calhoun"],"pdf_url":"https://arxiv.org/pdf/2209.07590v2.pdf","comment":"I submitted the wrong paper"},{"id":"http://arxiv.org/abs/2302.09908v2","updated":"2023-03-05T23:10:24Z","published":"2023-02-20T11:09:37Z","title":"A Sidecar Separator Can Convert a Single-Talker Speech Recognition\n  System to a Multi-Talker One","summary":"  Although automatic speech recognition (ASR) can perform well in common\nnon-overlapping environments, sustaining performance in multi-talker\noverlapping speech recognition remains challenging. Recent research revealed\nthat ASR model's encoder captures different levels of information with\ndifferent layers -- the lower layers tend to have more acoustic information,\nand the upper layers more linguistic. This inspires us to develop a Sidecar\nseparator to empower a well-trained ASR model for multi-talker scenarios by\nseparating the mixed speech embedding between two suitable layers. We\nexperimented with a wav2vec 2.0-based ASR model with a Sidecar mounted. By\nfreezing the parameters of the original model and training only the Sidecar\n(8.7 M, 8.4% of all parameters), the proposed approach outperforms the previous\nstate-of-the-art by a large margin for the 2-speaker mixed LibriMix dataset,\nreaching a word error rate (WER) of 10.36%; and obtains comparable results\n(7.56%) for LibriSpeechMix dataset when limited training.\n","authors":["Lingwei Meng","Jiawen Kang","Mingyu Cui","Yuejiao Wang","Xixin Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2302.09908v2.pdf","comment":"Accepted by IEEE International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), 2023"},{"id":"http://arxiv.org/abs/2303.02794v1","updated":"2023-03-05T23:01:02Z","published":"2023-03-05T23:01:02Z","title":"CoRTX: Contrastive Framework for Real-time Explanation","summary":"  Recent advancements in explainable machine learning provide effective and\nfaithful solutions for interpreting model behaviors. However, many explanation\nmethods encounter efficiency issues, which largely limit their deployments in\npractical scenarios. Real-time explainer (RTX) frameworks have thus been\nproposed to accelerate the model explanation process by learning a\none-feed-forward explainer. Existing RTX frameworks typically build the\nexplainer under the supervised learning paradigm, which requires large amounts\nof explanation labels as the ground truth. Considering that accurate\nexplanation labels are usually hard to obtain due to constrained computational\nresources and limited human efforts, effective explainer training is still\nchallenging in practice. In this work, we propose a COntrastive Real-Time\neXplanation (CoRTX) framework to learn the explanation-oriented representation\nand relieve the intensive dependence of explainer training on explanation\nlabels. Specifically, we design a synthetic strategy to select positive and\nnegative instances for the learning of explanation. Theoretical analysis show\nthat our selection strategy can benefit the contrastive learning process on\nexplanation tasks. Experimental results on three real-world datasets further\ndemonstrate the efficiency and efficacy of our proposed CoRTX framework.\n","authors":["Yu-Neng Chuang","Guanchu Wang","Fan Yang","Quan Zhou","Pushkar Tripathi","Xuanting Cai","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2303.02794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14510v2","updated":"2023-03-05T22:58:53Z","published":"2022-12-30T01:41:48Z","title":"A Machine Learning Case Study for AI-empowered echocardiography of\n  Intensive Care Unit Patients in low- and middle-income countries","summary":"  We present a Machine Learning (ML) study case to illustrate the challenges of\nclinical translation for a real-time AI-empowered echocardiography system with\ndata of ICU patients in LMICs. Such ML case study includes data preparation,\ncuration and labelling from 2D Ultrasound videos of 31 ICU patients in LMICs\nand model selection, validation and deployment of three thinner neural networks\nto classify apical four-chamber view. Results of the ML heuristics showed the\npromising implementation, validation and application of thinner networks to\nclassify 4CV with limited datasets. We conclude this work mentioning the need\nfor (a) datasets to improve diversity of demographics, diseases, and (b) the\nneed of further investigations of thinner models to be run and implemented in\nlow-cost hardware to be clinically translated in the ICU in LMICs. The code and\nother resources to reproduce this work are available at\nhttps://github.com/vital-ultrasound/ai-assisted-echocardiography-for-low-resource-countries.\n","authors":["Miguel Xochicale","Louise Thwaites","Sophie Yacoub","Luigi Pisani","Phung-Nhat Tran-Huy","Hamideh Kerdegari","Andrew King","Alberto Gomez"],"pdf_url":"https://arxiv.org/pdf/2212.14510v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11108v3","updated":"2023-03-05T22:30:18Z","published":"2023-01-25T16:39:00Z","title":"On the Mathematics of Diffusion Models","summary":"  This paper gives direct derivations of the differential equations and\nlikelihood formulas of diffusion models assuming only knowledge of Gaussian\ndistributions. A VAE analysis derives both forward and backward stochastic\ndifferential equations (SDEs) as well as non-variational integral expressions\nfor likelihood formulas. A score-matching analysis derives the reverse\ndiffusion ordinary differential equation (ODE) and a family of\nreverse-diffusion SDEs parameterized by noise level. The paper presents the\nmathematics directly with attributions saved for a final section.\n","authors":["David McAllester"],"pdf_url":"https://arxiv.org/pdf/2301.11108v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14730v2","updated":"2023-03-05T22:11:56Z","published":"2022-11-27T05:15:42Z","title":"A Time Series is Worth 64 Words: Long-term Forecasting with Transformers","summary":"  We propose an efficient design of Transformer-based models for multivariate\ntime series forecasting and self-supervised representation learning. It is\nbased on two key components: (i) segmentation of time series into\nsubseries-level patches which are served as input tokens to Transformer; (ii)\nchannel-independence where each channel contains a single univariate time\nseries that shares the same embedding and Transformer weights across all the\nseries. Patching design naturally has three-fold benefit: local semantic\ninformation is retained in the embedding; computation and memory usage of the\nattention maps are quadratically reduced given the same look-back window; and\nthe model can attend longer history. Our channel-independent patch time series\nTransformer (PatchTST) can improve the long-term forecasting accuracy\nsignificantly when compared with that of SOTA Transformer-based models. We also\napply our model to self-supervised pre-training tasks and attain excellent\nfine-tuning performance, which outperforms supervised training on large\ndatasets. Transferring of masked pre-trained representation on one dataset to\nothers also produces SOTA forecasting accuracy. Code is available at:\nhttps://github.com/yuqinie98/PatchTST.\n","authors":["Yuqi Nie","Nam H. Nguyen","Phanwadee Sinthong","Jayant Kalagnanam"],"pdf_url":"https://arxiv.org/pdf/2211.14730v2.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02783v1","updated":"2023-03-05T21:47:08Z","published":"2023-03-05T21:47:08Z","title":"Improved Sample Complexity Bounds for Distributionally Robust\n  Reinforcement Learning","summary":"  We consider the problem of learning a control policy that is robust against\nthe parameter mismatches between the training environment and testing\nenvironment. We formulate this as a distributionally robust reinforcement\nlearning (DR-RL) problem where the objective is to learn the policy which\nmaximizes the value function against the worst possible stochastic model of the\nenvironment in an uncertainty set. We focus on the tabular episodic learning\nsetting where the algorithm has access to a generative model of the nominal\n(training) environment around which the uncertainty set is defined. We propose\nthe Robust Phased Value Learning (RPVL) algorithm to solve this problem for the\nuncertainty sets specified by four different divergences: total variation,\nchi-square, Kullback-Leibler, and Wasserstein. We show that our algorithm\nachieves $\\tilde{\\mathcal{O}}(|\\mathcal{S}||\\mathcal{A}| H^{5})$ sample\ncomplexity, which is uniformly better than the existing results by a factor of\n$|\\mathcal{S}|$, where $|\\mathcal{S}|$ is number of states, $|\\mathcal{A}|$ is\nthe number of actions, and $H$ is the horizon length. We also provide the\nfirst-ever sample complexity result for the Wasserstein uncertainty set.\nFinally, we demonstrate the performance of our algorithm using simulation\nexperiments.\n","authors":["Zaiyan Xu","Kishan Panaganti","Dileep Kalathil"],"pdf_url":"https://arxiv.org/pdf/2303.02783v1.pdf","comment":"Appeared in The 26th (2023) International Conference on Artificial\n  Intelligence and Statistics (AISTATS)"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2303.02802v1","updated":"2023-03-05T23:41:00Z","published":"2023-03-05T23:41:00Z","title":"A Provably Secure Strong PUF based on LWE: Construction and\n  Implementation","summary":"  We construct a strong PUF with provable security against ML attacks on both\nclassical and quantum computers. The security is guaranteed by the\ncryptographic hardness of learning decryption functions of public-key\ncryptosystems, and the hardness of the learning-with-errors (LWE) problem\ndefined on integer lattices. We call our construction the lattice PUF.\n  We construct lattice PUF with a physically obfuscated key and an LWE\ndecryption function block. To allow deployments in different scenarios, we\ndemonstrate designs with different latency-area trade-offs. A compact design\nuses a highly serialized LFSR and LWE decryption function, while a\nlatency-optimized design uses an unrolled LFSR and a parallel datapath.\n  We prototype lattice PUF designs with $2^{136}$ challenge-response pairs\n(CRPs) on a Spartan 6 FPGA. In addition to theoretical security guarantee, we\nevaluate empirical resistance to the various leading ML techniques: the\nprediction error remains above $49.76\\%$ after $1$ million training CRPs. The\nresource-efficient design requires only $45$ slices for the PUF logic proper,\nand $351$ slices for a fuzzy extractor. The latency-optimized design achieves a\n$148X$ reduction in latency, at a $10X$ increase in PUF hardware utilization.\nThe mean uniformity of PUF responses is $49.98\\%$, the mean uniqueness is\n$50.00\\%$, and the mean reliability is $1.26\\%$.\n","authors":["Xiaodan Xi","Ge Li","Ye Wang","Yeonsoo Jeon","Michael Orshansky"],"pdf_url":"https://arxiv.org/pdf/2303.02802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02801v1","updated":"2023-03-05T23:38:44Z","published":"2023-03-05T23:38:44Z","title":"Neuroevolutionary algorithms driven by neuron coverage metrics for\n  semi-supervised classification","summary":"  In some machine learning applications the availability of labeled instances\nfor supervised classification is limited while unlabeled instances are\nabundant. Semi-supervised learning algorithms deal with these scenarios and\nattempt to exploit the information contained in the unlabeled examples. In this\npaper, we address the question of how to evolve neural networks for\nsemi-supervised problems. We introduce neuroevolutionary approaches that\nexploit unlabeled instances by using neuron coverage metrics computed on the\nneural network architecture encoded by each candidate solution. Neuron coverage\nmetrics resemble code coverage metrics used to test software, but are oriented\nto quantify how the different neural network components are covered by test\ninstances. In our neuroevolutionary approach, we define fitness functions that\ncombine classification accuracy computed on labeled examples and neuron\ncoverage metrics evaluated using unlabeled examples. We assess the impact of\nthese functions on semi-supervised problems with a varying amount of labeled\ninstances. Our results show that the use of neuron coverage metrics helps\nneuroevolution to become less sensitive to the scarcity of labeled data, and\ncan lead in some cases to a more robust generalization of the learned\nclassifiers.\n","authors":["Roberto Santana","Ivan Hidalgo-Cenalmor","Unai Garciarena","Alexander Mendiburu","Jose Antonio Lozano"],"pdf_url":"https://arxiv.org/pdf/2303.02801v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09908v2","updated":"2023-03-05T23:10:24Z","published":"2023-02-20T11:09:37Z","title":"A Sidecar Separator Can Convert a Single-Talker Speech Recognition\n  System to a Multi-Talker One","summary":"  Although automatic speech recognition (ASR) can perform well in common\nnon-overlapping environments, sustaining performance in multi-talker\noverlapping speech recognition remains challenging. Recent research revealed\nthat ASR model's encoder captures different levels of information with\ndifferent layers -- the lower layers tend to have more acoustic information,\nand the upper layers more linguistic. This inspires us to develop a Sidecar\nseparator to empower a well-trained ASR model for multi-talker scenarios by\nseparating the mixed speech embedding between two suitable layers. We\nexperimented with a wav2vec 2.0-based ASR model with a Sidecar mounted. By\nfreezing the parameters of the original model and training only the Sidecar\n(8.7 M, 8.4% of all parameters), the proposed approach outperforms the previous\nstate-of-the-art by a large margin for the 2-speaker mixed LibriMix dataset,\nreaching a word error rate (WER) of 10.36%; and obtains comparable results\n(7.56%) for LibriSpeechMix dataset when limited training.\n","authors":["Lingwei Meng","Jiawen Kang","Mingyu Cui","Yuejiao Wang","Xixin Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2302.09908v2.pdf","comment":"Accepted by IEEE International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), 2023"},{"id":"http://arxiv.org/abs/2303.02794v1","updated":"2023-03-05T23:01:02Z","published":"2023-03-05T23:01:02Z","title":"CoRTX: Contrastive Framework for Real-time Explanation","summary":"  Recent advancements in explainable machine learning provide effective and\nfaithful solutions for interpreting model behaviors. However, many explanation\nmethods encounter efficiency issues, which largely limit their deployments in\npractical scenarios. Real-time explainer (RTX) frameworks have thus been\nproposed to accelerate the model explanation process by learning a\none-feed-forward explainer. Existing RTX frameworks typically build the\nexplainer under the supervised learning paradigm, which requires large amounts\nof explanation labels as the ground truth. Considering that accurate\nexplanation labels are usually hard to obtain due to constrained computational\nresources and limited human efforts, effective explainer training is still\nchallenging in practice. In this work, we propose a COntrastive Real-Time\neXplanation (CoRTX) framework to learn the explanation-oriented representation\nand relieve the intensive dependence of explainer training on explanation\nlabels. Specifically, we design a synthetic strategy to select positive and\nnegative instances for the learning of explanation. Theoretical analysis show\nthat our selection strategy can benefit the contrastive learning process on\nexplanation tasks. Experimental results on three real-world datasets further\ndemonstrate the efficiency and efficacy of our proposed CoRTX framework.\n","authors":["Yu-Neng Chuang","Guanchu Wang","Fan Yang","Quan Zhou","Pushkar Tripathi","Xuanting Cai","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2303.02794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11108v3","updated":"2023-03-05T22:30:18Z","published":"2023-01-25T16:39:00Z","title":"On the Mathematics of Diffusion Models","summary":"  This paper gives direct derivations of the differential equations and\nlikelihood formulas of diffusion models assuming only knowledge of Gaussian\ndistributions. A VAE analysis derives both forward and backward stochastic\ndifferential equations (SDEs) as well as non-variational integral expressions\nfor likelihood formulas. A score-matching analysis derives the reverse\ndiffusion ordinary differential equation (ODE) and a family of\nreverse-diffusion SDEs parameterized by noise level. The paper presents the\nmathematics directly with attributions saved for a final section.\n","authors":["David McAllester"],"pdf_url":"https://arxiv.org/pdf/2301.11108v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14730v2","updated":"2023-03-05T22:11:56Z","published":"2022-11-27T05:15:42Z","title":"A Time Series is Worth 64 Words: Long-term Forecasting with Transformers","summary":"  We propose an efficient design of Transformer-based models for multivariate\ntime series forecasting and self-supervised representation learning. It is\nbased on two key components: (i) segmentation of time series into\nsubseries-level patches which are served as input tokens to Transformer; (ii)\nchannel-independence where each channel contains a single univariate time\nseries that shares the same embedding and Transformer weights across all the\nseries. Patching design naturally has three-fold benefit: local semantic\ninformation is retained in the embedding; computation and memory usage of the\nattention maps are quadratically reduced given the same look-back window; and\nthe model can attend longer history. Our channel-independent patch time series\nTransformer (PatchTST) can improve the long-term forecasting accuracy\nsignificantly when compared with that of SOTA Transformer-based models. We also\napply our model to self-supervised pre-training tasks and attain excellent\nfine-tuning performance, which outperforms supervised training on large\ndatasets. Transferring of masked pre-trained representation on one dataset to\nothers also produces SOTA forecasting accuracy. Code is available at:\nhttps://github.com/yuqinie98/PatchTST.\n","authors":["Yuqi Nie","Nam H. Nguyen","Phanwadee Sinthong","Jayant Kalagnanam"],"pdf_url":"https://arxiv.org/pdf/2211.14730v2.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02783v1","updated":"2023-03-05T21:47:08Z","published":"2023-03-05T21:47:08Z","title":"Improved Sample Complexity Bounds for Distributionally Robust\n  Reinforcement Learning","summary":"  We consider the problem of learning a control policy that is robust against\nthe parameter mismatches between the training environment and testing\nenvironment. We formulate this as a distributionally robust reinforcement\nlearning (DR-RL) problem where the objective is to learn the policy which\nmaximizes the value function against the worst possible stochastic model of the\nenvironment in an uncertainty set. We focus on the tabular episodic learning\nsetting where the algorithm has access to a generative model of the nominal\n(training) environment around which the uncertainty set is defined. We propose\nthe Robust Phased Value Learning (RPVL) algorithm to solve this problem for the\nuncertainty sets specified by four different divergences: total variation,\nchi-square, Kullback-Leibler, and Wasserstein. We show that our algorithm\nachieves $\\tilde{\\mathcal{O}}(|\\mathcal{S}||\\mathcal{A}| H^{5})$ sample\ncomplexity, which is uniformly better than the existing results by a factor of\n$|\\mathcal{S}|$, where $|\\mathcal{S}|$ is number of states, $|\\mathcal{A}|$ is\nthe number of actions, and $H$ is the horizon length. We also provide the\nfirst-ever sample complexity result for the Wasserstein uncertainty set.\nFinally, we demonstrate the performance of our algorithm using simulation\nexperiments.\n","authors":["Zaiyan Xu","Kishan Panaganti","Dileep Kalathil"],"pdf_url":"https://arxiv.org/pdf/2303.02783v1.pdf","comment":"Appeared in The 26th (2023) International Conference on Artificial\n  Intelligence and Statistics (AISTATS)"},{"id":"http://arxiv.org/abs/2303.02781v1","updated":"2023-03-05T21:41:16Z","published":"2023-03-05T21:41:16Z","title":"Robustness, Evaluation and Adaptation of Machine Learning Models in the\n  Wild","summary":"  Our goal is to improve reliability of Machine Learning (ML) systems deployed\nin the wild. ML models perform exceedingly well when test examples are similar\nto train examples. However, real-world applications are required to perform on\nany distribution of test examples. Current ML systems can fail silently on test\nexamples with distribution shifts. In order to improve reliability of ML models\ndue to covariate or domain shift, we propose algorithms that enable models to:\n(a) generalize to a larger family of test distributions, (b) evaluate accuracy\nunder distribution shifts, (c) adapt to a target distribution. We study causes\nof impaired robustness to domain shifts and present algorithms for training\ndomain robust models. A key source of model brittleness is due to domain\noverfitting, which our new training algorithms suppress and instead encourage\ndomain-general hypotheses. While we improve robustness over standard training\nmethods for certain problem settings, performance of ML systems can still vary\ndrastically with domain shifts. It is crucial for developers and stakeholders\nto understand model vulnerabilities and operational ranges of input, which\ncould be assessed on the fly during the deployment, albeit at a great cost.\nInstead, we advocate for proactively estimating accuracy surfaces over any\ncombination of prespecified and interpretable domain shifts for performance\nforecasting. We present a label-efficient estimation to address estimation over\na combinatorial space of domain shifts. Further, when a model's performance on\na target domain is found to be poor, traditional approaches adapt the model\nusing the target domain's resources. Standard adaptation methods assume access\nto sufficient labeled resources, which may be impractical for deployed models.\nWe initiate a study of lightweight adaptation techniques with only unlabeled\ndata resources with a focus on language applications.\n","authors":["Vihari Piratla"],"pdf_url":"https://arxiv.org/pdf/2303.02781v1.pdf","comment":"PhD Thesis; 191 pages; Dept of Computer Science, IIT Bombay"},{"id":"http://arxiv.org/abs/2110.03375v2","updated":"2023-03-05T21:26:23Z","published":"2021-10-07T12:13:19Z","title":"Learning Pessimism for Robust and Efficient Off-Policy Reinforcement\n  Learning","summary":"  Off-policy deep reinforcement learning algorithms commonly compensate for\noverestimation bias during temporal-difference learning by utilizing\npessimistic estimates of the expected target returns. In this work, we propose\nGeneralized Pessimism Learning (GPL), a strategy employing a novel learnable\npenalty to enact such pessimism. In particular, we propose to learn this\npenalty alongside the critic with dual TD-learning, a new procedure to estimate\nand minimize the magnitude of the target returns bias with trivial\ncomputational cost. GPL enables us to accurately counteract overestimation bias\nthroughout training without incurring the downsides of overly pessimistic\ntargets. By integrating GPL with popular off-policy algorithms, we achieve\nstate-of-the-art results in both competitive proprioceptive and pixel-based\nbenchmarks.\n","authors":["Edoardo Cetin","Oya Celiktutan"],"pdf_url":"https://arxiv.org/pdf/2110.03375v2.pdf","comment":"Oral at the 37th AAAI Conference on Artificial Intelligence (AAAI-23)"},{"id":"http://arxiv.org/abs/2208.10469v2","updated":"2023-03-05T21:21:58Z","published":"2022-08-22T17:42:03Z","title":"Get It in Writing: Formal Contracts Mitigate Social Dilemmas in\n  Multi-Agent RL","summary":"  Multi-agent reinforcement learning (MARL) is a powerful tool for training\nautomated systems acting independently in a common environment. However, it can\nlead to sub-optimal behavior when individual incentives and group incentives\ndiverge. Humans are remarkably capable at solving these social dilemmas. It is\nan open problem in MARL to replicate such cooperative behaviors in selfish\nagents. In this work, we draw upon the idea of formal contracting from\neconomics to overcome diverging incentives between agents in MARL. We propose\nan augmentation to a Markov game where agents voluntarily agree to binding\nstate-dependent transfers of reward, under pre-specified conditions. Our\ncontributions are theoretical and empirical. First, we show that this\naugmentation makes all subgame-perfect equilibria of all fully observed Markov\ngames exhibit socially optimal behavior, given a sufficiently rich space of\ncontracts. Next, we complement our game-theoretic analysis by showing that\nstate-of-the-art RL algorithms learn socially optimal policies given our\naugmentation. Our experiments include classic static dilemmas like Stag Hunt,\nPrisoner's Dilemma and a public goods game, as well as dynamic interactions\nthat simulate traffic, pollution management and common pool resource\nmanagement.\n","authors":["Phillip J. K. Christoffersen","Andreas A. Haupt","Dylan Hadfield-Menell"],"pdf_url":"https://arxiv.org/pdf/2208.10469v2.pdf","comment":"12 pages, 8 figures, AAMAS 2023"},{"id":"http://arxiv.org/abs/2302.05449v3","updated":"2023-03-05T21:05:09Z","published":"2023-02-13T14:42:15Z","title":"Heckerthoughts","summary":"  This manuscript is technical memoir about my work at Stanford and Microsoft\nResearch. Included are fundamental concepts central to machine learning and\nartificial intelligence, applications of these concepts, and stories behind\ntheir creation.\n","authors":["David Heckerman"],"pdf_url":"https://arxiv.org/pdf/2302.05449v3.pdf","comment":"Updated causality discussion"},{"id":"http://arxiv.org/abs/2212.13020v2","updated":"2023-03-05T20:38:01Z","published":"2022-12-26T06:19:49Z","title":"Detection and Tracking of Low Observable Objects in a Sequence of Image\n  Frames Using Particle Filter","summary":"  A track-before-detect (TBD) particle filter-based method for detection and\ntracking of low observable maneuvering objects based on a sequence of image\nframes in the presence of noise and clutter is briefly studied in this short\nletter. At each time instance after receiving a frame of image, first, some\npreprocessing approaches are applied to the image. Then, it is sent to the\ndetection and tracking algorithm which is based on a particle filter.\nPerformance of the approach is evaluated for detection and tracking of an\nobject in different scenarios including noise and clutter.\n","authors":["Reza Rezaie"],"pdf_url":"https://arxiv.org/pdf/2212.13020v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.03333v3","updated":"2023-03-05T19:44:47Z","published":"2022-07-06T05:57:24Z","title":"FewSOL: A Dataset for Few-Shot Object Learning in Robotic Environments","summary":"  We introduce the Few-Shot Object Learning (FewSOL) dataset for object\nrecognition with a few images per object. We captured 336 real-world objects\nwith 9 RGB-D images per object from different views. Object segmentation masks,\nobject poses and object attributes are provided. In addition, synthetic images\ngenerated using 330 3D object models are used to augment the dataset. We\ninvestigated (i) few-shot object classification and (ii) joint object\nsegmentation and few-shot classification with the state-of-the-art methods for\nfew-shot learning and meta-learning using our dataset. The evaluation results\nshow that there is still a large margin to be improved for few-shot object\nclassification in robotic environments. Our dataset can be used to study a set\nof few-shot object recognition problems such as classification, detection and\nsegmentation, shape reconstruction, pose estimation, keypoint correspondences\nand attribute recognition. The dataset and code are available at\nhttps://irvlutd.github.io/FewSOL.\n","authors":["Jishnu Jaykumar P","Yu-Wei Chao","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2207.03333v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02753v1","updated":"2023-03-05T19:20:55Z","published":"2023-03-05T19:20:55Z","title":"Frequency-domain Blind Quality Assessment of Blurred and\n  Blocking-artefact Images using Gaussian Process Regression model","summary":"  Most of the standard image and video codecs are block-based and depending\nupon the compression ratio the compressed images/videos suffer from different\ndistortions. At low ratios, blurriness is observed and as compression increases\nblocking artifacts occur. Generally, in order to reduce blockiness, images are\nlow-pass filtered which leads to more blurriness. Also, in bokeh mode images\nthey are commonly seen: blurriness as a result of intentional blurred\nbackground while blocking artifact and global blurriness arising due to\ncompression. Therefore, such visual media suffer from both blockiness and\nblurriness distortions. Along with this, noise is also commonly encountered\ndistortion. Most of the existing works on quality assessment quantify these\ndistortions individually. This paper proposes a methodology to blindly measure\noverall quality of an image suffering from these distortions, individually as\nwell as jointly. This is achieved by considering the sum of absolute values of\nlow and high-frequency Discrete Frequency Transform (DFT) coefficients defined\nas sum magnitudes. The number of blocks lying in specific ranges of sum\nmagnitudes including zero-valued AC coefficients and mean of 100 maximum and\n100 minimum values of these sum magnitudes are used as feature vectors. These\nfeatures are then fed to the Machine Learning (ML) based Gaussian Process\nRegression (GPR) model, which quantifies the image quality. The simulation\nresults show that the proposed method can estimate the quality of images\ndistorted with the blockiness, blurriness, noise and their combinations. It is\nrelatively fast compared to many state-of-art methods, and therefore is\nsuitable for real-time quality monitoring applications.\n","authors":["Maryam Viqar","Athar A. Moinuddin","Ekram Khan","M. Ghanbari"],"pdf_url":"https://arxiv.org/pdf/2303.02753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01382v3","updated":"2023-03-05T18:43:10Z","published":"2022-11-30T01:40:59Z","title":"Welfare and Fairness in Multi-objective Reinforcement Learning","summary":"  We study fair multi-objective reinforcement learning in which an agent must\nlearn a policy that simultaneously achieves high reward on multiple dimensions\nof a vector-valued reward. Motivated by the fair resource allocation\nliterature, we model this as an expected welfare maximization problem, for some\nnon-linear fair welfare function of the vector of long-term cumulative rewards.\nOne canonical example of such a function is the Nash Social Welfare, or\ngeometric mean, the log transform of which is also known as the Proportional\nFairness objective. We show that even approximately optimal optimization of the\nexpected Nash Social Welfare is computationally intractable even in the tabular\ncase. Nevertheless, we provide a novel adaptation of Q-learning that combines\nnon-linear scalarized learning updates and non-stationary action selection to\nlearn effective policies for optimizing nonlinear welfare functions. We show\nthat our algorithm is provably convergent, and we demonstrate experimentally\nthat our approach outperforms techniques based on linear scalarization,\nmixtures of optimal linear scalarizations, or stationary action selection for\nthe Nash Social Welfare Objective.\n","authors":["Zimeng Fan","Nianli Peng","Muhang Tian","Brandon Fain"],"pdf_url":"https://arxiv.org/pdf/2212.01382v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02735v1","updated":"2023-03-05T18:02:54Z","published":"2023-03-05T18:02:54Z","title":"Scalable Object Detection on Embedded Devices Using Weight Pruning and\n  Singular Value Decomposition","summary":"  This paper presents a method for optimizing object detection models by\ncombining weight pruning and singular value decomposition (SVD). The proposed\nmethod was evaluated on a custom dataset of street work images obtained from\nhttps://universe.roboflow.com/roboflow-100/street-work. The dataset consists of\n611 training images, 175 validation images, and 87 test images with 7 classes.\nWe compared the performance of the optimized models with the original\nunoptimized model in terms of frame rate, mean average precision (mAP@50), and\nweight size. The results show that the weight pruning + SVD model achieved a\n0.724 mAP@50 with a frame rate of 1.48 FPS and a weight size of 12.1 MB,\noutperforming the original model (0.717 mAP@50, 1.50 FPS, and 12.3 MB).\nPrecision-recall curves were also plotted for all models. Our work demonstrates\nthat the proposed method can effectively optimize object detection models while\nbalancing accuracy, speed, and model size.\n","authors":["Dohyun Ham","Jaeyeop Jeong","June-Kyoo Park","Raehyeon Jeong","Seungmin Jeon","Hyeongjun Jeon","Yewon Lim"],"pdf_url":"https://arxiv.org/pdf/2303.02735v1.pdf","comment":"8 pages, 3 figures. A report of the project done as part of the\n  Yonsei-Roboin project for the 2nd semester, 2022"},{"id":"http://arxiv.org/abs/2303.02733v1","updated":"2023-03-05T17:57:33Z","published":"2023-03-05T17:57:33Z","title":"Reparameterization through Spatial Gradient Scaling","summary":"  Reparameterization aims to improve the generalization of deep neural networks\nby transforming convolutional layers into equivalent multi-branched structures\nduring training. However, there exists a gap in understanding how\nreparameterization may change and benefit the learning process of neural\nnetworks. In this paper, we present a novel spatial gradient scaling method to\nredistribute learning focus among weights in convolutional networks. We prove\nthat spatial gradient scaling achieves the same learning dynamics as a branched\nreparameterization yet without introducing structural changes into the network.\nWe further propose an analytical approach that dynamically learns scalings for\neach convolutional layer based on the spatial characteristics of its input\nfeature map gauged by mutual information. Experiments on CIFAR-10, CIFAR-100,\nand ImageNet show that without searching for reparameterized structures, our\nproposed scaling method outperforms the state-of-the-art reparameterization\nstrategies at a lower computational cost.\n","authors":["Alexander Detkov","Mohammad Salameh","Muhammad Fetrat Qharabagh","Jialin Zhang","Wei Lui","Shangling Jui","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2303.02733v1.pdf","comment":"Published at ICLR 2023. Code available\n  $\\href{https://github.com/Ascend-Research/Reparameterization}{here}$"},{"id":"http://arxiv.org/abs/2303.02731v1","updated":"2023-03-05T17:55:15Z","published":"2023-03-05T17:55:15Z","title":"Vision based Virtual Guidance for Navigation","summary":"  This paper explores the impact of virtual guidance on mid-level\nrepresentation-based navigation, where an agent performs navigation tasks based\nsolely on visual observations. Instead of providing distance measures or\nnumerical directions to guide the agent, which may be difficult for it to\ninterpret visually, the paper investigates the potential of different forms of\nvirtual guidance schemes on navigation performance. Three schemes of virtual\nguidance signals are explored: virtual navigation path, virtual waypoints, and\na combination of both. The experiments were conducted using a virtual city\nbuilt with the Unity engine to train the agents while avoiding obstacles. The\nresults show that virtual guidance provides the agent with more meaningful\nnavigation information and achieves better performance in terms of path\ncompletion rates and navigation efficiency. In addition, a set of analyses were\nprovided to investigate the failure cases and the navigated trajectories, and a\npilot study was conducted for the real-world scenarios.\n","authors":["Hsuan-Kung Yang","Yu-Ying Chen","Tsung-Chih Chiang","Chia-Chuan Hsu","Chun-Chia Huang","Chun-Wei Huang","Jou-Min Liu","Ting-Ru Liu","Tsu-Ching Hsiao","Chun-Yi Lee"],"pdf_url":"https://arxiv.org/pdf/2303.02731v1.pdf","comment":"Yu-Ying Chen, Tsung-Chih Chiang, Chia-Chuan Hsu, Chun-Chia Huang,\n  Chun-Wei Huang, Jou-Min Liu, and Ting-Ru Liu contributed equally to this\n  work, names listed in alphabetical order; This work has been submitted to the\n  IEEE for possible publication"},{"id":"http://arxiv.org/abs/2301.04819v2","updated":"2023-03-05T17:29:00Z","published":"2023-01-12T05:28:59Z","title":"Data-centric AI: Perspectives and Challenges","summary":"  The role of data in building AI systems has recently been significantly\nmagnified by the emerging concept of data-centric AI (DCAI), which advocates a\nfundamental shift from model advancements to ensuring data quality and\nreliability. Although our community has continuously invested efforts into\nenhancing data in different aspects, they are often isolated initiatives on\nspecific tasks. To facilitate the collective initiative in our community and\npush forward DCAI, we draw a big picture and bring together three general\nmissions: training data development, evaluation data development, and data\nmaintenance. We provide a top-level discussion on representative DCAI tasks and\nshare perspectives. Finally, we list open challenges to motivate future\nexploration.\n","authors":["Daochen Zha","Zaid Pervaiz Bhat","Kwei-Herng Lai","Fan Yang","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2301.04819v2.pdf","comment":"Accepted by SDM 2023 Blue Sky Track"},{"id":"http://arxiv.org/abs/2209.08466v2","updated":"2023-03-05T15:57:52Z","published":"2022-09-18T03:51:58Z","title":"Simplifying Model-based RL: Learning Representations, Latent-space\n  Models, and Policies with One Objective","summary":"  While reinforcement learning (RL) methods that learn an internal model of the\nenvironment have the potential to be more sample efficient than their\nmodel-free counterparts, learning to model raw observations from high\ndimensional sensors can be challenging. Prior work has addressed this challenge\nby learning low-dimensional representation of observations through auxiliary\nobjectives, such as reconstruction or value prediction. However, the alignment\nbetween these auxiliary objectives and the RL objective is often unclear. In\nthis work, we propose a single objective which jointly optimizes a latent-space\nmodel and policy to achieve high returns while remaining self-consistent. This\nobjective is a lower bound on expected returns. Unlike prior bounds for\nmodel-based RL on policy exploration or model guarantees, our bound is directly\non the overall RL objective. We demonstrate that the resulting algorithm\nmatches or improves the sample-efficiency of the best prior model-based and\nmodel-free RL methods. While sample efficient methods typically are\ncomputationally demanding, our method attains the performance of SAC in about\n50% less wall-clock time.\n","authors":["Raj Ghugare","Homanga Bharadhwaj","Benjamin Eysenbach","Sergey Levine","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2209.08466v2.pdf","comment":"ICLR 2023, Project website with code:\n  https://alignedlatentmodels.github.io/"},{"id":"http://arxiv.org/abs/2303.02677v1","updated":"2023-03-05T14:25:05Z","published":"2023-03-05T14:25:05Z","title":"Mining both Commonality and Specificity from Multiple Documents for\n  Multi-Document Summarization","summary":"  The multi-document summarization task requires the designed summarizer to\ngenerate a short text that covers the important information of original\ndocuments and satisfies content diversity. This paper proposes a multi-document\nsummarization approach based on hierarchical clustering of documents. It\nutilizes the constructed class tree of documents to extract both the sentences\nreflecting the commonality of all documents and the sentences reflecting the\nspecificity of some subclasses of these documents for generating a summary, so\nas to satisfy the coverage and diversity requirements of multi-document\nsummarization. Comparative experiments with different variant approaches on\nDUC'2002-2004 datasets prove the effectiveness of mining both the commonality\nand specificity of documents for multi-document summarization. Experiments on\nDUC'2004 and Multi-News datasets show that our approach achieves competitive\nperformance compared to the state-of-the-art unsupervised and supervised\napproaches.\n","authors":["Bing Ma"],"pdf_url":"https://arxiv.org/pdf/2303.02677v1.pdf","comment":"10 pages, 1 figure"},{"id":"http://arxiv.org/abs/2303.02668v1","updated":"2023-03-05T13:19:10Z","published":"2023-03-05T13:19:10Z","title":"Knowledge-Enhanced Semi-Supervised Federated Learning for Aggregating\n  Heterogeneous Lightweight Clients in IoT","summary":"  Federated learning (FL) enables multiple clients to train models\ncollaboratively without sharing local data, which has achieved promising\nresults in different areas, including the Internet of Things (IoT). However,\nend IoT devices do not have abilities to automatically annotate their collected\ndata, which leads to the label shortage issue at the client side. To\ncollaboratively train an FL model, we can only use a small number of labeled\ndata stored on the server. This is a new yet practical scenario in federated\nlearning, i.e., labels-at-server semi-supervised federated learning (SemiFL).\nAlthough several SemiFL approaches have been proposed recently, none of them\ncan focus on the personalization issue in their model design. IoT environments\nmake SemiFL more challenging, as we need to take device computational\nconstraints and communication cost into consideration simultaneously. To tackle\nthese new challenges together, we propose a novel SemiFL framework named\npFedKnow. pFedKnow generates lightweight personalized client models via neural\nnetwork pruning techniques to reduce communication cost. Moreover, it\nincorporates pretrained large models as prior knowledge to guide the\naggregation of personalized client models and further enhance the framework\nperformance. Experiment results on both image and text datasets show that the\nproposed pFedKnow outperforms state-of-the-art baselines as well as reducing\nconsiderable communication cost. The source code of the proposed pFedKnow is\navailable at https://github.com/JackqqWang/pfedknow/tree/master.\n","authors":["Jiaqi Wang","Shenglai Zeng","Zewei Long","Yaqing Wang","Houping Xiao","Fenglong Ma"],"pdf_url":"https://arxiv.org/pdf/2303.02668v1.pdf","comment":"This paper is acceptted by SDM-2023. Jiaqi Wang and Shenglai Zeng are\n  of equal contribution"},{"id":"http://arxiv.org/abs/2303.02664v1","updated":"2023-03-05T13:05:26Z","published":"2023-03-05T13:05:26Z","title":"A Formal Metareasoning Model of Concurrent Planning and Execution","summary":"  Agents that plan and act in the real world must deal with the fact that time\npasses as they are planning. When timing is tight, there may be insufficient\ntime to complete the search for a plan before it is time to act. By commencing\nexecution before search concludes, one gains time to search by making planning\nand execution concurrent. However, this incurs the risk of making incorrect\naction choices, especially if actions are irreversible. This tradeoff between\nopportunity and risk is the problem addressed in this paper. Our main\ncontribution is to formally define this setting as an abstract metareasoning\nproblem. We find that the abstract problem is intractable. However, we identify\nspecial cases that are solvable in polynomial time, develop greedy solution\nalgorithms, and, through tests on instances derived from search problems, find\nseveral methods that achieve promising practical performance. This work lays\nthe foundation for a principled time-aware executive that concurrently plans\nand executes.\n","authors":["Amihay Elboher","Ava Bensoussan","Erez Karpas","Wheeler Ruml","Shahaf S. Shperberg","Solomon E. Shimony"],"pdf_url":"https://arxiv.org/pdf/2303.02664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.10368v3","updated":"2023-03-05T12:26:16Z","published":"2022-09-21T14:03:08Z","title":"Improving the Safety of 3D Object Detectors in Autonomous Driving using\n  IoGT and Distance Measures","summary":"  State-of-the-art object detectors are commonly evaluated based on accuracy\nmetrics such as mean Average Precision (mAP). In this paper, inspired by the\nfact that mAP is not a direct safety indicator, we propose a straightforward\nsafety metric, especially for 3D object detectors in Autonomous Driving\ncontexts, by combining the Intersection-over-Ground-Truth (IoGT) measure and a\ndistance ratio. Subsequently, we formulate a safety-aware loss function by\namending IoGT to commonly used accuracy-oriented loss functions. Our\nexperiments using models from the MMDetection3D library, the nuScenes dataset,\nand an in-house simulation dataset demonstrate that the object detector trained\nwith our loss function significantly reduces unsafe predictions while staying\nperformant on accuracy and maintaining good stability in the learning process.\n","authors":["Hsuan-Cheng Liao","Chih-Hong Cheng","Hasan Esen","Alois Knoll"],"pdf_url":"https://arxiv.org/pdf/2209.10368v3.pdf","comment":"8 pages (IEEE double column format), 8 figures, revised with clearer\n  presentation and resubmitted to IROS 2023"},{"id":"http://arxiv.org/abs/2303.02657v1","updated":"2023-03-05T12:25:49Z","published":"2023-03-05T12:25:49Z","title":"Sparsity-Aware Intelligent Massive Random Access Control in Open RAN: A\n  Reinforcement Learning Based Approach","summary":"  Massive random access of devices in the emerging Open Radio Access Network\n(O-RAN) brings great challenge to the access control and management. Exploiting\nthe bursting nature of the access requests, sparse active user detection (SAUD)\nis an efficient enabler towards efficient access management, but the sparsity\nmight be deteriorated in case of uncoordinated massive access requests. To\ndynamically preserve the sparsity of access requests, a reinforcement-learning\n(RL)-assisted scheme of closed-loop access control utilizing the access class\nbarring technique is proposed, where the RL policy is determined through\ncontinuous interaction between the RL agent, i.e., a next generation node base\n(gNB), and the environment. The proposed scheme can be implemented by the\nnear-real-time RAN intelligent controller (near-RT RIC) in O-RAN, supporting\nrapid switching between heterogeneous vertical applications, such as mMTC and\nuRLLC services. Moreover, a data-driven scheme of deep-RL-assisted SAUD is\nproposed to resolve highly complex environments with continuous and\nhigh-dimensional state and action spaces, where a replay buffer is applied for\nautomatic large-scale data collection. An actor-critic framework is formulated\nto incorporate the strategy-learning modules into the near-RT RIC. Simulation\nresults show that the proposed schemes can achieve superior performance in both\naccess efficiency and user detection accuracy over the benchmark scheme for\ndifferent heterogeneous services with massive access requests.\n","authors":["Xiao Tang","Sicong Liu","Xiaojiang Du","Mohsen Guizani"],"pdf_url":"https://arxiv.org/pdf/2303.02657v1.pdf","comment":"This paper has been submitted to IEEE Journal on Selected Areas in\n  Communications"},{"id":"http://arxiv.org/abs/2202.11954v2","updated":"2023-03-05T12:18:20Z","published":"2022-02-24T08:18:25Z","title":"XAutoML: A Visual Analytics Tool for Understanding and Validating\n  Automated Machine Learning","summary":"  In the last ten years, various automated machine learning (AutoM ) systems\nhave been proposed to build end-to-end machine learning (ML) pipelines with\nminimal human interaction. Even though such automatically synthesized ML\npipelines are able to achieve a competitive performance, recent studies have\nshown that users do not trust models constructed by AutoML due to missing\ntransparency of AutoML systems and missing explanations for the constructed ML\npipelines. In a requirements analysis study with 36 domain experts, data\nscientists, and AutoML researchers from different professions with vastly\ndifferent expertise in ML, we collect detailed informational needs for AutoML.\nWe propose XAutoML, an interactive visual analytics tool for explaining\narbitrary AutoML optimization procedures and ML pipelines constructed by\nAutoML. XAutoML combines interactive visualizations with established techniques\nfrom explainable artificial intelligence (XAI) to make the complete AutoML\nprocedure transparent and explainable. By integrating XAutoML with JupyterLab,\nexperienced users can extend the visual analytics with ad-hoc visualizations\nbased on information extracted from XAutoML. We validate our approach in a user\nstudy with the same diverse user group from the requirements analysis. All\nparticipants were able to extract useful information from XAutoML, leading to a\nsignificantly increased understanding of ML pipelines produced by AutoML and\nthe AutoML optimization itself.\n","authors":["Marc-André Zöller","Waldemar Titov","Thomas Schlegel","Marco F. Huber"],"pdf_url":"https://arxiv.org/pdf/2202.11954v2.pdf","comment":"Revised version submitted after review to ACM TiiS Special Issue on\n  Human-centered Explainable AI"},{"id":"http://arxiv.org/abs/2303.02655v1","updated":"2023-03-05T12:09:37Z","published":"2023-03-05T12:09:37Z","title":"On Modifying a Neural Network's Perception","summary":"  Artificial neural networks have proven to be extremely useful models that\nhave allowed for multiple recent breakthroughs in the field of Artificial\nIntelligence and many others. However, they are typically regarded as black\nboxes, given how difficult it is for humans to interpret how these models reach\ntheir results. In this work, we propose a method which allows one to modify\nwhat an artificial neural network is perceiving regarding specific\nhuman-defined concepts, enabling the generation of hypothetical scenarios that\ncould help understand and even debug the neural network model. Through\nempirical evaluation, in a synthetic dataset and in the ImageNet dataset, we\ntest the proposed method on different models, assessing whether the performed\nmanipulations are well interpreted by the models, and analyzing how they react\nto them.\n","authors":["Manuel de Sousa Ribeiro","João Leite"],"pdf_url":"https://arxiv.org/pdf/2303.02655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11466v2","updated":"2023-03-05T11:29:10Z","published":"2023-02-22T16:00:27Z","title":"Advancements in Federated Learning: Models, Methods, and Privacy","summary":"  Federated learning (FL) is a promising technique for addressing the rising\nprivacy and security issues. Its main ingredient is to cooperatively learn the\nmodel among the distributed clients without uploading any sensitive data. In\nthis paper, we conducted a thorough review of the related works, following the\ndevelopment context and deeply mining the key technologies behind FL from both\ntheoretical and practical perspectives. Specifically, we first classify the\nexisting works in FL architecture based on the network topology of FL systems\nwith detailed analysis and summarization. Next, we abstract the current\napplication problems, summarize the general techniques and frame the\napplication problems into the general paradigm of FL base models. Moreover, we\nprovide our proposed solutions for model training via FL. We have summarized\nand analyzed the existing FedOpt algorithms, and deeply revealed the\nalgorithmic development principles of many first-order algorithms in depth,\nproposing a more generalized algorithm design framework. Based on these\nframeworks, we have instantiated FedOpt algorithms. As privacy and security is\nthe fundamental requirement in FL, we provide the existing attack scenarios and\nthe defense methods. To the best of our knowledge, we are among the first tier\nto review the theoretical methodology and propose our strategies since there\nare very few works surveying the theoretical approaches. Our survey targets\nmotivating the development of high-performance, privacy-preserving, and secure\nmethods to integrate FL into real-world applications.\n","authors":["Huiming Chen","Huandong Wang","Qingyue Long","Depeng Jin","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2302.11466v2.pdf","comment":"35 pages, submitted to ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2303.02641v1","updated":"2023-03-05T11:06:20Z","published":"2023-03-05T11:06:20Z","title":"CueCAn: Cue Driven Contextual Attention For Identifying Missing Traffic\n  Signs on Unconstrained Roads","summary":"  Unconstrained Asian roads often involve poor infrastructure, affecting\noverall road safety. Missing traffic signs are a regular part of such roads.\nMissing or non-existing object detection has been studied for locating missing\ncurbs and estimating reasonable regions for pedestrians on road scene images.\nSuch methods involve analyzing task-specific single object cues. In this paper,\nwe present the first and most challenging video dataset for missing objects,\nwith multiple types of traffic signs for which the cues are visible without the\nsigns in the scenes. We refer to it as the Missing Traffic Signs Video Dataset\n(MTSVD). MTSVD is challenging compared to the previous works in two aspects i)\nThe traffic signs are generally not present in the vicinity of their cues, ii)\nThe traffic signs cues are diverse and unique. Also, MTSVD is the first\npublicly available missing object dataset. To train the models for identifying\nmissing signs, we complement our dataset with 10K traffic sign tracks, with 40\npercent of the traffic signs having cues visible in the scenes. For identifying\nmissing signs, we propose the Cue-driven Contextual Attention units (CueCAn),\nwhich we incorporate in our model encoder. We first train the encoder to\nclassify the presence of traffic sign cues and then train the entire\nsegmentation model end-to-end to localize missing traffic signs. Quantitative\nand qualitative analysis shows that CueCAn significantly improves the\nperformance of base models.\n","authors":["Varun Gupta","Anbumani Subramanian","C. V. Jawahar","Rohit Saluja"],"pdf_url":"https://arxiv.org/pdf/2303.02641v1.pdf","comment":"International Conference on Robotics and Automation (ICRA'23)"},{"id":"http://arxiv.org/abs/2302.07741v2","updated":"2023-03-05T10:59:54Z","published":"2023-02-15T15:39:28Z","title":"Prioritized offline Goal-swapping Experience Replay","summary":"  In goal-conditioned offline reinforcement learning, an agent learns from\npreviously collected data to go to an arbitrary goal. Since the offline data\nonly contains a finite number of trajectories, a main challenge is how to\ngenerate more data. Goal-swapping generates additional data by switching\ntrajectory goals but while doing so produces a large number of invalid\ntrajectories. To address this issue, we propose prioritized goal-swapping\nexperience replay (PGSER). PGSER uses a pre-trained Q function to assign higher\npriority weights to goal swapped transitions that allow reaching the goal. In\nexperiments, PGSER significantly improves over baselines in a wide range of\nbenchmark tasks, including challenging previously unsuccessful dexterous\nin-hand manipulation tasks.\n","authors":["Wenyan Yang","Joni Pajarinen","Dinging Cai","Joni Kämäräinen"],"pdf_url":"https://arxiv.org/pdf/2302.07741v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.08382v4","updated":"2023-03-05T09:35:06Z","published":"2022-03-16T04:10:45Z","title":"Dual Diffusion Implicit Bridges for Image-to-Image Translation","summary":"  Common image-to-image translation methods rely on joint training over data\nfrom both source and target domains. The training process requires concurrent\naccess to both datasets, which hinders data separation and privacy protection;\nand existing models cannot be easily adapted for translation of new domain\npairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation\nmethod based on diffusion models, that circumvents training on domain pairs.\nImage translation with DDIBs relies on two diffusion models trained\nindependently on each domain, and is a two-step process: DDIBs first obtain\nlatent encodings for source images with the source diffusion model, and then\ndecode such encodings using the target model to construct target images. Both\nsteps are defined via ordinary differential equations (ODEs), thus the process\nis cycle consistent only up to discretization errors of the ODE solvers.\nTheoretically, we interpret DDIBs as concatenation of source to latent, and\nlatent to target Schrodinger Bridges, a form of entropy-regularized optimal\ntransport, to explain the efficacy of the method. Experimentally, we apply\nDDIBs on synthetic and high-resolution image datasets, to demonstrate their\nutility in a wide variety of translation tasks and their inherent optimal\ntransport properties.\n","authors":["Xuan Su","Jiaming Song","Chenlin Meng","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2203.08382v4.pdf","comment":"18 pages, 12 figures, in the Eleventh International Conference on\n  Learning Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2303.02618v1","updated":"2023-03-05T09:26:44Z","published":"2023-03-05T09:26:44Z","title":"Ensemble Reinforcement Learning: A Survey","summary":"  Reinforcement learning (RL) has achieved state-of-the-art performance in many\nscientific and applied problems. However, some complex tasks still are\ndifficult to handle using a single model and algorithm. The highly popular\nensemble reinforcement learning (ERL) has become an important method to handle\ncomplex tasks with the advantage of combining reinforcement learning and\nensemble learning (EL). ERL combines several models or training algorithms to\nfully explore the problem space and has strong generalization characteristics.\nThis study presents a comprehensive survey on ERL to provide the readers with\nan overview of the recent advances and challenges. The background is introduced\nfirst. The strategies successfully applied in ERL are analyzed in detail.\nFinally, we outline some open questions and conclude by discussing some future\nresearch directions of ERL. This survey contributes to ERL development by\nproviding a guide for future scientific research and engineering applications.\n","authors":["Yanjie Song","P. N. Suganthan","Witold Pedrycz","Junwei Ou","Yongming He","Yingwu Chen"],"pdf_url":"https://arxiv.org/pdf/2303.02618v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2302.03669v2","updated":"2023-03-05T09:25:08Z","published":"2023-02-04T02:49:12Z","title":"Deep Reinforcement Learning for Traffic Light Control in Intelligent\n  Transportation Systems","summary":"  Smart traffic lights in intelligent transportation systems (ITSs) are\nenvisioned to greatly increase traffic efficiency and reduce congestion. Deep\nreinforcement learning (DRL) is a promising approach to adaptively control\ntraffic lights based on the real-time traffic situation in a road network.\nHowever, conventional methods may suffer from poor scalability. In this paper,\nwe investigate deep reinforcement learning to control traffic lights, and both\ntheoretical analysis and numerical experiments show that the intelligent\nbehavior ``greenwave\" (i.e., a vehicle will see a progressive cascade of green\nlights, and not have to brake at any intersection) emerges naturally a grid\nroad network, which is proved to be the optimal policy in an avenue with\nmultiple cross streets. As a first step, we use two DRL algorithms for the\ntraffic light control problems in two scenarios. In a single road intersection,\nwe verify that the deep Q-network (DQN) algorithm delivers a thresholding\npolicy; and in a grid road network, we adopt the deep deterministic policy\ngradient (DDPG) algorithm. Secondly, numerical experiments show that the DQN\nalgorithm delivers the optimal control, and the DDPG algorithm with passive\nobservations has the capability to produce on its own a high-level intelligent\nbehavior in a grid road network, namely, the ``greenwave\" policy emerges. We\nalso verify the ``greenwave\" patterns in a $5 \\times 10$ grid road network.\nThirdly, the ``greenwave\" patterns demonstrate that DRL algorithms produce\nfavorable solutions since the ``greenwave\" policy shown in experiment results\nis proved to be optimal in a specified traffic model (an avenue with multiple\ncross streets). The delivered policies both in a single road intersection and a\ngrid road network demonstrate the scalability of DRL algorithms.\n","authors":["Xiao-Yang Liu","Ming Zhu","Sem Borst","Anwar Walid"],"pdf_url":"https://arxiv.org/pdf/2302.03669v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2302.05907v3","updated":"2023-03-05T07:58:44Z","published":"2023-02-12T13:10:57Z","title":"LipLearner: Customizable Silent Speech Interactions on Mobile Devices","summary":"  Silent speech interface is a promising technology that enables private\ncommunications in natural language. However, previous approaches only support a\nsmall and inflexible vocabulary, which leads to limited expressiveness. We\nleverage contrastive learning to learn efficient lipreading representations,\nenabling few-shot command customization with minimal user effort. Our model\nexhibits high robustness to different lighting, posture, and gesture conditions\non an in-the-wild dataset. For 25-command classification, an F1-score of 0.8947\nis achievable only using one shot, and its performance can be further boosted\nby adaptively learning from more data. This generalizability allowed us to\ndevelop a mobile silent speech interface empowered with on-device fine-tuning\nand visual keyword spotting. A user study demonstrated that with LipLearner,\nusers could define their own commands with high reliability guaranteed by an\nonline incremental learning scheme. Subjective feedback indicated that our\nsystem provides essential functionalities for customizable silent speech\ninteractions with high usability and learnability.\n","authors":["Zixiong Su","Shitao Fang","Jun Rekimoto"],"pdf_url":"https://arxiv.org/pdf/2302.05907v3.pdf","comment":"Conditionally accepted to the ACM CHI Conference on Human Factors in\n  Computing Systems 2023 (CHI '23)"},{"id":"http://arxiv.org/abs/2303.02595v1","updated":"2023-03-05T07:37:28Z","published":"2023-03-05T07:37:28Z","title":"PyramidFlow: High-Resolution Defect Contrastive Localization using\n  Pyramid Normalizing Flow","summary":"  During industrial processing, unforeseen defects may arise in products due to\nuncontrollable factors. Although unsupervised methods have been successful in\ndefect localization, the usual use of pre-trained models results in\nlow-resolution outputs, which damages visual performance. To address this\nissue, we propose PyramidFlow, the first fully normalizing flow method without\npre-trained models that enables high-resolution defect localization.\nSpecifically, we propose a latent template-based defect contrastive\nlocalization paradigm to reduce intra-class variance, as the pre-trained models\ndo. In addition, PyramidFlow utilizes pyramid-like normalizing flows for\nmulti-scale fusing and volume normalization to help generalization. Our\ncomprehensive studies on MVTecAD demonstrate the proposed method outperforms\nthe comparable algorithms that do not use external priors, even achieving\nstate-of-the-art performance in more challenging BTAD scenarios.\n","authors":["Jiarui Lei","Xiaobo Hu","Yue Wang","Dong Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02595v1.pdf","comment":"Accepted to CVPR2023"},{"id":"http://arxiv.org/abs/2109.02823v3","updated":"2023-03-05T05:18:35Z","published":"2021-09-07T02:26:54Z","title":"Learning Visual-Audio Representations for Voice-Controlled Robots","summary":"  Based on the recent advancements in representation learning, we propose a\nnovel pipeline for task-oriented voice-controlled robots with raw sensor\ninputs. Previous methods rely on a large number of labels and task-specific\nreward functions. Not only can such an approach hardly be improved after the\ndeployment, but also has limited generalization across robotic platforms and\ntasks. To address these problems, our pipeline first learns a visual-audio\nrepresentation (VAR) that associates images and sound commands. Then the robot\nlearns to fulfill the sound command via reinforcement learning using the reward\ngenerated by the VAR. We demonstrate our approach with various sound types,\nrobots, and tasks. We show that our method outperforms previous work with much\nfewer labels. We show in both the simulated and real-world experiments that the\nsystem can self-improve in previously unseen scenarios given a reasonable\nnumber of newly labeled data.\n","authors":["Peixin Chang","Shuijing Liu","D. Livingston McPherson","Katherine Driggs-Campbell"],"pdf_url":"https://arxiv.org/pdf/2109.02823v3.pdf","comment":"Published in ICRA 2023"},{"id":"http://arxiv.org/abs/2303.02570v1","updated":"2023-03-05T03:54:54Z","published":"2023-03-05T03:54:54Z","title":"Time Associated Meta Learning for Clinical Prediction","summary":"  Rich Electronic Health Records (EHR), have created opportunities to improve\nclinical processes using machine learning methods. Prediction of the same\npatient events at different time horizons can have very different applications\nand interpretations; however, limited number of events in each potential time\nwindow hurts the effectiveness of conventional machine learning algorithms. We\npropose a novel time associated meta learning (TAML) method to make effective\npredictions at multiple future time points. We view time-associated disease\nprediction as classification tasks at multiple time points. Such\nclosely-related classification tasks are an excellent candidate for model-based\nmeta learning. To address the sparsity problem after task splitting, TAML\nemploys a temporal information sharing strategy to augment the number of\npositive samples and include the prediction of related phenotypes or events in\nthe meta-training phase. We demonstrate the effectiveness of TAML on multiple\nclinical datasets, where it consistently outperforms a range of strong\nbaselines. We also develop a MetaEHR package for implementing both\ntime-associated and time-independent few-shot prediction on EHR data.\n","authors":["Hao Liu","Muhan Zhang","Zehao Dong","Lecheng Kong","Yixin Chen","Bradley Fritz","Dacheng Tao","Christopher King"],"pdf_url":"https://arxiv.org/pdf/2303.02570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02568v1","updated":"2023-03-05T03:30:22Z","published":"2023-03-05T03:30:22Z","title":"Unlearnable Graph: Protecting Graphs from Unauthorized Exploitation","summary":"  While the use of graph-structured data in various fields is becoming\nincreasingly popular, it also raises concerns about the potential unauthorized\nexploitation of personal data for training commercial graph neural network\n(GNN) models, which can compromise privacy. To address this issue, we propose a\nnovel method for generating unlearnable graph examples. By injecting delusive\nbut imperceptible noise into graphs using our Error-Minimizing Structural\nPoisoning (EMinS) module, we are able to make the graphs unexploitable.\nNotably, by modifying only $5\\%$ at most of the potential edges in the graph\ndata, our method successfully decreases the accuracy from ${77.33\\%}$ to\n${42.47\\%}$ on the COLLAB dataset.\n","authors":["Yixin Liu","Chenrui Fan","Pan Zhou","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2303.02568v1.pdf","comment":"This paper is accepted as a poster for NDSS 2023"},{"id":"http://arxiv.org/abs/2303.02562v1","updated":"2023-03-05T03:12:57Z","published":"2023-03-05T03:12:57Z","title":"The First Comprehensive Dataset with Multiple Distortion Types for\n  Visual Just-Noticeable Differences","summary":"  Recently, with the development of deep learning, a number of Just Noticeable\nDifference (JND) datasets have been built for JND modeling. However, all the\nexisting JND datasets only label the JND points based on the level of\ncompression distortion. Hence, JND models learned from such datasets can only\nbe used for image/video compression. As known, JND is a major characteristic of\nthe human visual system (HVS), which reflects the maximum visual distortion\nthat the HVS can tolerate. Hence, a generalized JND modeling should take more\nkinds of distortion types into account. To benefit JND modeling, this work\nestablishes a generalized JND dataset with a coarse-to-fine JND selection,\nwhich contains 106 source images and 1,642 JND maps, covering 25 distortion\ntypes. To this end, we proposed a coarse JND candidate selection scheme to\nselect the distorted images from the existing Image Quality Assessment (IQA)\ndatasets as JND candidates instead of generating JND maps ourselves. Then, a\nfine JND selection is carried out on the JND candidates with a crowdsourced\nsubjective assessment.\n","authors":["Yaxuan Liu","Jian Jin","Yuan Xue","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2303.02562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02552v1","updated":"2023-03-05T02:28:15Z","published":"2023-03-05T02:28:15Z","title":"An Empirical Study of Pre-Trained Model Reuse in the Hugging Face Deep\n  Learning Model Registry","summary":"  Deep Neural Networks (DNNs) are being adopted as components in software\nsystems. Creating and specializing DNNs from scratch has grown increasingly\ndifficult as state-of-the-art architectures grow more complex. Following the\npath of traditional software engineering, machine learning engineers have begun\nto reuse large-scale pre-trained models (PTMs) and fine-tune these models for\ndownstream tasks. Prior works have studied reuse practices for traditional\nsoftware packages to guide software engineers towards better package\nmaintenance and dependency management. We lack a similar foundation of\nknowledge to guide behaviors in pre-trained model ecosystems.\n  In this work, we present the first empirical investigation of PTM reuse. We\ninterviewed 12 practitioners from the most popular PTM ecosystem, Hugging Face,\nto learn the practices and challenges of PTM reuse. From this data, we model\nthe decision-making process for PTM reuse. Based on the identified practices,\nwe describe useful attributes for model reuse, including provenance,\nreproducibility, and portability. Three challenges for PTM reuse are missing\nattributes, discrepancies between claimed and actual performance, and model\nrisks. We substantiate these identified challenges with systematic measurements\nin the Hugging Face ecosystem. Our work informs future directions on optimizing\ndeep learning ecosystems by automated measuring useful attributes and potential\nattacks, and envision future research on infrastructure and standardization for\nmodel registries.\n","authors":["Wenxin Jiang","Nicholas Synovic","Matt Hyatt","Taylor R. Schorlemmer","Rohan Sethi","Yung-Hsiang Lu","George K. Thiruvathukal","James C. Davis"],"pdf_url":"https://arxiv.org/pdf/2303.02552v1.pdf","comment":"Proceedings of the ACM/IEEE 45th International Conference on Software\n  Engineering (ICSE) 2023"},{"id":"http://arxiv.org/abs/2303.02551v1","updated":"2023-03-05T02:27:55Z","published":"2023-03-05T02:27:55Z","title":"Discrepancies among Pre-trained Deep Neural Networks: A New Threat to\n  Model Zoo Reliability","summary":"  Training deep neural networks (DNNs) takes signifcant time and resources. A\npractice for expedited deployment is to use pre-trained deep neural networks\n(PTNNs), often from model zoos -- collections of PTNNs; yet, the reliability of\nmodel zoos remains unexamined. In the absence of an industry standard for the\nimplementation and performance of PTNNs, engineers cannot confidently\nincorporate them into production systems. As a first step, discovering\npotential discrepancies between PTNNs across model zoos would reveal a threat\nto model zoo reliability. Prior works indicated existing variances in deep\nlearning systems in terms of accuracy. However, broader measures of reliability\nfor PTNNs from model zoos are unexplored. This work measures notable\ndiscrepancies between accuracy, latency, and architecture of 36 PTNNs across\nfour model zoos. Among the top 10 discrepancies, we find differences of\n1.23%-2.62% in accuracy and 9%-131% in latency. We also fnd mismatches in\narchitecture for well-known DNN architectures (e.g., ResNet and AlexNet). Our\nfindings call for future works on empirical validation, automated tools for\nmeasurement, and best practices for implementation.\n","authors":["Diego Montes","Pongpatapee Peerapatanapokin","Jeff Schultz","Chengjun Gun","Wenxin Jiang","James C. Davis"],"pdf_url":"https://arxiv.org/pdf/2303.02551v1.pdf","comment":"Proceedings of the 30th ACM Joint Meeting on European Software\n  Engineering Conference and Symposium on the Foundations of Software\n  Engineering: Ideas, Visions, and Reflections track (ESEC/FSE-IVR) 2022"},{"id":"http://arxiv.org/abs/2105.01220v2","updated":"2023-03-05T01:39:20Z","published":"2021-05-03T23:38:34Z","title":"Trust-Aware Planning: Modeling Trust Evolution in Iterated Human-Robot\n  Interaction","summary":"  Trust between team members is an essential requirement for any successful\ncooperation. Thus, engendering and maintaining the fellow team members' trust\nbecomes a central responsibility for any member trying to not only successfully\nparticipate in the task but to ensure the team achieves its goals. The problem\nof trust management is particularly challenging in mixed human-robot teams\nwhere the human and the robot may have different models about the task at hand\nand thus may have different expectations regarding the current course of\naction, thereby forcing the robot to focus on the costly explicable behavior.\nWe propose a computational model for capturing and modulating trust in such\niterated human-robot interaction settings, where the human adopts a supervisory\nrole. In our model, the robot integrates human's trust and their expectations\nabout the robot into its planning process to build and maintain trust over the\ninteraction horizon. By establishing the required level of trust, the robot can\nfocus on maximizing the team goal by eschewing explicit explanatory or\nexplicable behavior without worrying about the human supervisor monitoring and\nintervening to stop behaviors they may not necessarily understand. We model\nthis reasoning about trust levels as a meta reasoning process over individual\nplanning tasks. We additionally validate our model through a human subject\nexperiment.\n","authors":["Zahra Zahedi","Mudit Verma","Sarath Sreedharan","Subbarao Kambhampati"],"pdf_url":"https://arxiv.org/pdf/2105.01220v2.pdf","comment":"9 pages, in proceeding of 2023 18th ACM/IEEE International Conference\n  on Human-Robot Interaction (HRI)"},{"id":"http://arxiv.org/abs/2303.02536v1","updated":"2023-03-05T00:57:49Z","published":"2023-03-05T00:57:49Z","title":"Finding Alignments Between Interpretable Causal Variables and\n  Distributed Neural Representations","summary":"  Causal abstraction is a promising theoretical framework for explainable\nartificial intelligence that defines when an interpretable high-level causal\nmodel is a faithful simplification of a low-level deep learning system.\nHowever, existing causal abstraction methods have two major limitations: they\nrequire a brute-force search over alignments between the high-level model and\nthe low-level one, and they presuppose that variables in the high-level model\nwill align with disjoint sets of neurons in the low-level one. In this paper,\nwe present distributed alignment search (DAS), which overcomes these\nlimitations. In DAS, we find the alignment between high-level and low-level\nmodels using gradient descent rather than conducting a brute-force search, and\nwe allow individual neurons to play multiple distinct roles by analyzing\nrepresentations in non-standard bases-distributed representations. Our\nexperiments show that DAS can discover internal structure that prior approaches\nmiss. Overall, DAS removes previous obstacles to conducting causal abstraction\nanalyses and allows us to find conceptual structure in trained neural nets.\n","authors":["Atticus Geiger","Zhengxuan Wu","Christopher Potts","Thomas Icard","Noah D. Goodman"],"pdf_url":"https://arxiv.org/pdf/2303.02536v1.pdf","comment":null}]},"2023-03-07T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2303.04134v1","updated":"2023-03-07T18:49:13Z","published":"2023-03-07T18:49:13Z","title":"A Hybrid Architecture for Out of Domain Intent Detection and Intent\n  Discovery","summary":"  Intent Detection is one of the tasks of the Natural Language Understanding\n(NLU) unit in task-oriented dialogue systems. Out of Scope (OOS) and Out of\nDomain (OOD) inputs may run these systems into a problem. On the other side, a\nlabeled dataset is needed to train a model for Intent Detection in\ntask-oriented dialogue systems. The creation of a labeled dataset is\ntime-consuming and needs human resources. The purpose of this article is to\naddress mentioned problems. The task of identifying OOD/OOS inputs is named\nOOD/OOS Intent Detection. Also, discovering new intents and pseudo-labeling of\nOOD inputs is well known by Intent Discovery. In OOD intent detection part, we\nmake use of a Variational Autoencoder to distinguish between known and unknown\nintents independent of input data distribution. After that, an unsupervised\nclustering method is used to discover different unknown intents underlying\nOOD/OOS inputs. We also apply a non-linear dimensionality reduction on OOD/OOS\nrepresentations to make distances between representations more meaning full for\nclustering. Our results show that the proposed model for both OOD/OOS Intent\nDetection and Intent Discovery achieves great results and passes baselines in\nEnglish and Persian languages.\n","authors":["Masoud Akbari","Ali Mohades","M. Hassan Shirali-Shahreza"],"pdf_url":"https://arxiv.org/pdf/2303.04134v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04132v1","updated":"2023-03-07T18:48:55Z","published":"2023-03-07T18:48:55Z","title":"Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and\n  the Case of Information Extraction","summary":"  Large language models (LLMs) show great potential for synthetic data\ngeneration. This work shows that useful data can be synthetically generated\neven for tasks that cannot be solved directly by the LLM: we show that, for\nproblems with structured outputs, it is possible to prompt an LLM to perform\nthe task in the opposite direction, to generate plausible text for the target\nstructure. Leveraging the asymmetry in task difficulty makes it possible to\nproduce large-scale, high-quality data for complex tasks. We demonstrate the\neffectiveness of this approach on closed information extraction, where\ncollecting ground-truth data is challenging, and no satisfactory dataset exists\nto date. We synthetically generate a dataset of 1.8M data points, demonstrate\nits superior quality compared to existing datasets in a human evaluation and\nuse it to finetune small models (220M and 770M parameters). The models we\nintroduce, SynthIE, outperform existing baselines of comparable size with a\nsubstantial gap of 57 and 79 absolute points in micro and macro F1,\nrespectively. Code, data, and models are available at\nhttps://github.com/epfl-dlab/SynthIE.\n","authors":["Martin Josifoski","Marija Sakota","Maxime Peyrard","Robert West"],"pdf_url":"https://arxiv.org/pdf/2303.04132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.11171v4","updated":"2023-03-07T17:57:37Z","published":"2022-03-21T17:48:52Z","title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models","summary":"  Chain-of-thought prompting combined with pre-trained large language models\nhas achieved encouraging results on complex reasoning tasks. In this paper, we\npropose a new decoding strategy, self-consistency, to replace the naive greedy\ndecoding used in chain-of-thought prompting. It first samples a diverse set of\nreasoning paths instead of only taking the greedy one, and then selects the\nmost consistent answer by marginalizing out the sampled reasoning paths.\nSelf-consistency leverages the intuition that a complex reasoning problem\ntypically admits multiple different ways of thinking leading to its unique\ncorrect answer. Our extensive empirical evaluation shows that self-consistency\nboosts the performance of chain-of-thought prompting with a striking margin on\na range of popular arithmetic and commonsense reasoning benchmarks, including\nGSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and\nARC-challenge (+3.9%).\n","authors":["Xuezhi Wang","Jason Wei","Dale Schuurmans","Quoc Le","Ed Chi","Sharan Narang","Aakanksha Chowdhery","Denny Zhou"],"pdf_url":"https://arxiv.org/pdf/2203.11171v4.pdf","comment":"Published at ICLR 2023. V2: added PaLM results; V3: added UL2\n  results; V4: camera ready version at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.04093v1","updated":"2023-03-07T17:53:00Z","published":"2023-03-07T17:53:00Z","title":"Marpa and nullable symbols","summary":"  The Marpa parser was intended to make the best results in the academic\nliterature on Earley's algorithm available as a practical general parser.\nEarley-based parsers have had issues handling nullable symbols. Initially, we\ndealt with nullable symbols by following the approach in Aycock and Horspool's\n2002 paper. This paper reports our experience with the approach in that paper,\nand the approach to handling nullables that we settled on in reaction to that\nexperience.\n","authors":["Jeffrey Kegler"],"pdf_url":"https://arxiv.org/pdf/2303.04093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04092v1","updated":"2023-03-07T17:52:51Z","published":"2023-03-07T17:52:51Z","title":"CroCoSum: A Benchmark Dataset for Cross-Lingual Code-Switched\n  Summarization","summary":"  Cross-lingual summarization (CLS) has attracted increasing interest in recent\nyears due to the availability of large-scale web-mined datasets and the\nadvancements of multilingual language models. However, given the rareness of\nnaturally occurring CLS resources, the majority of datasets are forced to rely\non translation which can contain overly literal artifacts. This restricts our\nability to observe naturally occurring CLS pairs that capture organic diction,\nincluding instances of code-switching. This alteration between languages in\nmid-message is a common phenomenon in multilingual settings yet has been\nlargely overlooked in cross-lingual contexts due to data scarcity. To address\nthis gap, we introduce CroCoSum, a dataset of cross-lingual code-switched\nsummarization of technology news. It consists of over 24,000 English source\narticles and 18,000 human-curated Chinese news summaries, with more than 92% of\nthe summaries containing code-switched phrases. For reference, we evaluate the\nperformance of existing approaches including pipeline, end-to-end, and\nzero-shot methods. We show that leveraging existing resources as a pretraining\nstep does not improve performance on CroCoSum, indicating the limited\ngeneralizability of existing resources. Finally, we discuss the challenges of\nevaluating cross-lingual summarizers on code-switched generation through\nqualitative error analyses. Our collection and code can be accessed at\nhttps://github.com/RosenZhang/CroCoSum.\n","authors":["Ruochen Zhang","Carsten Eickhoff"],"pdf_url":"https://arxiv.org/pdf/2303.04092v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2303.04091v1","updated":"2023-03-07T17:52:46Z","published":"2023-03-07T17:52:46Z","title":"Visual Abstraction and Reasoning through Language","summary":"  While Artificial Intelligence (AI) models have achieved human or even\nsuperhuman performance in narrowly defined applications, they still struggle to\nshow signs of broader and more flexible intelligence. The Abstraction and\nReasoning Corpus (ARC), introduced by Fran\\c{c}ois Chollet, aims to assess how\nclose AI systems are to human-like cognitive abilities. Most current approaches\nrely on carefully handcrafted domain-specific languages (DSLs), which are used\nto brute-force solutions to the tasks present in ARC. In this work, we propose\na general framework for solving ARC based on natural language descriptions of\nthe tasks. While not yet beating state-of-the-art DSL models on ARC, we\ndemonstrate the immense potential of our approach hinted at by the ability to\nsolve previously unsolved tasks.\n","authors":["Giacomo Camposampiero","Loic Houmard","Benjamin Estermann","Joël Mathys","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.04091v1.pdf","comment":"The first two authors have contributed equally to this work"},{"id":"http://arxiv.org/abs/2303.04053v1","updated":"2023-03-07T17:01:25Z","published":"2023-03-07T17:01:25Z","title":"Describe me an Aucklet: Generating Grounded Perceptual Category\n  Descriptions","summary":"  Human language users can generate descriptions of perceptual concepts beyond\ninstance-level representations and also use such descriptions to learn\nprovisional class-level representations. However, the ability of computational\nmodels to learn and operate with class representations is under-investigated in\nthe language-and-vision field. In this paper, we train separate neural networks\nto generate and interpret class-level descriptions. We then use the zero-shot\nclassification performance of the interpretation model as a measure of\ncommunicative success and class-level conceptual grounding. We investigate the\nperformance of prototype- and exemplar-based neural representations grounded\ncategory description. Finally, we show that communicative success reveals\nperformance issues in the generation model that are not captured by traditional\nintrinsic NLG evaluation metrics, and argue that these issues can be traced to\na failure to properly ground language in vision at the class level. We observe\nthat the interpretation model performs better with descriptions that are low in\ndiversity on the class level, possibly indicating a strong reliance on\nfrequently occurring features.\n","authors":["Bill Noble","Nikolai Ilinykh"],"pdf_url":"https://arxiv.org/pdf/2303.04053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04048v1","updated":"2023-03-07T16:57:20Z","published":"2023-03-07T16:57:20Z","title":"Is ChatGPT a Good NLG Evaluator? A Preliminary Study","summary":"  Recently, the emergence of ChatGPT has attracted wide attention from the\ncomputational linguistics community. Many prior studies have shown that ChatGPT\nachieves remarkable performance on various NLP tasks in terms of automatic\nevaluation metrics. However, the ability of ChatGPT to serve as an evaluation\nmetric is still underexplored. Considering assessing the quality of NLG models\nis an arduous task and previous statistical metrics notoriously show their poor\ncorrelation with human judgments, we wonder whether ChatGPT is a good NLG\nevaluation metric. In this report, we provide a preliminary meta-evaluation on\nChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT\nas a human evaluator and give task-specific (e.g., summarization) and\naspect-specific (e.g., relevance) instruction to prompt ChatGPT to score the\ngeneration of NLG models. We conduct experiments on three widely-used NLG\nmeta-evaluation datasets (including summarization, story generation and\ndata-to-text tasks). Experimental results show that compared with previous\nautomatic metrics, ChatGPT achieves state-of-the-art or competitive correlation\nwith golden human judgments. We hope our preliminary study could prompt the\nemergence of a general-purposed reliable NLG metric.\n","authors":["Jiaan Wang","Yunlong Liang","Fandong Meng","Haoxiang Shi","Zhixu Li","Jinan Xu","Jianfeng Qu","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.04048v1.pdf","comment":"Technical Report, 8 pages"},{"id":"http://arxiv.org/abs/2303.00628v2","updated":"2023-03-07T16:41:01Z","published":"2023-03-01T16:31:01Z","title":"MuAViC: A Multilingual Audio-Visual Corpus for Robust Speech Recognition\n  and Robust Speech-to-Text Translation","summary":"  We introduce MuAViC, a multilingual audio-visual corpus for robust speech\nrecognition and robust speech-to-text translation providing 1200 hours of\naudio-visual speech in 9 languages. It is fully transcribed and covers 6\nEnglish-to-X translation as well as 6 X-to-English translation directions. To\nthe best of our knowledge, this is the first open benchmark for audio-visual\nspeech-to-text translation and the largest open benchmark for multilingual\naudio-visual speech recognition. Our baseline results show that MuAViC is\neffective for building noise-robust speech recognition and translation models.\nWe make the corpus available at https://github.com/facebookresearch/muavic.\n","authors":["Mohamed Anwar","Bowen Shi","Vedanuj Goswami","Wei-Ning Hsu","Juan Pino","Changhan Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00628v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04001v1","updated":"2023-03-07T16:00:26Z","published":"2023-03-07T16:00:26Z","title":"ELODIN: Naming Concepts in Embedding Spaces","summary":"  Despite recent advancements, the field of text-to-image synthesis still\nsuffers from lack of fine-grained control. Using only text, it remains\nchallenging to deal with issues such as concept coherence and concept\ncontamination. We propose a method to enhance control by generating specific\nconcepts that can be reused throughout multiple images, effectively expanding\nnatural language with new words that can be combined much like a painter's\npalette. Unlike previous contributions, our method does not copy visuals from\ninput data and can generate concepts through text alone. We perform a set of\ncomparisons that finds our method to be a significant improvement over\ntext-only prompts.\n","authors":["Rodrigo Mello","Filipe Calegario","Geber Ramalho"],"pdf_url":"https://arxiv.org/pdf/2303.04001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03975v1","updated":"2023-03-07T15:23:38Z","published":"2023-03-07T15:23:38Z","title":"GATE: A Challenge Set for Gender-Ambiguous Translation Examples","summary":"  Although recent years have brought significant progress in improving\ntranslation of unambiguously gendered sentences, translation of ambiguously\ngendered input remains relatively unexplored. When source gender is ambiguous,\nmachine translation models typically default to stereotypical gender roles,\nperpetuating harmful bias. Recent work has led to the development of \"gender\nrewriters\" that generate alternative gender translations on such ambiguous\ninputs, but such systems are plagued by poor linguistic coverage. To encourage\nbetter performance on this task we present and release GATE, a linguistically\ndiverse corpus of gender-ambiguous source sentences along with multiple\nalternative target language translations. We also provide tools for evaluation\nand system analysis when using GATE and use them to evaluate our translation\nrewriter system.\n","authors":["Spencer Rarrick","Ranjita Naik","Varun Mathur","Sundar Poudel","Vishal Chowdhary"],"pdf_url":"https://arxiv.org/pdf/2303.03975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03953v1","updated":"2023-03-07T14:59:33Z","published":"2023-03-07T14:59:33Z","title":"ChatGPT: Beginning of an End of Manual Annotation? Use Case of Automatic\n  Genre Identification","summary":"  ChatGPT has shown strong capabilities in natural language generation tasks,\nwhich naturally leads researchers to explore where its abilities end. In this\npaper, we examine whether ChatGPT can be used for zero-shot text\nclassification, more specifically, automatic genre identification. We compare\nChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on\ndatasets, manually annotated with genres. The models are compared on test sets\nin two languages: English and Slovenian. Results show that ChatGPT outperforms\nthe fine-tuned model when applied to the dataset which was not seen before by\neither of the models. Even when applied on Slovenian language as an\nunder-resourced language, ChatGPT's performance is no worse than when applied\nto English. However, if the model is fully prompted in Slovenian, the\nperformance drops significantly, showing the current limitations of ChatGPT\nusage on smaller languages. The presented results lead us to questioning\nwhether this is the beginning of an end of laborious manual annotation\ncampaigns even for smaller languages, such as Slovenian.\n","authors":["Taja Kuzman","Nikola Ljubešić","Igor Mozetič"],"pdf_url":"https://arxiv.org/pdf/2303.03953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03948v1","updated":"2023-03-07T14:57:06Z","published":"2023-03-07T14:57:06Z","title":"A Meta-Evaluation of Faithfulness Metrics for Long-Form Hospital-Course\n  Summarization","summary":"  Long-form clinical summarization of hospital admissions has real-world\nsignificance because of its potential to help both clinicians and patients. The\nfaithfulness of summaries is critical to their safe usage in clinical settings.\nTo better understand the limitations of abstractive systems, as well as the\nsuitability of existing evaluation metrics, we benchmark faithfulness metrics\nagainst fine-grained human annotations for model-generated summaries of a\npatient's Brief Hospital Course. We create a corpus of patient hospital\nadmissions and summaries for a cohort of HIV patients, each with complex\nmedical histories. Annotators are presented with summaries and source notes,\nand asked to categorize manually highlighted summary elements (clinical\nentities like conditions and medications as well as actions like \"following\nup\") into one of three categories: ``Incorrect,'' ``Missing,'' and ``Not in\nNotes.'' We meta-evaluate a broad set of proposed faithfulness metrics and,\nacross metrics, explore the importance of domain adaptation (e.g. the impact of\nin-domain pre-training and metric fine-tuning), the use of source-summary\nalignments, and the effects of distilling a single metric from an ensemble of\npre-existing metrics. Off-the-shelf metrics with no exposure to clinical text\ncorrelate well yet overly rely on summary extractiveness. As a practical guide\nto long-form clinical narrative summarization, we find that most metrics\ncorrelate best to human judgments when provided with one summary sentence at a\ntime and a minimal set of relevant source context.\n","authors":["Griffin Adams","Jason Zucker","Noémie Elhadad"],"pdf_url":"https://arxiv.org/pdf/2303.03948v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2210.00305v2","updated":"2023-03-07T14:35:33Z","published":"2022-10-01T16:01:53Z","title":"LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph\n  Embeddings","summary":"  Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. Text-based KG embeddings\ncan represent entities by encoding descriptions with pre-trained language\nmodels, but no open-sourced library is specifically designed for KGs with PLMs\nat present. In this paper, we present LambdaKG, a library for KGE that equips\nwith many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and\nsupports various tasks (e.g., knowledge graph completion, question answering,\nrecommendation, and knowledge probing). LambdaKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at\nhttp://deepke.zjukg.cn/lambdakg.mp4 and long-term maintenance.\n","authors":["Xin Xie","Zhoubo Li","Xiaohan Wang","Yuqi Zhu","Ningyu Zhang","Jintian Zhang","Siyuan Cheng","Bozhong Tian","Shumin Deng","Feiyu Xiong","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00305v2.pdf","comment":"Work in progress and the project website is\n  https://zjunlp.github.io/project/promptkg/"},{"id":"http://arxiv.org/abs/2303.03926v1","updated":"2023-03-07T14:31:55Z","published":"2023-03-07T14:31:55Z","title":"Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec\n  Language Modeling","summary":"  We propose a cross-lingual neural codec language model, VALL-E X, for\ncross-lingual speech synthesis. Specifically, we extend VALL-E and train a\nmulti-lingual conditional codec language model to predict the acoustic token\nsequences of the target language speech by using both the source language\nspeech and the target language text as prompts. VALL-E X inherits strong\nin-context learning capabilities and can be applied for zero-shot cross-lingual\ntext-to-speech synthesis and zero-shot speech-to-speech translation tasks.\nExperimental results show that it can generate high-quality speech in the\ntarget language via just one speech utterance in the source language as a\nprompt while preserving the unseen speaker's voice, emotion, and acoustic\nenvironment. Moreover, VALL-E X effectively alleviates the foreign accent\nproblems, which can be controlled by a language ID. Audio samples are available\nat \\url{https://aka.ms/vallex}.\n","authors":["Ziqiang Zhang","Long Zhou","Chengyi Wang","Sanyuan Chen","Yu Wu","Shujie Liu","Zhuo Chen","Yanqing Liu","Huaming Wang","Jinyu Li","Lei He","Sheng Zhao","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2303.03926v1.pdf","comment":"We encourage readers to listen to the audio samples on our demo page:\n  \\url{https://aka.ms/vallex}"},{"id":"http://arxiv.org/abs/2303.03915v1","updated":"2023-03-07T14:25:44Z","published":"2023-03-07T14:25:44Z","title":"The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset","summary":"  As language models grow ever larger, the need for large-scale high-quality\ntext datasets has never been more pressing, especially in multilingual\nsettings. The BigScience workshop, a 1-year international and multidisciplinary\ninitiative, was formed with the goal of researching and training large language\nmodels as a values-driven undertaking, putting issues of ethics, harm, and\ngovernance in the foreground. This paper documents the data creation and\ncuration efforts undertaken by BigScience to assemble the Responsible\nOpen-science Open-collaboration Text Sources (ROOTS) corpus, a 1.6TB dataset\nspanning 59 languages that was used to train the 176-billion-parameter\nBigScience Large Open-science Open-access Multilingual (BLOOM) language model.\nWe further release a large initial subset of the corpus and analyses thereof,\nand hope to empower large-scale monolingual and multilingual modeling projects\nwith both the data and the processing tools, as well as stimulate research\naround this large multilingual corpus.\n","authors":["Hugo Laurençon","Lucile Saulnier","Thomas Wang","Christopher Akiki","Albert Villanova del Moral","Teven Le Scao","Leandro Von Werra","Chenghao Mou","Eduardo González Ponferrada","Huu Nguyen","Jörg Frohberg","Mario Šaško","Quentin Lhoest","Angelina McMillan-Major","Gerard Dupont","Stella Biderman","Anna Rogers","Loubna Ben allal","Francesco De Toni","Giada Pistilli","Olivier Nguyen","Somaieh Nikpoor","Maraim Masoud","Pierre Colombo","Javier de la Rosa","Paulo Villegas","Tristan Thrush","Shayne Longpre","Sebastian Nagel","Leon Weber","Manuel Muñoz","Jian Zhu","Daniel Van Strien","Zaid Alyafeai","Khalid Almubarak","Minh Chien Vu","Itziar Gonzalez-Dios","Aitor Soroa","Kyle Lo","Manan Dey","Pedro Ortiz Suarez","Aaron Gokaslan","Shamik Bose","David Adelani","Long Phan","Hieu Tran","Ian Yu","Suhas Pai","Jenny Chim","Violette Lepercq","Suzana Ilic","Margaret Mitchell","Sasha Alexandra Luccioni","Yacine Jernite"],"pdf_url":"https://arxiv.org/pdf/2303.03915v1.pdf","comment":"NeurIPS 2022, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2303.03912v1","updated":"2023-03-07T14:14:12Z","published":"2023-03-07T14:14:12Z","title":"Document-level Relation Extraction with Cross-sentence Reasoning Graph","summary":"  Relation extraction (RE) has recently moved from the sentence-level to\ndocument-level, which requires aggregating document information and using\nentities and mentions for reasoning. Existing works put entity nodes and\nmention nodes with similar representations in a document-level graph, whose\ncomplex edges may incur redundant information. Furthermore, existing studies\nonly focus on entity-level reasoning paths without considering global\ninteractions among entities cross-sentence. To these ends, we propose a novel\ndocument-level RE model with a GRaph information Aggregation and Cross-sentence\nReasoning network (GRACR). Specifically, a simplified document-level graph is\nconstructed to model the semantic information of all mentions and sentences in\na document, and an entity-level graph is designed to explore relations of\nlong-distance cross-sentence entity pairs. Experimental results show that GRACR\nachieves excellent performance on two public datasets of document-level RE. It\nis especially effective in extracting potential relations of cross-sentence\nentity pairs. Our code is available at https://github.com/UESTC-LHF/GRACR.\n","authors":["Hongfei Liu","Zhao Kang","Lizong Zhang","Ling Tian","Fujun Hua"],"pdf_url":"https://arxiv.org/pdf/2303.03912v1.pdf","comment":"This paper is accepted by PAKDD 2023"},{"id":"http://arxiv.org/abs/2303.03846v1","updated":"2023-03-07T12:24:17Z","published":"2023-03-07T12:24:17Z","title":"Larger language models do in-context learning differently","summary":"  We study how in-context learning (ICL) in language models is affected by\nsemantic priors versus input-label mappings. We investigate two setups-ICL with\nflipped labels and ICL with semantically-unrelated labels-across various model\nfamilies (GPT-3, InstructGPT, Codex, PaLM, and Flan-PaLM). First, experiments\non ICL with flipped labels show that overriding semantic priors is an emergent\nability of model scale. While small language models ignore flipped labels\npresented in-context and thus rely primarily on semantic priors from\npretraining, large models can override semantic priors when presented with\nin-context exemplars that contradict priors, despite the stronger semantic\npriors that larger models may hold. We next study semantically-unrelated label\nICL (SUL-ICL), in which labels are semantically unrelated to their inputs\n(e.g., foo/bar instead of negative/positive), thereby forcing language models\nto learn the input-label mappings shown in in-context exemplars in order to\nperform the task. The ability to do SUL-ICL also emerges primarily with scale,\nand large-enough language models can even perform linear classification in a\nSUL-ICL setting. Finally, we evaluate instruction-tuned models and find that\ninstruction tuning strengthens both the use of semantic priors and the capacity\nto learn input-label mappings, but more of the former.\n","authors":["Jerry Wei","Jason Wei","Yi Tay","Dustin Tran","Albert Webson","Yifeng Lu","Xinyun Chen","Hanxiao Liu","Da Huang","Denny Zhou","Tengyu Ma"],"pdf_url":"https://arxiv.org/pdf/2303.03846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13149v2","updated":"2023-03-07T12:22:00Z","published":"2023-02-25T20:24:58Z","title":"STACC: Code Comment Classification using SentenceTransformers","summary":"  Code comments are a key resource for information about software artefacts.\nDepending on the use case, only some types of comments are useful. Thus,\nautomatic approaches to classify these comments have been proposed. In this\nwork, we address this need by proposing, STACC, a set of\nSentenceTransformers-based binary classifiers. These lightweight classifiers\nare trained and tested on the NLBSE Code Comment Classification tool\ncompetition dataset, and surpass the baseline by a significant margin,\nachieving an average F1 score of 0.74 against the baseline of 0.31, which is an\nimprovement of 139%. A replication package, as well as the models themselves,\nare publicly available.\n","authors":["Ali Al-Kaswan","Maliheh Izadi","Arie van Deursen"],"pdf_url":"https://arxiv.org/pdf/2302.13149v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03840v1","updated":"2023-03-07T12:10:47Z","published":"2023-03-07T12:10:47Z","title":"A Challenging Benchmark for Low-Resource Learning","summary":"  With promising yet saturated results in high-resource settings, low-resource\ndatasets have gradually become popular benchmarks for evaluating the learning\nability of advanced neural networks (e.g., BigBench, superGLUE). Some models\neven surpass humans according to benchmark test results. However, we find that\nthere exists a set of hard examples in low-resource settings that challenge\nneural networks but are not well evaluated, which causes over-estimated\nperformance. We first give a theoretical analysis on which factors bring the\ndifficulty of low-resource learning. It then motivate us to propose a\nchallenging benchmark hardBench to better evaluate the learning ability, which\ncovers 11 datasets, including 3 computer vision (CV) datasets and 8 natural\nlanguage process (NLP) datasets. Experiments on a wide range of models show\nthat neural networks, even pre-trained language models, have sharp performance\ndrops on our benchmark, demonstrating the effectiveness on evaluating the\nweaknesses of neural networks. On NLP tasks, we surprisingly find that despite\nbetter results on traditional low-resource benchmarks, pre-trained networks,\ndoes not show performance improvements on our benchmarks. These results\ndemonstrate that there are still a large robustness gap between existing models\nand human-level performance.\n","authors":["Yudong Wang","Chang Ma","Qingxiu Dong","Lingpeng Kong","Jingjing Xu"],"pdf_url":"https://arxiv.org/pdf/2303.03840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03836v1","updated":"2023-03-07T12:03:58Z","published":"2023-03-07T12:03:58Z","title":"Exploring the Feasibility of ChatGPT for Event Extraction","summary":"  Event extraction is a fundamental task in natural language processing that\ninvolves identifying and extracting information about events mentioned in text.\nHowever, it is a challenging task due to the lack of annotated data, which is\nexpensive and time-consuming to obtain. The emergence of large language models\n(LLMs) such as ChatGPT provides an opportunity to solve language tasks with\nsimple prompts without the need for task-specific datasets and fine-tuning.\nWhile ChatGPT has demonstrated impressive results in tasks like machine\ntranslation, text summarization, and question answering, it presents challenges\nwhen used for complex tasks like event extraction. Unlike other tasks, event\nextraction requires the model to be provided with a complex set of instructions\ndefining all event types and their schemas. To explore the feasibility of\nChatGPT for event extraction and the challenges it poses, we conducted a series\nof experiments. Our results show that ChatGPT has, on average, only 51.04% of\nthe performance of a task-specific model such as EEQA in long-tail and complex\nscenarios. Our usability testing experiments indicate that ChatGPT is not\nrobust enough, and continuous refinement of the prompt does not lead to stable\nperformance improvements, which can result in a poor user experience. Besides,\nChatGPT is highly sensitive to different prompt styles.\n","authors":["Jun Gao","Huan Zhao","Changlong Yu","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2303.03836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07017v2","updated":"2023-03-07T12:01:36Z","published":"2022-10-13T13:25:22Z","title":"ComSearch: Equation Searching with Combinatorial Strategy for Solving\n  Math Word Problems with Weak Supervision","summary":"  Previous studies have introduced a weakly-supervised paradigm for solving\nmath word problems requiring only the answer value annotation. While these\nmethods search for correct value equation candidates as pseudo labels, they\nsearch among a narrow sub-space of the enormous equation space. To address this\nproblem, we propose a novel search algorithm with combinatorial strategy\n\\textbf{ComSearch}, which can compress the search space by excluding\nmathematically equivalent equations. The compression allows the searching\nalgorithm to enumerate all possible equations and obtain high-quality data. We\ninvestigate the noise in the pseudo labels that hold wrong mathematical logic,\nwhich we refer to as the \\textit{false-matching} problem, and propose a ranking\nmodel to denoise the pseudo labels. Our approach holds a flexible framework to\nutilize two existing supervised math word problem solvers to train pseudo\nlabels, and both achieve state-of-the-art performance in the weak supervision\ntask.\n","authors":["Qianying Liu","Wenyu Guan","Jianhao Shen","Fei Cheng","Sadao Kurohashi"],"pdf_url":"https://arxiv.org/pdf/2210.07017v2.pdf","comment":"EACL 2023 long paper, 14 pages"},{"id":"http://arxiv.org/abs/2301.04388v2","updated":"2023-03-07T11:09:29Z","published":"2023-01-11T10:20:56Z","title":"Perceive and predict: self-supervised speech representation based loss\n  functions for speech enhancement","summary":"  Recent work in the domain of speech enhancement has explored the use of\nself-supervised speech representations to aid in the training of neural speech\nenhancement models. However, much of this work focuses on using the deepest or\nfinal outputs of self supervised speech representation models, rather than the\nearlier feature encodings. The use of self supervised representations in such a\nway is often not fully motivated. In this work it is shown that the distance\nbetween the feature encodings of clean and noisy speech correlate strongly with\npsychoacoustically motivated measures of speech quality and intelligibility, as\nwell as with human Mean Opinion Score (MOS) ratings. Experiments using this\ndistance as a loss function are performed and improved performance over the use\nof STFT spectrogram distance based loss as well as other common loss functions\nfrom speech enhancement literature is demonstrated using objective measures\nsuch as perceptual evaluation of speech quality (PESQ) and short-time objective\nintelligibility (STOI).\n","authors":["George Close","William Ravenscroft","Thomas Hain","Stefan Goetze"],"pdf_url":"https://arxiv.org/pdf/2301.04388v2.pdf","comment":"4 pages, accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.03750v1","updated":"2023-03-07T09:20:09Z","published":"2023-03-07T09:20:09Z","title":"Preparing the Vuk'uzenzele and ZA-gov-multilingual South African\n  multilingual corpora","summary":"  This paper introduces two multilingual government themed corpora in various\nSouth African languages. The corpora were collected by gathering the South\nAfrican Government newspaper (Vuk'uzenzele), as well as South African\ngovernment speeches (ZA-gov-multilingual), that are translated into all 11\nSouth African official languages. The corpora can be used for a myriad of\ndownstream NLP tasks. The corpora were created to allow researchers to study\nthe language used in South African government publications, with a focus on\nunderstanding how South African government officials communicate with their\nconstituents.\n  In this paper we highlight the process of gathering, cleaning and making\navailable the corpora. We create parallel sentence corpora for Neural Machine\nTranslation (NMT) tasks using Language-Agnostic Sentence Representations\n(LASER) embeddings. With these aligned sentences we then provide NMT benchmarks\nfor 9 indigenous languages by fine-tuning a massively multilingual pre-trained\nlanguage model. \\end{abstra\n","authors":["Richard Lastrucci","Isheanesu Dzingirai","Jenalea Rajab","Andani Madodonga","Matimba Shingange","Daniel Njini","Vukosi Marivate"],"pdf_url":"https://arxiv.org/pdf/2303.03750v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2303.03715v1","updated":"2023-03-07T07:56:38Z","published":"2023-03-07T07:56:38Z","title":"Universal resources for quantum computing","summary":"  Unravelling the source of quantum computing power has been a major goal in\nthe field of quantum information science. In recent years, the quantum resource\ntheory (QRT) has been established to characterize various quantum resources,\nyet their roles in quantum computing tasks still require investigation. The\nso-called universal quantum computing model (UQCM), e.g., the circuit model,\nhas been the main framework to guide the design of quantum algorithms, creation\nof real quantum computers etc. In this work, we combine the study of UQCM\ntogether with QRT. We find on one hand, using QRT can provide a\nresource-theoretic characterization of a UQCM, the relation among models and\ninspire new ones, and on the other hand, using UQCM offers a framework to apply\nresources, study relation among resources and classify them.\n  We develop the theory of universal resources in the setting of UQCM, and find\na rich spectrum of UQCMs and the corresponding universal resources. Depending\non a hierarchical structure of resource theories, we find models can be\nclassified into families. In this work, we study three natural families of\nUQCMs in details: the amplitude family, the quasi-probability family, and the\nHamiltonian family. They include some well known models, like the\nmeasurement-based model and adiabatic model, and also inspire new models such\nas the contextual model we introduce. Each family contains at least a triplet\nof models, and such a succinct structure of families of UQCMs offers a unifying\npicture to investigate resources and design models. It also provides a rigorous\nframework to resolve puzzles, such as the role of entanglement vs.\ninterference, and unravel resource-theoretic features of quantum algorithms.\n","authors":["Dong-Sheng Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09856v3","updated":"2023-03-07T07:53:35Z","published":"2023-02-20T09:38:11Z","title":"Knowledge-aware Bayesian Co-attention for Multimodal Emotion Recognition","summary":"  Multimodal emotion recognition is a challenging research area that aims to\nfuse different modalities to predict human emotion. However, most existing\nmodels that are based on attention mechanisms have difficulty in learning\nemotionally relevant parts on their own. To solve this problem, we propose to\nincorporate external emotion-related knowledge in the co-attention based fusion\nof pre-trained models. To effectively incorporate this knowledge, we enhance\nthe co-attention model with a Bayesian attention module (BAM) where a prior\ndistribution is estimated using the emotion-related knowledge. Experimental\nresults on the IEMOCAP dataset show that the proposed approach can outperform\nseveral state-of-the-art approaches by at least 0.7% unweighted accuracy (UA).\n","authors":["Zihan Zhao","Yu Wang","Yanfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2302.09856v3.pdf","comment":"Accepted to IEEE ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.03706v1","updated":"2023-03-07T07:42:26Z","published":"2023-03-07T07:42:26Z","title":"Classifying Text-Based Conspiracy Tweets related to COVID-19 using\n  Contextualized Word Embeddings","summary":"  The FakeNews task in MediaEval 2022 investigates the challenge of finding\naccurate and high-performance models for the classification of conspiracy\ntweets related to COVID-19. In this paper, we used BERT, ELMO, and their\ncombination for feature extraction and RandomForest as classifier. The results\nshow that ELMO performs slightly better than BERT, however their combination at\nfeature level reduces the performance.\n","authors":["Abdul Rehman","Rabeeh Ayaz Abbasi","Irfan ul Haq Qureshi","Akmal Saeed Khattak"],"pdf_url":"https://arxiv.org/pdf/2303.03706v1.pdf","comment":"Published in Multimedia Benchmark Workshop 2022, Bergen, Norway and\n  Online, 12-13 January 2023: https://2022.multimediaeval.com/"},{"id":"http://arxiv.org/abs/2303.03697v1","updated":"2023-03-07T07:26:09Z","published":"2023-03-07T07:26:09Z","title":"Stylometric Detection of AI-Generated Text in Twitter Timelines","summary":"  Recent advancements in pre-trained language models have enabled convenient\nmethods for generating human-like text at a large scale. Though these\ngeneration capabilities hold great potential for breakthrough applications, it\ncan also be a tool for an adversary to generate misinformation. In particular,\nsocial media platforms like Twitter are highly susceptible to AI-generated\nmisinformation. A potential threat scenario is when an adversary hijacks a\ncredible user account and incorporates a natural language generator to generate\nmisinformation. Such threats necessitate automated detectors for AI-generated\ntweets in a given user's Twitter timeline. However, tweets are inherently\nshort, thus making it difficult for current state-of-the-art pre-trained\nlanguage model-based detectors to accurately detect at what point the AI starts\nto generate tweets in a given Twitter timeline. In this paper, we present a\nnovel algorithm using stylometric signals to aid detecting AI-generated tweets.\nWe propose models corresponding to quantifying stylistic changes in human and\nAI tweets in two related tasks: Task 1 - discriminate between human and\nAI-generated tweets, and Task 2 - detect if and when an AI starts to generate\ntweets in a given Twitter timeline. Our extensive experiments demonstrate that\nthe stylometric features are effective in augmenting the state-of-the-art\nAI-generated text detectors.\n","authors":["Tharindu Kumarage","Joshua Garland","Amrita Bhattacharjee","Kirill Trapeznikov","Scott Ruston","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09865v2","updated":"2023-03-07T07:23:38Z","published":"2023-02-20T09:56:51Z","title":"Can discrete information extraction prompts generalize across language\n  models?","summary":"  We study whether automatically-induced prompts that effectively extract\ninformation from a language model can also be used, out-of-the-box, to probe\nother language models for the same information. After confirming that discrete\nprompts induced with the AutoPrompt algorithm outperform manual and semi-manual\nprompts on the slot-filling task, we demonstrate a drop in performance for\nAutoPrompt prompts learned on a model and tested on another. We introduce a way\nto induce prompts by mixing language models at training time that results in\nprompts that generalize well across models. We conduct an extensive analysis of\nthe induced prompts, finding that the more general prompts include a larger\nproportion of existing English words and have a less order-dependent and more\nuniform distribution of information across their component tokens. Our work\nprovides preliminary evidence that it's possible to generate discrete prompts\nthat can be induced once and used with a number of different models, and gives\ninsights on the properties characterizing such prompts.\n","authors":["Nathanaël Carraz Rakotonirina","Roberto Dessì","Fabio Petroni","Sebastian Riedel","Marco Baroni"],"pdf_url":"https://arxiv.org/pdf/2302.09865v2.pdf","comment":"Published as conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.08220v2","updated":"2023-03-07T07:00:35Z","published":"2023-02-16T11:05:24Z","title":"Dialogue State Distillation Network with Inter-slot Contrastive Learning\n  for Dialogue State Tracking","summary":"  In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to\nextract users' intentions from the dialogue history. Currently, most existing\napproaches suffer from error propagation and are unable to dynamically select\nrelevant information when utilizing previous dialogue states. Moreover, the\nrelations between the updates of different slots provide vital clues for DST.\nHowever, the existing approaches rely only on predefined graphs to indirectly\ncapture the relations. In this paper, we propose a Dialogue State Distillation\nNetwork (DSDN) to utilize relevant information of previous dialogue states and\nmigrate the gap of utilization between training and testing. Thus, it can\ndynamically exploit previous dialogue states and avoid introducing error\npropagation simultaneously. Further, we propose an inter-slot contrastive\nlearning loss to effectively capture the slot co-update relations from dialogue\ncontext. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ\n2.1 datasets. The experimental results show that our proposed model achieves\nthe state-of-the-art performance for DST.\n","authors":["Jing Xu","Dandan Song","Chong Liu","Siu Cheung Hui","Fei Li","Qiang Ju","Xiaonan He","Jian Xie"],"pdf_url":"https://arxiv.org/pdf/2302.08220v2.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2302.10166v3","updated":"2023-03-07T06:47:30Z","published":"2023-02-20T18:53:56Z","title":"Learning Deep Semantics for Test Completion","summary":"  Writing tests is a time-consuming yet essential task during software\ndevelopment. We propose to leverage recent advances in deep learning for text\nand code generation to assist developers in writing tests. We formalize the\nnovel task of test completion to automatically complete the next statement in a\ntest method based on the context of prior statements and the code under test.\nWe develop TeCo -- a deep learning model using code semantics for test\ncompletion. The key insight underlying TeCo is that predicting the next\nstatement in a test method requires reasoning about code execution, which is\nhard to do with only syntax-level data that existing code completion models\nuse. TeCo extracts and uses six kinds of code semantics data, including the\nexecution result of prior statements and the execution context of the test\nmethod. To provide a testbed for this new task, as well as to evaluate TeCo, we\ncollect a corpus of 130,934 test methods from 1,270 open-source Java projects.\nOur results show that TeCo achieves an exact-match accuracy of 18, which is 29%\nhigher than the best baseline using syntax-level data only. When measuring\nfunctional correctness of generated next statement, TeCo can generate runnable\ncode in 29% of the cases compared to 18% obtained by the best baseline.\nMoreover, TeCo is significantly better than prior work on test oracle\ngeneration.\n","authors":["Pengyu Nie","Rahul Banerjee","Junyi Jessy Li","Raymond J. Mooney","Milos Gligoric"],"pdf_url":"https://arxiv.org/pdf/2302.10166v3.pdf","comment":"Accepted as a conference paper in ICSE 2023"},{"id":"http://arxiv.org/abs/2303.01248v2","updated":"2023-03-07T05:35:39Z","published":"2023-03-01T06:16:14Z","title":"Can ChatGPT Assess Human Personalities? A General Evaluation Framework","summary":"  Large Language Models (LLMs) especially ChatGPT have produced impressive\nresults in various areas, but their potential human-like psychology is still\nlargely unexplored. Existing works study the virtual personalities of LLMs but\nrarely explore the possibility of analyzing human personalities via LLMs. This\npaper presents a generic evaluation framework for LLMs to assess human\npersonalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically,\nwe first devise unbiased prompts by randomly permuting options in MBTI\nquestions and adopt the average testing result to encourage more impartial\nanswer generation. Then, we propose to replace the subject in question\nstatements to enable flexible queries and assessments on different subjects\nfrom LLMs. Finally, we re-formulate the question instructions in a manner of\ncorrectness evaluation to facilitate LLMs to generate clearer responses. The\nproposed framework enables LLMs to flexibly assess personalities of different\ngroups of people. We further propose three evaluation metrics to measure the\nconsistency, robustness, and fairness of assessment results from\nstate-of-the-art LLMs including ChatGPT and InstructGPT. Our experiments reveal\nChatGPT's ability to assess human personalities, and the average results\ndemonstrate that it can achieve more consistent and fairer assessments in spite\nof lower robustness against prompt biases compared with InstructGPT.\n","authors":["Haocong Rao","Cyril Leung","Chunyan Miao"],"pdf_url":"https://arxiv.org/pdf/2303.01248v2.pdf","comment":"Our codes are available at https://github.com/Kali-Hac/ChatGPT-MBTI"},{"id":"http://arxiv.org/abs/2303.03628v1","updated":"2023-03-07T03:23:14Z","published":"2023-03-07T03:23:14Z","title":"CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation\n  Verification","summary":"  Chain-of-thought (CoT) prompting enables large language models (LLMs) to\nsolve complex reasoning tasks by generating an explanation before the final\nprediction. Despite it's promising ability, a critical downside of CoT\nprompting is that the performance is greatly affected by the factuality of the\ngenerated explanation. To improve the correctness of the explanations,\nfine-tuning language models with explanation data is needed. However, there\nexists only a few datasets that can be used for such approaches, and no data\ncollection tool for building them. Thus, we introduce CoTEVer, a tool-kit for\nannotating the factual correctness of generated explanations and collecting\nrevision data of wrong explanations. Furthermore, we suggest several use cases\nwhere the data collected with CoTEVer can be utilized for enhancing the\nfaithfulness of explanations. Our toolkit is publicly available at\nhttps://github.com/SeungoneKim/CoTEVer.\n","authors":["Seungone Kim","Se June Joo","Yul Jang","Hyungjoo Chae","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2303.03628v1.pdf","comment":"Accepted at EACL 2023 Demo"},{"id":"http://arxiv.org/abs/2303.03608v1","updated":"2023-03-07T02:49:50Z","published":"2023-03-07T02:49:50Z","title":"Towards Interpretable and Efficient Automatic Reference-Based\n  Summarization Evaluation","summary":"  Interpretability and efficiency are two important considerations for the\nadoption of neural automatic metrics. In this work, we develop\nstrong-performing automatic metrics for reference-based summarization\nevaluation, based on a two-stage evaluation pipeline that first extracts basic\ninformation units from one text sequence and then checks the extracted units in\nanother sequence. The metrics we developed include two-stage metrics that can\nprovide high interpretability at both the fine-grained unit level and summary\nlevel, and one-stage metrics that achieve a balance between efficiency and\ninteroperability. We make the developed tools publicly available through a\nPython package and GitHub.\n","authors":["Yixin Liu","Alexander R. Fabbri","Yilun Zhao","Pengfei Liu","Shafiq Joty","Chien-Sheng Wu","Caiming Xiong","Dragomir Radev"],"pdf_url":"https://arxiv.org/pdf/2303.03608v1.pdf","comment":"GitHub Repo: https://github.com/Yale-LILY/AutoACU"},{"id":"http://arxiv.org/abs/2303.03600v1","updated":"2023-03-07T02:31:57Z","published":"2023-03-07T02:31:57Z","title":"Adaptive Knowledge Distillation between Text and Speech Pre-trained\n  Models","summary":"  Learning on a massive amount of speech corpus leads to the recent success of\nmany self-supervised speech models. With knowledge distillation, these models\nmay also benefit from the knowledge encoded by language models that are\npre-trained on rich sources of texts. The distillation process, however, is\nchallenging due to the modal disparity between textual and speech embedding\nspaces. This paper studies metric-based distillation to align the embedding\nspace of text and speech with only a small amount of data without modifying the\nmodel structure. Since the semantic and granularity gap between text and speech\nhas been omitted in literature, which impairs the distillation, we propose the\nPrior-informed Adaptive knowledge Distillation (PAD) that adaptively leverages\ntext/speech units of variable granularity and prior distributions to achieve\nbetter global and local alignments between text and speech pre-trained models.\nWe evaluate on three spoken language understanding benchmarks to show that PAD\nis more effective in transferring linguistic knowledge than other metric-based\ndistillation approaches.\n","authors":["Jinjie Ni","Yukun Ma","Wen Wang","Qian Chen","Dianwen Ng","Han Lei","Trung Hieu Nguyen","Chong Zhang","Bin Ma","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2303.03600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03593v1","updated":"2023-03-07T01:57:10Z","published":"2023-03-07T01:57:10Z","title":"ADELT: Transpilation Between Deep Learning Frameworks","summary":"  We propose Adversarial DEep Learning Transpiler (ADELT) for source-to-source\ntranspilation between deep learning frameworks. Unlike prior approaches, we\ndecouple the transpilation of code skeletons and the mapping of API keywords\n(an API function name or a parameter name). ADELT transpile code skeletons\nusing few-shot prompting on big language models. Based on contextual embeddings\nextracted by a BERT for code, we train aligned API embeddings in a\ndomain-adversarial setup, upon which we generate a dictionary for keyword\ntranslation. The model is trained on our unlabeled DL corpus from web crawl\ndata, without using any hand-crafted rules and parallel data. Our method\noutperforms state-of-the-art transpilers on multiple transpilation pairs\nincluding PyTorch-Keras and PyTorch-MXNet by 15.9pts and 12.0pts in exact match\nscores respectively.\n","authors":["Linyuan Gong","Jiayi Wang","Alvin Cheung"],"pdf_url":"https://arxiv.org/pdf/2303.03593v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2303.04289v1","updated":"2023-03-07T23:35:58Z","published":"2023-03-07T23:35:58Z","title":"Do Prosody Transfer Models Transfer Prosody?","summary":"  Some recent models for Text-to-Speech synthesis aim to transfer the prosody\nof a reference utterance to the generated target synthetic speech. This is done\nby using a learned embedding of the reference utterance, which is used to\ncondition speech generation. During training, the reference utterance is\nidentical to the target utterance. Yet, during synthesis, these models are\noften used to transfer prosody from a reference that differs from the text or\nspeaker being synthesized.\n  To address this inconsistency, we propose to use a different, but\nprosodically-related, utterance during training too. We believe this should\nencourage the model to learn to transfer only those characteristics that the\nreference and target have in common. If prosody transfer methods do indeed\ntransfer prosody they should be able to be trained in the way we propose.\nHowever, results show that a model trained under these conditions performs\nsignificantly worse than one trained using the target utterance as a reference.\nTo explain this, we hypothesize that prosody transfer models do not learn a\ntransferable representation of prosody, but rather an utterance-level\nrepresentation which is highly dependent on both the reference speaker and\nreference text.\n","authors":["Atli Thor Sigurgeirsson","Simon King"],"pdf_url":"https://arxiv.org/pdf/2303.04289v1.pdf","comment":"Accepted in ICASSP 2023, 5 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2010.09697v5","updated":"2023-03-07T23:09:55Z","published":"2020-10-19T17:40:38Z","title":"Effects of Parameter Norm Growth During Transformer Training: Inductive\n  Bias from Gradient Descent","summary":"  The capacity of neural networks like the widely adopted transformer is known\nto be very high. Evidence is emerging that they learn successfully due to\ninductive bias in the training routine, typically a variant of gradient descent\n(GD). To better understand this bias, we study the tendency for transformer\nparameters to grow in magnitude ($\\ell_2$ norm) during training, and its\nimplications for the emergent representations within self attention layers.\nEmpirically, we document norm growth in the training of transformer language\nmodels, including T5 during its pretraining. As the parameters grow in\nmagnitude, we prove that the network approximates a discretized network with\nsaturated activation functions. Such \"saturated\" networks are known to have a\nreduced capacity compared to the full network family that can be described in\nterms of formal languages and automata. Our results suggest saturation is a new\ncharacterization of an inductive bias implicit in GD of particular interest for\nNLP. We leverage the emergent discrete structure in a saturated transformer to\nanalyze the role of different attention heads, finding that some focus locally\non a small number of positions, while other heads compute global averages,\nallowing counting. We believe understanding the interplay between these two\ncapabilities may shed further light on the structure of computation within\nlarge transformers.\n","authors":["William Merrill","Vivek Ramanujan","Yoav Goldberg","Roy Schwartz","Noah Smith"],"pdf_url":"https://arxiv.org/pdf/2010.09697v5.pdf","comment":"Appeared at EMNLP 2021. March 7, 2023: Removed irreproducible numbers\n  reported in a footnote with erratum note"},{"id":"http://arxiv.org/abs/2207.00729v3","updated":"2023-03-07T23:07:38Z","published":"2022-07-02T03:49:34Z","title":"The Parallelism Tradeoff: Limitations of Log-Precision Transformers","summary":"  Despite their omnipresence in modern NLP, characterizing the computational\npower of transformer neural nets remains an interesting open question. We prove\nthat transformers whose arithmetic precision is logarithmic in the number of\ninput tokens (and whose feedforward nets are computable using space linear in\ntheir input) can be simulated by constant-depth logspace-uniform threshold\ncircuits. This provides insight on the power of transformers using known\nresults in complexity theory. For example, if $\\mathsf L \\neq \\mathsf P$ (i.e.,\nnot all poly-time problems can be solved using logarithmic space), then\ntransformers cannot even accurately solve linear equalities or check membership\nin an arbitrary context-free grammar with empty productions. Our result\nintuitively emerges from the transformer architecture's high parallelizability.\nWe thus speculatively introduce the idea of a fundamental parallelism tradeoff:\nany model architecture as parallelizable as the transformer will obey\nlimitations similar to it. Since parallelism is key to training models at\nmassive scale, this suggests a potential inherent weakness of the scaling\nparadigm.\n","authors":["William Merrill","Ashish Sabharwal"],"pdf_url":"https://arxiv.org/pdf/2207.00729v3.pdf","comment":"Accepted at TACL. Formerly entitled \"Log-Precision Transformers are\n  Constant-Depth Threshold Circuits\". Updated with minor corrections March 6,\n  2023"},{"id":"http://arxiv.org/abs/2209.15558v2","updated":"2023-03-07T22:05:28Z","published":"2022-09-30T16:17:11Z","title":"Out-of-Distribution Detection and Selective Generation for Conditional\n  Language Models","summary":"  Machine learning algorithms typically assume independent and identically\ndistributed samples in training and at test time. Much work has shown that\nhigh-performing ML classifiers can degrade significantly and provide\noverly-confident, wrong classification predictions, particularly for\nout-of-distribution (OOD) inputs. Conditional language models (CLMs) are\npredominantly trained to classify the next token in an output sequence, and may\nsuffer even worse degradation on OOD inputs as the prediction is done\nauto-regressively over many steps. Furthermore, the space of potential\nlow-quality outputs is larger as arbitrary text can be generated and it is\nimportant to know when to trust the generated output. We present a highly\naccurate and lightweight OOD detection method for CLMs, and demonstrate its\neffectiveness on abstractive summarization and translation. We also show how\nour method can be used under the common and realistic setting of distribution\nshift for selective generation (analogous to selective prediction for\nclassification) of high-quality outputs, while automatically abstaining from\nlow-quality ones, enabling safer deployment of generative language models.\n","authors":["Jie Ren","Jiaming Luo","Yao Zhao","Kundan Krishna","Mohammad Saleh","Balaji Lakshminarayanan","Peter J. Liu"],"pdf_url":"https://arxiv.org/pdf/2209.15558v2.pdf","comment":"Published in ICLR 2023"},{"id":"http://arxiv.org/abs/2303.04245v1","updated":"2023-03-07T21:42:17Z","published":"2023-03-07T21:42:17Z","title":"How Do Transformers Learn Topic Structure: Towards a Mechanistic\n  Understanding","summary":"  While the successes of transformers across many domains are indisputable,\naccurate understanding of the learning mechanics is still largely lacking.\nTheir capabilities have been probed on benchmarks which include a variety of\nstructured and reasoning tasks -- but mathematical understanding is lagging\nsubstantially behind. Recent lines of work have begun studying representational\naspects of this question: that is, the size/depth/complexity of attention-based\nnetworks to perform certain tasks. However, there is no guarantee the learning\ndynamics will converge to the constructions proposed. In our paper, we provide\nfine-grained mechanistic understanding of how transformers learn \"semantic\nstructure\", understood as capturing co-occurrence structure of words.\nPrecisely, we show, through a combination of experiments on synthetic data\nmodeled by Latent Dirichlet Allocation (LDA), Wikipedia data, and mathematical\nanalysis that the embedding layer and the self-attention layer encode the\ntopical structure. In the former case, this manifests as higher average inner\nproduct of embeddings between same-topic words. In the latter, it manifests as\nhigher average pairwise attention between same-topic words. The mathematical\nresults involve several assumptions to make the analysis tractable, which we\nverify on data, and might be of independent interest as well.\n","authors":["Yuchen Li","Yuanzhi Li","Andrej Risteski"],"pdf_url":"https://arxiv.org/pdf/2303.04245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08841v2","updated":"2023-03-07T20:51:26Z","published":"2022-12-17T10:43:25Z","title":"AugTriever: Unsupervised Dense Retrieval by Scalable Data Augmentation","summary":"  Dense retrievers have made significant strides in text retrieval and\nopen-domain question answering, even though most achievements were made\npossible only with large amounts of human supervision. In this work, we aim to\ndevelop unsupervised methods by proposing two methods that create pseudo\nquery-document pairs and train dense retrieval models in an annotation-free and\nscalable manner: query extraction and transferred query generation. The former\nmethod produces pseudo queries by selecting salient spans from the original\ndocument. The latter utilizes generation models trained for other NLP tasks\n(e.g., summarization) to produce pseudo queries. Extensive experiments show\nthat models trained with the proposed augmentation methods can perform\ncomparably well (or better) to multiple strong baselines. Combining those\nstrategies leads to further improvements, achieving the state-of-the-art\nperformance of unsupervised dense retrieval on both BEIR and ODQA datasets.\n","authors":["Rui Meng","Ye Liu","Semih Yavuz","Divyansh Agarwal","Lifu Tu","Ning Yu","Jianguo Zhang","Meghana Bhat","Yingbo Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.08841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04226v1","updated":"2023-03-07T20:36:13Z","published":"2023-03-07T20:36:13Z","title":"A Comprehensive Survey of AI-Generated Content (AIGC): A History of\n  Generative AI from GAN to ChatGPT","summary":"  Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant\nattention from society. As a result, many individuals have become interested in\nrelated resources and are seeking to uncover the background and secrets behind\nits impressive performance. In fact, ChatGPT and other Generative AI (GAI)\ntechniques belong to the category of Artificial Intelligence Generated Content\n(AIGC), which involves the creation of digital content, such as images, music,\nand natural language, through AI models. The goal of AIGC is to make the\ncontent creation process more efficient and accessible, allowing for the\nproduction of high-quality content at a faster pace. AIGC is achieved by\nextracting and understanding intent information from instructions provided by\nhuman, and generating the content according to its knowledge and the intent\ninformation. In recent years, large-scale models have become increasingly\nimportant in AIGC as they provide better intent extraction and thus, improved\ngeneration results. With the growth of data and the size of the models, the\ndistribution that the model can learn becomes more comprehensive and closer to\nreality, leading to more realistic and high-quality content generation. This\nsurvey provides a comprehensive review on the history of generative models, and\nbasic components, recent advances in AIGC from unimodal interaction and\nmultimodal interaction. From the perspective of unimodality, we introduce the\ngeneration tasks and relative models of text and image. From the perspective of\nmultimodality, we introduce the cross-application between the modalities\nmentioned above. Finally, we discuss the existing open problems and future\nchallenges in AIGC.\n","authors":["Yihan Cao","Siyu Li","Yixin Liu","Zhiling Yan","Yutong Dai","Philip S. Yu","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2303.04226v1.pdf","comment":"44 pages, 15 figures"},{"id":"http://arxiv.org/abs/2303.04222v1","updated":"2023-03-07T20:28:39Z","published":"2023-03-07T20:28:39Z","title":"SemEval-2023 Task 10: Explainable Detection of Online Sexism","summary":"  Online sexism is a widespread and harmful phenomenon. Automated tools can\nassist the detection of sexism at scale. Binary detection, however, disregards\nthe diversity of sexist content, and fails to provide clear explanations for\nwhy something is sexist. To address this issue, we introduce SemEval Task 10 on\nthe Explainable Detection of Online Sexism (EDOS). We make three main\ncontributions: i) a novel hierarchical taxonomy of sexist content, which\nincludes granular vectors of sexism to aid explainability; ii) a new dataset of\n20,000 social media comments with fine-grained labels, along with larger\nunlabelled datasets for model adaptation; and iii) baseline models as well as\nan analysis of the methods, results and errors for participant submissions to\nour task.\n","authors":["Hannah Rose Kirk","Wenjie Yin","Bertie Vidgen","Paul Röttger"],"pdf_url":"https://arxiv.org/pdf/2303.04222v1.pdf","comment":"SemEval-2023 Task 10 (ACL 2023)"},{"id":"http://arxiv.org/abs/2303.04185v1","updated":"2023-03-07T19:12:31Z","published":"2023-03-07T19:12:31Z","title":"Gradient-Free Structured Pruning with Unlabeled Data","summary":"  Large Language Models (LLMs) have achieved great success in solving difficult\ntasks across many domains, but such success comes with a high computation cost,\nand inference latency. As developers and third parties customize these models,\nthe need to provide efficient inference has increased. Many efforts have\nattempted to reduce inference cost through model compression techniques such as\npruning and distillation. However, these techniques either require labeled\ndata, or are time-consuming as they require the compressed model to be\nretrained to regain accuracy. In this paper, we propose a gradient-free\nstructured pruning framework that uses only unlabeled data. An evaluation on\nthe GLUE and SQuAD benchmarks using BERT$_{BASE}$ and DistilBERT illustrates\nthe effectiveness of the proposed approach. By only using the weights of the\npre-trained model and unlabeled data, in a matter of a few minutes on a single\nGPU, up to 40% of the original FLOP count can be reduced with less than a 4%\naccuracy loss across all tasks considered.\n","authors":["Azade Nova","Hanjun Dai","Dale Schuurmans"],"pdf_url":"https://arxiv.org/pdf/2303.04185v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05279v1","updated":"2023-03-07T22:05:31Z","published":"2023-03-07T22:05:31Z","title":"Can large language models build causal graphs?","summary":"  Building causal graphs can be a laborious process. To ensure all relevant\ncausal pathways have been captured, researchers often have to discuss with\nclinicians and experts while also reviewing extensive relevant medical\nliterature. By encoding common and medical knowledge, large language models\n(LLMs) represent an opportunity to ease this process by automatically scoring\nedges (i.e., connections between two variables) in potential graphs. LLMs\nhowever have been shown to be brittle to the choice of probing words, context,\nand prompts that the user employs. In this work, we evaluate if LLMs can be a\nuseful tool in complementing causal graph development.\n","authors":["Stephanie Long","Tibor Schuster","Alexandre Piché","Department of Family Medicine","McGill University"," Mila","Université de Montreal","ServiceNow Research"],"pdf_url":"https://arxiv.org/pdf/2303.05279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05352v1","updated":"2023-03-07T17:54:53Z","published":"2023-03-07T17:54:53Z","title":"Extracting Accurate Materials Data from Research Papers with\n  Conversational Language Models and Prompt Engineering -- Example of ChatGPT","summary":"  There has been a growing effort to replace hand extraction of data from\nresearch papers with automated data extraction based on natural language\nprocessing (NLP), language models (LMs), and recently, large language models\n(LLMs). Although these methods enable efficient extraction of data from large\nsets of research papers, they require a significant amount of up-front effort,\nexpertise, and coding. In this work we propose the ChatExtract method that can\nfully automate very accurate data extraction with essentially no initial effort\nor background using an advanced conversational LLM (or AI). ChatExtract\nconsists of a set of engineered prompts applied to a conversational LLM that\nboth identify sentences with data, extract data, and assure its correctness\nthrough a series of follow-up questions. These follow-up questions address a\ncritical challenge associated with LLMs - their tendency to provide factually\ninaccurate responses. ChatExtract can be applied with any conversational LLMs\nand yields very high quality data extraction. In tests on materials data we\nfind precision and recall both over 90% from the best conversational LLMs,\nlikely rivaling or exceeding human accuracy in many cases. We demonstrate that\nthe exceptional performance is enabled by the information retention in a\nconversational model combined with purposeful redundancy and introducing\nuncertainty through follow-up prompts. These results suggest that approaches\nsimilar to ChatExtract, due to their simplicity, transferability and accuracy\nare likely to replace other methods of data extraction in the near future.\n","authors":["Maciej P. Polak","Dane Morgan"],"pdf_url":"https://arxiv.org/pdf/2303.05352v1.pdf","comment":"7 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2303.05392v1","updated":"2023-03-07T17:30:48Z","published":"2023-03-07T17:30:48Z","title":"Automatically Summarizing Evidence from Clinical Trials: A Prototype\n  Highlighting Current Challenges","summary":"  We present TrialsSummarizer, a system that aims to automatically summarize\nevidence presented in the set of randomized controlled trials most relevant to\na given query. Building on prior work, the system retrieves trial publications\nmatching a query specifying a combination of condition, intervention(s), and\noutcome(s), and ranks these according to sample size and estimated study\nquality. The top-k such studies are passed through a neural multi-document\nsummarization system, yielding a synopsis of these trials. We consider two\narchitectures: A standard sequence-to-sequence model based on BART and a\nmulti-headed architecture intended to provide greater transparency to\nend-users. Both models produce fluent and relevant summaries of evidence\nretrieved for queries, but their tendency to introduce unsupported statements\nrender them inappropriate for use in this domain at present. The proposed\narchitecture may help users verify outputs allowing users to trace generated\ntokens back to inputs.\n","authors":["Sanjana Ramprasad","Denis Jered McInerney","Iain J. Marshal","Byron C. Wallace"],"pdf_url":"https://arxiv.org/pdf/2303.05392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05383v1","updated":"2023-03-07T16:44:29Z","published":"2023-03-07T16:44:29Z","title":"Making a Computational Attorney","summary":"  This \"blue sky idea\" paper outlines the opportunities and challenges in data\nmining and machine learning involving making a computational attorney -- an\nintelligent software agent capable of helping human lawyers with a wide range\nof complex high-level legal tasks such as drafting legal briefs for the\nprosecution or defense in court. In particular, we discuss what a ChatGPT-like\nLarge Legal Language Model (L$^3$M) can and cannot do today, which will inspire\nresearchers with promising short-term and long-term research objectives.\n","authors":["Dell Zhang","Frank Schilder","Jack G. Conrad","Masoud Makrehchi","David von Rickenbach","Isabelle Moulinier"],"pdf_url":"https://arxiv.org/pdf/2303.05383v1.pdf","comment":"To be published in the Proceedings of the 2023 SIAM International\n  Conference on Data Mining (SDM'23)"},{"id":"http://arxiv.org/abs/2303.05391v1","updated":"2023-03-07T15:07:57Z","published":"2023-03-07T15:07:57Z","title":"Disambiguation of Company names via Deep Recurrent Networks","summary":"  Name Entity Disambiguation is the Natural Language Processing task of\nidentifying textual records corresponding to the same Named Entity, i.e.\nreal-world entities represented as a list of attributes (names, places,\norganisations, etc.). In this work, we face the task of disambiguating\ncompanies on the basis of their written names. We propose a Siamese LSTM\nNetwork approach to extract -- via supervised learning -- an embedding of\ncompany name strings in a (relatively) low dimensional vector space and use\nthis representation to identify pairs of company names that actually represent\nthe same company (i.e. the same Entity).\n  Given that the manual labelling of string pairs is a rather onerous task, we\nanalyse how an Active Learning approach to prioritise the samples to be\nlabelled leads to a more efficient overall learning pipeline.\n  With empirical investigations, we show that our proposed Siamese Network\noutperforms several benchmark approaches based on standard string matching\nalgorithms when enough labelled data are available. Moreover, we show that\nActive Learning prioritisation is indeed helpful when labelling resources are\nlimited, and let the learning models reach the out-of-sample performance\nsaturation with less labelled data with respect to standard (random) data\nlabelling approaches.\n","authors":["Alessandro Basile","Riccardo Crupi","Michele Grasso","Alessandro Mercanti","Daniele Regoli","Simone Scarsi","Shuyi Yang","Andrea Cosentini"],"pdf_url":"https://arxiv.org/pdf/2303.05391v1.pdf","comment":"submitted to Elsevier. 26 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2303.05388v1","updated":"2023-03-07T11:54:39Z","published":"2023-03-07T11:54:39Z","title":"German BERT Model for Legal Named Entity Recognition","summary":"  The use of BERT, one of the most popular language models, has led to\nimprovements in many Natural Language Processing (NLP) tasks. One such task is\nNamed Entity Recognition (NER) i.e. automatic identification of named entities\nsuch as location, person, organization, etc. from a given text. It is also an\nimportant base step for many NLP tasks such as information extraction and\nargumentation mining. Even though there is much research done on NER using BERT\nand other popular language models, the same is not explored in detail when it\ncomes to Legal NLP or Legal Tech. Legal NLP applies various NLP techniques such\nas sentence similarity or NER specifically on legal data. There are only a\nhandful of models for NER tasks using BERT language models, however, none of\nthese are aimed at legal documents in German. In this paper, we fine-tune a\npopular BERT language model trained on German data (German BERT) on a Legal\nEntity Recognition (LER) dataset. To make sure our model is not overfitting, we\nperformed a stratified 10-fold cross-validation. The results we achieve by\nfine-tuning German BERT on the LER dataset outperform the BiLSTM-CRF+ model\nused by the authors of the same LER dataset. Finally, we make the model openly\navailable via HuggingFace.\n","authors":["Harshil Darji","Jelena Mitrović","Michael Granitzer"],"pdf_url":"https://arxiv.org/pdf/2303.05388v1.pdf","comment":"Presented at ICAART 2023"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.04143v1","updated":"2023-03-07T18:56:59Z","published":"2023-03-07T18:56:59Z","title":"Can We Scale Transformers to Predict Parameters of Diverse ImageNet\n  Models?","summary":"  Pretraining a neural network on a large dataset is becoming a cornerstone in\nmachine learning that is within the reach of only a few communities with\nlarge-resources. We aim at an ambitious goal of democratizing pretraining.\nTowards that goal, we train and release a single neural network that can\npredict high quality ImageNet parameters of other neural networks. By using\npredicted parameters for initialization we are able to boost training of\ndiverse ImageNet models available in PyTorch. When transferred to other\ndatasets, models initialized with predicted parameters also converge faster and\nreach competitive final performance.\n","authors":["Boris Knyazev","Doha Hwang","Simon Lacoste-Julien"],"pdf_url":"https://arxiv.org/pdf/2303.04143v1.pdf","comment":"Code and models are available at\n  https://github.com/SamsungSAILMontreal/ghn3"},{"id":"http://arxiv.org/abs/2303.04116v1","updated":"2023-03-07T18:28:41Z","published":"2023-03-07T18:28:41Z","title":"TrafficBots: Towards World Models for Autonomous Driving Simulation and\n  Motion Prediction","summary":"  Data-driven simulation has become a favorable way to train and test\nautonomous driving algorithms. The idea of replacing the actual environment\nwith a learned simulator has also been explored in model-based reinforcement\nlearning in the context of world models. In this work, we show data-driven\ntraffic simulation can be formulated as a world model. We present TrafficBots,\na multi-agent policy built upon motion prediction and end-to-end driving, and\nbased on TrafficBots we obtain a world model tailored for the planning module\nof autonomous vehicles. Existing data-driven traffic simulators are lacking\nconfigurability and scalability. To generate configurable behaviors, for each\nagent we introduce a destination as navigational information, and a\ntime-invariant latent personality that specifies the behavioral style. To\nimprove the scalability, we present a new scheme of positional encoding for\nangles, allowing all agents to share the same vectorized context and the use of\nan architecture based on dot-product attention. As a result, we can simulate\nall traffic participants seen in dense urban scenarios. Experiments on the\nWaymo open motion dataset show TrafficBots can simulate realistic multi-agent\nbehaviors and achieve good performance on the motion prediction task.\n","authors":["Zhejun Zhang","Alexander Liniger","Dengxin Dai","Fisher Yu","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2303.04116v1.pdf","comment":"Accepted at ICRA 2023. The repository is available at\n  https://github.com/SysCV/TrafficBots"},{"id":"http://arxiv.org/abs/2303.04115v1","updated":"2023-03-07T18:28:39Z","published":"2023-03-07T18:28:39Z","title":"Predicted Embedding Power Regression for Large-Scale Out-of-Distribution\n  Detection","summary":"  Out-of-distribution (OOD) inputs can compromise the performance and safety of\nreal world machine learning systems. While many methods exist for OOD detection\nand work well on small scale datasets with lower resolution and few classes,\nfew methods have been developed for large-scale OOD detection. Existing\nlarge-scale methods generally depend on maximum classification probability,\nsuch as the state-of-the-art grouped softmax method. In this work, we develop a\nnovel approach that calculates the probability of the predicted class label\nbased on label distributions learned during the training process. Our method\nperforms better than current state-of-the-art methods with only a negligible\nincrease in compute cost. We evaluate our method against contemporary methods\nacross $14$ datasets and achieve a statistically significant improvement with\nrespect to AUROC (84.2 vs 82.4) and AUPR (96.2 vs 93.7).\n","authors":["Hong Yang","William Gebhardt","Alexander G. Ororbia","Travis Desell"],"pdf_url":"https://arxiv.org/pdf/2303.04115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04105v1","updated":"2023-03-07T18:12:24Z","published":"2023-03-07T18:12:24Z","title":"Introspective Cross-Attention Probing for Lightweight Transfer of\n  Pre-trained Models","summary":"  We propose InCA, a lightweight method for transfer learning that\ncross-attends to any activation layer of a pre-trained model. During training,\nInCA uses a single forward pass to extract multiple activations, which are\npassed to external cross-attention adapters, trained anew and combined or\nselected for downstream tasks. We show that, even when selecting a single\ntop-scoring adapter, InCA achieves performance comparable to full fine-tuning,\nat a cost comparable to fine-tuning just the last layer. For example, with a\ncross-attention probe 1.3% the size of a pre-trained ViT-L/16 model, we achieve\nperformance within 0.2% of the full fine-tuning paragon at 51% training cost of\nthe baseline, on average across 11 downstream classification tasks. Unlike\nother forms of efficient adaptation, InCA does not require backpropagating\nthrough the pre-trained model, thus leaving its execution unaltered at both\ntraining and inference. The versatility of InCA is best illustrated in\nfine-grained tasks, which may require accessing information absent in the last\nlayer but accessible in intermediate layer activations. Since the backbone is\nfixed, InCA allows parallel ensembling as well as parallel execution of\nmultiple tasks. InCA achieves state-of-the-art performance in the\nImageNet-to-Sketch multi-task benchmark.\n","authors":["Yonatan Dukler","Alessandro Achille","Hao Yang","Varsha Vivek","Luca Zancato","Ben Bowman","Avinash Ravichandran","Charless Fowlkes","Ashwin Swaminathan","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2303.04105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04086v1","updated":"2023-03-07T17:47:33Z","published":"2023-03-07T17:47:33Z","title":"NEPHELE: A Neural Platform for Highly Realistic Cloud Radiance Rendering","summary":"  We have recently seen tremendous progress in neural rendering (NR) advances,\ni.e., NeRF, for photo-real free-view synthesis. Yet, as a local technique based\non a single computer/GPU, even the best-engineered Instant-NGP or i-NGP cannot\nreach real-time performance when rendering at a high resolution, and often\nrequires huge local computing resources. In this paper, we resort to cloud\nrendering and present NEPHELE, a neural platform for highly realistic cloud\nradiance rendering. In stark contrast with existing NR approaches, our NEPHELE\nallows for more powerful rendering capabilities by combining multiple remote\nGPUs and facilitates collaboration by allowing multiple people to view the same\nNeRF scene simultaneously. We introduce i-NOLF to employ opacity light fields\nfor ultra-fast neural radiance rendering in a one-query-per-ray manner. We\nfurther resemble the Lumigraph with geometry proxies for fast ray querying and\nsubsequently employ a small MLP to model the local opacity lumishperes for\nhigh-quality rendering. We also adopt Perfect Spatial Hashing in i-NOLF to\nenhance cache coherence. As a result, our i-NOLF achieves an order of magnitude\nperformance gain in terms of efficiency than i-NGP, especially for the\nmulti-user multi-viewpoint setting under cloud rendering scenarios. We further\ntailor a task scheduler accompanied by our i-NOLF representation and\ndemonstrate the advance of our methodological design through a comprehensive\ncloud platform, consisting of a series of cooperated modules, i.e., render\nfarms, task assigner, frame composer, and detailed streaming strategies. Using\nsuch a cloud platform compatible with neural rendering, we further showcase the\ncapabilities of our cloud radiance rendering through a series of applications,\nranging from cloud VR/AR rendering.\n","authors":["Haimin Luo","Siyuan Zhang","Fuqiang Zhao","Haotian Jing","Penghao Wang","Zhenxiao Yu","Dongxue Yan","Junran Ding","Boyuan Zhang","Qiang Hu","Shu Yin","Lan Xu","JIngyi Yu"],"pdf_url":"https://arxiv.org/pdf/2303.04086v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04077v1","updated":"2023-03-07T17:39:53Z","published":"2023-03-07T17:39:53Z","title":"Meta-Explore: Exploratory Hierarchical Vision-and-Language Navigation\n  Using Scene Object Spectrum Grounding","summary":"  The main challenge in vision-and-language navigation (VLN) is how to\nunderstand natural-language instructions in an unseen environment. The main\nlimitation of conventional VLN algorithms is that if an action is mistaken, the\nagent fails to follow the instructions or explores unnecessary regions, leading\nthe agent to an irrecoverable path. To tackle this problem, we propose\nMeta-Explore, a hierarchical navigation method deploying an exploitation policy\nto correct misled recent actions. We show that an exploitation policy, which\nmoves the agent toward a well-chosen local goal among unvisited but observable\nstates, outperforms a method which moves the agent to a previously visited\nstate. We also highlight the demand for imagining regretful explorations with\nsemantically meaningful clues. The key to our approach is understanding the\nobject placements around the agent in spectral-domain. Specifically, we present\na novel visual representation, called scene object spectrum (SOS), which\nperforms category-wise 2D Fourier transform of detected objects. Combining\nexploitation policy and SOS features, the agent can correct its path by\nchoosing a promising local goal. We evaluate our method in three VLN\nbenchmarks: R2R, SOON, and REVERIE. Meta-Explore outperforms other baselines\nand shows significant generalization performance. In addition, local goal\nsearch using the proposed spectral-domain SOS features significantly improves\nthe success rate by 17.1% and SPL by 20.6% for the SOON benchmark.\n","authors":["Minyoung Hwang","Jaeyeon Jeong","Minsoo Kim","Yoonseon Oh","Songhwai Oh"],"pdf_url":"https://arxiv.org/pdf/2303.04077v1.pdf","comment":"Accepted by CVPR 2023. Project page:\n  https://rllab-snu.github.io/projects/Meta-Explore/doc.html"},{"id":"http://arxiv.org/abs/2303.04068v1","updated":"2023-03-07T17:26:04Z","published":"2023-03-07T17:26:04Z","title":"VOCALExplore: Pay-as-You-Go Video Data Exploration and Model Building","summary":"  We introduce VOCALExplore, a system designed to support users in building\ndomain-specific models over video datasets. VOCALExplore supports interactive\nlabeling sessions and trains models using user-supplied labels. VOCALExplore\nmaximizes model quality by automatically deciding how to select samples based\non observed skew in the collected labels. It also selects the optimal video\nrepresentations to use when training models by casting feature selection as a\nrising bandit problem. Finally, VOCALExplore implements optimizations to\nachieve low latency without sacrificing model performance. We demonstrate that\nVOCALExplore achieves close to the best possible model quality given candidate\nacquisition functions and feature extractors, and it does so with low visible\nlatency (~1 second per iteration) and no expensive preprocessing.\n","authors":["Maureen Daum","Enhao Zhang","Dong He","Stephen Mussmann","Brandon Haynes","Ranjay Krishna","Magdalena Balazinska"],"pdf_url":"https://arxiv.org/pdf/2303.04068v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.07530v3","updated":"2023-03-07T17:24:32Z","published":"2022-03-14T22:34:10Z","title":"TTCDist: Fast Distance Estimation From an Active Monocular Camera Using\n  Time-to-Contact","summary":"  Distance estimation from vision is fundamental for a myriad of robotic\napplications such as navigation, manipulation, and planning. Inspired by the\nmammal's visual system, which gazes at specific objects, we develop two novel\nconstraints relating time-to-contact, acceleration, and distance that we call\nthe $\\tau$-constraint and $\\Phi$-constraint. They allow an active (moving)\ncamera to estimate depth efficiently and accurately while using only a small\nportion of the image. The constraints are applicable to range sensing, sensor\nfusion, and visual servoing.\n  We successfully validate the proposed constraints with two experiments. The\nfirst applies both constraints in a trajectory estimation task with a monocular\ncamera and an Inertial Measurement Unit (IMU). Our methods achieve 30-70% less\naverage trajectory error while running 25$\\times$ and 6.2$\\times$ faster than\nthe popular Visual-Inertial Odometry methods VINS-Mono and ROVIO respectively.\nThe second experiment demonstrates that when the constraints are used for\nfeedback with efference copies the resulting closed loop system's eigenvalues\nare invariant to scaling of the applied control signal. We believe these\nresults indicate the $\\tau$ and $\\Phi$ constraint's potential as the basis of\nrobust and efficient algorithms for a multitude of robotic applications.\n","authors":["Levi Burner","Nitin J. Sanket","Cornelia Fermüller","Yiannis Aloimonos"],"pdf_url":"https://arxiv.org/pdf/2203.07530v3.pdf","comment":"19 pages, 24 figures, 1 table. To be published in ICRA 2023"},{"id":"http://arxiv.org/abs/2212.12053v2","updated":"2023-03-07T16:41:02Z","published":"2022-12-22T22:05:16Z","title":"On Calibrating Semantic Segmentation Models: Analyses and An Algorithm","summary":"  We study the problem of semantic segmentation calibration. For image\nclassification, lots of existing solutions are proposed to alleviate model\nmiscalibration of confidence. However, to date, confidence calibration research\non semantic segmentation is still limited. We provide a systematic study on the\ncalibration of semantic segmentation models and propose a simple yet effective\napproach. First, we find that model capacity, crop size, multi-scale testing,\nand prediction correctness have impact on calibration. Among them, prediction\ncorrectness, especially misprediction, is more important to miscalibration due\nto over-confidence. Next, we propose a simple, unifying, and effective\napproach, namely selective scaling, by separating correct/incorrect prediction\nfor scaling and more focusing on misprediction logit smoothing. Then, we study\npopular existing calibration methods and compare them with selective scaling on\nsemantic segmentation calibration. We conduct extensive experiments with a\nvariety of benchmarks on both in-domain and domain-shift calibration, and show\nthat selective scaling consistently outperforms other methods.\n","authors":["Dongdong Wang","Boqing Gong","Liqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.12053v2.pdf","comment":"Accepted to CVPR2023 (8 pages, 4 figures)"},{"id":"http://arxiv.org/abs/2303.04025v1","updated":"2023-03-07T16:38:50Z","published":"2023-03-07T16:38:50Z","title":"DeepSeeColor: Realtime Adaptive Color Correction for Autonomous\n  Underwater Vehicles via Deep Learning Methods","summary":"  Successful applications of complex vision-based behaviours underwater have\nlagged behind progress in terrestrial and aerial domains. This is largely due\nto the degraded image quality resulting from the physical phenomena involved in\nunderwater image formation. Spectrally-selective light attenuation drains some\ncolors from underwater images while backscattering adds others, making it\nchallenging to perform vision-based tasks underwater. State-of-the-art methods\nfor underwater color correction optimize the parameters of image formation\nmodels to restore the full spectrum of color to underwater imagery. However,\nthese methods have high computational complexity that is unfavourable for\nrealtime use by autonomous underwater vehicles (AUVs), as a result of having\nbeen primarily designed for offline color correction. Here, we present\nDeepSeeColor, a novel algorithm that combines a state-of-the-art underwater\nimage formation model with the computational efficiency of deep learning\nframeworks. In our experiments, we show that DeepSeeColor offers comparable\nperformance to the popular \"Sea-Thru\" algorithm (Akkaynak & Treibitz, 2019)\nwhile being able to rapidly process images at up to 60Hz, thus making it\nsuitable for use onboard AUVs as a preprocessing step to enable more robust\nvision-based behaviours.\n","authors":["Stewart Jamieson","Jonathan P. How","Yogesh Girdhar"],"pdf_url":"https://arxiv.org/pdf/2303.04025v1.pdf","comment":"7 pages, 5 figures, 2 tables. Presented at the 2023 International\n  Conference on Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2303.04016v1","updated":"2023-03-07T16:31:13Z","published":"2023-03-07T16:31:13Z","title":"Decoupling Skill Learning from Robotic Control for Generalizable Object\n  Manipulation","summary":"  Recent works in robotic manipulation through reinforcement learning (RL) or\nimitation learning (IL) have shown potential for tackling a range of tasks\ne.g., opening a drawer or a cupboard. However, these techniques generalize\npoorly to unseen objects. We conjecture that this is due to the\nhigh-dimensional action space for joint control. In this paper, we take an\nalternative approach and separate the task of learning 'what to do' from 'how\nto do it' i.e., whole-body control. We pose the RL problem as one of\ndetermining the skill dynamics for a disembodied virtual manipulator\ninteracting with articulated objects. The whole-body robotic kinematic control\nis optimized to execute the high-dimensional joint motion to reach the goals in\nthe workspace. It does so by solving a quadratic programming (QP) model with\nrobotic singularity and kinematic constraints. Our experiments on manipulating\ncomplex articulated objects show that the proposed approach is more\ngeneralizable to unseen objects with large intra-class variations,\noutperforming previous approaches. The evaluation results indicate that our\napproach generates more compliant robotic motion and outperforms the pure RL\nand IL baselines in task success rates.\n","authors":["Kai Lu","Bo Yang","Bing Wang","Andrew Markham"],"pdf_url":"https://arxiv.org/pdf/2303.04016v1.pdf","comment":"Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2211.09019v2","updated":"2023-03-07T16:29:49Z","published":"2022-11-16T16:26:48Z","title":"Learning Reward Functions for Robotic Manipulation by Observing Humans","summary":"  Observing a human demonstrator manipulate objects provides a rich, scalable\nand inexpensive source of data for learning robotic policies. However,\ntransferring skills from human videos to a robotic manipulator poses several\nchallenges, not least a difference in action and observation spaces. In this\nwork, we use unlabeled videos of humans solving a wide range of manipulation\ntasks to learn a task-agnostic reward function for robotic manipulation\npolicies. Thanks to the diversity of this training data, the learned reward\nfunction sufficiently generalizes to image observations from a previously\nunseen robot embodiment and environment to provide a meaningful prior for\ndirected exploration in reinforcement learning. We propose two methods for\nscoring states relative to a goal image: through direct temporal regression,\nand through distances in an embedding space obtained with time-contrastive\nlearning. By conditioning the function on a goal image, we are able to reuse\none model across a variety of tasks. Unlike prior work on leveraging human\nvideos to teach robots, our method, Human Offline Learned Distances (HOLD)\nrequires neither a priori data from the robot environment, nor a set of\ntask-specific human demonstrations, nor a predefined notion of correspondence\nacross morphologies, yet it is able to accelerate training of several\nmanipulation tasks on a simulated robot arm compared to using only a sparse\nreward obtained from task completion.\n","authors":["Minttu Alakuijala","Gabriel Dulac-Arnold","Julien Mairal","Jean Ponce","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2211.09019v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04001v1","updated":"2023-03-07T16:00:26Z","published":"2023-03-07T16:00:26Z","title":"ELODIN: Naming Concepts in Embedding Spaces","summary":"  Despite recent advancements, the field of text-to-image synthesis still\nsuffers from lack of fine-grained control. Using only text, it remains\nchallenging to deal with issues such as concept coherence and concept\ncontamination. We propose a method to enhance control by generating specific\nconcepts that can be reused throughout multiple images, effectively expanding\nnatural language with new words that can be combined much like a painter's\npalette. Unlike previous contributions, our method does not copy visuals from\ninput data and can generate concepts through text alone. We perform a set of\ncomparisons that finds our method to be a significant improvement over\ntext-only prompts.\n","authors":["Rodrigo Mello","Filipe Calegario","Geber Ramalho"],"pdf_url":"https://arxiv.org/pdf/2303.04001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13007v2","updated":"2023-03-07T15:56:14Z","published":"2022-10-24T07:55:57Z","title":"Iterative Patch Selection for High-Resolution Image Recognition","summary":"  High-resolution images are prevalent in various applications, such as\nautonomous driving and computer-aided diagnosis. However, training neural\nnetworks on such images is computationally challenging and easily leads to\nout-of-memory errors even on modern GPUs. We propose a simple method, Iterative\nPatch Selection (IPS), which decouples the memory usage from the input size and\nthus enables the processing of arbitrarily large images under tight hardware\nconstraints. IPS achieves this by selecting only the most salient patches,\nwhich are then aggregated into a global representation for image recognition.\nFor both patch selection and aggregation, a cross-attention based transformer\nis introduced, which exhibits a close connection to Multiple Instance Learning.\nOur method demonstrates strong performance and has wide applicability across\ndifferent domains, training regimes and image sizes while using minimal\naccelerator memory. For example, we are able to finetune our model on\nwhole-slide images consisting of up to 250k patches (>16 gigapixels) with only\n5 GB of GPU VRAM at a batch size of 16.\n","authors":["Benjamin Bergner","Christoph Lippert","Aravindh Mahendran"],"pdf_url":"https://arxiv.org/pdf/2210.13007v2.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03991v1","updated":"2023-03-07T15:43:39Z","published":"2023-03-07T15:43:39Z","title":"OpenOccupancy: A Large Scale Benchmark for Surrounding Semantic\n  Occupancy Perception","summary":"  Semantic occupancy perception is essential for autonomous driving, as\nautomated vehicles require a fine-grained perception of the 3D urban\nstructures. However, existing relevant benchmarks lack diversity in urban\nscenes, and they only evaluate front-view predictions. Towards a comprehensive\nbenchmarking of surrounding perception algorithms, we propose OpenOccupancy,\nwhich is the first surrounding semantic occupancy perception benchmark. In the\nOpenOccupancy benchmark, we extend the large-scale nuScenes dataset with dense\nsemantic occupancy annotations. Previous annotations rely on LiDAR points\nsuperimposition, where some occupancy labels are missed due to sparse LiDAR\nchannels. To mitigate the problem, we introduce the Augmenting And Purifying\n(AAP) pipeline to ~2x densify the annotations, where ~4000 human hours are\ninvolved in the labeling process. Besides, camera-based, LiDAR-based and\nmulti-modal baselines are established for the OpenOccupancy benchmark.\nFurthermore, considering the complexity of surrounding occupancy perception\nlies in the computational burden of high-resolution 3D predictions, we propose\nthe Cascade Occupancy Network (CONet) to refine the coarse prediction, which\nrelatively enhances the performance by ~30% than the baseline. We hope the\nOpenOccupancy benchmark will boost the development of surrounding occupancy\nperception algorithms.\n","authors":["Xiaofeng Wang","Zheng Zhu","Wenbo Xu","Yunpeng Zhang","Yi Wei","Xu Chi","Yun Ye","Dalong Du","Jiwen Lu","Xingang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03991v1.pdf","comment":"project page: https://github.com/JeffWang987/OpenOccupancy"},{"id":"http://arxiv.org/abs/2303.03988v1","updated":"2023-03-07T15:39:54Z","published":"2023-03-07T15:39:54Z","title":"DINet: Deformation Inpainting Network for Realistic Face Visually\n  Dubbing on High Resolution Video","summary":"  For few-shot learning, it is still a critical challenge to realize\nphoto-realistic face visually dubbing on high-resolution videos. Previous works\nfail to generate high-fidelity dubbing results. To address the above problem,\nthis paper proposes a Deformation Inpainting Network (DINet) for\nhigh-resolution face visually dubbing. Different from previous works relying on\nmultiple up-sample layers to directly generate pixels from latent embeddings,\nDINet performs spatial deformation on feature maps of reference images to\nbetter preserve high-frequency textural details. Specifically, DINet consists\nof one deformation part and one inpainting part. In the first part, five\nreference facial images adaptively perform spatial deformation to create\ndeformed feature maps encoding mouth shapes at each frame, in order to align\nwith the input driving audio and also the head poses of the input source\nimages. In the second part, to produce face visually dubbing, a feature decoder\nis responsible for adaptively incorporating mouth movements from the deformed\nfeature maps and other attributes (i.e., head pose and upper facial expression)\nfrom the source feature maps together. Finally, DINet achieves face visually\ndubbing with rich textural details. We conduct qualitative and quantitative\ncomparisons to validate our DINet on high-resolution videos. The experimental\nresults show that our method outperforms state-of-the-art works.\n","authors":["Zhimeng Zhang","Zhipeng Hu","Wenjin Deng","Changjie Fan","Tangjie Lv","Yu Ding"],"pdf_url":"https://arxiv.org/pdf/2303.03988v1.pdf","comment":"AAAI-23, 9pages"},{"id":"http://arxiv.org/abs/2303.02698v2","updated":"2023-03-07T15:21:14Z","published":"2023-03-05T15:27:24Z","title":"Robust affine feature matching via quadratic assignment on Grassmannians","summary":"  GraNNI (Grassmannians for Nearest Neighbours Identification) a new algorithm\nto solve the problem of affine registration is proposed. The algorithm is based\non the Grassmannian of $k$--dimensional planes in $\\mathbb{R}^n$ and minimizing\nthe Frobenius norm between the two elements of the Grassmannian. The Quadratic\nAssignment Problem (QAP) is used to find the matching. The results of the\nexperiments show that the algorithm is more robust to noise and point\ndiscrepancy in point clouds than previous approaches.\n","authors":["Alexander Kolpakov","Michael Werman"],"pdf_url":"https://arxiv.org/pdf/2303.02698v2.pdf","comment":"12 pages, 18 figures; GitHub repository at\n  (https://github.com/sashakolpakov/granni)"},{"id":"http://arxiv.org/abs/2206.02082v3","updated":"2023-03-07T15:17:57Z","published":"2022-06-05T01:43:52Z","title":"Towards Fast Adaptation of Pretrained Contrastive Models for\n  Multi-channel Video-Language Retrieval","summary":"  Multi-channel video-language retrieval require models to understand\ninformation from different channels (e.g. video$+$question, video$+$speech) to\ncorrectly link a video with a textual response or query. Fortunately,\ncontrastive multimodal models have been shown to be highly effective at\naligning entities in images/videos and text, e.g., CLIP; text contrastive\nmodels have been extensively studied recently for their strong ability of\nproducing discriminative sentence embeddings, e.g., SimCSE. Their abilities are\nexactly needed by multi-channel video-language retrieval. However, there is not\na clear way to quickly adapt these two lines to multi-channel video-language\nretrieval with limited data and resources. In this paper, we identify a\nprincipled model design space with two axes: how to represent videos and how to\nfuse video and text information. Based on categorization of recent methods, we\ninvestigate the options of representing videos using continuous feature vectors\nor discrete text tokens; for the fusion method, we explore the use of a\nmultimodal transformer or a pretrained contrastive text model. We extensively\nevaluate the four combinations on five video-language datasets. We surprisingly\nfind that discrete text tokens coupled with a pretrained contrastive text model\nyields the best performance, which can even outperform state-of-the-art on the\niVQA and How2QA datasets without the additional training on millions of\nvideo-language data. Further analysis shows that this is because representing\nvideos as text tokens captures the key visual information with text tokens that\nare naturally aligned with text models and the text models are strong\nmultimodal retriever after the contrastive pretraining process.\n","authors":["Xudong Lin","Simran Tiwari","Shiyuan Huang","Manling Li","Mike Zheng Shou","Heng Ji","Shih-Fu Chang"],"pdf_url":"https://arxiv.org/pdf/2206.02082v3.pdf","comment":"To appear in CVPR 2023"},{"id":"http://arxiv.org/abs/2302.10768v2","updated":"2023-03-07T15:11:10Z","published":"2023-01-19T11:11:57Z","title":"On the Importance of Sign Labeling: The Hamburg Sign Language Notation\n  System Case Study","summary":"  Labeling is the cornerstone of supervised machine learning, which has been\nexploited in a plethora of various applications, with sign language recognition\nbeing one of them. However, such algorithms must be fed with a huge amount of\nconsistently labeled data during the training process to elaborate a\nwell-generalizing model. In addition, there is a great need for an automated\nsolution that works with any nationally diversified sign language. Although\nthere are language-agnostic transcription systems, such as the Hamburg Sign\nLanguage Notation System (HamNoSys) that describe the signer's initial position\nand body movement instead of the glosses' meanings, there are still issues with\nproviding accurate and reliable labels for every real-world use case. In this\ncontext, the industry relies heavily on manual attribution and labeling of the\navailable video data. In this work, we tackle this issue and thoroughly analyze\nthe HamNoSys labels provided by various maintainers of open sign language\ncorpora in five sign languages, in order to examine the challenges encountered\nin labeling video data. We also investigate the consistency and objectivity of\nHamNoSys-based labels for the purpose of training machine learning models. Our\nfindings provide valuable insights into the limitations of the current labeling\nmethods and pave the way for future research on developing more accurate and\nefficient solutions for sign language recognition.\n","authors":["Maria Ferlin","Sylwia Majchrowska","Marta Plantykow","Alicja Kwaśniwska","Agnieszka Mikołajczyk-Bareła","Milena Olech","Jakub Nalepa"],"pdf_url":"https://arxiv.org/pdf/2302.10768v2.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2303.03965v1","updated":"2023-03-07T15:07:43Z","published":"2023-03-07T15:07:43Z","title":"Comparing 3D deformations between longitudinal daily CBCT acquisitions\n  using CNN for head and neck radiotherapy toxicity prediction","summary":"  Adaptive radiotherapy is a growing field of study in cancer treatment due to\nit's objective in sparing healthy tissue. The standard of care in several\ninstitutions includes longitudinal cone-beam computed tomography (CBCT)\nacquisitions to monitor changes, but have yet to be used to improve tumor\ncontrol while managing side-effects. The aim of this study is to demonstrate\nthe clinical value of pre-treatment CBCT acquired daily during radiation\ntherapy treatment for head and neck cancers for the downstream task of\npredicting severe toxicity occurrence: reactive feeding tube (NG),\nhospitalization and radionecrosis. For this, we propose a deformable 3D\nclassification pipeline that includes a component analyzing the Jacobian matrix\nof the deformation between planning CT and longitudinal CBCT, as well as\nclinical data. The model is based on a multi-branch 3D residual convolutional\nneural network, while the CT to CBCT registration is based on a pair of\nVoxelMorph architectures. Accuracies of 85.8% and 75.3% was found for\nradionecrosis and hospitalization, respectively, with similar performance as\nearly as after the first week of treatment. For NG tube risk, performance\nimproves with increasing the timing of the CBCT fraction, reaching 83.1% after\nthe $5_{th}$ week of treatment.\n","authors":["William Trung Le","Chulmin Bang","Philippine Cordelle","Daniel Markel","Phuc Felix Nguyen-Tan","Houda Bahig","Samuel Kadoury"],"pdf_url":"https://arxiv.org/pdf/2303.03965v1.pdf","comment":"11 pages, 3 figures, 2 equations, 2 tables"},{"id":"http://arxiv.org/abs/2302.06650v2","updated":"2023-03-07T15:03:27Z","published":"2023-02-13T19:30:17Z","title":"Surround-View Vision-based 3D Detection for Autonomous Driving: A Survey","summary":"  Vision-based 3D Detection task is fundamental task for the perception of an\nautonomous driving system, which has peaked interest amongst many researchers\nand autonomous driving engineers. However achieving a rather good 3D BEV\n(Bird's Eye View) performance is not an easy task using 2D sensor input-data\nwith cameras. In this paper we provide a literature survey for the existing\nVision Based 3D detection methods, focused on autonomous driving. We have made\ndetailed analysis of over $60$ papers leveraging Vision BEV detections\napproaches and highlighted different sub-groups for detailed understanding of\ncommon trends. Moreover, we have highlighted how the literature and industry\ntrend have moved towards surround-view image based methods and note down\nthoughts on what special cases this method addresses. In conclusion, we provoke\nthoughts of 3D Vision techniques for future research based on shortcomings of\nthe current techniques including the direction of collaborative perception.\n","authors":["Apoorv Singh","Varun Bankiti"],"pdf_url":"https://arxiv.org/pdf/2302.06650v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08231v2","updated":"2023-03-07T14:59:28Z","published":"2023-02-16T11:28:30Z","title":"3M3D: Multi-view, Multi-path, Multi-representation for 3D Object\n  Detection","summary":"  3D visual perception tasks based on multi-camera images are essential for\nautonomous driving systems. Latest work in this field performs 3D object\ndetection by leveraging multi-view images as an input and iteratively enhancing\nobject queries (object proposals) by cross-attending multi-view features.\nHowever, individual backbone features are not updated with multi-view features\nand it stays as a mere collection of the output of the single-image backbone\nnetwork. Therefore we propose 3M3D: A Multi-view, Multi-path,\nMulti-representation for 3D Object Detection where we update both multi-view\nfeatures and query features to enhance the representation of the scene in both\nfine panoramic view and coarse global view. Firstly, we update multi-view\nfeatures by multi-view axis self-attention. It will incorporate panoramic\ninformation in the multi-view features and enhance understanding of the global\nscene. Secondly, we update multi-view features by self-attention of the ROI\n(Region of Interest) windows which encodes local finer details in the features.\nIt will help exchange the information not only along the multi-view axis but\nalso along the other spatial dimension. Lastly, we leverage the fact of\nmulti-representation of queries in different domains to further boost the\nperformance. Here we use sparse floating queries along with dense BEV (Bird's\nEye View) queries, which are later post-processed to filter duplicate\ndetections. Moreover, we show performance improvements on nuScenes benchmark\ndataset on top of our baselines.\n","authors":["Jongwoo Park","Apoorv Singh","Varun Bankiti"],"pdf_url":"https://arxiv.org/pdf/2302.08231v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.13392v3","updated":"2023-03-07T14:56:18Z","published":"2021-02-26T11:01:30Z","title":"Unifying Remote Sensing Image Retrieval and Classification with Robust\n  Fine-tuning","summary":"  Advances in high resolution remote sensing image analysis are currently\nhampered by the difficulty of gathering enough annotated data for training deep\nlearning methods, giving rise to a variety of small datasets and associated\ndataset-specific methods. Moreover, typical tasks such as classification and\nretrieval lack a systematic evaluation on standard benchmarks and training\ndatasets, which make it hard to identify durable and generalizable scientific\ncontributions. We aim at unifying remote sensing image retrieval and\nclassification with a new large-scale training and testing dataset, SF300,\nincluding both vertical and oblique aerial images and made available to the\nresearch community, and an associated fine-tuning method. We additionally\npropose a new adversarial fine-tuning method for global descriptors. We show\nthat our framework systematically achieves a boost of retrieval and\nclassification performance on nine different datasets compared to an ImageNet\npretrained baseline, with currently no other method to compare to.\n","authors":["Dimitri Gominski","Valérie Gouet-Brunet","Liming Chen"],"pdf_url":"https://arxiv.org/pdf/2102.13392v3.pdf","comment":"Performance margin with the proposed method is not statistically\n  significant. Please refer to http://alegoria.ign.fr/en/SF300_dataset if you\n  are interested in the dataset"},{"id":"http://arxiv.org/abs/2303.03943v1","updated":"2023-03-07T14:52:29Z","published":"2023-03-07T14:52:29Z","title":"CUREE: A Curious Underwater Robot for Ecosystem Exploration","summary":"  The current approach to exploring and monitoring complex underwater\necosystems, such as coral reefs, is to conduct surveys using diver-held or\nstatic cameras, or deploying sensor buoys. These approaches often fail to\ncapture the full variation and complexity of interactions between different\nreef organisms and their habitat. The CUREE platform presented in this paper\nprovides a unique set of capabilities in the form of robot behaviors and\nperception algorithms to enable scientists to explore different aspects of an\necosystem. Examples of these capabilities include low-altitude visual surveys,\nsoundscape surveys, habitat characterization, and animal following. We\ndemonstrate these capabilities by describing two field deployments on coral\nreefs in the US Virgin Islands. In the first deployment, we show that CUREE can\nidentify the preferred habitat type of snapping shrimp in a reef through a\ncombination of a visual survey, habitat characterization, and a soundscape\nsurvey. In the second deployment, we demonstrate CUREE's ability to follow\narbitrary animals by separately following a barracuda and stingray for several\nminutes each in midwater and benthic environments, respectively.\n","authors":["ogesh Girdhar","Nathan McGuire","Levi Cai","Stewart Jamieson","Seth McCammon","Brian Claus","John E. San Soucie","Jessica E. Todd","T. Aran Mooney"],"pdf_url":"https://arxiv.org/pdf/2303.03943v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2302.02350v2","updated":"2023-03-07T14:51:01Z","published":"2023-02-05T09:48:57Z","title":"Aggregation of Disentanglement: Reconsidering Domain Variations in\n  Domain Generalization","summary":"  Domain Generalization (DG) is a fundamental challenge for machine learning\nmodels, which aims to improve model generalization on various domains. Previous\nmethods focus on generating domain invariant features from various source\ndomains. However, we argue that the domain variantions also contain useful\ninformation, ie, classification-aware information, for downstream tasks, which\nhas been largely ignored. Different from learning domain invariant features\nfrom source domains, we decouple the input images into Domain Expert Features\nand noise. The proposed domain expert features lie in a learned latent space\nwhere the images in each domain can be classified independently, enabling the\nimplicit use of classification-aware domain variations. Based on the analysis,\nwe proposed a novel paradigm called Domain Disentanglement Network (DDN) to\ndisentangle the domain expert features from the source domain images and\naggregate the source domain expert features for representing the target test\ndomain. We also propound a new contrastive learning method to guide the domain\nexpert features to form a more balanced and separable feature space.\nExperiments on the widely-used benchmarks of PACS, VLCS, OfficeHome, DomainNet,\nand TerraIncognita demonstrate the competitive performance of our method\ncompared to the recently proposed alternatives.\n","authors":["Daoan Zhang","Mingkai Chen","Chenming Li","Lingyun Huang","Jianguo Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.02350v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03003v2","updated":"2023-03-07T14:46:21Z","published":"2023-03-06T10:04:50Z","title":"Efficient Large-scale Scene Representation with a Hybrid of\n  High-resolution Grid and Plane Features","summary":"  Existing neural radiance fields (NeRF) methods for large-scale scene modeling\nrequire days of training using multiple GPUs, hindering their applications in\nscenarios with limited computing resources. Despite fast optimization NeRF\nvariants have been proposed based on the explicit dense or hash grid features,\ntheir effectivenesses are mainly demonstrated in object-scale scene\nrepresentation. In this paper, we point out that the low feature resolution in\nexplicit representation is the bottleneck for large-scale unbounded scene\nrepresentation. To address this problem, we introduce a new and efficient\nhybrid feature representation for NeRF that fuses the 3D hash-grids and\nhigh-resolution 2D dense plane features. Compared with the dense-grid\nrepresentation, the resolution of a dense 2D plane can be scaled up more\nefficiently. Based on this hybrid representation, we propose a fast\noptimization NeRF variant, called GP-NeRF, that achieves better rendering\nresults while maintaining a compact model size. Extensive experiments on\nmultiple large-scale unbounded scene datasets show that our model can converge\nin 1.5 hours using a single GPU while achieving results comparable to or even\nbetter than the existing method that requires about one day's training with 8\nGPUs.\n","authors":["Yuqi Zhang","Guanying Chen","Shuguang Cui"],"pdf_url":"https://arxiv.org/pdf/2303.03003v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15376v2","updated":"2023-03-07T14:45:08Z","published":"2022-09-30T11:09:54Z","title":"NBV-SC: Next Best View Planning based on Shape Completion for Fruit\n  Mapping and Reconstruction","summary":"  Active perception for fruit mapping and harvesting is a difficult task since\nocclusions occur frequently and the location as well as size of fruits change\nover time. State-of-the-art viewpoint planning approaches utilize\ncomputationally expensive ray casting operations to find good viewpoints aiming\nat maximizing information gain and covering the fruits in the scene. In this\npaper, we present a novel viewpoint planning approach that explicitly uses\ninformation about the predicted fruit shapes to compute targeted viewpoints\nthat observe as yet unobserved parts of the fruits. Furthermore, we formulate\nthe concept of viewpoint dissimilarity to reduce the sampling space for more\nefficient selection of useful, dissimilar viewpoints. Our simulation\nexperiments with a UR5e arm equipped with an RGB-D sensor provide a\nquantitative demonstration of the efficacy of our iterative next best view\nplanning method based on shape completion. In comparative experiments with a\nstate-of-the-art viewpoint planner, we demonstrate improvement not only in the\nestimation of the fruit sizes, but also in their reconstruction, while\nsignificantly reducing the planning time. Finally, we show the viability of our\napproach for mapping sweet peppers plants with a real robotic system in a\ncommercial glasshouse.\n","authors":["Rohit Menon","Tobias Zaenker","Nils Dengler","Maren Bennewitz"],"pdf_url":"https://arxiv.org/pdf/2209.15376v2.pdf","comment":"Agricultural Automation, Viewpoint Planning, Active Perception, Shape\n  Completion"},{"id":"http://arxiv.org/abs/2303.03932v1","updated":"2023-03-07T14:38:28Z","published":"2023-03-07T14:38:28Z","title":"FFT-based Dynamic Token Mixer for Vision","summary":"  Multi-head-self-attention (MHSA)-equipped models have achieved notable\nperformance in computer vision. Their computational complexity is proportional\nto quadratic numbers of pixels in input feature maps, resulting in slow\nprocessing, especially when dealing with high-resolution images. New types of\ntoken-mixer are proposed as an alternative to MHSA to circumvent this problem:\nan FFT-based token-mixer, similar to MHSA in global operation but with lower\ncomputational complexity. However, despite its attractive properties, the\nFFT-based token-mixer has not been carefully examined in terms of its\ncompatibility with the rapidly evolving MetaFormer architecture. Here, we\npropose a novel token-mixer called dynamic filter and DFFormer and CDFFormer,\nimage recognition models using dynamic filters to close the gaps above.\nCDFFormer achieved a Top-1 accuracy of 85.0%, close to the hybrid architecture\nwith convolution and MHSA. Other wide-ranging experiments and analysis,\nincluding object detection and semantic segmentation, demonstrate that they are\ncompetitive with state-of-the-art architectures; Their throughput and memory\nefficiency when dealing with high-resolution image recognition is convolution\nand MHSA, not much different from ConvFormer, and far superior to CAFormer. Our\nresults indicate that the dynamic filter is one of the token-mixer options that\nshould be seriously considered. The code is available at\nhttps://github.com/okojoalg/dfformer\n","authors":["Yuki Tatsunami","Masato Taki"],"pdf_url":"https://arxiv.org/pdf/2303.03932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00843v2","updated":"2023-03-07T14:28:56Z","published":"2022-10-03T12:08:09Z","title":"Early or Late Fusion Matters: Efficient RGB-D Fusion in Vision\n  Transformers for 3D Object Recognition","summary":"  The Vision Transformer (ViT) architecture has established its place in\ncomputer vision literature, however, training ViTs for RGB-D object recognition\nremains an understudied topic, viewed in recent literature only through the\nlens of multi-task pretraining in multiple vision modalities. Such approaches\nare often computationally intensive, relying on the scale of multiple\npretraining datasets to align RGB with 3D information. In this work, we propose\na simple yet strong recipe for transferring pretrained ViTs in RGB-D domains\nfor 3D object recognition, focusing on fusing RGB and depth representations\nencoded jointly by the ViT. Compared to previous works in multimodal\nTransformers, the key challenge here is to use the attested flexibility of ViTs\nto capture cross-modal interactions at the downstream and not the pretraining\nstage. We explore which depth representation is better in terms of resulting\naccuracy and compare early and late fusion techniques for aligning the RGB and\ndepth modalities within the ViT architecture. Experimental results in the\nWashington RGB-D Objects dataset (ROD) demonstrate that in such RGB -> RGB-D\nscenarios, late fusion techniques work better than most popularly employed\nearly fusion. With our transfer baseline, fusion ViTs score up to 95.4% top-1\naccuracy in ROD, achieving new state-of-the-art results in this benchmark. We\nfurther show the benefits of using our multimodal fusion baseline over unimodal\nfeature extractors in a synthetic-to-real visual adaptation as well as in an\nopen-ended lifelong learning scenario in the ROD benchmark, where our model\noutperforms previous works by a margin of >8%. Finally, we integrate our method\nwith a robot framework and demonstrate how it can serve as a perception utility\nin an interactive robot learning scenario, both in simulation and with a real\nrobot.\n","authors":["Georgios Tziafas","Hamidreza Kasaei"],"pdf_url":"https://arxiv.org/pdf/2210.00843v2.pdf","comment":"Submitted IROS 23. Supplementary video here:\n  https://youtu.be/L2gkDPkHsfo"},{"id":"http://arxiv.org/abs/2303.03916v1","updated":"2023-03-07T14:26:08Z","published":"2023-03-07T14:26:08Z","title":"A survey on automated detection and classification of acute leukemia and\n  WBCs in microscopic blood cells","summary":"  Leukemia (blood cancer) is an unusual spread of White Blood Cells or\nLeukocytes (WBCs) in the bone marrow and blood. Pathologists can diagnose\nleukemia by looking at a person's blood sample under a microscope. They\nidentify and categorize leukemia by counting various blood cells and\nmorphological features. This technique is time-consuming for the prediction of\nleukemia. The pathologist's professional skills and experiences may be\naffecting this procedure, too. In computer vision, traditional machine learning\nand deep learning techniques are practical roadmaps that increase the accuracy\nand speed in diagnosing and classifying medical images such as microscopic\nblood cells. This paper provides a comprehensive analysis of the detection and\nclassification of acute leukemia and WBCs in the microscopic blood cells.\nFirst, we have divided the previous works into six categories based on the\noutput of the models. Then, we describe various steps of detection and\nclassification of acute leukemia and WBCs, including Data Augmentation,\nPreprocessing, Segmentation, Feature Extraction, Feature Selection (Reduction),\nClassification, and focus on classification step in the methods. Finally, we\ndivide automated detection and classification of acute leukemia and WBCs into\nthree categories, including traditional, Deep Neural Network (DNN), and mixture\n(traditional and DNN) methods based on the type of classifier in the\nclassification step and analyze them. The results of this study show that in\nthe diagnosis and classification of acute leukemia and WBCs, the Support Vector\nMachine (SVM) classifier in traditional machine learning models and\nConvolutional Neural Network (CNN) classifier in deep learning models have\nwidely employed. The performance metrics of the models that use these\nclassifiers compared to the others model are higher.\n","authors":["Mohammad Zolfaghari","Hedieh Sajedi"],"pdf_url":"https://arxiv.org/pdf/2303.03916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03909v1","updated":"2023-03-07T14:12:52Z","published":"2023-03-07T14:12:52Z","title":"InsMOS: Instance-Aware Moving Object Segmentation in LiDAR Data","summary":"  Identifying moving objects is a crucial capability for autonomous navigation,\nconsistent map generation, and future trajectory prediction of objects. In this\npaper, we propose a novel network that addresses the challenge of segmenting\nmoving objects in 3D LiDAR scans. Our approach not only predicts point-wise\nmoving labels but also detects instance information of main traffic\nparticipants. Such a design helps determine which instances are actually moving\nand which ones are temporarily static in the current scene. Our method exploits\na sequence of point clouds as input and quantifies them into 4D voxels. We use\n4D sparse convolutions to extract motion features from the 4D voxels and inject\nthem into the current scan. Then, we extract spatio-temporal features from the\ncurrent scan for instance detection and feature fusion. Finally, we design an\nupsample fusion module to output point-wise labels by fusing the\nspatio-temporal features and predicted instance information. We evaluated our\napproach on the LiDAR-MOS benchmark based on SemanticKITTI and achieved better\nmoving object segmentation performance compared to state-of-the-art methods,\ndemonstrating the effectiveness of our approach in integrating instance\ninformation for moving object segmentation. Furthermore, our method shows\nsuperior performance on the Apollo dataset with a pre-trained model on\nSemanticKITTI, indicating that our method generalizes well in different\nscenes.The code and pre-trained models of our method will be released at\nhttps://github.com/nubot-nudt/InsMOS.\n","authors":["Neng Wang","Chenghao Shi","Ruibin Guo","Huimin Lu","Zhiqiang Zheng","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2303.03909v1.pdf","comment":"8 pages, 4 figures, submitted"},{"id":"http://arxiv.org/abs/2106.06924v3","updated":"2023-03-07T14:05:05Z","published":"2021-06-13T05:32:17Z","title":"Deep Learning for Predictive Analytics in Reversible Steganography","summary":"  Deep learning is regarded as a promising solution for reversible\nsteganography. There is an accelerating trend of representing a reversible\nsteo-system by monolithic neural networks, which bypass intermediate operations\nin traditional pipelines of reversible steganography. This end-to-end paradigm,\nhowever, suffers from imperfect reversibility. By contrast, the modular\nparadigm that incorporates neural networks into modules of traditional\npipelines can stably guarantee reversibility with mathematical explainability.\nPrediction-error modulation is a well-established reversible steganography\npipeline for digital images. It consists of a predictive analytics module and a\nreversible coding module. Given that reversibility is governed independently by\nthe coding module, we narrow our focus to the incorporation of neural networks\ninto the analytics module, which serves the purpose of predicting pixel\nintensities and a pivotal role in determining capacity and imperceptibility.\nThe objective of this study is to evaluate the impacts of different training\nconfigurations upon predictive accuracy of neural networks and provide\npractical insights. In particular, we investigate how different initialisation\nstrategies for input images may affect the learning process and how different\ntraining strategies for dual-layer prediction respond to the problem of\ndistributional shift. Furthermore, we compare steganographic performance of\nvarious model architectures with different loss functions.\n","authors":["Ching-Chun Chang","Xu Wang","Sisheng Chen","Isao Echizen","Victor Sanchez","Chang-Tsun Li"],"pdf_url":"https://arxiv.org/pdf/2106.06924v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14085v2","updated":"2023-03-07T13:56:51Z","published":"2022-11-25T13:14:33Z","title":"Positive unlabeled learning with tensor networks","summary":"  Positive unlabeled learning is a binary classification problem with positive\nand unlabeled data. It is common in domains where negative labels are costly or\nimpossible to obtain, e.g., medicine and personalized advertising. We apply the\nlocally purified state tensor network to the positive unlabeled learning\nproblem and test our model on the MNIST image and 15 categorical/mixed\ndatasets. On the MNIST dataset, we obtain close to the state-of-the-art results\neven with very few labeled positive samples. We significantly improve the\nstate-of-the-art on categorical datasets. Further, we show that the agreement\nfraction between outputs of different models on unlabeled samples is a good\nindicator of the model's performance. Finally, our method can generate new\npositive and negative instances, which we demonstrate on simple synthetic\ndatasets.\n","authors":["Bojan Žunkovič"],"pdf_url":"https://arxiv.org/pdf/2211.14085v2.pdf","comment":"12 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2302.09598v2","updated":"2023-03-07T13:50:01Z","published":"2023-02-19T15:43:54Z","title":"Guided Depth Map Super-resolution: A Survey","summary":"  Guided depth map super-resolution (GDSR), which aims to reconstruct a\nhigh-resolution (HR) depth map from a low-resolution (LR) observation with the\nhelp of a paired HR color image, is a longstanding and fundamental problem, it\nhas attracted considerable attention from computer vision and image processing\ncommunities. A myriad of novel and effective approaches have been proposed\nrecently, especially with powerful deep learning techniques. This survey is an\neffort to present a comprehensive survey of recent progress in GDSR. We start\nby summarizing the problem of GDSR and explaining why it is challenging. Next,\nwe introduce some commonly used datasets and image quality assessment methods.\nIn addition, we roughly classify existing GDSR methods into three categories,\ni.e., filtering-based methods, prior-based methods, and learning-based methods.\nIn each category, we introduce the general description of the published\nalgorithms and design principles, summarize the representative methods, and\ndiscuss their highlights and limitations. Moreover, the depth related\napplications are introduced. Furthermore, we conduct experiments to evaluate\nthe performance of some representative methods based on unified experimental\nconfigurations, so as to offer a systematic and fair performance evaluation to\nreaders. Finally, we conclude this survey with possible directions and open\nproblems for further research. All the related materials can be found at\n\\url{https://github.com/zhwzhong/Guided-Depth-Map-Super-resolution-A-Survey}.\n","authors":["Zhiwei Zhong","Xianming Liu","Junjun Jiang","Debin Zhao","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2302.09598v2.pdf","comment":"Accepted by ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2303.03056v2","updated":"2023-03-07T13:31:52Z","published":"2023-03-06T11:59:13Z","title":"MOISST: Multi-modal Optimization of Implicit Scene for SpatioTemporal\n  calibration","summary":"  With the recent advances in autonomous driving and the decreasing cost of\nLiDARs, the use of multi-modal sensor systems is on the rise. However, in order\nto make use of the information provided by a variety of complimentary sensors,\nit is necessary to accurately calibrate them. We take advantage of recent\nadvances in computer graphics and implicit volumetric scene representation to\ntackle the problem of multi-sensor spatial and temporal calibration. Thanks to\na new formulation of the implicit model optimization, we are able to jointly\noptimize calibration parameters along with scene representation based on\nradiometric and geometric measurements. Our method enables accurate and robust\ncalibration from data captured in uncontrolled and unstructured urban\nenvironments, making our solution more scalable than existing calibration\nsolutions. We demonstrate the accuracy and robustness of our method in urban\nscenes typically encountered in autonomous driving scenarios.\n","authors":["Quentin Herau","Nathan Piasco","Moussab Bennehar","Luis Roldão","Dzmitry Tsishkou","Cyrille Migniot","Pascal Vasseur","Cédric Demonceaux"],"pdf_url":"https://arxiv.org/pdf/2303.03056v2.pdf","comment":"Project site: https://qherau.github.io/MOISST/"},{"id":"http://arxiv.org/abs/2303.03879v1","updated":"2023-03-07T13:24:40Z","published":"2023-03-07T13:24:40Z","title":"SpinDOE: A ball spin estimation method for table tennis robot","summary":"  Spin plays a considerable role in table tennis, making a shot's trajectory\nharder to read and predict. However, the spin is challenging to measure because\nof the ball's high velocity and the magnitude of the spin values. Existing\nmethods either require extremely high framerate cameras or are unreliable\nbecause they use the ball's logo, which may not always be visible. Because of\nthis, many table tennis-playing robots ignore the spin, which severely limits\ntheir capabilities. This paper proposes an easily implementable and reliable\nspin estimation method. We developed a dotted-ball orientation estimation (DOE)\nmethod, that can then be used to estimate the spin. The dots are first\nlocalized on the image using a CNN and then identified using geometric hashing.\nThe spin is finally regressed from the estimated orientations. Using our\nalgorithm, the ball's orientation can be estimated with a mean error of\n2.4{\\deg} and the spin estimation has an relative error lower than 1%. Spins up\nto 175 rps are measurable with a camera of 350 fps in real time. Using our\nmethod, we generated a dataset of table tennis ball trajectories with position\nand spin, available on our project page.\n","authors":["Thomas Gossard","Jonas Tebbe","Andreas Ziegler","Andreas Zell"],"pdf_url":"https://arxiv.org/pdf/2303.03879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03876v1","updated":"2023-03-07T13:23:31Z","published":"2023-03-07T13:23:31Z","title":"Organelle-specific segmentation, spatial analysis, and visualization of\n  volume electron microscopy datasets","summary":"  Volume electron microscopy is the method of choice for the in-situ\ninterrogation of cellular ultrastructure at the nanometer scale. Recent\ntechnical advances have led to a rapid increase in large raw image datasets\nthat require computational strategies for segmentation and spatial analysis. In\nthis protocol, we describe a practical and annotation-efficient pipeline for\norganelle-specific segmentation, spatial analysis, and visualization of large\nvolume electron microscopy datasets using freely available, user-friendly\nsoftware tools that can be run on a single standard workstation. We\nspecifically target researchers in the life sciences with limited computational\nexpertise, who face the following tasks within their volume electron microscopy\nprojects: i) How to generate 3D segmentation labels for different types of cell\norganelles while minimizing manual annotation efforts, ii) how to analyze the\nspatial interactions between organelle instances, and iii) how to best\nvisualize the 3D segmentation results. To meet these demands we give detailed\nguidelines for choosing the most efficient segmentation tools for the specific\ncell organelle. We furthermore provide easily executable components for spatial\nanalysis and 3D rendering and bridge compatibility issues between freely\navailable open-source tools, such that others can replicate our full pipeline\nstarting from a raw dataset up to the final plots and rendered images. We\nbelieve that our detailed description can serve as a valuable reference for\nsimilar projects requiring special strategies for single- or multiple organelle\nanalysis which can be achieved with computational resources commonly available\nto single-user setups.\n","authors":["Andreas Müller","Deborah Schmidt","Lucas Rieckert","Michele Solimena","Martin Weigert"],"pdf_url":"https://arxiv.org/pdf/2303.03876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06983v4","updated":"2023-03-07T13:19:13Z","published":"2022-10-10T12:37:59Z","title":"Denoising Masked AutoEncoders Help Robust Classification","summary":"  In this paper, we propose a new self-supervised method, which is called\nDenoising Masked AutoEncoders (DMAE), for learning certified robust classifiers\nof images. In DMAE, we corrupt each image by adding Gaussian noises to each\npixel value and randomly masking several patches. A Transformer-based\nencoder-decoder model is then trained to reconstruct the original image from\nthe corrupted one. In this learning paradigm, the encoder will learn to capture\nrelevant semantics for the downstream tasks, which is also robust to Gaussian\nadditive noises. We show that the pre-trained encoder can naturally be used as\nthe base classifier in Gaussian smoothed models, where we can analytically\ncompute the certified radius for any data point. Although the proposed method\nis simple, it yields significant performance improvement in downstream\nclassification tasks. We show that the DMAE ViT-Base model, which just uses\n1/10 parameters of the model developed in recent work arXiv:2206.10550,\nachieves competitive or better certified accuracy in various settings. The DMAE\nViT-Large model significantly surpasses all previous results, establishing a\nnew state-of-the-art on ImageNet dataset. We further demonstrate that the\npre-trained model has good transferability to the CIFAR-10 dataset, suggesting\nits wide adaptability. Models and code are available at\nhttps://github.com/quanlin-wu/dmae.\n","authors":["Quanlin Wu","Hang Ye","Yuntian Gu","Huishuai Zhang","Liwei Wang","Di He"],"pdf_url":"https://arxiv.org/pdf/2210.06983v4.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2201.02478v2","updated":"2023-03-07T13:11:04Z","published":"2022-01-07T14:56:33Z","title":"Bayesian Neural Networks for Reversible Steganography","summary":"  Recent advances in deep learning have led to a paradigm shift in the field of\nreversible steganography. A fundamental pillar of reversible steganography is\npredictive modelling which can be realised via deep neural networks. However,\nnon-trivial errors exist in inferences about some out-of-distribution and noisy\ndata. In view of this issue, we propose to consider uncertainty in predictive\nmodels based upon a theoretical framework of Bayesian deep learning, thereby\ncreating an adaptive steganographic system. Most modern deep-learning models\nare regarded as deterministic because they only offer predictions while failing\nto provide uncertainty measurement. Bayesian neural networks bring a\nprobabilistic perspective to deep learning and can be regarded as self-aware\nintelligent machinery; that is, a machine that knows its own limitations. To\nquantify uncertainty, we apply Bayesian statistics to model the predictive\ndistribution and approximate it through Monte Carlo sampling with stochastic\nforward passes. We further show that predictive uncertainty can be disentangled\ninto aleatoric and epistemic uncertainties and these quantities can be learnt\nunsupervised. Experimental results demonstrate an improvement delivered by\nBayesian uncertainty analysis upon steganographic rate-distortion performance.\n","authors":["Ching-Chun Chang"],"pdf_url":"https://arxiv.org/pdf/2201.02478v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.02518v2","updated":"2023-03-07T12:55:55Z","published":"2022-02-05T09:04:50Z","title":"On the predictability in reversible steganography","summary":"  Artificial neural networks have advanced the frontiers of reversible\nsteganography. The core strength of neural networks is the ability to render\naccurate predictions for a bewildering variety of data. Residual modulation is\nrecognised as the most advanced reversible steganographic algorithm for digital\nimages. The pivot of this algorithm is predictive analytics in which pixel\nintensities are predicted given some pixel-wise contextual information. This\ntask can be perceived as a low-level vision problem and hence neural networks\nfor addressing a similar class of problems can be deployed. On top of the prior\nart, this paper investigates predictability of pixel intensities based on\nsupervised and unsupervised learning frameworks. Predictability analysis\nenables adaptive data embedding, which in turn leads to a better trade-off\nbetween capacity and imperceptibility. While conventional methods estimate\npredictability by the statistics of local image patterns, learning-based\nframeworks consider further the degree to which correct predictions can be made\nby a designated predictor. Not only should the image patterns be taken into\naccount but also the predictor in use. Experimental results show that\nsteganographic performance can be significantly improved by incorporating the\nlearning-based predictability analysers into a reversible steganographic\nsystem.\n","authors":["Ching-Chun Chang","Xu Wang","Sisheng Chen","Hitoshi Kiya","Isao Echizen"],"pdf_url":"https://arxiv.org/pdf/2202.02518v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03856v1","updated":"2023-03-07T12:48:02Z","published":"2023-03-07T12:48:02Z","title":"Event Voxel Set Transformer for Spatiotemporal Representation Learning\n  on Event Streams","summary":"  Event cameras are neuromorphic vision sensors representing visual information\nas sparse and asynchronous event streams. Most state-of-the-art event-based\nmethods project events into dense frames and process them with conventional\nlearning models. However, these approaches sacrifice the sparsity and high\ntemporal resolution of event data, resulting in a large model size and high\ncomputational complexity. To fit the sparse nature of events and sufficiently\nexplore their implicit relationship, we develop a novel attention-aware\nframework named Event Voxel Set Transformer (EVSTr) for spatiotemporal\nrepresentation learning on event streams. It first converts the event stream\ninto a voxel set and then hierarchically aggregates voxel features to obtain\nrobust representations. The core of EVSTr is an event voxel transformer encoder\nto extract discriminative spatiotemporal features, which consists of two\nwell-designed components, including a multi-scale neighbor embedding layer\n(MNEL) for local information aggregation and a voxel self-attention layer\n(VSAL) for global representation modeling. Enabling the framework to\nincorporate a long-term temporal structure, we introduce a segmental consensus\nstrategy for modeling motion patterns over a sequence of segmented voxel sets.\nWe evaluate the proposed framework on two event-based tasks: object\nclassification and action recognition. Comprehensive experiments show that\nEVSTr achieves state-of-the-art performance while maintaining low model\ncomplexity. Additionally, we present a new dataset (NeuroHAR) recorded in\nchallenging visual scenarios to address the lack of real-world event-based\ndatasets for action recognition.\n","authors":["Bochen Xie","Yongjian Deng","Zhanpeng Shao","Hai Liu","Qingsong Xu","Youfu Li"],"pdf_url":"https://arxiv.org/pdf/2303.03856v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.03851v1","updated":"2023-03-07T12:32:19Z","published":"2023-03-07T12:32:19Z","title":"Parsing Line Segments of Floor Plan Images Using Graph Neural Networks","summary":"  In this paper, we present a GNN-based Line Segment Parser (GLSP), which uses\na junction heatmap to predict line segments' endpoints, and graph neural\nnetworks to extract line segments and their categories. Different from previous\nfloor plan recognition methods, which rely on semantic segmentation, our\nproposed method is able to output vectorized line segment and requires less\npost-processing steps to be put into practical use. Our experiments show that\nthe methods outperform state-of-the-art line segment detection models on\nmulti-class line segment detection tasks with floor plan images. In the paper,\nwe use our floor plan dataset named Large-scale Residential Floor Plan data\n(LRFP). The dataset contains a total of 271,035 floor plan images. The label\ncorresponding to each picture contains the scale information, the categories\nand outlines of rooms, and the endpoint positions of line segments such as\ndoors, windows, and walls. Our augmentation method makes the dataset adaptable\nto the drawing styles of as many countries and regions as possible.\n","authors":["Mingxiang Chen","Cihui Pan"],"pdf_url":"https://arxiv.org/pdf/2303.03851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03817v1","updated":"2023-03-07T11:33:22Z","published":"2023-03-07T11:33:22Z","title":"Region and Spatial Aware Anomaly Detection for Fundus Images","summary":"  Recently anomaly detection has drawn much attention in diagnosing ocular\ndiseases. Most existing anomaly detection research in fundus images has\nrelatively large anomaly scores in the salient retinal structures, such as\nblood vessels, optical cups and discs. In this paper, we propose a Region and\nSpatial Aware Anomaly Detection (ReSAD) method for fundus images, which obtains\nlocal region and long-range spatial information to reduce the false positives\nin the normal structure. ReSAD transfers a pre-trained model to extract the\nfeatures of normal fundus images and applies the Region-and-Spatial-Aware\nfeature Combination module (ReSC) for pixel-level features to build a memory\nbank. In the testing phase, ReSAD uses the memory bank to determine\nout-of-distribution samples as abnormalities. Our method significantly\noutperforms the existing anomaly detection methods for fundus images on two\npublicly benchmark datasets.\n","authors":["Jingqi Niu","Shiwen Dong","Qinji Yu","Kang Dang","Xiaowei Ding"],"pdf_url":"https://arxiv.org/pdf/2303.03817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03808v1","updated":"2023-03-07T11:21:50Z","published":"2023-03-07T11:21:50Z","title":"Multiscale Tensor Decomposition and Rendering Equation Encoding for View\n  Synthesis","summary":"  Rendering novel views from captured multi-view images has made considerable\nprogress since the emergence of the neural radiance field. This paper aims to\nfurther advance the quality of view rendering by proposing a novel approach\ndubbed the neural radiance feature field (NRFF) which represents scenes in the\nfeature space. We first propose a multiscale tensor decomposition scheme to\norganize learnable features so as to represent scenes from coarse to fine\nscales. We demonstrate many benefits of the proposed multiscale representation,\nincluding more accurate scene shape and appearance reconstruction, and faster\nconvergence compared with the single-scale representation. Instead of encoding\nview directions to model view-dependent effects, we further propose to encode\nthe rendering equation in the feature space by employing the anisotropic\nspherical Gaussian mixture predicted from the proposed multiscale\nrepresentation. The proposed NRFF improves state-of-the-art rendering results\nby over 1 dB in PSNR on both the NeRF and NSVF synthetic datasets. A\nsignificant improvement has also been observed on the real-world Tanks and\nTemples dataset.\n","authors":["Kang Han","Wei Xiang"],"pdf_url":"https://arxiv.org/pdf/2303.03808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03800v1","updated":"2023-03-07T11:10:22Z","published":"2023-03-07T11:10:22Z","title":"Lformer: Text-to-Image Generation with L-shape Block Parallel Decoding","summary":"  Generative transformers have shown their superiority in synthesizing\nhigh-fidelity and high-resolution images, such as good diversity and training\nstability. However, they suffer from the problem of slow generation since they\nneed to generate a long token sequence autoregressively. To better accelerate\nthe generative transformers while keeping good generation quality, we propose\nLformer, a semi-autoregressive text-to-image generation model. Lformer firstly\nencodes an image into $h{\\times}h$ discrete tokens, then divides these tokens\ninto $h$ mirrored L-shape blocks from the top left to the bottom right and\ndecodes the tokens in a block parallelly in each step. Lformer predicts the\narea adjacent to the previous context like autoregressive models thus it is\nmore stable while accelerating. By leveraging the 2D structure of image tokens,\nLformer achieves faster speed than the existing transformer-based methods while\nkeeping good generation quality. Moreover, the pretrained Lformer can edit\nimages without the requirement for finetuning. We can roll back to the early\nsteps for regeneration or edit the image with a bounding box and a text prompt.\n","authors":["Jiacheng Li","Longhui Wei","ZongYuan Zhan","Xin He","Siliang Tang","Qi Tian","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2303.03800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03797v1","updated":"2023-03-07T11:03:33Z","published":"2023-03-07T11:03:33Z","title":"External Camera-based Mobile Robot Pose Estimation for Collaborative\n  Perception with Smart Edge Sensors","summary":"  We present an approach for estimating a mobile robot's pose w.r.t. the\nallocentric coordinates of a network of static cameras using multi-view RGB\nimages. The images are processed online, locally on smart edge sensors by deep\nneural networks to detect the robot and estimate 2D keypoints defined at\ndistinctive positions of the 3D robot model. Robot keypoint detections are\nsynchronized and fused on a central backend, where the robot's pose is\nestimated via multi-view minimization of reprojection errors. Through the pose\nestimation from external cameras, the robot's localization can be initialized\nin an allocentric map from a completely unknown state (kidnapped robot problem)\nand robustly tracked over time. We conduct a series of experiments evaluating\nthe accuracy and robustness of the camera-based pose estimation compared to the\nrobot's internal navigation stack, showing that our camera-based method\nachieves pose errors below 3 cm and 1{\\deg} and does not drift over time, as\nthe robot is localized allocentrically. With the robot's pose precisely\nestimated, its observations can be fused into the allocentric scene model. We\nshow a real-world application, where observations from mobile robot and static\nsmart edge sensors are fused to collaboratively build a 3D semantic map of a\n$\\sim$240 m$^2$ indoor environment.\n","authors":["Simon Bultmann","Raphael Memmesheimer","Sven Behnke"],"pdf_url":"https://arxiv.org/pdf/2303.03797v1.pdf","comment":"Accepted for ICRA 2023, 7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.03794v1","updated":"2023-03-07T11:01:19Z","published":"2023-03-07T11:01:19Z","title":"Hidden Knowledge: Mathematical Methods for the Extraction of the\n  Fingerprint of Medieval Paper from Digital Images","summary":"  Medieval paper, a handmade product, is made with a mould which leaves an\nindelible imprint on the sheet of paper. This imprint includes chain lines,\nlaid lines and watermarks which are often visible on the sheet. Extracting\nthese features allows the identification of paper stock and gives information\nabout chronology, localisation and movement of books and people. Most\ncomputational work for feature extraction of paper analysis has so far focused\non radiography or transmitted light images. While these imaging methods provide\nclear visualisation for the features of interest, they are expensive and time\nconsuming in their acquisition and not feasible for smaller institutions.\nHowever, reflected light images of medieval paper manuscripts are abundant and\npossibly cheaper in their acquisition. In this paper, we propose algorithms to\ndetect and extract the laid and chain lines from reflected light images. We\ntackle the main drawback of reflected light images, that is, the low contrast\nattenuation of lines and intensity jumps due to noise and degradation, by\nemploying the spectral total variation decomposition and develop methods for\nsubsequent line extraction. Our results clearly demonstrate the feasibility of\nusing reflected light images in paper analysis. This work enables the feature\nextraction for paper manuscripts that have otherwise not been analysed due to a\nlack of appropriate images. We also open the door for paper stock\nidentification at scale.\n","authors":["Tamara G. Grossmann","Carola-Bibiane Schönlieb","Orietta Da Rold"],"pdf_url":"https://arxiv.org/pdf/2303.03794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11423v2","updated":"2023-03-07T11:00:25Z","published":"2022-11-21T13:10:10Z","title":"Blur Interpolation Transformer for Real-World Motion from Blur","summary":"  This paper studies the challenging problem of recovering motion from blur,\nalso known as joint deblurring and interpolation or blur temporal\nsuper-resolution. The challenges are twofold: 1) the current methods still\nleave considerable room for improvement in terms of visual quality even on the\nsynthetic dataset, and 2) poor generalization to real-world data. To this end,\nwe propose a blur interpolation transformer (BiT) to effectively unravel the\nunderlying temporal correlation encoded in blur. Based on multi-scale residual\nSwin transformer blocks, we introduce dual-end temporal supervision and\ntemporally symmetric ensembling strategies to generate effective features for\ntime-varying motion rendering. In addition, we design a hybrid camera system to\ncollect the first real-world dataset of one-to-many blur-sharp video pairs.\nExperimental results show that BiT has a significant gain over the\nstate-of-the-art methods on the public dataset Adobe240. Besides, the proposed\nreal-world dataset effectively helps the model generalize well to real blurry\nscenarios. Code and data are available at https://github.com/zzh-tech/BiT.\n","authors":["Zhihang Zhong","Mingdeng Cao","Xiang Ji","Yinqiang Zheng","Imari Sato"],"pdf_url":"https://arxiv.org/pdf/2211.11423v2.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2107.00627v3","updated":"2023-03-07T10:34:32Z","published":"2021-07-01T17:31:42Z","title":"Semi-Sparsity for Smoothing Filters","summary":"  In this paper, we propose an interesting semi-sparsity smoothing algorithm\nbased on a novel sparsity-inducing optimization framework. This method is\nderived from the multiple observations that semi-sparsity prior knowledge is\nmore universally applicable, especially in areas where sparsity is not fully\nadmitted, such as polynomial-smoothing surfaces. We illustrate that this\nsemi-sparsity can be identified into a generalized $L_0$-norm minimization in\nhigher-order gradient domains, thereby giving rise to a new \"feature-aware\"\nfiltering method with a powerful simultaneous-fitting ability in both sparse\nfeatures (singularities and sharpening edges) and non-sparse regions\n(polynomial-smoothing surfaces). Notice that a direct solver is always\nunavailable due to the non-convexity and combinatorial nature of $L_0$-norm\nminimization. Instead, we solve the model based on an efficient half-quadratic\nsplitting minimization with fast Fourier transforms (FFTs) for acceleration. We\nfinally demonstrate its versatility and many benefits to a series of\nsignal/image processing and computer vision applications.\n","authors":["Junqing Huang","Haihui Wang","Xuechao Wang","Michael Ruzhansky"],"pdf_url":"https://arxiv.org/pdf/2107.00627v3.pdf","comment":"Final version but delete the graphic processing part"},{"id":"http://arxiv.org/abs/2303.03770v1","updated":"2023-03-07T10:04:55Z","published":"2023-03-07T10:04:55Z","title":"Guiding Pseudo-labels with Uncertainty Estimation for Test-Time\n  Adaptation","summary":"  Standard Unsupervised Domain Adaptation (UDA) methods assume the availability\nof both source and target data during the adaptation. In this work, we\ninvestigate the Test-Time Adaptation (TTA), a specific case of UDA where a\nmodel is adapted to a target domain without access to source data. We propose a\nnovel approach for the TTA setting based on a loss reweighting strategy that\nbrings robustness against the noise that inevitably affects the pseudo-labels.\nThe classification loss is reweighted based on the reliability of the\npseudo-labels that is measured by estimating their uncertainty. Guided by such\nreweighting strategy, the pseudo-labels are progressively refined by\naggregating knowledge from neighbouring samples. Furthermore, a self-supervised\ncontrastive framework is leveraged as a target space regulariser to enhance\nsuch knowledge aggregation. A novel negative pairs exclusion strategy is\nproposed to identify and exclude negative pairs made of samples sharing the\nsame class, even in presence of some noise in the pseudo-labels. Our method\noutperforms previous methods on three major benchmarks by a large margin. We\nset the new TTA state-of-the-art on VisDA-C and DomainNet with a performance\ngain of +1.8\\% on both benchmarks and on PACS with +12.3\\% in the single-source\nsetting and +6.6\\% in\\ multi-target adaptation. Additional analyses demonstrate\nthat the proposed approach is robust to the noise, which results in\nsignificantly more accurate pseudo-labels compared to state-of-the-art\napproaches.\n","authors":["Mattia Litrico","Alessio Del Bue","Pietro Morerio"],"pdf_url":"https://arxiv.org/pdf/2303.03770v1.pdf","comment":"To be published in Proceedings of the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition (CVPR) 2023"},{"id":"http://arxiv.org/abs/2303.03767v1","updated":"2023-03-07T10:01:00Z","published":"2023-03-07T10:01:00Z","title":"Proactive Multi-Camera Collaboration For 3D Human Pose Estimation","summary":"  This paper presents a multi-agent reinforcement learning (MARL) scheme for\nproactive Multi-Camera Collaboration in 3D Human Pose Estimation in dynamic\nhuman crowds. Traditional fixed-viewpoint multi-camera solutions for human\nmotion capture (MoCap) are limited in capture space and susceptible to dynamic\nocclusions. Active camera approaches proactively control camera poses to find\noptimal viewpoints for 3D reconstruction. However, current methods still face\nchallenges with credit assignment and environment dynamics. To address these\nissues, our proposed method introduces a novel Collaborative Triangulation\nContribution Reward (CTCR) that improves convergence and alleviates multi-agent\ncredit assignment issues resulting from using 3D reconstruction accuracy as the\nshared reward. Additionally, we jointly train our model with multiple world\ndynamics learning tasks to better capture environment dynamics and encourage\nanticipatory behaviors for occlusion avoidance. We evaluate our proposed method\nin four photo-realistic UE4 environments to ensure validity and\ngeneralizability. Empirical results show that our method outperforms fixed and\nactive baselines in various scenarios with different numbers of cameras and\nhumans.\n","authors":["Hai Ci","Mickel Liu","Xuehai Pan","Fangwei Zhong","Yizhou Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03767v1.pdf","comment":"ICLR 2023 poster"},{"id":"http://arxiv.org/abs/2302.01622v2","updated":"2023-03-07T10:00:43Z","published":"2023-02-03T09:49:13Z","title":"Private, fair and accurate: Training large-scale, privacy-preserving AI\n  models in medical imaging","summary":"  Artificial intelligence (AI) models are increasingly used in the medical\ndomain. However, as medical data is highly sensitive, special precautions to\nensure its protection are required. The gold standard for privacy preservation\nis the introduction of differential privacy (DP) to model training. Prior work\nindicates that DP has negative implications on model accuracy and fairness,\nwhich are unacceptable in medicine and represent a main barrier to the\nwidespread use of privacy-preserving techniques. In this work, we evaluated the\neffect of privacy-preserving training of AI models for chest radiograph\ndiagnosis regarding accuracy and fairness compared to non-private training. For\nthis, we used a large dataset (N=193,311) of high quality clinical chest\nradiographs, which were retrospectively collected and manually labeled by\nexperienced radiologists. We then compared non-private deep convolutional\nneural networks (CNNs) and privacy-preserving (DP) models with respect to\nprivacy-utility trade-offs measured as area under the\nreceiver-operator-characteristic curve (AUROC), and privacy-fairness\ntrade-offs, measured as Pearson's r or Statistical Parity Difference. We found\nthat the non-private CNNs achieved an average AUROC score of 0.90 +- 0.04 over\nall labels, whereas the DP CNNs with a privacy budget of epsilon=7.89 resulted\nin an AUROC of 0.87 +- 0.04, i.e., a mere 2.6% performance decrease compared to\nnon-private training. Furthermore, we found the privacy-preserving training not\nto amplify discrimination against age, sex or co-morbidity. Our study shows\nthat -- under the challenging realistic circumstances of a real-life clinical\ndataset -- the privacy-preserving training of diagnostic deep learning models\nis possible with excellent diagnostic accuracy and fairness.\n","authors":["Soroosh Tayebi Arasteh","Alexander Ziller","Christiane Kuhl","Marcus Makowski","Sven Nebelung","Rickmer Braren","Daniel Rueckert","Daniel Truhn","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2302.01622v2.pdf","comment":"3 tables, 5 figures, 11 supplementary materials"},{"id":"http://arxiv.org/abs/2208.11451v3","updated":"2023-03-07T09:58:15Z","published":"2022-08-24T11:36:53Z","title":"Q-Net: Query-Informed Few-Shot Medical Image Segmentation","summary":"  Deep learning has achieved tremendous success in computer vision, while\nmedical image segmentation (MIS) remains a challenge, due to the scarcity of\ndata annotations. Meta-learning techniques for few-shot segmentation (Meta-FSS)\nhave been widely used to tackle this challenge, while they neglect possible\ndistribution shifts between the query image and the support set. In contrast,\nan experienced clinician can perceive and address such shifts by borrowing\ninformation from the query image, then fine-tune or calibrate her prior\ncognitive model accordingly. Inspired by this, we propose Q-Net, a\nQuery-informed Meta-FSS approach, which mimics in spirit the learning mechanism\nof an expert clinician. We build Q-Net based on ADNet, a recently proposed\nanomaly detection-inspired method. Specifically, we add two query-informed\ncomputation modules into ADNet, namely a query-informed threshold adaptation\nmodule and a query-informed prototype refinement module. Combining them with a\ndual-path extension of the feature extraction module, Q-Net achieves\nstate-of-the-art performance on widely used abdominal and cardiac magnetic\nresonance (MR) image datasets. Our work sheds light on a novel way to improve\nMeta-FSS techniques by leveraging query information.\n","authors":["Qianqian Shen","Yanan Li","Jiyong Jin","Bin Liu"],"pdf_url":"https://arxiv.org/pdf/2208.11451v3.pdf","comment":"Accpeted by Intelligent Systems Conference (IntelliSys) 2023"},{"id":"http://arxiv.org/abs/2303.03761v1","updated":"2023-03-07T09:56:23Z","published":"2023-03-07T09:56:23Z","title":"Graph Neural Networks in Vision-Language Image Understanding: A Survey","summary":"  2D image understanding is a complex problem within Computer Vision, but it\nholds the key to providing human level scene comprehension. It goes further\nthan identifying the objects in an image, and instead it attempts to understand\nthe scene. Solutions to this problem form the underpinning of a range of tasks,\nincluding image captioning, Visual Question Answering (VQA), and image\nretrieval. Graphs provide a natural way to represent the relational arrangement\nbetween objects in an image, and thus in recent years Graph Neural Networks\n(GNNs) have become a standard component of many 2D image understanding\npipelines, becoming a core architectural component especially in the VQA group\nof tasks. In this survey, we review this rapidly evolving field and we provide\na taxonomy of graph types used in 2D image understanding approaches, a\ncomprehensive list of the GNN models used in this domain, and a roadmap of\nfuture potential developments. To the best of our knowledge, this is the first\ncomprehensive survey that covers image captioning, visual question answering,\nand image retrieval techniques that focus on using GNNs as the main part of\ntheir architecture.\n","authors":["Henry Senior","Gregory Slabaugh","Shanxin Yuan","Luca Rossi"],"pdf_url":"https://arxiv.org/pdf/2303.03761v1.pdf","comment":"19 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2103.13201v4","updated":"2023-03-07T09:44:23Z","published":"2021-03-24T13:59:40Z","title":"DRO: Deep Recurrent Optimizer for Video to Depth","summary":"  There are increasing interests of studying the video-to-depth (V2D) problem\nwith machine learning techniques. While earlier methods directly learn a\nmapping from images to depth maps and camera poses, more recent works enforce\nmulti-view geometry constraints through optimization embedded in the learning\nframework. This paper presents a novel optimization method based on recurrent\nneural networks to further exploit the potential of neural networks in V2D.\nSpecifically, our neural optimizer alternately updates the depth and camera\nposes through iterations to minimize a feature-metric cost, and two gated\nrecurrent units iteratively improve the results by tracing historical\ninformation. Extensive experimental results demonstrate that our method\noutperforms previous methods and is more efficient in computation and memory\nconsumption than cost-volume-based methods. In particular, our self-supervised\nmethod outperforms previous supervised methods on the KITTI and ScanNet\ndatasets. Our source code is available at https://github.com/aliyun/dro-sfm.\n","authors":["Xiaodong Gu","Weihao Yuan","Zuozhuo Dai","Siyu Zhu","Chengzhou Tang","Zilong Dong","Ping Tan"],"pdf_url":"https://arxiv.org/pdf/2103.13201v4.pdf","comment":"Accepted by IEEE Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2303.03758v1","updated":"2023-03-07T09:40:22Z","published":"2023-03-07T09:40:22Z","title":"Patched Diffusion Models for Unsupervised Anomaly Detection in Brain MRI","summary":"  The use of supervised deep learning techniques to detect pathologies in brain\nMRI scans can be challenging due to the diversity of brain anatomy and the need\nfor annotated data sets. An alternative approach is to use unsupervised anomaly\ndetection, which only requires sample-level labels of healthy brains to create\na reference representation. This reference representation can then be compared\nto unhealthy brain anatomy in a pixel-wise manner to identify abnormalities. To\naccomplish this, generative models are needed to create anatomically consistent\nMRI scans of healthy brains. While recent diffusion models have shown promise\nin this task, accurately generating the complex structure of the human brain\nremains a challenge. In this paper, we propose a method that reformulates the\ngeneration task of diffusion models as a patch-based estimation of healthy\nbrain anatomy, using spatial context to guide and improve reconstruction. We\nevaluate our approach on data of tumors and multiple sclerosis lesions and\ndemonstrate a relative improvement of 25.1% compared to existing baselines.\n","authors":["Finn Behrendt","Debayan Bhattacharya","Julia Krüger","Roland Opfer","Alexander Schlaefer"],"pdf_url":"https://arxiv.org/pdf/2303.03758v1.pdf","comment":"Accepted full paper at the MIDL23 conference"},{"id":"http://arxiv.org/abs/2303.03757v1","updated":"2023-03-07T09:33:49Z","published":"2023-03-07T09:33:49Z","title":"Deep Learning for Inertial Positioning: A Survey","summary":"  Inertial sensor has been widely deployed on smartphones, drones, robots and\nIoT devices. Due to its importance in ubiquitous and robust localization,\ninertial sensor based positioning is key in many applications, including\npersonal navigation, location based security, and human-device interaction.\nHowever, inertial positioning suffers from the so-called error drifts problem,\nas the measurements of low-cost MEMS inertial sensor are corrupted with various\ninevitable error sources, leading to unbounded drifts when being integrated\ndoubly in traditional inertial navigation algorithms. Recently, with increasing\nsensor data and computational power, the fast developments in deep learning\nhave spurred a large amount of research works in introducing deep learning to\ntackle the problem of inertial positioning. Relevant literature spans from the\nareas of mobile computing, robotics and machine learning. This article\ncomprehensively reviews relevant works on deep learning based inertial\npositioning, connects the efforts from different fields, and covers how deep\nlearning can be applied to solve sensor calibration, positioning error drifts\nreduction and sensor fusion. Finally, we provide insights on the benefits and\nlimitations of existing works, and indicate the future opportunities in this\ndirection.\n","authors":["Changhao Chen"],"pdf_url":"https://arxiv.org/pdf/2303.03757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03755v1","updated":"2023-03-07T09:30:43Z","published":"2023-03-07T09:30:43Z","title":"DLT: Conditioned layout generation with Joint Discrete-Continuous\n  Diffusion Layout Transformer","summary":"  Generating visual layouts is an essential ingredient of graphic design. The\nability to condition layout generation on a partial subset of component\nattributes is critical to real-world applications that involve user\ninteraction. Recently, diffusion models have demonstrated high-quality\ngenerative performances in various domains. However, it is unclear how to apply\ndiffusion models to the natural representation of layouts which consists of a\nmix of discrete (class) and continuous (location, size) attributes. To address\nthe conditioning layout generation problem, we introduce DLT, a joint\ndiscrete-continuous diffusion model. DLT is a transformer-based model which has\na flexible conditioning mechanism that allows for conditioning on any given\nsubset of all the layout component classes, locations, and sizes. Our method\noutperforms state-of-the-art generative models on various layout generation\ndatasets with respect to different metrics and conditioning settings.\nAdditionally, we validate the effectiveness of our proposed conditioning\nmechanism and the joint continuous-diffusion process. This joint process can be\nincorporated into a wide range of mixed discrete-continuous generative tasks.\n","authors":["Elad Levi","Eli Brosh","Mykola Mykhailych","Meir Perez"],"pdf_url":"https://arxiv.org/pdf/2303.03755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03745v1","updated":"2023-03-07T09:09:13Z","published":"2023-03-07T09:09:13Z","title":"At Your Fingertips: Extracting Piano Fingering Instructions from Videos","summary":"  Piano fingering -- knowing which finger to use to play each note in a musical\npiece, is a hard and important skill to master when learning to play the piano.\nWhile some sheet music is available with expert-annotated fingering\ninformation, most pieces lack this information, and people often resort to\nlearning the fingering from demonstrations in online videos. We consider the AI\ntask of automating the extraction of fingering information from videos. This is\na non-trivial task as fingers are often occluded by other fingers, and it is\noften not clear from the video which of the keys were pressed, requiring the\nsynchronization of hand position information and knowledge about the notes that\nwere played. We show how to perform this task with high-accuracy using a\ncombination of deep-learning modules, including a GAN-based approach for\nfine-tuning on out-of-domain data. We extract the fingering information with an\nf1 score of 97\\%. We run the resulting system on 90 videos, resulting in\nhigh-quality piano fingering information of 150K notes, the largest available\ndataset of piano-fingering to date.\n","authors":["Amit Moryossef","Yanai Elazar","Yoav Goldberg"],"pdf_url":"https://arxiv.org/pdf/2303.03745v1.pdf","comment":"6 pages, paper from 2019"},{"id":"http://arxiv.org/abs/2303.03730v1","updated":"2023-03-07T08:42:46Z","published":"2023-03-07T08:42:46Z","title":"LORE: Logical Location Regression Network for Table Structure\n  Recognition","summary":"  Table structure recognition (TSR) aims at extracting tables in images into\nmachine-understandable formats. Recent methods solve this problem by predicting\nthe adjacency relations of detected cell boxes, or learning to generate the\ncorresponding markup sequences from the table images. However, they either\ncount on additional heuristic rules to recover the table structures, or require\na huge amount of training data and time-consuming sequential decoders. In this\npaper, we propose an alternative paradigm. We model TSR as a logical location\nregression problem and propose a new TSR framework called LORE, standing for\nLOgical location REgression network, which for the first time combines logical\nlocation regression together with spatial location regression of table cells.\nOur proposed LORE is conceptually simpler, easier to train and more accurate\nthan previous TSR models of other paradigms. Experiments on standard benchmarks\ndemonstrate that LORE consistently outperforms prior arts. Code is available at\nhttps://\ngithub.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/LORE-TSR.\n","authors":["Hangdi Xing","Feiyu Gao","Rujiao Long","Jiajun Bu","Qi Zheng","Liangcheng Li","Cong Yao","Zhi Yu"],"pdf_url":"https://arxiv.org/pdf/2303.03730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03729v1","updated":"2023-03-07T08:37:48Z","published":"2023-03-07T08:37:48Z","title":"Learning Discriminative Representations for Skeleton Based Action\n  Recognition","summary":"  Human action recognition aims at classifying the category of human action\nfrom a segment of a video. Recently, people dive into designing GCN-based\nmodels to extract features from skeletons for performing this task, because\nskeleton representations are much efficient and robust than other modalities\nsuch as RGB frames. However, when employing the skeleton data, some important\nclues like related items are also dismissed. It results in some ambiguous\nactions that are hard to be distinguished and tend to be misclassified. To\nalleviate this problem, we propose an auxiliary feature refinement head (FR\nHead), which consists of spatial-temporal decoupling and contrastive feature\nrefinement, to obtain discriminative representations of skeletons. Ambiguous\nsamples are dynamically discovered and calibrated in the feature space.\nFurthermore, FR Head could be imposed on different stages of GCNs to build a\nmulti-level refinement for stronger supervision. Extensive experiments are\nconducted on NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets. Our proposed\nmodels obtain competitive results from state-of-the-art methods and can help to\ndiscriminate those ambiguous samples.\n","authors":["Huanyu Zhou","Qingjie Liu","Yunhong Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03729v1.pdf","comment":"Accepted by CVPR2023. 10 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2303.03728v1","updated":"2023-03-07T08:31:42Z","published":"2023-03-07T08:31:42Z","title":"Refined Pseudo labeling for Source-free Domain Adaptive Object Detection","summary":"  Domain adaptive object detection (DAOD) assumes that both labeled source data\nand unlabeled target data are available for training, but this assumption does\nnot always hold in real-world scenarios. Thus, source-free DAOD is proposed to\nadapt the source-trained detectors to target domains with only unlabeled target\ndata. Existing source-free DAOD methods typically utilize pseudo labeling,\nwhere the performance heavily relies on the selection of confidence threshold.\nHowever, most prior works adopt a single fixed threshold for all classes to\ngenerate pseudo labels, which ignore the imbalanced class distribution,\nresulting in biased pseudo labels. In this work, we propose a refined pseudo\nlabeling framework for source-free DAOD. First, to generate unbiased pseudo\nlabels, we present a category-aware adaptive threshold estimation module, which\nadaptively provides the appropriate threshold for each category. Second, to\nalleviate incorrect box regression, a localization-aware pseudo label\nassignment strategy is introduced to divide labels into certain and uncertain\nones and optimize them separately. Finally, extensive experiments on four\nadaptation tasks demonstrate the effectiveness of our method.\n","authors":["Siqi Zhang","Lu Zhang","Zhiyong Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03728v1.pdf","comment":"Accepted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2211.04894v3","updated":"2023-03-07T08:25:24Z","published":"2022-11-09T13:55:50Z","title":"Exploring Video Quality Assessment on User Generated Contents from\n  Aesthetic and Technical Perspectives","summary":"  The rapid increase in user-generated-content (UGC) videos calls for the\ndevelopment of effective video quality assessment (VQA) algorithms. However,\nthe objective of the UGC-VQA problem is still ambiguous and can be viewed from\ntwo perspectives: the technical perspective, measuring the perception of\ndistortions; and the aesthetic perspective, which relates to preference and\nrecommendation on contents. To understand how these two perspectives affect\noverall subjective opinions in UGC-VQA, we conduct a large-scale subjective\nstudy to collect human quality opinions on overall quality of videos as well as\nperceptions from aesthetic and technical perspectives. The collected\nDisentangled Video Quality Database (DIVIDE-3k) confirms that human quality\nopinions on UGC videos are universally and inevitably affected by both\naesthetic and technical perspectives. In light of this, we propose the\nDisentangled Objective Video Quality Evaluator (DOVER) to learn the quality of\nUGC videos based on the two perspectives. The DOVER proves state-of-the-art\nperformance in UGC-VQA under very high efficiency. With perspective opinions in\nDIVIDE-3k, we further propose DOVER++, the first approach to provide reliable\nclear-cut quality evaluations from a single aesthetic or technical perspective.\nCode at https://github.com/VQAssessment/DOVER.\n","authors":["Haoning Wu","Erli Zhang","Liang Liao","Chaofeng Chen","Jingwen Hou","Annan Wang","Wenxiu Sun","Qiong Yan","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2211.04894v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03716v1","updated":"2023-03-07T07:57:12Z","published":"2023-03-07T07:57:12Z","title":"Challenges of the Creation of a Dataset for Vision Based Human Hand\n  Action Recognition in Industrial Assembly","summary":"  This work presents the Industrial Hand Action Dataset V1, an industrial\nassembly dataset consisting of 12 classes with 459,180 images in the basic\nversion and 2,295,900 images after spatial augmentation. Compared to other\nfreely available datasets tested, it has an above-average duration and, in\naddition, meets the technical and legal requirements for industrial assembly\nlines. Furthermore, the dataset contains occlusions, hand-object interaction,\nand various fine-grained human hand actions for industrial assembly tasks that\nwere not found in combination in examined datasets. The recorded ground truth\nassembly classes were selected after extensive observation of real-world use\ncases. A Gated Transformer Network, a state-of-the-art model from the\ntransformer domain was adapted, and proved with a test accuracy of 86.25%\nbefore hyperparameter tuning by 18,269,959 trainable parameters, that it is\npossible to train sequential deep learning models with this dataset.\n","authors":["Fabian Sturm","Elke Hergenroether","Julian Reinhardt","Petar Smilevski Vojnovikj","Melanie Siegel"],"pdf_url":"https://arxiv.org/pdf/2303.03716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03709v1","updated":"2023-03-07T07:47:41Z","published":"2023-03-07T07:47:41Z","title":"Bootstrap The Original Latent: Freeze-and-thaw Adapter for\n  Back-Propagated Black-Box Adaptation","summary":"  In this paper, considering the balance of data/model privacy of model owners\nand user needs, we propose a new setting called Back-Propagated Black-Box\nAdaptation (BPBA) for users to better train their private models via the\nguidance of the back-propagated results of foundation/source models. Our\nsetting can ease the usage of foundation/source models as well as prevent the\nleakage and misuse of foundation/source models. Moreover, we also propose a new\ntraining strategy called Bootstrap The Original Latent (BTOL) to fully utilize\nthe foundation/source models. Our strategy consists of a domain adapter and a\nfreeze-and-thaw strategy. We apply our BTOL under BPBA and Black-box UDA\nsettings on three different datasets. Experiments show that our strategy is\nefficient and robust in various settings without manual augmentations.\n","authors":["Shuai Wang","Daoan Zhang","Jianguo Zhang","Weiwei Zhang","Rui Li"],"pdf_url":"https://arxiv.org/pdf/2303.03709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03707v1","updated":"2023-03-07T07:42:37Z","published":"2023-03-07T07:42:37Z","title":"Hybrid quantum-classical convolutional neural network for phytoplankton\n  classification","summary":"  The taxonomic composition and abundance of phytoplankton, having direct\nimpact on marine ecosystem dynamic and global environment change, are listed as\nessential ocean variables. Phytoplankton classification is very crucial for\nPhytoplankton analysis, but it is very difficult because of the huge amount and\ntiny volume of Phytoplankton. Machine learning is the principle way of\nperforming phytoplankton image classification automatically. When carrying out\nlarge-scale research on the marine phytoplankton, the volume of data increases\noverwhelmingly and more powerful computational resources are required for the\nsuccess of machine learning algorithms. Recently, quantum machine learning has\nemerged as the potential solution for large-scale data processing by harnessing\nthe exponentially computational power of quantum computer. Here, for the first\ntime, we demonstrate the feasibility of quantum deep neural networks for\nphytoplankton classification. Hybrid quantum-classical convolutional and\nresidual neural networks are developed based on the classical architectures.\nThese models make a proper balance between the limited function of the current\nquantum devices and the large size of phytoplankton images, which make it\npossible to perform phytoplankton classification on the near-term quantum\ncomputers. Better performance is obtained by the quantum-enhanced models\nagainst the classical counterparts. In particular, quantum models converge much\nfaster than classical ones. The present quantum models are versatile, and can\nbe applied for various tasks of image classification in the field of marine\nscience.\n","authors":["Shangshang Shi","Zhimin Wang","Ruimin Shang","Yanan Li","Jiaxin Li","Guoqiang Zhong","Yongjian Gu"],"pdf_url":"https://arxiv.org/pdf/2303.03707v1.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2303.03698v1","updated":"2023-03-07T07:30:08Z","published":"2023-03-07T07:30:08Z","title":"FIT: Frequency-based Image Translation for Domain Adaptive Object\n  Detection","summary":"  Domain adaptive object detection (DAOD) aims to adapt the detector from a\nlabelled source domain to an unlabelled target domain. In recent years, DAOD\nhas attracted massive attention since it can alleviate performance degradation\ndue to the large shift of data distributions in the wild. To align\ndistributions between domains, adversarial learning is widely used in existing\nDAOD methods. However, the decision boundary for the adversarial domain\ndiscriminator may be inaccurate, causing the model biased towards the source\ndomain. To alleviate this bias, we propose a novel Frequency-based Image\nTranslation (FIT) framework for DAOD. First, by keeping domain-invariant\nfrequency components and swapping domain-specific ones, we conduct image\ntranslation to reduce domain shift at the input level. Second, hierarchical\nadversarial feature learning is utilized to further mitigate the domain gap at\nthe feature level. Finally, we design a joint loss to train the entire network\nin an end-to-end manner without extra training to obtain translated images.\nExtensive experiments on three challenging DAOD benchmarks demonstrate the\neffectiveness of our method.\n","authors":["Siqi Zhang","Lu Zhang","Zhiyong Liu","Hangtao Feng"],"pdf_url":"https://arxiv.org/pdf/2303.03698v1.pdf","comment":"Accepted to ICONIP 2022"},{"id":"http://arxiv.org/abs/2210.06575v2","updated":"2023-03-07T07:26:40Z","published":"2022-10-12T20:31:23Z","title":"GraspNeRF: Multiview-based 6-DoF Grasp Detection for Transparent and\n  Specular Objects Using Generalizable NeRF","summary":"  In this work, we tackle 6-DoF grasp detection for transparent and specular\nobjects, which is an important yet challenging problem in vision-based robotic\nsystems, due to the failure of depth cameras in sensing their geometry. We, for\nthe first time, propose a multiview RGB-based 6-DoF grasp detection network,\nGraspNeRF, that leverages the generalizable neural radiance field (NeRF) to\nachieve material-agnostic object grasping in clutter. Compared to the existing\nNeRF-based 3-DoF grasp detection methods that rely on densely captured input\nimages and time-consuming per-scene optimization, our system can perform\nzero-shot NeRF construction with sparse RGB inputs and reliably detect 6-DoF\ngrasps, both in real-time. The proposed framework jointly learns generalizable\nNeRF and grasp detection in an end-to-end manner, optimizing the scene\nrepresentation construction for the grasping. For training data, we generate a\nlarge-scale photorealistic domain-randomized synthetic dataset of grasping in\ncluttered tabletop scenes that enables direct transfer to the real world. Our\nextensive experiments in synthetic and real-world environments demonstrate that\nour method significantly outperforms all the baselines in all the experiments\nwhile remaining in real-time. Project page can be found at\nhttps://pku-epic.github.io/GraspNeRF\n","authors":["Qiyu Dai","Yan Zhu","Yiran Geng","Ciyu Ruan","Jiazhao Zhang","He Wang"],"pdf_url":"https://arxiv.org/pdf/2210.06575v2.pdf","comment":"IEEE International Conference on Robotics and Automation (ICRA), 2023"},{"id":"http://arxiv.org/abs/2109.04100v2","updated":"2023-03-07T07:19:42Z","published":"2021-09-09T08:38:17Z","title":"Taming Self-Supervised Learning for Presentation Attack Detection:\n  In-Image De-Folding and Out-of-Image De-Mixing","summary":"  Biometric systems are vulnerable to Presentation Attacks (PA) performed using\nvarious Presentation Attack Instruments (PAIs). Even though there are numerous\nPresentation Attack Detection (PAD) techniques based on both deep learning and\nhand-crafted features, the generalization of PAD for unknown PAI is still a\nchallenging problem. In this work, we empirically prove that the initialization\nof the PAD model is a crucial factor for the generalization, which is rarely\ndiscussed in the community. Based on such observation, we proposed a\nself-supervised learning-based method, denoted as DF-DM. Specifically, DF-DM is\nbased on a global-local view coupled with De-Folding and De-Mixing to derive\nthe task-specific representation for PAD. During De-Folding, the proposed\ntechnique will learn region-specific features to represent samples in a local\npattern by explicitly minimizing generative loss. While De-Mixing drives\ndetectors to obtain the instance-specific features with global information for\nmore comprehensive representation by minimizing interpolation-based\nconsistency. Extensive experimental results show that the proposed method can\nachieve significant improvements in terms of both face and fingerprint PAD in\nmore complicated and hybrid datasets when compared with state-of-the-art\nmethods. When training in CASIA-FASD and Idiap Replay-Attack, the proposed\nmethod can achieve an 18.60% Equal Error Rate (EER) in OULU-NPU and MSU-MFSD,\nexceeding baseline performance by 9.54%. The source code of the proposed\ntechnique is available at https://github.com/kongzhecn/dfdm.\n","authors":["Zhe Kong","Wentian Zhang","Feng Liu","Wenhan Luo","Haozhe Liu","Linlin Shen","Raghavendra Ramachandra"],"pdf_url":"https://arxiv.org/pdf/2109.04100v2.pdf","comment":"Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)"},{"id":"http://arxiv.org/abs/2303.03684v1","updated":"2023-03-07T06:54:48Z","published":"2023-03-07T06:54:48Z","title":"MOSO: Decomposing MOtion, Scene and Object for Video Prediction","summary":"  Motion, scene and object are three primary visual components of a video. In\nparticular, objects represent the foreground, scenes represent the background,\nand motion traces their dynamics. Based on this insight, we propose a two-stage\nMOtion, Scene and Object decomposition framework (MOSO) for video prediction,\nconsisting of MOSO-VQVAE and MOSO-Transformer. In the first stage, MOSO-VQVAE\ndecomposes a previous video clip into the motion, scene and object components,\nand represents them as distinct groups of discrete tokens. Then, in the second\nstage, MOSO-Transformer predicts the object and scene tokens of the subsequent\nvideo clip based on the previous tokens and adds dynamic motion at the token\nlevel to the generated object and scene tokens. Our framework can be easily\nextended to unconditional video generation and video frame interpolation tasks.\nExperimental results demonstrate that our method achieves new state-of-the-art\nperformance on five challenging benchmarks for video prediction and\nunconditional video generation: BAIR, RoboNet, KTH, KITTI and UCF101. In\naddition, MOSO can produce realistic videos by combining objects and scenes\nfrom different videos.\n","authors":["Mingzhen Sun","Weining Wang","Xinxin Zhu","Jing Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03684v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.03680v1","updated":"2023-03-07T06:42:52Z","published":"2023-03-07T06:42:52Z","title":"Logit Margin Matters: Improving Transferable Targeted Adversarial Attack\n  by Logit Calibration","summary":"  Previous works have extensively studied the transferability of adversarial\nsamples in untargeted black-box scenarios. However, it still remains\nchallenging to craft targeted adversarial examples with higher transferability\nthan non-targeted ones. Recent studies reveal that the traditional\nCross-Entropy (CE) loss function is insufficient to learn transferable targeted\nadversarial examples due to the issue of vanishing gradient. In this work, we\nprovide a comprehensive investigation of the CE loss function and find that the\nlogit margin between the targeted and untargeted classes will quickly obtain\nsaturation in CE, which largely limits the transferability. Therefore, in this\npaper, we devote to the goal of continually increasing the logit margin along\nthe optimization to deal with the saturation issue and propose two simple and\neffective logit calibration methods, which are achieved by downscaling the\nlogits with a temperature factor and an adaptive margin, respectively. Both of\nthem can effectively encourage optimization to produce a larger logit margin\nand lead to higher transferability. Besides, we show that minimizing the cosine\ndistance between the adversarial examples and the classifier weights of the\ntarget class can further improve the transferability, which is benefited from\ndownscaling logits via L2-normalization. Experiments conducted on the ImageNet\ndataset validate the effectiveness of the proposed methods, which outperform\nthe state-of-the-art methods in black-box targeted attacks. The source code is\navailable at \\href{https://github.com/WJJLL/Target-Attack/}{Link}\n","authors":["Juanjuan Weng","Zhiming Luo","Zhun Zhong","Shaozi Li","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2303.03680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03679v1","updated":"2023-03-07T06:38:48Z","published":"2023-03-07T06:38:48Z","title":"MAST: Masked Augmentation Subspace Training for Generalizable\n  Self-Supervised Priors","summary":"  Recent Self-Supervised Learning (SSL) methods are able to learn feature\nrepresentations that are invariant to different data augmentations, which can\nthen be transferred to downstream tasks of interest. However, different\ndownstream tasks require different invariances for their best performance, so\nthe optimal choice of augmentations for SSL depends on the target task. In this\npaper, we aim to learn self-supervised features that generalize well across a\nvariety of downstream tasks (e.g., object classification, detection and\ninstance segmentation) without knowing any task information beforehand. We do\nso by Masked Augmentation Subspace Training (or MAST) to encode in the single\nfeature space the priors from different data augmentations in a factorized way.\nSpecifically, we disentangle the feature space into separate subspaces, each\ninduced by a learnable mask that selects relevant feature dimensions to model\ninvariance to a specific augmentation. We show the success of MAST in jointly\ncapturing generalizable priors from different augmentations, using both unique\nand shared features across the subspaces. We further show that MAST benefits\nfrom uncertainty modeling to reweight ambiguous samples from strong\naugmentations that may cause similarity mismatch in each subspace. Experiments\ndemonstrate that MAST consistently improves generalization on various\ndownstream tasks, while being task-agnostic and efficient during SSL. We also\nprovide interesting insights about how different augmentations are related and\nhow uncertainty reflects learning difficulty.\n","authors":["Chen Huang","Hanlin Goh","Jiatao Gu","Josh Susskind"],"pdf_url":"https://arxiv.org/pdf/2303.03679v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2209.02890v3","updated":"2023-03-07T06:37:40Z","published":"2022-09-07T02:23:40Z","title":"Data-Driven Target Localization Using Adaptive Radar Processing and\n  Convolutional Neural Networks","summary":"  Facilitated by the recent emergence of radio frequency (RF) modeling and\nsimulation tools purposed for adaptive radar processing applications,\ndata-driven approaches to classical problems in radar have rapidly grown in\npopularity over the past decade. Despite this surge, limited focus has been\ndirected toward the theoretical foundations of these data-driven approaches. In\nthis regard, using adaptive radar processing techniques, we propose a\ndata-driven approach in this work to address the classical problem of radar\ntarget localization post adaptive radar detection. To give context to the\nperformance of this data-driven approach, we first analyze the asymptotic\nbreakdown signal-to-clutter-plus-noise ratio (SCNR) threshold of the normalized\nadaptive matched filter (NAMF) test statistic within the context of radar\ntarget localization, and augment this analysis through our proposed deep\nlearning framework for target location estimation. In this procedure, we\ngenerate comprehensive datasets by randomly placing targets of variable\nstrengths in predetermined constrained areas using RFView, a site-specific,\ndigital twin, RF modeling and simulation tool. For each radar return from these\npredefined constrained areas, we generate heatmap tensors in range, azimuth,\nand elevation of the NAMF test statistic, and of the output power of a\ngeneralized sidelobe canceller (GSC). Using our deep learning framework, we\nestimate target locations from these heatmap tensors to demonstrate the\nfeasibility of and significant improvements provided by our data-driven\napproach across matched and mismatched settings.\n","authors":["Shyam Venkatasubramanian","Sandeep Gogineni","Bosung Kang","Ali Pezeshki","Muralidhar Rangaswamy","Vahid Tarokh"],"pdf_url":"https://arxiv.org/pdf/2209.02890v3.pdf","comment":"34 pages, 22 figures. Submitted to IEEE Transactions on Aerospace and\n  Electronic Systems"},{"id":"http://arxiv.org/abs/2111.07620v2","updated":"2023-03-07T06:37:09Z","published":"2021-11-15T09:13:21Z","title":"Fingerprint Presentation Attack Detection by Channel-wise Feature\n  Denoising","summary":"  Due to the diversity of attack materials, fingerprint recognition systems\n(AFRSs) are vulnerable to malicious attacks. It is thus important to propose\neffective fingerprint presentation attack detection (PAD) methods for the\nsafety and reliability of AFRSs. However, current PAD methods often exhibit\npoor robustness under new attack types settings. This paper thus proposes a\nnovel channel-wise feature denoising fingerprint PAD (CFD-PAD) method by\nhandling the redundant noise information ignored in previous studies. The\nproposed method learns important features of fingerprint images by weighing the\nimportance of each channel and identifying discriminative channels and \"noise\"\nchannels. Then, the propagation of \"noise\" channels is suppressed in the\nfeature map to reduce interference. Specifically, a PA-Adaptation loss is\ndesigned to constrain the feature distribution to make the feature distribution\nof live fingerprints more aggregate and that of spoof fingerprints more\ndisperse. Experimental results evaluated on the LivDet 2017 dataset showed that\nthe proposed CFD-PAD can achieve a 2.53% average classification error (ACE) and\na 93.83% true detection rate when the false detection rate equals 1.0%\n(TDR@FDR=1%). Also, the proposed method markedly outperforms the best\nsingle-model-based methods in terms of ACE (2.53% vs. 4.56%) and\nTDR@FDR=1%(93.83% vs. 73.32%), which demonstrates its effectiveness. Although\nwe have achieved a comparable result with the state-of-the-art\nmultiple-model-based methods, there still is an increase in TDR@FDR=1% from\n91.19% to 93.83%. In addition, the proposed model is simpler, lighter and more\nefficient and has achieved a 74.76% reduction in computation time compared with\nthe state-of-the-art multiple-model-based method. The source code is available\nat https://github.com/kongzhecn/cfd-pad.\n","authors":["Feng Liu","Zhe Kong","Haozhe Liu","Wentian Zhang","Linlin Shen"],"pdf_url":"https://arxiv.org/pdf/2111.07620v2.pdf","comment":"15 pages, 8 figures, Accepted by TIFS"},{"id":"http://arxiv.org/abs/2303.03672v1","updated":"2023-03-07T06:16:10Z","published":"2023-03-07T06:16:10Z","title":"CIFF-Net: Contextual Image Feature Fusion for Melanoma Diagnosis","summary":"  Melanoma is considered to be the deadliest variant of skin cancer causing\naround 75\\% of total skin cancer deaths. To diagnose Melanoma, clinicians\nassess and compare multiple skin lesions of the same patient concurrently to\ngather contextual information regarding the patterns, and abnormality of the\nskin. So far this concurrent multi-image comparative method has not been\nexplored by existing deep learning-based schemes. In this paper, based on\ncontextual image feature fusion (CIFF), a deep neural network (CIFF-Net) is\nproposed, which integrates patient-level contextual information into the\ntraditional approaches for improved Melanoma diagnosis by concurrent\nmulti-image comparative method. The proposed multi-kernel self attention (MKSA)\nmodule offers better generalization of the extracted features by introducing\nmulti-kernel operations in the self attention mechanisms. To utilize both self\nattention and contextual feature-wise attention, an attention guided module\nnamed contextual feature fusion (CFF) is proposed that integrates extracted\nfeatures from different contextual images into a single feature vector.\nFinally, in comparative contextual feature fusion (CCFF) module, primary and\ncontextual features are compared concurrently to generate comparative features.\nSignificant improvement in performance has been achieved on the ISIC-2020\ndataset over the traditional approaches that validate the effectiveness of the\nproposed contextual learning scheme.\n","authors":["Md Awsafur Rahman","Bishmoy Paul","Tanvir Mahmud","Shaikh Anowarul Fattah"],"pdf_url":"https://arxiv.org/pdf/2303.03672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15603v3","updated":"2023-03-07T06:14:56Z","published":"2022-11-28T17:57:48Z","title":"Action-GPT: Leveraging Large-scale Language Models for Improved and\n  Generalized Action Generation","summary":"  We introduce Action-GPT, a plug-and-play framework for incorporating Large\nLanguage Models (LLMs) into text-based action generation models. Action phrases\nin current motion capture datasets contain minimal and to-the-point\ninformation. By carefully crafting prompts for LLMs, we generate richer and\nfine-grained descriptions of the action. We show that utilizing these detailed\ndescriptions instead of the original action phrases leads to better alignment\nof text and motion spaces. We introduce a generic approach compatible with\nstochastic (e.g. VAE-based) and deterministic (e.g. MotionCLIP) text-to-motion\nmodels. In addition, the approach enables multiple text descriptions to be\nutilized. Our experiments show (i) noticeable qualitative and quantitative\nimprovement in the quality of synthesized motions, (ii) benefits of utilizing\nmultiple LLM-generated descriptions, (iii) suitability of the prompt function,\nand (iv) zero-shot generation capabilities of the proposed approach. Project\npage: https://actiongpt.github.io\n","authors":["Sai Shashank Kalakonda","Shubh Maheshwari","Ravi Kiran Sarvadevabhatla"],"pdf_url":"https://arxiv.org/pdf/2211.15603v3.pdf","comment":"Code, pretrained models and sample videos will be made available at\n  \\url{https://actiongpt.github.io}"},{"id":"http://arxiv.org/abs/2303.03667v1","updated":"2023-03-07T06:05:30Z","published":"2023-03-07T06:05:30Z","title":"Run, Don't Walk: Chasing Higher FLOPS for Faster Neural Networks","summary":"  To design fast neural networks, many works have been focusing on reducing the\nnumber of floating-point operations (FLOPs). We observe that such reduction in\nFLOPs, however, does not necessarily lead to a similar level of reduction in\nlatency. This mainly stems from inefficiently low floating-point operations per\nsecond (FLOPS). To achieve faster networks, we revisit popular operators and\ndemonstrate that such low FLOPS is mainly due to frequent memory access of the\noperators, especially the depthwise convolution. We hence propose a novel\npartial convolution (PConv) that extracts spatial features more efficiently, by\ncutting down redundant computation and memory access simultaneously. Building\nupon our PConv, we further propose FasterNet, a new family of neural networks,\nwhich attains substantially higher running speed than others on a wide range of\ndevices, without compromising on accuracy for various vision tasks. For\nexample, on ImageNet-1k, our tiny FasterNet-T0 is $3.1\\times$, $3.1\\times$, and\n$2.5\\times$ faster than MobileViT-XXS on GPU, CPU, and ARM processors,\nrespectively, while being $2.9\\%$ more accurate. Our large FasterNet-L achieves\nimpressive $83.5\\%$ top-1 accuracy, on par with the emerging Swin-B, while\nhaving $49\\%$ higher inference throughput on GPU, as well as saving $42\\%$\ncompute time on CPU. Code is available at\n\\url{https://github.com/JierunChen/FasterNet}.\n","authors":["Jierun Chen","Shiu-hong Kao","Hao He","Weipeng Zhuo","Song Wen","Chul-Ho Lee","S. -H. Gary Chan"],"pdf_url":"https://arxiv.org/pdf/2303.03667v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2211.03264v3","updated":"2023-03-07T05:43:56Z","published":"2022-11-07T02:18:27Z","title":"Few-shot Image Generation with Diffusion Models","summary":"  Denoising diffusion probabilistic models (DDPMs) have been proven capable of\nsynthesizing high-quality images with remarkable diversity when trained on\nlarge amounts of data. However, to our knowledge, few-shot image generation\ntasks have yet to be studied with DDPM-based approaches. Modern approaches are\nmainly built on Generative Adversarial Networks (GANs) and adapt models\npre-trained on large source domains to target domains using a few available\nsamples. In this paper, we make the first attempt to study when do DDPMs\noverfit and suffer severe diversity degradation as training data become scarce.\nThen we fine-tune DDPMs pre-trained on large source domains to solve the\noverfitting problem when training data is limited. Although the directly\nfine-tuned models accelerate convergence and improve generation quality and\ndiversity compared with training from scratch, they still fail to retain some\ndiverse features and can only produce coarse images. Therefore, we design a\nDDPM pairwise adaptation (DDPM-PA) approach to optimize few-shot DDPM domain\nadaptation. DDPM-PA efficiently preserves information learned from source\ndomains by keeping the relative pairwise distances between generated samples\nduring adaptation. Besides, DDPM-PA enhances the learning of high-frequency\ndetails from source models and limited training data. DDPM-PA further improves\ngeneration quality and diversity and achieves results better than current\nstate-of-the-art GAN-based approaches. We demonstrate the effectiveness of our\napproach on a series of few-shot image generation tasks qualitatively and\nquantitatively.\n","authors":["Jingyuan Zhu","Huimin Ma","Jiansheng Chen","Jian Yuan"],"pdf_url":"https://arxiv.org/pdf/2211.03264v3.pdf","comment":"Updated Version"},{"id":"http://arxiv.org/abs/2303.02968v2","updated":"2023-03-07T05:43:39Z","published":"2023-03-06T08:53:22Z","title":"DwinFormer: Dual Window Transformers for End-to-End Monocular Depth\n  Estimation","summary":"  Depth estimation from a single image is of paramount importance in the realm\nof computer vision, with a multitude of applications. Conventional methods\nsuffer from the trade-off between consistency and fine-grained details due to\nthe local-receptive field limiting their practicality. This lack of long-range\ndependency inherently comes from the convolutional neural network part of the\narchitecture. In this paper, a dual window transformer-based network, namely\nDwinFormer, is proposed, which utilizes both local and global features for\nend-to-end monocular depth estimation. The DwinFormer consists of dual window\nself-attention and cross-attention transformers, Dwin-SAT and Dwin-CAT,\nrespectively. The Dwin-SAT seamlessly extracts intricate, locally aware\nfeatures while concurrently capturing global context. It harnesses the power of\nlocal and global window attention to adeptly capture both short-range and\nlong-range dependencies, obviating the need for complex and computationally\nexpensive operations, such as attention masking or window shifting. Moreover,\nDwin-SAT introduces inductive biases which provide desirable properties, such\nas translational equvariance and less dependence on large-scale data.\nFurthermore, conventional decoding methods often rely on skip connections which\nmay result in semantic discrepancies and a lack of global context when fusing\nencoder and decoder features. In contrast, the Dwin-CAT employs both local and\nglobal window cross-attention to seamlessly fuse encoder and decoder features\nwith both fine-grained local and contextually aware global information,\neffectively amending semantic gap. Empirical evidence obtained through\nextensive experimentation on the NYU-Depth-V2 and KITTI datasets demonstrates\nthe superiority of the proposed method, consistently outperforming existing\napproaches across both indoor and outdoor environments.\n","authors":["Md Awsafur Rahman","Shaikh Anowarul Fattah"],"pdf_url":"https://arxiv.org/pdf/2303.02968v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.12735v3","updated":"2023-03-07T05:29:56Z","published":"2021-06-24T02:52:12Z","title":"Multi-Modal 3D Object Detection in Autonomous Driving: a Survey","summary":"  In this survey, we first introduce the background of popular sensors used for\nself-driving, their data properties, and the corresponding object detection\nalgorithms. Next, we discuss existing datasets that can be used for evaluating\nmulti-modal 3D object detection algorithms. Then we present a review of\nmulti-modal fusion based 3D detection networks, taking a close look at their\nfusion stage, fusion input and fusion granularity, and how these design choices\nevolve with time and technology. After the review, we discuss open challenges\nas well as possible solutions. We hope that this survey can help researchers to\nget familiar with the field and embark on investigations in the area of\nmulti-modal 3D object detection.\n","authors":["Yingjie Wang","Qiuyu Mao","Hanqi Zhu","Jiajun Deng","Yu Zhang","Jianmin Ji","Houqiang Li","Yanyong Zhang"],"pdf_url":"https://arxiv.org/pdf/2106.12735v3.pdf","comment":"Accepted by International Journal of Computer Vision (IJCV)"},{"id":"http://arxiv.org/abs/2211.12046v3","updated":"2023-03-07T05:13:18Z","published":"2022-11-22T06:40:53Z","title":"DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors","summary":"  Neural Radiance Field (NeRF) has exhibited outstanding three-dimensional (3D)\nreconstruction quality via the novel view synthesis from multi-view images and\npaired calibrated camera parameters. However, previous NeRF-based systems have\nbeen demonstrated under strictly controlled settings, with little attention\npaid to less ideal scenarios, including with the presence of noise such as\nexposure, illumination changes, and blur. In particular, though blur frequently\noccurs in real situations, NeRF that can handle blurred images has received\nlittle attention. The few studies that have investigated NeRF for blurred\nimages have not considered geometric and appearance consistency in 3D space,\nwhich is one of the most important factors in 3D reconstruction. This leads to\ninconsistency and the degradation of the perceptual quality of the constructed\nscene. Hence, this paper proposes a DP-NeRF, a novel clean NeRF framework for\nblurred images, which is constrained with two physical priors. These priors are\nderived from the actual blurring process during image acquisition by the\ncamera. DP-NeRF proposes rigid blurring kernel to impose 3D consistency\nutilizing the physical priors and adaptive weight proposal to refine the color\ncomposition error in consideration of the relationship between depth and blur.\nWe present extensive experimental results for synthetic and real scenes with\ntwo types of blur: camera motion blur and defocus blur. The results demonstrate\nthat DP-NeRF successfully improves the perceptual quality of the constructed\nNeRF ensuring 3D geometric and appearance consistency. We further demonstrate\nthe effectiveness of our model with comprehensive ablation analysis.\n","authors":["Dogyoon Lee","Minhyeok Lee","Chajin Shin","Sangyoun Lee"],"pdf_url":"https://arxiv.org/pdf/2211.12046v3.pdf","comment":"To be appeared at CVPR 2023, Code:\n  https://github.com/dogyoonlee/DP-NeRF, Project page:\n  https://dogyoonlee.github.io/dpnerf/"},{"id":"http://arxiv.org/abs/2204.11280v3","updated":"2023-03-07T05:01:02Z","published":"2022-04-24T13:54:42Z","title":"Deconstructed Generation-Based Zero-Shot Model","summary":"  Recent research on Generalized Zero-Shot Learning (GZSL) has focused\nprimarily on generation-based methods. However, current literature has\noverlooked the fundamental principles of these methods and has made limited\nprogress in a complex manner. In this paper, we aim to deconstruct the\ngenerator-classifier framework and provide guidance for its improvement and\nextension. We begin by breaking down the generator-learned unseen class\ndistribution into class-level and instance-level distributions. Through our\nanalysis of the role of these two types of distributions in solving the GZSL\nproblem, we generalize the focus of the generation-based approach, emphasizing\nthe importance of (i) attribute generalization in generator learning and (ii)\nindependent classifier learning with partially biased data. We present a simple\nmethod based on this analysis that outperforms SotAs on four public GZSL\ndatasets, demonstrating the validity of our deconstruction. Furthermore, our\nproposed method remains effective even without a generative model, representing\na step towards simplifying the generator-classifier structure. Our code is\navailable at \\url{https://github.com/cdb342/DGZ}.\n","authors":["Dubing Chen","Yuming Shen","Haofeng Zhang","Philip H. S. Torr"],"pdf_url":"https://arxiv.org/pdf/2204.11280v3.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2303.03651v1","updated":"2023-03-07T04:58:57Z","published":"2023-03-07T04:58:57Z","title":"F2BEV: Bird's Eye View Generation from Surround-View Fisheye Camera\n  Images for Automated Driving","summary":"  Bird's Eye View (BEV) representations are tremendously useful for\nperception-related automated driving tasks. However, generating BEVs from\nsurround-view fisheye camera images is challenging due to the strong\ndistortions introduced by such wide-angle lenses. We take the first step in\naddressing this challenge and introduce a baseline, F2BEV, to generate BEV\nheight maps and semantic segmentation maps from fisheye images. F2BEV consists\nof a distortion-aware spatial cross attention module for querying and\nconsolidating spatial information from fisheye image features in a\ntransformer-style architecture followed by a task-specific head. We evaluate\nsingle-task and multi-task variants of F2BEV on our synthetic FB-SSEM dataset,\nall of which generate better BEV height and segmentation maps (in terms of the\nIoU) than a state-of-the-art BEV generation method operating on undistorted\nfisheye images. We also demonstrate height map generation from real-world\nfisheye images using F2BEV. An initial sample of our dataset is publicly\navailable at https://tinyurl.com/58jvnscy\n","authors":["Ekta U. Samani","Feng Tao","Harshavardhan R. Dasari","Sihao Ding","Ashis G. Banerjee"],"pdf_url":"https://arxiv.org/pdf/2303.03651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03645v1","updated":"2023-03-07T04:26:44Z","published":"2023-03-07T04:26:44Z","title":"Filter Pruning based on Information Capacity and Independence","summary":"  Filter pruning has been widely used in the compression and acceleration of\nconvolutional neural networks (CNNs). However, most existing methods are still\nchallenged by heavy compute cost and biased filter selection. Moreover, most\ndesigns for filter evaluation miss interpretability due to the lack of\nappropriate theoretical guidance. In this paper, we propose a novel filter\npruning method which evaluates filters in a interpretable, multi-persepective\nand data-free manner. We introduce information capacity, a metric that\nrepresents the amount of information contained in a filter. Based on the\ninterpretability and validity of information entropy, we propose to use that as\na quantitative index of information quantity. Besides, we experimently show\nthat the obvious correlation between the entropy of the feature map and the\ncorresponding filter, so as to propose an interpretable, data-driven scheme to\nmeasure the information capacity of the filter. Further, we introduce\ninformation independence, another metric that represents the correlation among\ndifferrent filters. Consequently, the least impotant filters, which have less\ninformation capacity and less information independence, will be pruned. We\nevaluate our method on two benchmarks using multiple representative CNN\narchitectures, including VGG-16 and ResNet. On CIFAR-10, we reduce 71.9% of\nfloating-point operations (FLOPs) and 69.4% of parameters for ResNet-110 with\n0.28% accuracy increase. On ILSVRC-2012, we reduce 76.6% of floating-point\noperations (FLOPs) and 68.6% of parameters for ResNet-50 with only 2.80%\naccuracy decrease, which outperforms the state-of-the-arts.\n","authors":["Xiaolong Tang","Tianheng Hu","Yufeng Shi"],"pdf_url":"https://arxiv.org/pdf/2303.03645v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2208.02646v3","updated":"2023-03-07T04:23:53Z","published":"2022-08-04T13:24:04Z","title":"DropKey","summary":"  In this paper, we focus on analyzing and improving the dropout technique for\nself-attention layers of Vision Transformer, which is important while\nsurprisingly ignored by prior works. In particular, we conduct researches on\nthree core questions: First, what to drop in self-attention layers? Different\nfrom dropping attention weights in literature, we propose to move dropout\noperations forward ahead of attention matrix calculation and set the Key as the\ndropout unit, yielding a novel dropout-before-softmax scheme. We theoretically\nverify that this scheme helps keep both regularization and probability features\nof attention weights, alleviating the overfittings problem to specific patterns\nand enhancing the model to globally capture vital information; Second, how to\nschedule the drop ratio in consecutive layers? In contrast to exploit a\nconstant drop ratio for all layers, we present a new decreasing schedule that\ngradually decreases the drop ratio along the stack of self-attention layers. We\nexperimentally validate the proposed schedule can avoid overfittings in\nlow-level features and missing in high-level semantics, thus improving the\nrobustness and stableness of model training; Third, whether need to perform\nstructured dropout operation as CNN? We attempt patch-based block-version of\ndropout operation and find that this useful trick for CNN is not essential for\nViT. Given exploration on the above three questions, we present the novel\nDropKey method that regards Key as the drop unit and exploits decreasing\nschedule for drop ratio, improving ViTs in a general way. Comprehensive\nexperiments demonstrate the effectiveness of DropKey for various ViT\narchitectures, e.g. T2T and VOLO, as well as for various vision tasks, e.g.,\nimage classification, object detection, human-object interaction detection and\nhuman body shape recovery. Codes will be released upon acceptance.\n","authors":["Bonan Li","Yinhan Hu","Xuecheng Nie","Congying Han","Xiangjian Jiang","Tiande Guo","Luoqi Liu"],"pdf_url":"https://arxiv.org/pdf/2208.02646v3.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2302.13334v2","updated":"2023-03-07T04:01:46Z","published":"2023-02-26T15:34:05Z","title":"Knowledge Restore and Transfer for Multi-label Class-Incremental\n  Learning","summary":"  Current class-incremental learning research mainly focuses on single-label\nclassification tasks while multi-label class-incremental learning (MLCIL) with\nmore practical application scenarios is rarely studied. Although there have\nbeen many anti-forgetting methods to solve the problem of catastrophic\nforgetting in class-incremental learning, these methods have difficulty in\nsolving the MLCIL problem due to label absence and information dilution. In\nthis paper, we propose a knowledge restore and transfer (KRT) framework for\nMLCIL, which includes a dynamic pseudo-label (DPL) module to restore the old\nclass knowledge and an incremental cross-attention(ICA) module to save\nsession-specific knowledge and transfer old class knowledge to the new model\nsufficiently. Besides, we propose a token loss to jointly optimize the\nincremental cross-attention module. Experimental results on MS-COCO and PASCAL\nVOC datasets demonstrate the effectiveness of our method for improving\nrecognition performance and mitigating forgetting on multi-label\nclass-incremental learning tasks.\n","authors":["Songlin Dong","Haoyu Luo","Yuhang He","Xing Wei","Yihong Gong"],"pdf_url":"https://arxiv.org/pdf/2302.13334v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03231v2","updated":"2023-03-07T04:01:11Z","published":"2023-03-06T15:48:33Z","title":"StyO: Stylize Your Face in Only One-Shot","summary":"  This paper focuses on face stylization with a single artistic target.\nExisting works for this task often fail to retain the source content while\nachieving geometry variation. Here, we present a novel StyO model, ie. Stylize\nthe face in only One-shot, to solve the above problem. In particular, StyO\nexploits a disentanglement and recombination strategy. It first disentangles\nthe content and style of source and target images into identifiers, which are\nthen recombined in a cross manner to derive the stylized face image. In this\nway, StyO decomposes complex images into independent and specific attributes,\nand simplifies one-shot face stylization as the combination of different\nattributes from input images, thus producing results better matching face\ngeometry of target image and content of source one. StyO is implemented with\nlatent diffusion models (LDM) and composed of two key modules: 1) Identifier\nDisentanglement Learner (IDL) for disentanglement phase. It represents\nidentifiers as contrastive text prompts, ie. positive and negative\ndescriptions. And it introduces a novel triple reconstruction loss to fine-tune\nthe pre-trained LDM for encoding style and content into corresponding\nidentifiers; 2) Fine-grained Content Controller (FCC) for the recombination\nphase. It recombines disentangled identifiers from IDL to form an augmented\ntext prompt for generating stylized faces. In addition, FCC also constrains the\ncross-attention maps of latent and text features to preserve source face\ndetails in results. The extensive evaluation shows that StyO produces\nhigh-quality images on numerous paintings of various styles and outperforms the\ncurrent state-of-the-art. Code will be released upon acceptance.\n","authors":["Bonan Li","Zicheng Zhang","Xuecheng Nie","Congying Han","Yinhan Hu","Tiande Guo"],"pdf_url":"https://arxiv.org/pdf/2303.03231v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01032v2","updated":"2023-03-07T03:52:21Z","published":"2023-03-02T07:42:07Z","title":"ESceme: Vision-and-Language Navigation with Episodic Scene Memory","summary":"  Vision-and-language navigation (VLN) simulates a visual agent that follows\nnatural-language navigation instructions in real-world scenes. Existing\napproaches have made enormous progress in navigation in new environments, such\nas beam search, pre-exploration, and dynamic or hierarchical history encoding.\nTo balance generalization and efficiency, we resort to memorizing visited\nscenarios apart from the ongoing route while navigating. In this work, we\nintroduce a mechanism of Episodic Scene memory (ESceme) for VLN that wakes an\nagent's memories of past visits when it enters the current scene. The episodic\nscene memory allows the agent to envision a bigger picture of the next\nprediction. This way, the agent learns to utilize dynamically updated\ninformation instead of merely adapting to static observations. We provide a\nsimple yet effective implementation of ESceme by enhancing the accessible views\nat each location and progressively completing the memory while navigating. We\nverify the superiority of ESceme on short-horizon (R2R), long-horizon (R4R),\nand vision-and-dialog (CVDN) VLN tasks. Our ESceme also wins first place on the\nCVDN leaderboard. Code is available: \\url{https://github.com/qizhust/esceme}.}\n","authors":["Qi Zheng","Daqing Liu","Chaoyue Wang","Jing Zhang","Dadong Wang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.01032v2.pdf","comment":"Tech. report; typos corrected"},{"id":"http://arxiv.org/abs/2303.03633v1","updated":"2023-03-07T03:41:13Z","published":"2023-03-07T03:41:13Z","title":"Sketch-based Medical Image Retrieval","summary":"  The amount of medical images stored in hospitals is increasing faster than\never; however, utilizing the accumulated medical images has been limited. This\nis because existing content-based medical image retrieval (CBMIR) systems\nusually require example images to construct query vectors; nevertheless,\nexample images cannot always be prepared. Besides, there can be images with\nrare characteristics that make it difficult to find similar example images,\nwhich we call isolated samples. Here, we introduce a novel sketch-based medical\nimage retrieval (SBMIR) system that enables users to find images of interest\nwithout example images. The key idea lies in feature decomposition of medical\nimages, whereby the entire feature of a medical image can be decomposed into\nand reconstructed from normal and abnormal features. By extending this idea,\nour SBMIR system provides an easy-to-use two-step graphical user interface:\nusers first select a template image to specify a normal feature and then draw a\nsemantic sketch of the disease on the template image to represent an abnormal\nfeature. Subsequently, it integrates the two kinds of input to construct a\nquery vector and retrieves reference images with the closest reference vectors.\nUsing two datasets, ten healthcare professionals with various clinical\nbackgrounds participated in the user test for evaluation. As a result, our\nSBMIR system enabled users to overcome previous challenges, including image\nretrieval based on fine-grained image characteristics, image retrieval without\nexample images, and image retrieval for isolated samples. Our SBMIR system\nachieves flexible medical image retrieval on demand, thereby expanding the\nutility of medical image databases.\n","authors":["Kazuma Kobayashi","Lin Gu","Ryuichiro Hataya","Takaaki Mizuno","Mototaka Miyake","Hirokazu Watanabe","Masamichi Takahashi","Yasuyuki Takamizawa","Yukihiro Yoshida","Satoshi Nakamura","Nobuji Kouno","Amina Bolatkan","Yusuke Kurose","Tatsuya Harada","Ryuji Hamamoto"],"pdf_url":"https://arxiv.org/pdf/2303.03633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03630v1","updated":"2023-03-07T03:24:54Z","published":"2023-03-07T03:24:54Z","title":"No One Left Behind: Improving the Worst Categories in Long-Tailed\n  Learning","summary":"  Unlike the case when using a balanced training dataset, the per-class recall\n(i.e., accuracy) of neural networks trained with an imbalanced dataset are\nknown to vary a lot from category to category. The convention in long-tailed\nrecognition is to manually split all categories into three subsets and report\nthe average accuracy within each subset. We argue that under such an evaluation\nsetting, some categories are inevitably sacrificed. On one hand, focusing on\nthe average accuracy on a balanced test set incurs little penalty even if some\nworst performing categories have zero accuracy. On the other hand, classes in\nthe \"Few\" subset do not necessarily perform worse than those in the \"Many\" or\n\"Medium\" subsets. We therefore advocate to focus more on improving the lowest\nrecall among all categories and the harmonic mean of all recall values.\nSpecifically, we propose a simple plug-in method that is applicable to a wide\nrange of methods. By simply re-training the classifier of an existing\npre-trained model with our proposed loss function and using an optional\nensemble trick that combines the predictions of the two classifiers, we achieve\na more uniform distribution of recall values across categories, which leads to\na higher harmonic mean accuracy while the (arithmetic) average accuracy is\nstill high. The effectiveness of our method is justified on widely used\nbenchmark datasets.\n","authors":["Yingxiao Du","Jianxin Wu"],"pdf_url":"https://arxiv.org/pdf/2303.03630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03625v1","updated":"2023-03-07T03:17:49Z","published":"2023-03-07T03:17:49Z","title":"SGDA: Towards 3D Universal Pulmonary Nodule Detection via Slice Grouped\n  Domain Attention","summary":"  Lung cancer is the leading cause of cancer death worldwide. The best solution\nfor lung cancer is to diagnose the pulmonary nodules in the early stage, which\nis usually accomplished with the aid of thoracic computed tomography (CT). As\ndeep learning thrives, convolutional neural networks (CNNs) have been\nintroduced into pulmonary nodule detection to help doctors in this\nlabor-intensive task and demonstrated to be very effective. However, the\ncurrent pulmonary nodule detection methods are usually domain-specific, and\ncannot satisfy the requirement of working in diverse real-world scenarios. To\naddress this issue, we propose a slice grouped domain attention (SGDA) module\nto enhance the generalization capability of the pulmonary nodule detection\nnetworks. This attention module works in the axial, coronal, and sagittal\ndirections. In each direction, we divide the input feature into groups, and for\neach group, we utilize a universal adapter bank to capture the feature\nsubspaces of the domains spanned by all pulmonary nodule datasets. Then the\nbank outputs are combined from the perspective of domain to modulate the input\ngroup. Extensive experiments demonstrate that SGDA enables substantially better\nmulti-domain pulmonary nodule detection performance compared with the\nstate-of-the-art multi-domain learning methods.\n","authors":["Rui Xu","Zhi Liu","Yong Luo","Han Hu","Li Shen","Bo Du","Kaiming Kuang","Jiancheng Yang"],"pdf_url":"https://arxiv.org/pdf/2303.03625v1.pdf","comment":"Accepted by IEEE/ACM Transactions on Computational Biology and\n  Bioinformatics"},{"id":"http://arxiv.org/abs/2207.09339v2","updated":"2023-03-07T03:17:12Z","published":"2022-07-19T15:49:35Z","title":"Vision Transformers: From Semantic Segmentation to Dense Prediction","summary":"  The emergence of vision transformers (ViTs) in image classification has\nshifted the methodologies for visual representation learning. In particular,\nViTs learn visual representation at full receptive field per layer across all\nthe image patches, in comparison to the increasing receptive fields of CNNs\nacross layers and other alternatives (e.g., large kernels and atrous\nconvolution). In this work, for the first time we explore the global context\nlearning potentials of ViTs for dense visual prediction (e.g., semantic\nsegmentation). Our motivation is that through learning global context at full\nreceptive field layer by layer, ViTs may capture stronger long-range dependency\ninformation, critical for dense prediction tasks. We first demonstrate that\nencoding an image as a sequence of patches, a vanilla ViT without local\nconvolution and resolution reduction can yield stronger visual representation\nfor semantic segmentation. For example, our model, termed as SEgmentation\nTRansformer (SETR), excels on ADE20K (50.28% mIoU, the first position in the\ntest leaderboard on the day of submission) and Pascal Context (55.83% mIoU),\nand performs competitively on Cityscapes. For tackling general dense visual\nprediction tasks in a cost-effective manner, we further formulate a family of\nHierarchical Local-Global (HLG) Transformers, characterized by local attention\nwithin windows and global-attention across windows in a pyramidal architecture.\nExtensive experiments show that our methods achieve appealing performance on a\nvariety of dense prediction tasks (e.g., object detection and instance\nsegmentation and semantic segmentation) as well as image classification. Our\ncode and models are available at https://github.com/fudan-zvg/SETR.\n","authors":["Li Zhang","Jiachen Lu","Sixiao Zheng","Xinxuan Zhao","Xiatian Zhu","Yanwei Fu","Tao Xiang","Jianfeng Feng"],"pdf_url":"https://arxiv.org/pdf/2207.09339v2.pdf","comment":"Extended version of CVPR 2021 paper arXiv:2012.15840"},{"id":"http://arxiv.org/abs/2211.08064v2","updated":"2023-03-07T02:46:34Z","published":"2022-11-15T11:34:30Z","title":"Physics-Informed Machine Learning: A Survey on Problems, Methods and\n  Applications","summary":"  Recent advances of data-driven machine learning have revolutionized fields\nlike computer vision, reinforcement learning, and many scientific and\nengineering domains. In many real-world and scientific problems, systems that\ngenerate data are governed by physical laws. Recent work shows that it provides\npotential benefits for machine learning models by incorporating the physical\nprior and collected data, which makes the intersection of machine learning and\nphysics become a prevailing paradigm. By integrating the data and mathematical\nphysics models seamlessly, it can guide the machine learning model towards\nsolutions that are physically plausible, improving accuracy and efficiency even\nin uncertain and high-dimensional contexts. In this survey, we present this\nlearning paradigm called Physics-Informed Machine Learning (PIML) which is to\nbuild a model that leverages empirical data and available physical prior\nknowledge to improve performance on a set of tasks that involve a physical\nmechanism. We systematically review the recent development of physics-informed\nmachine learning from three perspectives of machine learning tasks,\nrepresentation of physical prior, and methods for incorporating physical prior.\nWe also propose several important open research problems based on the current\ntrends in the field. We argue that encoding different forms of physical prior\ninto model architectures, optimizers, inference algorithms, and significant\ndomain-specific applications like inverse engineering design and robotic\ncontrol is far from being fully explored in the field of physics-informed\nmachine learning. We believe that the interdisciplinary research of\nphysics-informed machine learning will significantly propel research progress,\nfoster the creation of more effective machine learning models, and also offer\ninvaluable assistance in addressing long-standing problems in related\ndisciplines.\n","authors":["Zhongkai Hao","Songming Liu","Yichi Zhang","Chengyang Ying","Yao Feng","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2211.08064v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12739v2","updated":"2023-03-07T02:32:53Z","published":"2023-01-30T09:03:10Z","title":"FractalAD: A simple industrial anomaly detection method using fractal\n  anomaly generation and backbone knowledge distillation","summary":"  Although industrial anomaly detection (AD) technology has made significant\nprogress in recent years, generating realistic anomalies and learning priors of\nnormal remain challenging tasks. In this study, we propose an end-to-end\nindustrial anomaly detection method called FractalAD. Training samples are\nobtained by synthesizing fractal images and patches from normal samples. This\nfractal anomaly generation method is designed to sample the full morphology of\nanomalies. Moreover, we designed a backbone knowledge distillation structure to\nextract prior knowledge contained in normal samples. The differences between a\nteacher and a student model are converted into anomaly attention using a cosine\nsimilarity attention module. The proposed method enables an end-to-end semantic\nsegmentation network to be used for anomaly detection without adding any\ntrainable parameters to the backbone and segmentation head, and has obvious\nadvantages over other methods in training and inference speed.. The results of\nablation studies confirmed the effectiveness of fractal anomaly generation and\nbackbone knowledge distillation. The results of performance experiments showed\nthat FractalAD achieved competitive results on the MVTec AD dataset and MVTec\n3D-AD dataset compared with other state-of-the-art anomaly detection methods.\n","authors":["Xuan Xia","Weijie Lv","Xing He","Nan Li","Chuanqi Liu","Ning Ding"],"pdf_url":"https://arxiv.org/pdf/2301.12739v2.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.03599v1","updated":"2023-03-07T02:31:08Z","published":"2023-03-07T02:31:08Z","title":"FSVVD: A Dataset of Full Scene Volumetric Video","summary":"  Recent years have witnessed a rapid development of immersive multimedia which\nbridges the gap between the real world and virtual space. Volumetric videos, as\nan emerging representative 3D video paradigm that empowers extended reality,\nstand out to provide unprecedented immersive and interactive video watching\nexperience. Despite the tremendous potential, the research towards 3D\nvolumetric video is still in its infancy, relying on sufficient and complete\ndatasets for further exploration. However, existing related volumetric video\ndatasets mostly only include a single object, lacking details about the scene\nand the interaction between them. In this paper, we focus on the current most\nwidely used data format, point cloud, and for the first time release a\nfull-scene volumetric video dataset that includes multiple people and their\ndaily activities interacting with the external environments. Comprehensive\ndataset description and analysis are conducted, with potential usage of this\ndataset. The dataset and additional tools can be accessed via the following\nwebsite: https://cuhksz-inml.github.io/full_scene_volumetric_video_dataset/.\n","authors":["Kaiyuan Hu","Yili Jin","Haowen Yang","Junhua Liu","Fangxin Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03599v1.pdf","comment":"Accepted by MMSys'23 Open Dataset and Software Track, A preliminary\n  version. The dataset and additional tools can be accessed via\n  https://cuhksz-inml.github.io/full_scene_volumetric_video_dataset/"},{"id":"http://arxiv.org/abs/2210.00030v2","updated":"2023-03-07T02:29:59Z","published":"2022-09-30T18:14:07Z","title":"VIP: Towards Universal Visual Reward and Representation via\n  Value-Implicit Pre-Training","summary":"  Reward and representation learning are two long-standing challenges for\nlearning an expanding set of robot manipulation skills from sensory\nobservations. Given the inherent cost and scarcity of in-domain, task-specific\nrobot data, learning from large, diverse, offline human videos has emerged as a\npromising path towards acquiring a generally useful visual representation for\ncontrol; however, how these human videos can be used for general-purpose reward\nlearning remains an open question. We introduce\n$\\textbf{V}$alue-$\\textbf{I}$mplicit $\\textbf{P}$re-training (VIP), a\nself-supervised pre-trained visual representation capable of generating dense\nand smooth reward functions for unseen robotic tasks. VIP casts representation\nlearning from human videos as an offline goal-conditioned reinforcement\nlearning problem and derives a self-supervised dual goal-conditioned\nvalue-function objective that does not depend on actions, enabling pre-training\non unlabeled human videos. Theoretically, VIP can be understood as a novel\nimplicit time contrastive objective that generates a temporally smooth\nembedding, enabling the value function to be implicitly defined via the\nembedding distance, which can then be used to construct the reward for any\ngoal-image specified downstream task. Trained on large-scale Ego4D human videos\nand without any fine-tuning on in-domain, task-specific data, VIP's frozen\nrepresentation can provide dense visual reward for an extensive set of\nsimulated and $\\textbf{real-robot}$ tasks, enabling diverse reward-based visual\ncontrol methods and significantly outperforming all prior pre-trained\nrepresentations. Notably, VIP can enable simple, $\\textbf{few-shot}$ offline RL\non a suite of real-world robot tasks with as few as 20 trajectories.\n","authors":["Yecheng Jason Ma","Shagun Sodhani","Dinesh Jayaraman","Osbert Bastani","Vikash Kumar","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.00030v2.pdf","comment":"ICLR 2023, Notable-Top-25% (Spotlight). Project website:\n  https://sites.google.com/view/vip-rl"},{"id":"http://arxiv.org/abs/2303.03598v1","updated":"2023-03-07T02:29:36Z","published":"2023-03-07T02:29:36Z","title":"Guided Image-to-Image Translation by Discriminator-Generator\n  Communication","summary":"  The goal of Image-to-image (I2I) translation is to transfer an image from a\nsource domain to a target domain, which has recently drawn increasing\nattention. One major branch of this research is to formulate I2I translation\nbased on Generative Adversarial Network (GAN). As a zero-sum game, GAN can be\nreformulated as a Partially-observed Markov Decision Process (POMDP) for\ngenerators, where generators cannot access full state information of their\nenvironments. This formulation illustrates the information insufficiency in the\nGAN training. To mitigate this problem, we propose to add a communication\nchannel between discriminators and generators. We explore multiple architecture\ndesigns to integrate the communication mechanism into the I2I translation\nframework. To validate the performance of the proposed approach, we have\nconducted extensive experiments on various benchmark datasets. The experimental\nresults confirm the superiority of our proposed method.\n","authors":["Yuanjiang Cao","Lina Yao","Le Pan","Quan Z. Sheng","Xiaojun Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02307v3","updated":"2023-03-07T02:14:39Z","published":"2022-06-06T01:30:03Z","title":"Bootstrapping Semi-supervised Medical Image Segmentation with\n  Anatomical-aware Contrastive Distillation","summary":"  Contrastive learning has shown great promise over annotation scarcity\nproblems in the context of medical image segmentation. Existing approaches\ntypically assume a balanced class distribution for both labeled and unlabeled\nmedical images. However, medical image data in reality is commonly imbalanced\n(i.e., multi-class label imbalance), which naturally yields blurry contours and\nusually incorrectly labels rare objects. Moreover, it remains unclear whether\nall negative samples are equally negative. In this work, we present ACTION, an\nAnatomical-aware ConTrastive dIstillatiON framework, for semi-supervised\nmedical image segmentation. Specifically, we first develop an iterative\ncontrastive distillation algorithm by softly labeling the negatives rather than\nbinary supervision between positive and negative pairs. We also capture more\nsemantically similar features from the randomly chosen negative set compared to\nthe positives to enforce the diversity of the sampled data. Second, we raise a\nmore important question: Can we really handle imbalanced samples to yield\nbetter performance? Hence, the key innovation in ACTION is to learn global\nsemantic relationship across the entire dataset and local anatomical features\namong the neighbouring pixels with minimal additional memory footprint. During\nthe training, we introduce anatomical contrast by actively sampling a sparse\nset of hard negative pixels, which can generate smoother segmentation\nboundaries and more accurate predictions. Extensive experiments across two\nbenchmark datasets and different unlabeled settings show that ACTION\nsignificantly outperforms the current state-of-the-art semi-supervised methods.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2206.02307v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.05869v2","updated":"2023-03-07T02:10:21Z","published":"2022-05-12T03:54:35Z","title":"View Synthesis with Sculpted Neural Points","summary":"  We address the task of view synthesis, generating novel views of a scene\ngiven a set of images as input. In many recent works such as NeRF (Mildenhall\net al., 2020), the scene geometry is parameterized using neural implicit\nrepresentations (i.e., MLPs). Implicit neural representations have achieved\nimpressive visual quality but have drawbacks in computational efficiency. In\nthis work, we propose a new approach that performs view synthesis using point\nclouds. It is the first point-based method that achieves better visual quality\nthan NeRF while being 100x faster in rendering speed. Our approach builds on\nexisting works on differentiable point-based rendering but introduces a novel\ntechnique we call \"Sculpted Neural Points (SNP)\", which significantly improves\nthe robustness to errors and holes in the reconstructed point cloud. We further\npropose to use view-dependent point features based on spherical harmonics to\ncapture non-Lambertian surfaces, and new designs in the point-based rendering\npipeline that further boost the performance. Finally, we show that our system\nsupports fine-grained scene editing. Code is available at\nhttps://github.com/princeton-vl/SNP.\n","authors":["Yiming Zuo","Jia Deng"],"pdf_url":"https://arxiv.org/pdf/2205.05869v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02733v2","updated":"2023-03-07T02:07:01Z","published":"2023-03-05T17:57:33Z","title":"Reparameterization through Spatial Gradient Scaling","summary":"  Reparameterization aims to improve the generalization of deep neural networks\nby transforming convolutional layers into equivalent multi-branched structures\nduring training. However, there exists a gap in understanding how\nreparameterization may change and benefit the learning process of neural\nnetworks. In this paper, we present a novel spatial gradient scaling method to\nredistribute learning focus among weights in convolutional networks. We prove\nthat spatial gradient scaling achieves the same learning dynamics as a branched\nreparameterization yet without introducing structural changes into the network.\nWe further propose an analytical approach that dynamically learns scalings for\neach convolutional layer based on the spatial characteristics of its input\nfeature map gauged by mutual information. Experiments on CIFAR-10, CIFAR-100,\nand ImageNet show that without searching for reparameterized structures, our\nproposed scaling method outperforms the state-of-the-art reparameterization\nstrategies at a lower computational cost.\n","authors":["Alexander Detkov","Mohammad Salameh","Muhammad Fetrat Qharabagh","Jialin Zhang","Wei Lui","Shangling Jui","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2303.02733v2.pdf","comment":"Published at ICLR 2023. Code available at\n  https://github.com/Ascend-Research/Reparameterization"},{"id":"http://arxiv.org/abs/2303.03595v1","updated":"2023-03-07T02:00:34Z","published":"2023-03-07T02:00:34Z","title":"LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global\n  Cross-Modal Fusion","summary":"  LiDAR-camera fusion methods have shown impressive performance in 3D object\ndetection. Recent advanced multi-modal methods mainly perform global fusion,\nwhere image features and point cloud features are fused across the whole scene.\nSuch practice lacks fine-grained region-level information, yielding suboptimal\nfusion performance. In this paper, we present the novel Local-to-Global fusion\nnetwork (LoGoNet), which performs LiDAR-camera fusion at both local and global\nlevels. Concretely, the Global Fusion (GoF) of LoGoNet is built upon previous\nliterature, while we exclusively use point centroids to more precisely\nrepresent the position of voxel features, thus achieving better cross-modal\nalignment. As to the Local Fusion (LoF), we first divide each proposal into\nuniform grids and then project these grid centers to the images. The image\nfeatures around the projected grid points are sampled to be fused with\nposition-decorated point cloud features, maximally utilizing the rich\ncontextual information around the proposals. The Feature Dynamic Aggregation\n(FDA) module is further proposed to achieve information interaction between\nthese locally and globally fused features, thus producing more informative\nmulti-modal features. Extensive experiments on both Waymo Open Dataset (WOD)\nand KITTI datasets show that LoGoNet outperforms all state-of-the-art 3D\ndetection methods. Notably, LoGoNet ranks 1st on Waymo 3D object detection\nleaderboard and obtains 81.02 mAPH (L2) detection performance. It is noteworthy\nthat, for the first time, the detection performance on three classes surpasses\n80 APH (L2) simultaneously. Code will be available at\n\\url{https://github.com/sankin97/LoGoNet}.\n","authors":["Xin Li","Tao Ma","Yuenan Hou","Botian Shi","Yucheng Yang","Youquan Liu","Xingjiao Wu","Qin Chen","Yikang Li","Yu Qiao","Liang He"],"pdf_url":"https://arxiv.org/pdf/2303.03595v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2303.03583v1","updated":"2023-03-07T01:31:06Z","published":"2023-03-07T01:31:06Z","title":"Calibration-free BEV Representation for Infrastructure Perception","summary":"  Effective BEV object detection on infrastructure can greatly improve traffic\nscenes understanding and vehicle-toinfrastructure (V2I) cooperative perception.\nHowever, cameras installed on infrastructure have various postures, and\nprevious BEV detection methods rely on accurate calibration, which is difficult\nfor practical applications due to inevitable natural factors (e.g., wind and\nsnow). In this paper, we propose a Calibration-free BEV Representation (CBR)\nnetwork, which achieves 3D detection based on BEV representation without\ncalibration parameters and additional depth supervision. Specifically, we\nutilize two multi-layer perceptrons for decoupling the features from\nperspective view to front view and birdeye view under boxes-induced foreground\nsupervision. Then, a cross-view feature fusion module matches features from\northogonal views according to similarity and conducts BEV feature enhancement\nwith front view features. Experimental results on DAIR-V2X demonstrate that CBR\nachieves acceptable performance without any camera parameters and is naturally\nnot affected by calibration noises. We hope CBR can serve as a baseline for\nfuture research addressing practical challenges of infrastructure perception.\n","authors":["Siqi Fan","Zhe Wang","Xiaoliang Huo","Yan Wang","Jingjing Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03565v1","updated":"2023-03-07T00:26:02Z","published":"2023-03-07T00:26:02Z","title":"CLIP-Layout: Style-Consistent Indoor Scene Synthesis with Semantic\n  Furniture Embedding","summary":"  Indoor scene synthesis involves automatically picking and placing furniture\nappropriately on a floor plan, so that the scene looks realistic and is\nfunctionally plausible. Such scenes can serve as a home for immersive 3D\nexperiences, or be used to train embodied agents. Existing methods for this\ntask rely on labeled categories of furniture, e.g. bed, chair or table, to\ngenerate contextually relevant combinations of furniture. Whether heuristic or\nlearned, these methods ignore instance-level attributes of objects such as\ncolor and style, and as a result may produce visually less coherent scenes. In\nthis paper, we introduce an auto-regressive scene model which can output\ninstance-level predictions, making use of general purpose image embedding based\non CLIP. This allows us to learn visual correspondences such as matching color\nand style, and produce more plausible and aesthetically pleasing scenes.\nEvaluated on the 3D-FRONT dataset, our model achieves SOTA results in scene\ngeneration and improves auto-completion metrics by over 50%. Moreover, our\nembedding-based approach enables zero-shot text-guided scene generation and\nediting, which easily generalizes to furniture not seen at training time.\n","authors":["Jingyu Liu","Wenhan Xiong","Ian Jones","Yixin Nie","Anchit Gupta","Barlas Oğuz"],"pdf_url":"https://arxiv.org/pdf/2303.03565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04291v1","updated":"2023-03-07T23:52:51Z","published":"2023-03-07T23:52:51Z","title":"Diffusion in the Dark: A Diffusion Model for Low-Light Text Recognition","summary":"  Images are indispensable for the automation of high-level tasks, such as text\nrecognition. Low-light conditions pose a challenge for these high-level\nperception stacks, which are often optimized on well-lit, artifact-free images.\nReconstruction methods for low-light images can produce well-lit counterparts,\nbut typically at the cost of high-frequency details critical for downstream\ntasks. We propose Diffusion in the Dark (DiD), a diffusion model for low-light\nimage reconstruction that provides qualitatively competitive reconstructions\nwith that of SOTA, while preserving high-frequency details even in extremely\nnoisy, dark conditions. We demonstrate that DiD, without any task-specific\noptimization, can outperform SOTA low-light methods in low-light text\nrecognition on real images, bolstering the potential of diffusion models for\nill-posed inverse problems.\n","authors":["Cindy M. Nguyen","Eric R. Chan","Alexander W. Bergman","Gordon Wetzstein"],"pdf_url":"https://arxiv.org/pdf/2303.04291v1.pdf","comment":"Project website: https://ccnguyen.github.io/diffusion-in-the-dark/"},{"id":"http://arxiv.org/abs/2211.01202v2","updated":"2023-03-07T23:44:29Z","published":"2022-11-02T15:27:31Z","title":"Human-in-the-Loop Mixup","summary":"  Aligning model representations to humans has been found to improve robustness\nand generalization. However, such methods often focus on standard observational\ndata. Synthetic data is proliferating and powering many advances in machine\nlearning; yet, it is not always clear whether synthetic labels are perceptually\naligned to humans -- rendering it likely model representations are not human\naligned. We focus on the synthetic data used in mixup: a powerful regularizer\nshown to improve model robustness, generalization, and calibration. We design a\ncomprehensive series of elicitation interfaces, which we release as HILL MixE\nSuite, and recruit 159 participants to provide perceptual judgments along with\ntheir uncertainties, over mixup examples. We find that human perceptions do not\nconsistently align with the labels traditionally used for synthetic points, and\nbegin to demonstrate the applicability of these findings to potentially\nincrease the reliability of downstream models, particularly when incorporating\nhuman uncertainty. We release all elicited judgments in a new data hub we call\nH-Mix.\n","authors":["Katherine M. Collins","Umang Bhatt","Weiyang Liu","Vihari Piratla","Ilia Sucholutsky","Bradley Love","Adrian Weller"],"pdf_url":"https://arxiv.org/pdf/2211.01202v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04278v1","updated":"2023-03-07T22:57:23Z","published":"2023-03-07T22:57:23Z","title":"CUDA: Convolution-based Unlearnable Datasets","summary":"  Large-scale training of modern deep learning models heavily relies on\npublicly available data on the web. This potentially unauthorized usage of\nonline data leads to concerns regarding data privacy. Recent works aim to make\nunlearnable data for deep learning models by adding small, specially designed\nnoises to tackle this issue. However, these methods are vulnerable to\nadversarial training (AT) and/or are computationally heavy. In this work, we\npropose a novel, model-free, Convolution-based Unlearnable DAtaset (CUDA)\ngeneration technique. CUDA is generated using controlled class-wise\nconvolutions with filters that are randomly generated via a private key. CUDA\nencourages the network to learn the relation between filters and labels rather\nthan informative features for classifying the clean data. We develop some\ntheoretical analysis demonstrating that CUDA can successfully poison Gaussian\nmixture data by reducing the clean data performance of the optimal Bayes\nclassifier. We also empirically demonstrate the effectiveness of CUDA with\nvarious datasets (CIFAR-10, CIFAR-100, ImageNet-100, and Tiny-ImageNet), and\narchitectures (ResNet-18, VGG-16, Wide ResNet-34-10, DenseNet-121, DeIT,\nEfficientNetV2-S, and MobileNetV2). Our experiments show that CUDA is robust to\nvarious data augmentations and training approaches such as smoothing, AT with\ndifferent budgets, transfer learning, and fine-tuning. For instance, training a\nResNet-18 on ImageNet-100 CUDA achieves only 8.96$\\%$, 40.08$\\%$, and 20.58$\\%$\nclean test accuracies with empirical risk minimization (ERM), $L_{\\infty}$ AT,\nand $L_{2}$ AT, respectively. Here, ERM on the clean training data achieves a\nclean test accuracy of 80.66$\\%$. CUDA exhibits unlearnability effect with ERM\neven when only a fraction of the training dataset is perturbed. Furthermore, we\nalso show that CUDA is robust to adaptive defenses designed specifically to\nbreak it.\n","authors":["Vinu Sankar Sadasivan","Mahdi Soltanolkotabi","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2303.04278v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.04275v1","updated":"2023-03-07T22:53:36Z","published":"2023-03-07T22:53:36Z","title":"A Computer Vision Enabled damage detection model with improved YOLOv5\n  based on Transformer Prediction Head","summary":"  Objective:Computer vision-based up-to-date accurate damage classification and\nlocalization are of decisive importance for infrastructure monitoring, safety,\nand the serviceability of civil infrastructure. Current state-of-the-art deep\nlearning (DL)-based damage detection models, however, often lack superior\nfeature extraction capability in complex and noisy environments, limiting the\ndevelopment of accurate and reliable object distinction. Method: To this end,\nwe present DenseSPH-YOLOv5, a real-time DL-based high-performance damage\ndetection model where DenseNet blocks have been integrated with the backbone to\nimprove in preserving and reusing critical feature information. Additionally,\nconvolutional block attention modules (CBAM) have been implemented to improve\nattention performance mechanisms for strong and discriminating deep spatial\nfeature extraction that results in superior detection under various challenging\nenvironments. Moreover, additional feature fusion layers and a Swin-Transformer\nPrediction Head (SPH) have been added leveraging advanced self-attention\nmechanism for more efficient detection of multiscale object sizes and\nsimultaneously reducing the computational complexity. Results: Evaluating the\nmodel performance in large-scale Road Damage Dataset (RDD-2018), at a detection\nrate of 62.4 FPS, DenseSPH-YOLOv5 obtains a mean average precision (mAP) value\nof 85.25 %, F1-score of 81.18 %, and precision (P) value of 89.51 %\noutperforming current state-of-the-art models. Significance: The present\nresearch provides an effective and efficient damage localization model\naddressing the shortcoming of existing DL-based damage detection models by\nproviding highly accurate localized bounding box prediction. Current work\nconstitutes a step towards an accurate and robust automated damage detection\nsystem in real-time in-field applications.\n","authors":["Arunabha M. Roy","Jayabrata Bhaduri"],"pdf_url":"https://arxiv.org/pdf/2303.04275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04269v1","updated":"2023-03-07T22:42:13Z","published":"2023-03-07T22:42:13Z","title":"PSDNet: Determination of Particle Size Distributions Using Synthetic\n  Soil Images and Convolutional Neural Networks","summary":"  This project aimed to determine the grain size distribution of granular\nmaterials from images using convolutional neural networks. The application of\nConvNet and pretrained ConvNet models, including AlexNet, SqueezeNet,\nGoogLeNet, InceptionV3, DenseNet201, MobileNetV2, ResNet18, ResNet50,\nResNet101, Xception, InceptionResNetV2, ShuffleNet, and NASNetMobile was\nstudied. Synthetic images of granular materials created with the discrete\nelement code YADE were used. All the models were trained and verified with\ngrayscale and color band datasets with image sizes ranging from 32 to 160\npixels. The proposed ConvNet model predicts the percentages of mass retained on\nthe finest sieve, coarsest sieve, and all sieves with root-mean-square errors\nof 1.8 %, 3.3 %, and 2.8 %, respectively, and a coefficient of determination of\n0.99. For pretrained networks, root-mean-square errors of 2.4 % and 2.8 % were\nobtained for the finest sieve with feature extraction and transfer learning\nmodels, respectively.\n","authors":["Javad Manashti","Pouyan Pirnia","Alireza Manashty","Sahar Ujan","Matthew Toews","François Duhaime"],"pdf_url":"https://arxiv.org/pdf/2303.04269v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04265v1","updated":"2023-03-07T22:29:38Z","published":"2023-03-07T22:29:38Z","title":"Comparing PSDNet, pretrained networks, and traditional feature\n  extraction for predicting the particle size distribution of granular\n  materials from photographs","summary":"  This study aims to evaluate PSDNet, a series of convolutional neural networks\n(ConvNets) trained with photographs to predict the particle size distribution\nof granular materials. Nine traditional feature extraction methods and 15\npretrained ConvNets were also evaluated and compared. A dataset including 9600\nphotographs of 15 different granular materials was used. The influence of image\nsize and color band was verified by using six image sizes between 32 and 160\npixels, and both grayscale and color images as PSDNet inputs. In addition to\nrandom training, validation, and testing datasets, a material removal method\nwas also used to evaluate the performances of each image analysis method. With\nthis method, each material was successively removed from the training and\nvalidation datasets and used as the testing dataset. Results show that a\ncombination of all PSDNet color and grayscale features can lead to a root mean\nsquare error (RMSE) on the percentages passing as low as 1.8 % with a random\ntesting dataset and 9.1% with the material removal method. For the random\ndatasets, a combination of all traditional features, and the features extracted\nfrom InceptionResNetV2 led to RMSE on the percentages passing of 2.3 and 1.7 %,\nrespectively.\n","authors":["Javad Manashti","François Duhaime","Matthew F. Toews","Pouyan Pirnia","Jn Kinsonn Telcy"],"pdf_url":"https://arxiv.org/pdf/2303.04265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.03509v4","updated":"2023-03-07T22:13:20Z","published":"2021-04-08T04:52:21Z","title":"Py-Feat: Python Facial Expression Analysis Toolbox","summary":"  Studying facial expressions is a notoriously difficult endeavor. Recent\nadvances in the field of affective computing have yielded impressive progress\nin automatically detecting facial expressions from pictures and videos.\nHowever, much of this work has yet to be widely disseminated in social science\ndomains such as psychology. Current state of the art models require\nconsiderable domain expertise that is not traditionally incorporated into\nsocial science training programs. Furthermore, there is a notable absence of\nuser-friendly and open-source software that provides a comprehensive set of\ntools and functions that support facial expression research. In this paper, we\nintroduce Py-Feat, an open-source Python toolbox that provides support for\ndetecting, preprocessing, analyzing, and visualizing facial expression data.\nPy-Feat makes it easy for domain experts to disseminate and benchmark computer\nvision models and also for end users to quickly process, analyze, and visualize\nface expression data. We hope this platform will facilitate increased use of\nfacial expression data in human behavior research.\n","authors":["Jin Hyun Cheong","Eshin Jolly","Tiankang Xie","Sophie Byrne","Matthew Kenney","Luke J. Chang"],"pdf_url":"https://arxiv.org/pdf/2104.03509v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04253v1","updated":"2023-03-07T21:52:10Z","published":"2023-03-07T21:52:10Z","title":"SKGHOI: Spatial-Semantic Knowledge Graph for Human-Object Interaction\n  Detection","summary":"  Detecting human-object interactions (HOIs) is a challenging problem in\ncomputer vision. Existing techniques for HOI detection heavily rely on\nappearance-based features, which may not capture other essential\ncharacteristics for accurate detection. Furthermore, the use of\ntransformer-based models for sentiment representation of human-object pairs can\nbe computationally expensive. To address these challenges, we propose a novel\ngraph-based approach, SKGHOI (Spatial-Semantic Knowledge Graph for Human-Object\nInteraction Detection), that effectively captures the sentiment representation\nof HOIs by integrating both spatial and semantic knowledge. In a graph, SKGHOI\ntakes the components of interaction as nodes, and the spatial relationships\nbetween them as edges. Our approach employs a spatial encoder and a semantic\nencoder to extract spatial and semantic information, respectively, and then\ncombines these encodings to create a knowledge graph that captures the\nsentiment representation of HOIs. Compared to existing techniques, SKGHOI is\ncomputationally efficient and allows for the incorporation of prior knowledge,\nmaking it practical for use in real-world applications. We demonstrate the\neffectiveness of our proposed method on the widely-used HICO-DET datasets,\nwhere it outperforms existing state-of-the-art graph-based methods by a\nsignificant margin. Our results indicate that the SKGHOI approach has the\npotential to significantly improve the accuracy and efficiency of HOI\ndetection, and we anticipate that it will be of great interest to researchers\nand practitioners working on this challenging task.\n","authors":["Lijing Zhu","Qizhen Lan","Alvaro Velasquez","Houbing Song","Acharya Kamal","Qing Tian","Shuteng Niu"],"pdf_url":"https://arxiv.org/pdf/2303.04253v1.pdf","comment":"10 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2303.04249v1","updated":"2023-03-07T21:47:58Z","published":"2023-03-07T21:47:58Z","title":"Where We Are and What We're Looking At: Query Based Worldwide Image\n  Geo-localization Using Hierarchies and Scenes","summary":"  Determining the exact latitude and longitude that a photo was taken is a\nuseful and widely applicable task, yet it remains exceptionally difficult\ndespite the accelerated progress of other computer vision tasks. Most previous\napproaches have opted to learn a single representation of query images, which\nare then classified at different levels of geographic granularity. These\napproaches fail to exploit the different visual cues that give context to\ndifferent hierarchies, such as the country, state, and city level. To this end,\nwe introduce an end-to-end transformer-based architecture that exploits the\nrelationship between different geographic levels (which we refer to as\nhierarchies) and the corresponding visual scene information in an image through\nhierarchical cross-attention. We achieve this by learning a query for each\ngeographic hierarchy and scene type. Furthermore, we learn a separate\nrepresentation for different environmental scenes, as different scenes in the\nsame location are often defined by completely different visual features. We\nachieve state of the art street level accuracy on 4 standard geo-localization\ndatasets : Im2GPS, Im2GPS3k, YFCC4k, and YFCC26k, as well as qualitatively\ndemonstrate how our method learns different representations for different\nvisual hierarchies and scenes, which has not been demonstrated in the previous\nmethods. These previous testing datasets mostly consist of iconic landmarks or\nimages taken from social media, which makes them either a memorization task, or\nbiased towards certain places. To address this issue we introduce a much harder\ntesting dataset, Google-World-Streets-15k, comprised of images taken from\nGoogle Streetview covering the whole planet and present state of the art\nresults. Our code will be made available in the camera-ready version.\n","authors":["Brandon Clark","Alec Kerrigan","Parth Parag Kulkarni","Vicente Vivanco Cepeda","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2303.04249v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.04248v1","updated":"2023-03-07T21:46:15Z","published":"2023-03-07T21:46:15Z","title":"TRACT: Denoising Diffusion Models with Transitive Closure\n  Time-Distillation","summary":"  Denoising Diffusion models have demonstrated their proficiency for generative\nsampling. However, generating good samples often requires many iterations.\nConsequently, techniques such as binary time-distillation (BTD) have been\nproposed to reduce the number of network calls for a fixed architecture. In\nthis paper, we introduce TRAnsitive Closure Time-distillation (TRACT), a new\nmethod that extends BTD. For single step diffusion,TRACT improves FID by up to\n2.4x on the same architecture, and achieves new single-step Denoising Diffusion\nImplicit Models (DDIM) state-of-the-art FID (7.4 for ImageNet64, 3.8 for\nCIFAR10). Finally we tease apart the method through extended ablations. The\nPyTorch implementation will be released soon.\n","authors":["David Berthelot","Arnaud Autef","Jierui Lin","Dian Ang Yap","Shuangfei Zhai","Siyuan Hu","Daniel Zheng","Walter Talbot","Eric Gu"],"pdf_url":"https://arxiv.org/pdf/2303.04248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04244v1","updated":"2023-03-07T21:35:02Z","published":"2023-03-07T21:35:02Z","title":"A Light-Weight Contrastive Approach for Aligning Human Pose Sequences","summary":"  We present a simple unsupervised method for learning an encoder mapping short\n3D pose sequences into embedding vectors suitable for sequence-to-sequence\nalignment by dynamic time warping. Training samples consist of temporal windows\nof frames containing 3D body points such as mocap markers or skeleton joints. A\nlight-weight, 3-layer encoder is trained using a contrastive loss function that\nencourages embedding vectors of augmented sample pairs to have cosine\nsimilarity 1, and similarity 0 with all other samples in a minibatch. When\nmultiple scripted training sequences are available, temporal alignments\ninferred from an initial round of training are harvested to extract additional,\ncross-performance match pairs for a second phase of training to refine the\nencoder. In addition to being simple, the proposed method is fast to train,\nmaking it easy to adapt to new data using different marker sets or skeletal\njoint layouts. Experimental results illustrate ease of use, transferability,\nand utility of the learned embeddings for comparing and analyzing human\nbehavior sequences.\n","authors":["Robert T. Collins"],"pdf_url":"https://arxiv.org/pdf/2303.04244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04240v1","updated":"2023-03-07T21:09:09Z","published":"2023-03-07T21:09:09Z","title":"Gradient-Guided Knowledge Distillation for Object Detectors","summary":"  Deep learning models have demonstrated remarkable success in object\ndetection, yet their complexity and computational intensity pose a barrier to\ndeploying them in real-world applications (e.g., self-driving perception).\nKnowledge Distillation (KD) is an effective way to derive efficient models.\nHowever, only a small number of KD methods tackle object detection. Also, most\nof them focus on mimicking the plain features of the teacher model but rarely\nconsider how the features contribute to the final detection. In this paper, we\npropose a novel approach for knowledge distillation in object detection, named\nGradient-guided Knowledge Distillation (GKD). Our GKD uses gradient information\nto identify and assign more weights to features that significantly impact the\ndetection loss, allowing the student to learn the most relevant features from\nthe teacher. Furthermore, we present bounding-box-aware multi-grained feature\nimitation (BMFI) to further improve the KD performance. Experiments on the\nKITTI and COCO-Traffic datasets demonstrate our method's efficacy in knowledge\ndistillation for object detection. On one-stage and two-stage detectors, our\nGKD-BMFI leads to an average of 5.1% and 3.8% mAP improvement, respectively,\nbeating various state-of-the-art KD methods.\n","authors":["Qizhen Lan","Qing Tian"],"pdf_url":"https://arxiv.org/pdf/2303.04240v1.pdf","comment":"9 pages include references, 4 figures, and 4 tables"},{"id":"http://arxiv.org/abs/2303.04238v1","updated":"2023-03-07T21:03:48Z","published":"2023-03-07T21:03:48Z","title":"Patch of Invisibility: Naturalistic Black-Box Adversarial Attacks on\n  Object Detectors","summary":"  Adversarial attacks on deep-learning models have been receiving increased\nattention in recent years. Work in this area has mostly focused on\ngradient-based techniques, so-called white-box attacks, wherein the attacker\nhas access to the targeted model's internal parameters; such an assumption is\nusually unrealistic in the real world. Some attacks additionally use the entire\npixel space to fool a given model, which is neither practical nor physical\n(i.e., real-world). On the contrary, we propose herein a gradient-free method\nthat uses the learned image manifold of a pretrained generative adversarial\nnetwork (GAN) to generate naturalistic physical adversarial patches for object\ndetectors. We show that our proposed method works both digitally and\nphysically.\n","authors":["Raz Lapid","Moshe Sipper"],"pdf_url":"https://arxiv.org/pdf/2303.04238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09211v2","updated":"2023-03-07T21:03:26Z","published":"2022-09-19T17:26:32Z","title":"Neural Collapse with Normalized Features: A Geometric Analysis over the\n  Riemannian Manifold","summary":"  When training overparameterized deep networks for classification tasks, it\nhas been widely observed that the learned features exhibit a so-called \"neural\ncollapse\" phenomenon. More specifically, for the output features of the\npenultimate layer, for each class the within-class features converge to their\nmeans, and the means of different classes exhibit a certain tight frame\nstructure, which is also aligned with the last layer's classifier. As feature\nnormalization in the last layer becomes a common practice in modern\nrepresentation learning, in this work we theoretically justify the neural\ncollapse phenomenon for normalized features. Based on an unconstrained feature\nmodel, we simplify the empirical loss function in a multi-class classification\ntask into a nonconvex optimization problem over the Riemannian manifold by\nconstraining all features and classifiers over the sphere. In this context, we\nanalyze the nonconvex landscape of the Riemannian optimization problem over the\nproduct of spheres, showing a benign global landscape in the sense that the\nonly global minimizers are the neural collapse solutions while all other\ncritical points are strict saddles with negative curvature. Experimental\nresults on practical deep networks corroborate our theory and demonstrate that\nbetter representations can be learned faster via feature normalization.\n","authors":["Can Yaras","Peng Wang","Zhihui Zhu","Laura Balzano","Qing Qu"],"pdf_url":"https://arxiv.org/pdf/2209.09211v2.pdf","comment":"The first two authors contributed to this work equally; 38 pages, 13\n  figures. Accepted at NeurIPS'22"},{"id":"http://arxiv.org/abs/2303.04208v1","updated":"2023-03-07T19:58:57Z","published":"2023-03-07T19:58:57Z","title":"EscherNet 101","summary":"  A deep learning model, EscherNet 101, is constructed to categorize images of\n2D periodic patterns into their respective 17 wallpaper groups. Beyond\nevaluating EscherNet 101 performance by classification rates, at a micro-level\nwe investigate the filters learned at different layers in the network, capable\nof capturing second-order invariants beyond edge and curvature.\n","authors":["Christopher Funk","Yanxi Liu"],"pdf_url":"https://arxiv.org/pdf/2303.04208v1.pdf","comment":"16 page, 12 figures"},{"id":"http://arxiv.org/abs/2303.04204v1","updated":"2023-03-07T19:49:11Z","published":"2023-03-07T19:49:11Z","title":"Deep hybrid model with satellite imagery: how to combine demand modeling\n  and computer vision for behavior analysis?","summary":"  Classical demand modeling analyzes travel behavior using only low-dimensional\nnumeric data (i.e. sociodemographics and travel attributes) but not\nhigh-dimensional urban imagery. However, travel behavior depends on the factors\nrepresented by both numeric data and urban imagery, thus necessitating a\nsynergetic framework to combine them. This study creates a theoretical\nframework of deep hybrid models with a crossing structure consisting of a\nmixing operator and a behavioral predictor, thus integrating the numeric and\nimagery data into a latent space. Empirically, this framework is applied to\nanalyze travel mode choice using the MyDailyTravel Survey from Chicago as the\nnumeric inputs and the satellite images as the imagery inputs. We found that\ndeep hybrid models outperform both the traditional demand models and the recent\ndeep learning in predicting the aggregate and disaggregate travel behavior with\nour supervision-as-mixing design. The latent space in deep hybrid models can be\ninterpreted, because it reveals meaningful spatial and social patterns. The\ndeep hybrid models can also generate new urban images that do not exist in\nreality and interpret them with economic theory, such as computing substitution\npatterns and social welfare changes. Overall, the deep hybrid models\ndemonstrate the complementarity between the low-dimensional numeric and\nhigh-dimensional imagery data and between the traditional demand modeling and\nrecent deep learning. It generalizes the latent classes and variables in\nclassical hybrid demand models to a latent space, and leverages the\ncomputational power of deep learning for imagery while retaining the economic\ninterpretability on the microeconomics foundation.\n","authors":["Qingyi Wang","Shenhao Wang","Yunhan Zheng","Hongzhou Lin","Xiaohu Zhang","Jinhua Zhao","Joan Walker"],"pdf_url":"https://arxiv.org/pdf/2303.04204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04203v1","updated":"2023-03-07T19:47:01Z","published":"2023-03-07T19:47:01Z","title":"Toward a Geometric Theory of Manifold Untangling","summary":"  It has been hypothesized that the ventral stream processing for object\nrecognition is based on a mechanism called cortically local subspace\nuntangling. A mathematical abstraction of object recognition by the visual\ncortex is how to untangle the manifolds associated with different object\ncategory. Such a manifold untangling problem is closely related to the\ncelebrated kernel trick in metric space. In this paper, we conjecture that\nthere is a more general solution to manifold untangling in the topological\nspace without artificially defining any distance metric. Geometrically, we can\neither $embed$ a manifold in a higher dimensional space to promote selectivity\nor $flatten$ a manifold to promote tolerance. General strategies of both global\nmanifold embedding and local manifold flattening are presented and connected\nwith existing work on the untangling of image, audio, and language data. We\nalso discuss the implications of untangling the manifold into motor control and\ninternal representations.\n","authors":["Xin Li","Shuo Wang"],"pdf_url":"https://arxiv.org/pdf/2303.04203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05339v3","updated":"2023-03-07T19:35:43Z","published":"2023-01-13T00:20:05Z","title":"A Comprehensive Review of Data-Driven Co-Speech Gesture Generation","summary":"  Gestures that accompany speech are an essential part of natural and efficient\nembodied human communication. The automatic generation of such co-speech\ngestures is a long-standing problem in computer animation and is considered an\nenabling technology in film, games, virtual social spaces, and for interaction\nwith social robots. The problem is made challenging by the idiosyncratic and\nnon-periodic nature of human co-speech gesture motion, and by the great\ndiversity of communicative functions that gestures encompass. Gesture\ngeneration has seen surging interest recently, owing to the emergence of more\nand larger datasets of human gesture motion, combined with strides in\ndeep-learning-based generative models, that benefit from the growing\navailability of data. This review article summarizes co-speech gesture\ngeneration research, with a particular focus on deep generative models. First,\nwe articulate the theory describing human gesticulation and how it complements\nspeech. Next, we briefly discuss rule-based and classical statistical gesture\nsynthesis, before delving into deep learning approaches. We employ the choice\nof input modalities as an organizing principle, examining systems that generate\ngestures from audio, text, and non-linguistic input. We also chronicle the\nevolution of the related training data sets in terms of size, diversity, motion\nquality, and collection method. Finally, we identify key research challenges in\ngesture generation, including data availability and quality; producing\nhuman-like motion; grounding the gesture in the co-occurring speech in\ninteraction with other speakers, and in the environment; performing gesture\nevaluation; and integration of gesture synthesis into applications. We\nhighlight recent approaches to tackling the various key challenges, as well as\nthe limitations of these approaches, and point toward areas of future\ndevelopment.\n","authors":["Simbarashe Nyatsanga","Taras Kucherenko","Chaitanya Ahuja","Gustav Eje Henter","Michael Neff"],"pdf_url":"https://arxiv.org/pdf/2301.05339v3.pdf","comment":"Accepted for EUROGRAPHICS 2023"},{"id":"http://arxiv.org/abs/2303.04188v1","updated":"2023-03-07T19:23:33Z","published":"2023-03-07T19:23:33Z","title":"Clustering large 3D volumes: A sampling-based approach","summary":"  In many applications of X-ray computed tomography, an unsupervised\nsegmentation of the reconstructed 3D volumes forms an important step in the\nimage processing chain for further investigation of the digitized object.\nTherefore, the goal is to train a clustering algorithm on the volume, which\nproduces a voxelwise classification by assigning a cluster index to each voxel.\nHowever, clustering methods, e.g., K-Means, typically have an asymptotic\npolynomial runtime with respect to the dataset size, and thus, these techniques\nare rarely applicable to large volumes. In this work, we introduce a novel\nclustering technique based on random sampling, which allows for the voxelwise\nclassification of arbitrarily large volumes. The presented method conducts\nefficient linear passes over the data to extract a representative random sample\nof a fixed size on which the classifier can be trained. Then, a final linear\npass performs the segmentation and assigns a cluster index to each individual\nvoxel. Quantitative and qualitative evaluations show that excellent results can\nbe achieved even with a very small sample size. Consequently, the unsupervised\nsegmentation by means of clustering becomes feasible for arbitrarily large\nvolumes.\n","authors":["Thomas Lang"],"pdf_url":"https://arxiv.org/pdf/2303.04188v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.04186v1","updated":"2023-03-07T19:16:20Z","published":"2023-03-07T19:16:20Z","title":"End-to-end Face-swapping via Adaptive Latent Representation Learning","summary":"  Taking full advantage of the excellent performance of StyleGAN, style\ntransfer-based face swapping methods have been extensively investigated\nrecently. However, these studies require separate face segmentation and\nblending modules for successful face swapping, and the fixed selection of the\nmanipulated latent code in these works is reckless, thus degrading face\nswapping quality, generalizability, and practicability. This paper proposes a\nnovel and end-to-end integrated framework for high resolution and attribute\npreservation face swapping via Adaptive Latent Representation Learning.\nSpecifically, we first design a multi-task dual-space face encoder by sharing\nthe underlying feature extraction network to simultaneously complete the facial\nregion perception and face encoding. This encoder enables us to control the\nface pose and attribute individually, thus enhancing the face swapping quality.\nNext, we propose an adaptive latent codes swapping module to adaptively learn\nthe mapping between the facial attributes and the latent codes and select\neffective latent codes for improved retention of facial attributes. Finally,\nthe initial face swapping image generated by StyleGAN2 is blended with the\nfacial region mask generated by our encoder to address the background blur\nproblem. Our framework integrating facial perceiving and blending into the\nend-to-end training and testing process can achieve high realistic\nface-swapping on wild faces without segmentation masks. Experimental results\ndemonstrate the superior performance of our approach over state-of-the-art\nmethods.\n","authors":["Chenhao Lin","Pengbin Hu","Chao Shen","Qian Li"],"pdf_url":"https://arxiv.org/pdf/2303.04186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04183v1","updated":"2023-03-07T19:09:03Z","published":"2023-03-07T19:09:03Z","title":"Robustness-preserving Lifelong Learning via Dataset Condensation","summary":"  Lifelong learning (LL) aims to improve a predictive model as the data source\nevolves continuously. Most work in this learning paradigm has focused on\nresolving the problem of 'catastrophic forgetting,' which refers to a notorious\ndilemma between improving model accuracy over new data and retaining accuracy\nover previous data. Yet, it is also known that machine learning (ML) models can\nbe vulnerable in the sense that tiny, adversarial input perturbations can\ndeceive the models into producing erroneous predictions. This motivates the\nresearch objective of this paper - specification of a new LL framework that can\nsalvage model robustness (against adversarial attacks) from catastrophic\nforgetting. Specifically, we propose a new memory-replay LL strategy that\nleverages modern bi-level optimization techniques to determine the 'coreset' of\nthe current data (i.e., a small amount of data to be memorized) for ease of\npreserving adversarial robustness over time. We term the resulting LL framework\n'Data-Efficient Robustness-Preserving LL' (DERPLL). The effectiveness of DERPLL\nis evaluated for class-incremental image classification using ResNet-18 over\nthe CIFAR-10 dataset. Experimental results show that DERPLL outperforms the\nconventional coreset-guided LL baseline and achieves a substantial improvement\nin both standard accuracy and robust accuracy.\n","authors":["Jinghan Jia","Yihua Zhang","Dogyoon Song","Sijia Liu","Alfred Hero"],"pdf_url":"https://arxiv.org/pdf/2303.04183v1.pdf","comment":"Accepted by ICASSP2023 Main Track: Machine Learning for Signal\n  Processing"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2102.13392v3","updated":"2023-03-07T14:56:18Z","published":"2021-02-26T11:01:30Z","title":"Unifying Remote Sensing Image Retrieval and Classification with Robust\n  Fine-tuning","summary":"  Advances in high resolution remote sensing image analysis are currently\nhampered by the difficulty of gathering enough annotated data for training deep\nlearning methods, giving rise to a variety of small datasets and associated\ndataset-specific methods. Moreover, typical tasks such as classification and\nretrieval lack a systematic evaluation on standard benchmarks and training\ndatasets, which make it hard to identify durable and generalizable scientific\ncontributions. We aim at unifying remote sensing image retrieval and\nclassification with a new large-scale training and testing dataset, SF300,\nincluding both vertical and oblique aerial images and made available to the\nresearch community, and an associated fine-tuning method. We additionally\npropose a new adversarial fine-tuning method for global descriptors. We show\nthat our framework systematically achieves a boost of retrieval and\nclassification performance on nine different datasets compared to an ImageNet\npretrained baseline, with currently no other method to compare to.\n","authors":["Dimitri Gominski","Valérie Gouet-Brunet","Liming Chen"],"pdf_url":"https://arxiv.org/pdf/2102.13392v3.pdf","comment":"Performance margin with the proposed method is not statistically\n  significant. Please refer to http://alegoria.ign.fr/en/SF300_dataset if you\n  are interested in the dataset"},{"id":"http://arxiv.org/abs/2210.00305v2","updated":"2023-03-07T14:35:33Z","published":"2022-10-01T16:01:53Z","title":"LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph\n  Embeddings","summary":"  Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. Text-based KG embeddings\ncan represent entities by encoding descriptions with pre-trained language\nmodels, but no open-sourced library is specifically designed for KGs with PLMs\nat present. In this paper, we present LambdaKG, a library for KGE that equips\nwith many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and\nsupports various tasks (e.g., knowledge graph completion, question answering,\nrecommendation, and knowledge probing). LambdaKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at\nhttp://deepke.zjukg.cn/lambdakg.mp4 and long-term maintenance.\n","authors":["Xin Xie","Zhoubo Li","Xiaohan Wang","Yuqi Zhu","Ningyu Zhang","Jintian Zhang","Siyuan Cheng","Bozhong Tian","Shumin Deng","Feiyu Xiong","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00305v2.pdf","comment":"Work in progress and the project website is\n  https://zjunlp.github.io/project/promptkg/"},{"id":"http://arxiv.org/abs/2202.12524v4","updated":"2023-03-07T03:21:01Z","published":"2022-02-25T06:58:28Z","title":"MAMDR: A Model Agnostic Learning Method for Multi-Domain Recommendation","summary":"  Large-scale e-commercial platforms in the real-world usually contain various\nrecommendation scenarios (domains) to meet demands of diverse customer groups.\nMulti-Domain Recommendation (MDR), which aims to jointly improve\nrecommendations on all domains and easily scales to thousands of domains, has\nattracted increasing attention from practitioners and researchers. Existing MDR\nmethods usually employ a shared structure and several specific components to\nrespectively leverage reusable features and domain-specific information.\nHowever, data distribution differs across domains, making it challenging to\ndevelop a general model that can be applied to all circumstances. Additionally,\nduring training, shared parameters often suffer from the domain conflict while\nspecific parameters are inclined to overfitting on data sparsity domains. we\nfirst present a scalable MDR platform served in Taobao that enables to provide\nservices for thousands of domains without specialists involved. To address the\nproblems of MDR methods, we propose a novel model agnostic learning framework,\nnamely MAMDR, for the multi-domain recommendation. Specifically, we first\npropose a Domain Negotiation (DN) strategy to alleviate the conflict between\ndomains. Then, we develop a Domain Regularization (DR) to improve the\ngeneralizability of specific parameters by learning from other domains. We\nintegrate these components into a unified framework and present MAMDR, which\ncan be applied to any model structure to perform multi-domain recommendation.\nFinally, we present a large-scale implementation of MAMDR in the Taobao\napplication and construct various public MDR benchmark datasets which can be\nused for following studies. Extensive experiments on both benchmark datasets\nand industry datasets demonstrate the effectiveness and generalizability of\nMAMDR.\n","authors":["Linhao Luo","Yumeng Li","Buyu Gao","Shuai Tang","Sinan Wang","Jiancheng Li","Tanchao Zhu","Jiancai Liu","Zhao Li","Shirui Pan"],"pdf_url":"https://arxiv.org/pdf/2202.12524v4.pdf","comment":"This paper has been accepted by ICDE 2023"},{"id":"http://arxiv.org/abs/2212.08841v2","updated":"2023-03-07T20:51:26Z","published":"2022-12-17T10:43:25Z","title":"AugTriever: Unsupervised Dense Retrieval by Scalable Data Augmentation","summary":"  Dense retrievers have made significant strides in text retrieval and\nopen-domain question answering, even though most achievements were made\npossible only with large amounts of human supervision. In this work, we aim to\ndevelop unsupervised methods by proposing two methods that create pseudo\nquery-document pairs and train dense retrieval models in an annotation-free and\nscalable manner: query extraction and transferred query generation. The former\nmethod produces pseudo queries by selecting salient spans from the original\ndocument. The latter utilizes generation models trained for other NLP tasks\n(e.g., summarization) to produce pseudo queries. Extensive experiments show\nthat models trained with the proposed augmentation methods can perform\ncomparably well (or better) to multiple strong baselines. Combining those\nstrategies leads to further improvements, achieving the state-of-the-art\nperformance of unsupervised dense retrieval on both BEIR and ODQA datasets.\n","authors":["Rui Meng","Ye Liu","Semih Yavuz","Divyansh Agarwal","Lifu Tu","Ning Yu","Jianguo Zhang","Meghana Bhat","Yingbo Zhou"],"pdf_url":"https://arxiv.org/pdf/2212.08841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04188v1","updated":"2023-03-07T19:23:33Z","published":"2023-03-07T19:23:33Z","title":"Clustering large 3D volumes: A sampling-based approach","summary":"  In many applications of X-ray computed tomography, an unsupervised\nsegmentation of the reconstructed 3D volumes forms an important step in the\nimage processing chain for further investigation of the digitized object.\nTherefore, the goal is to train a clustering algorithm on the volume, which\nproduces a voxelwise classification by assigning a cluster index to each voxel.\nHowever, clustering methods, e.g., K-Means, typically have an asymptotic\npolynomial runtime with respect to the dataset size, and thus, these techniques\nare rarely applicable to large volumes. In this work, we introduce a novel\nclustering technique based on random sampling, which allows for the voxelwise\nclassification of arbitrarily large volumes. The presented method conducts\nefficient linear passes over the data to extract a representative random sample\nof a fixed size on which the classifier can be trained. Then, a final linear\npass performs the segmentation and assigns a cluster index to each individual\nvoxel. Quantitative and qualitative evaluations show that excellent results can\nbe achieved even with a very small sample size. Consequently, the unsupervised\nsegmentation by means of clustering becomes feasible for arbitrarily large\nvolumes.\n","authors":["Thomas Lang"],"pdf_url":"https://arxiv.org/pdf/2303.04188v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.04689v1","updated":"2023-03-07T17:22:38Z","published":"2023-03-07T17:22:38Z","title":"A Privacy Preserving System for Movie Recommendations using Federated\n  Learning","summary":"  Recommender systems have become ubiquitous in the past years. They solve the\ntyranny of choice problem faced by many users, and are employed by many online\nbusinesses to drive engagement and sales. Besides other criticisms, like\ncreating filter bubbles within social networks, recommender systems are often\nreproved for collecting considerable amounts of personal data. However, to\npersonalize recommendations, personal information is fundamentally required. A\nrecent distributed learning scheme called federated learning has made it\npossible to learn from personal user data without its central collection.\nAccordingly, we present a complete recommender system for movie\nrecommendations, which provides privacy and thus trustworthiness on two levels:\nFirst, it is trained using federated learning and thus is, by its very nature,\nprivacy-preserving, while still enabling individual users to benefit from\nglobal insights. And second, a novel federated learning scheme, FedQ, is\nemployed, which not only addresses the problem of non-i.i.d. and small local\ndatasets, but also prevents input data reconstruction attacks by aggregating\nclient models early. To reduce the communication overhead, compression is\napplied, which significantly reduces the exchanged neural network updates to a\nfraction of their original data. We conjecture that it may also improve data\nprivacy through its lossy quantization stage.\n","authors":["David Neumann","Andreas Lutz","Karsten Müller","Wojciech Samek"],"pdf_url":"https://arxiv.org/pdf/2303.04689v1.pdf","comment":"Submitted to the ACM TORS Special Issue on Trustworthy Recommender\n  Systems"},{"id":"http://arxiv.org/abs/2303.05392v1","updated":"2023-03-07T17:30:48Z","published":"2023-03-07T17:30:48Z","title":"Automatically Summarizing Evidence from Clinical Trials: A Prototype\n  Highlighting Current Challenges","summary":"  We present TrialsSummarizer, a system that aims to automatically summarize\nevidence presented in the set of randomized controlled trials most relevant to\na given query. Building on prior work, the system retrieves trial publications\nmatching a query specifying a combination of condition, intervention(s), and\noutcome(s), and ranks these according to sample size and estimated study\nquality. The top-k such studies are passed through a neural multi-document\nsummarization system, yielding a synopsis of these trials. We consider two\narchitectures: A standard sequence-to-sequence model based on BART and a\nmulti-headed architecture intended to provide greater transparency to\nend-users. Both models produce fluent and relevant summaries of evidence\nretrieved for queries, but their tendency to introduce unsupported statements\nrender them inappropriate for use in this domain at present. The proposed\narchitecture may help users verify outputs allowing users to trace generated\ntokens back to inputs.\n","authors":["Sanjana Ramprasad","Denis Jered McInerney","Iain J. Marshal","Byron C. Wallace"],"pdf_url":"https://arxiv.org/pdf/2303.05392v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2203.01924v2","updated":"2023-03-07T18:59:48Z","published":"2022-03-03T18:56:13Z","title":"Min-Max Bilevel Multi-objective Optimization with Applications in\n  Machine Learning","summary":"  We consider a generic min-max multi-objective bilevel optimization problem\nwith applications in robust machine learning such as representation learning\nand hyperparameter optimization. We design MORBiT, a novel single-loop gradient\ndescent-ascent bilevel optimization algorithm, to solve the generic problem and\npresent a novel analysis showing that MORBiT converges to the first-order\nstationary point at a rate of $\\widetilde{\\mathcal{O}}(n^{1/2} K^{-2/5})$ for a\nclass of weakly convex problems with $n$ objectives upon $K$ iterations of the\nalgorithm. Our analysis utilizes novel results to handle the non-smooth min-max\nmulti-objective setup and to obtain a sublinear dependence in the number of\nobjectives $n$. Experimental results on robust representation learning and\nrobust hyperparameter optimization showcase (i) the advantages of considering\nthe min-max multi-objective setup, and (ii) convergence properties of the\nproposed MORBiT. Our code is at https://github.com/minimario/MORBiT.\n","authors":["Alex Gu","Songtao Lu","Parikshit Ram","Lily Weng"],"pdf_url":"https://arxiv.org/pdf/2203.01924v2.pdf","comment":"43 pages, 3 figures, ICLR 2023 version"},{"id":"http://arxiv.org/abs/2303.04145v1","updated":"2023-03-07T18:59:38Z","published":"2023-03-07T18:59:38Z","title":"Benign Overfitting for Two-layer ReLU Networks","summary":"  Modern deep learning models with great expressive power can be trained to\noverfit the training data but still generalize well. This phenomenon is\nreferred to as benign overfitting. Recently, a few studies have attempted to\ntheoretically understand benign overfitting in neural networks. However, these\nworks are either limited to neural networks with smooth activation functions or\nto the neural tangent kernel regime. How and when benign overfitting can occur\nin ReLU neural networks remains an open problem. In this work, we seek to\nanswer this question by establishing algorithm-dependent risk bounds for\nlearning two-layer ReLU convolutional neural networks with label-flipping\nnoise. We show that, under mild conditions, the neural network trained by\ngradient descent can achieve near-zero training loss and Bayes optimal test\nrisk. Our result also reveals a sharp transition between benign and harmful\noverfitting under different conditions on data distribution in terms of test\nrisk. Experiments on synthetic data back up our theory.\n","authors":["Yiwen Kou","Zixiang Chen","Yuanzhou Chen","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2303.04145v1.pdf","comment":"54 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2303.04143v1","updated":"2023-03-07T18:56:59Z","published":"2023-03-07T18:56:59Z","title":"Can We Scale Transformers to Predict Parameters of Diverse ImageNet\n  Models?","summary":"  Pretraining a neural network on a large dataset is becoming a cornerstone in\nmachine learning that is within the reach of only a few communities with\nlarge-resources. We aim at an ambitious goal of democratizing pretraining.\nTowards that goal, we train and release a single neural network that can\npredict high quality ImageNet parameters of other neural networks. By using\npredicted parameters for initialization we are able to boost training of\ndiverse ImageNet models available in PyTorch. When transferred to other\ndatasets, models initialized with predicted parameters also converge faster and\nreach competitive final performance.\n","authors":["Boris Knyazev","Doha Hwang","Simon Lacoste-Julien"],"pdf_url":"https://arxiv.org/pdf/2303.04143v1.pdf","comment":"Code and models are available at\n  https://github.com/SamsungSAILMontreal/ghn3"},{"id":"http://arxiv.org/abs/2303.04142v1","updated":"2023-03-07T18:56:52Z","published":"2023-03-07T18:56:52Z","title":"From Copilot to Pilot: Towards AI Supported Software Development","summary":"  AI-supported programming has arrived, as shown by the introduction and\nsuccesses of large language models for code, such as Copilot/Codex\n(Github/OpenAI) and AlphaCode (DeepMind). Above human average performance on\nprogramming challenges is now possible. However, software engineering is much\nmore than solving programming contests. Moving beyond code completion to\nAI-supported software engineering will require an AI system that can, among\nother things, understand how to avoid code smells, to follow language idioms,\nand eventually (maybe!) propose rational software designs. In this study, we\nexplore the current limitations of AI-supported code completion tools like\nCopilot and offer a simple taxonomy for understanding the classification of\nAI-supported code completion tools in this space. We first perform an\nexploratory study on Copilot's code suggestions for language idioms and code\nsmells. Copilot does not follow language idioms and avoid code smells in most\nof our test scenarios. We then conduct additional investigation to determine\nthe current boundaries of AI-supported code completion tools like Copilot by\nintroducing a taxonomy of software abstraction hierarchies where 'basic\nprogramming functionality' such as code compilation and syntax checking is at\nthe least abstract level, software architecture analysis and design are at the\nmost abstract level. We conclude by providing a discussion on challenges for\nfuture development of AI-supported code completion tools to reach the design\nlevel of abstraction in our taxonomy.\n","authors":["Rohith Pudari","Neil A. Ernst"],"pdf_url":"https://arxiv.org/pdf/2303.04142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04136v1","updated":"2023-03-07T18:50:00Z","published":"2023-03-07T18:50:00Z","title":"Domain Randomization for Robust, Affordable and Effective Closed-loop\n  Control of Soft Robots","summary":"  Soft robots are becoming extremely popular thanks to their intrinsic safety\nto contacts and adaptability. However, the potentially infinite number of\nDegrees of Freedom makes their modeling a daunting task, and in many cases only\nan approximated description is available. This challenge makes reinforcement\nlearning (RL) based approaches inefficient when deployed on a realistic\nscenario, due to the large domain gap between models and the real platform. In\nthis work, we demonstrate, for the first time, how Domain Randomization (DR)\ncan solve this problem by enhancing RL policies with: i) a higher robustness\nw.r.t. environmental changes; ii) a higher affordability of learned policies\nwhen the target model differs significantly from the training model; iii) a\nhigher effectiveness of the policy, which can even autonomously learn to\nexploit the environment to increase the robot capabilities (environmental\nconstraints exploitation). Moreover, we introduce a novel algorithmic extension\nof previous adaptive domain randomization methods for the automatic inference\nof dynamics parameters for deformable objects. We provide results on four\ndifferent tasks and two soft robot designs, opening interesting perspectives\nfor future research on Reinforcement Learning for closed-loop soft robot\ncontrol.\n","authors":["Gabriele Tiboni","Andrea Protopapa","Tatiana Tommasi","Giuseppe Averta"],"pdf_url":"https://arxiv.org/pdf/2303.04136v1.pdf","comment":"Project website at https://andreaprotopapa.github.io/dr-soro/"},{"id":"http://arxiv.org/abs/2303.04132v1","updated":"2023-03-07T18:48:55Z","published":"2023-03-07T18:48:55Z","title":"Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and\n  the Case of Information Extraction","summary":"  Large language models (LLMs) show great potential for synthetic data\ngeneration. This work shows that useful data can be synthetically generated\neven for tasks that cannot be solved directly by the LLM: we show that, for\nproblems with structured outputs, it is possible to prompt an LLM to perform\nthe task in the opposite direction, to generate plausible text for the target\nstructure. Leveraging the asymmetry in task difficulty makes it possible to\nproduce large-scale, high-quality data for complex tasks. We demonstrate the\neffectiveness of this approach on closed information extraction, where\ncollecting ground-truth data is challenging, and no satisfactory dataset exists\nto date. We synthetically generate a dataset of 1.8M data points, demonstrate\nits superior quality compared to existing datasets in a human evaluation and\nuse it to finetune small models (220M and 770M parameters). The models we\nintroduce, SynthIE, outperform existing baselines of comparable size with a\nsubstantial gap of 57 and 79 absolute points in micro and macro F1,\nrespectively. Code, data, and models are available at\nhttps://github.com/epfl-dlab/SynthIE.\n","authors":["Martin Josifoski","Marija Sakota","Maxime Peyrard","Robert West"],"pdf_url":"https://arxiv.org/pdf/2303.04132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04129v1","updated":"2023-03-07T18:44:07Z","published":"2023-03-07T18:44:07Z","title":"Foundation Models for Decision Making: Problems, Methods, and\n  Opportunities","summary":"  Foundation models pretrained on diverse data at scale have demonstrated\nextraordinary capabilities in a wide range of vision and language tasks. When\nsuch models are deployed in real world environments, they inevitably interface\nwith other entities and agents. For example, language models are often used to\ninteract with human beings through dialogue, and visual perception models are\nused to autonomously navigate neighborhood streets. In response to these\ndevelopments, new paradigms are emerging for training foundation models to\ninteract with other agents and perform long-term reasoning. These paradigms\nleverage the existence of ever-larger datasets curated for multimodal,\nmultitask, and generalist interaction. Research at the intersection of\nfoundation models and decision making holds tremendous promise for creating\npowerful new systems that can interact effectively across a diverse range of\napplications such as dialogue, autonomous driving, healthcare, education, and\nrobotics. In this manuscript, we examine the scope of foundation models for\ndecision making, and provide conceptual tools and technical background for\nunderstanding the problem space and exploring new research directions. We\nreview recent approaches that ground foundation models in practical decision\nmaking applications through a variety of methods such as prompting, conditional\ngenerative modeling, planning, optimal control, and reinforcement learning, and\ndiscuss common challenges and open problems in the field.\n","authors":["Sherry Yang","Ofir Nachum","Yilun Du","Jason Wei","Pieter Abbeel","Dale Schuurmans"],"pdf_url":"https://arxiv.org/pdf/2303.04129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04124v1","updated":"2023-03-07T18:34:55Z","published":"2023-03-07T18:34:55Z","title":"Wigner kernels: body-ordered equivariant machine learning without a\n  basis","summary":"  Machine-learning models based on a point-cloud representation of a physical\nobject are ubiquitous in scientific applications and particularly well-suited\nto the atomic-scale description of molecules and materials. Among the many\ndifferent approaches that have been pursued, the description of local atomic\nenvironments in terms of their neighbor densities has been used widely and very\nsuccesfully. We propose a novel density-based method which involves computing\n``Wigner kernels''. These are fully equivariant and body-ordered kernels that\ncan be computed iteratively with a cost that is independent of the\nradial-chemical basis and grows only linearly with the maximum body-order\nconsidered. This is in marked contrast to feature-space models, which comprise\nan exponentially-growing number of terms with increasing order of correlations.\nWe present several examples of the accuracy of models based on Wigner kernels\nin chemical applications, for both scalar and tensorial targets, reaching\nstate-of-the-art accuracy on the popular QM9 benchmark dataset, and we discuss\nthe broader relevance of these ideas to equivariant geometric machine-learning.\n","authors":["Filippo Bigi","Sergey N. Pozdnyakov","Michele Ceriotti"],"pdf_url":"https://arxiv.org/pdf/2303.04124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04118v1","updated":"2023-03-07T18:29:15Z","published":"2023-03-07T18:29:15Z","title":"A Multiplicative Value Function for Safe and Efficient Reinforcement\n  Learning","summary":"  An emerging field of sequential decision problems is safe Reinforcement\nLearning (RL), where the objective is to maximize the reward while obeying\nsafety constraints. Being able to handle constraints is essential for deploying\nRL agents in real-world environments, where constraint violations can harm the\nagent and the environment. To this end, we propose a safe model-free RL\nalgorithm with a novel multiplicative value function consisting of a safety\ncritic and a reward critic. The safety critic predicts the probability of\nconstraint violation and discounts the reward critic that only estimates\nconstraint-free returns. By splitting responsibilities, we facilitate the\nlearning task leading to increased sample efficiency. We integrate our approach\ninto two popular RL algorithms, Proximal Policy Optimization and Soft\nActor-Critic, and evaluate our method in four safety-focused environments,\nincluding classical RL benchmarks augmented with safety constraints and robot\nnavigation tasks with images and raw Lidar scans as observations. Finally, we\nmake the zero-shot sim-to-real transfer where a differential drive robot has to\nnavigate through a cluttered room. Our code can be found at\nhttps://github.com/nikeke19/Safe-Mult-RL.\n","authors":["Nick Bührer","Zhejun Zhang","Alexander Liniger","Fisher Yu","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2303.04118v1.pdf","comment":"Repository available at https://github.com/nikeke19/Safe-Mult-RL"},{"id":"http://arxiv.org/abs/2303.04117v1","updated":"2023-03-07T18:28:45Z","published":"2023-03-07T18:28:45Z","title":"Validation of a Hospital Digital Twin with Machine Learning","summary":"  Recently there has been a surge of interest in developing Digital Twins of\nprocess flows in healthcare to better understand bottlenecks and areas of\nimprovement. A key challenge is in the validation process. We describe a work\nin progress for a digital twin using an agent based simulation model for\ndetermining bed turnaround time for patients in hospitals. We employ a strategy\nusing machine learning for validating the model and implementing sensitivity\nanalysis.\n","authors":["Muhammad Aurangzeb Ahmad","Vijay Chickarmane","Farinaz Ali Sabzpour","Nima Shariari","Taposh Roy"],"pdf_url":"https://arxiv.org/pdf/2303.04117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04115v1","updated":"2023-03-07T18:28:39Z","published":"2023-03-07T18:28:39Z","title":"Predicted Embedding Power Regression for Large-Scale Out-of-Distribution\n  Detection","summary":"  Out-of-distribution (OOD) inputs can compromise the performance and safety of\nreal world machine learning systems. While many methods exist for OOD detection\nand work well on small scale datasets with lower resolution and few classes,\nfew methods have been developed for large-scale OOD detection. Existing\nlarge-scale methods generally depend on maximum classification probability,\nsuch as the state-of-the-art grouped softmax method. In this work, we develop a\nnovel approach that calculates the probability of the predicted class label\nbased on label distributions learned during the training process. Our method\nperforms better than current state-of-the-art methods with only a negligible\nincrease in compute cost. We evaluate our method against contemporary methods\nacross $14$ datasets and achieve a statistically significant improvement with\nrespect to AUROC (84.2 vs 82.4) and AUPR (96.2 vs 93.7).\n","authors":["Hong Yang","William Gebhardt","Alexander G. Ororbia","Travis Desell"],"pdf_url":"https://arxiv.org/pdf/2303.04115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.11299v6","updated":"2023-03-07T18:26:49Z","published":"2021-06-21T17:56:07Z","title":"Boundary Graph Neural Networks for 3D Simulations","summary":"  The abundance of data has given machine learning considerable momentum in\nnatural sciences and engineering, though modeling of physical processes is\noften difficult. A particularly tough problem is the efficient representation\nof geometric boundaries. Triangularized geometric boundaries are well\nunderstood and ubiquitous in engineering applications. However, it is\nnotoriously difficult to integrate them into machine learning approaches due to\ntheir heterogeneity with respect to size and orientation. In this work, we\nintroduce an effective theory to model particle-boundary interactions, which\nleads to our new Boundary Graph Neural Networks (BGNNs) that dynamically modify\ngraph structures to obey boundary conditions. The new BGNNs are tested on\ncomplex 3D granular flow processes of hoppers, rotating drums and mixers, which\nare all standard components of modern industrial machinery but still have\ncomplicated geometry. BGNNs are evaluated in terms of computational efficiency\nas well as prediction accuracy of particle flows and mixing entropies. BGNNs\nare able to accurately reproduce 3D granular flows within simulation\nuncertainties over hundreds of thousands of simulation timesteps. Most notably,\nin our experiments, particles stay within the geometric objects without using\nhandcrafted conditions or restrictions.\n","authors":["Andreas Mayr","Sebastian Lehner","Arno Mayrhofer","Christoph Kloss","Sepp Hochreiter","Johannes Brandstetter"],"pdf_url":"https://arxiv.org/pdf/2106.11299v6.pdf","comment":"accepted for presentation at the Thirty-Seventh AAAI Conference on\n  Artificial Intelligence (AAAI-23)"},{"id":"http://arxiv.org/abs/2212.01848v2","updated":"2023-03-07T18:26:01Z","published":"2022-12-04T15:26:36Z","title":"Convergence under Lipschitz smoothness of ease-controlled Random\n  Reshuffling gradient Algorithms","summary":"  We consider minimizing the average of a very large number of smooth and\npossibly non-convex functions. This optimization problem has deserved much\nattention in the past years due to the many applications in different fields,\nthe most challenging being training Machine Learning models. Widely used\napproaches for solving this problem are mini-batch gradient methods which, at\neach iteration, update the decision vector moving along the gradient of a\nmini-batch of the component functions. We consider the Incremental Gradient\n(IG) and the Random reshuffling (RR) methods which proceed in cycles, picking\nbatches in a fixed order or by reshuffling the order after each epoch.\nConvergence properties of these schemes have been proved under different\nassumptions, usually quite strong. We aim to define ease-controlled\nmodifications of the IG/RR schemes, which require a light additional\ncomputational effort and can be proved to converge under very weak and standard\nassumptions. In particular, we define two algorithmic schemes, monotone or\nnon-monotone, in which the IG/RR iteration is controlled by using a watchdog\nrule and a derivative-free line search that activates only sporadically to\nguarantee convergence. The two schemes also allow controlling the updating of\nthe stepsize used in the main IG/RR iteration, avoiding the use of preset\nrules. We prove convergence under the lonely assumption of Lipschitz continuity\nof the gradients of the component functions and perform extensive computational\nanalysis using Deep Neural Architectures and a benchmark of datasets. We\ncompare our implementation with both full batch gradient methods and online\nstandard implementation of IG/RR methods, proving that the computational effort\nis comparable with the corresponding online methods and that the control on the\nlearning rate may allow faster decrease.\n","authors":["Giampaolo Liuzzi","Laura Palagi","Ruggiero Seccia"],"pdf_url":"https://arxiv.org/pdf/2212.01848v2.pdf","comment":"Add references, correct typos"},{"id":"http://arxiv.org/abs/2106.09215v4","updated":"2023-03-07T18:23:05Z","published":"2021-06-17T02:37:39Z","title":"Optimum-statistical Collaboration Towards General and Efficient\n  Black-box Optimization","summary":"  In this paper, we make the key delineation on the roles of resolution and\nstatistical uncertainty in hierarchical bandits-based black-box optimization\nalgorithms, guiding a more general analysis and a more efficient algorithm\ndesign. We introduce the \\textit{optimum-statistical collaboration}, an\nalgorithm framework of managing the interaction between optimization error flux\nand statistical error flux evolving in the optimization process. We provide a\ngeneral analysis of this framework without specifying the forms of statistical\nerror and uncertainty quantifier. Our framework and its analysis, due to their\ngenerality, can be applied to a large family of functions and partitions that\nsatisfy different local smoothness assumptions and have different numbers of\nlocal optimums, which is much richer than the class of functions studied in\nprior works. Our framework also inspires us to propose a better measure of the\nstatistical uncertainty and consequently a variance-adaptive algorithm\n\\texttt{VHCT}. In theory, we prove the algorithm enjoys rate-optimal regret\nbounds under different local smoothness assumptions; in experiments, we show\nthe algorithm outperforms prior efforts in different settings.\n","authors":["Wenjie Li","Chi-Hua Wang","Qifan Song","Guang Cheng"],"pdf_url":"https://arxiv.org/pdf/2106.09215v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04105v1","updated":"2023-03-07T18:12:24Z","published":"2023-03-07T18:12:24Z","title":"Introspective Cross-Attention Probing for Lightweight Transfer of\n  Pre-trained Models","summary":"  We propose InCA, a lightweight method for transfer learning that\ncross-attends to any activation layer of a pre-trained model. During training,\nInCA uses a single forward pass to extract multiple activations, which are\npassed to external cross-attention adapters, trained anew and combined or\nselected for downstream tasks. We show that, even when selecting a single\ntop-scoring adapter, InCA achieves performance comparable to full fine-tuning,\nat a cost comparable to fine-tuning just the last layer. For example, with a\ncross-attention probe 1.3% the size of a pre-trained ViT-L/16 model, we achieve\nperformance within 0.2% of the full fine-tuning paragon at 51% training cost of\nthe baseline, on average across 11 downstream classification tasks. Unlike\nother forms of efficient adaptation, InCA does not require backpropagating\nthrough the pre-trained model, thus leaving its execution unaltered at both\ntraining and inference. The versatility of InCA is best illustrated in\nfine-grained tasks, which may require accessing information absent in the last\nlayer but accessible in intermediate layer activations. Since the backbone is\nfixed, InCA allows parallel ensembling as well as parallel execution of\nmultiple tasks. InCA achieves state-of-the-art performance in the\nImageNet-to-Sketch multi-task benchmark.\n","authors":["Yonatan Dukler","Alessandro Achille","Hao Yang","Varsha Vivek","Luca Zancato","Ben Bowman","Avinash Ravichandran","Charless Fowlkes","Ashwin Swaminathan","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2303.04105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04104v1","updated":"2023-03-07T18:10:05Z","published":"2023-03-07T18:10:05Z","title":"An Inception-Residual-Based Architecture with Multi-Objective Loss for\n  Detecting Respiratory Anomalies","summary":"  This paper presents a deep learning system applied for detecting anomalies\nfrom respiratory sound recordings. Initially, our system begins with audio\nfeature extraction using Gammatone and Continuous Wavelet transformation. This\nstep aims to transform the respiratory sound input into a two-dimensional\nspectrogram where both spectral and temporal features are presented. Then, our\nproposed system integrates Inception-residual-based backbone models combined\nwith multi-head attention and multi-objective loss to classify respiratory\nanomalies. In this work, we conducted experiments over the benchmark dataset of\nSPRSound (The Open-Source SJTU Paediatric Respiratory Sound) proposed by the\nIEEE BioCAS 2022 challenge. As regards the Score computed by an average between\nthe average score and harmonic score, our proposed system gained significant\nimprovements of 9.7%, 15.8%, 17.0%, and 9.4% in Task 1-1, Task 1-2, Task 2-1,\nand Task 2-2 compared to the challenge baseline system. Notably, we achieved\nthe Top-1 performance in Task 2-1 with the highest Score of 73.7%.\n","authors":["Dat Ngo","Lam Pham","Huy Phan","Minh Tran","Delaram Jarchi","Sefki Kolozali"],"pdf_url":"https://arxiv.org/pdf/2303.04104v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.03051v3","updated":"2023-03-07T18:05:45Z","published":"2021-10-06T20:13:57Z","title":"Prior and Posterior Networks: A Survey on Evidential Deep Learning\n  Methods For Uncertainty Estimation","summary":"  Popular approaches for quantifying predictive uncertainty in deep neural\nnetworks often involve distributions over weights or multiple models, for\ninstance via Markov Chain sampling, ensembling, or Monte Carlo dropout. These\ntechniques usually incur overhead by having to train multiple model instances\nor do not produce very diverse predictions. This comprehensive and extensive\nsurvey aims to familiarize the reader with an alternative class of models based\non the concept of Evidential Deep Learning: For unfamiliar data, they aim to\nadmit \"what they don't know\", and fall back onto a prior belief. Furthermore,\nthey allow uncertainty estimation in a single model and forward pass by\nparameterizing distributions over distributions. This survey recapitulates\nexisting works, focusing on the implementation in a classification setting,\nbefore surveying the application of the same paradigm to regression. We also\nreflect on the strengths and weaknesses compared to other existing methods and\nprovide the most fundamental derivations using a unified notation to aid future\nresearch.\n","authors":["Dennis Ulmer","Christian Hardmeier","Jes Frellsen"],"pdf_url":"https://arxiv.org/pdf/2110.03051v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04096v1","updated":"2023-03-07T17:55:28Z","published":"2023-03-07T17:55:28Z","title":"Mastering Strategy Card Game (Legends of Code and Magic) via End-to-End\n  Policy and Optimistic Smooth Fictitious Play","summary":"  Deep Reinforcement Learning combined with Fictitious Play shows impressive\nresults on many benchmark games, most of which are, however, single-stage. In\ncontrast, real-world decision making problems may consist of multiple stages,\nwhere the observation spaces and the action spaces can be completely different\nacross stages. We study a two-stage strategy card game Legends of Code and\nMagic and propose an end-to-end policy to address the difficulties that arise\nin multi-stage game. We also propose an optimistic smooth fictitious play\nalgorithm to find the Nash Equilibrium for the two-player game. Our approach\nwins double championships of COG2022 competition. Extensive studies verify and\nshow the advancement of our approach.\n","authors":["Wei Xi","Yongxin Zhang","Changnan Xiao","Xuefeng Huang","Shihong Deng","Haowei Liang","Jie Chen","Peng Sun"],"pdf_url":"https://arxiv.org/pdf/2303.04096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04091v1","updated":"2023-03-07T17:52:46Z","published":"2023-03-07T17:52:46Z","title":"Visual Abstraction and Reasoning through Language","summary":"  While Artificial Intelligence (AI) models have achieved human or even\nsuperhuman performance in narrowly defined applications, they still struggle to\nshow signs of broader and more flexible intelligence. The Abstraction and\nReasoning Corpus (ARC), introduced by Fran\\c{c}ois Chollet, aims to assess how\nclose AI systems are to human-like cognitive abilities. Most current approaches\nrely on carefully handcrafted domain-specific languages (DSLs), which are used\nto brute-force solutions to the tasks present in ARC. In this work, we propose\na general framework for solving ARC based on natural language descriptions of\nthe tasks. While not yet beating state-of-the-art DSL models on ARC, we\ndemonstrate the immense potential of our approach hinted at by the ability to\nsolve previously unsolved tasks.\n","authors":["Giacomo Camposampiero","Loic Houmard","Benjamin Estermann","Joël Mathys","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.04091v1.pdf","comment":"The first two authors have contributed equally to this work"},{"id":"http://arxiv.org/abs/2106.02735v4","updated":"2023-03-07T17:34:29Z","published":"2021-06-04T22:00:53Z","title":"Learning particle swarming models from data with Gaussian processes","summary":"  Interacting particle or agent systems that display a rich variety of swarming\nbehaviours are ubiquitous in science and engineering. A fundamental and\nchallenging goal is to understand the link between individual interaction rules\nand swarming. In this paper, we study the data-driven discovery of a\nsecond-order particle swarming model that describes the evolution of $N$\nparticles in $\\mathbb{R}^d$ under radial interactions. We propose a learning\napproach that models the latent radial interaction function as Gaussian\nprocesses, which can simultaneously fulfill two inference goals: one is the\nnonparametric inference of {the} interaction function with pointwise\nuncertainty quantification, and the other one is the inference of unknown\nscalar parameters in the non-collective friction forces of the system. We\nformulate the learning problem as a statistical inverse problem and provide a\ndetailed analysis of recoverability conditions, establishing that a coercivity\ncondition is sufficient for recoverability. Given data collected from $M$ i.i.d\ntrajectories with independent Gaussian observational noise, we provide a\nfinite-sample analysis, showing that our posterior mean estimator converges in\na Reproducing kernel Hilbert space norm, at an optimal rate in $M$ equal to the\none in the classical 1-dimensional Kernel Ridge regression. As a byproduct, we\nshow we can obtain a parametric learning rate in $M$ for the posterior marginal\nvariance using $L^{\\infty}$ norm, and the rate could also involve $N$ and $L$\n(the number of observation time instances for each trajectory), depending on\nthe condition number of the inverse problem. Numerical results on systems that\nexhibit different swarming behaviors demonstrate efficient learning of our\napproach from scarce noisy trajectory data.\n","authors":["Jinchao Feng","Charles Kulick","Yunxiang Ren","Sui Tang"],"pdf_url":"https://arxiv.org/pdf/2106.02735v4.pdf","comment":"44 pages; Appendix 5 pages"},{"id":"http://arxiv.org/abs/2211.09330v3","updated":"2023-03-07T17:20:45Z","published":"2022-11-17T04:37:24Z","title":"ACon$^2$: Adaptive Conformal Consensus for Provable Blockchain Oracles","summary":"  Blockchains with smart contracts are distributed ledger systems that achieve\nblock-state consistency among distributed nodes by only allowing deterministic\noperations of smart contracts. However, the power of smart contracts is enabled\nby interacting with stochastic off-chain data, which in turn opens the\npossibility to undermine the block-state consistency. To address this issue, an\noracle smart contract is used to provide a single consistent source of external\ndata; but, simultaneously, this introduces a single point of failure, which is\ncalled the oracle problem. To address the oracle problem, we propose an\nadaptive conformal consensus (ACon$^2$) algorithm that derives a consensus set\nof data from multiple oracle contracts via the recent advance in online\nuncertainty quantification learning. Interesting, the consensus set provides a\ndesired correctness guarantee under distribution shift and Byzantine\nadversaries. We demonstrate the efficacy of the proposed algorithm on two price\ndatasets and an Ethereum case study. In particular, the Solidity implementation\nof the proposed algorithm shows the potential practicality of the proposed\nalgorithm, implying that online machine learning algorithms are applicable to\naddress security issues in blockchains.\n","authors":["Sangdon Park","Osbert Bastani","Taesoo Kim"],"pdf_url":"https://arxiv.org/pdf/2211.09330v3.pdf","comment":"Accepted to USENIX Security 2023"},{"id":"http://arxiv.org/abs/2303.04040v1","updated":"2023-03-07T16:49:46Z","published":"2023-03-07T16:49:46Z","title":"Uncertainty Quantification of Spatiotemporal Travel Demand with\n  Probabilistic Graph Neural Networks","summary":"  Recent studies have significantly improved the prediction accuracy of travel\ndemand using graph neural networks. However, these studies largely ignored\nuncertainty that inevitably exists in travel demand prediction. To fill this\ngap, this study proposes a framework of probabilistic graph neural networks\n(Prob-GNN) to quantify the spatiotemporal uncertainty of travel demand. This\nProb-GNN framework is substantiated by deterministic and probabilistic\nassumptions, and empirically applied to the task of predicting the transit and\nridesharing demand in Chicago. We found that the probabilistic assumptions\n(e.g. distribution tail, support) have a greater impact on uncertainty\nprediction than the deterministic ones (e.g. deep modules, depth). Among the\nfamily of Prob-GNNs, the GNNs with truncated Gaussian and Laplace distributions\nachieve the highest performance in transit and ridesharing data. Even under\nsignificant domain shifts, Prob-GNNs can predict the ridership uncertainty in a\nstable manner, when the models are trained on pre-COVID data and tested across\nmultiple periods during and after the COVID-19 pandemic. Prob-GNNs also reveal\nthe spatiotemporal pattern of uncertainty, which is concentrated on the\nafternoon peak hours and the areas with large travel volumes. Overall, our\nfindings highlight the importance of incorporating randomness into deep\nlearning for spatiotemporal ridership prediction. Future research should\ncontinue to investigate versatile probabilistic assumptions to capture\nbehavioral randomness, and further develop methods to quantify uncertainty to\nbuild resilient cities.\n","authors":["Qingyi Wang","Shenhao Wang","Dingyi Zhuang","Haris Koutsopoulos","Jinhua Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.04040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08261v2","updated":"2023-03-07T16:48:14Z","published":"2023-02-16T12:38:01Z","title":"Knowledge-augmented Graph Machine Learning for Drug Discovery: A Survey\n  from Precision to Interpretability","summary":"  The integration of Artificial Intelligence (AI) into the field of drug\ndiscovery has been a growing area of interdisciplinary scientific research.\nHowever, conventional AI models are heavily limited in handling complex\nbiomedical structures (such as 2D or 3D protein and molecule structures) and\nproviding interpretations for outputs, which hinders their practical\napplication. As of late, Graph Machine Learning (GML) has gained considerable\nattention for its exceptional ability to model graph-structured biomedical data\nand investigate their properties and functional relationships. Despite\nextensive efforts, GML methods still suffer from several deficiencies, such as\nthe limited ability to handle supervision sparsity and provide interpretability\nin learning and inference processes, and their ineffectiveness in utilising\nrelevant domain knowledge. In response, recent studies have proposed\nintegrating external biomedical knowledge into the GML pipeline to realise more\nprecise and interpretable drug discovery with limited training instances.\nHowever, a systematic definition for this burgeoning research direction is yet\nto be established. This survey presents a comprehensive overview of\nlong-standing drug discovery principles, provides the foundational concepts and\ncutting-edge techniques for graph-structured data and knowledge databases, and\nformally summarises Knowledge-augmented Graph Machine Learning (KaGML) for drug\ndiscovery. we propose a thorough review of related KaGML works, collected\nfollowing a carefully designed search methodology, and organise them into four\ncategories following a novel-defined taxonomy. To facilitate research in this\npromptly emerging field, we also share collected practical resources that are\nvaluable for intelligent drug discovery and provide an in-depth discussion of\nthe potential avenues for future advancements.\n","authors":["Zhiqiang Zhong","Anastasia Barkova","Davide Mottin"],"pdf_url":"https://arxiv.org/pdf/2302.08261v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04038v1","updated":"2023-03-07T16:47:35Z","published":"2023-03-07T16:47:35Z","title":"Root Cause Identification for Collective Anomalies in Time Series given\n  an Acyclic Summary Causal Graph with Loops","summary":"  This paper presents an approach for identifying the root causes of collective\nanomalies given observational time series and an acyclic summary causal graph\nwhich depicts an abstraction of causal relations present in a dynamic system at\nits normal regime. The paper first shows how the problem of root cause\nidentification can be divided into many independent subproblems by grouping\nrelated anomalies using d-separation. Further, it shows how, under this\nsetting, some root causes can be found directly from the graph and from the\ntime of appearance of anomalies. Finally, it shows, how the rest of the root\ncauses can be found by comparing direct causal effects in the normal and in the\nanomalous regime. To this end, temporal adaptations of the back-door and the\nsingle-door criterions are introduced. Extensive experiments conducted on both\nsimulated and real-world datasets demonstrate the effectiveness of the proposed\nmethod.\n","authors":["Charles K. Assaad","Imad Ez-zejjari","Lei Zan"],"pdf_url":"https://arxiv.org/pdf/2303.04038v1.pdf","comment":"Proceedings of the 26th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2023, Valencia, Spain"},{"id":"http://arxiv.org/abs/2303.04030v1","updated":"2023-03-07T16:43:05Z","published":"2023-03-07T16:43:05Z","title":"PyXAB -- A Python Library for $\\mathcal{X}$-Armed Bandit and Online\n  Blackbox Optimization Algorithms","summary":"  We introduce a Python open-source library for $\\mathcal{X}$-armed bandit and\nonline blackbox optimization named PyXAB. PyXAB contains the implementations\nfor more than 10 $\\mathcal{X}$-armed bandit algorithms, such as HOO, StoSOO,\nHCT, and the most recent works GPO and VHCT. PyXAB also provides the most\ncommonly-used synthetic objectives to evaluate the performance of different\nalgorithms and the various choices of the hierarchical partitions on the\nparameter space. The online documentation for PyXAB includes clear instructions\nfor installation, straight-forward examples, detailed feature descriptions, and\na complete reference of the API. PyXAB is released under the MIT license in\norder to encourage both academic and industrial usage. The library can be\ndirectly installed from PyPI with its source code available at\nhttps://github.com/WilliamLwj/PyXAB\n","authors":["Wenjie Li","Haoze Li","Jean Honorio","Qifan Song"],"pdf_url":"https://arxiv.org/pdf/2303.04030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.12053v2","updated":"2023-03-07T16:41:02Z","published":"2022-12-22T22:05:16Z","title":"On Calibrating Semantic Segmentation Models: Analyses and An Algorithm","summary":"  We study the problem of semantic segmentation calibration. For image\nclassification, lots of existing solutions are proposed to alleviate model\nmiscalibration of confidence. However, to date, confidence calibration research\non semantic segmentation is still limited. We provide a systematic study on the\ncalibration of semantic segmentation models and propose a simple yet effective\napproach. First, we find that model capacity, crop size, multi-scale testing,\nand prediction correctness have impact on calibration. Among them, prediction\ncorrectness, especially misprediction, is more important to miscalibration due\nto over-confidence. Next, we propose a simple, unifying, and effective\napproach, namely selective scaling, by separating correct/incorrect prediction\nfor scaling and more focusing on misprediction logit smoothing. Then, we study\npopular existing calibration methods and compare them with selective scaling on\nsemantic segmentation calibration. We conduct extensive experiments with a\nvariety of benchmarks on both in-domain and domain-shift calibration, and show\nthat selective scaling consistently outperforms other methods.\n","authors":["Dongdong Wang","Boqing Gong","Liqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.12053v2.pdf","comment":"Accepted to CVPR2023 (8 pages, 4 figures)"},{"id":"http://arxiv.org/abs/2303.04020v1","updated":"2023-03-07T16:37:30Z","published":"2023-03-07T16:37:30Z","title":"When is Importance Weighting Correction Needed for Covariate Shift\n  Adaptation?","summary":"  This paper investigates when the importance weighting (IW) correction is\nneeded to address covariate shift, a common situation in supervised learning\nwhere the input distributions of training and test data differ. Classic results\nshow that the IW correction is needed when the model is parametric and\nmisspecified. In contrast, recent results indicate that the IW correction may\nnot be necessary when the model is nonparametric and well-specified. We examine\nthe missing case in the literature where the model is nonparametric and\nmisspecified, and show that the IW correction is needed for obtaining the best\napproximation of the true unknown function for the test distribution. We do\nthis by analyzing IW-corrected kernel ridge regression, covering a variety of\nsettings, including parametric and nonparametric models, well-specified and\nmisspecified settings, and arbitrary weighting functions.\n","authors":["Davit Gogolashvili","Matteo Zecchin","Motonobu Kanagawa","Marios Kountouris","Maurizio Filippone"],"pdf_url":"https://arxiv.org/pdf/2303.04020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.11485v2","updated":"2023-03-07T16:34:59Z","published":"2021-11-22T19:24:57Z","title":"A Free Lunch from the Noise: Provable and Practical Exploration for\n  Representation Learning","summary":"  Representation learning lies at the heart of the empirical success of deep\nlearning for dealing with the curse of dimensionality. However, the power of\nrepresentation learning has not been fully exploited yet in reinforcement\nlearning (RL), due to i), the trade-off between expressiveness and\ntractability; and ii), the coupling between exploration and representation\nlearning. In this paper, we first reveal the fact that under some noise\nassumption in the stochastic control model, we can obtain the linear spectral\nfeature of its corresponding Markov transition operator in closed-form for\nfree. Based on this observation, we propose Spectral Dynamics Embedding\n(SPEDE), which breaks the trade-off and completes optimistic exploration for\nrepresentation learning by exploiting the structure of the noise. We provide\nrigorous theoretical analysis of SPEDE, and demonstrate the practical superior\nperformance over the existing state-of-the-art empirical algorithms on several\nbenchmarks.\n","authors":["Tongzheng Ren","Tianjun Zhang","Csaba Szepesvári","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2111.11485v2.pdf","comment":"UAI 2022. The first two authors contribute equally"},{"id":"http://arxiv.org/abs/2303.04016v1","updated":"2023-03-07T16:31:13Z","published":"2023-03-07T16:31:13Z","title":"Decoupling Skill Learning from Robotic Control for Generalizable Object\n  Manipulation","summary":"  Recent works in robotic manipulation through reinforcement learning (RL) or\nimitation learning (IL) have shown potential for tackling a range of tasks\ne.g., opening a drawer or a cupboard. However, these techniques generalize\npoorly to unseen objects. We conjecture that this is due to the\nhigh-dimensional action space for joint control. In this paper, we take an\nalternative approach and separate the task of learning 'what to do' from 'how\nto do it' i.e., whole-body control. We pose the RL problem as one of\ndetermining the skill dynamics for a disembodied virtual manipulator\ninteracting with articulated objects. The whole-body robotic kinematic control\nis optimized to execute the high-dimensional joint motion to reach the goals in\nthe workspace. It does so by solving a quadratic programming (QP) model with\nrobotic singularity and kinematic constraints. Our experiments on manipulating\ncomplex articulated objects show that the proposed approach is more\ngeneralizable to unseen objects with large intra-class variations,\noutperforming previous approaches. The evaluation results indicate that our\napproach generates more compliant robotic motion and outperforms the pure RL\nand IL baselines in task success rates.\n","authors":["Kai Lu","Bo Yang","Bing Wang","Andrew Markham"],"pdf_url":"https://arxiv.org/pdf/2303.04016v1.pdf","comment":"Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2211.09019v2","updated":"2023-03-07T16:29:49Z","published":"2022-11-16T16:26:48Z","title":"Learning Reward Functions for Robotic Manipulation by Observing Humans","summary":"  Observing a human demonstrator manipulate objects provides a rich, scalable\nand inexpensive source of data for learning robotic policies. However,\ntransferring skills from human videos to a robotic manipulator poses several\nchallenges, not least a difference in action and observation spaces. In this\nwork, we use unlabeled videos of humans solving a wide range of manipulation\ntasks to learn a task-agnostic reward function for robotic manipulation\npolicies. Thanks to the diversity of this training data, the learned reward\nfunction sufficiently generalizes to image observations from a previously\nunseen robot embodiment and environment to provide a meaningful prior for\ndirected exploration in reinforcement learning. We propose two methods for\nscoring states relative to a goal image: through direct temporal regression,\nand through distances in an embedding space obtained with time-contrastive\nlearning. By conditioning the function on a goal image, we are able to reuse\none model across a variety of tasks. Unlike prior work on leveraging human\nvideos to teach robots, our method, Human Offline Learned Distances (HOLD)\nrequires neither a priori data from the robot environment, nor a set of\ntask-specific human demonstrations, nor a predefined notion of correspondence\nacross morphologies, yet it is able to accelerate training of several\nmanipulation tasks on a simulated robot arm compared to using only a sparse\nreward obtained from task completion.\n","authors":["Minttu Alakuijala","Gabriel Dulac-Arnold","Julien Mairal","Jean Ponce","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2211.09019v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08765v2","updated":"2023-03-07T16:28:18Z","published":"2022-12-17T00:26:31Z","title":"Latent Variable Representation for Reinforcement Learning","summary":"  Deep latent variable models have achieved significant empirical successes in\nmodel-based reinforcement learning (RL) due to their expressiveness in modeling\ncomplex transition dynamics. On the other hand, it remains unclear\ntheoretically and empirically how latent variable models may facilitate\nlearning, planning, and exploration to improve the sample efficiency of RL. In\nthis paper, we provide a representation view of the latent variable models for\nstate-action value functions, which allows both tractable variational learning\nalgorithm and effective implementation of the optimism/pessimism principle in\nthe face of uncertainty for exploration. In particular, we propose a\ncomputationally efficient planning algorithm with UCB exploration by\nincorporating kernel embeddings of latent variable models. Theoretically, we\nestablish the sample complexity of the proposed approach in the online and\noffline settings. Empirically, we demonstrate superior performance over current\nstate-of-the-art algorithms across various benchmarks.\n","authors":["Tongzheng Ren","Chenjun Xiao","Tianjun Zhang","Na Li","Zhaoran Wang","Sujay Sanghavi","Dale Schuurmans","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2212.08765v2.pdf","comment":"ICLR 2023. The first two authors contribute equally. Project Website:\n  https://rlrep.github.io/lvrep/"},{"id":"http://arxiv.org/abs/2208.09515v2","updated":"2023-03-07T16:26:05Z","published":"2022-08-19T19:01:30Z","title":"Spectral Decomposition Representation for Reinforcement Learning","summary":"  Representation learning often plays a critical role in reinforcement learning\nby managing the curse of dimensionality. A representative class of algorithms\nexploits a spectral decomposition of the stochastic transition dynamics to\nconstruct representations that enjoy strong theoretical properties in an\nidealized setting. However, current spectral methods suffer from limited\napplicability because they are constructed for state-only aggregation and\nderived from a policy-dependent transition kernel, without considering the\nissue of exploration. To address these issues, we propose an alternative\nspectral method, Spectral Decomposition Representation (SPEDER), that extracts\na state-action abstraction from the dynamics without inducing spurious\ndependence on the data collection policy, while also balancing the\nexploration-versus-exploitation trade-off during learning. A theoretical\nanalysis establishes the sample efficiency of the proposed algorithm in both\nthe online and offline settings. In addition, an experimental investigation\ndemonstrates superior performance over current state-of-the-art algorithms\nacross several benchmarks.\n","authors":["Tongzheng Ren","Tianjun Zhang","Lisa Lee","Joseph E. Gonzalez","Dale Schuurmans","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2208.09515v2.pdf","comment":"ICLR 2023. The first two authors contribute equally"},{"id":"http://arxiv.org/abs/2303.04012v1","updated":"2023-03-07T16:25:52Z","published":"2023-03-07T16:25:52Z","title":"Exploration via Epistemic Value Estimation","summary":"  How to efficiently explore in reinforcement learning is an open problem. Many\nexploration algorithms employ the epistemic uncertainty of their own value\npredictions -- for instance to compute an exploration bonus or upper confidence\nbound. Unfortunately the required uncertainty is difficult to estimate in\ngeneral with function approximation.\n  We propose epistemic value estimation (EVE): a recipe that is compatible with\nsequential decision making and with neural network function approximators. It\nequips agents with a tractable posterior over all their parameters from which\nepistemic value uncertainty can be computed efficiently.\n  We use the recipe to derive an epistemic Q-Learning agent and observe\ncompetitive performance on a series of benchmarks. Experiments confirm that the\nEVE recipe facilitates efficient exploration in hard exploration tasks.\n","authors":["Simon Schmitt","John Shawe-Taylor","Hado van Hasselt"],"pdf_url":"https://arxiv.org/pdf/2303.04012v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.05117v4","updated":"2023-03-07T16:15:11Z","published":"2022-03-10T02:27:45Z","title":"Optimal Methods for Convex Risk Averse Distributed Optimization","summary":"  This paper studies the communication complexity of convex risk-averse\noptimization over a network. The problem generalizes the well-studied\nrisk-neutral finite-sum distributed optimization problem and its importance\nstems from the need to handle risk in an uncertain environment. For algorithms\nin the literature, there exists a gap in communication complexities for solving\nrisk-averse and risk-neutral problems. We propose two distributed algorithms,\nnamely the distributed risk averse optimization (DRAO) method and the\ndistributed risk averse optimization with sliding (DRAO-S) method, to close the\ngap. Specifically, the DRAO method achieves the optimal communication\ncomplexity by assuming a certain saddle point subproblem can be easily solved\nin the server node. The DRAO-S method removes the strong assumption by\nintroducing a novel saddle point sliding subroutine which only requires the\nprojection over the ambiguity set $P$. We observe that the number of\n$P$-projections performed by DRAO-S is optimal. Moreover, we develop matching\nlower complexity bounds to show the communication complexities of both DRAO and\nDRAO-S to be improvable. Numerical experiments are conducted to demonstrate the\nencouraging empirical performance of the DRAO-S method.\n","authors":["Guanghui Lan","Zhe Zhang"],"pdf_url":"https://arxiv.org/pdf/2203.05117v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06718v2","updated":"2023-03-07T16:12:58Z","published":"2022-10-13T04:19:05Z","title":"Hybrid RL: Using Both Offline and Online Data Can Make RL Efficient","summary":"  We consider a hybrid reinforcement learning setting (Hybrid RL), in which an\nagent has access to an offline dataset and the ability to collect experience\nvia real-world online interaction. The framework mitigates the challenges that\narise in both pure offline and online RL settings, allowing for the design of\nsimple and highly effective algorithms, in both theory and practice. We\ndemonstrate these advantages by adapting the classical Q learning/iteration\nalgorithm to the hybrid setting, which we call Hybrid Q-Learning or Hy-Q. In\nour theoretical results, we prove that the algorithm is both computationally\nand statistically efficient whenever the offline dataset supports a\nhigh-quality policy and the environment has bounded bilinear rank. Notably, we\nrequire no assumptions on the coverage provided by the initial distribution, in\ncontrast with guarantees for policy gradient/iteration methods. In our\nexperimental results, we show that Hy-Q with neural network function\napproximation outperforms state-of-the-art online, offline, and hybrid RL\nbaselines on challenging benchmarks, including Montezuma's Revenge.\n","authors":["Yuda Song","Yifei Zhou","Ayush Sekhari","J. Andrew Bagnell","Akshay Krishnamurthy","Wen Sun"],"pdf_url":"https://arxiv.org/pdf/2210.06718v2.pdf","comment":"42 pages, 6 figures. Published at ICLR 2023. Code available at\n  https://github.com/yudasong/HyQ"},{"id":"http://arxiv.org/abs/2303.04001v1","updated":"2023-03-07T16:00:26Z","published":"2023-03-07T16:00:26Z","title":"ELODIN: Naming Concepts in Embedding Spaces","summary":"  Despite recent advancements, the field of text-to-image synthesis still\nsuffers from lack of fine-grained control. Using only text, it remains\nchallenging to deal with issues such as concept coherence and concept\ncontamination. We propose a method to enhance control by generating specific\nconcepts that can be reused throughout multiple images, effectively expanding\nnatural language with new words that can be combined much like a painter's\npalette. Unlike previous contributions, our method does not copy visuals from\ninput data and can generate concepts through text alone. We perform a set of\ncomparisons that finds our method to be a significant improvement over\ntext-only prompts.\n","authors":["Rodrigo Mello","Filipe Calegario","Geber Ramalho"],"pdf_url":"https://arxiv.org/pdf/2303.04001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13007v2","updated":"2023-03-07T15:56:14Z","published":"2022-10-24T07:55:57Z","title":"Iterative Patch Selection for High-Resolution Image Recognition","summary":"  High-resolution images are prevalent in various applications, such as\nautonomous driving and computer-aided diagnosis. However, training neural\nnetworks on such images is computationally challenging and easily leads to\nout-of-memory errors even on modern GPUs. We propose a simple method, Iterative\nPatch Selection (IPS), which decouples the memory usage from the input size and\nthus enables the processing of arbitrarily large images under tight hardware\nconstraints. IPS achieves this by selecting only the most salient patches,\nwhich are then aggregated into a global representation for image recognition.\nFor both patch selection and aggregation, a cross-attention based transformer\nis introduced, which exhibits a close connection to Multiple Instance Learning.\nOur method demonstrates strong performance and has wide applicability across\ndifferent domains, training regimes and image sizes while using minimal\naccelerator memory. For example, we are able to finetune our model on\nwhole-slide images consisting of up to 250k patches (>16 gigapixels) with only\n5 GB of GPU VRAM at a batch size of 16.\n","authors":["Benjamin Bergner","Christoph Lippert","Aravindh Mahendran"],"pdf_url":"https://arxiv.org/pdf/2210.13007v2.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03995v1","updated":"2023-03-07T15:51:03Z","published":"2023-03-07T15:51:03Z","title":"Group conditional validity via multi-group learning","summary":"  We consider the problem of distribution-free conformal prediction and the\ncriterion of group conditional validity. This criterion is motivated by many\npractical scenarios including hidden stratification and group fairness.\nExisting methods achieve such guarantees under either restrictive grouping\nstructure or distributional assumptions, or they are overly-conservative under\nheteroskedastic noise. We propose a simple reduction to the problem of\nachieving validity guarantees for individual populations by leveraging\nalgorithms for a problem called multi-group learning. This allows us to port\ntheoretical guarantees from multi-group learning to obtain obtain sample\ncomplexity guarantees for conformal prediction. We also provide a new algorithm\nfor multi-group learning for groups with hierarchical structure. Using this\nalgorithm in our reduction leads to improved sample complexity guarantees with\na simpler predictor structure.\n","authors":["Samuel Deng","Navid Ardeshir","Daniel Hsu"],"pdf_url":"https://arxiv.org/pdf/2303.03995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.00378v2","updated":"2023-03-07T15:47:13Z","published":"2022-07-01T12:29:33Z","title":"Rapid training of quantum recurrent neural networks","summary":"  Time series prediction is essential for human activities in diverse areas. A\ncommon approach to this task is to harness Recurrent Neural Networks (RNNs).\nHowever, while their predictions are quite accurate, their learning process is\ncomplex and, thus, time and energy consuming. Here, we propose to extend the\nconcept of RRNs by including continuous-variable quantum resources in it, and\nto use a quantum-enhanced RNN to overcome these obstacles. The design of the\nContinuous-Variable Quantum RNN (CV-QRNN) is rooted in the continuous-variable\nquantum computing paradigm. By performing extensive numerical simulations, we\ndemonstrate that the quantum network is capable of learning-time dependence of\nseveral types of temporal data, and that it converges to the optimal weights in\nfewer epochs than a classical network. Furthermore, for a small number of\ntrainable parameters, it can achieve lower losses than its classical\ncounterpart. CV-QRNN can be implemented using commercially available\nquantum-photonic hardware.\n","authors":["Michał Siemaszko","Adam Buraczewski","Bertrand Le Saux","Magdalena Stobińska"],"pdf_url":"https://arxiv.org/pdf/2207.00378v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03984v1","updated":"2023-03-07T15:33:12Z","published":"2023-03-07T15:33:12Z","title":"Enhanced Adaptive Gradient Algorithms for Nonconvex-PL Minimax\n  Optimization","summary":"  In the paper, we study a class of nonconvex nonconcave minimax optimization\nproblems (i.e., $\\min_x\\max_y f(x,y)$), where $f(x,y)$ is possible nonconvex in\n$x$, and it is nonconcave and satisfies the Polyak-Lojasiewicz (PL) condition\nin $y$. Moreover, we propose a class of enhanced momentum-based gradient\ndescent ascent methods (i.e., MSGDA and AdaMSGDA) to solve these stochastic\nNonconvex-PL minimax problems. In particular, our AdaMSGDA algorithm can use\nvarious adaptive learning rates in updating the variables $x$ and $y$ without\nrelying on any global and coordinate-wise adaptive learning rates.\nTheoretically, we present an effective convergence analysis framework for our\nmethods. Specifically, we prove that our MSGDA and AdaMSGDA methods have the\nbest known sample (gradient) complexity of $O(\\epsilon^{-3})$ only requiring\none sample at each loop in finding an $\\epsilon$-stationary solution (i.e.,\n$\\mathbb{E}\\|\\nabla F(x)\\|\\leq \\epsilon$, where $F(x)=\\max_y f(x,y)$). This\nmanuscript commemorates the mathematician Boris Polyak (1935-2023).\n","authors":["Feihu Huang"],"pdf_url":"https://arxiv.org/pdf/2303.03984v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2303.03982v1","updated":"2023-03-07T15:32:18Z","published":"2023-03-07T15:32:18Z","title":"Structured State Space Models for In-Context Reinforcement Learning","summary":"  Structured state space sequence (S4) models have recently achieved\nstate-of-the-art performance on long-range sequence modeling tasks. These\nmodels also have fast inference speeds and parallelisable training, making them\npotentially useful in many reinforcement learning settings. We propose a\nmodification to a variant of S4 that enables us to initialise and reset the\nhidden state in parallel, allowing us to tackle reinforcement learning tasks.\nWe show that our modified architecture runs asymptotically faster than\nTransformers and performs better than LSTM models on a simple memory-based\ntask. Then, by leveraging the model's ability to handle long-range sequences,\nwe achieve strong performance on a challenging meta-learning task in which the\nagent is given a randomly-sampled continuous control environment, combined with\na randomly-sampled linear projection of the environment's observations and\nactions. Furthermore, we show the resulting model can adapt to\nout-of-distribution held-out tasks. Overall, the results presented in this\npaper suggest that the S4 models are a strong contender for the default\narchitecture used for in-context reinforcement learning\n","authors":["Chris Lu","Yannick Schroecker","Albert Gu","Emilio Parisotto","Jakob Foerster","Satinder Singh","Feryal Behbahani"],"pdf_url":"https://arxiv.org/pdf/2303.03982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1906.07801v4","updated":"2023-03-07T15:17:24Z","published":"2019-06-18T20:39:27Z","title":"Safe Testing","summary":"  We develop the theory of hypothesis testing based on the e-value, a notion of\nevidence that, unlike the p-value, allows for effortlessly combining results\nfrom several studies in the common scenario where the decision to perform a new\nstudy may depend on previous outcomes. Tests based on e-values are safe, i.e.\nthey preserve Type-I error guarantees, under such optional continuation. We\ndefine growth-rate optimality (GRO) as an analogue of power in an optional\ncontinuation context, and we show how to construct GRO e-variables for general\ntesting problems with composite null and alternative, emphasizing models with\nnuisance parameters. GRO e-values take the form of Bayes factors with special\npriors. We illustrate the theory using several classic examples including a\none-sample safe t-test and the 2 x 2 contingency table. Sharing Fisherian,\nNeymanian and Jeffreys-Bayesian interpretations, e-values may provide a\nmethodology acceptable to adherents of all three schools.\n","authors":["Peter Grünwald","Rianne de Heide","Wouter Koolen"],"pdf_url":"https://arxiv.org/pdf/1906.07801v4.pdf","comment":"Accepted as discussion paper to the Journal of the Royal Statistical\n  Society series B"},{"id":"http://arxiv.org/abs/2302.10768v2","updated":"2023-03-07T15:11:10Z","published":"2023-01-19T11:11:57Z","title":"On the Importance of Sign Labeling: The Hamburg Sign Language Notation\n  System Case Study","summary":"  Labeling is the cornerstone of supervised machine learning, which has been\nexploited in a plethora of various applications, with sign language recognition\nbeing one of them. However, such algorithms must be fed with a huge amount of\nconsistently labeled data during the training process to elaborate a\nwell-generalizing model. In addition, there is a great need for an automated\nsolution that works with any nationally diversified sign language. Although\nthere are language-agnostic transcription systems, such as the Hamburg Sign\nLanguage Notation System (HamNoSys) that describe the signer's initial position\nand body movement instead of the glosses' meanings, there are still issues with\nproviding accurate and reliable labels for every real-world use case. In this\ncontext, the industry relies heavily on manual attribution and labeling of the\navailable video data. In this work, we tackle this issue and thoroughly analyze\nthe HamNoSys labels provided by various maintainers of open sign language\ncorpora in five sign languages, in order to examine the challenges encountered\nin labeling video data. We also investigate the consistency and objectivity of\nHamNoSys-based labels for the purpose of training machine learning models. Our\nfindings provide valuable insights into the limitations of the current labeling\nmethods and pave the way for future research on developing more accurate and\nefficient solutions for sign language recognition.\n","authors":["Maria Ferlin","Sylwia Majchrowska","Marta Plantykow","Alicja Kwaśniwska","Agnieszka Mikołajczyk-Bareła","Milena Olech","Jakub Nalepa"],"pdf_url":"https://arxiv.org/pdf/2302.10768v2.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2303.03965v1","updated":"2023-03-07T15:07:43Z","published":"2023-03-07T15:07:43Z","title":"Comparing 3D deformations between longitudinal daily CBCT acquisitions\n  using CNN for head and neck radiotherapy toxicity prediction","summary":"  Adaptive radiotherapy is a growing field of study in cancer treatment due to\nit's objective in sparing healthy tissue. The standard of care in several\ninstitutions includes longitudinal cone-beam computed tomography (CBCT)\nacquisitions to monitor changes, but have yet to be used to improve tumor\ncontrol while managing side-effects. The aim of this study is to demonstrate\nthe clinical value of pre-treatment CBCT acquired daily during radiation\ntherapy treatment for head and neck cancers for the downstream task of\npredicting severe toxicity occurrence: reactive feeding tube (NG),\nhospitalization and radionecrosis. For this, we propose a deformable 3D\nclassification pipeline that includes a component analyzing the Jacobian matrix\nof the deformation between planning CT and longitudinal CBCT, as well as\nclinical data. The model is based on a multi-branch 3D residual convolutional\nneural network, while the CT to CBCT registration is based on a pair of\nVoxelMorph architectures. Accuracies of 85.8% and 75.3% was found for\nradionecrosis and hospitalization, respectively, with similar performance as\nearly as after the first week of treatment. For NG tube risk, performance\nimproves with increasing the timing of the CBCT fraction, reaching 83.1% after\nthe $5_{th}$ week of treatment.\n","authors":["William Trung Le","Chulmin Bang","Philippine Cordelle","Daniel Markel","Phuc Felix Nguyen-Tan","Houda Bahig","Samuel Kadoury"],"pdf_url":"https://arxiv.org/pdf/2303.03965v1.pdf","comment":"11 pages, 3 figures, 2 equations, 2 tables"},{"id":"http://arxiv.org/abs/2303.03955v1","updated":"2023-03-07T15:01:52Z","published":"2023-03-07T15:01:52Z","title":"Diminishing Return of Value Expansion Methods in Model-Based\n  Reinforcement Learning","summary":"  Model-based reinforcement learning is one approach to increase sample\nefficiency. However, the accuracy of the dynamics model and the resulting\ncompounding error over modelled trajectories are commonly regarded as key\nlimitations. A natural question to ask is: How much more sample efficiency can\nbe gained by improving the learned dynamics models? Our paper empirically\nanswers this question for the class of model-based value expansion methods in\ncontinuous control problems. Value expansion methods should benefit from\nincreased model accuracy by enabling longer rollout horizons and better value\nfunction approximations. Our empirical study, which leverages oracle dynamics\nmodels to avoid compounding model errors, shows that (1) longer horizons\nincrease sample efficiency, but the gain in improvement decreases with each\nadditional expansion step, and (2) the increased model accuracy only marginally\nincreases the sample efficiency compared to learned models with identical\nhorizons. Therefore, longer horizons and increased model accuracy yield\ndiminishing returns in terms of sample efficiency. These improvements in sample\nefficiency are particularly disappointing when compared to model-free value\nexpansion methods. Even though they introduce no computational overhead, we\nfind their performance to be on-par with model-based value expansion methods.\nTherefore, we conclude that the limitation of model-based value expansion\nmethods is not the model accuracy of the learned models. While higher model\naccuracy is beneficial, our experiments show that even a perfect model will not\nprovide an un-rivalled sample efficiency but that the bottleneck lies\nelsewhere.\n","authors":["Daniel Palenicek","Michael Lutter","Joao Carvalho","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2303.03955v1.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.11864v2","updated":"2023-03-07T15:01:39Z","published":"2023-02-23T09:06:42Z","title":"Grounding Graph Network Simulators using Physical Sensor Observations","summary":"  Physical simulations that accurately model reality are crucial for many\nengineering disciplines such as mechanical engineering and robotic motion\nplanning. In recent years, learned Graph Network Simulators produced accurate\nmesh-based simulations while requiring only a fraction of the computational\ncost of traditional simulators. Yet, the resulting predictors are confined to\nlearning from data generated by existing mesh-based simulators and thus cannot\ninclude real world sensory information such as point cloud data. As these\npredictors have to simulate complex physical systems from only an initial\nstate, they exhibit a high error accumulation for long-term predictions. In\nthis work, we integrate sensory information to ground Graph Network Simulators\non real world observations. In particular, we predict the mesh state of\ndeformable objects by utilizing point cloud data. The resulting model allows\nfor accurate predictions over longer time horizons, even under uncertainties in\nthe simulation, such as unknown material properties. Since point clouds are\nusually not available for every time step, especially in online settings, we\nemploy an imputation-based model. The model can make use of such additional\ninformation only when provided, and resorts to a standard Graph Network\nSimulator, otherwise. We experimentally validate our approach on a suite of\nprediction tasks for mesh-based interactions between soft and rigid bodies. Our\nmethod results in utilization of additional point cloud information to\naccurately predict stable simulations where existing Graph Network Simulators\nfail.\n","authors":["Jonas Linkerhägner","Niklas Freymuth","Paul Maria Scheikl","Franziska Mathis-Ullrich","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2302.11864v2.pdf","comment":"Accepted as a poster at the 11th International Conference on Learning\n  Representations (ICLR), 2023"},{"id":"http://arxiv.org/abs/2303.03953v1","updated":"2023-03-07T14:59:33Z","published":"2023-03-07T14:59:33Z","title":"ChatGPT: Beginning of an End of Manual Annotation? Use Case of Automatic\n  Genre Identification","summary":"  ChatGPT has shown strong capabilities in natural language generation tasks,\nwhich naturally leads researchers to explore where its abilities end. In this\npaper, we examine whether ChatGPT can be used for zero-shot text\nclassification, more specifically, automatic genre identification. We compare\nChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on\ndatasets, manually annotated with genres. The models are compared on test sets\nin two languages: English and Slovenian. Results show that ChatGPT outperforms\nthe fine-tuned model when applied to the dataset which was not seen before by\neither of the models. Even when applied on Slovenian language as an\nunder-resourced language, ChatGPT's performance is no worse than when applied\nto English. However, if the model is fully prompted in Slovenian, the\nperformance drops significantly, showing the current limitations of ChatGPT\nusage on smaller languages. The presented results lead us to questioning\nwhether this is the beginning of an end of laborious manual annotation\ncampaigns even for smaller languages, such as Slovenian.\n","authors":["Taja Kuzman","Nikola Ljubešić","Igor Mozetič"],"pdf_url":"https://arxiv.org/pdf/2303.03953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03951v1","updated":"2023-03-07T14:58:18Z","published":"2023-03-07T14:58:18Z","title":"Probing Graph Representations","summary":"  Today we have a good theoretical understanding of the representational power\nof Graph Neural Networks (GNNs). For example, their limitations have been\ncharacterized in relation to a hierarchy of Weisfeiler-Lehman (WL) isomorphism\ntests. However, we do not know what is encoded in the learned representations.\nThis is our main question. We answer it using a probing framework to quantify\nthe amount of meaningful information captured in graph representations. Our\nfindings on molecular datasets show the potential of probing for understanding\nthe inductive biases of graph-based models. We compare different families of\nmodels and show that transformer-based models capture more chemically relevant\ninformation compared to models based on message passing. We also study the\neffect of different design choices such as skip connections and virtual nodes.\nWe advocate for probing as a useful diagnostic tool for evaluating graph-based\nmodels.\n","authors":["Mohammad Sadegh Akhondzadeh","Vijay Lingam","Aleksandar Bojchevski"],"pdf_url":"https://arxiv.org/pdf/2303.03951v1.pdf","comment":"20 pages, 12 figures, AISTATS 2023"},{"id":"http://arxiv.org/abs/2303.03944v1","updated":"2023-03-07T14:55:05Z","published":"2023-03-07T14:55:05Z","title":"On Momentum-Based Gradient Methods for Bilevel Optimization with\n  Nonconvex Lower-Level","summary":"  Bilevel optimization is a popular two-level hierarchical optimization, which\nhas been widely applied to many machine learning tasks such as hyperparameter\nlearning, meta learning and continual learning. Although many bilevel\noptimization methods recently have been developed, the bilevel methods are not\nwell studied when the lower-level problem is nonconvex. To fill this gap, in\nthe paper, we study a class of nonconvex bilevel optimization problems, which\nboth upper-level and lower-level problems are nonconvex, and the lower-level\nproblem satisfies Polyak-Lojasiewicz (PL) condition. We propose an efficient\nmomentum-based gradient bilevel method (MGBiO) to solve these deterministic\nproblems. Meanwhile, we propose a class of efficient momentum-based stochastic\ngradient bilevel methods (MSGBiO and VR-MSGBiO) to solve these stochastic\nproblems. Moreover, we provide a useful convergence analysis framework for our\nmethods. Specifically, under some mild conditions, we prove that our MGBiO\nmethod has a sample (or gradient) complexity of $O(\\epsilon^{-2})$ for finding\nan $\\epsilon$-stationary solution of the deterministic bilevel problems (i.e.,\n$\\|\\nabla F(x)\\|\\leq \\epsilon$), which improves the existing best results by a\nfactor of $O(\\epsilon^{-1})$. Meanwhile, we prove that our MSGBiO and VR-MSGBiO\nmethods have sample complexities of $\\tilde{O}(\\epsilon^{-4})$ and\n$\\tilde{O}(\\epsilon^{-3})$, respectively, in finding an $\\epsilon$-stationary\nsolution of the stochastic bilevel problems (i.e., $\\mathbb{E}\\|\\nabla\nF(x)\\|\\leq \\epsilon$), which improves the existing best results by a factor of\n$O(\\epsilon^{-3})$. This manuscript commemorates the mathematician Boris Polyak\n(1935 -2023).\n","authors":["Feihu Huang"],"pdf_url":"https://arxiv.org/pdf/2303.03944v1.pdf","comment":"37 pages"},{"id":"http://arxiv.org/abs/2303.03941v1","updated":"2023-03-07T14:51:09Z","published":"2023-03-07T14:51:09Z","title":"Fast Latent Factor Analysis via a Fuzzy PID-Incorporated Stochastic\n  Gradient Descent Algorithm","summary":"  A high-dimensional and incomplete (HDI) matrix can describe the complex\ninteractions among numerous nodes in various big data-related applications. A\nstochastic gradient descent (SGD)-based latent factor analysis (LFA) model is\nremarkably effective in extracting valuable information from an HDI matrix.\nHowever, such a model commonly encounters the problem of slow convergence\nbecause a standard SGD algorithm learns a latent factor relying on the\nstochastic gradient of current instance error only without considering past\nupdate information. To address this critical issue, this paper innovatively\nproposes a Fuzzy PID-incorporated SGD (FPS) algorithm with two-fold ideas: 1)\nrebuilding the instance learning error by considering the past update\ninformation in an efficient way following the principle of PID, and 2)\nimplementing hyper-parameters and gain parameters adaptation following the\nfuzzy rules. With it, an FPS-incorporated LFA model is further achieved for\nfast processing an HDI matrix. Empirical studies on six HDI datasets\ndemonstrate that the proposed FPS-incorporated LFA model significantly\noutperforms the state-of-the-art LFA models in terms of computational\nefficiency for predicting the missing data of an HDI matrix with competitive\naccuracy.\n","authors":["Li Jinli","Yuan Ye"],"pdf_url":"https://arxiv.org/pdf/2303.03941v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2303.03932v1","updated":"2023-03-07T14:38:28Z","published":"2023-03-07T14:38:28Z","title":"FFT-based Dynamic Token Mixer for Vision","summary":"  Multi-head-self-attention (MHSA)-equipped models have achieved notable\nperformance in computer vision. Their computational complexity is proportional\nto quadratic numbers of pixels in input feature maps, resulting in slow\nprocessing, especially when dealing with high-resolution images. New types of\ntoken-mixer are proposed as an alternative to MHSA to circumvent this problem:\nan FFT-based token-mixer, similar to MHSA in global operation but with lower\ncomputational complexity. However, despite its attractive properties, the\nFFT-based token-mixer has not been carefully examined in terms of its\ncompatibility with the rapidly evolving MetaFormer architecture. Here, we\npropose a novel token-mixer called dynamic filter and DFFormer and CDFFormer,\nimage recognition models using dynamic filters to close the gaps above.\nCDFFormer achieved a Top-1 accuracy of 85.0%, close to the hybrid architecture\nwith convolution and MHSA. Other wide-ranging experiments and analysis,\nincluding object detection and semantic segmentation, demonstrate that they are\ncompetitive with state-of-the-art architectures; Their throughput and memory\nefficiency when dealing with high-resolution image recognition is convolution\nand MHSA, not much different from ConvFormer, and far superior to CAFormer. Our\nresults indicate that the dynamic filter is one of the token-mixer options that\nshould be seriously considered. The code is available at\nhttps://github.com/okojoalg/dfformer\n","authors":["Yuki Tatsunami","Masato Taki"],"pdf_url":"https://arxiv.org/pdf/2303.03932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00305v2","updated":"2023-03-07T14:35:33Z","published":"2022-10-01T16:01:53Z","title":"LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph\n  Embeddings","summary":"  Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. Text-based KG embeddings\ncan represent entities by encoding descriptions with pre-trained language\nmodels, but no open-sourced library is specifically designed for KGs with PLMs\nat present. In this paper, we present LambdaKG, a library for KGE that equips\nwith many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and\nsupports various tasks (e.g., knowledge graph completion, question answering,\nrecommendation, and knowledge probing). LambdaKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at\nhttp://deepke.zjukg.cn/lambdakg.mp4 and long-term maintenance.\n","authors":["Xin Xie","Zhoubo Li","Xiaohan Wang","Yuqi Zhu","Ningyu Zhang","Jintian Zhang","Siyuan Cheng","Bozhong Tian","Shumin Deng","Feiyu Xiong","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00305v2.pdf","comment":"Work in progress and the project website is\n  https://zjunlp.github.io/project/promptkg/"},{"id":"http://arxiv.org/abs/2303.03912v1","updated":"2023-03-07T14:14:12Z","published":"2023-03-07T14:14:12Z","title":"Document-level Relation Extraction with Cross-sentence Reasoning Graph","summary":"  Relation extraction (RE) has recently moved from the sentence-level to\ndocument-level, which requires aggregating document information and using\nentities and mentions for reasoning. Existing works put entity nodes and\nmention nodes with similar representations in a document-level graph, whose\ncomplex edges may incur redundant information. Furthermore, existing studies\nonly focus on entity-level reasoning paths without considering global\ninteractions among entities cross-sentence. To these ends, we propose a novel\ndocument-level RE model with a GRaph information Aggregation and Cross-sentence\nReasoning network (GRACR). Specifically, a simplified document-level graph is\nconstructed to model the semantic information of all mentions and sentences in\na document, and an entity-level graph is designed to explore relations of\nlong-distance cross-sentence entity pairs. Experimental results show that GRACR\nachieves excellent performance on two public datasets of document-level RE. It\nis especially effective in extracting potential relations of cross-sentence\nentity pairs. Our code is available at https://github.com/UESTC-LHF/GRACR.\n","authors":["Hongfei Liu","Zhao Kang","Lizong Zhang","Ling Tian","Fujun Hua"],"pdf_url":"https://arxiv.org/pdf/2303.03912v1.pdf","comment":"This paper is accepted by PAKDD 2023"},{"id":"http://arxiv.org/abs/2303.03908v1","updated":"2023-03-07T14:11:01Z","published":"2023-03-07T14:11:01Z","title":"Client-specific Property Inference against Secure Aggregation in\n  Federated Learning","summary":"  Federated learning has become a widely used paradigm for collaboratively\ntraining a common model among different participants with the help of a central\nserver that coordinates the training. Although only the model parameters or\nother model updates are exchanged during the federated training instead of the\nparticipant's data, many attacks have shown that it is still possible to infer\nsensitive information such as membership, property, or outright reconstruction\nof participant data. Although differential privacy is considered an effective\nsolution to protect against privacy attacks, it is also criticized for its\nnegative effect on utility. Another possible defense is to use secure\naggregation which allows the server to only access the aggregated update\ninstead of each individual one, and it is often more appealing because it does\nnot degrade model quality. However, combining only the aggregated updates,\nwhich are generated by a different composition of clients in every round, may\nstill allow the inference of some client-specific information.\n  In this paper, we show that simple linear models can effectively capture\nclient-specific properties only from the aggregated model updates due to the\nlinearity of aggregation. We formulate an optimization problem across different\nrounds in order to infer a tested property of every client from the output of\nthe linear models, for example, whether they have a specific sample in their\ntraining data (membership inference) or whether they misbehave and attempt to\ndegrade the performance of the common model by poisoning attacks. Our\nreconstruction technique is completely passive and undetectable. We demonstrate\nthe efficacy of our approach on several scenarios which shows that secure\naggregation provides very limited privacy guarantees in practice. The source\ncode will be released upon publication.\n","authors":["Raouf Kerkouche","Gergely Ács","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2303.03908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03907v1","updated":"2023-03-07T14:09:08Z","published":"2023-03-07T14:09:08Z","title":"GaussianMLR: Learning Implicit Class Significance via Calibrated\n  Multi-Label Ranking","summary":"  Existing multi-label frameworks only exploit the information deduced from the\nbipartition of the labels into a positive and negative set. Therefore, they do\nnot benefit from the ranking order between positive labels, which is the\nconcept we introduce in this paper. We propose a novel multi-label ranking\nmethod: GaussianMLR, which aims to learn implicit class significance values\nthat determine the positive label ranks instead of treating them as of equal\nimportance, by following an approach that unifies ranking and classification\ntasks associated with multi-label ranking. Due to the scarcity of public\ndatasets, we introduce eight synthetic datasets generated under varying\nimportance factors to provide an enriched and controllable experimental\nenvironment for this study. On both real-world and synthetic datasets, we carry\nout extensive comparisons with relevant baselines and evaluate the performance\non both of the two sub-tasks. We show that our method is able to accurately\nlearn a representation of the incorporated positive rank order, which is not\nonly consistent with the ground truth but also proportional to the underlying\ninformation. We strengthen our claims empirically by conducting comprehensive\nexperimental studies. Code is available at\nhttps://github.com/MrGranddy/GaussianMLR.\n","authors":["V. Bugra Yesilkaynak","Emine Dari","Alican Mertan","Gozde Unal"],"pdf_url":"https://arxiv.org/pdf/2303.03907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14085v2","updated":"2023-03-07T13:56:51Z","published":"2022-11-25T13:14:33Z","title":"Positive unlabeled learning with tensor networks","summary":"  Positive unlabeled learning is a binary classification problem with positive\nand unlabeled data. It is common in domains where negative labels are costly or\nimpossible to obtain, e.g., medicine and personalized advertising. We apply the\nlocally purified state tensor network to the positive unlabeled learning\nproblem and test our model on the MNIST image and 15 categorical/mixed\ndatasets. On the MNIST dataset, we obtain close to the state-of-the-art results\neven with very few labeled positive samples. We significantly improve the\nstate-of-the-art on categorical datasets. Further, we show that the agreement\nfraction between outputs of different models on unlabeled samples is a good\nindicator of the model's performance. Finally, our method can generate new\npositive and negative instances, which we demonstrate on simple synthetic\ndatasets.\n","authors":["Bojan Žunkovič"],"pdf_url":"https://arxiv.org/pdf/2211.14085v2.pdf","comment":"12 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2303.03894v1","updated":"2023-03-07T13:38:04Z","published":"2023-03-07T13:38:04Z","title":"Manually Selecting The Data Function for Supervised Learning of small\n  datasets","summary":"  Supervised learning problems may become ill-posed when there is a lack of\ninformation, resulting in unstable and non-unique solutions. However, instead\nof solely relying on regularization, initializing an informative ill-posed\noperator is akin to posing better questions to achieve more accurate answers.\nThe Fredholm integral equation of the first kind (FIFK) is a reliable ill-posed\noperator that can integrate distributions and prior knowledge as input\ninformation. By incorporating input distributions and prior knowledge, the FIFK\noperator can address the limitations of using high-dimensional input\ndistributions by semi-supervised assumptions, leading to more precise\napproximations of the integral operator. Additionally, the FIFK's incorporation\nof probabilistic principles can further enhance the accuracy and effectiveness\nof solutions. In cases of noisy operator equations and limited data, the FIFK's\nflexibility in defining problems using prior information or cross-validation\nwith various kernel designs is especially advantageous. This capability allows\nfor detailed problem definitions and facilitates achieving high levels of\naccuracy and stability in solutions. In our study, we examined the FIFK through\ntwo different approaches. Firstly, we implemented a semi-supervised assumption\nby using the same Fredholm operator kernel and data function kernel and\nincorporating unlabeled information. Secondly, we used the MSDF method, which\ninvolves selecting different kernels on both sides of the equation to define\nwhen the mapping kernel is different from the data function kernel. To assess\nthe effectiveness of the FIFK and the proposed methods in solving ill-posed\nproblems, we conducted experiments on a real-world dataset. Our goal was to\ncompare the performance of these methods against the widely used least-squares\nmethod and other comparable methods.\n","authors":["Amir Khanjari","Saeid Pourmand","Mohammad Reza Faridrohani"],"pdf_url":"https://arxiv.org/pdf/2303.03894v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03876v1","updated":"2023-03-07T13:23:31Z","published":"2023-03-07T13:23:31Z","title":"Organelle-specific segmentation, spatial analysis, and visualization of\n  volume electron microscopy datasets","summary":"  Volume electron microscopy is the method of choice for the in-situ\ninterrogation of cellular ultrastructure at the nanometer scale. Recent\ntechnical advances have led to a rapid increase in large raw image datasets\nthat require computational strategies for segmentation and spatial analysis. In\nthis protocol, we describe a practical and annotation-efficient pipeline for\norganelle-specific segmentation, spatial analysis, and visualization of large\nvolume electron microscopy datasets using freely available, user-friendly\nsoftware tools that can be run on a single standard workstation. We\nspecifically target researchers in the life sciences with limited computational\nexpertise, who face the following tasks within their volume electron microscopy\nprojects: i) How to generate 3D segmentation labels for different types of cell\norganelles while minimizing manual annotation efforts, ii) how to analyze the\nspatial interactions between organelle instances, and iii) how to best\nvisualize the 3D segmentation results. To meet these demands we give detailed\nguidelines for choosing the most efficient segmentation tools for the specific\ncell organelle. We furthermore provide easily executable components for spatial\nanalysis and 3D rendering and bridge compatibility issues between freely\navailable open-source tools, such that others can replicate our full pipeline\nstarting from a raw dataset up to the final plots and rendered images. We\nbelieve that our detailed description can serve as a valuable reference for\nsimilar projects requiring special strategies for single- or multiple organelle\nanalysis which can be achieved with computational resources commonly available\nto single-user setups.\n","authors":["Andreas Müller","Deborah Schmidt","Lucas Rieckert","Michele Solimena","Martin Weigert"],"pdf_url":"https://arxiv.org/pdf/2303.03876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06983v4","updated":"2023-03-07T13:19:13Z","published":"2022-10-10T12:37:59Z","title":"Denoising Masked AutoEncoders Help Robust Classification","summary":"  In this paper, we propose a new self-supervised method, which is called\nDenoising Masked AutoEncoders (DMAE), for learning certified robust classifiers\nof images. In DMAE, we corrupt each image by adding Gaussian noises to each\npixel value and randomly masking several patches. A Transformer-based\nencoder-decoder model is then trained to reconstruct the original image from\nthe corrupted one. In this learning paradigm, the encoder will learn to capture\nrelevant semantics for the downstream tasks, which is also robust to Gaussian\nadditive noises. We show that the pre-trained encoder can naturally be used as\nthe base classifier in Gaussian smoothed models, where we can analytically\ncompute the certified radius for any data point. Although the proposed method\nis simple, it yields significant performance improvement in downstream\nclassification tasks. We show that the DMAE ViT-Base model, which just uses\n1/10 parameters of the model developed in recent work arXiv:2206.10550,\nachieves competitive or better certified accuracy in various settings. The DMAE\nViT-Large model significantly surpasses all previous results, establishing a\nnew state-of-the-art on ImageNet dataset. We further demonstrate that the\npre-trained model has good transferability to the CIFAR-10 dataset, suggesting\nits wide adaptability. Models and code are available at\nhttps://github.com/quanlin-wu/dmae.\n","authors":["Quanlin Wu","Hang Ye","Yuntian Gu","Huishuai Zhang","Liwei Wang","Di He"],"pdf_url":"https://arxiv.org/pdf/2210.06983v4.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2201.02478v2","updated":"2023-03-07T13:11:04Z","published":"2022-01-07T14:56:33Z","title":"Bayesian Neural Networks for Reversible Steganography","summary":"  Recent advances in deep learning have led to a paradigm shift in the field of\nreversible steganography. A fundamental pillar of reversible steganography is\npredictive modelling which can be realised via deep neural networks. However,\nnon-trivial errors exist in inferences about some out-of-distribution and noisy\ndata. In view of this issue, we propose to consider uncertainty in predictive\nmodels based upon a theoretical framework of Bayesian deep learning, thereby\ncreating an adaptive steganographic system. Most modern deep-learning models\nare regarded as deterministic because they only offer predictions while failing\nto provide uncertainty measurement. Bayesian neural networks bring a\nprobabilistic perspective to deep learning and can be regarded as self-aware\nintelligent machinery; that is, a machine that knows its own limitations. To\nquantify uncertainty, we apply Bayesian statistics to model the predictive\ndistribution and approximate it through Monte Carlo sampling with stochastic\nforward passes. We further show that predictive uncertainty can be disentangled\ninto aleatoric and epistemic uncertainties and these quantities can be learnt\nunsupervised. Experimental results demonstrate an improvement delivered by\nBayesian uncertainty analysis upon steganographic rate-distortion performance.\n","authors":["Ching-Chun Chang"],"pdf_url":"https://arxiv.org/pdf/2201.02478v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10669v2","updated":"2023-03-07T13:06:51Z","published":"2023-02-21T13:39:40Z","title":"UAV Path Planning Employing MPC- Reinforcement Learning Method\n  Considering Collision Avoidance","summary":"  In this paper, we tackle the problem of Unmanned Aerial (UA V) path planning\nin complex and uncertain environments by designing a Model Predictive Control\n(MPC), based on a Long-Short-Term Memory (LSTM) network integrated into the\nDeep Deterministic Policy Gradient algorithm. In the proposed solution,\nLSTM-MPC operates as a deterministic policy within the DDPG network, and it\nleverages a predicting pool to store predicted future states and actions for\nimproved robustness and efficiency. The use of the predicting pool also enables\nthe initialization of the critic network, leading to improved convergence speed\nand reduced failure rate compared to traditional reinforcement learning and\ndeep reinforcement learning methods. The effectiveness of the proposed solution\nis evaluated by numerical simulations.\n","authors":["Mahya Ramezani","Hamed Habibi","Jose luis Sanchez Lopez","Holger Voos"],"pdf_url":"https://arxiv.org/pdf/2302.10669v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.01893v3","updated":"2023-03-07T12:28:59Z","published":"2022-08-03T07:44:48Z","title":"Flow Annealed Importance Sampling Bootstrap","summary":"  Normalizing flows are tractable density models that can approximate\ncomplicated target distributions, e.g. Boltzmann distributions of physical\nsystems. However, current methods for training flows either suffer from\nmode-seeking behavior, use samples from the target generated beforehand by\nexpensive MCMC methods, or use stochastic losses that have high variance. To\navoid these problems, we augment flows with annealed importance sampling (AIS)\nand minimize the mass-covering $\\alpha$-divergence with $\\alpha=2$, which\nminimizes importance weight variance. Our method, Flow AIS Bootstrap (FAB),\nuses AIS to generate samples in regions where the flow is a poor approximation\nof the target, facilitating the discovery of new modes. We apply FAB to\nmultimodal targets and show that we can approximate them very accurately where\nprevious methods fail. To the best of our knowledge, we are the first to learn\nthe Boltzmann distribution of the alanine dipeptide molecule using only the\nunnormalized target density, without access to samples generated via Molecular\nDynamics (MD) simulations: FAB produces better results than training via\nmaximum likelihood on MD samples while using 100 times fewer target\nevaluations. After reweighting the samples, we obtain unbiased histograms of\ndihedral angles that are almost identical to the ground truth.\n","authors":["Laurence Illing Midgley","Vincent Stimper","Gregor N. C. Simm","Bernhard Schölkopf","José Miguel Hernández-Lobato"],"pdf_url":"https://arxiv.org/pdf/2208.01893v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.03875v2","updated":"2023-03-07T12:14:55Z","published":"2021-05-09T08:49:14Z","title":"Bounding Information Leakage in Machine Learning","summary":"  Recently, it has been shown that Machine Learning models can leak sensitive\ninformation about their training data. This information leakage is exposed\nthrough membership and attribute inference attacks. Although many attack\nstrategies have been proposed, little effort has been made to formalize these\nproblems. We present a novel formalism, generalizing membership and attribute\ninference attack setups previously studied in the literature and connecting\nthem to memorization and generalization. First, we derive a universal bound on\nthe success rate of inference attacks and connect it to the generalization gap\nof the target model. Second, we study the question of how much sensitive\ninformation is stored by the algorithm about its training set and we derive\nbounds on the mutual information between the sensitive attributes and model\nparameters. Experimentally, we illustrate the potential of our approach by\napplying it to both synthetic data and classification tasks on natural images.\nFinally, we apply our formalism to different attribute inference strategies,\nwith which an adversary is able to recover the identity of writers in the\nPenDigits dataset.\n","authors":["Ganesh Del Grosso","Georg Pichler","Catuscia Palamidessi","Pablo Piantanida"],"pdf_url":"https://arxiv.org/pdf/2105.03875v2.pdf","comment":"Published in [Elsevier\n  Neurocomputing](https://doi.org/10.1016/j.neucom.2023.02.058)"},{"id":"http://arxiv.org/abs/2202.09657v4","updated":"2023-03-07T11:59:50Z","published":"2022-02-19T18:40:55Z","title":"Survey of Machine Learning Based Intrusion Detection Methods for\n  Internet of Medical Things","summary":"  The Internet of Medical Things (IoMT) has revolutionized the healthcare\nindustry by enabling physiological data collection using sensors, which are\ntransmitted to remote servers for continuous analysis by physicians and\nhealthcare professionals. This technology offers numerous benefits, including\nearly disease detection and automatic medication for patients with chronic\nillnesses. However, IoMT technology also presents significant security risks,\nsuch as violating patient privacy or exposing sensitive data to interception\nattacks due to wireless communication, which could be fatal for the patient.\nAdditionally, traditional security measures, such as cryptography, are\nchallenging to implement in medical equipment due to the heterogeneous\ncommunication and their limited computation, storage, and energy capacity.\nThese protection methods are also ineffective against new and zero-day attacks.\nIt is essential to adopt robust security measures to ensure data integrity,\nconfidentiality, and availability during data collection, transmission,\nstorage, and processing. In this context, using Intrusion Detection Systems\n(IDS) based on Machine Learning (ML) can bring a complementary security\nsolution adapted to the unique characteristics of IoMT systems. Therefore, this\npaper investigates how IDS based on ML can address security and privacy issues\nin IoMT systems. First, the generic three-layer architecture of IoMT is\nprovided, and the security requirements of IoMT systems are outlined. Then, the\nvarious threats that can affect IoMT security are identified, and the\nadvantages, disadvantages, methods, and datasets used in each solution based on\nML at the three layers that make up IoMT are presented. Finally, the paper\ndiscusses the challenges and limitations of applying IDS based on ML at each\nlayer of IoMT, which can serve as a future research direction.\n","authors":["Ayoub Si-Ahmed","Mohammed Ali Al-Garadi","Narhimene Boustia"],"pdf_url":"https://arxiv.org/pdf/2202.09657v4.pdf","comment":"40 pages, 3 figures, and 6 tables"},{"id":"http://arxiv.org/abs/2303.03829v1","updated":"2023-03-07T11:53:37Z","published":"2023-03-07T11:53:37Z","title":"Can Decentralized Learning be more robust than Federated Learning?","summary":"  Decentralized Learning (DL) is a peer--to--peer learning approach that allows\na group of users to jointly train a machine learning model. To ensure\ncorrectness, DL should be robust, i.e., Byzantine users must not be able to\ntamper with the result of the collaboration. In this paper, we introduce two\n\\textit{new} attacks against DL where a Byzantine user can: make the network\nconverge to an arbitrary model of their choice, and exclude an arbitrary user\nfrom the learning process. We demonstrate our attacks' efficiency against\nSelf--Centered Clipping, the state--of--the--art robust DL protocol. Finally,\nwe show that the capabilities decentralization grants to Byzantine users result\nin decentralized learning \\emph{always} providing less robustness than\nfederated learning.\n","authors":["Mathilde Raynal","Dario Pasquini","Carmela Troncoso"],"pdf_url":"https://arxiv.org/pdf/2303.03829v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01141v2","updated":"2023-03-07T11:39:26Z","published":"2022-12-02T12:42:53Z","title":"MHCCL: Masked Hierarchical Cluster-wise Contrastive Learning for\n  Multivariate Time Series","summary":"  Learning semantic-rich representations from raw unlabeled time series data is\ncritical for downstream tasks such as classification and forecasting.\nContrastive learning has recently shown its promising representation learning\ncapability in the absence of expert annotations. However, existing contrastive\napproaches generally treat each instance independently, which leads to false\nnegative pairs that share the same semantics. To tackle this problem, we\npropose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model,\nwhich exploits semantic information obtained from the hierarchical structure\nconsisting of multiple latent partitions for multivariate time series.\nMotivated by the observation that fine-grained clustering preserves higher\npurity while coarse-grained one reflects higher-level semantics, we propose a\nnovel downward masking strategy to filter out fake negatives and supplement\npositives by incorporating the multi-granularity information from the\nclustering hierarchy. In addition, a novel upward masking strategy is designed\nin MHCCL to remove outliers of clusters at each partition to refine prototypes,\nwhich helps speed up the hierarchical clustering process and improves the\nclustering quality. We conduct experimental evaluations on seven widely-used\nmultivariate time series datasets. The results demonstrate the superiority of\nMHCCL over the state-of-the-art approaches for unsupervised time series\nrepresentation learning.\n","authors":["Qianwen Meng","Hangwei Qian","Yong Liu","Lizhen Cui","Yonghui Xu","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2212.01141v2.pdf","comment":"accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.03811v1","updated":"2023-03-07T11:26:09Z","published":"2023-03-07T11:26:09Z","title":"ENTROPY: Environment Transformer and Offline Policy Optimization","summary":"  Model-based methods provide an effective approach to offline reinforcement\nlearning (RL). They learn an environmental dynamics model from interaction\nexperiences and then perform policy optimization based on the learned model.\nHowever, previous model-based offline RL methods lack long-term prediction\ncapability, resulting in large errors when generating multi-step trajectories.\nWe address this issue by developing a sequence modeling architecture,\nEnvironment Transformer, which can generate reliable long-horizon trajectories\nbased on offline datasets. We then propose a novel model-based offline RL\nalgorithm, ENTROPY, that learns the dynamics model and reward function by\nENvironment TRansformer and performs Offline PolicY optimization. We evaluate\nthe proposed method on MuJoCo continuous control RL environments. Results show\nthat ENTROPY performs comparably or better than the state-of-the-art\nmodel-based and model-free offline RL methods and demonstrates more powerful\nlong-term trajectory prediction capability compared to existing model-based\noffline methods.\n","authors":["Pengqin Wang","Meixin Zhu","Shaojie Shen"],"pdf_url":"https://arxiv.org/pdf/2303.03811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04388v2","updated":"2023-03-07T11:09:29Z","published":"2023-01-11T10:20:56Z","title":"Perceive and predict: self-supervised speech representation based loss\n  functions for speech enhancement","summary":"  Recent work in the domain of speech enhancement has explored the use of\nself-supervised speech representations to aid in the training of neural speech\nenhancement models. However, much of this work focuses on using the deepest or\nfinal outputs of self supervised speech representation models, rather than the\nearlier feature encodings. The use of self supervised representations in such a\nway is often not fully motivated. In this work it is shown that the distance\nbetween the feature encodings of clean and noisy speech correlate strongly with\npsychoacoustically motivated measures of speech quality and intelligibility, as\nwell as with human Mean Opinion Score (MOS) ratings. Experiments using this\ndistance as a loss function are performed and improved performance over the use\nof STFT spectrogram distance based loss as well as other common loss functions\nfrom speech enhancement literature is demonstrated using objective measures\nsuch as perceptual evaluation of speech quality (PESQ) and short-time objective\nintelligibility (STOI).\n","authors":["George Close","William Ravenscroft","Thomas Hain","Stefan Goetze"],"pdf_url":"https://arxiv.org/pdf/2301.04388v2.pdf","comment":"4 pages, accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.03789v1","updated":"2023-03-07T10:52:59Z","published":"2023-03-07T10:52:59Z","title":"Fast and Multi-aspect Mining of Complex Time-stamped Event Streams","summary":"  Given a huge, online stream of time-evolving events with multiple attributes,\nsuch as online shopping logs: (item, price, brand, time), and local mobility\nactivities: (pick-up and drop-off locations, time), how can we summarize large,\ndynamic high-order tensor streams? How can we see any hidden patterns, rules,\nand anomalies? Our answer is to focus on two types of patterns, i.e.,\n''regimes'' and ''components'', for which we present CubeScope, an efficient\nand effective method over high-order tensor streams. Specifically, it\nidentifies any sudden discontinuity and recognizes distinct dynamical patterns,\n''regimes'' (e.g., weekday/weekend/holiday patterns). In each regime, it also\nperforms multi-way summarization for all attributes (e.g., item, price, brand,\nand time) and discovers hidden ''components'' representing latent groups (e.g.,\nitem/brand groups) and their relationship. Thanks to its concise but effective\nsummarization, CubeScope can also detect the sudden appearance of anomalies and\nidentify the types of anomalies that occur in practice. Our proposed method has\nthe following properties: (a) Effective: it captures dynamical multi-aspect\npatterns, i.e., regimes and components, and statistically summarizes all the\nevents; (b) General: it is practical for successful application to data\ncompression, pattern discovery, and anomaly detection on various types of\ntensor streams; (c) Scalable: our algorithm does not depend on the length of\nthe data stream and its dimensionality. Extensive experiments on real datasets\ndemonstrate that CubeScope finds meaningful patterns and anomalies correctly,\nand consistently outperforms the state-of-the-art methods as regards accuracy\nand execution speed.\n","authors":["Kota Nakamura","Yasuko Matsubara","Koki Kawabata","Yuhei Umeda","Yuichiro Wada","Yasushi Sakurai"],"pdf_url":"https://arxiv.org/pdf/2303.03789v1.pdf","comment":"Accepted by WWW 2023"},{"id":"http://arxiv.org/abs/2303.03787v1","updated":"2023-03-07T10:48:20Z","published":"2023-03-07T10:48:20Z","title":"Sample-efficient Real-time Planning with Curiosity Cross-Entropy Method\n  and Contrastive Learning","summary":"  Model-based reinforcement learning (MBRL) with real-time planning has shown\ngreat potential in locomotion and manipulation control tasks. However, the\nexisting planning methods, such as the Cross-Entropy Method (CEM), do not scale\nwell to complex high-dimensional environments. One of the key reasons for\nunderperformance is the lack of exploration, as these planning methods only aim\nto maximize the cumulative extrinsic reward over the planning horizon.\nFurthermore, planning inside the compact latent space in the absence of\nobservations makes it challenging to use curiosity-based intrinsic motivation.\nWe propose Curiosity CEM (CCEM), an improved version of the CEM algorithm for\nencouraging exploration via curiosity. Our proposed method maximizes the sum of\nstate-action Q values over the planning horizon, in which these Q values\nestimate the future extrinsic and intrinsic reward, hence encouraging reaching\nnovel observations. In addition, our model uses contrastive representation\nlearning to efficiently learn latent representations. Experiments on\nimage-based continuous control tasks from the DeepMind Control suite show that\nCCEM is by a large margin more sample-efficient than previous MBRL algorithms\nand compares favorably with the best model-free RL methods.\n","authors":["Mostafa Kotb","Cornelius Weber","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2303.03787v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.12526v2","updated":"2023-03-07T10:31:42Z","published":"2023-02-24T09:18:27Z","title":"Model-Based Uncertainty in Value Functions","summary":"  We consider the problem of quantifying uncertainty over expected cumulative\nrewards in model-based reinforcement learning. In particular, we focus on\ncharacterizing the variance over values induced by a distribution over MDPs.\nPrevious work upper bounds the posterior variance over values by solving a\nso-called uncertainty Bellman equation, but the over-approximation may result\nin inefficient exploration. We propose a new uncertainty Bellman equation whose\nsolution converges to the true posterior variance over values and explicitly\ncharacterizes the gap in previous work. Moreover, our uncertainty\nquantification technique is easily integrated into common exploration\nstrategies and scales naturally beyond the tabular setting by using standard\ndeep reinforcement learning architectures. Experiments in difficult exploration\ntasks, both in tabular and continuous control settings, show that our sharper\nuncertainty estimates improve sample-efficiency.\n","authors":["Carlos E. Luis","Alessandro G. Bottero","Julia Vinogradska","Felix Berkenkamp","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2302.12526v2.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2209.15430v2","updated":"2023-03-07T10:08:04Z","published":"2022-09-30T12:37:03Z","title":"Relative representations enable zero-shot latent space communication","summary":"  Neural networks embed the geometric structure of a data manifold lying in a\nhigh-dimensional space into latent representations. Ideally, the distribution\nof the data points in the latent space should depend only on the task, the\ndata, the loss, and other architecture-specific constraints. However, factors\nsuch as the random weights initialization, training hyperparameters, or other\nsources of randomness in the training phase may induce incoherent latent spaces\nthat hinder any form of reuse. Nevertheless, we empirically observe that, under\nthe same data and modeling choices, the angles between the encodings within\ndistinct latent spaces do not change. In this work, we propose the latent\nsimilarity between each sample and a fixed set of anchors as an alternative\ndata representation, demonstrating that it can enforce the desired invariances\nwithout any additional training. We show how neural architectures can leverage\nthese relative representations to guarantee, in practice, invariance to latent\nisometries and rescalings, effectively enabling latent space communication:\nfrom zero-shot model stitching to latent space comparison between diverse\nsettings. We extensively validate the generalization capability of our approach\non different datasets, spanning various modalities (images, text, graphs),\ntasks (e.g., classification, reconstruction) and architectures (e.g., CNNs,\nGCNs, transformers).\n","authors":["Luca Moschella","Valentino Maiorca","Marco Fumero","Antonio Norelli","Francesco Locatello","Emanuele Rodolà"],"pdf_url":"https://arxiv.org/pdf/2209.15430v2.pdf","comment":"ICLR 2023 notable top 5%, 26 pages, 11 figures, 18 tables"},{"id":"http://arxiv.org/abs/2303.03770v1","updated":"2023-03-07T10:04:55Z","published":"2023-03-07T10:04:55Z","title":"Guiding Pseudo-labels with Uncertainty Estimation for Test-Time\n  Adaptation","summary":"  Standard Unsupervised Domain Adaptation (UDA) methods assume the availability\nof both source and target data during the adaptation. In this work, we\ninvestigate the Test-Time Adaptation (TTA), a specific case of UDA where a\nmodel is adapted to a target domain without access to source data. We propose a\nnovel approach for the TTA setting based on a loss reweighting strategy that\nbrings robustness against the noise that inevitably affects the pseudo-labels.\nThe classification loss is reweighted based on the reliability of the\npseudo-labels that is measured by estimating their uncertainty. Guided by such\nreweighting strategy, the pseudo-labels are progressively refined by\naggregating knowledge from neighbouring samples. Furthermore, a self-supervised\ncontrastive framework is leveraged as a target space regulariser to enhance\nsuch knowledge aggregation. A novel negative pairs exclusion strategy is\nproposed to identify and exclude negative pairs made of samples sharing the\nsame class, even in presence of some noise in the pseudo-labels. Our method\noutperforms previous methods on three major benchmarks by a large margin. We\nset the new TTA state-of-the-art on VisDA-C and DomainNet with a performance\ngain of +1.8\\% on both benchmarks and on PACS with +12.3\\% in the single-source\nsetting and +6.6\\% in\\ multi-target adaptation. Additional analyses demonstrate\nthat the proposed approach is robust to the noise, which results in\nsignificantly more accurate pseudo-labels compared to state-of-the-art\napproaches.\n","authors":["Mattia Litrico","Alessio Del Bue","Pietro Morerio"],"pdf_url":"https://arxiv.org/pdf/2303.03770v1.pdf","comment":"To be published in Proceedings of the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition (CVPR) 2023"},{"id":"http://arxiv.org/abs/2303.03769v1","updated":"2023-03-07T10:04:51Z","published":"2023-03-07T10:04:51Z","title":"Learning Hamiltonian Systems with Mono-Implicit Runge-Kutta Methods","summary":"  Numerical integrators could be used to form interpolation conditions when\ntraining neural networks to approximate the vector field of an ordinary\ndifferential equation (ODE) from data. When numerical one-step schemes such as\nthe Runge-Kutta methods are used to approximate the temporal discretization of\nan ODE with a known vector field, properties such as symmetry and stability are\nmuch studied. Here, we show that using mono-implicit Runge-Kutta methods of\nhigh order allows for accurate training of Hamiltonian neural networks on small\ndatasets. This is demonstrated by numerical experiments where the Hamiltonian\nof the chaotic double pendulum in addition to the Fermi-Pasta-Ulam-Tsingou\nsystem is learned from data.\n","authors":["Håkon Noren"],"pdf_url":"https://arxiv.org/pdf/2303.03769v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.03767v1","updated":"2023-03-07T10:01:00Z","published":"2023-03-07T10:01:00Z","title":"Proactive Multi-Camera Collaboration For 3D Human Pose Estimation","summary":"  This paper presents a multi-agent reinforcement learning (MARL) scheme for\nproactive Multi-Camera Collaboration in 3D Human Pose Estimation in dynamic\nhuman crowds. Traditional fixed-viewpoint multi-camera solutions for human\nmotion capture (MoCap) are limited in capture space and susceptible to dynamic\nocclusions. Active camera approaches proactively control camera poses to find\noptimal viewpoints for 3D reconstruction. However, current methods still face\nchallenges with credit assignment and environment dynamics. To address these\nissues, our proposed method introduces a novel Collaborative Triangulation\nContribution Reward (CTCR) that improves convergence and alleviates multi-agent\ncredit assignment issues resulting from using 3D reconstruction accuracy as the\nshared reward. Additionally, we jointly train our model with multiple world\ndynamics learning tasks to better capture environment dynamics and encourage\nanticipatory behaviors for occlusion avoidance. We evaluate our proposed method\nin four photo-realistic UE4 environments to ensure validity and\ngeneralizability. Empirical results show that our method outperforms fixed and\nactive baselines in various scenarios with different numbers of cameras and\nhumans.\n","authors":["Hai Ci","Mickel Liu","Xuehai Pan","Fangwei Zhong","Yizhou Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03767v1.pdf","comment":"ICLR 2023 poster"},{"id":"http://arxiv.org/abs/2302.01622v2","updated":"2023-03-07T10:00:43Z","published":"2023-02-03T09:49:13Z","title":"Private, fair and accurate: Training large-scale, privacy-preserving AI\n  models in medical imaging","summary":"  Artificial intelligence (AI) models are increasingly used in the medical\ndomain. However, as medical data is highly sensitive, special precautions to\nensure its protection are required. The gold standard for privacy preservation\nis the introduction of differential privacy (DP) to model training. Prior work\nindicates that DP has negative implications on model accuracy and fairness,\nwhich are unacceptable in medicine and represent a main barrier to the\nwidespread use of privacy-preserving techniques. In this work, we evaluated the\neffect of privacy-preserving training of AI models for chest radiograph\ndiagnosis regarding accuracy and fairness compared to non-private training. For\nthis, we used a large dataset (N=193,311) of high quality clinical chest\nradiographs, which were retrospectively collected and manually labeled by\nexperienced radiologists. We then compared non-private deep convolutional\nneural networks (CNNs) and privacy-preserving (DP) models with respect to\nprivacy-utility trade-offs measured as area under the\nreceiver-operator-characteristic curve (AUROC), and privacy-fairness\ntrade-offs, measured as Pearson's r or Statistical Parity Difference. We found\nthat the non-private CNNs achieved an average AUROC score of 0.90 +- 0.04 over\nall labels, whereas the DP CNNs with a privacy budget of epsilon=7.89 resulted\nin an AUROC of 0.87 +- 0.04, i.e., a mere 2.6% performance decrease compared to\nnon-private training. Furthermore, we found the privacy-preserving training not\nto amplify discrimination against age, sex or co-morbidity. Our study shows\nthat -- under the challenging realistic circumstances of a real-life clinical\ndataset -- the privacy-preserving training of diagnostic deep learning models\nis possible with excellent diagnostic accuracy and fairness.\n","authors":["Soroosh Tayebi Arasteh","Alexander Ziller","Christiane Kuhl","Marcus Makowski","Sven Nebelung","Rickmer Braren","Daniel Rueckert","Daniel Truhn","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2302.01622v2.pdf","comment":"3 tables, 5 figures, 11 supplementary materials"},{"id":"http://arxiv.org/abs/2303.03761v1","updated":"2023-03-07T09:56:23Z","published":"2023-03-07T09:56:23Z","title":"Graph Neural Networks in Vision-Language Image Understanding: A Survey","summary":"  2D image understanding is a complex problem within Computer Vision, but it\nholds the key to providing human level scene comprehension. It goes further\nthan identifying the objects in an image, and instead it attempts to understand\nthe scene. Solutions to this problem form the underpinning of a range of tasks,\nincluding image captioning, Visual Question Answering (VQA), and image\nretrieval. Graphs provide a natural way to represent the relational arrangement\nbetween objects in an image, and thus in recent years Graph Neural Networks\n(GNNs) have become a standard component of many 2D image understanding\npipelines, becoming a core architectural component especially in the VQA group\nof tasks. In this survey, we review this rapidly evolving field and we provide\na taxonomy of graph types used in 2D image understanding approaches, a\ncomprehensive list of the GNN models used in this domain, and a roadmap of\nfuture potential developments. To the best of our knowledge, this is the first\ncomprehensive survey that covers image captioning, visual question answering,\nand image retrieval techniques that focus on using GNNs as the main part of\ntheir architecture.\n","authors":["Henry Senior","Gregory Slabaugh","Shanxin Yuan","Luca Rossi"],"pdf_url":"https://arxiv.org/pdf/2303.03761v1.pdf","comment":"19 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2209.03997v2","updated":"2023-03-07T09:35:11Z","published":"2022-09-08T18:49:10Z","title":"Online Low Rank Matrix Completion","summary":"  We study the problem of {\\em online} low-rank matrix completion with\n$\\mathsf{M}$ users, $\\mathsf{N}$ items and $\\mathsf{T}$ rounds. In each round,\nthe algorithm recommends one item per user, for which it gets a (noisy) reward\nsampled from a low-rank user-item preference matrix. The goal is to design a\nmethod with sub-linear regret (in $\\mathsf{T}$) and nearly optimal dependence\non $\\mathsf{M}$ and $\\mathsf{N}$. The problem can be easily mapped to the\nstandard multi-armed bandit problem where each item is an {\\em independent}\narm, but that leads to poor regret as the correlation between arms and users is\nnot exploited. On the other hand, exploiting the low-rank structure of reward\nmatrix is challenging due to non-convexity of the low-rank manifold. We first\ndemonstrate that the low-rank structure can be exploited using a simple\nexplore-then-commit (ETC) approach that ensures a regret of $O(\\mathsf{polylog}\n(\\mathsf{M}+\\mathsf{N}) \\mathsf{T}^{2/3})$. That is, roughly only\n$\\mathsf{polylog} (\\mathsf{M}+\\mathsf{N})$ item recommendations are required\nper user to get a non-trivial solution. We then improve our result for the\nrank-$1$ setting which in itself is quite challenging and encapsulates some of\nthe key issues. Here, we propose \\textsc{OCTAL} (Online Collaborative filTering\nusing iterAtive user cLustering) that guarantees nearly optimal regret of\n$O(\\mathsf{polylog} (\\mathsf{M}+\\mathsf{N}) \\mathsf{T}^{1/2})$. OCTAL is based\non a novel technique of clustering users that allows iterative elimination of\nitems and leads to a nearly optimal minimax rate.\n","authors":["Prateek Jain","Soumyabrata Pal"],"pdf_url":"https://arxiv.org/pdf/2209.03997v2.pdf","comment":"37 pages, 7 figures (Accepted at ICLR 2023)"},{"id":"http://arxiv.org/abs/2303.03755v1","updated":"2023-03-07T09:30:43Z","published":"2023-03-07T09:30:43Z","title":"DLT: Conditioned layout generation with Joint Discrete-Continuous\n  Diffusion Layout Transformer","summary":"  Generating visual layouts is an essential ingredient of graphic design. The\nability to condition layout generation on a partial subset of component\nattributes is critical to real-world applications that involve user\ninteraction. Recently, diffusion models have demonstrated high-quality\ngenerative performances in various domains. However, it is unclear how to apply\ndiffusion models to the natural representation of layouts which consists of a\nmix of discrete (class) and continuous (location, size) attributes. To address\nthe conditioning layout generation problem, we introduce DLT, a joint\ndiscrete-continuous diffusion model. DLT is a transformer-based model which has\na flexible conditioning mechanism that allows for conditioning on any given\nsubset of all the layout component classes, locations, and sizes. Our method\noutperforms state-of-the-art generative models on various layout generation\ndatasets with respect to different metrics and conditioning settings.\nAdditionally, we validate the effectiveness of our proposed conditioning\nmechanism and the joint continuous-diffusion process. This joint process can be\nincorporated into a wide range of mixed discrete-continuous generative tasks.\n","authors":["Elad Levi","Eli Brosh","Mykola Mykhailych","Meir Perez"],"pdf_url":"https://arxiv.org/pdf/2303.03755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03751v1","updated":"2023-03-07T09:20:43Z","published":"2023-03-07T09:20:43Z","title":"Zeroth-Order Optimization Meets Human Feedback: Provable Learning via\n  Ranking Oracles","summary":"  In this paper, we focus on a novel optimization problem in which the\nobjective function is a black-box and can only be evaluated through a ranking\noracle. This problem is common in real-world applications, particularly in\ncases where the function is assessed by human judges. Reinforcement Learning\nwith Human Feedback (RLHF) is a prominent example of such an application, which\nis adopted by the recent works\n\\cite{ouyang2022training,liu2023languages,chatgpt,bai2022training} to improve\nthe quality of Large Language Models (LLMs) with human guidance. We propose\nZO-RankSGD, a first-of-its-kind zeroth-order optimization algorithm, to solve\nthis optimization problem with a theoretical guarantee. Specifically, our\nalgorithm employs a new rank-based random estimator for the descent direction\nand is proven to converge to a stationary point. ZO-RankSGD can also be\ndirectly applied to the policy search problem in reinforcement learning when\nonly a ranking oracle of the episode reward is available. This makes ZO-RankSGD\na promising alternative to existing RLHF methods, as it optimizes in an online\nfashion and thus can work without any pre-collected data. Furthermore, we\ndemonstrate the effectiveness of ZO-RankSGD in a novel application: improving\nthe quality of images generated by a diffusion generative model with human\nranking feedback. Throughout experiments, we found that ZO-RankSGD can\nsignificantly enhance the detail of generated images with only a few rounds of\nhuman feedback. Overall, our work advances the field of zeroth-order\noptimization by addressing the problem of optimizing functions with only\nranking feedback, and offers an effective approach for aligning human and\nmachine intentions in a wide range of domains. Our code is released here\n\\url{https://github.com/TZW1998/Taming-Stable-Diffusion-with-Human-Ranking-Feedback}.\n","authors":["Zhiwei Tang","Dmitry Rybin","Tsung-Hui Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03748v1","updated":"2023-03-07T09:14:16Z","published":"2023-03-07T09:14:16Z","title":"Computing formation enthalpies through an explainable machine learning\n  method: the case of Lanthanide Orthophosphates solid solutions","summary":"  In the last decade, the use of Machine and Deep Learning (MDL) methods in\nCondensed Matter physics has seen a steep increase in the number of problems\ntackled and methods employed. A number of distinct MDL approaches have been\nemployed in many different topics; from prediction of materials properties to\ncomputation of Density Functional Theory potentials and inter-atomic force\nfields. In many cases the result is a surrogate model which returns promising\npredictions but is opaque on the inner mechanisms of its success. On the other\nhand, the typical practitioner looks for answers that are explainable and\nprovide a clear insight on the mechanisms governing a physical phenomena. In\nthis work, we describe a proposal to use a sophisticated combination of\ntraditional Machine Learning methods to obtain an explainable model that\noutputs an explicit functional formulation for the material property of\ninterest. We demonstrate the effectiveness of our methodology in deriving a new\nhighly accurate expression for the enthalpy of formation of solid solutions of\nlanthanides orthophosphates.\n","authors":["Edoardo Di Napoli","Xinzhe Wu","Thomas Bornhake","Piotr M. Kowalski"],"pdf_url":"https://arxiv.org/pdf/2303.03748v1.pdf","comment":"24 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.03747v1","updated":"2023-03-07T09:10:34Z","published":"2023-03-07T09:10:34Z","title":"Graph Decision Transformer","summary":"  Offline reinforcement learning (RL) is a challenging task, whose objective is\nto learn policies from static trajectory data without interacting with the\nenvironment. Recently, offline RL has been viewed as a sequence modeling\nproblem, where an agent generates a sequence of subsequent actions based on a\nset of static transition experiences. However, existing approaches that use\ntransformers to attend to all tokens naively can overlook the dependencies\nbetween different tokens and limit long-term dependency learning. In this\npaper, we propose the Graph Decision Transformer (GDT), a novel offline RL\napproach that models the input sequence into a causal graph to capture\npotential dependencies between fundamentally different concepts and facilitate\ntemporal and causal relationship learning. GDT uses a graph transformer to\nprocess the graph inputs with relation-enhanced mechanisms, and an optional\nsequence transformer to handle fine-grained spatial information in visual\ntasks. Our experiments show that GDT matches or surpasses the performance of\nstate-of-the-art offline RL methods on image-based Atari and OpenAI Gym.\n","authors":["Shengchao Hu","Li Shen","Ya Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.03747v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2303.03743v1","updated":"2023-03-07T09:07:42Z","published":"2023-03-07T09:07:42Z","title":"High-Precision Machine-Learning Based Indoor Localization with Massive\n  MIMO System","summary":"  High-precision cellular-based localization is one of the key technologies for\nnext-generation communication systems. In this paper, we investigate the\npotential of applying machine learning (ML) to a massive multiple-input\nmultiple-output (MIMO) system to enhance localization accuracy. We analyze a\nnew ML-based localization pipeline that has two parallel fully connected neural\nnetworks (FCNN). The first FCNN takes the instantaneous spatial covariance\nmatrix to capture angular information, while the second FCNN takes the channel\nimpulse responses to capture delay information. We fuse the estimated\ncoordinates of these two FCNNs for further accuracy improvement. To test the\nlocalization algorithm, we performed an indoor measurement campaign with a\nmassive MIMO testbed at 3.7GHz. In the measured scenario, the proposed pipeline\ncan achieve centimeter-level accuracy by combining delay and angular\ninformation.\n","authors":["Guoda Tian","Ilayda Yaman","Michiel Sandra","Xuesong Cai","Liang Liu","Fredrik Tufvesson"],"pdf_url":"https://arxiv.org/pdf/2303.03743v1.pdf","comment":"6 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.03737v1","updated":"2023-03-07T08:53:20Z","published":"2023-03-07T08:53:20Z","title":"Multi-Dimensional and Multi-Scale Modeling for Speech Separation\n  Optimized by Discriminative Learning","summary":"  Transformer has shown advanced performance in speech separation, benefiting\nfrom its ability to capture global features. However, capturing local features\nand channel information of audio sequences in speech separation is equally\nimportant. In this paper, we present a novel approach named Intra-SE-Conformer\nand Inter-Transformer (ISCIT) for speech separation. Specifically, we design a\nnew network SE-Conformer that can model audio sequences in multiple dimensions\nand scales, and apply it to the dual-path speech separation framework.\nFurthermore, we propose Multi-Block Feature Aggregation to improve the\nseparation effect by selectively utilizing information from the intermediate\nblocks of the separation network. Meanwhile, we propose a speaker similarity\ndiscriminative loss to optimize the speech separation model to address the\nproblem of poor performance when speakers have similar voices. Experimental\nresults on the benchmark datasets WSJ0-2mix and WHAM! show that ISCIT can\nachieve state-of-the-art results.\n","authors":["Zhaoxi Mu","Xinyu Yang","Wenjing Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.03737v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.03732v1","updated":"2023-03-07T08:44:58Z","published":"2023-03-07T08:44:58Z","title":"A Multi-Stage Triple-Path Method for Speech Separation in Noisy and\n  Reverberant Environments","summary":"  In noisy and reverberant environments, the performance of deep learning-based\nspeech separation methods drops dramatically because previous methods are not\ndesigned and optimized for such situations. To address this issue, we propose a\nmulti-stage end-to-end learning method that decouples the difficult speech\nseparation problem in noisy and reverberant environments into three\nsub-problems: speech denoising, separation, and de-reverberation. The\nprobability and speed of searching for the optimal solution of the speech\nseparation model are improved by reducing the solution space. Moreover, since\nthe channel information of the audio sequence in the time domain is crucial for\nspeech separation, we propose a triple-path structure capable of modeling the\nchannel dimension of audio sequences. Experimental results show that the\nproposed multi-stage triple-path method can improve the performance of speech\nseparation models at the cost of little model parameter increment.\n","authors":["Zhaoxi Mu","Xinyu Yang","Xiangyuan Yang","Wenjing Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.03732v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2211.04894v3","updated":"2023-03-07T08:25:24Z","published":"2022-11-09T13:55:50Z","title":"Exploring Video Quality Assessment on User Generated Contents from\n  Aesthetic and Technical Perspectives","summary":"  The rapid increase in user-generated-content (UGC) videos calls for the\ndevelopment of effective video quality assessment (VQA) algorithms. However,\nthe objective of the UGC-VQA problem is still ambiguous and can be viewed from\ntwo perspectives: the technical perspective, measuring the perception of\ndistortions; and the aesthetic perspective, which relates to preference and\nrecommendation on contents. To understand how these two perspectives affect\noverall subjective opinions in UGC-VQA, we conduct a large-scale subjective\nstudy to collect human quality opinions on overall quality of videos as well as\nperceptions from aesthetic and technical perspectives. The collected\nDisentangled Video Quality Database (DIVIDE-3k) confirms that human quality\nopinions on UGC videos are universally and inevitably affected by both\naesthetic and technical perspectives. In light of this, we propose the\nDisentangled Objective Video Quality Evaluator (DOVER) to learn the quality of\nUGC videos based on the two perspectives. The DOVER proves state-of-the-art\nperformance in UGC-VQA under very high efficiency. With perspective opinions in\nDIVIDE-3k, we further propose DOVER++, the first approach to provide reliable\nclear-cut quality evaluations from a single aesthetic or technical perspective.\nCode at https://github.com/VQAssessment/DOVER.\n","authors":["Haoning Wu","Erli Zhang","Liang Liao","Chaofeng Chen","Jingwen Hou","Annan Wang","Wenxiu Sun","Qiong Yan","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2211.04894v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16307v3","updated":"2023-03-07T08:18:26Z","published":"2022-10-24T06:19:43Z","title":"Investigation of chemical structure recognition by encoder-decoder\n  models in learning progress","summary":"  Descriptor generation methods using latent representations of\nencoder$-$decoder (ED) models with SMILES as input are useful because of the\ncontinuity of descriptor and restorability to the structure. However, it is not\nclear how the structure is recognized in the learning progress of ED models. In\nthis work, we created ED models of various learning progress and investigated\nthe relationship between structural information and learning progress. We\nshowed that compound substructures were learned early in ED models by\nmonitoring the accuracy of downstream tasks and input$-$output substructure\nsimilarity using substructure$-$based descriptors, which suggests that existing\nevaluation methods based on the accuracy of downstream tasks may not be\nsensitive enough to evaluate the performance of ED models with SMILES as\ndescriptor generation methods. On the other hand, we showed that structure\nrestoration was time$-$consuming, and in particular, insufficient learning led\nto the estimation of a larger structure than the actual one. It can be inferred\nthat determining the endpoint of the structure is a difficult task for the\nmodel. To our knowledge, this is the first study to link the learning progress\nof SMILES by ED model to chemical structures for a wide range of chemicals.\n","authors":["Shumpei Nemoto","Tadahaya Mizuno","Hiroyuki Kusuhara"],"pdf_url":"https://arxiv.org/pdf/2210.16307v3.pdf","comment":"17 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.03724v1","updated":"2023-03-07T08:16:46Z","published":"2023-03-07T08:16:46Z","title":"Learning Bipedal Walking for Humanoids with Current Feedback","summary":"  Recent advances in deep reinforcement learning (RL) based techniques combined\nwith training in simulation have offered a new approach to developing control\npolicies for legged robots. However, the application of such approaches to real\nhardware has largely been limited to quadrupedal robots with direct-drive\nactuators and light-weight bipedal robots with low gear-ratio transmission\nsystems. Application to life-sized humanoid robots has been elusive due to the\nlarge sim-to-real gap arising from their large size, heavier limbs, and a high\ngear-ratio transmission systems. In this paper, we present an approach for\neffectively overcoming the sim-to-real gap issue for humanoid robots arising\nfrom inaccurate torque tracking at the actuator level. Our key idea is to\nutilize the current feedback from the motors on the real robot, after training\nthe policy in a simulation environment artificially degraded with poor torque\ntracking. Our approach successfully trains an end-to-end policy in simulation\nthat can be deployed on a real HRP-5P humanoid robot for bipedal locomotion on\nchallenging terrain. We also perform robustness tests on the RL policy and\ncompare its performance against a conventional model-based controller for\nwalking on uneven terrain. YouTube video: https://youtu.be/IeUaSsBRbNY\n","authors":["Rohan Pratap Singh","Zhaoming Xie","Pierre Gergondet","Fumio Kanehiro"],"pdf_url":"https://arxiv.org/pdf/2303.03724v1.pdf","comment":"Submitted to the 2023 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2023). YouTube video:\n  https://youtu.be/IeUaSsBRbNY"},{"id":"http://arxiv.org/abs/2110.09140v2","updated":"2023-03-07T08:06:56Z","published":"2021-10-18T09:49:05Z","title":"Learning Prototype-oriented Set Representations for Meta-Learning","summary":"  Learning from set-structured data is a fundamental problem that has recently\nattracted increasing attention, where a series of summary networks are\nintroduced to deal with the set input. In fact, many meta-learning problems can\nbe treated as set-input tasks. Most existing summary networks aim to design\ndifferent architectures for the input set in order to enforce permutation\ninvariance. However, scant attention has been paid to the common cases where\ndifferent sets in a meta-distribution are closely related and share certain\nstatistical properties. Viewing each set as a distribution over a set of global\nprototypes, this paper provides a novel prototype-oriented optimal transport\n(POT) framework to improve existing summary networks. To learn the distribution\nover the global prototypes, we minimize its regularized optimal transport\ndistance to the set empirical distribution over data points, providing a\nnatural unsupervised way to improve the summary network. Since our\nplug-and-play framework can be applied to many meta-learning problems, we\nfurther instantiate it to the cases of few-shot classification and implicit\nmeta generative modeling. Extensive experiments demonstrate that our framework\nsignificantly improves the existing summary networks on learning more powerful\nsummary statistics from sets and can be successfully integrated into\nmetric-based few-shot classification and generative modeling applications,\nproviding a promising tool for addressing set-input and meta-learning problems.\n","authors":["Dandan Guo","Long Tian","Minghe Zhang","Mingyuan Zhou","Hongyuan Zha"],"pdf_url":"https://arxiv.org/pdf/2110.09140v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08405v3","updated":"2023-03-07T08:02:52Z","published":"2022-10-26T17:44:03Z","title":"Using multimodal learning and deep generative models for corporate\n  bankruptcy prediction","summary":"  This research introduces for the first time, to the best of our knowledge,\nthe concept of multimodal learning in bankruptcy prediction models. We use the\nConditional Multimodal Discriminative (CMMD) model to learn multimodal\nrepresentations that embed information from accounting, market, and textual\nmodalities. The CMMD model needs a sample with all data modalities for model\ntraining. At test time, the CMMD model only needs access to accounting and\nmarket modalities to generate multimodal representations, which are further\nused to make bankruptcy predictions. This fact makes the use of bankruptcy\nprediction models using textual data realistic and possible, since accounting\nand market data are available for all companies unlike textual data. The\nempirical results in this research show that the classification performance of\nour proposed methodology is superior compared to that of a large number of\ntraditional classifier models. We also show that our proposed methodology\nsolves the limitation of previous bankruptcy models using textual data, as they\ncan only make predictions for a small proportion of companies. Finally, based\non multimodal representations, we introduce an index that is able to capture\nthe uncertainty of the financial situation of companies during periods of\nfinancial distress.\n","authors":["Rogelio A. Mancisidor"],"pdf_url":"https://arxiv.org/pdf/2211.08405v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03714v1","updated":"2023-03-07T07:55:52Z","published":"2023-03-07T07:55:52Z","title":"Generative Modeling with Flow-Guided Density Ratio Learning","summary":"  We present Flow-Guided Density Ratio Learning (FDRL), a simple and scalable\napproach to generative modeling which builds on the stale (time-independent)\napproximation of the gradient flow of entropy-regularized f-divergences\nintroduced in DGflow. In DGflow, the intractable time-dependent density ratio\nis approximated by a stale estimator given by a GAN discriminator. This is\nsufficient in the case of sample refinement, where the source and target\ndistributions of the flow are close to each other. However, this assumption is\ninvalid for generation and a naive application of the stale estimator fails due\nto the large chasm between the two distributions. FDRL proposes to train a\ndensity ratio estimator such that it learns from progressively improving\nsamples during the training process. We show that this simple method alleviates\nthe density chasm problem, allowing FDRL to generate images of dimensions as\nhigh as $128\\times128$, as well as outperform existing gradient flow baselines\non quantitative benchmarks. We also show the flexibility of FDRL with two use\ncases. First, unconditional FDRL can be easily composed with external\nclassifiers to perform class-conditional generation. Second, FDRL can be\ndirectly applied to unpaired image-to-image translation with no modifications\nneeded to the framework. Code is publicly available at\nhttps://github.com/ajrheng/FDRL.\n","authors":["Alvin Heng","Abdul Fatir Ansari","Harold Soh"],"pdf_url":"https://arxiv.org/pdf/2303.03714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.11049v2","updated":"2023-03-07T07:44:11Z","published":"2022-03-21T15:14:44Z","title":"AutoTTS: End-to-End Text-to-Speech Synthesis through Differentiable\n  Duration Modeling","summary":"  Parallel text-to-speech (TTS) models have recently enabled fast and\nhighly-natural speech synthesis. However, they typically require external\nalignment models, which are not necessarily optimized for the decoder as they\nare not jointly trained. In this paper, we propose a differentiable duration\nmethod for learning monotonic alignments between input and output sequences.\nOur method is based on a soft-duration mechanism that optimizes a stochastic\nprocess in expectation. Using this differentiable duration method, we introduce\nAutoTTS, a direct text-to-waveform speech synthesis model. AutoTTS enables\nhigh-fidelity speech synthesis through a combination of adversarial training\nand matching the total ground-truth duration. Experimental results show that\nour model obtains competitive results while enjoying a much simpler training\npipeline. Audio samples are available online.\n","authors":["Bac Nguyen","Fabien Cardinaux","Stefan Uhlich"],"pdf_url":"https://arxiv.org/pdf/2203.11049v2.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.03707v1","updated":"2023-03-07T07:42:37Z","published":"2023-03-07T07:42:37Z","title":"Hybrid quantum-classical convolutional neural network for phytoplankton\n  classification","summary":"  The taxonomic composition and abundance of phytoplankton, having direct\nimpact on marine ecosystem dynamic and global environment change, are listed as\nessential ocean variables. Phytoplankton classification is very crucial for\nPhytoplankton analysis, but it is very difficult because of the huge amount and\ntiny volume of Phytoplankton. Machine learning is the principle way of\nperforming phytoplankton image classification automatically. When carrying out\nlarge-scale research on the marine phytoplankton, the volume of data increases\noverwhelmingly and more powerful computational resources are required for the\nsuccess of machine learning algorithms. Recently, quantum machine learning has\nemerged as the potential solution for large-scale data processing by harnessing\nthe exponentially computational power of quantum computer. Here, for the first\ntime, we demonstrate the feasibility of quantum deep neural networks for\nphytoplankton classification. Hybrid quantum-classical convolutional and\nresidual neural networks are developed based on the classical architectures.\nThese models make a proper balance between the limited function of the current\nquantum devices and the large size of phytoplankton images, which make it\npossible to perform phytoplankton classification on the near-term quantum\ncomputers. Better performance is obtained by the quantum-enhanced models\nagainst the classical counterparts. In particular, quantum models converge much\nfaster than classical ones. The present quantum models are versatile, and can\nbe applied for various tasks of image classification in the field of marine\nscience.\n","authors":["Shangshang Shi","Zhimin Wang","Ruimin Shang","Yanan Li","Jiaxin Li","Guoqiang Zhong","Yongjian Gu"],"pdf_url":"https://arxiv.org/pdf/2303.03707v1.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2303.03706v1","updated":"2023-03-07T07:42:26Z","published":"2023-03-07T07:42:26Z","title":"Classifying Text-Based Conspiracy Tweets related to COVID-19 using\n  Contextualized Word Embeddings","summary":"  The FakeNews task in MediaEval 2022 investigates the challenge of finding\naccurate and high-performance models for the classification of conspiracy\ntweets related to COVID-19. In this paper, we used BERT, ELMO, and their\ncombination for feature extraction and RandomForest as classifier. The results\nshow that ELMO performs slightly better than BERT, however their combination at\nfeature level reduces the performance.\n","authors":["Abdul Rehman","Rabeeh Ayaz Abbasi","Irfan ul Haq Qureshi","Akmal Saeed Khattak"],"pdf_url":"https://arxiv.org/pdf/2303.03706v1.pdf","comment":"Published in Multimedia Benchmark Workshop 2022, Bergen, Norway and\n  Online, 12-13 January 2023: https://2022.multimediaeval.com/"},{"id":"http://arxiv.org/abs/2303.03701v1","updated":"2023-03-07T07:32:10Z","published":"2023-03-07T07:32:10Z","title":"Variational Inference for Neyman-Scott Processes","summary":"  Neyman-Scott processes (NSPs) have been applied across a range of fields to\nmodel points or temporal events with a hierarchy of clusters. Markov chain\nMonte Carlo (MCMC) is typically used for posterior sampling in the model.\nHowever, MCMC's mixing time can cause the resulting inference to be slow, and\nthereby slow down model learning and prediction. We develop the first\nvariational inference (VI) algorithm for NSPs, and give two examples of\nsuitable variational posterior point process distributions. Our method\nminimizes the inclusive Kullback-Leibler (KL) divergence for VI to obtain the\nvariational parameters. We generate samples from the approximate posterior\npoint processes much faster than MCMC, as we can directly estimate the\napproximate posterior point processes without any MCMC steps or gradient\ndescent. We include synthetic and real-world data experiments that demonstrate\nour VI algorithm achieves better prediction performance than MCMC when\ncomputational time is limited.\n","authors":["Chengkuan Hong","Christian R. Shelton"],"pdf_url":"https://arxiv.org/pdf/2303.03701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00930v2","updated":"2023-03-07T07:28:09Z","published":"2023-01-03T02:19:20Z","title":"Data Valuation Without Training of a Model","summary":"  Many recent works on understanding deep learning try to quantify how much\nindividual data instances influence the optimization and generalization of a\nmodel. Such attempts reveal characteristics and importance of individual\ninstances, which may provide useful information in diagnosing and improving\ndeep learning. However, most of the existing works on data valuation require\nactual training of a model, which often demands high-computational cost. In\nthis paper, we provide a training-free data valuation score, called\ncomplexity-gap score, which is a data-centric score to quantify the influence\nof individual instances in generalization of two-layer overparameterized neural\nnetworks. The proposed score can quantify irregularity of the instances and\nmeasure how much each data instance contributes in the total movement of the\nnetwork parameters during training. We theoretically analyze and empirically\ndemonstrate the effectiveness of the complexity-gap score in finding `irregular\nor mislabeled' data instances, and also provide applications of the score in\nanalyzing datasets and diagnosing training dynamics. Our code is publicly\navailable at https://github.com/JJchy/CG_score\n","authors":["Nohyun Ki","Hoyong Choi","Hye Won Chung"],"pdf_url":"https://arxiv.org/pdf/2301.00930v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03697v1","updated":"2023-03-07T07:26:09Z","published":"2023-03-07T07:26:09Z","title":"Stylometric Detection of AI-Generated Text in Twitter Timelines","summary":"  Recent advancements in pre-trained language models have enabled convenient\nmethods for generating human-like text at a large scale. Though these\ngeneration capabilities hold great potential for breakthrough applications, it\ncan also be a tool for an adversary to generate misinformation. In particular,\nsocial media platforms like Twitter are highly susceptible to AI-generated\nmisinformation. A potential threat scenario is when an adversary hijacks a\ncredible user account and incorporates a natural language generator to generate\nmisinformation. Such threats necessitate automated detectors for AI-generated\ntweets in a given user's Twitter timeline. However, tweets are inherently\nshort, thus making it difficult for current state-of-the-art pre-trained\nlanguage model-based detectors to accurately detect at what point the AI starts\nto generate tweets in a given Twitter timeline. In this paper, we present a\nnovel algorithm using stylometric signals to aid detecting AI-generated tweets.\nWe propose models corresponding to quantifying stylistic changes in human and\nAI tweets in two related tasks: Task 1 - discriminate between human and\nAI-generated tweets, and Task 2 - detect if and when an AI starts to generate\ntweets in a given Twitter timeline. Our extensive experiments demonstrate that\nthe stylometric features are effective in augmenting the state-of-the-art\nAI-generated text detectors.\n","authors":["Tharindu Kumarage","Joshua Garland","Amrita Bhattacharjee","Kirill Trapeznikov","Scott Ruston","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09865v2","updated":"2023-03-07T07:23:38Z","published":"2023-02-20T09:56:51Z","title":"Can discrete information extraction prompts generalize across language\n  models?","summary":"  We study whether automatically-induced prompts that effectively extract\ninformation from a language model can also be used, out-of-the-box, to probe\nother language models for the same information. After confirming that discrete\nprompts induced with the AutoPrompt algorithm outperform manual and semi-manual\nprompts on the slot-filling task, we demonstrate a drop in performance for\nAutoPrompt prompts learned on a model and tested on another. We introduce a way\nto induce prompts by mixing language models at training time that results in\nprompts that generalize well across models. We conduct an extensive analysis of\nthe induced prompts, finding that the more general prompts include a larger\nproportion of existing English words and have a less order-dependent and more\nuniform distribution of information across their component tokens. Our work\nprovides preliminary evidence that it's possible to generate discrete prompts\nthat can be induced once and used with a number of different models, and gives\ninsights on the properties characterizing such prompts.\n","authors":["Nathanaël Carraz Rakotonirina","Roberto Dessì","Fabio Petroni","Sebastian Riedel","Marco Baroni"],"pdf_url":"https://arxiv.org/pdf/2302.09865v2.pdf","comment":"Published as conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2212.01689v2","updated":"2023-03-07T07:04:32Z","published":"2022-12-03T20:56:29Z","title":"Learning-Assisted Algorithm Unrolling for Online Optimization with\n  Budget Constraints","summary":"  Online optimization with multiple budget constraints is challenging since the\nonline decisions over a short time horizon are coupled together by strict\ninventory constraints. The existing manually-designed algorithms cannot achieve\nsatisfactory average performance for this setting because they often need a\nlarge number of time steps for convergence and/or may violate the inventory\nconstraints. In this paper, we propose a new machine learning (ML) assisted\nunrolling approach, called LAAU (Learning-Assisted Algorithm Unrolling), which\nunrolls the online decision pipeline and leverages an ML model for updating the\nLagrangian multiplier online. For efficient training via backpropagation, we\nderive gradients of the decision pipeline over time. We also provide the\naverage cost bounds for two cases when training data is available offline and\ncollected online, respectively. Finally, we present numerical results to\nhighlight that LAAU can outperform the existing baselines.\n","authors":["Jianyi Yang","Shaolei Ren"],"pdf_url":"https://arxiv.org/pdf/2212.01689v2.pdf","comment":"Accepted by AAAI'23"},{"id":"http://arxiv.org/abs/2302.10166v3","updated":"2023-03-07T06:47:30Z","published":"2023-02-20T18:53:56Z","title":"Learning Deep Semantics for Test Completion","summary":"  Writing tests is a time-consuming yet essential task during software\ndevelopment. We propose to leverage recent advances in deep learning for text\nand code generation to assist developers in writing tests. We formalize the\nnovel task of test completion to automatically complete the next statement in a\ntest method based on the context of prior statements and the code under test.\nWe develop TeCo -- a deep learning model using code semantics for test\ncompletion. The key insight underlying TeCo is that predicting the next\nstatement in a test method requires reasoning about code execution, which is\nhard to do with only syntax-level data that existing code completion models\nuse. TeCo extracts and uses six kinds of code semantics data, including the\nexecution result of prior statements and the execution context of the test\nmethod. To provide a testbed for this new task, as well as to evaluate TeCo, we\ncollect a corpus of 130,934 test methods from 1,270 open-source Java projects.\nOur results show that TeCo achieves an exact-match accuracy of 18, which is 29%\nhigher than the best baseline using syntax-level data only. When measuring\nfunctional correctness of generated next statement, TeCo can generate runnable\ncode in 29% of the cases compared to 18% obtained by the best baseline.\nMoreover, TeCo is significantly better than prior work on test oracle\ngeneration.\n","authors":["Pengyu Nie","Rahul Banerjee","Junyi Jessy Li","Raymond J. Mooney","Milos Gligoric"],"pdf_url":"https://arxiv.org/pdf/2302.10166v3.pdf","comment":"Accepted as a conference paper in ICSE 2023"},{"id":"http://arxiv.org/abs/2303.03679v1","updated":"2023-03-07T06:38:48Z","published":"2023-03-07T06:38:48Z","title":"MAST: Masked Augmentation Subspace Training for Generalizable\n  Self-Supervised Priors","summary":"  Recent Self-Supervised Learning (SSL) methods are able to learn feature\nrepresentations that are invariant to different data augmentations, which can\nthen be transferred to downstream tasks of interest. However, different\ndownstream tasks require different invariances for their best performance, so\nthe optimal choice of augmentations for SSL depends on the target task. In this\npaper, we aim to learn self-supervised features that generalize well across a\nvariety of downstream tasks (e.g., object classification, detection and\ninstance segmentation) without knowing any task information beforehand. We do\nso by Masked Augmentation Subspace Training (or MAST) to encode in the single\nfeature space the priors from different data augmentations in a factorized way.\nSpecifically, we disentangle the feature space into separate subspaces, each\ninduced by a learnable mask that selects relevant feature dimensions to model\ninvariance to a specific augmentation. We show the success of MAST in jointly\ncapturing generalizable priors from different augmentations, using both unique\nand shared features across the subspaces. We further show that MAST benefits\nfrom uncertainty modeling to reweight ambiguous samples from strong\naugmentations that may cause similarity mismatch in each subspace. Experiments\ndemonstrate that MAST consistently improves generalization on various\ndownstream tasks, while being task-agnostic and efficient during SSL. We also\nprovide interesting insights about how different augmentations are related and\nhow uncertainty reflects learning difficulty.\n","authors":["Chen Huang","Hanlin Goh","Jiatao Gu","Josh Susskind"],"pdf_url":"https://arxiv.org/pdf/2303.03679v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03678v1","updated":"2023-03-07T06:34:04Z","published":"2023-03-07T06:34:04Z","title":"A Comparative Study of Deep Learning and Iterative Algorithms for Joint\n  Channel Estimation and Signal Detection","summary":"  Joint channel estimation and signal detection (JCESD) is crucial in wireless\ncommunication systems, but traditional algorithms perform poorly in low\nsignal-to-noise ratio (SNR) scenarios. Deep learning (DL) methods have been\ninvestigated, but concerns regarding computational expense and lack of\nvalidation in low-SNR settings remain. Hence, the development of a robust and\nlow-complexity model that can deliver excellent performance across a wide range\nof SNRs is highly desirable. In this paper, we aim to establish a benchmark\nwhere traditional algorithms and DL methods are validated on different channel\nmodels, Doppler, and SNR settings. In particular, we propose a new DL model\nwhere the backbone network is formed by unrolling the iterative algorithm, and\nthe hyperparameters are estimated by hypernetworks. Additionally, we adapt a\nlightweight DenseNet to the task of JCESD for comparison. We evaluate different\nmethods in three aspects: generalization in terms of bit error rate (BER),\nrobustness, and complexity. Our results indicate that DL approaches outperform\ntraditional algorithms in the challenging low-SNR setting, while the iterative\nalgorithm performs better in highSNR settings. Furthermore, the iterative\nalgorithm is more robust in the presence of carrier frequency offset, whereas\nDL methods excel when signals are corrupted by asymmetric Gaussian noise.\n","authors":["Haocheng Ju","Haimiao Zhang","Lin Li","Xiao Li","Bin Dong"],"pdf_url":"https://arxiv.org/pdf/2303.03678v1.pdf","comment":"25 pages, this work has been submitted to the IEEE for possible\n  publication. Code is available at https://github.com/j991222/MIMO_JCESD"},{"id":"http://arxiv.org/abs/2303.03677v1","updated":"2023-03-07T06:33:40Z","published":"2023-03-07T06:33:40Z","title":"Training Machine Learning Models to Characterize Temporal Evolution of\n  Disadvantaged Communities","summary":"  Disadvantaged communities (DAC), as defined by the Justice40 initiative of\nthe Department of Energy (DOE), USA, identifies census tracts across the USA to\ndetermine where benefits of climate and energy investments are or are not\ncurrently accruing. The DAC status not only helps in determining the\neligibility for future Justice40-related investments but is also critical for\nexploring ways to achieve equitable distribution of resources. However,\ndesigning inclusive and equitable strategies not just requires a good\nunderstanding of current demographics, but also a deeper analysis of the\ntransformations that happened in those demographics over the years. In this\npaper, machine learning (ML) models are trained on publicly available census\ndata from recent years to classify the DAC status at the census tracts level\nand then the trained model is used to classify DAC status for historical years.\nA detailed analysis of the feature and model selection along with the evolution\nof disadvantaged communities between 2013 and 2018 is presented in this study.\n","authors":["Milan Jain","Narmadha Meenu Mohankumar","Heng Wan","Sumitrra Ganguly","Kyle D Wilson","David M Anderson"],"pdf_url":"https://arxiv.org/pdf/2303.03677v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03666v1","updated":"2023-03-07T06:04:58Z","published":"2023-03-07T06:04:58Z","title":"Face: Fast, Accurate and Context-Aware Audio Annotation and\n  Classification","summary":"  This paper presents a context-aware framework for feature selection and\nclassification procedures to realize a fast and accurate audio event annotation\nand classification. The context-aware design starts with exploring feature\nextraction techniques to find an appropriate combination to select a set\nresulting in remarkable classification accuracy with minimal computational\neffort. The exploration for feature selection also embraces an investigation of\naudio Tempo representation, an advantageous feature extraction method missed by\nprevious works in the environmental audio classification research scope. The\nproposed annotation method considers outlier, inlier, and hard-to-predict data\nsamples to realize context-aware Active Learning, leading to the average\naccuracy of 90% when only 15% of data possess initial annotation. Our proposed\nalgorithm for sound classification obtained average prediction accuracy of\n98.05% on the UrbanSound8K dataset. The notebooks containing our source codes\nand implementation results are available at https://github.com/gitmehrdad/FACE.\n","authors":["M. Mehrdad Morsali","Hoda Mohammadzade","Saeed Bagheri Shouraki"],"pdf_url":"https://arxiv.org/pdf/2303.03666v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2211.05385v2","updated":"2023-03-07T05:54:27Z","published":"2022-11-10T07:24:09Z","title":"GANStrument: Adversarial Instrument Sound Synthesis with Pitch-invariant\n  Instance Conditioning","summary":"  We propose GANStrument, a generative adversarial model for instrument sound\nsynthesis. Given a one-shot sound as input, it is able to generate pitched\ninstrument sounds that reflect the timbre of the input within an interactive\ntime. By exploiting instance conditioning, GANStrument achieves better fidelity\nand diversity of synthesized sounds and generalization ability to various\ninputs. In addition, we introduce an adversarial training scheme for a\npitch-invariant feature extractor that significantly improves the pitch\naccuracy and timbre consistency. Experimental results show that GANStrument\noutperforms strong baselines that do not use instance conditioning in terms of\ngeneration quality and input editability. Qualitative examples are available\nonline.\n","authors":["Gaku Narita","Junichi Shimizu","Taketo Akama"],"pdf_url":"https://arxiv.org/pdf/2211.05385v2.pdf","comment":"5 pages, 4 figures, Accepted to 2023 IEEE International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP), Audio examples:\n  https://ganstrument.github.io/ganstrument-demo/"},{"id":"http://arxiv.org/abs/2303.03660v1","updated":"2023-03-07T05:48:28Z","published":"2023-03-07T05:48:28Z","title":"ECG Classification System for Arrhythmia Detection Using Convolutional\n  Neural Networks","summary":"  Arrhythmia is just one of the many cardiovascular illnesses that have been\nextensively studied throughout the years. Using a multi-lead ECG data, this\nresearch describes a deep learning (DL) technique based on a convolutional\nneural network (CNN) algorithm to detect cardiovascular arrhythmia in patients.\nThe suggested CNN model has six layers total, two convolution layers, two\npooling layers, and two fully linked layers within a residual block, in\naddition to the input and output layers. In this study, the classification of\nthe ECG signals into five groups, Left Bundle Branch Block (LBBB), Right Bundle\nBranch Block (RBBB), Atrial Premature Contraction (APC), Premature Ventricular\nContraction (PVC), and Normal Beat is the main goal (N). Using the MIT-BIH\narrhythmia dataset, we assessed the suggested technique. The findings show that\nour suggested strategy classified 15000 cases with an average accuracy of\n98.2%.\n","authors":["Aryan Odugoudar","Jaskaran Singh Walia"],"pdf_url":"https://arxiv.org/pdf/2303.03660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10243v2","updated":"2023-03-07T05:46:46Z","published":"2022-10-19T01:45:29Z","title":"CLUTR: Curriculum Learning via Unsupervised Task Representation Learning","summary":"  Reinforcement Learning (RL) algorithms are often known for sample\ninefficiency and difficult generalization. Recently, Unsupervised Environment\nDesign (UED) emerged as a new paradigm for zero-shot generalization by\nsimultaneously learning a task distribution and agent policies on the generated\ntasks. This is a non-stationary process where the task distribution evolves\nalong with agent policies; creating an instability over time. While past works\ndemonstrated the potential of such approaches, sampling effectively from the\ntask space remains an open challenge, bottlenecking these approaches. To this\nend, we introduce CLUTR: a novel unsupervised curriculum learning algorithm\nthat decouples task representation and curriculum learning into a two-stage\noptimization. It first trains a recurrent variational autoencoder on randomly\ngenerated tasks to learn a latent task manifold. Next, a teacher agent creates\na curriculum by maximizing a minimax REGRET-based objective on a set of latent\ntasks sampled from this manifold. Using the fixed-pretrained task manifold, we\nshow that CLUTR successfully overcomes the non-stationarity problem and\nimproves stability. Our experimental results show CLUTR outperforms PAIRED, a\nprincipled and popular UED method, in the challenging CarRacing and navigation\nenvironments: achieving 10.6X and 45\\% improvement in zero-shot generalization,\nrespectively. CLUTR also performs comparably to the non-UED state-of-the-art\nfor CarRacing, while requiring 500X fewer environment interactions.\n","authors":["Abdus Salam Azad","Izzeddin Gur","Jasper Emhoff","Nathaniel Alexis","Aleksandra Faust","Pieter Abbeel","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2210.10243v2.pdf","comment":"Preprint, Currently Under Review"},{"id":"http://arxiv.org/abs/2110.05887v3","updated":"2023-03-07T05:32:23Z","published":"2021-10-12T10:56:54Z","title":"Discovery of Single Independent Latent Variable","summary":"  Latent variable discovery is a central problem in data analysis with a broad\nrange of applications in applied science. In this work, we consider data given\nas an invertible mixture of two statistically independent components and assume\nthat one of the components is observed while the other is hidden. Our goal is\nto recover the hidden component. For this purpose, we propose an autoencoder\nequipped with a discriminator. Unlike the standard nonlinear ICA problem, which\nwas shown to be non-identifiable, in the special case of ICA we consider here,\nwe show that our approach can recover the component of interest up to\nentropy-preserving transformation. We demonstrate the performance of the\nproposed approach in several tasks, including image synthesis, voice cloning,\nand fetal ECG extraction.\n","authors":["Uri Shaham","Jonathan Svirsky","Ori Katz","Ronen Talmon"],"pdf_url":"https://arxiv.org/pdf/2110.05887v3.pdf","comment":"Published as a conference paper at Neurips 2022. In the current\n  version the proof of the lemma is modified"},{"id":"http://arxiv.org/abs/2303.03654v1","updated":"2023-03-07T05:21:15Z","published":"2023-03-07T05:21:15Z","title":"MPool: Motif-Based Graph Pooling","summary":"  Graph Neural networks (GNNs) have recently become a powerful technique for\nmany graph-related tasks including graph classification. Current GNN models\napply different graph pooling methods that reduce the number of nodes and edges\nto learn the higher-order structure of the graph in a hierarchical way. All\nthese methods primarily rely on the one-hop neighborhood. However, they do not\nconsider the higher- order structure of the graph. In this work, we propose a\nmulti-channel Motif-based Graph Pooling method named (MPool) captures the\nhigher-order graph structure with motif and local and global graph structure\nwith a combination of selection and clustering-based pooling operations. As the\nfirst channel, we develop node selection-based graph pooling by designing a\nnode ranking model considering the motif adjacency of nodes. As the second\nchannel, we develop cluster-based graph pooling by designing a spectral\nclustering model using motif adjacency. As the final layer, the result of each\nchannel is aggregated into the final graph representation. We perform extensive\nexperiments on eight benchmark datasets and show that our proposed method shows\nbetter accuracy than the baseline methods for graph classification tasks.\n","authors":["Muhammad Ifte Khairul Islam","Max Khanov","Esra Akbas"],"pdf_url":"https://arxiv.org/pdf/2303.03654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.11280v3","updated":"2023-03-07T05:01:02Z","published":"2022-04-24T13:54:42Z","title":"Deconstructed Generation-Based Zero-Shot Model","summary":"  Recent research on Generalized Zero-Shot Learning (GZSL) has focused\nprimarily on generation-based methods. However, current literature has\noverlooked the fundamental principles of these methods and has made limited\nprogress in a complex manner. In this paper, we aim to deconstruct the\ngenerator-classifier framework and provide guidance for its improvement and\nextension. We begin by breaking down the generator-learned unseen class\ndistribution into class-level and instance-level distributions. Through our\nanalysis of the role of these two types of distributions in solving the GZSL\nproblem, we generalize the focus of the generation-based approach, emphasizing\nthe importance of (i) attribute generalization in generator learning and (ii)\nindependent classifier learning with partially biased data. We present a simple\nmethod based on this analysis that outperforms SotAs on four public GZSL\ndatasets, demonstrating the validity of our deconstruction. Furthermore, our\nproposed method remains effective even without a generative model, representing\na step towards simplifying the generator-classifier structure. Our code is\navailable at \\url{https://github.com/cdb342/DGZ}.\n","authors":["Dubing Chen","Yuming Shen","Haofeng Zhang","Philip H. S. Torr"],"pdf_url":"https://arxiv.org/pdf/2204.11280v3.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2205.03699v2","updated":"2023-03-07T04:59:51Z","published":"2022-05-07T18:28:20Z","title":"Rate-Optimal Contextual Online Matching Bandit","summary":"  Two-sided online matching platforms have been employed in various markets.\nHowever, agents' preferences in present market are usually implicit and unknown\nand must be learned from data. With the growing availability of side\ninformation involved in the decision process, modern online matching\nmethodology demands the capability to track preference dynamics for agents\nbased on their contextual information. This motivates us to consider a novel\nContextual Online Matching Bandit prOblem (COMBO), which allows dynamic\npreferences in matching decisions. Existing works focus on multi-armed bandit\nwith static preference, but this is insufficient: the two-sided preference\nchanges as along as one-side's contextual information updates, resulting in\nnon-static matching. In this paper, we propose a Centralized Contextual -\nExplore Then Commit (CC-ETC) algorithm to adapt to the COMBO. CC-ETC solves\nonline matching with dynamic preference. In theory, we show that CC-ETC\nachieves a sublinear regret upper bound O(log(T)) and is a rate-optimal\nalgorithm by proving a matching lower bound. In the experiments, we demonstrate\nthat CC-ETC is robust to variant preference schemes, dimensions of contexts,\nreward noise levels, and contexts variation levels.\n","authors":["Yuantong Li","Chi-hua Wang","Guang Cheng","Will Wei Sun"],"pdf_url":"https://arxiv.org/pdf/2205.03699v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03648v1","updated":"2023-03-07T04:36:35Z","published":"2023-03-07T04:36:35Z","title":"Can Membership Inferencing be Refuted?","summary":"  Membership inference (MI) attack is currently the most popular test for\nmeasuring privacy leakage in machine learning models. Given a machine learning\nmodel, a data point and some auxiliary information, the goal of an MI~attack is\nto determine whether the data point was used to train the model. In this work,\nwe study the reliability of membership inference attacks in practice.\nSpecifically, we show that a model owner can plausibly refute the result of a\nmembership inference test on a data point $x$ by constructing a \\textit{proof\nof repudiation} that proves that the model was trained \\textit{without} $x$. We\ndesign efficient algorithms to construct proofs of repudiation for all data\npoints of the training dataset. Our empirical evaluation demonstrates the\npractical feasibility of our algorithm by constructing proofs of repudiation\nfor popular machine learning models on MNIST and CIFAR-10. Consequently, our\nresults call for a re-evaluation of the implications of membership inference\nattacks in practice.\n","authors":["Zhifeng Kong","Amrita Roy Chowdhury","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2303.03648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14051v2","updated":"2023-03-07T04:06:45Z","published":"2022-10-25T14:30:48Z","title":"Bridging Distributional and Risk-sensitive Reinforcement Learning with\n  Provable Regret Bounds","summary":"  We study the regret guarantee for risk-sensitive reinforcement learning\n(RSRL) via distributional reinforcement learning (DRL) methods. In particular,\nwe consider finite episodic Markov decision processes whose objective is the\nentropic risk measure (EntRM) of return. We identify a key property of the\nEntRM, the monotonicity-preserving property, which enables the risk-sensitive\ndistributional dynamic programming framework. We then propose two novel DRL\nalgorithms that implement optimism through two different schemes, including a\nmodel-free one and a model-based one.\n  We prove that both of them attain $\\tilde{\\mathcal{O}}(\\frac{\\exp(|\\beta|\nH)-1}{|\\beta|H}H\\sqrt{HS^2AT})$ regret upper bound, where $S$ is the number of\nstates, $A$ the number of states, $H$ the time horizon and $T$ the number of\ntotal time steps. It matches RSVI2 proposed in \\cite{fei2021exponential} with a\nmuch simpler regret analysis. To the best of our knowledge, this is the first\nregret analysis of DRL, which bridges DRL and RSRL in terms of sample\ncomplexity. Finally, we improve the existing lower bound by proving a tighter\nbound of $\\Omega(\\frac{\\exp(\\beta H/6)-1}{\\beta H}H\\sqrt{SAT})$ for $\\beta>0$\ncase, which recovers the tight lower bound $\\Omega(H\\sqrt{SAT})$ in the\nrisk-neutral setting.\n","authors":["Hao Liang","Zhi-Quan Luo"],"pdf_url":"https://arxiv.org/pdf/2210.14051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03640v1","updated":"2023-03-07T04:04:23Z","published":"2023-03-07T04:04:23Z","title":"AHPA: Adaptive Horizontal Pod Autoscaling Systems on Alibaba Cloud\n  Container Service for Kubernetes","summary":"  The existing resource allocation policy for application instances in\nKubernetes cannot dynamically adjust according to the requirement of business,\nwhich would cause an enormous waste of resources during fluctuations. Moreover,\nthe emergence of new cloud services puts higher resource management\nrequirements. This paper discusses horizontal POD resources management in\nAlibaba Cloud Container Services with a newly deployed AI algorithm framework\nnamed AHPA -- the adaptive horizontal pod auto-scaling system. Based on a\nrobust decomposition forecasting algorithm and performance training model, AHPA\noffers an optimal pod number adjustment plan that could reduce POD resources\nand maintain business stability. Since being deployed in April 2021, this\nsystem has expanded to multiple customer scenarios, including logistics, social\nnetworks, AI audio and video, e-commerce, etc. Compared with the previous\nalgorithms, AHPA solves the elastic lag problem, increasing CPU usage by 10%\nand reducing resource cost by more than 20%. In addition, AHPA can\nautomatically perform flexible planning according to the predicted business\nvolume without manual intervention, significantly saving operation and\nmaintenance costs.\n","authors":["Zhiqiang Zhou","Chaoli Zhang","Lingna Ma","Jing Gu","Huajie Qian","Qingsong Wen","Liang Sun","Peng Li","Zhimin Tang"],"pdf_url":"https://arxiv.org/pdf/2303.03640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03634v1","updated":"2023-03-07T03:46:53Z","published":"2023-03-07T03:46:53Z","title":"PreFallKD: Pre-Impact Fall Detection via CNN-ViT Knowledge Distillation","summary":"  Fall accidents are critical issues in an aging and aged society. Recently,\nmany researchers developed pre-impact fall detection systems using deep\nlearning to support wearable-based fall protection systems for preventing\nsevere injuries. However, most works only employed simple neural network models\ninstead of complex models considering the usability in resource-constrained\nmobile devices and strict latency requirements. In this work, we propose a\nnovel pre-impact fall detection via CNN-ViT knowledge distillation, namely\nPreFallKD, to strike a balance between detection performance and computational\ncomplexity. The proposed PreFallKD transfers the detection knowledge from the\npre-trained teacher model (vision transformer) to the student model\n(lightweight convolutional neural networks). Additionally, we apply data\naugmentation techniques to tackle issues of data imbalance. We conduct the\nexperiment on the KFall public dataset and compare PreFallKD with other\nstate-of-the-art models. The experiment results show that PreFallKD could boost\nthe student model during the testing phase and achieves reliable F1-score\n(92.66%) and lead time (551.3 ms).\n","authors":["Tin-Han Chi","Kai-Chun Liu","Chia-Yeh Hsieh"," Yu-Tsao","Chia-Tai Chan"],"pdf_url":"https://arxiv.org/pdf/2303.03634v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00102v2","updated":"2023-03-07T03:38:56Z","published":"2022-09-30T21:33:51Z","title":"MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP\n  Initialization","summary":"  Training graph neural networks (GNNs) on large graphs is complex and\nextremely time consuming. This is attributed to overheads caused by sparse\nmatrix multiplication, which are sidestepped when training multi-layer\nperceptrons (MLPs) with only node features. MLPs, by ignoring graph context,\nare simple and faster for graph data, however they usually sacrifice prediction\naccuracy, limiting their applications for graph data. We observe that for most\nmessage passing-based GNNs, we can trivially derive an analog MLP (we call this\na PeerMLP) with an equivalent weight space, by setting the trainable parameters\nwith the same shapes, making us curious about \\textbf{\\emph{how do GNNs using\nweights from a fully trained PeerMLP perform?}} Surprisingly, we find that GNNs\ninitialized with such weights significantly outperform their PeerMLPs,\nmotivating us to use PeerMLP training as a precursor, initialization step to\nGNN training. To this end, we propose an embarrassingly simple, yet hugely\neffective initialization method for GNN training acceleration, called MLPInit.\nOur extensive experiments on multiple large-scale graph datasets with diverse\nGNN architectures validate that MLPInit can accelerate the training of GNNs (up\nto 33X speedup on OGB-Products) and often improve prediction performance (e.g.,\nup to $7.97\\%$ improvement for GraphSAGE across $7$ datasets for node\nclassification, and up to $17.81\\%$ improvement across $4$ datasets for link\nprediction on metric Hits@10). The code is available at\n\\href{https://github.com/snap-research/MLPInit-for-GNNs}.\n","authors":["Xiaotian Han","Tong Zhao","Yozen Liu","Xia Hu","Neil Shah"],"pdf_url":"https://arxiv.org/pdf/2210.00102v2.pdf","comment":"Accepted by ICLR2023"},{"id":"http://arxiv.org/abs/2303.03628v1","updated":"2023-03-07T03:23:14Z","published":"2023-03-07T03:23:14Z","title":"CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation\n  Verification","summary":"  Chain-of-thought (CoT) prompting enables large language models (LLMs) to\nsolve complex reasoning tasks by generating an explanation before the final\nprediction. Despite it's promising ability, a critical downside of CoT\nprompting is that the performance is greatly affected by the factuality of the\ngenerated explanation. To improve the correctness of the explanations,\nfine-tuning language models with explanation data is needed. However, there\nexists only a few datasets that can be used for such approaches, and no data\ncollection tool for building them. Thus, we introduce CoTEVer, a tool-kit for\nannotating the factual correctness of generated explanations and collecting\nrevision data of wrong explanations. Furthermore, we suggest several use cases\nwhere the data collected with CoTEVer can be utilized for enhancing the\nfaithfulness of explanations. Our toolkit is publicly available at\nhttps://github.com/SeungoneKim/CoTEVer.\n","authors":["Seungone Kim","Se June Joo","Yul Jang","Hyungjoo Chae","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2303.03628v1.pdf","comment":"Accepted at EACL 2023 Demo"},{"id":"http://arxiv.org/abs/2110.06482v3","updated":"2023-03-07T03:01:00Z","published":"2021-10-13T04:03:51Z","title":"Parallel Deep Neural Networks Have Zero Duality Gap","summary":"  Training deep neural networks is a challenging non-convex optimization\nproblem. Recent work has proven that the strong duality holds (which means zero\nduality gap) for regularized finite-width two-layer ReLU networks and\nconsequently provided an equivalent convex training problem. However, extending\nthis result to deeper networks remains to be an open problem. In this paper, we\nprove that the duality gap for deeper linear networks with vector outputs is\nnon-zero. In contrast, we show that the zero duality gap can be obtained by\nstacking standard deep networks in parallel, which we call a parallel\narchitecture, and modifying the regularization. Therefore, we prove the strong\nduality and existence of equivalent convex problems that enable globally\noptimal training of deep networks. As a by-product of our analysis, we\ndemonstrate that the weight decay regularization on the network parameters\nexplicitly encourages low-rank solutions via closed-form expressions. In\naddition, we show that strong duality holds for three-layer standard ReLU\nnetworks given rank-1 data matrices.\n","authors":["Yifei Wang","Tolga Ergen","Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2110.06482v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03611v1","updated":"2023-03-07T02:56:15Z","published":"2023-03-07T02:56:15Z","title":"TinyAD: Memory-efficient anomaly detection for time series data in\n  Industrial IoT","summary":"  Monitoring and detecting abnormal events in cyber-physical systems is crucial\nto industrial production. With the prevalent deployment of the Industrial\nInternet of Things (IIoT), an enormous amount of time series data is collected\nto facilitate machine learning models for anomaly detection, and it is of the\nutmost importance to directly deploy the trained models on the IIoT devices.\nHowever, it is most challenging to deploy complex deep learning models such as\nConvolutional Neural Networks (CNNs) on these memory-constrained IIoT devices\nembedded with microcontrollers (MCUs). To alleviate the memory constraints of\nMCUs, we propose a novel framework named Tiny Anomaly Detection (TinyAD) to\nefficiently facilitate onboard inference of CNNs for real-time anomaly\ndetection. First, we conduct a comprehensive analysis of depthwise separable\nCNNs and regular CNNs for anomaly detection and find that the depthwise\nseparable convolution operation can reduce the model size by 50-90% compared\nwith the traditional CNNs. Then, to reduce the peak memory consumption of CNNs,\nwe explore two complementary strategies, in-place, and patch-by-patch memory\nrescheduling, and integrate them into a unified framework. The in-place method\ndecreases the peak memory of the depthwise convolution by sparing a temporary\nbuffer to transfer the activation results, while the patch-by-patch method\nfurther reduces the peak memory of layer-wise execution by slicing the input\ndata into corresponding receptive fields and executing in order. Furthermore,\nby adjusting the dimension of convolution filters, these strategies apply to\nboth univariate time series and multidomain time series features. Extensive\nexperiments on real-world industrial datasets show that our framework can\nreduce peak memory consumption by 2-5x with negligible computation overhead.\n","authors":["Yuting Sun","Tong Chen","Quoc Viet Hung Nguyen","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2303.03611v1.pdf","comment":"Accepted by IEEE Transactions on Industrial Informatics"},{"id":"http://arxiv.org/abs/2211.08064v2","updated":"2023-03-07T02:46:34Z","published":"2022-11-15T11:34:30Z","title":"Physics-Informed Machine Learning: A Survey on Problems, Methods and\n  Applications","summary":"  Recent advances of data-driven machine learning have revolutionized fields\nlike computer vision, reinforcement learning, and many scientific and\nengineering domains. In many real-world and scientific problems, systems that\ngenerate data are governed by physical laws. Recent work shows that it provides\npotential benefits for machine learning models by incorporating the physical\nprior and collected data, which makes the intersection of machine learning and\nphysics become a prevailing paradigm. By integrating the data and mathematical\nphysics models seamlessly, it can guide the machine learning model towards\nsolutions that are physically plausible, improving accuracy and efficiency even\nin uncertain and high-dimensional contexts. In this survey, we present this\nlearning paradigm called Physics-Informed Machine Learning (PIML) which is to\nbuild a model that leverages empirical data and available physical prior\nknowledge to improve performance on a set of tasks that involve a physical\nmechanism. We systematically review the recent development of physics-informed\nmachine learning from three perspectives of machine learning tasks,\nrepresentation of physical prior, and methods for incorporating physical prior.\nWe also propose several important open research problems based on the current\ntrends in the field. We argue that encoding different forms of physical prior\ninto model architectures, optimizers, inference algorithms, and significant\ndomain-specific applications like inverse engineering design and robotic\ncontrol is far from being fully explored in the field of physics-informed\nmachine learning. We believe that the interdisciplinary research of\nphysics-informed machine learning will significantly propel research progress,\nfoster the creation of more effective machine learning models, and also offer\ninvaluable assistance in addressing long-standing problems in related\ndisciplines.\n","authors":["Zhongkai Hao","Songming Liu","Yichi Zhang","Chengyang Ying","Yao Feng","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2211.08064v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.17244v2","updated":"2023-03-07T02:43:20Z","published":"2022-11-30T18:46:00Z","title":"Tight Certification of Adversarially Trained Neural Networks via\n  Nonconvex Low-Rank Semidefinite Relaxations","summary":"  Adversarial training is well-known to produce high-quality neural network\nmodels that are empirically robust against adversarial perturbations.\nNevertheless, once a model has been adversarially trained, one often desires a\ncertification that the model is truly robust against all future attacks.\nUnfortunately, when faced with adversarially trained models, all existing\napproaches have significant trouble making certifications that are strong\nenough to be practically useful. Linear programming (LP) techniques in\nparticular face a \"convex relaxation barrier\" that prevent them from making\nhigh-quality certifications, even after refinement with mixed-integer linear\nprogramming (MILP) techniques, and even when using state-of-the-art\ncomputational facilities. In this paper, we propose a nonconvex certification\ntechnique, based on a low-rank restriction of a semidefinite programming (SDP)\nrelaxation. The nonconvex relaxation makes strong certifications comparable to\nmuch more expensive SDP methods, while optimizing over dramatically fewer\nvariables comparable to much weaker LP methods. Despite nonconvexity, we show\nhow off-the-shelf local optimization algorithms can be used to achieve and to\ncertify global optimality in polynomial time. Our experiments find that the\nnonconvex relaxation almost completely closes the gap towards exact\ncertification of adversarially trained models.\n","authors":["Hong-Ming Chiu","Richard Y. Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.17244v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04526v2","updated":"2023-03-07T02:42:45Z","published":"2022-09-09T21:03:43Z","title":"Gluformer: Transformer-Based Personalized Glucose Forecasting with\n  Uncertainty Quantification","summary":"  Deep learning models achieve state-of-the art results in predicting blood\nglucose trajectories, with a wide range of architectures being proposed.\nHowever, the adaptation of such models in clinical practice is slow, largely\ndue to the lack of uncertainty quantification of provided predictions. In this\nwork, we propose to model the future glucose trajectory conditioned on the past\nas an infinite mixture of basis distributions (i.e., Gaussian, Laplace, etc.).\nThis change allows us to learn the uncertainty and predict more accurately in\nthe cases when the trajectory has a heterogeneous or multi-modal distribution.\nTo estimate the parameters of the predictive distribution, we utilize the\nTransformer architecture. We empirically demonstrate the superiority of our\nmethod over existing state-of-the-art techniques both in terms of accuracy and\nuncertainty on the synthetic and benchmark glucose data sets.\n","authors":["Renat Sergazinov","Mohammadreza Armandpour","Irina Gaynanova"],"pdf_url":"https://arxiv.org/pdf/2209.04526v2.pdf","comment":"5 pages, 2 figures, IEEE ICASSP"},{"id":"http://arxiv.org/abs/2303.03600v1","updated":"2023-03-07T02:31:57Z","published":"2023-03-07T02:31:57Z","title":"Adaptive Knowledge Distillation between Text and Speech Pre-trained\n  Models","summary":"  Learning on a massive amount of speech corpus leads to the recent success of\nmany self-supervised speech models. With knowledge distillation, these models\nmay also benefit from the knowledge encoded by language models that are\npre-trained on rich sources of texts. The distillation process, however, is\nchallenging due to the modal disparity between textual and speech embedding\nspaces. This paper studies metric-based distillation to align the embedding\nspace of text and speech with only a small amount of data without modifying the\nmodel structure. Since the semantic and granularity gap between text and speech\nhas been omitted in literature, which impairs the distillation, we propose the\nPrior-informed Adaptive knowledge Distillation (PAD) that adaptively leverages\ntext/speech units of variable granularity and prior distributions to achieve\nbetter global and local alignments between text and speech pre-trained models.\nWe evaluate on three spoken language understanding benchmarks to show that PAD\nis more effective in transferring linguistic knowledge than other metric-based\ndistillation approaches.\n","authors":["Jinjie Ni","Yukun Ma","Wen Wang","Qian Chen","Dianwen Ng","Han Lei","Trung Hieu Nguyen","Chong Zhang","Bin Ma","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2303.03600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00030v2","updated":"2023-03-07T02:29:59Z","published":"2022-09-30T18:14:07Z","title":"VIP: Towards Universal Visual Reward and Representation via\n  Value-Implicit Pre-Training","summary":"  Reward and representation learning are two long-standing challenges for\nlearning an expanding set of robot manipulation skills from sensory\nobservations. Given the inherent cost and scarcity of in-domain, task-specific\nrobot data, learning from large, diverse, offline human videos has emerged as a\npromising path towards acquiring a generally useful visual representation for\ncontrol; however, how these human videos can be used for general-purpose reward\nlearning remains an open question. We introduce\n$\\textbf{V}$alue-$\\textbf{I}$mplicit $\\textbf{P}$re-training (VIP), a\nself-supervised pre-trained visual representation capable of generating dense\nand smooth reward functions for unseen robotic tasks. VIP casts representation\nlearning from human videos as an offline goal-conditioned reinforcement\nlearning problem and derives a self-supervised dual goal-conditioned\nvalue-function objective that does not depend on actions, enabling pre-training\non unlabeled human videos. Theoretically, VIP can be understood as a novel\nimplicit time contrastive objective that generates a temporally smooth\nembedding, enabling the value function to be implicitly defined via the\nembedding distance, which can then be used to construct the reward for any\ngoal-image specified downstream task. Trained on large-scale Ego4D human videos\nand without any fine-tuning on in-domain, task-specific data, VIP's frozen\nrepresentation can provide dense visual reward for an extensive set of\nsimulated and $\\textbf{real-robot}$ tasks, enabling diverse reward-based visual\ncontrol methods and significantly outperforming all prior pre-trained\nrepresentations. Notably, VIP can enable simple, $\\textbf{few-shot}$ offline RL\non a suite of real-world robot tasks with as few as 20 trajectories.\n","authors":["Yecheng Jason Ma","Shagun Sodhani","Dinesh Jayaraman","Osbert Bastani","Vikash Kumar","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.00030v2.pdf","comment":"ICLR 2023, Notable-Top-25% (Spotlight). Project website:\n  https://sites.google.com/view/vip-rl"},{"id":"http://arxiv.org/abs/2207.08894v3","updated":"2023-03-07T02:26:25Z","published":"2022-07-18T19:07:56Z","title":"A Deep Reinforcement Learning Approach for Finding Non-Exploitable\n  Strategies in Two-Player Atari Games","summary":"  This paper proposes new, end-to-end deep reinforcement learning algorithms\nfor learning two-player zero-sum Markov games. Different from prior efforts on\ntraining agents to beat a fixed set of opponents, our objective is to find the\nNash equilibrium policies that are free from exploitation by even the\nadversarial opponents. We propose (a) Nash-DQN algorithm, which integrates the\ndeep learning techniques from single DQN into the classic Nash Q-learning\nalgorithm for solving tabular Markov games; (b) Nash-DQN-Exploiter algorithm,\nwhich additionally adopts an exploiter to guide the exploration of the main\nagent. We conduct experimental evaluation on tabular examples as well as\nvarious two-player Atari games. Our empirical results demonstrate that (i) the\npolicies found by many existing methods including Neural Fictitious Self Play\nand Policy Space Response Oracle can be prone to exploitation by adversarial\nopponents; (ii) the output policies of our algorithms are robust to\nexploitation, and thus outperform existing methods.\n","authors":["Zihan Ding","Dijia Su","Qinghua Liu","Chi Jin"],"pdf_url":"https://arxiv.org/pdf/2207.08894v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14311v2","updated":"2023-03-07T02:18:36Z","published":"2023-02-28T05:01:01Z","title":"Towards Memory- and Time-Efficient Backpropagation for Training Spiking\n  Neural Networks","summary":"  Spiking Neural Networks (SNNs) are promising energy-efficient models for\nneuromorphic computing. For training the non-differentiable SNN models, the\nbackpropagation through time (BPTT) with surrogate gradients (SG) method has\nachieved high performance. However, this method suffers from considerable\nmemory cost and training time during training. In this paper, we propose the\nSpatial Learning Through Time (SLTT) method that can achieve high performance\nwhile greatly improving training efficiency compared with BPTT. First, we show\nthat the backpropagation of SNNs through the temporal domain contributes just a\nlittle to the final calculated gradients. Thus, we propose to ignore the\nunimportant routes in the computational graph during backpropagation. The\nproposed method reduces the number of scalar multiplications and achieves a\nsmall memory occupation that is independent of the total time steps.\nFurthermore, we propose a variant of SLTT, called SLTT-K, that allows\nbackpropagation only at K time steps, then the required number of scalar\nmultiplications is further reduced and is independent of the total time steps.\nExperiments on both static and neuromorphic datasets demonstrate superior\ntraining efficiency and performance of our SLTT. In particular, our method\nachieves state-of-the-art accuracy on ImageNet, while the memory cost and\ntraining time are reduced by more than 70% and 50%, respectively, compared with\nBPTT.\n","authors":["Qingyan Meng","Mingqing Xiao","Shen Yan","Yisen Wang","Zhouchen Lin","Zhi-Quan Luo"],"pdf_url":"https://arxiv.org/pdf/2302.14311v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02307v3","updated":"2023-03-07T02:14:39Z","published":"2022-06-06T01:30:03Z","title":"Bootstrapping Semi-supervised Medical Image Segmentation with\n  Anatomical-aware Contrastive Distillation","summary":"  Contrastive learning has shown great promise over annotation scarcity\nproblems in the context of medical image segmentation. Existing approaches\ntypically assume a balanced class distribution for both labeled and unlabeled\nmedical images. However, medical image data in reality is commonly imbalanced\n(i.e., multi-class label imbalance), which naturally yields blurry contours and\nusually incorrectly labels rare objects. Moreover, it remains unclear whether\nall negative samples are equally negative. In this work, we present ACTION, an\nAnatomical-aware ConTrastive dIstillatiON framework, for semi-supervised\nmedical image segmentation. Specifically, we first develop an iterative\ncontrastive distillation algorithm by softly labeling the negatives rather than\nbinary supervision between positive and negative pairs. We also capture more\nsemantically similar features from the randomly chosen negative set compared to\nthe positives to enforce the diversity of the sampled data. Second, we raise a\nmore important question: Can we really handle imbalanced samples to yield\nbetter performance? Hence, the key innovation in ACTION is to learn global\nsemantic relationship across the entire dataset and local anatomical features\namong the neighbouring pixels with minimal additional memory footprint. During\nthe training, we introduce anatomical contrast by actively sampling a sparse\nset of hard negative pixels, which can generate smoother segmentation\nboundaries and more accurate predictions. Extensive experiments across two\nbenchmark datasets and different unlabeled settings show that ACTION\nsignificantly outperforms the current state-of-the-art semi-supervised methods.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2206.02307v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02733v2","updated":"2023-03-07T02:07:01Z","published":"2023-03-05T17:57:33Z","title":"Reparameterization through Spatial Gradient Scaling","summary":"  Reparameterization aims to improve the generalization of deep neural networks\nby transforming convolutional layers into equivalent multi-branched structures\nduring training. However, there exists a gap in understanding how\nreparameterization may change and benefit the learning process of neural\nnetworks. In this paper, we present a novel spatial gradient scaling method to\nredistribute learning focus among weights in convolutional networks. We prove\nthat spatial gradient scaling achieves the same learning dynamics as a branched\nreparameterization yet without introducing structural changes into the network.\nWe further propose an analytical approach that dynamically learns scalings for\neach convolutional layer based on the spatial characteristics of its input\nfeature map gauged by mutual information. Experiments on CIFAR-10, CIFAR-100,\nand ImageNet show that without searching for reparameterized structures, our\nproposed scaling method outperforms the state-of-the-art reparameterization\nstrategies at a lower computational cost.\n","authors":["Alexander Detkov","Mohammad Salameh","Muhammad Fetrat Qharabagh","Jialin Zhang","Wei Lui","Shangling Jui","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2303.02733v2.pdf","comment":"Published at ICLR 2023. Code available at\n  https://github.com/Ascend-Research/Reparameterization"},{"id":"http://arxiv.org/abs/2303.03593v1","updated":"2023-03-07T01:57:10Z","published":"2023-03-07T01:57:10Z","title":"ADELT: Transpilation Between Deep Learning Frameworks","summary":"  We propose Adversarial DEep Learning Transpiler (ADELT) for source-to-source\ntranspilation between deep learning frameworks. Unlike prior approaches, we\ndecouple the transpilation of code skeletons and the mapping of API keywords\n(an API function name or a parameter name). ADELT transpile code skeletons\nusing few-shot prompting on big language models. Based on contextual embeddings\nextracted by a BERT for code, we train aligned API embeddings in a\ndomain-adversarial setup, upon which we generate a dictionary for keyword\ntranslation. The model is trained on our unlabeled DL corpus from web crawl\ndata, without using any hand-crafted rules and parallel data. Our method\noutperforms state-of-the-art transpilers on multiple transpilation pairs\nincluding PyTorch-Keras and PyTorch-MXNet by 15.9pts and 12.0pts in exact match\nscores respectively.\n","authors":["Linyuan Gong","Jiayi Wang","Alvin Cheung"],"pdf_url":"https://arxiv.org/pdf/2303.03593v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2303.02219v2","updated":"2023-03-07T01:56:56Z","published":"2023-03-03T21:24:51Z","title":"NSGA-PINN: A Multi-Objective Optimization Method for Physics-Informed\n  Neural Network Training","summary":"  This paper presents NSGA-PINN, a multi-objective optimization framework for\neffective training of Physics-Informed Neural Networks (PINNs). The proposed\nframework uses the Non-dominated Sorting Genetic Algorithm (NSGA-II) to enable\ntraditional stochastic gradient optimization algorithms (e.g., ADAM) to escape\nlocal minima effectively. Additionally, the NSGA-II algorithm enables\nsatisfying the initial and boundary conditions encoded into the loss function\nduring physics-informed training precisely. We demonstrate the effectiveness of\nour framework by applying NSGA-PINN to several ordinary and partial\ndifferential equation problems. In particular, we show that the proposed\nframework can handle challenging inverse problems with noisy data.\n","authors":["Binghang Lu","Christian B. Moya","Guang Lin"],"pdf_url":"https://arxiv.org/pdf/2303.02219v2.pdf","comment":"13 pages, 35 figures"},{"id":"http://arxiv.org/abs/2303.03592v1","updated":"2023-03-07T01:55:26Z","published":"2023-03-07T01:55:26Z","title":"Exploring the Limits of Indiscriminate Data Poisoning Attacks","summary":"  Indiscriminate data poisoning attacks aim to decrease a model's test accuracy\nby injecting a small amount of corrupted training data. Despite significant\ninterest, existing attacks remain relatively ineffective against modern machine\nlearning (ML) architectures. In this work, we introduce the notion of model\npoisonability as a technical tool to explore the intrinsic limits of data\npoisoning attacks. We derive an easily computable threshold to establish and\nquantify a surprising phase transition phenomenon among popular ML models: data\npoisoning attacks become effective only when the poisoning ratio exceeds our\nthreshold. Building on existing parameter corruption attacks and refining the\nGradient Canceling attack, we perform extensive experiments to confirm our\ntheoretical findings, test the predictability of our transition threshold, and\nsignificantly improve existing data poisoning baselines over a range of\ndatasets and models. Our work highlights the critical role played by the\npoisoning ratio, and sheds new insights on existing empirical results, attacks\nand mitigation strategies in data poisoning.\n","authors":["Yiwei Lu","Gautam Kamth","Yaoliang Yu"],"pdf_url":"https://arxiv.org/pdf/2303.03592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03591v1","updated":"2023-03-07T01:54:24Z","published":"2023-03-07T01:54:24Z","title":"Approach to Learning Generalized Audio Representation Through Batch\n  Embedding Covariance Regularization and Constant-Q Transforms","summary":"  General-purpose embedding is highly desirable for few-shot even zero-shot\nlearning in many application scenarios, including audio tasks. In order to\nunderstand representations better, we conducted a thorough error analysis and\nvisualization of HEAR 2021 submission results. Inspired by the analysis, this\nwork experiments with different front-end audio preprocessing methods,\nincluding Constant-Q Transform (CQT) and Short-time Fourier transform (STFT),\nand proposes a Batch Embedding Covariance Regularization (BECR) term to uncover\na more holistic simulation of the frequency information received by the human\nauditory system. We tested the models on the suite of HEAR 2021 tasks, which\nencompass a broad category of tasks. Preliminary results show (1) the proposed\nBECR can incur a more dispersed embedding on the test set, (2) BECR improves\nthe PaSST model without extra computation complexity, and (3) STFT\npreprocessing outperforms CQT in all tasks we tested.\nGithub:https://github.com/ankitshah009/general_audio_embedding_hear_2021\n","authors":["Ankit Shah","Shuyi Chen","Kejun Zhou","Yue Chen","Bhiksha Raj"],"pdf_url":"https://arxiv.org/pdf/2303.03591v1.pdf","comment":"Technical report, 10 pages"},{"id":"http://arxiv.org/abs/2303.03590v1","updated":"2023-03-07T01:52:55Z","published":"2023-03-07T01:52:55Z","title":"Research on Efficient Fuzzy Clustering Method Based on Local Fuzzy\n  Granules","summary":"  In recent years, the problem of fuzzy clustering has been widely concerned.\nThe membership iteration of existing methods is mostly considered globally,\nwhich has considerable problems in noisy environments, and iterative\ncalculations for clusters with a large number of different sample sizes are not\naccurate and efficient. In this paper, starting from the strategy of\nlarge-scale priority, the data is fuzzy iterated using granular-balls, and the\nmembership degree of data only considers the two granular-balls where it is\nlocated, thus improving the efficiency of iteration. The formed fuzzy\ngranular-balls set can use more processing methods in the face of different\ndata scenarios, which enhances the practicability of fuzzy clustering\ncalculations.\n","authors":["Jiang Xie","Qiao Deng","Shuyin Xia","Yangzhou Zhao","Guoyin Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2303.03590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03577v1","updated":"2023-03-07T01:14:54Z","published":"2023-03-07T01:14:54Z","title":"A Review of and Roadmap for Data Science and Machine Learning for the\n  Neuropsychiatric Phenotype of Autism","summary":"  Autism Spectrum Disorder (autism) is a neurodevelopmental delay which affects\nat least 1 in 44 children. Like many neurological disorder phenotypes, the\ndiagnostic features are observable, can be tracked over time, and can be\nmanaged or even eliminated through proper therapy and treatments. Yet, there\nare major bottlenecks in the diagnostic, therapeutic, and longitudinal tracking\npipelines for autism and related delays, creating an opportunity for novel data\nscience solutions to augment and transform existing workflows and provide\naccess to services for more affected families. Several prior efforts conducted\nby a multitude of research labs have spawned great progress towards improved\ndigital diagnostics and digital therapies for children with autism. We review\nthe literature of digital health methods for autism behavior quantification\nusing data science. We describe both case-control studies and classification\nsystems for digital phenotyping. We then discuss digital diagnostics and\ntherapeutics which integrate machine learning models of autism-related\nbehaviors, including the factors which must be addressed for translational use.\nFinally, we describe ongoing challenges and potent opportunities for the field\nof autism data science. Given the heterogeneous nature of autism and the\ncomplexities of the relevant behaviors, this review contains insights which are\nrelevant to neurological behavior analysis and digital psychiatry more broadly.\n","authors":["Peter Washington","Dennis P. Wall"],"pdf_url":"https://arxiv.org/pdf/2303.03577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08987v2","updated":"2023-03-07T01:10:53Z","published":"2023-01-21T18:05:59Z","title":"Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors","summary":"  The pursuit of long-term fairness involves the interplay between\ndecision-making and the underlying data generating process. In this paper,\nthrough causal modeling with a directed acyclic graph (DAG) on the\ndecision-distribution interplay, we investigate the possibility of achieving\nlong-term fairness from a dynamic perspective. We propose Tier Balancing, a\ntechnically more challenging but more natural notion to achieve in the context\nof long-term, dynamic fairness analysis. Different from previous fairness\nnotions that are defined purely on observed variables, our notion goes one step\nfurther, capturing behind-the-scenes situation changes on the unobserved latent\ncausal factors that directly carry out the influence from the current decision\nto the future data distribution. Under the specified dynamics, we prove that in\ngeneral one cannot achieve the long-term fairness goal only through one-step\ninterventions. Furthermore, in the effort of approaching long-term fairness, we\nconsider the mission of \"getting closer to\" the long-term fairness goal and\npresent possibility and impossibility results accordingly.\n","authors":["Zeyu Tang","Yatong Chen","Yang Liu","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08987v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2010.13934v3","updated":"2023-03-07T00:58:23Z","published":"2020-10-26T22:37:49Z","title":"Accelerate the Warm-up Stage in the Lasso Computation via a Homotopic\n  Approach","summary":"  In optimization, it is known that when the objective functions are strictly\nconvex and well-conditioned, gradient-based approaches can be extremely\neffective, e.g., achieving the exponential rate of convergence. On the other\nhand, the existing Lasso-type estimator in general cannot achieve the optimal\nrate due to the undesirable behavior of the absolute function at the origin. A\nhomotopic method is to use a sequence of surrogate functions to approximate the\n$\\ell_1$ penalty that is used in the Lasso-type of estimators. The surrogate\nfunctions will converge to the $\\ell_1$ penalty in the Lasso estimator. At the\nsame time, each surrogate function is strictly convex, which enables a provable\nfaster numerical rate of convergence. In this paper, we demonstrate that by\nmeticulously defining the surrogate functions, one can prove a faster numerical\nconvergence rate than any existing methods in computing for the Lasso-type of\nestimators. Namely, the state-of-the-art algorithms can only guarantee\n$O(1/\\epsilon)$ or $O(1/\\sqrt{\\epsilon})$ convergence rates, while we can prove\nan $O([\\log(1/\\epsilon)]^2)$ for the newly proposed algorithm. Our numerical\nsimulations show that the new algorithm also performs better empirically.\n","authors":["Yujie Zhao","Xiaoming Huo"],"pdf_url":"https://arxiv.org/pdf/2010.13934v3.pdf","comment":"19 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.03572v1","updated":"2023-03-07T00:46:04Z","published":"2023-03-07T00:46:04Z","title":"Learning When to Treat Business Processes: Prescriptive Process\n  Monitoring with Causal Inference and Reinforcement Learning","summary":"  Increasing the success rate of a process, i.e. the percentage of cases that\nend in a positive outcome, is a recurrent process improvement goal. At runtime,\nthere are often certain actions (a.k.a. treatments) that workers may execute to\nlift the probability that a case ends in a positive outcome. For example, in a\nloan origination process, a possible treatment is to issue multiple loan offers\nto increase the probability that the customer takes a loan. Each treatment has\na cost. Thus, when defining policies for prescribing treatments to cases,\nmanagers need to consider the net gain of the treatments. Also, the effect of a\ntreatment varies over time: treating a case earlier may be more effective than\nlater in a case. This paper presents a prescriptive monitoring method that\nautomates this decision-making task. The method combines causal inference and\nreinforcement learning to learn treatment policies that maximize the net gain.\nThe method leverages a conformal prediction technique to speed up the\nconvergence of the reinforcement learning mechanism by separating cases that\nare likely to end up in a positive or negative outcome, from uncertain cases.\nAn evaluation on two real-life datasets shows that the proposed method\noutperforms a state-of-the-art baseline.\n","authors":["Zahra Dasht Bozorgi","Marlon Dumas","Marcello La Rosa","Artem Polyvyanyy","Mahmoud Shoush","Irene Teinemaa"],"pdf_url":"https://arxiv.org/pdf/2303.03572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.09244v4","updated":"2023-03-07T00:12:00Z","published":"2022-05-18T23:32:20Z","title":"Riemannian Metric Learning via Optimal Transport","summary":"  We introduce an optimal transport-based model for learning a metric tensor\nfrom cross-sectional samples of evolving probability measures on a common\nRiemannian manifold. We neurally parametrize the metric as a spatially-varying\nmatrix field and efficiently optimize our model's objective using a simple\nalternating scheme. Using this learned metric, we can nonlinearly interpolate\nbetween probability measures and compute geodesics on the manifold. We show\nthat metrics learned using our method improve the quality of trajectory\ninference on scRNA and bird migration data at the cost of little additional\ncross-sectional data.\n","authors":["Christopher Scarvelis","Justin Solomon"],"pdf_url":"https://arxiv.org/pdf/2205.09244v4.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2106.02968v4","updated":"2023-03-07T00:09:11Z","published":"2021-06-05T21:25:03Z","title":"Low Budget Active Learning via Wasserstein Distance: An Integer\n  Programming Approach","summary":"  Active learning is the process of training a model with limited labeled data\nby selecting a core subset of an unlabeled data pool to label. The large scale\nof data sets used in deep learning forces most sample selection strategies to\nemploy efficient heuristics. This paper introduces an integer optimization\nproblem for selecting a core set that minimizes the discrete Wasserstein\ndistance from the unlabeled pool. We demonstrate that this problem can be\ntractably solved with a Generalized Benders Decomposition algorithm. Our\nstrategy uses high-quality latent features that can be obtained by unsupervised\nlearning on the unlabeled pool. Numerical results on several data sets show\nthat our optimization approach is competitive with baselines and particularly\noutperforms them in the low budget regime where less than one percent of the\ndata set is labeled.\n","authors":["Rafid Mahmood","Sanja Fidler","Marc T. Law"],"pdf_url":"https://arxiv.org/pdf/2106.02968v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04292v1","updated":"2023-03-07T23:54:35Z","published":"2023-03-07T23:54:35Z","title":"ERUDITE: Human-in-the-Loop IoT for an Adaptive Personalized Learning\n  System","summary":"  Thanks to the rapid growth in wearable technologies and recent advancement in\nmachine learning and signal processing, monitoring complex human contexts\nbecomes feasible, paving the way to develop human-in-the-loop IoT systems that\nnaturally evolve to adapt to the human and environment state autonomously.\nNevertheless, a central challenge in designing many of these IoT systems arises\nfrom the requirement to infer the human mental state, such as intention,\nstress, cognition load, or learning ability. While different human contexts can\nbe inferred from the fusion of different sensor modalities that can correlate\nto a particular mental state, the human brain provides a richer sensor modality\nthat gives us more insights into the required human context. This paper\nproposes ERUDITE, a human-in-the-loop IoT system for the learning environment\nthat exploits recent wearable neurotechnology to decode brain signals. Through\ninsights from concept learning theory, ERUDITE can infer the human state of\nlearning and understand when human learning increases or declines. By\nquantifying human learning as an input sensory signal, ERUDITE can provide\nadequate personalized feedback to humans in a learning environment to enhance\ntheir learning experience. ERUDITE is evaluated across $15$ participants and\nshowed that by using the brain signals as a sensor modality to infer the human\nlearning state and providing personalized adaptation to the learning\nenvironment, the participants' learning performance increased on average by\n$26\\%$. Furthermore, we showed that ERUDITE can be deployed on an edge-based\nprototype to evaluate its practicality and scalability.\n","authors":["Mojtaba Taherisadr","Mohammad Abdullah Al Faruque","Salma Elmalaki"],"pdf_url":"https://arxiv.org/pdf/2303.04292v1.pdf","comment":"It is under review in the IEEE IoT journal"},{"id":"http://arxiv.org/abs/2211.01202v2","updated":"2023-03-07T23:44:29Z","published":"2022-11-02T15:27:31Z","title":"Human-in-the-Loop Mixup","summary":"  Aligning model representations to humans has been found to improve robustness\nand generalization. However, such methods often focus on standard observational\ndata. Synthetic data is proliferating and powering many advances in machine\nlearning; yet, it is not always clear whether synthetic labels are perceptually\naligned to humans -- rendering it likely model representations are not human\naligned. We focus on the synthetic data used in mixup: a powerful regularizer\nshown to improve model robustness, generalization, and calibration. We design a\ncomprehensive series of elicitation interfaces, which we release as HILL MixE\nSuite, and recruit 159 participants to provide perceptual judgments along with\ntheir uncertainties, over mixup examples. We find that human perceptions do not\nconsistently align with the labels traditionally used for synthetic points, and\nbegin to demonstrate the applicability of these findings to potentially\nincrease the reliability of downstream models, particularly when incorporating\nhuman uncertainty. We release all elicited judgments in a new data hub we call\nH-Mix.\n","authors":["Katherine M. Collins","Umang Bhatt","Weiyang Liu","Vihari Piratla","Ilia Sucholutsky","Bradley Love","Adrian Weller"],"pdf_url":"https://arxiv.org/pdf/2211.01202v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.01888v4","updated":"2023-03-07T23:36:04Z","published":"2022-06-04T03:15:57Z","title":"Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning","summary":"  In offline multi-agent reinforcement learning (MARL), agents estimate\npolicies from a given dataset. We study reward-poisoning attacks in this\nsetting where an exogenous attacker modifies the rewards in the dataset before\nthe agents see the dataset. The attacker wants to guide each agent into a\nnefarious target policy while minimizing the $L^p$ norm of the reward\nmodification. Unlike attacks on single-agent RL, we show that the attacker can\ninstall the target policy as a Markov Perfect Dominant Strategy Equilibrium\n(MPDSE), which rational agents are guaranteed to follow. This attack can be\nsignificantly cheaper than separate single-agent attacks. We show that the\nattack works on various MARL agents including uncertainty-aware learners, and\nwe exhibit linear programs to efficiently solve the attack problem. We also\nstudy the relationship between the structure of the datasets and the minimal\nattack cost. Our work paves the way for studying defense in offline MARL.\n","authors":["Young Wu","Jeremy McMahan","Xiaojin Zhu","Qiaomin Xie"],"pdf_url":"https://arxiv.org/pdf/2206.01888v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04288v1","updated":"2023-03-07T23:24:27Z","published":"2023-03-07T23:24:27Z","title":"Polynomial Time and Private Learning of Unbounded Gaussian Mixture\n  Models","summary":"  We study the problem of privately estimating the parameters of\n$d$-dimensional Gaussian Mixture Models (GMMs) with $k$ components. For this,\nwe develop a technique to reduce the problem to its non-private counterpart.\nThis allows us to privatize existing non-private algorithms in a blackbox\nmanner, while incurring only a small overhead in the sample complexity and\nrunning time. As the main application of our framework, we develop an\n$(\\varepsilon, \\delta)$-differentially private algorithm to learn GMMs using\nthe non-private algorithm of Moitra and Valiant [MV10] as a blackbox.\nConsequently, this gives the first sample complexity upper bound and first\npolynomial time algorithm for privately learning GMMs without any boundedness\nassumptions on the parameters.\n","authors":["Jamil Arbas","Hassan Ashtiani","Christopher Liaw"],"pdf_url":"https://arxiv.org/pdf/2303.04288v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.12311v4","updated":"2023-03-07T23:24:12Z","published":"2021-10-23T22:38:54Z","title":"Vector Optimization with Stochastic Bandit Feedback","summary":"  We introduce vector optimization problems with stochastic bandit feedback, in\nwhich preferences among designs are encoded by a polyhedral ordering cone $C$.\nOur setup generalizes the best arm identification problem to vector-valued\nrewards by extending the concept of Pareto set beyond multi-objective\noptimization. We characterize the sample complexity of ($\\epsilon,\\delta$)-PAC\nPareto set identification by defining a new cone-dependent notion of\ncomplexity, called the ordering complexity. In particular, we provide\ngap-dependent and worst-case lower bounds on the sample complexity and show\nthat, in the worst-case, the sample complexity scales with the square of\nordering complexity. Furthermore, we investigate the sample complexity of the\nna\\\"ive elimination algorithm and prove that it nearly matches the worst-case\nsample complexity. Finally, we run experiments to verify our theoretical\nresults and illustrate how $C$ and sampling budget affect the Pareto set, the\nreturned ($\\epsilon,\\delta$)-PAC Pareto set, and the success of identification.\n","authors":["Çağın Ararat","Cem Tekin"],"pdf_url":"https://arxiv.org/pdf/2110.12311v4.pdf","comment":"26 pages, 3 tables, 2 figure; Proceedings of the 26th International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2023,\n  Valencia, Spain"},{"id":"http://arxiv.org/abs/2203.00546v3","updated":"2023-03-07T23:23:28Z","published":"2022-03-01T15:29:39Z","title":"Optimal quantum dataset for learning a unitary transformation","summary":"  Unitary transformations formulate the time evolution of quantum states. How\nto learn a unitary transformation efficiently is a fundamental problem in\nquantum machine learning. The most natural and leading strategy is to train a\nquantum machine learning model based on a quantum dataset. Although the\npresence of more training data results in better models, using too much data\nreduces the efficiency of training. In this work, we solve the problem on the\nminimum size of sufficient quantum datasets for learning a unitary\ntransformation exactly, which reveals the power and limitation of quantum data.\nFirst, we prove that the minimum size of a dataset with pure states is $2^n$\nfor learning an $n$-qubit unitary transformation. To fully explore the\ncapability of quantum data, we introduce a practical quantum dataset consisting\nof $n+1$ elementary tensor product states that are sufficient for exact\ntraining. The main idea is to simplify the structure utilizing decoupling,\nwhich leads to an exponential improvement in the size of the datasets with pure\nstates. Furthermore, we show that the size of the quantum dataset with mixed\nstates can be reduced to a constant, which yields an optimal quantum dataset\nfor learning a unitary. We showcase the applications of our results in oracle\ncompiling and Hamiltonian simulation. Notably, to accurately simulate a 3-qubit\none-dimensional nearest-neighbor Heisenberg model, our circuit only uses $96$\nelementary quantum gates, which is significantly less than $4080$ gates in the\ncircuit constructed by the Trotter-Suzuki product formula.\n","authors":["Zhan Yu","Xuanqiang Zhao","Benchi Zhao","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2203.00546v3.pdf","comment":"11 pages including appendix, v2 added remarks and references, v3 is\n  closed to the published version"},{"id":"http://arxiv.org/abs/2303.04286v1","updated":"2023-03-07T23:16:46Z","published":"2023-03-07T23:16:46Z","title":"Sufficient dimension reduction for feature matrices","summary":"  We address the problem of sufficient dimension reduction for feature\nmatrices, which arises often in sensor network localization, brain\nneuroimaging, and electroencephalography analysis. In general, feature matrices\nhave both row- and column-wise interpretations and contain structural\ninformation that can be lost with naive vectorization approaches. To address\nthis, we propose a method called principal support matrix machine (PSMM) for\nthe matrix sufficient dimension reduction. The PSMM converts the sufficient\ndimension reduction problem into a series of classification problems by\ndividing the response variables into slices. It effectively utilizes the matrix\nstructure by finding hyperplanes with rank-1 normal matrix that optimally\nseparate the sliced responses. Additionally, we extend our approach to the\nhigher-order tensor case. Our numerical analysis demonstrates that the PSMM\noutperforms existing methods and has strong interpretability in real data\napplications.\n","authors":["Chanwoo Lee"],"pdf_url":"https://arxiv.org/pdf/2303.04286v1.pdf","comment":"30 pages, 3 figures"},{"id":"http://arxiv.org/abs/2010.09697v5","updated":"2023-03-07T23:09:55Z","published":"2020-10-19T17:40:38Z","title":"Effects of Parameter Norm Growth During Transformer Training: Inductive\n  Bias from Gradient Descent","summary":"  The capacity of neural networks like the widely adopted transformer is known\nto be very high. Evidence is emerging that they learn successfully due to\ninductive bias in the training routine, typically a variant of gradient descent\n(GD). To better understand this bias, we study the tendency for transformer\nparameters to grow in magnitude ($\\ell_2$ norm) during training, and its\nimplications for the emergent representations within self attention layers.\nEmpirically, we document norm growth in the training of transformer language\nmodels, including T5 during its pretraining. As the parameters grow in\nmagnitude, we prove that the network approximates a discretized network with\nsaturated activation functions. Such \"saturated\" networks are known to have a\nreduced capacity compared to the full network family that can be described in\nterms of formal languages and automata. Our results suggest saturation is a new\ncharacterization of an inductive bias implicit in GD of particular interest for\nNLP. We leverage the emergent discrete structure in a saturated transformer to\nanalyze the role of different attention heads, finding that some focus locally\non a small number of positions, while other heads compute global averages,\nallowing counting. We believe understanding the interplay between these two\ncapabilities may shed further light on the structure of computation within\nlarge transformers.\n","authors":["William Merrill","Vivek Ramanujan","Yoav Goldberg","Roy Schwartz","Noah Smith"],"pdf_url":"https://arxiv.org/pdf/2010.09697v5.pdf","comment":"Appeared at EMNLP 2021. March 7, 2023: Removed irreproducible numbers\n  reported in a footnote with erratum note"},{"id":"http://arxiv.org/abs/2303.04278v1","updated":"2023-03-07T22:57:23Z","published":"2023-03-07T22:57:23Z","title":"CUDA: Convolution-based Unlearnable Datasets","summary":"  Large-scale training of modern deep learning models heavily relies on\npublicly available data on the web. This potentially unauthorized usage of\nonline data leads to concerns regarding data privacy. Recent works aim to make\nunlearnable data for deep learning models by adding small, specially designed\nnoises to tackle this issue. However, these methods are vulnerable to\nadversarial training (AT) and/or are computationally heavy. In this work, we\npropose a novel, model-free, Convolution-based Unlearnable DAtaset (CUDA)\ngeneration technique. CUDA is generated using controlled class-wise\nconvolutions with filters that are randomly generated via a private key. CUDA\nencourages the network to learn the relation between filters and labels rather\nthan informative features for classifying the clean data. We develop some\ntheoretical analysis demonstrating that CUDA can successfully poison Gaussian\nmixture data by reducing the clean data performance of the optimal Bayes\nclassifier. We also empirically demonstrate the effectiveness of CUDA with\nvarious datasets (CIFAR-10, CIFAR-100, ImageNet-100, and Tiny-ImageNet), and\narchitectures (ResNet-18, VGG-16, Wide ResNet-34-10, DenseNet-121, DeIT,\nEfficientNetV2-S, and MobileNetV2). Our experiments show that CUDA is robust to\nvarious data augmentations and training approaches such as smoothing, AT with\ndifferent budgets, transfer learning, and fine-tuning. For instance, training a\nResNet-18 on ImageNet-100 CUDA achieves only 8.96$\\%$, 40.08$\\%$, and 20.58$\\%$\nclean test accuracies with empirical risk minimization (ERM), $L_{\\infty}$ AT,\nand $L_{2}$ AT, respectively. Here, ERM on the clean training data achieves a\nclean test accuracy of 80.66$\\%$. CUDA exhibits unlearnability effect with ERM\neven when only a fraction of the training dataset is perturbed. Furthermore, we\nalso show that CUDA is robust to adaptive defenses designed specifically to\nbreak it.\n","authors":["Vinu Sankar Sadasivan","Mahdi Soltanolkotabi","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2303.04278v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.04275v1","updated":"2023-03-07T22:53:36Z","published":"2023-03-07T22:53:36Z","title":"A Computer Vision Enabled damage detection model with improved YOLOv5\n  based on Transformer Prediction Head","summary":"  Objective:Computer vision-based up-to-date accurate damage classification and\nlocalization are of decisive importance for infrastructure monitoring, safety,\nand the serviceability of civil infrastructure. Current state-of-the-art deep\nlearning (DL)-based damage detection models, however, often lack superior\nfeature extraction capability in complex and noisy environments, limiting the\ndevelopment of accurate and reliable object distinction. Method: To this end,\nwe present DenseSPH-YOLOv5, a real-time DL-based high-performance damage\ndetection model where DenseNet blocks have been integrated with the backbone to\nimprove in preserving and reusing critical feature information. Additionally,\nconvolutional block attention modules (CBAM) have been implemented to improve\nattention performance mechanisms for strong and discriminating deep spatial\nfeature extraction that results in superior detection under various challenging\nenvironments. Moreover, additional feature fusion layers and a Swin-Transformer\nPrediction Head (SPH) have been added leveraging advanced self-attention\nmechanism for more efficient detection of multiscale object sizes and\nsimultaneously reducing the computational complexity. Results: Evaluating the\nmodel performance in large-scale Road Damage Dataset (RDD-2018), at a detection\nrate of 62.4 FPS, DenseSPH-YOLOv5 obtains a mean average precision (mAP) value\nof 85.25 %, F1-score of 81.18 %, and precision (P) value of 89.51 %\noutperforming current state-of-the-art models. Significance: The present\nresearch provides an effective and efficient damage localization model\naddressing the shortcoming of existing DL-based damage detection models by\nproviding highly accurate localized bounding box prediction. Current work\nconstitutes a step towards an accurate and robust automated damage detection\nsystem in real-time in-field applications.\n","authors":["Arunabha M. Roy","Jayabrata Bhaduri"],"pdf_url":"https://arxiv.org/pdf/2303.04275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04274v1","updated":"2023-03-07T22:52:40Z","published":"2023-03-07T22:52:40Z","title":"Amplitude-Varying Perturbation for Balancing Privacy and Utility in\n  Federated Learning","summary":"  While preserving the privacy of federated learning (FL), differential privacy\n(DP) inevitably degrades the utility (i.e., accuracy) of FL due to model\nperturbations caused by DP noise added to model updates. Existing studies have\nconsidered exclusively noise with persistent root-mean-square amplitude and\noverlooked an opportunity of adjusting the amplitudes to alleviate the adverse\neffects of the noise. This paper presents a new DP perturbation mechanism with\na time-varying noise amplitude to protect the privacy of FL and retain the\ncapability of adjusting the learning performance. Specifically, we propose a\ngeometric series form for the noise amplitude and reveal analytically the\ndependence of the series on the number of global aggregations and the\n$(\\epsilon,\\delta)$-DP requirement. We derive an online refinement of the\nseries to prevent FL from premature convergence resulting from excessive\nperturbation noise. Another important aspect is an upper bound developed for\nthe loss function of a multi-layer perceptron (MLP) trained by FL running the\nnew DP mechanism. Accordingly, the optimal number of global aggregations is\nobtained, balancing the learning and privacy. Extensive experiments are\nconducted using MLP, supporting vector machine, and convolutional neural\nnetwork models on four public datasets. The contribution of the new DP\nmechanism to the convergence and accuracy of privacy-preserving FL is\ncorroborated, compared to the state-of-the-art Gaussian noise mechanism with a\npersistent noise amplitude.\n","authors":["Xin Yuan","Wei Ni","Ming Ding","Kang Wei","Jun Li","H. Vincent Poor"],"pdf_url":"https://arxiv.org/pdf/2303.04274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.01911v3","updated":"2023-03-07T22:46:55Z","published":"2022-07-05T09:43:17Z","title":"Explainability in Deep Reinforcement Learning, a Review into Current\n  Methods and Applications","summary":"  The use of Deep Reinforcement Learning (DRL) schemes has increased\ndramatically since their first introduction in 2015. Though uses in many\ndifferent applications are being found, they still have a problem with the lack\nof interpretability. This has bread a lack of understanding and trust in the\nuse of DRL solutions from researchers and the general public. To solve this\nproblem, the field of Explainable Artificial Intelligence (XAI) has emerged.\nThis entails a variety of different methods that look to open the DRL black\nboxes, ranging from the use of interpretable symbolic Decision Trees (DT) to\nnumerical methods like Shapley Values. This review looks at which methods are\nbeing used and for which applications. This is done to identify which models\nare the best suited to each application or if a method is being underutilised.\n","authors":["Thomas Hickling","Abdelhafid Zenati","Nabil Aouf","Phillippa Spencer"],"pdf_url":"https://arxiv.org/pdf/2207.01911v3.pdf","comment":"30 pages, 6 figures, Paper Review"},{"id":"http://arxiv.org/abs/2303.04268v1","updated":"2023-03-07T22:39:23Z","published":"2023-03-07T22:39:23Z","title":"On the Sample Complexity of Vanilla Model-Based Offline Reinforcement\n  Learning with Dependent Samples","summary":"  Offline reinforcement learning (offline RL) considers problems where learning\nis performed using only previously collected samples and is helpful for the\nsettings in which collecting new data is costly or risky. In model-based\noffline RL, the learner performs estimation (or optimization) using a model\nconstructed according to the empirical transition frequencies. We analyze the\nsample complexity of vanilla model-based offline RL with dependent samples in\nthe infinite-horizon discounted-reward setting. In our setting, the samples\nobey the dynamics of the Markov decision process and, consequently, may have\ninterdependencies. Under no assumption of independent samples, we provide a\nhigh-probability, polynomial sample complexity bound for vanilla model-based\noff-policy evaluation that requires partial or uniform coverage. We extend this\nresult to the off-policy optimization under uniform coverage. As a comparison\nto the model-based approach, we analyze the sample complexity of off-policy\nevaluation with vanilla importance sampling in the infinite-horizon setting.\nFinally, we provide an estimator that outperforms the sample-mean estimator for\nalmost deterministic dynamics that are prevalent in reinforcement learning.\n","authors":["Mustafa O. Karabag","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2303.04268v1.pdf","comment":"Accepted to AAAI-23"},{"id":"http://arxiv.org/abs/2212.06864v2","updated":"2023-03-07T22:29:37Z","published":"2022-12-10T01:50:35Z","title":"Task-Adaptive Meta-Learning Framework for Advancing Spatial\n  Generalizability","summary":"  Spatio-temporal machine learning is critically needed for a variety of\nsocietal applications, such as agricultural monitoring, hydrological forecast,\nand traffic management. These applications greatly rely on regional features\nthat characterize spatial and temporal differences. However, spatio-temporal\ndata often exhibit complex patterns and significant data variability across\ndifferent locations. The labels in many real-world applications can also be\nlimited, which makes it difficult to separately train independent models for\ndifferent locations. Although meta learning has shown promise in model\nadaptation with small samples, existing meta learning methods remain limited in\nhandling a large number of heterogeneous tasks, e.g., a large number of\nlocations with varying data patterns. To bridge the gap, we propose\ntask-adaptive formulations and a model-agnostic meta-learning framework that\nensembles regionally heterogeneous data into location-sensitive meta tasks. We\nconduct task adaptation following an easy-to-hard task hierarchy in which\ndifferent meta models are adapted to tasks of different difficulty levels. One\nmajor advantage of our proposed method is that it improves the model adaptation\nto a large number of heterogeneous tasks. It also enhances the model\ngeneralization by automatically adapting the meta model of the corresponding\ndifficulty level to any new tasks. We demonstrate the superiority of our\nproposed framework over a diverse set of baselines and state-of-the-art\nmeta-learning frameworks. Our extensive experiments on real crop yield data\nshow the effectiveness of the proposed method in handling spatial-related\nheterogeneous tasks in real societal applications.\n","authors":["Zhexiong Liu","Licheng Liu","Yiqun Xie","Zhenong Jin","Xiaowei Jia"],"pdf_url":"https://arxiv.org/pdf/2212.06864v2.pdf","comment":"In the Thirty-Seventh AAAI Conference on Artificial Intelligence,\n  February 2023"},{"id":"http://arxiv.org/abs/2104.03509v4","updated":"2023-03-07T22:13:20Z","published":"2021-04-08T04:52:21Z","title":"Py-Feat: Python Facial Expression Analysis Toolbox","summary":"  Studying facial expressions is a notoriously difficult endeavor. Recent\nadvances in the field of affective computing have yielded impressive progress\nin automatically detecting facial expressions from pictures and videos.\nHowever, much of this work has yet to be widely disseminated in social science\ndomains such as psychology. Current state of the art models require\nconsiderable domain expertise that is not traditionally incorporated into\nsocial science training programs. Furthermore, there is a notable absence of\nuser-friendly and open-source software that provides a comprehensive set of\ntools and functions that support facial expression research. In this paper, we\nintroduce Py-Feat, an open-source Python toolbox that provides support for\ndetecting, preprocessing, analyzing, and visualizing facial expression data.\nPy-Feat makes it easy for domain experts to disseminate and benchmark computer\nvision models and also for end users to quickly process, analyze, and visualize\nface expression data. We hope this platform will facilitate increased use of\nfacial expression data in human behavior research.\n","authors":["Jin Hyun Cheong","Eshin Jolly","Tiankang Xie","Sophie Byrne","Matthew Kenney","Luke J. Chang"],"pdf_url":"https://arxiv.org/pdf/2104.03509v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04257v1","updated":"2023-03-07T21:55:22Z","published":"2023-03-07T21:55:22Z","title":"adaPARL: Adaptive Privacy-Aware Reinforcement Learning for\n  Sequential-Decision Making Human-in-the-Loop Systems","summary":"  Reinforcement learning (RL) presents numerous benefits compared to rule-based\napproaches in various applications. Privacy concerns have grown with the\nwidespread use of RL trained with privacy-sensitive data in IoT devices,\nespecially for human-in-the-loop systems. On the one hand, RL methods enhance\nthe user experience by trying to adapt to the highly dynamic nature of humans.\nOn the other hand, trained policies can leak the user's private information.\nRecent attention has been drawn to designing privacy-aware RL algorithms while\nmaintaining an acceptable system utility. A central challenge in designing\nprivacy-aware RL, especially for human-in-the-loop systems, is that humans have\nintrinsic variability and their preferences and behavior evolve. The effect of\none privacy leak mitigation can be different for the same human or across\ndifferent humans over time. Hence, we can not design one fixed model for\nprivacy-aware RL that fits all. To that end, we propose adaPARL, an adaptive\napproach for privacy-aware RL, especially for human-in-the-loop IoT systems.\nadaPARL provides a personalized privacy-utility trade-off depending on human\nbehavior and preference. We validate the proposed adaPARL on two IoT\napplications, namely (i) Human-in-the-Loop Smart Home and (ii)\nHuman-in-the-Loop Virtual Reality (VR) Smart Classroom. Results obtained on\nthese two applications validate the generality of adaPARL and its ability to\nprovide a personalized privacy-utility trade-off. On average, for the first\napplication, adaPARL improves the utility by $57\\%$ over the baseline and by\n$43\\%$ over randomization. adaPARL also reduces the privacy leak by $23\\%$ on\naverage. For the second application, adaPARL decreases the privacy leak to\n$44\\%$ before the utility drops by $15\\%$.\n","authors":["Mojtaba Taherisadr","Stelios Andrew Stavroulakis","Salma Elmalaki"],"pdf_url":"https://arxiv.org/pdf/2303.04257v1.pdf","comment":"This paper is accepted at CPS-IoT week (IoTDI'23)"},{"id":"http://arxiv.org/abs/2303.04255v1","updated":"2023-03-07T21:54:35Z","published":"2023-03-07T21:54:35Z","title":"Self-supervised speech representation learning for keyword-spotting with\n  light-weight transformers","summary":"  Self-supervised speech representation learning (S3RL) is revolutionizing the\nway we leverage the ever-growing availability of data. While S3RL related\nstudies typically use large models, we employ light-weight networks to comply\nwith tight memory of compute-constrained devices. We demonstrate the\neffectiveness of S3RL on a keyword-spotting (KS) problem by using transformers\nwith 330k parameters and propose a mechanism to enhance utterance-wise\ndistinction, which proves crucial for improving performance on classification\ntasks. On the Google speech commands v2 dataset, the proposed method applied to\nthe Auto-Regressive Predictive Coding S3RL led to a 1.2% accuracy improvement\ncompared to training from scratch. On an in-house KS dataset with four\ndifferent keywords, it provided 6% to 23.7% relative false accept improvement\nat fixed false reject rate. We argue this demonstrates the applicability of\nS3RL approaches to light-weight models for KS and confirms S3RL is a powerful\nalternative to traditional supervised learning for resource-constrained\napplications.\n","authors":["Chenyang Gao","Yue Gu","Francesco Caliva","Yuzong Liu"],"pdf_url":"https://arxiv.org/pdf/2303.04255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04248v1","updated":"2023-03-07T21:46:15Z","published":"2023-03-07T21:46:15Z","title":"TRACT: Denoising Diffusion Models with Transitive Closure\n  Time-Distillation","summary":"  Denoising Diffusion models have demonstrated their proficiency for generative\nsampling. However, generating good samples often requires many iterations.\nConsequently, techniques such as binary time-distillation (BTD) have been\nproposed to reduce the number of network calls for a fixed architecture. In\nthis paper, we introduce TRAnsitive Closure Time-distillation (TRACT), a new\nmethod that extends BTD. For single step diffusion,TRACT improves FID by up to\n2.4x on the same architecture, and achieves new single-step Denoising Diffusion\nImplicit Models (DDIM) state-of-the-art FID (7.4 for ImageNet64, 3.8 for\nCIFAR10). Finally we tease apart the method through extended ablations. The\nPyTorch implementation will be released soon.\n","authors":["David Berthelot","Arnaud Autef","Jierui Lin","Dian Ang Yap","Shuangfei Zhai","Siyuan Hu","Daniel Zheng","Walter Talbot","Eric Gu"],"pdf_url":"https://arxiv.org/pdf/2303.04248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2004.05209v2","updated":"2023-03-07T21:42:54Z","published":"2020-04-10T19:31:57Z","title":"Estimating a Brain Network Predictive of Stress and Genotype with\n  Supervised Autoencoders","summary":"  Targeted stimulation of the brain has the potential to treat mental\nillnesses. We propose an approach to help design the stimulation protocol by\nidentifying electrical dynamics across many brain regions that relate to\nillness states. We model multi-region electrical activity as a superposition of\nactivity from latent networks, where the weights on the latent networks relate\nto an outcome of interest. In order to improve on drawbacks of latent factor\nmodeling in this context, we focus on supervised autoencoders (SAEs), which can\nimprove predictive performance while maintaining a generative model. We explain\nwhy SAEs yield improved predictions, describe the distributional assumptions\nunder which SAEs are an appropriate modeling choice, and provide modeling\nconstraints to ensure biological relevance of the learned network. We use the\nanalysis strategy to find a network associated with stress that characterizes a\ngenotype associated with bipolar disorder. This discovered network aligns with\na previously used stimulation technique, providing experimental validation of\nour approach.\n","authors":["Austin Talbot","David Dunson","Kafui Dzirasa","David Carlson"],"pdf_url":"https://arxiv.org/pdf/2004.05209v2.pdf","comment":"43 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.04245v1","updated":"2023-03-07T21:42:17Z","published":"2023-03-07T21:42:17Z","title":"How Do Transformers Learn Topic Structure: Towards a Mechanistic\n  Understanding","summary":"  While the successes of transformers across many domains are indisputable,\naccurate understanding of the learning mechanics is still largely lacking.\nTheir capabilities have been probed on benchmarks which include a variety of\nstructured and reasoning tasks -- but mathematical understanding is lagging\nsubstantially behind. Recent lines of work have begun studying representational\naspects of this question: that is, the size/depth/complexity of attention-based\nnetworks to perform certain tasks. However, there is no guarantee the learning\ndynamics will converge to the constructions proposed. In our paper, we provide\nfine-grained mechanistic understanding of how transformers learn \"semantic\nstructure\", understood as capturing co-occurrence structure of words.\nPrecisely, we show, through a combination of experiments on synthetic data\nmodeled by Latent Dirichlet Allocation (LDA), Wikipedia data, and mathematical\nanalysis that the embedding layer and the self-attention layer encode the\ntopical structure. In the former case, this manifests as higher average inner\nproduct of embeddings between same-topic words. In the latter, it manifests as\nhigher average pairwise attention between same-topic words. The mathematical\nresults involve several assumptions to make the analysis tractable, which we\nverify on data, and might be of independent interest as well.\n","authors":["Yuchen Li","Yuanzhi Li","Andrej Risteski"],"pdf_url":"https://arxiv.org/pdf/2303.04245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08917v3","updated":"2023-03-07T21:34:59Z","published":"2022-06-17T17:54:10Z","title":"The Open Catalyst 2022 (OC22) Dataset and Challenges for Oxide\n  Electrocatalysts","summary":"  The development of machine learning models for electrocatalysts requires a\nbroad set of training data to enable their use across a wide variety of\nmaterials. One class of materials that currently lacks sufficient training data\nis oxides, which are critical for the development of OER catalysts. To address\nthis, we developed the OC22 dataset, consisting of 62,331 DFT relaxations\n(~9,854,504 single point calculations) across a range of oxide materials,\ncoverages, and adsorbates. We define generalized total energy tasks that enable\nproperty prediction beyond adsorption energies; we test baseline performance of\nseveral graph neural networks; and we provide pre-defined dataset splits to\nestablish clear benchmarks for future efforts. In the most general task,\nGemNet-OC sees a ~36% improvement in energy predictions when combining the\nchemically dissimilar OC20 and OC22 datasets via fine-tuning. Similarly, we\nachieved a ~19% improvement in total energy predictions on OC20 and a ~9%\nimprovement in force predictions in OC22 when using joint training. We\ndemonstrate the practical utility of a top performing model by capturing\nliterature adsorption energies and important OER scaling relationships. We\nexpect OC22 to provide an important benchmark for models seeking to incorporate\nintricate long-range electrostatic and magnetic interactions in oxide surfaces.\nDataset and baseline models are open sourced, and a public leaderboard is\navailable to encourage continued community developments on the total energy\ntasks and data.\n","authors":["Richard Tran","Janice Lan","Muhammed Shuaibi","Brandon M. Wood","Siddharth Goyal","Abhishek Das","Javier Heras-Domingo","Adeesh Kolluru","Ammar Rizvi","Nima Shoghi","Anuroop Sriram","Felix Therrien","Jehad Abed","Oleksandr Voznyy","Edward H. Sargent","Zachary Ulissi","C. Lawrence Zitnick"],"pdf_url":"https://arxiv.org/pdf/2206.08917v3.pdf","comment":"50 pages, 14 figures"},{"id":"http://arxiv.org/abs/2209.09211v2","updated":"2023-03-07T21:03:26Z","published":"2022-09-19T17:26:32Z","title":"Neural Collapse with Normalized Features: A Geometric Analysis over the\n  Riemannian Manifold","summary":"  When training overparameterized deep networks for classification tasks, it\nhas been widely observed that the learned features exhibit a so-called \"neural\ncollapse\" phenomenon. More specifically, for the output features of the\npenultimate layer, for each class the within-class features converge to their\nmeans, and the means of different classes exhibit a certain tight frame\nstructure, which is also aligned with the last layer's classifier. As feature\nnormalization in the last layer becomes a common practice in modern\nrepresentation learning, in this work we theoretically justify the neural\ncollapse phenomenon for normalized features. Based on an unconstrained feature\nmodel, we simplify the empirical loss function in a multi-class classification\ntask into a nonconvex optimization problem over the Riemannian manifold by\nconstraining all features and classifiers over the sphere. In this context, we\nanalyze the nonconvex landscape of the Riemannian optimization problem over the\nproduct of spheres, showing a benign global landscape in the sense that the\nonly global minimizers are the neural collapse solutions while all other\ncritical points are strict saddles with negative curvature. Experimental\nresults on practical deep networks corroborate our theory and demonstrate that\nbetter representations can be learned faster via feature normalization.\n","authors":["Can Yaras","Peng Wang","Zhihui Zhu","Laura Balzano","Qing Qu"],"pdf_url":"https://arxiv.org/pdf/2209.09211v2.pdf","comment":"The first two authors contributed to this work equally; 38 pages, 13\n  figures. Accepted at NeurIPS'22"},{"id":"http://arxiv.org/abs/2103.05243v3","updated":"2023-03-07T20:54:33Z","published":"2021-03-09T06:24:59Z","title":"On the Generalization Power of Overfitted Two-Layer Neural Tangent\n  Kernel Models","summary":"  In this paper, we study the generalization performance of min $\\ell_2$-norm\noverfitting solutions for the neural tangent kernel (NTK) model of a two-layer\nneural network with ReLU activation that has no bias term. We show that,\ndepending on the ground-truth function, the test error of overfitted NTK models\nexhibits characteristics that are different from the \"double-descent\" of other\noverparameterized linear models with simple Fourier or Gaussian features.\nSpecifically, for a class of learnable functions, we provide a new upper bound\nof the generalization error that approaches a small limiting value, even when\nthe number of neurons $p$ approaches infinity. This limiting value further\ndecreases with the number of training samples $n$. For functions outside of\nthis class, we provide a lower bound on the generalization error that does not\ndiminish to zero even when $n$ and $p$ are both large.\n","authors":["Peizhong Ju","Xiaojun Lin","Ness B. Shroff"],"pdf_url":"https://arxiv.org/pdf/2103.05243v3.pdf","comment":"Published in ICML21. This version fixes an error of Lemma 31 and\n  other parts affected by this error. The main results remain the same except\n  some small changes on certain coefficients of Eq.(9)"},{"id":"http://arxiv.org/abs/2206.06169v2","updated":"2023-03-07T20:46:58Z","published":"2022-06-13T13:56:40Z","title":"Causal Representation Learning for Instantaneous and Temporal Effects in\n  Interactive Systems","summary":"  Causal representation learning is the task of identifying the underlying\ncausal variables and their relations from high-dimensional observations, such\nas images. Recent work has shown that one can reconstruct the causal variables\nfrom temporal sequences of observations under the assumption that there are no\ninstantaneous causal relations between them. In practical applications,\nhowever, our measurement or frame rate might be slower than many of the causal\neffects. This effectively creates \"instantaneous\" effects and invalidates\nprevious identifiability results. To address this issue, we propose iCITRIS, a\ncausal representation learning method that allows for instantaneous effects in\nintervened temporal sequences when intervention targets can be observed, e.g.,\nas actions of an agent. iCITRIS identifies the potentially multidimensional\ncausal variables from temporal observations, while simultaneously using a\ndifferentiable causal discovery method to learn their causal graph. In\nexperiments on three datasets of interactive systems, iCITRIS accurately\nidentifies the causal variables and their causal graph.\n","authors":["Phillip Lippe","Sara Magliacane","Sindy Löwe","Yuki M. Asano","Taco Cohen","Efstratios Gavves"],"pdf_url":"https://arxiv.org/pdf/2206.06169v2.pdf","comment":"Published at International Conference on Learning Representations\n  (ICLR), 2023"},{"id":"http://arxiv.org/abs/2303.04231v1","updated":"2023-03-07T20:45:15Z","published":"2023-03-07T20:45:15Z","title":"A topological classifier to characterize brain states: When shape\n  matters more than variance","summary":"  Despite the remarkable accuracies attained by machine learning classifiers to\nseparate complex datasets in a supervised fashion, most of their operation\nfalls short to provide an informed intuition about the structure of data, and,\nwhat is more important, about the phenomena being characterized by the given\ndatasets. By contrast, topological data analysis (TDA) is devoted to study the\nshape of data clouds by means of persistence descriptors and provides a\nquantitative characterization of specific topological features of the dataset\nunder scrutiny.\n  In this article we introduce a novel TDA-based classifier that works on the\nprinciple of assessing quantifiable changes on topological metrics caused by\nthe addition of new input to a subset of data. We used this classifier with a\nhigh-dimensional electro-encephalographic (EEG) dataset recorded from eleven\nparticipants during a decision-making experiment in which three motivational\nstates were induced through a manipulation of social pressure. After processing\na band-pass filtered version of EEG signals, we calculated silhouettes from\npersistence diagrams associated with each motivated state, and classified\nunlabeled signals according to their impact on each reference silhouette. Our\nresults show that in addition to providing accuracies within the range of those\nof a nearest neighbour classifier, the TDA classifier provides formal intuition\nof the structure of the dataset as well as an estimate of its intrinsic\ndimension. Towards this end, we incorporated dimensionality reduction methods\nto our procedure and found that the accuracy of our TDA classifier is generally\nnot sensitive to explained variance but rather to shape, contrary to what\nhappens with most machine learning classifiers.\n","authors":["Aina Ferrà","Gloria Cecchini","Fritz-Pere Nobbe Fisas","Carles Casacuberta","Ignasi Cos"],"pdf_url":"https://arxiv.org/pdf/2303.04231v1.pdf","comment":"21 pages, 13 figures"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2303.04143v1","updated":"2023-03-07T18:56:59Z","published":"2023-03-07T18:56:59Z","title":"Can We Scale Transformers to Predict Parameters of Diverse ImageNet\n  Models?","summary":"  Pretraining a neural network on a large dataset is becoming a cornerstone in\nmachine learning that is within the reach of only a few communities with\nlarge-resources. We aim at an ambitious goal of democratizing pretraining.\nTowards that goal, we train and release a single neural network that can\npredict high quality ImageNet parameters of other neural networks. By using\npredicted parameters for initialization we are able to boost training of\ndiverse ImageNet models available in PyTorch. When transferred to other\ndatasets, models initialized with predicted parameters also converge faster and\nreach competitive final performance.\n","authors":["Boris Knyazev","Doha Hwang","Simon Lacoste-Julien"],"pdf_url":"https://arxiv.org/pdf/2303.04143v1.pdf","comment":"Code and models are available at\n  https://github.com/SamsungSAILMontreal/ghn3"},{"id":"http://arxiv.org/abs/2303.04142v1","updated":"2023-03-07T18:56:52Z","published":"2023-03-07T18:56:52Z","title":"From Copilot to Pilot: Towards AI Supported Software Development","summary":"  AI-supported programming has arrived, as shown by the introduction and\nsuccesses of large language models for code, such as Copilot/Codex\n(Github/OpenAI) and AlphaCode (DeepMind). Above human average performance on\nprogramming challenges is now possible. However, software engineering is much\nmore than solving programming contests. Moving beyond code completion to\nAI-supported software engineering will require an AI system that can, among\nother things, understand how to avoid code smells, to follow language idioms,\nand eventually (maybe!) propose rational software designs. In this study, we\nexplore the current limitations of AI-supported code completion tools like\nCopilot and offer a simple taxonomy for understanding the classification of\nAI-supported code completion tools in this space. We first perform an\nexploratory study on Copilot's code suggestions for language idioms and code\nsmells. Copilot does not follow language idioms and avoid code smells in most\nof our test scenarios. We then conduct additional investigation to determine\nthe current boundaries of AI-supported code completion tools like Copilot by\nintroducing a taxonomy of software abstraction hierarchies where 'basic\nprogramming functionality' such as code compilation and syntax checking is at\nthe least abstract level, software architecture analysis and design are at the\nmost abstract level. We conclude by providing a discussion on challenges for\nfuture development of AI-supported code completion tools to reach the design\nlevel of abstraction in our taxonomy.\n","authors":["Rohith Pudari","Neil A. Ernst"],"pdf_url":"https://arxiv.org/pdf/2303.04142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04141v1","updated":"2023-03-07T18:56:50Z","published":"2023-03-07T18:56:50Z","title":"Toward Defining a Domain Complexity Measure Across Domains","summary":"  Artificial Intelligence (AI) systems planned for deployment in real-world\napplications frequently are researched and developed in closed simulation\nenvironments where all variables are controlled and known to the simulator or\nlabeled benchmark datasets are used. Transition from these simulators,\ntestbeds, and benchmark datasets to more open-world domains poses significant\nchallenges to AI systems, including significant increases in the complexity of\nthe domain and the inclusion of real-world novelties; the open-world\nenvironment contains numerous out-of-distribution elements that are not part in\nthe AI systems' training set. Here, we propose a path to a general,\ndomain-independent measure of domain complexity level. We distinguish two\naspects of domain complexity: intrinsic and extrinsic. The intrinsic domain\ncomplexity is the complexity that exists by itself without any action or\ninteraction from an AI agent performing a task on that domain. This is an\nagent-independent aspect of the domain complexity. The extrinsic domain\ncomplexity is agent- and task-dependent. Intrinsic and extrinsic elements\ncombined capture the overall complexity of the domain. We frame the components\nthat define and impact domain complexity levels in a domain-independent light.\nDomain-independent measures of complexity could enable quantitative predictions\nof the difficulty posed to AI systems when transitioning from one testbed or\nenvironment to another, when facing out-of-distribution data in open-world\ntasks, and when navigating the rapidly expanding solution and search spaces\nencountered in open-world domains.\n","authors":["Katarina Doctor","Christine Task","Eric Kildebeck","Mayank Kejriwal","Lawrence Holder","Russell Leong"],"pdf_url":"https://arxiv.org/pdf/2303.04141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04134v1","updated":"2023-03-07T18:49:13Z","published":"2023-03-07T18:49:13Z","title":"A Hybrid Architecture for Out of Domain Intent Detection and Intent\n  Discovery","summary":"  Intent Detection is one of the tasks of the Natural Language Understanding\n(NLU) unit in task-oriented dialogue systems. Out of Scope (OOS) and Out of\nDomain (OOD) inputs may run these systems into a problem. On the other side, a\nlabeled dataset is needed to train a model for Intent Detection in\ntask-oriented dialogue systems. The creation of a labeled dataset is\ntime-consuming and needs human resources. The purpose of this article is to\naddress mentioned problems. The task of identifying OOD/OOS inputs is named\nOOD/OOS Intent Detection. Also, discovering new intents and pseudo-labeling of\nOOD inputs is well known by Intent Discovery. In OOD intent detection part, we\nmake use of a Variational Autoencoder to distinguish between known and unknown\nintents independent of input data distribution. After that, an unsupervised\nclustering method is used to discover different unknown intents underlying\nOOD/OOS inputs. We also apply a non-linear dimensionality reduction on OOD/OOS\nrepresentations to make distances between representations more meaning full for\nclustering. Our results show that the proposed model for both OOD/OOS Intent\nDetection and Intent Discovery achieves great results and passes baselines in\nEnglish and Persian languages.\n","authors":["Masoud Akbari","Ali Mohades","M. Hassan Shirali-Shahreza"],"pdf_url":"https://arxiv.org/pdf/2303.04134v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04132v1","updated":"2023-03-07T18:48:55Z","published":"2023-03-07T18:48:55Z","title":"Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and\n  the Case of Information Extraction","summary":"  Large language models (LLMs) show great potential for synthetic data\ngeneration. This work shows that useful data can be synthetically generated\neven for tasks that cannot be solved directly by the LLM: we show that, for\nproblems with structured outputs, it is possible to prompt an LLM to perform\nthe task in the opposite direction, to generate plausible text for the target\nstructure. Leveraging the asymmetry in task difficulty makes it possible to\nproduce large-scale, high-quality data for complex tasks. We demonstrate the\neffectiveness of this approach on closed information extraction, where\ncollecting ground-truth data is challenging, and no satisfactory dataset exists\nto date. We synthetically generate a dataset of 1.8M data points, demonstrate\nits superior quality compared to existing datasets in a human evaluation and\nuse it to finetune small models (220M and 770M parameters). The models we\nintroduce, SynthIE, outperform existing baselines of comparable size with a\nsubstantial gap of 57 and 79 absolute points in micro and macro F1,\nrespectively. Code, data, and models are available at\nhttps://github.com/epfl-dlab/SynthIE.\n","authors":["Martin Josifoski","Marija Sakota","Maxime Peyrard","Robert West"],"pdf_url":"https://arxiv.org/pdf/2303.04132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04129v1","updated":"2023-03-07T18:44:07Z","published":"2023-03-07T18:44:07Z","title":"Foundation Models for Decision Making: Problems, Methods, and\n  Opportunities","summary":"  Foundation models pretrained on diverse data at scale have demonstrated\nextraordinary capabilities in a wide range of vision and language tasks. When\nsuch models are deployed in real world environments, they inevitably interface\nwith other entities and agents. For example, language models are often used to\ninteract with human beings through dialogue, and visual perception models are\nused to autonomously navigate neighborhood streets. In response to these\ndevelopments, new paradigms are emerging for training foundation models to\ninteract with other agents and perform long-term reasoning. These paradigms\nleverage the existence of ever-larger datasets curated for multimodal,\nmultitask, and generalist interaction. Research at the intersection of\nfoundation models and decision making holds tremendous promise for creating\npowerful new systems that can interact effectively across a diverse range of\napplications such as dialogue, autonomous driving, healthcare, education, and\nrobotics. In this manuscript, we examine the scope of foundation models for\ndecision making, and provide conceptual tools and technical background for\nunderstanding the problem space and exploring new research directions. We\nreview recent approaches that ground foundation models in practical decision\nmaking applications through a variety of methods such as prompting, conditional\ngenerative modeling, planning, optimal control, and reinforcement learning, and\ndiscuss common challenges and open problems in the field.\n","authors":["Sherry Yang","Ofir Nachum","Yilun Du","Jason Wei","Pieter Abbeel","Dale Schuurmans"],"pdf_url":"https://arxiv.org/pdf/2303.04129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04117v1","updated":"2023-03-07T18:28:45Z","published":"2023-03-07T18:28:45Z","title":"Validation of a Hospital Digital Twin with Machine Learning","summary":"  Recently there has been a surge of interest in developing Digital Twins of\nprocess flows in healthcare to better understand bottlenecks and areas of\nimprovement. A key challenge is in the validation process. We describe a work\nin progress for a digital twin using an agent based simulation model for\ndetermining bed turnaround time for patients in hospitals. We employ a strategy\nusing machine learning for validating the model and implementing sensitivity\nanalysis.\n","authors":["Muhammad Aurangzeb Ahmad","Vijay Chickarmane","Farinaz Ali Sabzpour","Nima Shariari","Taposh Roy"],"pdf_url":"https://arxiv.org/pdf/2303.04117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.11299v6","updated":"2023-03-07T18:26:49Z","published":"2021-06-21T17:56:07Z","title":"Boundary Graph Neural Networks for 3D Simulations","summary":"  The abundance of data has given machine learning considerable momentum in\nnatural sciences and engineering, though modeling of physical processes is\noften difficult. A particularly tough problem is the efficient representation\nof geometric boundaries. Triangularized geometric boundaries are well\nunderstood and ubiquitous in engineering applications. However, it is\nnotoriously difficult to integrate them into machine learning approaches due to\ntheir heterogeneity with respect to size and orientation. In this work, we\nintroduce an effective theory to model particle-boundary interactions, which\nleads to our new Boundary Graph Neural Networks (BGNNs) that dynamically modify\ngraph structures to obey boundary conditions. The new BGNNs are tested on\ncomplex 3D granular flow processes of hoppers, rotating drums and mixers, which\nare all standard components of modern industrial machinery but still have\ncomplicated geometry. BGNNs are evaluated in terms of computational efficiency\nas well as prediction accuracy of particle flows and mixing entropies. BGNNs\nare able to accurately reproduce 3D granular flows within simulation\nuncertainties over hundreds of thousands of simulation timesteps. Most notably,\nin our experiments, particles stay within the geometric objects without using\nhandcrafted conditions or restrictions.\n","authors":["Andreas Mayr","Sebastian Lehner","Arno Mayrhofer","Christoph Kloss","Sepp Hochreiter","Johannes Brandstetter"],"pdf_url":"https://arxiv.org/pdf/2106.11299v6.pdf","comment":"accepted for presentation at the Thirty-Seventh AAAI Conference on\n  Artificial Intelligence (AAAI-23)"},{"id":"http://arxiv.org/abs/2110.03051v3","updated":"2023-03-07T18:05:45Z","published":"2021-10-06T20:13:57Z","title":"Prior and Posterior Networks: A Survey on Evidential Deep Learning\n  Methods For Uncertainty Estimation","summary":"  Popular approaches for quantifying predictive uncertainty in deep neural\nnetworks often involve distributions over weights or multiple models, for\ninstance via Markov Chain sampling, ensembling, or Monte Carlo dropout. These\ntechniques usually incur overhead by having to train multiple model instances\nor do not produce very diverse predictions. This comprehensive and extensive\nsurvey aims to familiarize the reader with an alternative class of models based\non the concept of Evidential Deep Learning: For unfamiliar data, they aim to\nadmit \"what they don't know\", and fall back onto a prior belief. Furthermore,\nthey allow uncertainty estimation in a single model and forward pass by\nparameterizing distributions over distributions. This survey recapitulates\nexisting works, focusing on the implementation in a classification setting,\nbefore surveying the application of the same paradigm to regression. We also\nreflect on the strengths and weaknesses compared to other existing methods and\nprovide the most fundamental derivations using a unified notation to aid future\nresearch.\n","authors":["Dennis Ulmer","Christian Hardmeier","Jes Frellsen"],"pdf_url":"https://arxiv.org/pdf/2110.03051v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.11171v4","updated":"2023-03-07T17:57:37Z","published":"2022-03-21T17:48:52Z","title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models","summary":"  Chain-of-thought prompting combined with pre-trained large language models\nhas achieved encouraging results on complex reasoning tasks. In this paper, we\npropose a new decoding strategy, self-consistency, to replace the naive greedy\ndecoding used in chain-of-thought prompting. It first samples a diverse set of\nreasoning paths instead of only taking the greedy one, and then selects the\nmost consistent answer by marginalizing out the sampled reasoning paths.\nSelf-consistency leverages the intuition that a complex reasoning problem\ntypically admits multiple different ways of thinking leading to its unique\ncorrect answer. Our extensive empirical evaluation shows that self-consistency\nboosts the performance of chain-of-thought prompting with a striking margin on\na range of popular arithmetic and commonsense reasoning benchmarks, including\nGSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and\nARC-challenge (+3.9%).\n","authors":["Xuezhi Wang","Jason Wei","Dale Schuurmans","Quoc Le","Ed Chi","Sharan Narang","Aakanksha Chowdhery","Denny Zhou"],"pdf_url":"https://arxiv.org/pdf/2203.11171v4.pdf","comment":"Published at ICLR 2023. V2: added PaLM results; V3: added UL2\n  results; V4: camera ready version at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.04096v1","updated":"2023-03-07T17:55:28Z","published":"2023-03-07T17:55:28Z","title":"Mastering Strategy Card Game (Legends of Code and Magic) via End-to-End\n  Policy and Optimistic Smooth Fictitious Play","summary":"  Deep Reinforcement Learning combined with Fictitious Play shows impressive\nresults on many benchmark games, most of which are, however, single-stage. In\ncontrast, real-world decision making problems may consist of multiple stages,\nwhere the observation spaces and the action spaces can be completely different\nacross stages. We study a two-stage strategy card game Legends of Code and\nMagic and propose an end-to-end policy to address the difficulties that arise\nin multi-stage game. We also propose an optimistic smooth fictitious play\nalgorithm to find the Nash Equilibrium for the two-player game. Our approach\nwins double championships of COG2022 competition. Extensive studies verify and\nshow the advancement of our approach.\n","authors":["Wei Xi","Yongxin Zhang","Changnan Xiao","Xuefeng Huang","Shihong Deng","Haowei Liang","Jie Chen","Peng Sun"],"pdf_url":"https://arxiv.org/pdf/2303.04096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04091v1","updated":"2023-03-07T17:52:46Z","published":"2023-03-07T17:52:46Z","title":"Visual Abstraction and Reasoning through Language","summary":"  While Artificial Intelligence (AI) models have achieved human or even\nsuperhuman performance in narrowly defined applications, they still struggle to\nshow signs of broader and more flexible intelligence. The Abstraction and\nReasoning Corpus (ARC), introduced by Fran\\c{c}ois Chollet, aims to assess how\nclose AI systems are to human-like cognitive abilities. Most current approaches\nrely on carefully handcrafted domain-specific languages (DSLs), which are used\nto brute-force solutions to the tasks present in ARC. In this work, we propose\na general framework for solving ARC based on natural language descriptions of\nthe tasks. While not yet beating state-of-the-art DSL models on ARC, we\ndemonstrate the immense potential of our approach hinted at by the ability to\nsolve previously unsolved tasks.\n","authors":["Giacomo Camposampiero","Loic Houmard","Benjamin Estermann","Joël Mathys","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.04091v1.pdf","comment":"The first two authors have contributed equally to this work"},{"id":"http://arxiv.org/abs/2303.04077v1","updated":"2023-03-07T17:39:53Z","published":"2023-03-07T17:39:53Z","title":"Meta-Explore: Exploratory Hierarchical Vision-and-Language Navigation\n  Using Scene Object Spectrum Grounding","summary":"  The main challenge in vision-and-language navigation (VLN) is how to\nunderstand natural-language instructions in an unseen environment. The main\nlimitation of conventional VLN algorithms is that if an action is mistaken, the\nagent fails to follow the instructions or explores unnecessary regions, leading\nthe agent to an irrecoverable path. To tackle this problem, we propose\nMeta-Explore, a hierarchical navigation method deploying an exploitation policy\nto correct misled recent actions. We show that an exploitation policy, which\nmoves the agent toward a well-chosen local goal among unvisited but observable\nstates, outperforms a method which moves the agent to a previously visited\nstate. We also highlight the demand for imagining regretful explorations with\nsemantically meaningful clues. The key to our approach is understanding the\nobject placements around the agent in spectral-domain. Specifically, we present\na novel visual representation, called scene object spectrum (SOS), which\nperforms category-wise 2D Fourier transform of detected objects. Combining\nexploitation policy and SOS features, the agent can correct its path by\nchoosing a promising local goal. We evaluate our method in three VLN\nbenchmarks: R2R, SOON, and REVERIE. Meta-Explore outperforms other baselines\nand shows significant generalization performance. In addition, local goal\nsearch using the proposed spectral-domain SOS features significantly improves\nthe success rate by 17.1% and SPL by 20.6% for the SOON benchmark.\n","authors":["Minyoung Hwang","Jaeyeon Jeong","Minsoo Kim","Yoonseon Oh","Songhwai Oh"],"pdf_url":"https://arxiv.org/pdf/2303.04077v1.pdf","comment":"Accepted by CVPR 2023. Project page:\n  https://rllab-snu.github.io/projects/Meta-Explore/doc.html"},{"id":"http://arxiv.org/abs/2211.09330v3","updated":"2023-03-07T17:20:45Z","published":"2022-11-17T04:37:24Z","title":"ACon$^2$: Adaptive Conformal Consensus for Provable Blockchain Oracles","summary":"  Blockchains with smart contracts are distributed ledger systems that achieve\nblock-state consistency among distributed nodes by only allowing deterministic\noperations of smart contracts. However, the power of smart contracts is enabled\nby interacting with stochastic off-chain data, which in turn opens the\npossibility to undermine the block-state consistency. To address this issue, an\noracle smart contract is used to provide a single consistent source of external\ndata; but, simultaneously, this introduces a single point of failure, which is\ncalled the oracle problem. To address the oracle problem, we propose an\nadaptive conformal consensus (ACon$^2$) algorithm that derives a consensus set\nof data from multiple oracle contracts via the recent advance in online\nuncertainty quantification learning. Interesting, the consensus set provides a\ndesired correctness guarantee under distribution shift and Byzantine\nadversaries. We demonstrate the efficacy of the proposed algorithm on two price\ndatasets and an Ethereum case study. In particular, the Solidity implementation\nof the proposed algorithm shows the potential practicality of the proposed\nalgorithm, implying that online machine learning algorithms are applicable to\naddress security issues in blockchains.\n","authors":["Sangdon Park","Osbert Bastani","Taesoo Kim"],"pdf_url":"https://arxiv.org/pdf/2211.09330v3.pdf","comment":"Accepted to USENIX Security 2023"},{"id":"http://arxiv.org/abs/2303.04048v1","updated":"2023-03-07T16:57:20Z","published":"2023-03-07T16:57:20Z","title":"Is ChatGPT a Good NLG Evaluator? A Preliminary Study","summary":"  Recently, the emergence of ChatGPT has attracted wide attention from the\ncomputational linguistics community. Many prior studies have shown that ChatGPT\nachieves remarkable performance on various NLP tasks in terms of automatic\nevaluation metrics. However, the ability of ChatGPT to serve as an evaluation\nmetric is still underexplored. Considering assessing the quality of NLG models\nis an arduous task and previous statistical metrics notoriously show their poor\ncorrelation with human judgments, we wonder whether ChatGPT is a good NLG\nevaluation metric. In this report, we provide a preliminary meta-evaluation on\nChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT\nas a human evaluator and give task-specific (e.g., summarization) and\naspect-specific (e.g., relevance) instruction to prompt ChatGPT to score the\ngeneration of NLG models. We conduct experiments on three widely-used NLG\nmeta-evaluation datasets (including summarization, story generation and\ndata-to-text tasks). Experimental results show that compared with previous\nautomatic metrics, ChatGPT achieves state-of-the-art or competitive correlation\nwith golden human judgments. We hope our preliminary study could prompt the\nemergence of a general-purposed reliable NLG metric.\n","authors":["Jiaan Wang","Yunlong Liang","Fandong Meng","Haoxiang Shi","Zhixu Li","Jinan Xu","Jianfeng Qu","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.04048v1.pdf","comment":"Technical Report, 8 pages"},{"id":"http://arxiv.org/abs/2209.01535v4","updated":"2023-03-07T16:56:31Z","published":"2022-09-04T05:30:51Z","title":"Towards Optimal and Scalable Evacuation Planning Using Data-driven Agent\n  Based Models","summary":"  Evacuation planning is a crucial part of disaster management where the goal\nis to relocate people to safety and minimize casualties. Every evacuation plan\nhas two essential components: routing and scheduling. However, joint\noptimization of these two components with objectives such as minimizing average\nevacuation time or evacuation completion time, is a computationally hard\nproblem. To approach it, we present MIP-LNS, a scalable optimization method\nthat utilizes heuristic search with mathematical optimization and can optimize\na variety of objective functions. We also present the method MIP-LNS-SIM, where\nwe further combine an agent-based model together with MIP-LNS to more\naccurately estimate the delay on roads due to congestion. We use real-world\nroad network and population data from Harris County in Houston, Texas, and\napply our methods to find evacuation routes and schedule for the area. We show\nthat, within a given time limit, MIP-LNS finds better solutions than existing\nmethods in terms of average evacuation time, evacuation completion time and\noptimality guarantee of the solutions. We also perform experiments with\nMIP-LNS-SIM to show its efficacy in estimating delays in the road network due\nto congestion by using an agent based model. Our results show that MIP-LNS-SIM\ncan find efficient evacuation plans, and at the same time provide an estimate\nof the evacuation completion time for the given plan with a small percent\nerror.\n","authors":["Kazi Ashik Islam","Da Qi Chen","Madhav Marathe","Henning Mortveit","Samarth Swarup","Anil Vullikanti"],"pdf_url":"https://arxiv.org/pdf/2209.01535v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04042v1","updated":"2023-03-07T16:51:24Z","published":"2023-03-07T16:51:24Z","title":"System Theoretic View on Uncertainties","summary":"  The complexity of the operating environment and required technologies for\nhighly automated driving is unprecedented. A different type of threat to safe\noperation besides the fault-error-failure model by Laprie et al. arises in the\nform of performance limitations. We propose a system theoretic approach to\nhandle these and derive a taxonomy based on uncertainty, i.e. lack of\nknowledge, as a root cause. Uncertainty is a threat to the dependability of a\nsystem, as it limits our ability to assess its dependability properties. We\ndistinguish uncertainties by aleatory (inherent to probabilistic models),\nepistemic (lack of model parameter knowledge) and ontological (incompleteness\nof models) in order to determine strategies and methods to cope with them.\nAnalogous to the taxonomy of Laprie et al. we cluster methods into uncertainty\nprevention (use of elements with well-known behavior, avoiding architectures\nprone to emergent behavior, restriction of operational design domain, etc.),\nuncertainty removal (during design time by design of experiment, etc. and after\nrelease by field observation, continuous updates, etc.), uncertainty tolerance\n(use of redundant architectures with diverse uncertainties, uncertainty aware\ndeep learning, etc.) and uncertainty forecasting (estimation of residual\nuncertainty, etc.).\n","authors":["Roman Gansch","Ahmad Adee"],"pdf_url":"https://arxiv.org/pdf/2303.04042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04038v1","updated":"2023-03-07T16:47:35Z","published":"2023-03-07T16:47:35Z","title":"Root Cause Identification for Collective Anomalies in Time Series given\n  an Acyclic Summary Causal Graph with Loops","summary":"  This paper presents an approach for identifying the root causes of collective\nanomalies given observational time series and an acyclic summary causal graph\nwhich depicts an abstraction of causal relations present in a dynamic system at\nits normal regime. The paper first shows how the problem of root cause\nidentification can be divided into many independent subproblems by grouping\nrelated anomalies using d-separation. Further, it shows how, under this\nsetting, some root causes can be found directly from the graph and from the\ntime of appearance of anomalies. Finally, it shows, how the rest of the root\ncauses can be found by comparing direct causal effects in the normal and in the\nanomalous regime. To this end, temporal adaptations of the back-door and the\nsingle-door criterions are introduced. Extensive experiments conducted on both\nsimulated and real-world datasets demonstrate the effectiveness of the proposed\nmethod.\n","authors":["Charles K. Assaad","Imad Ez-zejjari","Lei Zan"],"pdf_url":"https://arxiv.org/pdf/2303.04038v1.pdf","comment":"Proceedings of the 26th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2023, Valencia, Spain"},{"id":"http://arxiv.org/abs/2303.04030v1","updated":"2023-03-07T16:43:05Z","published":"2023-03-07T16:43:05Z","title":"PyXAB -- A Python Library for $\\mathcal{X}$-Armed Bandit and Online\n  Blackbox Optimization Algorithms","summary":"  We introduce a Python open-source library for $\\mathcal{X}$-armed bandit and\nonline blackbox optimization named PyXAB. PyXAB contains the implementations\nfor more than 10 $\\mathcal{X}$-armed bandit algorithms, such as HOO, StoSOO,\nHCT, and the most recent works GPO and VHCT. PyXAB also provides the most\ncommonly-used synthetic objectives to evaluate the performance of different\nalgorithms and the various choices of the hierarchical partitions on the\nparameter space. The online documentation for PyXAB includes clear instructions\nfor installation, straight-forward examples, detailed feature descriptions, and\na complete reference of the API. PyXAB is released under the MIT license in\norder to encourage both academic and industrial usage. The library can be\ndirectly installed from PyPI with its source code available at\nhttps://github.com/WilliamLwj/PyXAB\n","authors":["Wenjie Li","Haoze Li","Jean Honorio","Qifan Song"],"pdf_url":"https://arxiv.org/pdf/2303.04030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.12053v2","updated":"2023-03-07T16:41:02Z","published":"2022-12-22T22:05:16Z","title":"On Calibrating Semantic Segmentation Models: Analyses and An Algorithm","summary":"  We study the problem of semantic segmentation calibration. For image\nclassification, lots of existing solutions are proposed to alleviate model\nmiscalibration of confidence. However, to date, confidence calibration research\non semantic segmentation is still limited. We provide a systematic study on the\ncalibration of semantic segmentation models and propose a simple yet effective\napproach. First, we find that model capacity, crop size, multi-scale testing,\nand prediction correctness have impact on calibration. Among them, prediction\ncorrectness, especially misprediction, is more important to miscalibration due\nto over-confidence. Next, we propose a simple, unifying, and effective\napproach, namely selective scaling, by separating correct/incorrect prediction\nfor scaling and more focusing on misprediction logit smoothing. Then, we study\npopular existing calibration methods and compare them with selective scaling on\nsemantic segmentation calibration. We conduct extensive experiments with a\nvariety of benchmarks on both in-domain and domain-shift calibration, and show\nthat selective scaling consistently outperforms other methods.\n","authors":["Dongdong Wang","Boqing Gong","Liqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.12053v2.pdf","comment":"Accepted to CVPR2023 (8 pages, 4 figures)"},{"id":"http://arxiv.org/abs/2111.11485v2","updated":"2023-03-07T16:34:59Z","published":"2021-11-22T19:24:57Z","title":"A Free Lunch from the Noise: Provable and Practical Exploration for\n  Representation Learning","summary":"  Representation learning lies at the heart of the empirical success of deep\nlearning for dealing with the curse of dimensionality. However, the power of\nrepresentation learning has not been fully exploited yet in reinforcement\nlearning (RL), due to i), the trade-off between expressiveness and\ntractability; and ii), the coupling between exploration and representation\nlearning. In this paper, we first reveal the fact that under some noise\nassumption in the stochastic control model, we can obtain the linear spectral\nfeature of its corresponding Markov transition operator in closed-form for\nfree. Based on this observation, we propose Spectral Dynamics Embedding\n(SPEDE), which breaks the trade-off and completes optimistic exploration for\nrepresentation learning by exploiting the structure of the noise. We provide\nrigorous theoretical analysis of SPEDE, and demonstrate the practical superior\nperformance over the existing state-of-the-art empirical algorithms on several\nbenchmarks.\n","authors":["Tongzheng Ren","Tianjun Zhang","Csaba Szepesvári","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2111.11485v2.pdf","comment":"UAI 2022. The first two authors contribute equally"},{"id":"http://arxiv.org/abs/2211.09019v2","updated":"2023-03-07T16:29:49Z","published":"2022-11-16T16:26:48Z","title":"Learning Reward Functions for Robotic Manipulation by Observing Humans","summary":"  Observing a human demonstrator manipulate objects provides a rich, scalable\nand inexpensive source of data for learning robotic policies. However,\ntransferring skills from human videos to a robotic manipulator poses several\nchallenges, not least a difference in action and observation spaces. In this\nwork, we use unlabeled videos of humans solving a wide range of manipulation\ntasks to learn a task-agnostic reward function for robotic manipulation\npolicies. Thanks to the diversity of this training data, the learned reward\nfunction sufficiently generalizes to image observations from a previously\nunseen robot embodiment and environment to provide a meaningful prior for\ndirected exploration in reinforcement learning. We propose two methods for\nscoring states relative to a goal image: through direct temporal regression,\nand through distances in an embedding space obtained with time-contrastive\nlearning. By conditioning the function on a goal image, we are able to reuse\none model across a variety of tasks. Unlike prior work on leveraging human\nvideos to teach robots, our method, Human Offline Learned Distances (HOLD)\nrequires neither a priori data from the robot environment, nor a set of\ntask-specific human demonstrations, nor a predefined notion of correspondence\nacross morphologies, yet it is able to accelerate training of several\nmanipulation tasks on a simulated robot arm compared to using only a sparse\nreward obtained from task completion.\n","authors":["Minttu Alakuijala","Gabriel Dulac-Arnold","Julien Mairal","Jean Ponce","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2211.09019v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04012v1","updated":"2023-03-07T16:25:52Z","published":"2023-03-07T16:25:52Z","title":"Exploration via Epistemic Value Estimation","summary":"  How to efficiently explore in reinforcement learning is an open problem. Many\nexploration algorithms employ the epistemic uncertainty of their own value\npredictions -- for instance to compute an exploration bonus or upper confidence\nbound. Unfortunately the required uncertainty is difficult to estimate in\ngeneral with function approximation.\n  We propose epistemic value estimation (EVE): a recipe that is compatible with\nsequential decision making and with neural network function approximators. It\nequips agents with a tractable posterior over all their parameters from which\nepistemic value uncertainty can be computed efficiently.\n  We use the recipe to derive an epistemic Q-Learning agent and observe\ncompetitive performance on a series of benchmarks. Experiments confirm that the\nEVE recipe facilitates efficient exploration in hard exploration tasks.\n","authors":["Simon Schmitt","John Shawe-Taylor","Hado van Hasselt"],"pdf_url":"https://arxiv.org/pdf/2303.04012v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03961v1","updated":"2023-03-07T15:04:49Z","published":"2023-03-07T15:04:49Z","title":"An End-to-End Approach for Online Decision Mining and Decision Drift\n  Analysis in Process-Aware Information Systems: Extended Version","summary":"  Decision mining enables the discovery of decision rules from event logs or\nstreams, and constitutes an important part of in-depth analysis and\noptimisation of business processes. So far, decision mining has been merely\napplied in an ex-post way resulting in a snapshot of decision rules for the\ngiven chunk of log data. Online decision mining, by contrast, enables\ncontinuous monitoring of decision rule evolution and decision drift. Hence this\npaper presents an end-to-end approach for the discovery as well as monitoring\nof decision points and the corresponding decision rules during runtime,\nbridging the gap between online control flow discovery and decision mining. The\napproach provides automatic decision support for process-aware information\nsystems with efficient decision drift discovery and monitoring. For monitoring,\nnot only the performance, in terms of accuracy, of decision rules is taken into\naccount, but also the occurrence of data elements and changes in branching\nfrequency. The paper provides two algorithms, which are evaluated on four\nsynthetic and one real-life data set, showing feasibility and applicability of\nthe approach. Overall, the approach fosters the understanding of decisions in\nbusiness processes and hence contributes to an improved human-process\ninteraction.\n","authors":["Beate Scheibel","Stefanie Rinderle-Ma"],"pdf_url":"https://arxiv.org/pdf/2303.03961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08231v2","updated":"2023-03-07T14:59:28Z","published":"2023-02-16T11:28:30Z","title":"3M3D: Multi-view, Multi-path, Multi-representation for 3D Object\n  Detection","summary":"  3D visual perception tasks based on multi-camera images are essential for\nautonomous driving systems. Latest work in this field performs 3D object\ndetection by leveraging multi-view images as an input and iteratively enhancing\nobject queries (object proposals) by cross-attending multi-view features.\nHowever, individual backbone features are not updated with multi-view features\nand it stays as a mere collection of the output of the single-image backbone\nnetwork. Therefore we propose 3M3D: A Multi-view, Multi-path,\nMulti-representation for 3D Object Detection where we update both multi-view\nfeatures and query features to enhance the representation of the scene in both\nfine panoramic view and coarse global view. Firstly, we update multi-view\nfeatures by multi-view axis self-attention. It will incorporate panoramic\ninformation in the multi-view features and enhance understanding of the global\nscene. Secondly, we update multi-view features by self-attention of the ROI\n(Region of Interest) windows which encodes local finer details in the features.\nIt will help exchange the information not only along the multi-view axis but\nalso along the other spatial dimension. Lastly, we leverage the fact of\nmulti-representation of queries in different domains to further boost the\nperformance. Here we use sparse floating queries along with dense BEV (Bird's\nEye View) queries, which are later post-processed to filter duplicate\ndetections. Moreover, we show performance improvements on nuScenes benchmark\ndataset on top of our baselines.\n","authors":["Jongwoo Park","Apoorv Singh","Varun Bankiti"],"pdf_url":"https://arxiv.org/pdf/2302.08231v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03943v1","updated":"2023-03-07T14:52:29Z","published":"2023-03-07T14:52:29Z","title":"CUREE: A Curious Underwater Robot for Ecosystem Exploration","summary":"  The current approach to exploring and monitoring complex underwater\necosystems, such as coral reefs, is to conduct surveys using diver-held or\nstatic cameras, or deploying sensor buoys. These approaches often fail to\ncapture the full variation and complexity of interactions between different\nreef organisms and their habitat. The CUREE platform presented in this paper\nprovides a unique set of capabilities in the form of robot behaviors and\nperception algorithms to enable scientists to explore different aspects of an\necosystem. Examples of these capabilities include low-altitude visual surveys,\nsoundscape surveys, habitat characterization, and animal following. We\ndemonstrate these capabilities by describing two field deployments on coral\nreefs in the US Virgin Islands. In the first deployment, we show that CUREE can\nidentify the preferred habitat type of snapping shrimp in a reef through a\ncombination of a visual survey, habitat characterization, and a soundscape\nsurvey. In the second deployment, we demonstrate CUREE's ability to follow\narbitrary animals by separately following a barracuda and stingray for several\nminutes each in midwater and benthic environments, respectively.\n","authors":["ogesh Girdhar","Nathan McGuire","Levi Cai","Stewart Jamieson","Seth McCammon","Brian Claus","John E. San Soucie","Jessica E. Todd","T. Aran Mooney"],"pdf_url":"https://arxiv.org/pdf/2303.03943v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2303.03932v1","updated":"2023-03-07T14:38:28Z","published":"2023-03-07T14:38:28Z","title":"FFT-based Dynamic Token Mixer for Vision","summary":"  Multi-head-self-attention (MHSA)-equipped models have achieved notable\nperformance in computer vision. Their computational complexity is proportional\nto quadratic numbers of pixels in input feature maps, resulting in slow\nprocessing, especially when dealing with high-resolution images. New types of\ntoken-mixer are proposed as an alternative to MHSA to circumvent this problem:\nan FFT-based token-mixer, similar to MHSA in global operation but with lower\ncomputational complexity. However, despite its attractive properties, the\nFFT-based token-mixer has not been carefully examined in terms of its\ncompatibility with the rapidly evolving MetaFormer architecture. Here, we\npropose a novel token-mixer called dynamic filter and DFFormer and CDFFormer,\nimage recognition models using dynamic filters to close the gaps above.\nCDFFormer achieved a Top-1 accuracy of 85.0%, close to the hybrid architecture\nwith convolution and MHSA. Other wide-ranging experiments and analysis,\nincluding object detection and semantic segmentation, demonstrate that they are\ncompetitive with state-of-the-art architectures; Their throughput and memory\nefficiency when dealing with high-resolution image recognition is convolution\nand MHSA, not much different from ConvFormer, and far superior to CAFormer. Our\nresults indicate that the dynamic filter is one of the token-mixer options that\nshould be seriously considered. The code is available at\nhttps://github.com/okojoalg/dfformer\n","authors":["Yuki Tatsunami","Masato Taki"],"pdf_url":"https://arxiv.org/pdf/2303.03932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00305v2","updated":"2023-03-07T14:35:33Z","published":"2022-10-01T16:01:53Z","title":"LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph\n  Embeddings","summary":"  Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. Text-based KG embeddings\ncan represent entities by encoding descriptions with pre-trained language\nmodels, but no open-sourced library is specifically designed for KGs with PLMs\nat present. In this paper, we present LambdaKG, a library for KGE that equips\nwith many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and\nsupports various tasks (e.g., knowledge graph completion, question answering,\nrecommendation, and knowledge probing). LambdaKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at\nhttp://deepke.zjukg.cn/lambdakg.mp4 and long-term maintenance.\n","authors":["Xin Xie","Zhoubo Li","Xiaohan Wang","Yuqi Zhu","Ningyu Zhang","Jintian Zhang","Siyuan Cheng","Bozhong Tian","Shumin Deng","Feiyu Xiong","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00305v2.pdf","comment":"Work in progress and the project website is\n  https://zjunlp.github.io/project/promptkg/"},{"id":"http://arxiv.org/abs/2303.03926v1","updated":"2023-03-07T14:31:55Z","published":"2023-03-07T14:31:55Z","title":"Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec\n  Language Modeling","summary":"  We propose a cross-lingual neural codec language model, VALL-E X, for\ncross-lingual speech synthesis. Specifically, we extend VALL-E and train a\nmulti-lingual conditional codec language model to predict the acoustic token\nsequences of the target language speech by using both the source language\nspeech and the target language text as prompts. VALL-E X inherits strong\nin-context learning capabilities and can be applied for zero-shot cross-lingual\ntext-to-speech synthesis and zero-shot speech-to-speech translation tasks.\nExperimental results show that it can generate high-quality speech in the\ntarget language via just one speech utterance in the source language as a\nprompt while preserving the unseen speaker's voice, emotion, and acoustic\nenvironment. Moreover, VALL-E X effectively alleviates the foreign accent\nproblems, which can be controlled by a language ID. Audio samples are available\nat \\url{https://aka.ms/vallex}.\n","authors":["Ziqiang Zhang","Long Zhou","Chengyi Wang","Sanyuan Chen","Yu Wu","Shujie Liu","Zhuo Chen","Yanqing Liu","Huaming Wang","Jinyu Li","Lei He","Sheng Zhao","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2303.03926v1.pdf","comment":"We encourage readers to listen to the audio samples on our demo page:\n  \\url{https://aka.ms/vallex}"},{"id":"http://arxiv.org/abs/2303.03915v1","updated":"2023-03-07T14:25:44Z","published":"2023-03-07T14:25:44Z","title":"The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset","summary":"  As language models grow ever larger, the need for large-scale high-quality\ntext datasets has never been more pressing, especially in multilingual\nsettings. The BigScience workshop, a 1-year international and multidisciplinary\ninitiative, was formed with the goal of researching and training large language\nmodels as a values-driven undertaking, putting issues of ethics, harm, and\ngovernance in the foreground. This paper documents the data creation and\ncuration efforts undertaken by BigScience to assemble the Responsible\nOpen-science Open-collaboration Text Sources (ROOTS) corpus, a 1.6TB dataset\nspanning 59 languages that was used to train the 176-billion-parameter\nBigScience Large Open-science Open-access Multilingual (BLOOM) language model.\nWe further release a large initial subset of the corpus and analyses thereof,\nand hope to empower large-scale monolingual and multilingual modeling projects\nwith both the data and the processing tools, as well as stimulate research\naround this large multilingual corpus.\n","authors":["Hugo Laurençon","Lucile Saulnier","Thomas Wang","Christopher Akiki","Albert Villanova del Moral","Teven Le Scao","Leandro Von Werra","Chenghao Mou","Eduardo González Ponferrada","Huu Nguyen","Jörg Frohberg","Mario Šaško","Quentin Lhoest","Angelina McMillan-Major","Gerard Dupont","Stella Biderman","Anna Rogers","Loubna Ben allal","Francesco De Toni","Giada Pistilli","Olivier Nguyen","Somaieh Nikpoor","Maraim Masoud","Pierre Colombo","Javier de la Rosa","Paulo Villegas","Tristan Thrush","Shayne Longpre","Sebastian Nagel","Leon Weber","Manuel Muñoz","Jian Zhu","Daniel Van Strien","Zaid Alyafeai","Khalid Almubarak","Minh Chien Vu","Itziar Gonzalez-Dios","Aitor Soroa","Kyle Lo","Manan Dey","Pedro Ortiz Suarez","Aaron Gokaslan","Shamik Bose","David Adelani","Long Phan","Hieu Tran","Ian Yu","Suhas Pai","Jenny Chim","Violette Lepercq","Suzana Ilic","Margaret Mitchell","Sasha Alexandra Luccioni","Yacine Jernite"],"pdf_url":"https://arxiv.org/pdf/2303.03915v1.pdf","comment":"NeurIPS 2022, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2209.08212v4","updated":"2023-03-07T14:19:17Z","published":"2022-09-17T01:20:59Z","title":"Compose & Embellish: Well-Structured Piano Performance Generation via A\n  Two-Stage Approach","summary":"  Even with strong sequence models like Transformers, generating expressive\npiano performances with long-range musical structures remains challenging.\nMeanwhile, methods to compose well-structured melodies or lead sheets (melody +\nchords), i.e., simpler forms of music, gained more success. Observing the\nabove, we devise a two-stage Transformer-based framework that Composes a lead\nsheet first, and then Embellishes it with accompaniment and expressive touches.\nSuch a factorization also enables pretraining on non-piano data. Our objective\nand subjective experiments show that Compose & Embellish shrinks the gap in\nstructureness between a current state of the art and real performances by half,\nand improves other musical aspects such as richness and coherence as well.\n","authors":["Shih-Lun Wu","Yi-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2209.08212v4.pdf","comment":"Accepted to International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP) 2023"},{"id":"http://arxiv.org/abs/2303.03912v1","updated":"2023-03-07T14:14:12Z","published":"2023-03-07T14:14:12Z","title":"Document-level Relation Extraction with Cross-sentence Reasoning Graph","summary":"  Relation extraction (RE) has recently moved from the sentence-level to\ndocument-level, which requires aggregating document information and using\nentities and mentions for reasoning. Existing works put entity nodes and\nmention nodes with similar representations in a document-level graph, whose\ncomplex edges may incur redundant information. Furthermore, existing studies\nonly focus on entity-level reasoning paths without considering global\ninteractions among entities cross-sentence. To these ends, we propose a novel\ndocument-level RE model with a GRaph information Aggregation and Cross-sentence\nReasoning network (GRACR). Specifically, a simplified document-level graph is\nconstructed to model the semantic information of all mentions and sentences in\na document, and an entity-level graph is designed to explore relations of\nlong-distance cross-sentence entity pairs. Experimental results show that GRACR\nachieves excellent performance on two public datasets of document-level RE. It\nis especially effective in extracting potential relations of cross-sentence\nentity pairs. Our code is available at https://github.com/UESTC-LHF/GRACR.\n","authors":["Hongfei Liu","Zhao Kang","Lizong Zhang","Ling Tian","Fujun Hua"],"pdf_url":"https://arxiv.org/pdf/2303.03912v1.pdf","comment":"This paper is accepted by PAKDD 2023"},{"id":"http://arxiv.org/abs/2303.03900v1","updated":"2023-03-07T13:52:32Z","published":"2023-03-07T13:52:32Z","title":"New Perspectives on Regularization and Computation in Optimal\n  Transport-Based Distributionally Robust Optimization","summary":"  We study optimal transport-based distributionally robust optimization\nproblems where a fictitious adversary, often envisioned as nature, can choose\nthe distribution of the uncertain problem parameters by reshaping a prescribed\nreference distribution at a finite transportation cost. In this framework, we\nshow that robustification is intimately related to various forms of variation\nand Lipschitz regularization even if the transportation cost function fails to\nbe (some power of) a metric. We also derive conditions for the existence and\nthe computability of a Nash equilibrium between the decision-maker and nature,\nand we demonstrate numerically that nature's Nash strategy can be viewed as a\ndistribution that is supported on remarkably deceptive adversarial samples.\nFinally, we identify practically relevant classes of optimal transport-based\ndistributionally robust optimization problems that can be addressed with\nefficient gradient descent algorithms even if the loss function or the\ntransportation cost function are nonconvex (but not both at the same time).\n","authors":["Soroosh Shafieezadeh-Abadeh","Liviu Aolaritei","Florian Dörfler","Daniel Kuhn"],"pdf_url":"https://arxiv.org/pdf/2303.03900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10669v2","updated":"2023-03-07T13:06:51Z","published":"2023-02-21T13:39:40Z","title":"UAV Path Planning Employing MPC- Reinforcement Learning Method\n  Considering Collision Avoidance","summary":"  In this paper, we tackle the problem of Unmanned Aerial (UA V) path planning\nin complex and uncertain environments by designing a Model Predictive Control\n(MPC), based on a Long-Short-Term Memory (LSTM) network integrated into the\nDeep Deterministic Policy Gradient algorithm. In the proposed solution,\nLSTM-MPC operates as a deterministic policy within the DDPG network, and it\nleverages a predicting pool to store predicted future states and actions for\nimproved robustness and efficiency. The use of the predicting pool also enables\nthe initialization of the critic network, leading to improved convergence speed\nand reduced failure rate compared to traditional reinforcement learning and\ndeep reinforcement learning methods. The effectiveness of the proposed solution\nis evaluated by numerical simulations.\n","authors":["Mahya Ramezani","Hamed Habibi","Jose luis Sanchez Lopez","Holger Voos"],"pdf_url":"https://arxiv.org/pdf/2302.10669v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.12878v2","updated":"2023-03-07T13:05:08Z","published":"2022-09-26T17:44:55Z","title":"Learning and Deploying Robust Locomotion Policies with Minimal Dynamics\n  Randomization","summary":"  Training deep reinforcement learning (DRL) locomotion policies often require\nmassive amounts of data to converge to the desired behaviour. In this regard,\nsimulators provide a cheap and abundant source. For successful sim-to-real\ntransfer, exhaustively engineered approaches such as system identification,\ndynamics randomization, and domain adaptation are generally employed. As an\nalternative, we investigate a simple strategy of random force injection (RFI)\nto perturb system dynamics during training. We show that the application of\nrandom forces enables us to emulate dynamics randomization. This allows us to\nobtain locomotion policies that are robust to variations in system dynamics. We\nfurther extend RFI, referred to as extended random force injection (ERFI), by\nintroducing an episodic actuation offset. We demonstrate that ERFI provides\nadditional robustness for variations in system mass offering on average a 53%\nimproved performance over RFI. We also show that ERFI is sufficient to perform\na successful sim-to-real transfer on two different quadrupedal platforms,\nANYmal C and Unitree A1, even for perceptive locomotion over uneven terrain in\noutdoor environments.\n","authors":["Luigi Campanaro","Siddhant Gangapurwala","Wolfgang Merkt","Ioannis Havoutis"],"pdf_url":"https://arxiv.org/pdf/2209.12878v2.pdf","comment":"8 pages, 5 figures. Under review. Supplementary video:\n  https://youtu.be/YwxUUL-4YIM. Project website:\n  https://sites.google.com/view/erfi-video"},{"id":"http://arxiv.org/abs/2303.03857v1","updated":"2023-03-07T12:49:45Z","published":"2023-03-07T12:49:45Z","title":"Leveraging Pre-trained AudioLDM for Sound Generation: A Benchmark Study","summary":"  Deep neural networks have recently achieved breakthroughs in sound\ngeneration. Despite the outstanding sample quality, current sound generation\nmodels face issues on small-scale datasets (e.g., overfitting and low coverage\nof sound classes), significantly limiting performance. In this paper, we make\nthe first attempt to investigate the benefits of pre-training on sound\ngeneration with AudioLDM, the cutting-edge model for audio generation, as the\nbackbone. Our study demonstrates the advantages of the pre-trained AudioLDM,\nespecially in data-scarcity scenarios. In addition, the baselines and\nevaluation protocol for sound generation systems are not consistent enough to\ncompare different studies directly. Aiming to facilitate further study on sound\ngeneration tasks, we benchmark the sound generation task on various\nfrequently-used datasets. We hope our results on transfer learning and\nbenchmarks can provide references for further research on conditional sound\ngeneration.\n","authors":["Yi Yuan","Haohe Liu","Jinhua Liang","Xubo Liu","Mark D. Plumbley","Wenwu Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03857v1.pdf","comment":"EUSIPCO 2023"},{"id":"http://arxiv.org/abs/2302.13149v2","updated":"2023-03-07T12:22:00Z","published":"2023-02-25T20:24:58Z","title":"STACC: Code Comment Classification using SentenceTransformers","summary":"  Code comments are a key resource for information about software artefacts.\nDepending on the use case, only some types of comments are useful. Thus,\nautomatic approaches to classify these comments have been proposed. In this\nwork, we address this need by proposing, STACC, a set of\nSentenceTransformers-based binary classifiers. These lightweight classifiers\nare trained and tested on the NLBSE Code Comment Classification tool\ncompetition dataset, and surpass the baseline by a significant margin,\nachieving an average F1 score of 0.74 against the baseline of 0.31, which is an\nimprovement of 139%. A replication package, as well as the models themselves,\nare publicly available.\n","authors":["Ali Al-Kaswan","Maliheh Izadi","Arie van Deursen"],"pdf_url":"https://arxiv.org/pdf/2302.13149v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.11262v3","updated":"2023-03-07T12:12:26Z","published":"2022-10-20T13:34:26Z","title":"RMBench: Benchmarking Deep Reinforcement Learning for Robotic\n  Manipulator Control","summary":"  Reinforcement learning is applied to solve actual complex tasks from\nhigh-dimensional, sensory inputs. The last decade has developed a long list of\nreinforcement learning algorithms. Recent progress benefits from deep learning\nfor raw sensory signal representation. One question naturally arises: how well\ndo they perform concerning different robotic manipulation tasks? Benchmarks use\nobjective performance metrics to offer a scientific way to compare algorithms.\nIn this paper, we present RMBench, the first benchmark for robotic\nmanipulations, which have high-dimensional continuous action and state spaces.\nWe implement and evaluate reinforcement learning algorithms that directly use\nobserved pixels as inputs. We report their average performance and learning\ncurves to show their performance and stability of training. Our study concludes\nthat none of the studied algorithms can handle all tasks well, soft\nActor-Critic outperforms most algorithms in average reward and stability, and\nan algorithm combined with data augmentation may facilitate learning policies.\nOur code is publicly available at\nhttps://github.com/xiangyanfei212/RMBench-2022, including all benchmark tasks\nand studied algorithms.\n","authors":["Yanfei Xiang","Xin Wang","Shu Hu","Bin Zhu","Xiaomeng Huang","Xi Wu","Siwei Lyu"],"pdf_url":"https://arxiv.org/pdf/2210.11262v3.pdf","comment":"8 pages, 3 figures, 2 tables; update code's link"},{"id":"http://arxiv.org/abs/2303.03840v1","updated":"2023-03-07T12:10:47Z","published":"2023-03-07T12:10:47Z","title":"A Challenging Benchmark for Low-Resource Learning","summary":"  With promising yet saturated results in high-resource settings, low-resource\ndatasets have gradually become popular benchmarks for evaluating the learning\nability of advanced neural networks (e.g., BigBench, superGLUE). Some models\neven surpass humans according to benchmark test results. However, we find that\nthere exists a set of hard examples in low-resource settings that challenge\nneural networks but are not well evaluated, which causes over-estimated\nperformance. We first give a theoretical analysis on which factors bring the\ndifficulty of low-resource learning. It then motivate us to propose a\nchallenging benchmark hardBench to better evaluate the learning ability, which\ncovers 11 datasets, including 3 computer vision (CV) datasets and 8 natural\nlanguage process (NLP) datasets. Experiments on a wide range of models show\nthat neural networks, even pre-trained language models, have sharp performance\ndrops on our benchmark, demonstrating the effectiveness on evaluating the\nweaknesses of neural networks. On NLP tasks, we surprisingly find that despite\nbetter results on traditional low-resource benchmarks, pre-trained networks,\ndoes not show performance improvements on our benchmarks. These results\ndemonstrate that there are still a large robustness gap between existing models\nand human-level performance.\n","authors":["Yudong Wang","Chang Ma","Qingxiu Dong","Lingpeng Kong","Jingjing Xu"],"pdf_url":"https://arxiv.org/pdf/2303.03840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01141v2","updated":"2023-03-07T11:39:26Z","published":"2022-12-02T12:42:53Z","title":"MHCCL: Masked Hierarchical Cluster-wise Contrastive Learning for\n  Multivariate Time Series","summary":"  Learning semantic-rich representations from raw unlabeled time series data is\ncritical for downstream tasks such as classification and forecasting.\nContrastive learning has recently shown its promising representation learning\ncapability in the absence of expert annotations. However, existing contrastive\napproaches generally treat each instance independently, which leads to false\nnegative pairs that share the same semantics. To tackle this problem, we\npropose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model,\nwhich exploits semantic information obtained from the hierarchical structure\nconsisting of multiple latent partitions for multivariate time series.\nMotivated by the observation that fine-grained clustering preserves higher\npurity while coarse-grained one reflects higher-level semantics, we propose a\nnovel downward masking strategy to filter out fake negatives and supplement\npositives by incorporating the multi-granularity information from the\nclustering hierarchy. In addition, a novel upward masking strategy is designed\nin MHCCL to remove outliers of clusters at each partition to refine prototypes,\nwhich helps speed up the hierarchical clustering process and improves the\nclustering quality. We conduct experimental evaluations on seven widely-used\nmultivariate time series datasets. The results demonstrate the superiority of\nMHCCL over the state-of-the-art approaches for unsupervised time series\nrepresentation learning.\n","authors":["Qianwen Meng","Hangwei Qian","Yong Liu","Lizhen Cui","Yonghui Xu","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2212.01141v2.pdf","comment":"accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2208.04873v3","updated":"2023-03-07T11:33:31Z","published":"2022-08-09T16:04:32Z","title":"Kill Chaos with Kindness: Agreeableness Improves Team Performance Under\n  Uncertainty","summary":"  Teams are central to human accomplishment. Over the past half-century,\npsychologists have identified the Big-Five cross-culturally valid personality\nvariables: Neuroticism, Extraversion, Openness, Conscientiousness, and\nAgreeableness. The first four have shown consistent relationships with team\nperformance. Agreeableness (being harmonious, altruistic, humble, and\ncooperative), however, has demonstrated a non-significant and highly variable\nrelationship with team performance. We resolve this inconsistency through\ncomputational modelling. An agent-based model (ABM) is used to predict the\neffects of personality traits on teamwork and a genetic algorithm is then used\nto explore the limits of the ABM in order to discover which traits correlate\nwith best and worst performing teams for a problem with different levels of\nuncertainty (noise). New dependencies revealed by the exploration are\ncorroborated by analyzing previously-unseen data from one the largest datasets\non team performance to date comprising 3,698 individuals in 593 teams working\non more than 5,000 group tasks with and without uncertainty, collected over a\n10-year period. Our finding is that the dependency between team performance and\nAgreeableness is moderated by task uncertainty. Combining evolutionary\ncomputation with ABMs in this way provides a new methodology for the scientific\ninvestigation of teamwork, making new predictions, and improving our\nunderstanding of human behaviors. Our results confirm the potential usefulness\nof computer modelling for developing theory, as well as shedding light on the\nfuture of teams as work environments are becoming increasingly fluid and\nuncertain.\n","authors":["Soo Ling Lim","Peter J. Bentley","Randall S. Peterson","Xiaoran Hu","JoEllyn Prouty McLaren"],"pdf_url":"https://arxiv.org/pdf/2208.04873v3.pdf","comment":"Final version (open access) as published in journal"},{"id":"http://arxiv.org/abs/2303.03817v1","updated":"2023-03-07T11:33:22Z","published":"2023-03-07T11:33:22Z","title":"Region and Spatial Aware Anomaly Detection for Fundus Images","summary":"  Recently anomaly detection has drawn much attention in diagnosing ocular\ndiseases. Most existing anomaly detection research in fundus images has\nrelatively large anomaly scores in the salient retinal structures, such as\nblood vessels, optical cups and discs. In this paper, we propose a Region and\nSpatial Aware Anomaly Detection (ReSAD) method for fundus images, which obtains\nlocal region and long-range spatial information to reduce the false positives\nin the normal structure. ReSAD transfers a pre-trained model to extract the\nfeatures of normal fundus images and applies the Region-and-Spatial-Aware\nfeature Combination module (ReSC) for pixel-level features to build a memory\nbank. In the testing phase, ReSAD uses the memory bank to determine\nout-of-distribution samples as abnormalities. Our method significantly\noutperforms the existing anomaly detection methods for fundus images on two\npublicly benchmark datasets.\n","authors":["Jingqi Niu","Shiwen Dong","Qinji Yu","Kang Dang","Xiaowei Ding"],"pdf_url":"https://arxiv.org/pdf/2303.03817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03811v1","updated":"2023-03-07T11:26:09Z","published":"2023-03-07T11:26:09Z","title":"ENTROPY: Environment Transformer and Offline Policy Optimization","summary":"  Model-based methods provide an effective approach to offline reinforcement\nlearning (RL). They learn an environmental dynamics model from interaction\nexperiences and then perform policy optimization based on the learned model.\nHowever, previous model-based offline RL methods lack long-term prediction\ncapability, resulting in large errors when generating multi-step trajectories.\nWe address this issue by developing a sequence modeling architecture,\nEnvironment Transformer, which can generate reliable long-horizon trajectories\nbased on offline datasets. We then propose a novel model-based offline RL\nalgorithm, ENTROPY, that learns the dynamics model and reward function by\nENvironment TRansformer and performs Offline PolicY optimization. We evaluate\nthe proposed method on MuJoCo continuous control RL environments. Results show\nthat ENTROPY performs comparably or better than the state-of-the-art\nmodel-based and model-free offline RL methods and demonstrates more powerful\nlong-term trajectory prediction capability compared to existing model-based\noffline methods.\n","authors":["Pengqin Wang","Meixin Zhu","Shaojie Shen"],"pdf_url":"https://arxiv.org/pdf/2303.03811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03789v1","updated":"2023-03-07T10:52:59Z","published":"2023-03-07T10:52:59Z","title":"Fast and Multi-aspect Mining of Complex Time-stamped Event Streams","summary":"  Given a huge, online stream of time-evolving events with multiple attributes,\nsuch as online shopping logs: (item, price, brand, time), and local mobility\nactivities: (pick-up and drop-off locations, time), how can we summarize large,\ndynamic high-order tensor streams? How can we see any hidden patterns, rules,\nand anomalies? Our answer is to focus on two types of patterns, i.e.,\n''regimes'' and ''components'', for which we present CubeScope, an efficient\nand effective method over high-order tensor streams. Specifically, it\nidentifies any sudden discontinuity and recognizes distinct dynamical patterns,\n''regimes'' (e.g., weekday/weekend/holiday patterns). In each regime, it also\nperforms multi-way summarization for all attributes (e.g., item, price, brand,\nand time) and discovers hidden ''components'' representing latent groups (e.g.,\nitem/brand groups) and their relationship. Thanks to its concise but effective\nsummarization, CubeScope can also detect the sudden appearance of anomalies and\nidentify the types of anomalies that occur in practice. Our proposed method has\nthe following properties: (a) Effective: it captures dynamical multi-aspect\npatterns, i.e., regimes and components, and statistically summarizes all the\nevents; (b) General: it is practical for successful application to data\ncompression, pattern discovery, and anomaly detection on various types of\ntensor streams; (c) Scalable: our algorithm does not depend on the length of\nthe data stream and its dimensionality. Extensive experiments on real datasets\ndemonstrate that CubeScope finds meaningful patterns and anomalies correctly,\nand consistently outperforms the state-of-the-art methods as regards accuracy\nand execution speed.\n","authors":["Kota Nakamura","Yasuko Matsubara","Koki Kawabata","Yuhei Umeda","Yuichiro Wada","Yasushi Sakurai"],"pdf_url":"https://arxiv.org/pdf/2303.03789v1.pdf","comment":"Accepted by WWW 2023"},{"id":"http://arxiv.org/abs/2302.12526v2","updated":"2023-03-07T10:31:42Z","published":"2023-02-24T09:18:27Z","title":"Model-Based Uncertainty in Value Functions","summary":"  We consider the problem of quantifying uncertainty over expected cumulative\nrewards in model-based reinforcement learning. In particular, we focus on\ncharacterizing the variance over values induced by a distribution over MDPs.\nPrevious work upper bounds the posterior variance over values by solving a\nso-called uncertainty Bellman equation, but the over-approximation may result\nin inefficient exploration. We propose a new uncertainty Bellman equation whose\nsolution converges to the true posterior variance over values and explicitly\ncharacterizes the gap in previous work. Moreover, our uncertainty\nquantification technique is easily integrated into common exploration\nstrategies and scales naturally beyond the tabular setting by using standard\ndeep reinforcement learning architectures. Experiments in difficult exploration\ntasks, both in tabular and continuous control settings, show that our sharper\nuncertainty estimates improve sample-efficiency.\n","authors":["Carlos E. Luis","Alessandro G. Bottero","Julia Vinogradska","Felix Berkenkamp","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2302.12526v2.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2209.15430v2","updated":"2023-03-07T10:08:04Z","published":"2022-09-30T12:37:03Z","title":"Relative representations enable zero-shot latent space communication","summary":"  Neural networks embed the geometric structure of a data manifold lying in a\nhigh-dimensional space into latent representations. Ideally, the distribution\nof the data points in the latent space should depend only on the task, the\ndata, the loss, and other architecture-specific constraints. However, factors\nsuch as the random weights initialization, training hyperparameters, or other\nsources of randomness in the training phase may induce incoherent latent spaces\nthat hinder any form of reuse. Nevertheless, we empirically observe that, under\nthe same data and modeling choices, the angles between the encodings within\ndistinct latent spaces do not change. In this work, we propose the latent\nsimilarity between each sample and a fixed set of anchors as an alternative\ndata representation, demonstrating that it can enforce the desired invariances\nwithout any additional training. We show how neural architectures can leverage\nthese relative representations to guarantee, in practice, invariance to latent\nisometries and rescalings, effectively enabling latent space communication:\nfrom zero-shot model stitching to latent space comparison between diverse\nsettings. We extensively validate the generalization capability of our approach\non different datasets, spanning various modalities (images, text, graphs),\ntasks (e.g., classification, reconstruction) and architectures (e.g., CNNs,\nGCNs, transformers).\n","authors":["Luca Moschella","Valentino Maiorca","Marco Fumero","Antonio Norelli","Francesco Locatello","Emanuele Rodolà"],"pdf_url":"https://arxiv.org/pdf/2209.15430v2.pdf","comment":"ICLR 2023 notable top 5%, 26 pages, 11 figures, 18 tables"},{"id":"http://arxiv.org/abs/2303.03770v1","updated":"2023-03-07T10:04:55Z","published":"2023-03-07T10:04:55Z","title":"Guiding Pseudo-labels with Uncertainty Estimation for Test-Time\n  Adaptation","summary":"  Standard Unsupervised Domain Adaptation (UDA) methods assume the availability\nof both source and target data during the adaptation. In this work, we\ninvestigate the Test-Time Adaptation (TTA), a specific case of UDA where a\nmodel is adapted to a target domain without access to source data. We propose a\nnovel approach for the TTA setting based on a loss reweighting strategy that\nbrings robustness against the noise that inevitably affects the pseudo-labels.\nThe classification loss is reweighted based on the reliability of the\npseudo-labels that is measured by estimating their uncertainty. Guided by such\nreweighting strategy, the pseudo-labels are progressively refined by\naggregating knowledge from neighbouring samples. Furthermore, a self-supervised\ncontrastive framework is leveraged as a target space regulariser to enhance\nsuch knowledge aggregation. A novel negative pairs exclusion strategy is\nproposed to identify and exclude negative pairs made of samples sharing the\nsame class, even in presence of some noise in the pseudo-labels. Our method\noutperforms previous methods on three major benchmarks by a large margin. We\nset the new TTA state-of-the-art on VisDA-C and DomainNet with a performance\ngain of +1.8\\% on both benchmarks and on PACS with +12.3\\% in the single-source\nsetting and +6.6\\% in\\ multi-target adaptation. Additional analyses demonstrate\nthat the proposed approach is robust to the noise, which results in\nsignificantly more accurate pseudo-labels compared to state-of-the-art\napproaches.\n","authors":["Mattia Litrico","Alessio Del Bue","Pietro Morerio"],"pdf_url":"https://arxiv.org/pdf/2303.03770v1.pdf","comment":"To be published in Proceedings of the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition (CVPR) 2023"},{"id":"http://arxiv.org/abs/2302.01622v2","updated":"2023-03-07T10:00:43Z","published":"2023-02-03T09:49:13Z","title":"Private, fair and accurate: Training large-scale, privacy-preserving AI\n  models in medical imaging","summary":"  Artificial intelligence (AI) models are increasingly used in the medical\ndomain. However, as medical data is highly sensitive, special precautions to\nensure its protection are required. The gold standard for privacy preservation\nis the introduction of differential privacy (DP) to model training. Prior work\nindicates that DP has negative implications on model accuracy and fairness,\nwhich are unacceptable in medicine and represent a main barrier to the\nwidespread use of privacy-preserving techniques. In this work, we evaluated the\neffect of privacy-preserving training of AI models for chest radiograph\ndiagnosis regarding accuracy and fairness compared to non-private training. For\nthis, we used a large dataset (N=193,311) of high quality clinical chest\nradiographs, which were retrospectively collected and manually labeled by\nexperienced radiologists. We then compared non-private deep convolutional\nneural networks (CNNs) and privacy-preserving (DP) models with respect to\nprivacy-utility trade-offs measured as area under the\nreceiver-operator-characteristic curve (AUROC), and privacy-fairness\ntrade-offs, measured as Pearson's r or Statistical Parity Difference. We found\nthat the non-private CNNs achieved an average AUROC score of 0.90 +- 0.04 over\nall labels, whereas the DP CNNs with a privacy budget of epsilon=7.89 resulted\nin an AUROC of 0.87 +- 0.04, i.e., a mere 2.6% performance decrease compared to\nnon-private training. Furthermore, we found the privacy-preserving training not\nto amplify discrimination against age, sex or co-morbidity. Our study shows\nthat -- under the challenging realistic circumstances of a real-life clinical\ndataset -- the privacy-preserving training of diagnostic deep learning models\nis possible with excellent diagnostic accuracy and fairness.\n","authors":["Soroosh Tayebi Arasteh","Alexander Ziller","Christiane Kuhl","Marcus Makowski","Sven Nebelung","Rickmer Braren","Daniel Rueckert","Daniel Truhn","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2302.01622v2.pdf","comment":"3 tables, 5 figures, 11 supplementary materials"},{"id":"http://arxiv.org/abs/2303.03755v1","updated":"2023-03-07T09:30:43Z","published":"2023-03-07T09:30:43Z","title":"DLT: Conditioned layout generation with Joint Discrete-Continuous\n  Diffusion Layout Transformer","summary":"  Generating visual layouts is an essential ingredient of graphic design. The\nability to condition layout generation on a partial subset of component\nattributes is critical to real-world applications that involve user\ninteraction. Recently, diffusion models have demonstrated high-quality\ngenerative performances in various domains. However, it is unclear how to apply\ndiffusion models to the natural representation of layouts which consists of a\nmix of discrete (class) and continuous (location, size) attributes. To address\nthe conditioning layout generation problem, we introduce DLT, a joint\ndiscrete-continuous diffusion model. DLT is a transformer-based model which has\na flexible conditioning mechanism that allows for conditioning on any given\nsubset of all the layout component classes, locations, and sizes. Our method\noutperforms state-of-the-art generative models on various layout generation\ndatasets with respect to different metrics and conditioning settings.\nAdditionally, we validate the effectiveness of our proposed conditioning\nmechanism and the joint continuous-diffusion process. This joint process can be\nincorporated into a wide range of mixed discrete-continuous generative tasks.\n","authors":["Elad Levi","Eli Brosh","Mykola Mykhailych","Meir Perez"],"pdf_url":"https://arxiv.org/pdf/2303.03755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03751v1","updated":"2023-03-07T09:20:43Z","published":"2023-03-07T09:20:43Z","title":"Zeroth-Order Optimization Meets Human Feedback: Provable Learning via\n  Ranking Oracles","summary":"  In this paper, we focus on a novel optimization problem in which the\nobjective function is a black-box and can only be evaluated through a ranking\noracle. This problem is common in real-world applications, particularly in\ncases where the function is assessed by human judges. Reinforcement Learning\nwith Human Feedback (RLHF) is a prominent example of such an application, which\nis adopted by the recent works\n\\cite{ouyang2022training,liu2023languages,chatgpt,bai2022training} to improve\nthe quality of Large Language Models (LLMs) with human guidance. We propose\nZO-RankSGD, a first-of-its-kind zeroth-order optimization algorithm, to solve\nthis optimization problem with a theoretical guarantee. Specifically, our\nalgorithm employs a new rank-based random estimator for the descent direction\nand is proven to converge to a stationary point. ZO-RankSGD can also be\ndirectly applied to the policy search problem in reinforcement learning when\nonly a ranking oracle of the episode reward is available. This makes ZO-RankSGD\na promising alternative to existing RLHF methods, as it optimizes in an online\nfashion and thus can work without any pre-collected data. Furthermore, we\ndemonstrate the effectiveness of ZO-RankSGD in a novel application: improving\nthe quality of images generated by a diffusion generative model with human\nranking feedback. Throughout experiments, we found that ZO-RankSGD can\nsignificantly enhance the detail of generated images with only a few rounds of\nhuman feedback. Overall, our work advances the field of zeroth-order\noptimization by addressing the problem of optimizing functions with only\nranking feedback, and offers an effective approach for aligning human and\nmachine intentions in a wide range of domains. Our code is released here\n\\url{https://github.com/TZW1998/Taming-Stable-Diffusion-with-Human-Ranking-Feedback}.\n","authors":["Zhiwei Tang","Dmitry Rybin","Tsung-Hui Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03747v1","updated":"2023-03-07T09:10:34Z","published":"2023-03-07T09:10:34Z","title":"Graph Decision Transformer","summary":"  Offline reinforcement learning (RL) is a challenging task, whose objective is\nto learn policies from static trajectory data without interacting with the\nenvironment. Recently, offline RL has been viewed as a sequence modeling\nproblem, where an agent generates a sequence of subsequent actions based on a\nset of static transition experiences. However, existing approaches that use\ntransformers to attend to all tokens naively can overlook the dependencies\nbetween different tokens and limit long-term dependency learning. In this\npaper, we propose the Graph Decision Transformer (GDT), a novel offline RL\napproach that models the input sequence into a causal graph to capture\npotential dependencies between fundamentally different concepts and facilitate\ntemporal and causal relationship learning. GDT uses a graph transformer to\nprocess the graph inputs with relation-enhanced mechanisms, and an optional\nsequence transformer to handle fine-grained spatial information in visual\ntasks. Our experiments show that GDT matches or surpasses the performance of\nstate-of-the-art offline RL methods on image-based Atari and OpenAI Gym.\n","authors":["Shengchao Hu","Li Shen","Ya Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.03747v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2303.03714v1","updated":"2023-03-07T07:55:52Z","published":"2023-03-07T07:55:52Z","title":"Generative Modeling with Flow-Guided Density Ratio Learning","summary":"  We present Flow-Guided Density Ratio Learning (FDRL), a simple and scalable\napproach to generative modeling which builds on the stale (time-independent)\napproximation of the gradient flow of entropy-regularized f-divergences\nintroduced in DGflow. In DGflow, the intractable time-dependent density ratio\nis approximated by a stale estimator given by a GAN discriminator. This is\nsufficient in the case of sample refinement, where the source and target\ndistributions of the flow are close to each other. However, this assumption is\ninvalid for generation and a naive application of the stale estimator fails due\nto the large chasm between the two distributions. FDRL proposes to train a\ndensity ratio estimator such that it learns from progressively improving\nsamples during the training process. We show that this simple method alleviates\nthe density chasm problem, allowing FDRL to generate images of dimensions as\nhigh as $128\\times128$, as well as outperform existing gradient flow baselines\non quantitative benchmarks. We also show the flexibility of FDRL with two use\ncases. First, unconditional FDRL can be easily composed with external\nclassifiers to perform class-conditional generation. Second, FDRL can be\ndirectly applied to unpaired image-to-image translation with no modifications\nneeded to the framework. Code is publicly available at\nhttps://github.com/ajrheng/FDRL.\n","authors":["Alvin Heng","Abdul Fatir Ansari","Harold Soh"],"pdf_url":"https://arxiv.org/pdf/2303.03714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03709v1","updated":"2023-03-07T07:47:41Z","published":"2023-03-07T07:47:41Z","title":"Bootstrap The Original Latent: Freeze-and-thaw Adapter for\n  Back-Propagated Black-Box Adaptation","summary":"  In this paper, considering the balance of data/model privacy of model owners\nand user needs, we propose a new setting called Back-Propagated Black-Box\nAdaptation (BPBA) for users to better train their private models via the\nguidance of the back-propagated results of foundation/source models. Our\nsetting can ease the usage of foundation/source models as well as prevent the\nleakage and misuse of foundation/source models. Moreover, we also propose a new\ntraining strategy called Bootstrap The Original Latent (BTOL) to fully utilize\nthe foundation/source models. Our strategy consists of a domain adapter and a\nfreeze-and-thaw strategy. We apply our BTOL under BPBA and Black-box UDA\nsettings on three different datasets. Experiments show that our strategy is\nefficient and robust in various settings without manual augmentations.\n","authors":["Shuai Wang","Daoan Zhang","Jianguo Zhang","Weiwei Zhang","Rui Li"],"pdf_url":"https://arxiv.org/pdf/2303.03709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09865v2","updated":"2023-03-07T07:23:38Z","published":"2023-02-20T09:56:51Z","title":"Can discrete information extraction prompts generalize across language\n  models?","summary":"  We study whether automatically-induced prompts that effectively extract\ninformation from a language model can also be used, out-of-the-box, to probe\nother language models for the same information. After confirming that discrete\nprompts induced with the AutoPrompt algorithm outperform manual and semi-manual\nprompts on the slot-filling task, we demonstrate a drop in performance for\nAutoPrompt prompts learned on a model and tested on another. We introduce a way\nto induce prompts by mixing language models at training time that results in\nprompts that generalize well across models. We conduct an extensive analysis of\nthe induced prompts, finding that the more general prompts include a larger\nproportion of existing English words and have a less order-dependent and more\nuniform distribution of information across their component tokens. Our work\nprovides preliminary evidence that it's possible to generate discrete prompts\nthat can be induced once and used with a number of different models, and gives\ninsights on the properties characterizing such prompts.\n","authors":["Nathanaël Carraz Rakotonirina","Roberto Dessì","Fabio Petroni","Sebastian Riedel","Marco Baroni"],"pdf_url":"https://arxiv.org/pdf/2302.09865v2.pdf","comment":"Published as conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2109.04100v2","updated":"2023-03-07T07:19:42Z","published":"2021-09-09T08:38:17Z","title":"Taming Self-Supervised Learning for Presentation Attack Detection:\n  In-Image De-Folding and Out-of-Image De-Mixing","summary":"  Biometric systems are vulnerable to Presentation Attacks (PA) performed using\nvarious Presentation Attack Instruments (PAIs). Even though there are numerous\nPresentation Attack Detection (PAD) techniques based on both deep learning and\nhand-crafted features, the generalization of PAD for unknown PAI is still a\nchallenging problem. In this work, we empirically prove that the initialization\nof the PAD model is a crucial factor for the generalization, which is rarely\ndiscussed in the community. Based on such observation, we proposed a\nself-supervised learning-based method, denoted as DF-DM. Specifically, DF-DM is\nbased on a global-local view coupled with De-Folding and De-Mixing to derive\nthe task-specific representation for PAD. During De-Folding, the proposed\ntechnique will learn region-specific features to represent samples in a local\npattern by explicitly minimizing generative loss. While De-Mixing drives\ndetectors to obtain the instance-specific features with global information for\nmore comprehensive representation by minimizing interpolation-based\nconsistency. Extensive experimental results show that the proposed method can\nachieve significant improvements in terms of both face and fingerprint PAD in\nmore complicated and hybrid datasets when compared with state-of-the-art\nmethods. When training in CASIA-FASD and Idiap Replay-Attack, the proposed\nmethod can achieve an 18.60% Equal Error Rate (EER) in OULU-NPU and MSU-MFSD,\nexceeding baseline performance by 9.54%. The source code of the proposed\ntechnique is available at https://github.com/kongzhecn/dfdm.\n","authors":["Zhe Kong","Wentian Zhang","Feng Liu","Wenhan Luo","Haozhe Liu","Linlin Shen","Raghavendra Ramachandra"],"pdf_url":"https://arxiv.org/pdf/2109.04100v2.pdf","comment":"Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)"},{"id":"http://arxiv.org/abs/2212.01689v2","updated":"2023-03-07T07:04:32Z","published":"2022-12-03T20:56:29Z","title":"Learning-Assisted Algorithm Unrolling for Online Optimization with\n  Budget Constraints","summary":"  Online optimization with multiple budget constraints is challenging since the\nonline decisions over a short time horizon are coupled together by strict\ninventory constraints. The existing manually-designed algorithms cannot achieve\nsatisfactory average performance for this setting because they often need a\nlarge number of time steps for convergence and/or may violate the inventory\nconstraints. In this paper, we propose a new machine learning (ML) assisted\nunrolling approach, called LAAU (Learning-Assisted Algorithm Unrolling), which\nunrolls the online decision pipeline and leverages an ML model for updating the\nLagrangian multiplier online. For efficient training via backpropagation, we\nderive gradients of the decision pipeline over time. We also provide the\naverage cost bounds for two cases when training data is available offline and\ncollected online, respectively. Finally, we present numerical results to\nhighlight that LAAU can outperform the existing baselines.\n","authors":["Jianyi Yang","Shaolei Ren"],"pdf_url":"https://arxiv.org/pdf/2212.01689v2.pdf","comment":"Accepted by AAAI'23"},{"id":"http://arxiv.org/abs/2209.12890v2","updated":"2023-03-07T06:44:46Z","published":"2022-09-26T17:59:23Z","title":"It Takes Two: Learning to Plan for Human-Robot Cooperative Carrying","summary":"  Cooperative table-carrying is a complex task due to the continuous nature of\nthe action and state-spaces, multimodality of strategies, and the need for\ninstantaneous adaptation to other agents. In this work, we present a method for\npredicting realistic motion plans for cooperative human-robot teams on the\ntask. Using a Variational Recurrent Neural Network (VRNN) to model the\nvariation in the trajectory of a human-robot team across time, we are able to\ncapture the distribution over the team's future states while leveraging\ninformation from interaction history. The key to our approach is leveraging\nhuman demonstration data to generate trajectories that synergize well with\nhumans during test time in a receding horizon fashion. Comparison between a\nbaseline, sampling-based planner RRT (Rapidly-exploring Random Trees) and the\nVRNN planner in centralized planning shows that the VRNN generates motion more\nsimilar to the distribution of human-human demonstrations than the RRT. Results\nin a human-in-the-loop user study show that the VRNN planner outperforms\ndecentralized RRT on task-related metrics, and is significantly more likely to\nbe perceived as human than the RRT planner. Finally, we demonstrate the VRNN\nplanner on a real robot paired with a human teleoperating another robot.\n","authors":["Eley Ng","Ziang Liu","Monroe Kennedy III"],"pdf_url":"https://arxiv.org/pdf/2209.12890v2.pdf","comment":"IEEE International Conference on Robotics and Automation (ICRA) 2023.\n  Supplementary materials at https://sites.google.com/view/cooperative-carrying"},{"id":"http://arxiv.org/abs/2303.03677v1","updated":"2023-03-07T06:33:40Z","published":"2023-03-07T06:33:40Z","title":"Training Machine Learning Models to Characterize Temporal Evolution of\n  Disadvantaged Communities","summary":"  Disadvantaged communities (DAC), as defined by the Justice40 initiative of\nthe Department of Energy (DOE), USA, identifies census tracts across the USA to\ndetermine where benefits of climate and energy investments are or are not\ncurrently accruing. The DAC status not only helps in determining the\neligibility for future Justice40-related investments but is also critical for\nexploring ways to achieve equitable distribution of resources. However,\ndesigning inclusive and equitable strategies not just requires a good\nunderstanding of current demographics, but also a deeper analysis of the\ntransformations that happened in those demographics over the years. In this\npaper, machine learning (ML) models are trained on publicly available census\ndata from recent years to classify the DAC status at the census tracts level\nand then the trained model is used to classify DAC status for historical years.\nA detailed analysis of the feature and model selection along with the evolution\nof disadvantaged communities between 2013 and 2018 is presented in this study.\n","authors":["Milan Jain","Narmadha Meenu Mohankumar","Heng Wan","Sumitrra Ganguly","Kyle D Wilson","David M Anderson"],"pdf_url":"https://arxiv.org/pdf/2303.03677v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12355v3","updated":"2023-03-07T06:09:25Z","published":"2023-01-29T04:17:32Z","title":"Semantics-enhanced Temporal Graph Networks for Content Caching and\n  Energy Saving","summary":"  The enormous amount of network equipment and users implies a tremendous\ngrowth of Internet traffic for multimedia services. To mitigate the traffic\npressure, architectures with in-network storage are proposed to cache popular\ncontent at nodes in close proximity to users to shorten the backhaul links.\nMeanwhile, the reduction of transmission distance also contributes to the\nenergy saving. However, due to limited storage, only a fraction of the content\ncan be cached, while caching the most popular content is cost-effective.\nCorrespondingly, it becomes essential to devise an effective popularity\nprediction method. In this regard, existing efforts adopt dynamic graph neural\nnetwork (DGNN) models, but it remains challenging to tackle sparse datasets. In\nthis paper, we first propose a reformative temporal graph network, which is\nnamed STGN, that utilizes extra semantic messages to enhance the temporal and\nstructural learning of a DGNN model, since the consideration of semantics can\nhelp establish implicit paths within the sparse interaction graph and hence\nimprove the prediction performance. Furthermore, we propose a user-specific\nattention mechanism to fine-grainedly aggregate various semantics. Finally,\nextensive simulations verify the superiority of our STGN models and demonstrate\ntheir high potential in energy-saving.\n","authors":["Jianhang Zhu","Rongpeng Li","Xianfu Chen","Shiwen Mao","Jianjun Wu","Zhifeng Zhao"],"pdf_url":"https://arxiv.org/pdf/2301.12355v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10243v2","updated":"2023-03-07T05:46:46Z","published":"2022-10-19T01:45:29Z","title":"CLUTR: Curriculum Learning via Unsupervised Task Representation Learning","summary":"  Reinforcement Learning (RL) algorithms are often known for sample\ninefficiency and difficult generalization. Recently, Unsupervised Environment\nDesign (UED) emerged as a new paradigm for zero-shot generalization by\nsimultaneously learning a task distribution and agent policies on the generated\ntasks. This is a non-stationary process where the task distribution evolves\nalong with agent policies; creating an instability over time. While past works\ndemonstrated the potential of such approaches, sampling effectively from the\ntask space remains an open challenge, bottlenecking these approaches. To this\nend, we introduce CLUTR: a novel unsupervised curriculum learning algorithm\nthat decouples task representation and curriculum learning into a two-stage\noptimization. It first trains a recurrent variational autoencoder on randomly\ngenerated tasks to learn a latent task manifold. Next, a teacher agent creates\na curriculum by maximizing a minimax REGRET-based objective on a set of latent\ntasks sampled from this manifold. Using the fixed-pretrained task manifold, we\nshow that CLUTR successfully overcomes the non-stationarity problem and\nimproves stability. Our experimental results show CLUTR outperforms PAIRED, a\nprincipled and popular UED method, in the challenging CarRacing and navigation\nenvironments: achieving 10.6X and 45\\% improvement in zero-shot generalization,\nrespectively. CLUTR also performs comparably to the non-UED state-of-the-art\nfor CarRacing, while requiring 500X fewer environment interactions.\n","authors":["Abdus Salam Azad","Izzeddin Gur","Jasper Emhoff","Nathaniel Alexis","Aleksandra Faust","Pieter Abbeel","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2210.10243v2.pdf","comment":"Preprint, Currently Under Review"},{"id":"http://arxiv.org/abs/2303.01248v2","updated":"2023-03-07T05:35:39Z","published":"2023-03-01T06:16:14Z","title":"Can ChatGPT Assess Human Personalities? A General Evaluation Framework","summary":"  Large Language Models (LLMs) especially ChatGPT have produced impressive\nresults in various areas, but their potential human-like psychology is still\nlargely unexplored. Existing works study the virtual personalities of LLMs but\nrarely explore the possibility of analyzing human personalities via LLMs. This\npaper presents a generic evaluation framework for LLMs to assess human\npersonalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically,\nwe first devise unbiased prompts by randomly permuting options in MBTI\nquestions and adopt the average testing result to encourage more impartial\nanswer generation. Then, we propose to replace the subject in question\nstatements to enable flexible queries and assessments on different subjects\nfrom LLMs. Finally, we re-formulate the question instructions in a manner of\ncorrectness evaluation to facilitate LLMs to generate clearer responses. The\nproposed framework enables LLMs to flexibly assess personalities of different\ngroups of people. We further propose three evaluation metrics to measure the\nconsistency, robustness, and fairness of assessment results from\nstate-of-the-art LLMs including ChatGPT and InstructGPT. Our experiments reveal\nChatGPT's ability to assess human personalities, and the average results\ndemonstrate that it can achieve more consistent and fairer assessments in spite\nof lower robustness against prompt biases compared with InstructGPT.\n","authors":["Haocong Rao","Cyril Leung","Chunyan Miao"],"pdf_url":"https://arxiv.org/pdf/2303.01248v2.pdf","comment":"Our codes are available at https://github.com/Kali-Hac/ChatGPT-MBTI"},{"id":"http://arxiv.org/abs/2212.13020v3","updated":"2023-03-07T05:11:12Z","published":"2022-12-26T06:19:49Z","title":"Track Before Detect of Low Observable Maneuvering Objects in a Sequence\n  of Image Frames Using Particle Filter","summary":"  A multiple model track-before-detect (TBD) particle filter-based approach for\ndetection and tracking of low observable maneuvering objects based on a\nsequence of image frames in the presence of noise and clutter is briefly\nstudied in this letter. At each time instance after receiving a frame of image,\nfirst, some preprocessing approaches are applied to the image. Then, it is sent\nto the multiple model TBD particle filter for detection and tracking of an\nobject. Performance of the approach is evaluated for detection and tracking of\nan object in different scenarios including noise and clutter.\n","authors":["Reza Rezaie"],"pdf_url":"https://arxiv.org/pdf/2212.13020v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14051v2","updated":"2023-03-07T04:06:45Z","published":"2022-10-25T14:30:48Z","title":"Bridging Distributional and Risk-sensitive Reinforcement Learning with\n  Provable Regret Bounds","summary":"  We study the regret guarantee for risk-sensitive reinforcement learning\n(RSRL) via distributional reinforcement learning (DRL) methods. In particular,\nwe consider finite episodic Markov decision processes whose objective is the\nentropic risk measure (EntRM) of return. We identify a key property of the\nEntRM, the monotonicity-preserving property, which enables the risk-sensitive\ndistributional dynamic programming framework. We then propose two novel DRL\nalgorithms that implement optimism through two different schemes, including a\nmodel-free one and a model-based one.\n  We prove that both of them attain $\\tilde{\\mathcal{O}}(\\frac{\\exp(|\\beta|\nH)-1}{|\\beta|H}H\\sqrt{HS^2AT})$ regret upper bound, where $S$ is the number of\nstates, $A$ the number of states, $H$ the time horizon and $T$ the number of\ntotal time steps. It matches RSVI2 proposed in \\cite{fei2021exponential} with a\nmuch simpler regret analysis. To the best of our knowledge, this is the first\nregret analysis of DRL, which bridges DRL and RSRL in terms of sample\ncomplexity. Finally, we improve the existing lower bound by proving a tighter\nbound of $\\Omega(\\frac{\\exp(\\beta H/6)-1}{\\beta H}H\\sqrt{SAT})$ for $\\beta>0$\ncase, which recovers the tight lower bound $\\Omega(H\\sqrt{SAT})$ in the\nrisk-neutral setting.\n","authors":["Hao Liang","Zhi-Quan Luo"],"pdf_url":"https://arxiv.org/pdf/2210.14051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03638v1","updated":"2023-03-07T03:59:14Z","published":"2023-03-07T03:59:14Z","title":"Collaboration with Conversational AI Assistants for UX Evaluation:\n  Questions and How to Ask them (Voice vs. Text)","summary":"  AI is promising in assisting UX evaluators with analyzing usability tests,\nbut its judgments are typically presented as non-interactive visualizations.\nEvaluators may have questions about test recordings, but have no way of asking\nthem. Interactive conversational assistants provide a Q&A dynamic that may\nimprove analysis efficiency and evaluator autonomy. To understand the full\nrange of analysis-related questions, we conducted a Wizard-of-Oz design probe\nstudy with 20 participants who interacted with simulated AI assistants via text\nor voice. We found that participants asked for five categories of information:\nuser actions, user mental model, help from the AI assistant, product and task\ninformation, and user demographics. Those who used the text assistant asked\nmore questions, but the question lengths were similar. The text assistant was\nperceived as significantly more efficient, but both were rated equally in\nsatisfaction and trust. We also provide design considerations for future\nconversational AI assistants for UX evaluation.\n","authors":["Emily Kuang","Ehsan Jahangirzadeh Soure","Mingming Fan","Jian Zhao","Kristen Shinohara"],"pdf_url":"https://arxiv.org/pdf/2303.03638v1.pdf","comment":"Proceedings of the 2023 CHI Conference on Human Factors in Computing\n  Systems (CHI '23), April 23--28, 2023, Hamburg, Germany"},{"id":"http://arxiv.org/abs/2302.09270v2","updated":"2023-03-07T03:28:47Z","published":"2023-02-18T09:32:55Z","title":"Recent Advances towards Safe, Responsible, and Moral Dialogue Systems: A\n  Survey","summary":"  With the development of artificial intelligence, dialogue systems have been\nendowed with amazing chit-chat capabilities, and there is widespread interest\nand discussion about whether the generated contents are socially beneficial. In\nthis paper, we present a new perspective of research scope towards building a\nsafe, responsible, and modal dialogue system, including 1) abusive and toxic\ncontents, 2) unfairness and discrimination, 3) ethics and morality issues, and\n4) risk of misleading and privacy information. Besides, we review the\nmainstream methods for evaluating the safety of large models from the\nperspectives of exposure and detection of safety issues. The recent advances in\nmethodologies for the safety improvement of both end-to-end dialogue systems\nand pipeline-based models are further introduced. Finally, we discussed six\nexisting challenges towards responsible AI: explainable safety monitoring,\ncontinuous learning of safety issues, robustness against malicious attacks,\nmultimodal information processing, unified research framework, and\nmultidisciplinary theory integration. We hope this survey will inspire further\nresearch toward safer dialogue systems.\n","authors":["Jiawen Deng","Hao Sun","Zhexin Zhang","Jiale Cheng","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2302.09270v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08064v2","updated":"2023-03-07T02:46:34Z","published":"2022-11-15T11:34:30Z","title":"Physics-Informed Machine Learning: A Survey on Problems, Methods and\n  Applications","summary":"  Recent advances of data-driven machine learning have revolutionized fields\nlike computer vision, reinforcement learning, and many scientific and\nengineering domains. In many real-world and scientific problems, systems that\ngenerate data are governed by physical laws. Recent work shows that it provides\npotential benefits for machine learning models by incorporating the physical\nprior and collected data, which makes the intersection of machine learning and\nphysics become a prevailing paradigm. By integrating the data and mathematical\nphysics models seamlessly, it can guide the machine learning model towards\nsolutions that are physically plausible, improving accuracy and efficiency even\nin uncertain and high-dimensional contexts. In this survey, we present this\nlearning paradigm called Physics-Informed Machine Learning (PIML) which is to\nbuild a model that leverages empirical data and available physical prior\nknowledge to improve performance on a set of tasks that involve a physical\nmechanism. We systematically review the recent development of physics-informed\nmachine learning from three perspectives of machine learning tasks,\nrepresentation of physical prior, and methods for incorporating physical prior.\nWe also propose several important open research problems based on the current\ntrends in the field. We argue that encoding different forms of physical prior\ninto model architectures, optimizers, inference algorithms, and significant\ndomain-specific applications like inverse engineering design and robotic\ncontrol is far from being fully explored in the field of physics-informed\nmachine learning. We believe that the interdisciplinary research of\nphysics-informed machine learning will significantly propel research progress,\nfoster the creation of more effective machine learning models, and also offer\ninvaluable assistance in addressing long-standing problems in related\ndisciplines.\n","authors":["Zhongkai Hao","Songming Liu","Yichi Zhang","Chengyang Ying","Yao Feng","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2211.08064v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03602v1","updated":"2023-03-07T02:40:16Z","published":"2023-03-07T02:40:16Z","title":"Data Games: A Game-Theoretic Approach to Swarm Robotic Data Collection","summary":"  Fleets of networked autonomous vehicles (AVs) collect terabytes of sensory\ndata, which is often transmitted to central servers (the ''cloud'') for\ntraining machine learning (ML) models. Ideally, these fleets should upload all\ntheir data, especially from rare operating contexts, in order to train robust\nML models. However, this is infeasible due to prohibitive network bandwidth and\ndata labeling costs. Instead, we propose a cooperative data sampling strategy\nwhere geo-distributed AVs collaborate to collect a diverse ML training dataset\nin the cloud. Since the AVs have a shared objective but minimal information\nabout each other's local data distribution and perception model, we can\nnaturally cast cooperative data collection as an $N$-player mathematical game.\nWe show that our cooperative sampling strategy uses minimal information to\nconverge to a centralized oracle policy with complete information about all\nAVs. Moreover, we theoretically characterize the performance benefits of our\ngame-theoretic strategy compared to greedy sampling. Finally, we experimentally\ndemonstrate that our method outperforms standard benchmarks by up to $21.9\\%$\non 4 perception datasets, including for autonomous driving in adverse weather\nconditions. Crucially, our experimental results on real-world datasets closely\nalign with our theoretical guarantees.\n","authors":["Oguzhan Akcin","Po-han Li","Shubhankar Agarwal","Sandeep Chinchali"],"pdf_url":"https://arxiv.org/pdf/2303.03602v1.pdf","comment":"Accepted to CoRL 2022"},{"id":"http://arxiv.org/abs/2210.00030v2","updated":"2023-03-07T02:29:59Z","published":"2022-09-30T18:14:07Z","title":"VIP: Towards Universal Visual Reward and Representation via\n  Value-Implicit Pre-Training","summary":"  Reward and representation learning are two long-standing challenges for\nlearning an expanding set of robot manipulation skills from sensory\nobservations. Given the inherent cost and scarcity of in-domain, task-specific\nrobot data, learning from large, diverse, offline human videos has emerged as a\npromising path towards acquiring a generally useful visual representation for\ncontrol; however, how these human videos can be used for general-purpose reward\nlearning remains an open question. We introduce\n$\\textbf{V}$alue-$\\textbf{I}$mplicit $\\textbf{P}$re-training (VIP), a\nself-supervised pre-trained visual representation capable of generating dense\nand smooth reward functions for unseen robotic tasks. VIP casts representation\nlearning from human videos as an offline goal-conditioned reinforcement\nlearning problem and derives a self-supervised dual goal-conditioned\nvalue-function objective that does not depend on actions, enabling pre-training\non unlabeled human videos. Theoretically, VIP can be understood as a novel\nimplicit time contrastive objective that generates a temporally smooth\nembedding, enabling the value function to be implicitly defined via the\nembedding distance, which can then be used to construct the reward for any\ngoal-image specified downstream task. Trained on large-scale Ego4D human videos\nand without any fine-tuning on in-domain, task-specific data, VIP's frozen\nrepresentation can provide dense visual reward for an extensive set of\nsimulated and $\\textbf{real-robot}$ tasks, enabling diverse reward-based visual\ncontrol methods and significantly outperforming all prior pre-trained\nrepresentations. Notably, VIP can enable simple, $\\textbf{few-shot}$ offline RL\non a suite of real-world robot tasks with as few as 20 trajectories.\n","authors":["Yecheng Jason Ma","Shagun Sodhani","Dinesh Jayaraman","Osbert Bastani","Vikash Kumar","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.00030v2.pdf","comment":"ICLR 2023, Notable-Top-25% (Spotlight). Project website:\n  https://sites.google.com/view/vip-rl"},{"id":"http://arxiv.org/abs/2207.08894v3","updated":"2023-03-07T02:26:25Z","published":"2022-07-18T19:07:56Z","title":"A Deep Reinforcement Learning Approach for Finding Non-Exploitable\n  Strategies in Two-Player Atari Games","summary":"  This paper proposes new, end-to-end deep reinforcement learning algorithms\nfor learning two-player zero-sum Markov games. Different from prior efforts on\ntraining agents to beat a fixed set of opponents, our objective is to find the\nNash equilibrium policies that are free from exploitation by even the\nadversarial opponents. We propose (a) Nash-DQN algorithm, which integrates the\ndeep learning techniques from single DQN into the classic Nash Q-learning\nalgorithm for solving tabular Markov games; (b) Nash-DQN-Exploiter algorithm,\nwhich additionally adopts an exploiter to guide the exploration of the main\nagent. We conduct experimental evaluation on tabular examples as well as\nvarious two-player Atari games. Our empirical results demonstrate that (i) the\npolicies found by many existing methods including Neural Fictitious Self Play\nand Policy Space Response Oracle can be prone to exploitation by adversarial\nopponents; (ii) the output policies of our algorithms are robust to\nexploitation, and thus outperform existing methods.\n","authors":["Zihan Ding","Dijia Su","Qinghua Liu","Chi Jin"],"pdf_url":"https://arxiv.org/pdf/2207.08894v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02307v3","updated":"2023-03-07T02:14:39Z","published":"2022-06-06T01:30:03Z","title":"Bootstrapping Semi-supervised Medical Image Segmentation with\n  Anatomical-aware Contrastive Distillation","summary":"  Contrastive learning has shown great promise over annotation scarcity\nproblems in the context of medical image segmentation. Existing approaches\ntypically assume a balanced class distribution for both labeled and unlabeled\nmedical images. However, medical image data in reality is commonly imbalanced\n(i.e., multi-class label imbalance), which naturally yields blurry contours and\nusually incorrectly labels rare objects. Moreover, it remains unclear whether\nall negative samples are equally negative. In this work, we present ACTION, an\nAnatomical-aware ConTrastive dIstillatiON framework, for semi-supervised\nmedical image segmentation. Specifically, we first develop an iterative\ncontrastive distillation algorithm by softly labeling the negatives rather than\nbinary supervision between positive and negative pairs. We also capture more\nsemantically similar features from the randomly chosen negative set compared to\nthe positives to enforce the diversity of the sampled data. Second, we raise a\nmore important question: Can we really handle imbalanced samples to yield\nbetter performance? Hence, the key innovation in ACTION is to learn global\nsemantic relationship across the entire dataset and local anatomical features\namong the neighbouring pixels with minimal additional memory footprint. During\nthe training, we introduce anatomical contrast by actively sampling a sparse\nset of hard negative pixels, which can generate smoother segmentation\nboundaries and more accurate predictions. Extensive experiments across two\nbenchmark datasets and different unlabeled settings show that ACTION\nsignificantly outperforms the current state-of-the-art semi-supervised methods.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2206.02307v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02733v2","updated":"2023-03-07T02:07:01Z","published":"2023-03-05T17:57:33Z","title":"Reparameterization through Spatial Gradient Scaling","summary":"  Reparameterization aims to improve the generalization of deep neural networks\nby transforming convolutional layers into equivalent multi-branched structures\nduring training. However, there exists a gap in understanding how\nreparameterization may change and benefit the learning process of neural\nnetworks. In this paper, we present a novel spatial gradient scaling method to\nredistribute learning focus among weights in convolutional networks. We prove\nthat spatial gradient scaling achieves the same learning dynamics as a branched\nreparameterization yet without introducing structural changes into the network.\nWe further propose an analytical approach that dynamically learns scalings for\neach convolutional layer based on the spatial characteristics of its input\nfeature map gauged by mutual information. Experiments on CIFAR-10, CIFAR-100,\nand ImageNet show that without searching for reparameterized structures, our\nproposed scaling method outperforms the state-of-the-art reparameterization\nstrategies at a lower computational cost.\n","authors":["Alexander Detkov","Mohammad Salameh","Muhammad Fetrat Qharabagh","Jialin Zhang","Wei Lui","Shangling Jui","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2303.02733v2.pdf","comment":"Published at ICLR 2023. Code available at\n  https://github.com/Ascend-Research/Reparameterization"},{"id":"http://arxiv.org/abs/2303.03581v1","updated":"2023-03-07T01:29:52Z","published":"2023-03-07T01:29:52Z","title":"Neural Compositional Rule Learning for Knowledge Graph Reasoning","summary":"  Learning logical rules is critical to improving reasoning in KGs. This is due\nto their ability to provide logical and interpretable explanations when used\nfor predictions, as well as their ability to generalize to other tasks,\ndomains, and data. While recent methods have been proposed to learn logical\nrules, the majority of these methods are either restricted by their\ncomputational complexity and can not handle the large search space of\nlarge-scale KGs, or show poor generalization when exposed to data outside the\ntraining set. In this paper, we propose an end-to-end neural model for learning\ncompositional logical rules called NCRL. NCRL detects the best compositional\nstructure of a rule body, and breaks it into small compositions in order to\ninfer the rule head. By recurrently merging compositions in the rule body with\na recurrent attention unit, NCRL finally predicts a single rule head.\nExperimental results show that NCRL learns high-quality rules, as well as being\ngeneralizable. Specifically, we show that NCRL is scalable, efficient, and\nyields state-of-the-art results for knowledge graph completion on large-scale\nKGs. Moreover, we test NCRL for systematic generalization by learning to reason\non small-scale observed graphs and evaluating on larger unseen ones.\n","authors":["Kewei Cheng","Nesreen K. Ahmed","Yizhou Sun"],"pdf_url":"https://arxiv.org/pdf/2303.03581v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03572v1","updated":"2023-03-07T00:46:04Z","published":"2023-03-07T00:46:04Z","title":"Learning When to Treat Business Processes: Prescriptive Process\n  Monitoring with Causal Inference and Reinforcement Learning","summary":"  Increasing the success rate of a process, i.e. the percentage of cases that\nend in a positive outcome, is a recurrent process improvement goal. At runtime,\nthere are often certain actions (a.k.a. treatments) that workers may execute to\nlift the probability that a case ends in a positive outcome. For example, in a\nloan origination process, a possible treatment is to issue multiple loan offers\nto increase the probability that the customer takes a loan. Each treatment has\na cost. Thus, when defining policies for prescribing treatments to cases,\nmanagers need to consider the net gain of the treatments. Also, the effect of a\ntreatment varies over time: treating a case earlier may be more effective than\nlater in a case. This paper presents a prescriptive monitoring method that\nautomates this decision-making task. The method combines causal inference and\nreinforcement learning to learn treatment policies that maximize the net gain.\nThe method leverages a conformal prediction technique to speed up the\nconvergence of the reinforcement learning mechanism by separating cases that\nare likely to end up in a positive or negative outcome, from uncertain cases.\nAn evaluation on two real-life datasets shows that the proposed method\noutperforms a state-of-the-art baseline.\n","authors":["Zahra Dasht Bozorgi","Marlon Dumas","Marcello La Rosa","Artem Polyvyanyy","Mahmoud Shoush","Irene Teinemaa"],"pdf_url":"https://arxiv.org/pdf/2303.03572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.12267v2","updated":"2023-03-07T23:43:30Z","published":"2022-09-25T17:13:24Z","title":"Probabilistic Planning with Partially Ordered Preferences over Temporal\n  Goals","summary":"  In this paper, we study planning in stochastic systems, modeled as Markov\ndecision processes (MDPs), with preferences over temporally extended goals.\nPrior work on temporal planning with preferences assumes that the user\npreferences form a total order, meaning that every pair of outcomes are\ncomparable with each other. In this work, we consider the case where the\npreferences over possible outcomes are a partial order rather than a total\norder. We first introduce a variant of deterministic finite automaton, referred\nto as a preference DFA, for specifying the user's preferences over temporally\nextended goals. Based on the order theory, we translate the preference DFA to a\npreference relation over policies for probabilistic planning in a labeled MDP.\nIn this treatment, a most preferred policy induces a weak-stochastic\nnondominated probability distribution over the finite paths in the MDP. The\nproposed planning algorithm hinges on the construction of a multi-objective\nMDP. We prove that a weak-stochastic nondominated policy given the preference\nspecification is Pareto-optimal in the constructed multi-objective MDP, and\nvice versa. Throughout the paper, we employ a running example to demonstrate\nthe proposed preference specification and solution approaches. We show the\nefficacy of our algorithm using the example with detailed analysis, and then\ndiscuss possible future directions.\n","authors":["Hazhar Rahmani","Abhishek N. Kulkarni","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2209.12267v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.01888v4","updated":"2023-03-07T23:36:04Z","published":"2022-06-04T03:15:57Z","title":"Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning","summary":"  In offline multi-agent reinforcement learning (MARL), agents estimate\npolicies from a given dataset. We study reward-poisoning attacks in this\nsetting where an exogenous attacker modifies the rewards in the dataset before\nthe agents see the dataset. The attacker wants to guide each agent into a\nnefarious target policy while minimizing the $L^p$ norm of the reward\nmodification. Unlike attacks on single-agent RL, we show that the attacker can\ninstall the target policy as a Markov Perfect Dominant Strategy Equilibrium\n(MPDSE), which rational agents are guaranteed to follow. This attack can be\nsignificantly cheaper than separate single-agent attacks. We show that the\nattack works on various MARL agents including uncertainty-aware learners, and\nwe exhibit linear programs to efficiently solve the attack problem. We also\nstudy the relationship between the structure of the datasets and the minimal\nattack cost. Our work paves the way for studying defense in offline MARL.\n","authors":["Young Wu","Jeremy McMahan","Xiaojin Zhu","Qiaomin Xie"],"pdf_url":"https://arxiv.org/pdf/2206.01888v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04283v1","updated":"2023-03-07T23:05:38Z","published":"2023-03-07T23:05:38Z","title":"Fast and Slow Planning","summary":"  The concept of Artificial Intelligence has gained a lot of attention over the\nlast decade. In particular, AI-based tools have been employed in several\nscenarios and are, by now, pervading our everyday life. Nonetheless, most of\nthese systems lack many capabilities that we would naturally consider to be\nincluded in a notion of \"intelligence\". In this work, we present an\narchitecture that, inspired by the cognitive theory known as Thinking Fast and\nSlow by D. Kahneman, is tasked with solving planning problems in different\nsettings, specifically: classical and multi-agent epistemic. The system\nproposed is an instance of a more general AI paradigm, referred to as SOFAI\n(for Slow and Fast AI). SOFAI exploits multiple solving approaches, with\ndifferent capabilities that characterize them as either fast or slow, and a\nmetacognitive module to regulate them. This combination of components, which\nroughly reflects the human reasoning process according to D. Kahneman, allowed\nus to enhance the reasoning process that, in this case, is concerned with\nplanning in two different settings. The behavior of this system is then\ncompared to state-of-the-art solvers, showing that the newly introduced system\npresents better results in terms of generality, solving a wider set of problems\nwith an acceptable trade-off between solving times and solution accuracy.\n","authors":["Francesco Fabiano","Vishal Pallagani","Marianna Bergamaschi Ganapini","Lior Horesh","Andrea Loreggia","Keerthiram Murugesan","Francesca Rossi","Biplav Srivastava"],"pdf_url":"https://arxiv.org/pdf/2303.04283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04275v1","updated":"2023-03-07T22:53:36Z","published":"2023-03-07T22:53:36Z","title":"A Computer Vision Enabled damage detection model with improved YOLOv5\n  based on Transformer Prediction Head","summary":"  Objective:Computer vision-based up-to-date accurate damage classification and\nlocalization are of decisive importance for infrastructure monitoring, safety,\nand the serviceability of civil infrastructure. Current state-of-the-art deep\nlearning (DL)-based damage detection models, however, often lack superior\nfeature extraction capability in complex and noisy environments, limiting the\ndevelopment of accurate and reliable object distinction. Method: To this end,\nwe present DenseSPH-YOLOv5, a real-time DL-based high-performance damage\ndetection model where DenseNet blocks have been integrated with the backbone to\nimprove in preserving and reusing critical feature information. Additionally,\nconvolutional block attention modules (CBAM) have been implemented to improve\nattention performance mechanisms for strong and discriminating deep spatial\nfeature extraction that results in superior detection under various challenging\nenvironments. Moreover, additional feature fusion layers and a Swin-Transformer\nPrediction Head (SPH) have been added leveraging advanced self-attention\nmechanism for more efficient detection of multiscale object sizes and\nsimultaneously reducing the computational complexity. Results: Evaluating the\nmodel performance in large-scale Road Damage Dataset (RDD-2018), at a detection\nrate of 62.4 FPS, DenseSPH-YOLOv5 obtains a mean average precision (mAP) value\nof 85.25 %, F1-score of 81.18 %, and precision (P) value of 89.51 %\noutperforming current state-of-the-art models. Significance: The present\nresearch provides an effective and efficient damage localization model\naddressing the shortcoming of existing DL-based damage detection models by\nproviding highly accurate localized bounding box prediction. Current work\nconstitutes a step towards an accurate and robust automated damage detection\nsystem in real-time in-field applications.\n","authors":["Arunabha M. Roy","Jayabrata Bhaduri"],"pdf_url":"https://arxiv.org/pdf/2303.04275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.01911v3","updated":"2023-03-07T22:46:55Z","published":"2022-07-05T09:43:17Z","title":"Explainability in Deep Reinforcement Learning, a Review into Current\n  Methods and Applications","summary":"  The use of Deep Reinforcement Learning (DRL) schemes has increased\ndramatically since their first introduction in 2015. Though uses in many\ndifferent applications are being found, they still have a problem with the lack\nof interpretability. This has bread a lack of understanding and trust in the\nuse of DRL solutions from researchers and the general public. To solve this\nproblem, the field of Explainable Artificial Intelligence (XAI) has emerged.\nThis entails a variety of different methods that look to open the DRL black\nboxes, ranging from the use of interpretable symbolic Decision Trees (DT) to\nnumerical methods like Shapley Values. This review looks at which methods are\nbeing used and for which applications. This is done to identify which models\nare the best suited to each application or if a method is being underutilised.\n","authors":["Thomas Hickling","Abdelhafid Zenati","Nabil Aouf","Phillippa Spencer"],"pdf_url":"https://arxiv.org/pdf/2207.01911v3.pdf","comment":"30 pages, 6 figures, Paper Review"},{"id":"http://arxiv.org/abs/2303.04268v1","updated":"2023-03-07T22:39:23Z","published":"2023-03-07T22:39:23Z","title":"On the Sample Complexity of Vanilla Model-Based Offline Reinforcement\n  Learning with Dependent Samples","summary":"  Offline reinforcement learning (offline RL) considers problems where learning\nis performed using only previously collected samples and is helpful for the\nsettings in which collecting new data is costly or risky. In model-based\noffline RL, the learner performs estimation (or optimization) using a model\nconstructed according to the empirical transition frequencies. We analyze the\nsample complexity of vanilla model-based offline RL with dependent samples in\nthe infinite-horizon discounted-reward setting. In our setting, the samples\nobey the dynamics of the Markov decision process and, consequently, may have\ninterdependencies. Under no assumption of independent samples, we provide a\nhigh-probability, polynomial sample complexity bound for vanilla model-based\noff-policy evaluation that requires partial or uniform coverage. We extend this\nresult to the off-policy optimization under uniform coverage. As a comparison\nto the model-based approach, we analyze the sample complexity of off-policy\nevaluation with vanilla importance sampling in the infinite-horizon setting.\nFinally, we provide an estimator that outperforms the sample-mean estimator for\nalmost deterministic dynamics that are prevalent in reinforcement learning.\n","authors":["Mustafa O. Karabag","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2303.04268v1.pdf","comment":"Accepted to AAAI-23"},{"id":"http://arxiv.org/abs/2212.06864v2","updated":"2023-03-07T22:29:37Z","published":"2022-12-10T01:50:35Z","title":"Task-Adaptive Meta-Learning Framework for Advancing Spatial\n  Generalizability","summary":"  Spatio-temporal machine learning is critically needed for a variety of\nsocietal applications, such as agricultural monitoring, hydrological forecast,\nand traffic management. These applications greatly rely on regional features\nthat characterize spatial and temporal differences. However, spatio-temporal\ndata often exhibit complex patterns and significant data variability across\ndifferent locations. The labels in many real-world applications can also be\nlimited, which makes it difficult to separately train independent models for\ndifferent locations. Although meta learning has shown promise in model\nadaptation with small samples, existing meta learning methods remain limited in\nhandling a large number of heterogeneous tasks, e.g., a large number of\nlocations with varying data patterns. To bridge the gap, we propose\ntask-adaptive formulations and a model-agnostic meta-learning framework that\nensembles regionally heterogeneous data into location-sensitive meta tasks. We\nconduct task adaptation following an easy-to-hard task hierarchy in which\ndifferent meta models are adapted to tasks of different difficulty levels. One\nmajor advantage of our proposed method is that it improves the model adaptation\nto a large number of heterogeneous tasks. It also enhances the model\ngeneralization by automatically adapting the meta model of the corresponding\ndifficulty level to any new tasks. We demonstrate the superiority of our\nproposed framework over a diverse set of baselines and state-of-the-art\nmeta-learning frameworks. Our extensive experiments on real crop yield data\nshow the effectiveness of the proposed method in handling spatial-related\nheterogeneous tasks in real societal applications.\n","authors":["Zhexiong Liu","Licheng Liu","Yiqun Xie","Zhenong Jin","Xiaowei Jia"],"pdf_url":"https://arxiv.org/pdf/2212.06864v2.pdf","comment":"In the Thirty-Seventh AAAI Conference on Artificial Intelligence,\n  February 2023"},{"id":"http://arxiv.org/abs/2303.04257v1","updated":"2023-03-07T21:55:22Z","published":"2023-03-07T21:55:22Z","title":"adaPARL: Adaptive Privacy-Aware Reinforcement Learning for\n  Sequential-Decision Making Human-in-the-Loop Systems","summary":"  Reinforcement learning (RL) presents numerous benefits compared to rule-based\napproaches in various applications. Privacy concerns have grown with the\nwidespread use of RL trained with privacy-sensitive data in IoT devices,\nespecially for human-in-the-loop systems. On the one hand, RL methods enhance\nthe user experience by trying to adapt to the highly dynamic nature of humans.\nOn the other hand, trained policies can leak the user's private information.\nRecent attention has been drawn to designing privacy-aware RL algorithms while\nmaintaining an acceptable system utility. A central challenge in designing\nprivacy-aware RL, especially for human-in-the-loop systems, is that humans have\nintrinsic variability and their preferences and behavior evolve. The effect of\none privacy leak mitigation can be different for the same human or across\ndifferent humans over time. Hence, we can not design one fixed model for\nprivacy-aware RL that fits all. To that end, we propose adaPARL, an adaptive\napproach for privacy-aware RL, especially for human-in-the-loop IoT systems.\nadaPARL provides a personalized privacy-utility trade-off depending on human\nbehavior and preference. We validate the proposed adaPARL on two IoT\napplications, namely (i) Human-in-the-Loop Smart Home and (ii)\nHuman-in-the-Loop Virtual Reality (VR) Smart Classroom. Results obtained on\nthese two applications validate the generality of adaPARL and its ability to\nprovide a personalized privacy-utility trade-off. On average, for the first\napplication, adaPARL improves the utility by $57\\%$ over the baseline and by\n$43\\%$ over randomization. adaPARL also reduces the privacy leak by $23\\%$ on\naverage. For the second application, adaPARL decreases the privacy leak to\n$44\\%$ before the utility drops by $15\\%$.\n","authors":["Mojtaba Taherisadr","Stelios Andrew Stavroulakis","Salma Elmalaki"],"pdf_url":"https://arxiv.org/pdf/2303.04257v1.pdf","comment":"This paper is accepted at CPS-IoT week (IoTDI'23)"},{"id":"http://arxiv.org/abs/2303.04238v1","updated":"2023-03-07T21:03:48Z","published":"2023-03-07T21:03:48Z","title":"Patch of Invisibility: Naturalistic Black-Box Adversarial Attacks on\n  Object Detectors","summary":"  Adversarial attacks on deep-learning models have been receiving increased\nattention in recent years. Work in this area has mostly focused on\ngradient-based techniques, so-called white-box attacks, wherein the attacker\nhas access to the targeted model's internal parameters; such an assumption is\nusually unrealistic in the real world. Some attacks additionally use the entire\npixel space to fool a given model, which is neither practical nor physical\n(i.e., real-world). On the contrary, we propose herein a gradient-free method\nthat uses the learned image manifold of a pretrained generative adversarial\nnetwork (GAN) to generate naturalistic physical adversarial patches for object\ndetectors. We show that our proposed method works both digitally and\nphysically.\n","authors":["Raz Lapid","Moshe Sipper"],"pdf_url":"https://arxiv.org/pdf/2303.04238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.06169v2","updated":"2023-03-07T20:46:58Z","published":"2022-06-13T13:56:40Z","title":"Causal Representation Learning for Instantaneous and Temporal Effects in\n  Interactive Systems","summary":"  Causal representation learning is the task of identifying the underlying\ncausal variables and their relations from high-dimensional observations, such\nas images. Recent work has shown that one can reconstruct the causal variables\nfrom temporal sequences of observations under the assumption that there are no\ninstantaneous causal relations between them. In practical applications,\nhowever, our measurement or frame rate might be slower than many of the causal\neffects. This effectively creates \"instantaneous\" effects and invalidates\nprevious identifiability results. To address this issue, we propose iCITRIS, a\ncausal representation learning method that allows for instantaneous effects in\nintervened temporal sequences when intervention targets can be observed, e.g.,\nas actions of an agent. iCITRIS identifies the potentially multidimensional\ncausal variables from temporal observations, while simultaneously using a\ndifferentiable causal discovery method to learn their causal graph. In\nexperiments on three datasets of interactive systems, iCITRIS accurately\nidentifies the causal variables and their causal graph.\n","authors":["Phillip Lippe","Sara Magliacane","Sindy Löwe","Yuki M. Asano","Taco Cohen","Efstratios Gavves"],"pdf_url":"https://arxiv.org/pdf/2206.06169v2.pdf","comment":"Published at International Conference on Learning Representations\n  (ICLR), 2023"},{"id":"http://arxiv.org/abs/2303.04226v1","updated":"2023-03-07T20:36:13Z","published":"2023-03-07T20:36:13Z","title":"A Comprehensive Survey of AI-Generated Content (AIGC): A History of\n  Generative AI from GAN to ChatGPT","summary":"  Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant\nattention from society. As a result, many individuals have become interested in\nrelated resources and are seeking to uncover the background and secrets behind\nits impressive performance. In fact, ChatGPT and other Generative AI (GAI)\ntechniques belong to the category of Artificial Intelligence Generated Content\n(AIGC), which involves the creation of digital content, such as images, music,\nand natural language, through AI models. The goal of AIGC is to make the\ncontent creation process more efficient and accessible, allowing for the\nproduction of high-quality content at a faster pace. AIGC is achieved by\nextracting and understanding intent information from instructions provided by\nhuman, and generating the content according to its knowledge and the intent\ninformation. In recent years, large-scale models have become increasingly\nimportant in AIGC as they provide better intent extraction and thus, improved\ngeneration results. With the growth of data and the size of the models, the\ndistribution that the model can learn becomes more comprehensive and closer to\nreality, leading to more realistic and high-quality content generation. This\nsurvey provides a comprehensive review on the history of generative models, and\nbasic components, recent advances in AIGC from unimodal interaction and\nmultimodal interaction. From the perspective of unimodality, we introduce the\ngeneration tasks and relative models of text and image. From the perspective of\nmultimodality, we introduce the cross-application between the modalities\nmentioned above. Finally, we discuss the existing open problems and future\nchallenges in AIGC.\n","authors":["Yihan Cao","Siyu Li","Yixin Liu","Zhiling Yan","Yutong Dai","Philip S. Yu","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2303.04226v1.pdf","comment":"44 pages, 15 figures"},{"id":"http://arxiv.org/abs/2303.04217v1","updated":"2023-03-07T20:21:43Z","published":"2023-03-07T20:21:43Z","title":"AI for Science: An Emerging Agenda","summary":"  This report documents the programme and the outcomes of Dagstuhl Seminar\n22382 \"Machine Learning for Science: Bridging Data-Driven and Mechanistic\nModelling\". Today's scientific challenges are characterised by complexity.\nInterconnected natural, technological, and human systems are influenced by\nforces acting across time- and spatial-scales, resulting in complex\ninteractions and emergent behaviours. Understanding these phenomena -- and\nleveraging scientific advances to deliver innovative solutions to improve\nsociety's health, wealth, and well-being -- requires new ways of analysing\ncomplex systems. The transformative potential of AI stems from its widespread\napplicability across disciplines, and will only be achieved through integration\nacross research domains. AI for science is a rendezvous point. It brings\ntogether expertise from $\\mathrm{AI}$ and application domains; combines\nmodelling knowledge with engineering know-how; and relies on collaboration\nacross disciplines and between humans and machines. Alongside technical\nadvances, the next wave of progress in the field will come from building a\ncommunity of machine learning researchers, domain experts, citizen scientists,\nand engineers working together to design and deploy effective AI tools. This\nreport summarises the discussions from the seminar and provides a roadmap to\nsuggest how different communities can collaborate to deliver a new wave of\nprogress in AI and its application for scientific discovery.\n","authors":["Philipp Berens","Kyle Cranmer","Neil D. Lawrence","Ulrike von Luxburg","Jessica Montgomery"],"pdf_url":"https://arxiv.org/pdf/2303.04217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04209v1","updated":"2023-03-07T20:00:42Z","published":"2023-03-07T20:00:42Z","title":"Causal Dependence Plots for Interpretable Machine Learning","summary":"  Explaining artificial intelligence or machine learning models is an\nincreasingly important problem. For humans to stay in the loop and control such\nsystems, we must be able to understand how they interact with the world. This\nwork proposes using known or assumed causal structure in the input variables to\nproduce simple and practical explanations of supervised learning models. Our\nexplanations -- which we name Causal Dependence Plots or CDP -- visualize how\nthe model output depends on changes in a given predictor \\emph{along with any\nconsequent causal changes in other predictors}. Since this causal dependence\ncaptures how humans often think about input-output dependence, CDPs can be\npowerful tools in the explainable AI or interpretable ML toolkit and contribute\nto applications including scientific machine learning and algorithmic fairness.\nCDP can also be used for model-agnostic or black-box explanations.\n","authors":["Joshua R. Loftus","Lucius E. J. Bynum","Sakina Hansen"],"pdf_url":"https://arxiv.org/pdf/2303.04209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04193v1","updated":"2023-03-07T19:31:25Z","published":"2023-03-07T19:31:25Z","title":"A Strategy-Oriented Bayesian Soft Actor-Critic Model","summary":"  Adopting reasonable strategies is challenging but crucial for an intelligent\nagent with limited resources working in hazardous, unstructured, and dynamic\nenvironments to improve the system's utility, decrease the overall cost, and\nincrease mission success probability. This paper proposes a novel hierarchical\nstrategy decomposition approach based on the Bayesian chain rule to separate an\nintricate policy into several simple sub-policies and organize their\nrelationships as Bayesian strategy networks (BSN). We integrate this approach\ninto the state-of-the-art DRL method -- soft actor-critic (SAC) and build the\ncorresponding Bayesian soft actor-critic (BSAC) model by organizing several\nsub-policies as a joint policy. We compare the proposed BSAC method with the\nSAC and other state-of-the-art approaches such as TD3, DDPG, and PPO on the\nstandard continuous control benchmarks -- Hopper-v2, Walker2d-v2, and\nHumanoid-v2 -- in MuJoCo with the OpenAI Gym environment. The results\ndemonstrate that the promising potential of the BSAC method significantly\nimproves training efficiency.\n","authors":["Qin Yang","Ramviyas Parasuraman"],"pdf_url":"https://arxiv.org/pdf/2303.04193v1.pdf","comment":"Accepted by the Elsevier Science 14th International Conference on\n  Ambient Systems, Networks and Technologies (ANT 2023). arXiv admin note:\n  substantial text overlap with arXiv:2208.06033, arXiv:2302.13132"},{"id":"http://arxiv.org/abs/2303.04186v1","updated":"2023-03-07T19:16:20Z","published":"2023-03-07T19:16:20Z","title":"End-to-end Face-swapping via Adaptive Latent Representation Learning","summary":"  Taking full advantage of the excellent performance of StyleGAN, style\ntransfer-based face swapping methods have been extensively investigated\nrecently. However, these studies require separate face segmentation and\nblending modules for successful face swapping, and the fixed selection of the\nmanipulated latent code in these works is reckless, thus degrading face\nswapping quality, generalizability, and practicability. This paper proposes a\nnovel and end-to-end integrated framework for high resolution and attribute\npreservation face swapping via Adaptive Latent Representation Learning.\nSpecifically, we first design a multi-task dual-space face encoder by sharing\nthe underlying feature extraction network to simultaneously complete the facial\nregion perception and face encoding. This encoder enables us to control the\nface pose and attribute individually, thus enhancing the face swapping quality.\nNext, we propose an adaptive latent codes swapping module to adaptively learn\nthe mapping between the facial attributes and the latent codes and select\neffective latent codes for improved retention of facial attributes. Finally,\nthe initial face swapping image generated by StyleGAN2 is blended with the\nfacial region mask generated by our encoder to address the background blur\nproblem. Our framework integrating facial perceiving and blending into the\nend-to-end training and testing process can achieve high realistic\nface-swapping on wild faces without segmentation masks. Experimental results\ndemonstrate the superior performance of our approach over state-of-the-art\nmethods.\n","authors":["Chenhao Lin","Pengbin Hu","Chao Shen","Qian Li"],"pdf_url":"https://arxiv.org/pdf/2303.04186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04185v1","updated":"2023-03-07T19:12:31Z","published":"2023-03-07T19:12:31Z","title":"Gradient-Free Structured Pruning with Unlabeled Data","summary":"  Large Language Models (LLMs) have achieved great success in solving difficult\ntasks across many domains, but such success comes with a high computation cost,\nand inference latency. As developers and third parties customize these models,\nthe need to provide efficient inference has increased. Many efforts have\nattempted to reduce inference cost through model compression techniques such as\npruning and distillation. However, these techniques either require labeled\ndata, or are time-consuming as they require the compressed model to be\nretrained to regain accuracy. In this paper, we propose a gradient-free\nstructured pruning framework that uses only unlabeled data. An evaluation on\nthe GLUE and SQuAD benchmarks using BERT$_{BASE}$ and DistilBERT illustrates\nthe effectiveness of the proposed approach. By only using the weights of the\npre-trained model and unlabeled data, in a matter of a few minutes on a single\nGPU, up to 40% of the original FLOP count can be reduced with less than a 4%\naccuracy loss across all tasks considered.\n","authors":["Azade Nova","Hanjun Dai","Dale Schuurmans"],"pdf_url":"https://arxiv.org/pdf/2303.04185v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2010.14648v5","updated":"2023-03-07T19:09:59Z","published":"2020-10-27T22:23:04Z","title":"Formally Verified SAT-Based AI Planning","summary":"  We present an executable formally verified SAT encoding of classical AI\nplanning. We use the theorem prover Isabelle/HOL to perform the verification.\nWe experimentally test the verified encoding and show that it can be used for\nreasonably sized standard planning benchmarks. We also use it as a reference to\ntest a state-of-the-art SAT-based planner, showing that it sometimes falsely\nclaims that problems have no solutions of certain lengths.\n","authors":["Mohammad Abdulaziz","Friedrich Kurz"],"pdf_url":"https://arxiv.org/pdf/2010.14648v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04156v1","updated":"2023-03-07T17:26:18Z","published":"2023-03-07T17:26:18Z","title":"Computing with Categories in Machine Learning","summary":"  Category theory has been successfully applied in various domains of science,\nshedding light on universal principles unifying diverse phenomena and thereby\nenabling knowledge transfer between them. Applications to machine learning have\nbeen pursued recently, and yet there is still a gap between abstract\nmathematical foundations and concrete applications to machine learning tasks.\nIn this paper we introduce DisCoPyro as a categorical structure learning\nframework, which combines categorical structures (such as symmetric monoidal\ncategories and operads) with amortized variational inference, and can be\napplied, e.g., in program learning for variational autoencoders. We provide\nboth mathematical foundations and concrete applications together with\ncomparison of experimental performance with other models (e.g., neuro-symbolic\nmodels). We speculate that DisCoPyro could ultimately contribute to the\ndevelopment of artificial general intelligence.\n","authors":["Eli Sennesh","Tom Xu","Yoshihiro Maruyama"],"pdf_url":"https://arxiv.org/pdf/2303.04156v1.pdf","comment":"Submitted to AGI 2023"},{"id":"http://arxiv.org/abs/2303.04154v1","updated":"2023-03-07T16:05:24Z","published":"2023-03-07T16:05:24Z","title":"Adaptive Weighted Multiview Kernel Matrix Factorization with its\n  application in Alzheimer's Disease Analysis -- A clustering Perspective","summary":"  Recent technology and equipment advancements provide with us opportunities to\nbetter analyze Alzheimer's disease (AD), where we could collect and employ the\ndata from different image and genetic modalities that may potentially enhance\nthe predictive performance. To perform better clustering in AD analysis, in\nthis paper we propose a novel model to leverage data from all different\nmodalities/views, which can learn the weights of each view adaptively.\nDifferent from previous vanilla Non-negative Matrix Factorization which assumes\ndata is linearly separable, we propose a simple yet efficient method based on\nkernel matrix factorization, which is not only able to deal with non-linear\ndata structure but also can achieve better prediction accuracy. Experimental\nresults on ADNI dataset demonstrate the effectiveness of our proposed method,\nwhich indicate promising prospects of kernel application in AD analysis.\n","authors":["Kai Liu","Yarui Cao"],"pdf_url":"https://arxiv.org/pdf/2303.04154v1.pdf","comment":"2 figures"},{"id":"http://arxiv.org/abs/2303.04592v1","updated":"2023-03-07T03:37:47Z","published":"2023-03-07T03:37:47Z","title":"Controlled Diversity with Preference : Towards Learning a Diverse Set of\n  Desired Skills","summary":"  Autonomously learning diverse behaviors without an extrinsic reward signal\nhas been a problem of interest in reinforcement learning. However, the nature\nof learning in such mechanisms is unconstrained, often resulting in the\naccumulation of several unusable, unsafe or misaligned skills. In order to\navoid such issues and ensure the discovery of safe and human-aligned skills, it\nis necessary to incorporate humans into the unsupervised training process,\nwhich remains a largely unexplored research area. In this work, we propose\nControlled Diversity with Preference (CDP), a novel, collaborative human-guided\nmechanism for an agent to learn a set of skills that is diverse as well as\ndesirable. The key principle is to restrict the discovery of skills to those\nregions that are deemed to be desirable as per a preference model trained using\nhuman preference labels on trajectory pairs. We evaluate our approach on 2D\nnavigation and Mujoco environments and demonstrate the ability to discover\ndiverse, yet desirable skills.\n","authors":["Maxence Hussonnois","Thommen George Karimpanal","Santu Rana"],"pdf_url":"https://arxiv.org/pdf/2303.04592v1.pdf","comment":"Accepted to AAMAS 2023"}]},"2023-03-08T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2303.04794v1","updated":"2023-03-08T18:43:39Z","published":"2023-03-08T18:43:39Z","title":"Comprehensive Event Representations using Event Knowledge Graphs and\n  Natural Language Processing","summary":"  Recent work has utilised knowledge-aware approaches to natural language\nunderstanding, question answering, recommendation systems, and other tasks.\nThese approaches rely on well-constructed and large-scale knowledge graphs that\ncan be useful for many downstream applications and empower knowledge-aware\nmodels with commonsense reasoning. Such knowledge graphs are constructed\nthrough knowledge acquisition tasks such as relation extraction and knowledge\ngraph completion. This work seeks to utilise and build on the growing body of\nwork that uses findings from the field of natural language processing (NLP) to\nextract knowledge from text and build knowledge graphs. The focus of this\nresearch project is on how we can use transformer-based approaches to extract\nand contextualise event information, matching it to existing ontologies, to\nbuild a comprehensive knowledge of graph-based event representations.\nSpecifically, sub-event extraction is used as a way of creating sub-event-aware\nevent representations. These event representations are then further enriched\nthrough fine-grained location extraction and contextualised through the\nalignment of historically relevant quotes.\n","authors":["Tin Kuculo"],"pdf_url":"https://arxiv.org/pdf/2303.04794v1.pdf","comment":"This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution. The definitive Version of Record was\n  published in Companion Proceedings of the Web Conference 2022"},{"id":"http://arxiv.org/abs/2303.04729v1","updated":"2023-03-08T17:15:58Z","published":"2023-03-08T17:15:58Z","title":"On the Risks of Stealing the Decoding Algorithms of Language Models","summary":"  A key component of generating text from modern language models (LM) is the\nselection and tuning of decoding algorithms. These algorithms determine how to\ngenerate text from the internal probability distribution generated by the LM.\nThe process of choosing a decoding algorithm and tuning its hyperparameters\ntakes significant time, manual effort, and computation, and it also requires\nextensive human evaluation. Therefore, the identity and hyperparameters of such\ndecoding algorithms are considered to be extremely valuable to their owners. In\nthis work, we show, for the first time, that an adversary with typical API\naccess to an LM can steal the type and hyperparameters of its decoding\nalgorithms at very low monetary costs. Our attack is effective against popular\nLMs used in text generation APIs, including GPT-2 and GPT-3. We demonstrate the\nfeasibility of stealing such information with only a few dollars, e.g.,\n$\\$0.8$, $\\$1$, $\\$4$, and $\\$40$ for the four versions of GPT-3.\n","authors":["Ali Naseh","Kalpesh Krishna","Mohit Iyyer","Amir Houmansadr"],"pdf_url":"https://arxiv.org/pdf/2303.04729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04715v1","updated":"2023-03-08T16:53:19Z","published":"2023-03-08T16:53:19Z","title":"Extending the Pre-Training of BLOOM for Improved Support of Traditional\n  Chinese: Models, Methods and Results","summary":"  In this paper we present the multilingual language model BLOOM-zh that\nfeatures enhanced support for Traditional Chinese. BLOOM-zh has its origins in\nthe open-source BLOOM models presented by BigScience in 2022. Starting from\nreleased models, we extended the pre-training of BLOOM by additional 7.4\nbillion tokens in Traditional Chinese and English covering a variety of domains\nsuch as news articles, books, encyclopedias, educational materials as well as\nspoken language. In order to show the properties of BLOOM-zh, both existing and\nnewly created benchmark scenarios are used for evaluating the performance.\nBLOOM-zh outperforms its predecessor on most Traditional Chinese benchmarks\nwhile maintaining its English capability. We release all our models to the\nresearch community.\n","authors":["Philipp Ennen","Po-Chun Hsu","Chan-Jan Hsu","Chang-Le Liu","Yen-Chen Wu","Yin-Hsiang Liao","Chin-Tung Lin","Da-Shan Shiu","Wei-Yun Ma"],"pdf_url":"https://arxiv.org/pdf/2303.04715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.17517v2","updated":"2023-03-08T16:47:46Z","published":"2022-10-31T17:41:26Z","title":"Lila: A Unified Benchmark for Mathematical Reasoning","summary":"  Mathematical reasoning skills are essential for general-purpose intelligent\nsystems to perform tasks from grocery shopping to climate modeling. Towards\nevaluating and improving AI systems in this domain, we propose LILA, a unified\nmathematical reasoning benchmark consisting of 23 diverse tasks along four\ndimensions: (i) mathematical abilities e.g., arithmetic, calculus (ii) language\nformat e.g., question-answering, fill-in-the-blanks (iii) language diversity\ne.g., no language, simple language (iv) external knowledge e.g., commonsense,\nphysics. We construct our benchmark by extending 20 datasets benchmark by\ncollecting task instructions and solutions in the form of Python programs,\nthereby obtaining explainable solutions in addition to the correct answer. We\nadditionally introduce two evaluation datasets to measure out-of-distribution\nperformance and robustness to language perturbation. Finally, we introduce\nBHASKARA, a general-purpose mathematical reasoning model trained on LILA.\nImportantly, we find that multi-tasking leads to significant improvements\n(average relative improvement of 21.83% F1 score vs. single-task models), while\nthe best performing model only obtains 60.40%, indicating the room for\nimprovement in general mathematical reasoning and understanding.\n","authors":["Swaroop Mishra","Matthew Finlayson","Pan Lu","Leonard Tang","Sean Welleck","Chitta Baral","Tanmay Rajpurohit","Oyvind Tafjord","Ashish Sabharwal","Peter Clark","Ashwin Kalyan"],"pdf_url":"https://arxiv.org/pdf/2210.17517v2.pdf","comment":"EMNLP 2022"},{"id":"http://arxiv.org/abs/2303.04691v1","updated":"2023-03-08T16:32:10Z","published":"2023-03-08T16:32:10Z","title":"Self-contained Beta-with-Spikes Approximation for Inference Under a\n  Wright-Fisher Model","summary":"  We construct a reliable estimation of evolutionary parameters within the\nWright-Fisher model, which describes changes in allele frequencies due to\nselection and genetic drift, from time-series data. Such data exists for\nbiological populations, for example via artificial evolution experiments, and\nfor the cultural evolution of behavior, such as linguistic corpora that\ndocument historical usage of different words with similar meanings. Our method\nof analysis builds on a Beta-with-Spikes approximation to the distribution of\nallele frequencies predicted by the Wright-Fisher model. We introduce a\nself-contained scheme for estimating the parameters in the approximation, and\ndemonstrate its robustness with synthetic data, especially in the\nstrong-selection and near-extinction regimes where previous approaches fail. We\nfurther apply to allele frequency data for baker's yeast (Saccharomyces\ncerevisiae), finding a significant signal of selection in cases where\nindependent evidence supports such a conclusion. We further demonstrate the\npossibility of detecting time-points at which evolutionary parameters change in\nthe context of a historical spelling reform in the Spanish language.\n","authors":["Juan Guerrero Montero","Richard A. Blythe"],"pdf_url":"https://arxiv.org/pdf/2303.04691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04673v1","updated":"2023-03-08T15:52:14Z","published":"2023-03-08T15:52:14Z","title":"Cost-Effective Hyperparameter Optimization for Large Language Model\n  Generation Inference","summary":"  Large Language Models (LLMs) like GPT-3 have sparked significant interest in\ntheir generative capabilities, leading to the development of various commercial\napplications. The high cost of using the models drives application builders to\nmaximize the value of generation under a limited inference budget. This paper\npresents a study of optimizing inference hyperparameters like the number of\nresponses, temperature and max tokens, which significantly affects the\nutility/cost of text generation. We design a framework named EcoOptiGen which\nleverages economical hyperparameter optimization and cost-based pruning.\nExperiments with the latest GPT-3.5 models on a variety of tasks verify its\neffectiveness. EcoOptiGen is implemented in the FLAML library:\nhttps://github.com/microsoft/FLAML, and we provide one example of using it at:\nhttps://microsoft.github.io/FLAML/docs/Examples/Integrate%20-%20OpenAI.\n","authors":["Chi Wang","Susan Xueqing Liu","Ahmed H. Awadallah"],"pdf_url":"https://arxiv.org/pdf/2303.04673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.15720v3","updated":"2023-03-08T13:35:04Z","published":"2021-10-08T20:17:10Z","title":"Weakly Supervised Concept Map Generation through Task-Guided Graph\n  Translation","summary":"  Recent years have witnessed the rapid development of concept map generation\ntechniques due to their advantages in providing well-structured summarization\nof knowledge from free texts. Traditional unsupervised methods do not generate\ntask-oriented concept maps, whereas deep generative models require large\namounts of training data. In this work, we present GT-D2G (Graph\nTranslation-based Document To Graph), an automatic concept map generation\nframework that leverages generalized NLP pipelines to derive semantic-rich\ninitial graphs, and translates them into more concise structures under the weak\nsupervision of downstream task labels. The concept maps generated by GT-D2G can\nprovide interpretable summarization of structured knowledge for the input\ntexts, which are demonstrated through human evaluation and case studies on\nthree real-world corpora. Further experiments on the downstream task of\ndocument classification show that GT-D2G beats other concept map generation\nmethods. Moreover, we specifically validate the labeling efficiency of GT-D2G\nin the label-efficient learning setting and the flexibility of generated graph\nsizes in controlled hyper-parameter studies.\n","authors":["Jiaying Lu","Xiangjue Dong","Carl Yang"],"pdf_url":"https://arxiv.org/pdf/2110.15720v3.pdf","comment":"Accepted by IEEE TKDE. All code and data available at\n  https://github.com/lujiaying/GT-doc2graph"},{"id":"http://arxiv.org/abs/2303.04562v1","updated":"2023-03-08T13:21:27Z","published":"2023-03-08T13:21:27Z","title":"Extrapolative Controlled Sequence Generation via Iterative Refinement","summary":"  We study the problem of extrapolative controlled generation, i.e., generating\nsequences with attribute values beyond the range seen in training. This task is\nof significant importance in automated design, especially drug discovery, where\nthe goal is to design novel proteins that are \\textit{better} (e.g., more\nstable) than existing sequences. Thus, by definition, the target sequences and\ntheir attribute values are out of the training distribution, posing challenges\nto existing methods that aim to directly generate the target sequence. Instead,\nin this work, we propose Iterative Controlled Extrapolation (ICE) which\niteratively makes local edits to a sequence to enable extrapolation. We train\nthe model on synthetically generated sequence pairs that demonstrate small\nimprovement in the attribute value. Results on one natural language task\n(sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV\nfitness) show that ICE considerably outperforms state-of-the-art approaches\ndespite its simplicity. Our code and models are available at:\nhttps://github.com/vishakhpk/iter-extrapolation.\n","authors":["Vishakh Padmakumar","Richard Yuanzhe Pang","He He","Ankur P. Parikh"],"pdf_url":"https://arxiv.org/pdf/2303.04562v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2303.04544v1","updated":"2023-03-08T12:53:03Z","published":"2023-03-08T12:53:03Z","title":"Models of symbol emergence in communication: a conceptual review and a\n  guide for avoiding local minima","summary":"  Computational simulations are a popular method for testing hypotheses about\nthe emergence of communication. This kind of research is performed in a variety\nof traditions including language evolution, developmental psychology, cognitive\nscience, machine learning, robotics, etc. The motivations for the models are\ndifferent, but the operationalizations and methods used are often similar. We\nidentify the assumptions and explanatory targets of several most representative\nmodels and summarise the known results. We claim that some of the assumptions\n-- such as portraying meaning in terms of mapping, focusing on the descriptive\nfunction of communication, modelling signals with amodal tokens -- may hinder\nthe success of modelling. Relaxing these assumptions and foregrounding the\ninteractions of embodied and situated agents allows one to systematise the\nmultiplicity of pressures under which symbolic systems evolve. In line with\nthis perspective, we sketch the road towards modelling the emergence of\nmeaningful symbolic communication, where symbols are simultaneously grounded in\naction and perception and form an abstract system.\n","authors":["Julian Zubek","Tomasz Korbak","Joanna Rączaszek-Leonardi"],"pdf_url":"https://arxiv.org/pdf/2303.04544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05764v2","updated":"2023-03-08T12:29:29Z","published":"2022-12-12T08:32:28Z","title":"Domain Adaptation of Transformer-Based Models using Unlabeled Data for\n  Relevance and Polarity Classification of German Customer Feedback","summary":"  Understanding customer feedback is becoming a necessity for companies to\nidentify problems and improve their products and services. Text classification\nand sentiment analysis can play a major role in analyzing this data by using a\nvariety of machine and deep learning approaches. In this work, different\ntransformer-based models are utilized to explore how efficient these models are\nwhen working with a German customer feedback dataset. In addition, these\npre-trained models are further analyzed to determine if adapting them to a\nspecific domain using unlabeled data can yield better results than\noff-the-shelf pre-trained models. To evaluate the models, two downstream tasks\nfrom the GermEval 2017 are considered. The experimental results show that\ntransformer-based models can reach significant improvements compared to a\nfastText baseline and outperform the published scores and previous models. For\nthe subtask Relevance Classification, the best models achieve a micro-averaged\n$F1$-Score of 96.1 % on the first test set and 95.9 % on the second one, and a\nscore of 85.1 % and 85.3 % for the subtask Polarity Classification.\n","authors":["Ahmad Idrissi-Yaghir","Henning Schäfer","Nadja Bauer","Christoph M. Friedrich"],"pdf_url":"https://arxiv.org/pdf/2212.05764v2.pdf","comment":"Complete"},{"id":"http://arxiv.org/abs/2303.04526v1","updated":"2023-03-08T11:51:26Z","published":"2023-03-08T11:51:26Z","title":"Student's t-Distribution: On Measuring the Inter-Rater Reliability When\n  the Observations are Scarce","summary":"  In natural language processing (NLP) we always rely on human judgement as the\ngolden quality evaluation method. However, there has been an ongoing debate on\nhow to better evaluate inter-rater reliability (IRR) levels for certain\nevaluation tasks, such as translation quality evaluation (TQE), especially when\nthe data samples (observations) are very scarce. In this work, we first\nintroduce the study on how to estimate the confidence interval for the\nmeasurement value when only one data (evaluation) point is available. Then,\nthis leads to our example with two human-generated observational scores, for\nwhich, we introduce ``Student's \\textit{t}-Distribution'' method and explain\nhow to use it to measure the IRR score using only these two data points, as\nwell as the confidence intervals (CIs) of the quality evaluation. We give\nquantitative analysis on how the evaluation confidence can be greatly improved\nby introducing more observations, even if only one extra observation. We\nencourage researchers to report their IRR scores in all possible means, e.g.\nusing Student's \\textit{t}-Distribution method whenever possible; thus making\nthe NLP evaluation more meaningful, transparent, and trustworthy. This\n\\textit{t}-Distribution method can be also used outside of NLP fields to\nmeasure IRR level for trustworthy evaluation of experimental investigations,\nwhenever the observational data is scarce.\n  Keywords: Inter-Rater Reliability (IRR); Scarce Observations; Confidence\nIntervals (CIs); Natural Language Processing (NLP); Translation Quality\nEvaluation (TQE); Student's \\textit{t}-Distribution\n","authors":["Serge Gladkoff","Lifeng Han","Goran Nenadic"],"pdf_url":"https://arxiv.org/pdf/2303.04526v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2302.04054v4","updated":"2023-03-08T11:37:27Z","published":"2023-02-08T13:47:00Z","title":"Towards Inferential Reproducibility of Machine Learning Research","summary":"  Reliability of machine learning evaluation -- the consistency of observed\nevaluation scores across replicated model training runs -- is affected by\nseveral sources of nondeterminism which can be regarded as measurement noise.\nCurrent tendencies to remove noise in order to enforce reproducibility of\nresearch results neglect inherent nondeterminism at the implementation level\nand disregard crucial interaction effects between algorithmic noise factors and\ndata properties. This limits the scope of conclusions that can be drawn from\nsuch experiments. Instead of removing noise, we propose to incorporate several\nsources of variance, including their interaction with data properties, into an\nanalysis of significance and reliability of machine learning evaluation, with\nthe aim to draw inferences beyond particular instances of trained models. We\nshow how to use linear mixed effects models (LMEMs) to analyze performance\nevaluation scores, and to conduct statistical inference with a generalized\nlikelihood ratio test (GLRT). This allows us to incorporate arbitrary sources\nof noise like meta-parameter variations into statistical significance testing,\nand to assess performance differences conditional on data properties.\nFurthermore, a variance component analysis (VCA) enables the analysis of the\ncontribution of noise sources to overall variance and the computation of a\nreliability coefficient by the ratio of substantial to total variance.\n","authors":["Michael Hagmann","Philipp Meier","Stefan Riezler"],"pdf_url":"https://arxiv.org/pdf/2302.04054v4.pdf","comment":"Published at ICLR 2023 (see https://openreview.net/pdf?id=li4GQCQWkv)"},{"id":"http://arxiv.org/abs/2210.01911v3","updated":"2023-03-08T11:00:55Z","published":"2022-10-04T21:16:48Z","title":"Grounding Language with Visual Affordances over Unstructured Data","summary":"  Recent works have shown that Large Language Models (LLMs) can be applied to\nground natural language to a wide variety of robot skills. However, in\npractice, learning multi-task, language-conditioned robotic skills typically\nrequires large-scale data collection and frequent human intervention to reset\nthe environment or help correcting the current policies. In this work, we\npropose a novel approach to efficiently learn general-purpose\nlanguage-conditioned robot skills from unstructured, offline and reset-free\ndata in the real world by exploiting a self-supervised visuo-lingual affordance\nmodel, which requires annotating as little as 1% of the total data with\nlanguage. We evaluate our method in extensive experiments both in simulated and\nreal-world robotic tasks, achieving state-of-the-art performance on the\nchallenging CALVIN benchmark and learning over 25 distinct visuomotor\nmanipulation tasks with a single policy in the real world. We find that when\npaired with LLMs to break down abstract natural language instructions into\nsubgoals via few-shot prompting, our method is capable of completing\nlong-horizon, multi-tier tasks in the real world, while requiring an order of\nmagnitude less data than previous approaches. Code and videos are available at\nhttp://hulc2.cs.uni-freiburg.de\n","authors":["Oier Mees","Jessica Borja-Diaz","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2210.01911v3.pdf","comment":"Accepted at the 2023 IEEE International Conference on Robotics and\n  Automation (ICRA). Project website: http://hulc2.cs.uni-freiburg.de"},{"id":"http://arxiv.org/abs/2303.04496v1","updated":"2023-03-08T10:39:38Z","published":"2023-03-08T10:39:38Z","title":"MenuCraft: Interactive Menu System Design with Large Language Models","summary":"  Menu system design is a challenging task involving many design options and\nvarious human factors. For example, one crucial factor that designers need to\nconsider is the semantic and systematic relation of menu commands. However,\ncapturing these relations can be challenging due to limited available\nresources. With the advancement of neural language models, large language\nmodels can utilize their vast pre-existing knowledge in designing and refining\nmenu systems.\n  In this paper, we propose MenuCraft, an AI-assisted designer for menu design\nthat enables collaboration between the designer and a dialogue system to design\nmenus. MenuCraft offers an interactive language-based menu design tool that\nsimplifies the menu design process and enables easy customization of design\noptions. MenuCraft supports a variety of interactions through dialog that\nallows performing few-shot learning.\n","authors":["Amir Hossein Kargaran","Nafiseh Nikeghbal","Abbas Heydarnoori","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2303.04496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05714v4","updated":"2023-03-08T10:30:41Z","published":"2022-10-11T18:13:20Z","title":"Visual Language Maps for Robot Navigation","summary":"  Grounding language to the visual observations of a navigating agent can be\nperformed using off-the-shelf visual-language models pretrained on\nInternet-scale data (e.g., image captions). While this is useful for matching\nimages to natural language descriptions of object goals, it remains disjoint\nfrom the process of mapping the environment, so that it lacks the spatial\nprecision of classic geometric maps. To address this problem, we propose\nVLMaps, a spatial map representation that directly fuses pretrained\nvisual-language features with a 3D reconstruction of the physical world. VLMaps\ncan be autonomously built from video feed on robots using standard exploration\napproaches and enables natural language indexing of the map without additional\nlabeled data. Specifically, when combined with large language models (LLMs),\nVLMaps can be used to (i) translate natural language commands into a sequence\nof open-vocabulary navigation goals (which, beyond prior work, can be spatial\nby construction, e.g., \"in between the sofa and TV\" or \"three meters to the\nright of the chair\") directly localized in the map, and (ii) can be shared\namong multiple robots with different embodiments to generate new obstacle maps\non-the-fly (by using a list of obstacle categories). Extensive experiments\ncarried out in simulated and real world environments show that VLMaps enable\nnavigation according to more complex language instructions than existing\nmethods. Videos are available at https://vlmaps.github.io.\n","authors":["Chenguang Huang","Oier Mees","Andy Zeng","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2210.05714v4.pdf","comment":"Accepted at the 2023 IEEE International Conference on Robotics and\n  Automation (ICRA). Project page: https://vlmaps.github.io"},{"id":"http://arxiv.org/abs/2303.04487v1","updated":"2023-03-08T10:21:45Z","published":"2023-03-08T10:21:45Z","title":"Query-Utterance Attention with Joint modeling for Query-Focused Meeting\n  Summarization","summary":"  Query-focused meeting summarization (QFMS) aims to generate summaries from\nmeeting transcripts in response to a given query. Previous works typically\nconcatenate the query with meeting transcripts and implicitly model the query\nrelevance only at the token level with attention mechanism. However, due to the\ndilution of key query-relevant information caused by long meeting transcripts,\nthe original transformer-based model is insufficient to highlight the key parts\nrelated to the query. In this paper, we propose a query-aware framework with\njoint modeling token and utterance based on Query-Utterance Attention. It\ncalculates the utterance-level relevance to the query with a dense retrieval\nmodule. Then both token-level query relevance and utterance-level query\nrelevance are combined and incorporated into the generation process with\nattention mechanism explicitly. We show that the query relevance of different\ngranularities contributes to generating a summary more related to the query.\nExperimental results on the QMSum dataset show that the proposed model achieves\nnew state-of-the-art performance.\n","authors":["Xingxian Liu","Bin Duan","Bo Xiao","Yajing Xu"],"pdf_url":"https://arxiv.org/pdf/2303.04487v1.pdf","comment":"icassp 2023"},{"id":"http://arxiv.org/abs/2303.03953v2","updated":"2023-03-08T09:35:09Z","published":"2023-03-07T14:59:33Z","title":"ChatGPT: Beginning of an End of Manual Linguistic Data Annotation? Use\n  Case of Automatic Genre Identification","summary":"  ChatGPT has shown strong capabilities in natural language generation tasks,\nwhich naturally leads researchers to explore where its abilities end. In this\npaper, we examine whether ChatGPT can be used for zero-shot text\nclassification, more specifically, automatic genre identification. We compare\nChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on\ndatasets, manually annotated with genres. The models are compared on test sets\nin two languages: English and Slovenian. Results show that ChatGPT outperforms\nthe fine-tuned model when applied to the dataset which was not seen before by\neither of the models. Even when applied on Slovenian language as an\nunder-resourced language, ChatGPT's performance is no worse than when applied\nto English. However, if the model is fully prompted in Slovenian, the\nperformance drops significantly, showing the current limitations of ChatGPT\nusage on smaller languages. The presented results lead us to questioning\nwhether this is the beginning of an end of laborious manual annotation\ncampaigns even for smaller languages, such as Slovenian.\n","authors":["Taja Kuzman","Igor Mozetič","Nikola Ljubešić"],"pdf_url":"https://arxiv.org/pdf/2303.03953v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04053v2","updated":"2023-03-08T08:14:51Z","published":"2023-03-07T17:01:25Z","title":"Describe me an Aucklet: Generating Grounded Perceptual Category\n  Descriptions","summary":"  Human language users can generate descriptions of perceptual concepts beyond\ninstance-level representations and also use such descriptions to learn\nprovisional class-level representations. However, the ability of computational\nmodels to learn and operate with class representations is under-investigated in\nthe language-and-vision field. In this paper, we train separate neural networks\nto generate and interpret class-level descriptions. We then use the zero-shot\nclassification performance of the interpretation model as a measure of\ncommunicative success and class-level conceptual grounding. We investigate the\nperformance of prototype- and exemplar-based neural representations grounded\ncategory description. Finally, we show that communicative success reveals\nperformance issues in the generation model that are not captured by traditional\nintrinsic NLG evaluation metrics, and argue that these issues can be traced to\na failure to properly ground language in vision at the class level. We observe\nthat the interpretation model performs better with descriptions that are low in\ndiversity on the class level, possibly indicating a strong reliance on\nfrequently occurring features.\n","authors":["Bill Noble","Nikolai Ilinykh"],"pdf_url":"https://arxiv.org/pdf/2303.04053v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04426v1","updated":"2023-03-08T08:08:57Z","published":"2023-03-08T08:08:57Z","title":"NASTyLinker: NIL-Aware Scalable Transformer-based Entity Linker","summary":"  Entity Linking (EL) is the task of detecting mentions of entities in text and\ndisambiguating them to a reference knowledge base. Most prevalent EL approaches\nassume that the reference knowledge base is complete. In practice, however, it\nis necessary to deal with the case of linking to an entity that is not\ncontained in the knowledge base (NIL entity). Recent works have shown that,\ninstead of focusing only on affinities between mentions and entities,\nconsidering inter-mention affinities can be used to represent NIL entities by\nproducing clusters of mentions. At the same time, inter-mention affinities can\nhelp to substantially improve linking performance for known entities. With\nNASTyLinker, we introduce an EL approach that is aware of NIL-entities and\nproduces corresponding mention clusters while maintaining high linking\nperformance for known entities. The approach clusters mentions and entities\nbased on dense representations from Transformers and resolves conflicts (if\nmore than one entity is assigned to a cluster) by computing transitive\nmention-entity affinities. We show the effectiveness and scalability of\nNASTyLinker on NILK, a dataset that is explicitly constructed to evaluate EL\nwith respect to NIL-entities. Further, we apply the presented approach to an\nactual EL task, namely to knowledge graph population by linking entities in\nWikipedia listings, and provide an analysis of the outcome.\n","authors":["Nicolas Heist","Heiko Paulheim"],"pdf_url":"https://arxiv.org/pdf/2303.04426v1.pdf","comment":"Preprint of a paper in the research track of the 20th Extended\n  Semantic Web Conference (ESWC'23)"},{"id":"http://arxiv.org/abs/2303.03846v2","updated":"2023-03-08T07:37:43Z","published":"2023-03-07T12:24:17Z","title":"Larger language models do in-context learning differently","summary":"  We study how in-context learning (ICL) in language models is affected by\nsemantic priors versus input-label mappings. We investigate two setups-ICL with\nflipped labels and ICL with semantically-unrelated labels-across various model\nfamilies (GPT-3, InstructGPT, Codex, PaLM, and Flan-PaLM). First, experiments\non ICL with flipped labels show that overriding semantic priors is an emergent\nability of model scale. While small language models ignore flipped labels\npresented in-context and thus rely primarily on semantic priors from\npretraining, large models can override semantic priors when presented with\nin-context exemplars that contradict priors, despite the stronger semantic\npriors that larger models may hold. We next study semantically-unrelated label\nICL (SUL-ICL), in which labels are semantically unrelated to their inputs\n(e.g., foo/bar instead of negative/positive), thereby forcing language models\nto learn the input-label mappings shown in in-context exemplars in order to\nperform the task. The ability to do SUL-ICL also emerges primarily with scale,\nand large-enough language models can even perform linear classification in a\nSUL-ICL setting. Finally, we evaluate instruction-tuned models and find that\ninstruction tuning strengthens both the use of semantic priors and the capacity\nto learn input-label mappings, but more of the former.\n","authors":["Jerry Wei","Jason Wei","Yi Tay","Dustin Tran","Albert Webson","Yifeng Lu","Xinyun Chen","Hanxiao Liu","Da Huang","Denny Zhou","Tengyu Ma"],"pdf_url":"https://arxiv.org/pdf/2303.03846v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12764v2","updated":"2023-03-08T06:31:05Z","published":"2022-11-23T08:20:29Z","title":"VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval","summary":"  Many recent studies leverage the pre-trained CLIP for text-video cross-modal\nretrieval by tuning the backbone with additional heavy modules, which not only\nbrings huge computational burdens with much more parameters, but also leads to\nthe knowledge forgetting from upstream models.In this work, we propose the VoP:\nText-Video Co-operative Prompt Tuning for efficient tuning on the text-video\nretrieval task. The proposed VoP is an end-to-end framework with both video &\ntext prompts introducing, which can be regarded as a powerful baseline with\nonly 0.1% trainable parameters. Further, based on the spatio-temporal\ncharacteristics of videos, we develop three novel video prompt mechanisms to\nimprove the performance with different scales of trainable parameters. The\nbasic idea of the VoP enhancement is to model the frame position, frame\ncontext, and layer function with specific trainable prompts, respectively.\nExtensive experiments show that compared to full fine-tuning, the enhanced VoP\nachieves a 1.4% average R@1 gain across five text-video retrieval benchmarks\nwith 6x less parameter overhead. The code will be available at\nhttps://github.com/bighuang624/VoP.\n","authors":["Siteng Huang","Biao Gong","Yulin Pan","Jianwen Jiang","Yiliang Lv","Yuyuan Li","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2211.12764v2.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.04381v1","updated":"2023-03-08T05:09:59Z","published":"2023-03-08T05:09:59Z","title":"Automatically Auditing Large Language Models via Discrete Optimization","summary":"  Auditing large language models for unexpected behaviors is critical to\npreempt catastrophic deployments, yet remains challenging. In this work, we\ncast auditing as an optimization problem, where we automatically search for\ninput-output pairs that match a desired target behavior. For example, we might\naim to find a non-toxic input that starts with \"Barack Obama\" that a model maps\nto a toxic output. This optimization problem is difficult to solve as the set\nof feasible points is sparse, the space is discrete, and the language models we\naudit are non-linear and high-dimensional. To combat these challenges, we\nintroduce a discrete optimization algorithm, ARCA, that jointly and efficiently\noptimizes over inputs and outputs. Our approach automatically uncovers\nderogatory completions about celebrities (e.g. \"Barack Obama is a legalized\nunborn\" -> \"child murderer\"), produces French inputs that complete to English\noutputs, and finds inputs that generate a specific name. Our work offers a\npromising new tool to uncover models' failure-modes before deployment.\n","authors":["Erik Jones","Anca Dragan","Aditi Raghunathan","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2303.04381v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04361v1","updated":"2023-03-08T03:58:06Z","published":"2023-03-08T03:58:06Z","title":"Sample Efficient Multimodal Semantic Augmentation for Incremental\n  Summarization","summary":"  In this work, we develop a prompting approach for incremental summarization\nof task videos. We develop a sample-efficient few-shot approach for extracting\nsemantic concepts as an intermediate step. We leverage an existing model for\nextracting the concepts from the images and extend it to videos and introduce a\nclustering and querying approach for sample efficiency, motivated by the recent\nadvances in perceiver-based architectures. Our work provides further evidence\nthat an approach with richer input context with relevant entities and actions\nfrom the videos and using these as prompts could enhance the summaries\ngenerated by the model. We show the results on a relevant dataset and discuss\npossible directions for the work.\n","authors":["Sumanta Bhattacharyya","Ramesh Manuvinakurike","Sahisnu Mazumder","Saurav Sahay"],"pdf_url":"https://arxiv.org/pdf/2303.04361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04360v1","updated":"2023-03-08T03:56:31Z","published":"2023-03-08T03:56:31Z","title":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining?","summary":"  Recent advancements in large language models (LLMs) have led to the\ndevelopment of highly potent models like OpenAI's ChatGPT. These models have\nexhibited exceptional performance in a variety of tasks, such as question\nanswering, essay composition, and code generation. However, their effectiveness\nin the healthcare sector remains uncertain. In this study, we seek to\ninvestigate the potential of ChatGPT to aid in clinical text mining by\nexamining its ability to extract structured information from unstructured\nhealthcare texts, with a focus on biological named entity recognition and\nrelation extraction. However, our preliminary results indicate that employing\nChatGPT directly for these tasks resulted in poor performance and raised\nprivacy concerns associated with uploading patients' information to the ChatGPT\nAPI. To overcome these limitations, we propose a new training paradigm that\ninvolves generating a vast quantity of high-quality synthetic data with labels\nutilizing ChatGPT and fine-tuning a local model for the downstream task. Our\nmethod has resulted in significant improvements in the performance of\ndownstream tasks, improving the F1-score from 23.37% to 63.99% for the named\nentity recognition task and from 75.86% to 83.59% for the relation extraction\ntask. Furthermore, generating data using ChatGPT can significantly reduce the\ntime and effort required for data collection and labeling, as well as mitigate\ndata privacy concerns. In summary, the proposed framework presents a promising\nsolution to enhance the applicability of LLM models to clinical text mining.\n","authors":["Ruixiang Tang","Xiaotian Han","Xiaoqian Jiang","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2303.04360v1.pdf","comment":"10 pages, 8 tables, 4 figures"},{"id":"http://arxiv.org/abs/2212.01146v2","updated":"2023-03-08T03:54:24Z","published":"2022-12-02T12:51:39Z","title":"SumREN: Summarizing Reported Speech about Events in News","summary":"  A primary objective of news articles is to establish the factual record for\nan event, frequently achieved by conveying both the details of the specified\nevent (i.e., the 5 Ws; Who, What, Where, When and Why regarding the event) and\nhow people reacted to it (i.e., reported statements). However, existing work on\nnews summarization almost exclusively focuses on the event details. In this\nwork, we propose the novel task of summarizing the reactions of different\nspeakers, as expressed by their reported statements, to a given event. To this\nend, we create a new multi-document summarization benchmark, SUMREN, comprising\n745 summaries of reported statements from various public figures obtained from\n633 news articles discussing 132 events. We propose an automatic silver\ntraining data generation approach for our task, which helps smaller models like\nBART achieve GPT-3 level performance on this task. Finally, we introduce a\npipeline-based framework for summarizing reported speech, which we empirically\nshow to generate summaries that are more abstractive and factual than baseline\nquery-focused summarization approaches.\n","authors":["Revanth Gangi Reddy","Heba Elfardy","Hou Pong Chan","Kevin Small","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2212.01146v2.pdf","comment":"Accepted at AAAI 2023"},{"id":"http://arxiv.org/abs/2303.03715v2","updated":"2023-03-08T02:02:20Z","published":"2023-03-07T07:56:38Z","title":"Universal resources for quantum computing","summary":"  Unravelling the source of quantum computing power has been a major goal in\nthe field of quantum information science. In recent years, the quantum resource\ntheory (QRT) has been established to characterize various quantum resources,\nyet their roles in quantum computing tasks still require investigation. The\nso-called universal quantum computing model (UQCM), e.g., the circuit model,\nhas been the main framework to guide the design of quantum algorithms, creation\nof real quantum computers etc. In this work, we combine the study of UQCM\ntogether with QRT. We find on one hand, using QRT can provide a\nresource-theoretic characterization of a UQCM, the relation among models and\ninspire new ones, and on the other hand, using UQCM offers a framework to apply\nresources, study relation among resources and classify them.\n  We develop the theory of universal resources in the setting of UQCM, and find\na rich spectrum of UQCMs and the corresponding universal resources. Depending\non a hierarchical structure of resource theories, we find models can be\nclassified into families. In this work, we study three natural families of\nUQCMs in details: the amplitude family, the quasi-probability family, and the\nHamiltonian family. They include some well known models, like the\nmeasurement-based model and adiabatic model, and also inspire new models such\nas the contextual model we introduce. Each family contains at least a triplet\nof models, and such a succinct structure of families of UQCMs offers a unifying\npicture to investigate resources and design models. It also provides a rigorous\nframework to resolve puzzles, such as the role of entanglement vs.\ninterference, and unravel resource-theoretic features of quantum algorithms.\n","authors":["D. -S. Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03715v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10447v2","updated":"2023-03-08T01:01:51Z","published":"2023-02-21T05:24:00Z","title":"Mask-guided BERT for Few Shot Text Classification","summary":"  Transformer-based language models have achieved significant success in\nvarious domains. However, the data-intensive nature of the transformer\narchitecture requires much labeled data, which is challenging in low-resource\nscenarios (i.e., few-shot learning (FSL)). The main challenge of FSL is the\ndifficulty of training robust models on small amounts of samples, which\nfrequently leads to overfitting. Here we present Mask-BERT, a simple and\nmodular framework to help BERT-based architectures tackle FSL. The proposed\napproach fundamentally differs from existing FSL strategies such as prompt\ntuning and meta-learning. The core idea is to selectively apply masks on text\ninputs and filter out irrelevant information, which guides the model to focus\non discriminative tokens that influence prediction results. In addition, to\nmake the text representations from different categories more separable and the\ntext representations from the same category more compact, we introduce a\ncontrastive learning loss function. Experimental results on public-domain\nbenchmark datasets demonstrate the effectiveness of Mask-BERT.\n","authors":["Wenxiong Liao","Zhengliang Liu","Haixing Dai","Zihao Wu","Yiyang Zhang","Xiaoke Huang","Yuzhong Chen","Xi Jiang","Wei Liu","Dajiang Zhu","Tianming Liu","Sheng Li","Xiang Li","Hongmin Cai"],"pdf_url":"https://arxiv.org/pdf/2302.10447v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12813v3","updated":"2023-03-08T23:41:49Z","published":"2023-02-24T18:48:43Z","title":"Check Your Facts and Try Again: Improving Large Language Models with\n  External Knowledge and Automated Feedback","summary":"  Large language models (LLMs), such as ChatGPT, are able to generate\nhuman-like, fluent responses for many downstream tasks, e.g., task-oriented\ndialog and question answering. However, applying LLMs to real-world,\nmission-critical applications remains challenging mainly due to their tendency\nto generate hallucinations and their inability to use external knowledge. This\npaper proposes a LLM-Augmenter system, which augments a black-box LLM with a\nset of plug-and-play modules. Our system makes the LLM generate responses\ngrounded in external knowledge, e.g., stored in task-specific databases. It\nalso iteratively revises LLM prompts to improve model responses using feedback\ngenerated by utility functions, e.g., the factuality score of a LLM-generated\nresponse. The effectiveness of LLM-Augmenter is empirically validated on two\ntypes of scenarios, task-oriented dialog and open-domain question answering.\nLLM-Augmenter significantly reduces ChatGPT's hallucinations without\nsacrificing the fluency and informativeness of its responses. We make the\nsource code and models publicly available.\n","authors":["Baolin Peng","Michel Galley","Pengcheng He","Hao Cheng","Yujia Xie","Yu Hu","Qiuyuan Huang","Lars Liden","Zhou Yu","Weizhu Chen","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2302.12813v3.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2211.08451v3","updated":"2023-03-08T20:50:27Z","published":"2022-11-15T19:04:13Z","title":"kogito: A Commonsense Knowledge Inference Toolkit","summary":"  In this paper, we present kogito, an open-source tool for generating\ncommonsense inferences about situations described in text. kogito provides an\nintuitive and extensible interface to interact with natural language generation\nmodels that can be used for hypothesizing commonsense knowledge inference from\na textual input. In particular, kogito offers several features for targeted,\nmulti-granularity knowledge generation. These include a standardized API for\ntraining and evaluating knowledge models, and generating and filtering\ninferences from them. We also include helper functions for converting natural\nlanguage texts into a format ingestible by knowledge models - intermediate\npipeline stages such as knowledge head extraction from text, heuristic and\nmodel-based knowledge head-relation matching, and an ability to define and use\ncustom knowledge relations. We make the code for kogito available at\nhttps://github.com/epfl-nlp/kogito along with thorough documentation at\nhttps://kogito.readthedocs.io.\n","authors":["Mete Ismayilzada","Antoine Bosselut"],"pdf_url":"https://arxiv.org/pdf/2211.08451v3.pdf","comment":"EACL 2023 Camera ready, 9 pages"},{"id":"http://arxiv.org/abs/2301.06024v2","updated":"2023-03-08T20:31:58Z","published":"2023-01-15T06:25:50Z","title":"A data science and machine learning approach to continuous analysis of\n  Shakespeare's plays","summary":"  The availability of quantitative methods that can analyze text has provided\nnew ways of examining literature in a manner that was not available in the\npre-information era. Here we apply comprehensive machine learning analysis to\nthe work of William Shakespeare. The analysis shows clear change in style of\nwriting over time, with the most significant changes in the sentence length,\nfrequency of adjectives and adverbs, and the sentiments expressed in the text.\nApplying machine learning to make a stylometric prediction of the year of the\nplay shows a Pearson correlation of 0.71 between the actual and predicted year,\nindicating that Shakespeare's writing style as reflected by the quantitative\nmeasurements changed over time. Additionally, it shows that the stylometrics of\nsome of the plays is more similar to plays written either before or after the\nyear they were written. For instance, Romeo and Juliet is dated 1596, but is\nmore similar in stylometrics to plays written by Shakespeare after 1600. The\nsource code for the analysis is available for free download.\n","authors":["Charles Swisher","Lior Shamir"],"pdf_url":"https://arxiv.org/pdf/2301.06024v2.pdf","comment":"Journal of Data Mining and Digital Humanities, accepted"},{"id":"http://arxiv.org/abs/2303.04851v1","updated":"2023-03-08T19:35:08Z","published":"2023-03-08T19:35:08Z","title":"Lexical Complexity Prediction: An Overview","summary":"  The occurrence of unknown words in texts significantly hinders reading\ncomprehension. To improve accessibility for specific target populations,\ncomputational modelling has been applied to identify complex words in texts and\nsubstitute them for simpler alternatives. In this paper, we present an overview\nof computational approaches to lexical complexity prediction focusing on the\nwork carried out on English data. We survey relevant approaches to this problem\nwhich include traditional machine learning classifiers (e.g. SVMs, logistic\nregression) and deep neural networks as well as a variety of features, such as\nthose inspired by literature in psycholinguistics as well as word frequency,\nword length, and many others. Furthermore, we introduce readers to past\ncompetitions and available datasets created on this topic. Finally, we include\nbrief sections on applications of lexical complexity prediction, such as\nreadability and text simplification, together with related studies on languages\nother than English.\n","authors":["Kai North","Marcos Zampieri","Matthew Shardlow"],"pdf_url":"https://arxiv.org/pdf/2303.04851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04838v1","updated":"2023-03-08T19:17:05Z","published":"2023-03-08T19:17:05Z","title":"The Casual Conversations v2 Dataset","summary":"  This paper introduces a new large consent-driven dataset aimed at assisting\nin the evaluation of algorithmic bias and robustness of computer vision and\naudio speech models in regards to 11 attributes that are self-provided or\nlabeled by trained annotators. The dataset includes 26,467 videos of 5,567\nunique paid participants, with an average of almost 5 videos per person,\nrecorded in Brazil, India, Indonesia, Mexico, Vietnam, Philippines, and the\nUSA, representing diverse demographic characteristics. The participants agreed\nfor their data to be used in assessing fairness of AI models and provided\nself-reported age, gender, language/dialect, disability status, physical\nadornments, physical attributes and geo-location information, while trained\nannotators labeled apparent skin tone using the Fitzpatrick Skin Type and Monk\nSkin Tone scales, and voice timbre. Annotators also labeled for different\nrecording setups and per-second activity annotations.\n","authors":["Bilal Porgali","Vítor Albiero","Jordan Ryda","Cristian Canton Ferrer","Caner Hazirbas"],"pdf_url":"https://arxiv.org/pdf/2303.04838v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10761v2","updated":"2023-03-08T19:10:39Z","published":"2023-01-25T18:55:05Z","title":"Fillers in Spoken Language Understanding: Computational and\n  Psycholinguistic Perspectives","summary":"  Disfluencies (i.e. interruptions in the regular flow of speech), are\nubiquitous to spoken discourse. Fillers (\"uh\", \"um\") are disfluencies that\noccur the most frequently compared to other kinds of disfluencies. Yet, to the\nbest of our knowledge, there isn't a resource that brings together the research\nperspectives influencing Spoken Language Understanding (SLU) on these speech\nevents. This aim of this article is to survey a breadth of perspectives in a\nholistic way; i.e. from considering underlying (psycho)linguistic theory, to\ntheir annotation and consideration in Automatic Speech Recognition (ASR) and\nSLU systems, to lastly, their study from a generation standpoint. This article\naims to present the perspectives in an approachable way to the SLU and\nConversational AI community, and discuss moving forward, what we believe are\nthe trends and challenges in each area.\n","authors":["Tanvi Dinkar","Chloé Clavel","Ioana Vasilescu"],"pdf_url":"https://arxiv.org/pdf/2301.10761v2.pdf","comment":"To appear in TAL Journal"},{"id":"http://arxiv.org/abs/2303.05431v1","updated":"2023-03-08T18:58:52Z","published":"2023-03-08T18:58:52Z","title":"disco: a toolkit for Distributional Control of Generative Models","summary":"  Pre-trained language models and other generative models have revolutionized\nNLP and beyond. However, these models tend to reproduce undesirable biases\npresent in their training data. Also, they may overlook patterns that are\nimportant but challenging to capture. To address these limitations, researchers\nhave introduced distributional control techniques. These techniques, not\nlimited to language, allow controlling the prevalence (i.e., expectations) of\nany features of interest in the model's outputs. Despite their potential, the\nwidespread adoption of these techniques has been hindered by the difficulty in\nadapting complex, disconnected code. Here, we present disco, an open-source\nPython library that brings these techniques to the broader public.\n","authors":["Germán Kruszewski","Jos Rozen","Marc Dymetman"],"pdf_url":"https://arxiv.org/pdf/2303.05431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.08087v4","updated":"2023-03-08T15:06:11Z","published":"2022-07-17T06:50:35Z","title":"Automatic Context Pattern Generation for Entity Set Expansion","summary":"  Entity Set Expansion (ESE) is a valuable task that aims to find entities of\nthe target semantic class described by given seed entities. Various Natural\nLanguage Processing (NLP) and Information Retrieval (IR) downstream\napplications have benefited from ESE due to its ability to discover knowledge.\nAlthough existing corpus-based ESE methods have achieved great progress, they\nstill rely on corpora with high-quality entity information annotated, because\nmost of them need to obtain the context patterns through the position of the\nentity in a sentence. Therefore, the quality of the given corpora and their\nentity annotation has become the bottleneck that limits the performance of such\nmethods. To overcome this dilemma and make the ESE models free from the\ndependence on entity annotation, our work aims to explore a new ESE paradigm,\nnamely corpus-independent ESE. Specifically, we devise a context pattern\ngeneration module that utilizes autoregressive language models (e.g., GPT-2) to\nautomatically generate high-quality context patterns for entities. In addition,\nwe propose the GAPA, a novel ESE framework that leverages the aforementioned\nGenerAted PAtterns to expand target entities. Extensive experiments and\ndetailed analyses on three widely used datasets demonstrate the effectiveness\nof our method. All the codes of our experiments are available at\nhttps://github.com/geekjuruo/GAPA.\n","authors":["Yinghui Li","Shulin Huang","Xinwei Zhang","Qingyu Zhou","Yangning Li","Ruiyang Liu","Yunbo Cao","Hai-Tao Zheng","Ying Shen"],"pdf_url":"https://arxiv.org/pdf/2207.08087v4.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2303.05387v1","updated":"2023-03-08T12:41:56Z","published":"2023-03-08T12:41:56Z","title":"Automatic Detection of Industry Sectors in Legal Articles Using Machine\n  Learning Approaches","summary":"  The ability to automatically identify industry sector coverage in articles on\nlegal developments, or any kind of news articles for that matter, can bring\nplentiful of benefits both to the readers and the content creators themselves.\nBy having articles tagged based on industry coverage, readers from all around\nthe world would be able to get to legal news that are specific to their region\nand professional industry. Simultaneously, writers would benefit from\nunderstanding which industries potentially lack coverage or which industries\nreaders are currently mostly interested in and thus, they would focus their\nwriting efforts towards more inclusive and relevant legal news coverage. In\nthis paper, a Machine Learning-powered industry analysis approach which\ncombined Natural Language Processing (NLP) with Statistical and Machine\nLearning (ML) techniques was investigated. A dataset consisting of over 1,700\nannotated legal articles was created for the identification of six industry\nsectors. Text and legal based features were extracted from the text. Both\ntraditional ML methods (e.g. gradient boosting machine algorithms, and\ndecision-tree based algorithms) and deep neural network (e.g. transformer\nmodels) were applied for performance comparison of predictive models. The\nsystem achieved promising results with area under the receiver operating\ncharacteristic curve scores above 0.90 and F-scores above 0.81 with respect to\nthe six industry sectors. The experimental results show that the suggested\nautomated industry analysis which employs ML techniques allows the processing\nof large collections of text data in an easy, efficient, and scalable way.\nTraditional ML methods perform better than deep neural networks when only a\nsmall and domain-specific training data is available for the study.\n","authors":["Hui Yang","Stella Hadjiantoni","Yunfei Long","Ruta Petraityte","Berthold Lausen"],"pdf_url":"https://arxiv.org/pdf/2303.05387v1.pdf","comment":"26 pages, 5 figures, 3 tables. Paper was presented at 'Classification\n  and Data Science in the Digital Age', 17th conference of the International\n  Federation of Classification Societies (IFCS2022), Porto, Portugal,\n  https://ifcs2022.fep.up.pt/"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.04805v1","updated":"2023-03-08T18:59:39Z","published":"2023-03-08T18:59:39Z","title":"X-Avatar: Expressive Human Avatars","summary":"  We present X-Avatar, a novel avatar model that captures the full\nexpressiveness of digital humans to bring about life-like experiences in\ntelepresence, AR/VR and beyond. Our method models bodies, hands, facial\nexpressions and appearance in a holistic fashion and can be learned from either\nfull 3D scans or RGB-D data. To achieve this, we propose a part-aware learned\nforward skinning module that can be driven by the parameter space of SMPL-X,\nallowing for expressive animation of X-Avatars. To efficiently learn the neural\nshape and deformation fields, we propose novel part-aware sampling and\ninitialization strategies. This leads to higher fidelity results, especially\nfor smaller body parts while maintaining efficient training despite increased\nnumber of articulated bones. To capture the appearance of the avatar with\nhigh-frequency details, we extend the geometry and deformation fields with a\ntexture network that is conditioned on pose, facial expression, geometry and\nthe normals of the deformed surface. We show experimentally that our method\noutperforms strong baselines in both data domains both quantitatively and\nqualitatively on the animation task. To facilitate future research on\nexpressive avatars we contribute a new dataset, called X-Humans, containing 233\nsequences of high-quality textured scans from 20 participants, totalling 35,500\ndata frames.\n","authors":["Kaiyue Shen","Chen Guo","Manuel Kaufmann","Juan Jose Zarate","Julien Valentin","Jie Song","Otmar Hilliges"],"pdf_url":"https://arxiv.org/pdf/2303.04805v1.pdf","comment":"Project page: https://skype-line.github.io/projects/X-Avatar/"},{"id":"http://arxiv.org/abs/2303.04803v1","updated":"2023-03-08T18:58:26Z","published":"2023-03-08T18:58:26Z","title":"Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion\n  Models","summary":"  We present ODISE: Open-vocabulary DIffusion-based panoptic SEgmentation,\nwhich unifies pre-trained text-image diffusion and discriminative models to\nperform open-vocabulary panoptic segmentation. Text-to-image diffusion models\nhave shown the remarkable capability of generating high-quality images with\ndiverse open-vocabulary language descriptions. This demonstrates that their\ninternal representation space is highly correlated with open concepts in the\nreal world. Text-image discriminative models like CLIP, on the other hand, are\ngood at classifying images into open-vocabulary labels. We propose to leverage\nthe frozen representation of both these models to perform panoptic segmentation\nof any category in the wild. Our approach outperforms the previous state of the\nart by significant margins on both open-vocabulary panoptic and semantic\nsegmentation tasks. In particular, with COCO training only, our method achieves\n23.4 PQ and 30.0 mIoU on the ADE20K dataset, with 8.3 PQ and 7.9 mIoU absolute\nimprovement over the previous state-of-the-art. Project page is available at\n\\url{https://jerryxu.net/ODISE}.\n","authors":["Jiarui Xu","Sifei Liu","Arash Vahdat","Wonmin Byeon","Xiaolong Wang","Shalini De Mello"],"pdf_url":"https://arxiv.org/pdf/2303.04803v1.pdf","comment":"CVPR 2022. Project page: https://jerryxu.net/ODISE"},{"id":"http://arxiv.org/abs/2303.04772v1","updated":"2023-03-08T18:10:10Z","published":"2023-03-08T18:10:10Z","title":"Multilevel Diffusion: Infinite Dimensional Score-Based Diffusion Models\n  for Image Generation","summary":"  Score-based diffusion models (SBDM) have recently emerged as state-of-the-art\napproaches for image generation. Existing SBDMs are typically formulated in a\nfinite-dimensional setting, where images are considered as tensors of a finite\nsize. This papers develops SBDMs in the infinite-dimensional setting, that is,\nwe model the training data as functions supported on a rectangular domain.\nBesides the quest for generating images at ever higher resolution our primary\nmotivation is to create a well-posed infinite-dimensional learning problem so\nthat we can discretize it consistently on multiple resolution levels. We\nthereby hope to obtain diffusion models that generalize across different\nresolution levels and improve the efficiency of the training process. We\ndemonstrate how to overcome two shortcomings of current SBDM approaches in the\ninfinite-dimensional setting. First, we modify the forward process to ensure\nthat the latent distribution is well-defined in the infinite-dimensional\nsetting using the notion of trace class operators. Second, we illustrate that\napproximating the score function with an operator network, in our case Fourier\nneural operators (FNOs), is beneficial for multilevel training. After deriving\nthe forward and reverse process in the infinite-dimensional setting, we show\ntheir well-posedness, derive adequate discretizations, and investigate the role\nof the latent distributions. We provide first promising numerical results on\ntwo datasets, MNIST and material structures. In particular, we show that\nmultilevel training is feasible within this framework.\n","authors":["Paul Hagemann","Lars Ruthotto","Gabriele Steidl","Nicole Tianjiao Yang"],"pdf_url":"https://arxiv.org/pdf/2303.04772v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07845v2","updated":"2023-03-08T18:07:33Z","published":"2023-01-19T01:51:37Z","title":"Foresee What You Will Learn: Data Augmentation for Domain Generalization\n  in Non-stationary Environment","summary":"  Existing domain generalization aims to learn a generalizable model to perform\nwell even on unseen domains. For many real-world machine learning applications,\nthe data distribution often shifts gradually along domain indices. For example,\na self-driving car with a vision system drives from dawn to dusk, with the sky\ndarkening gradually. Therefore, the system must be able to adapt to changes in\nambient illumination and continue to drive safely on the road. In this paper,\nwe formulate such problems as Evolving Domain Generalization, where a model\naims to generalize well on a target domain by discovering and leveraging the\nevolving pattern of the environment. We then propose Directional Domain\nAugmentation (DDA), which simulates the unseen target features by mapping\nsource data as augmentations through a domain transformer. Specifically, we\nformulate DDA as a bi-level optimization problem and solve it through a novel\nmeta-learning approach in the representation space. We evaluate the proposed\nmethod on both synthetic datasets and realworld datasets, and empirical results\nshow that our approach can outperform other existing methods.\n","authors":["Qiuhao Zeng","Wei Wang","Fan Zhou","Charles Ling","Boyu Wang"],"pdf_url":"https://arxiv.org/pdf/2301.07845v2.pdf","comment":"12 pages, 6 figures, accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.04766v1","updated":"2023-03-08T18:03:51Z","published":"2023-03-08T18:03:51Z","title":"FastFill: Efficient Compatible Model Update","summary":"  In many retrieval systems the original high dimensional data (e.g., images)\nis mapped to a lower dimensional feature through a learned embedding model. The\ntask of retrieving the most similar data from a gallery set to a given query\ndata is performed through a similarity comparison on features. When the\nembedding model is updated, it might produce features that are not\ncomparable/compatible with features already in the gallery computed with the\nold model. Subsequently, all features in the gallery need to be re-computed\nusing the new embedding model -- a computationally expensive process called\nbackfilling. Recently, compatible representation learning methods have been\nproposed to avoid backfilling. Despite their relative success, there is an\ninherent trade-off between the new model performance and its compatibility with\nthe old model. In this work, we introduce FastFill: a compatible model update\nprocess using feature alignment and policy based partial backfilling to\npromptly elevate retrieval performance. We show that previous backfilling\nstrategies suffer from decreased performance and demonstrate the importance of\nboth the training objective and the ordering in online partial backfilling. We\npropose a new training method for feature alignment between old and new\nembedding models using uncertainty estimation. Compared to previous works, we\nobtain significantly improved backfilling results on a variety of datasets: mAP\non ImageNet (+4.4\\%), Places-365 (+2.7\\%), and VGG-Face2 (+1.3\\%). Further, we\ndemonstrate that when updating a biased model with FastFill, the minority\nsubgroup accuracy gap promptly vanishes with a small fraction of partial\nbackfilling.\n","authors":["Florian Jaeckle","Fartash Faghri","Ali Farhadi","Oncel Tuzel","Hadi Pouransari"],"pdf_url":"https://arxiv.org/pdf/2303.04766v1.pdf","comment":"To appear in The Eleventh International Conference on Learning\n  Representations"},{"id":"http://arxiv.org/abs/2303.04761v1","updated":"2023-03-08T17:53:49Z","published":"2023-03-08T17:53:49Z","title":"Video-P2P: Video Editing with Cross-attention Control","summary":"  This paper presents Video-P2P, a novel framework for real-world video editing\nwith cross-attention control. While attention control has proven effective for\nimage editing with pre-trained image generation models, there are currently no\nlarge-scale video generation models publicly available. Video-P2P addresses\nthis limitation by adapting an image generation diffusion model to complete\nvarious video editing tasks. Specifically, we propose to first tune a\nText-to-Set (T2S) model to complete an approximate inversion and then optimize\na shared unconditional embedding to achieve accurate video inversion with a\nsmall memory cost. For attention control, we introduce a novel\ndecoupled-guidance strategy, which uses different guidance strategies for the\nsource and target prompts. The optimized unconditional embedding for the source\nprompt improves reconstruction ability, while an initialized unconditional\nembedding for the target prompt enhances editability. Incorporating the\nattention maps of these two branches enables detailed editing. These technical\ndesigns enable various text-driven editing applications, including word swap,\nprompt refinement, and attention re-weighting. Video-P2P works well on\nreal-world videos for generating new characters while optimally preserving\ntheir original poses and scenes. It significantly outperforms previous\napproaches.\n","authors":["Shaoteng Liu","Yuechen Zhang","Wenbo Li","Zhe Lin","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2303.04761v1.pdf","comment":"10 pages, 9 figures. Project page: https://video-p2p.github.io/"},{"id":"http://arxiv.org/abs/2211.02736v3","updated":"2023-03-08T17:46:27Z","published":"2022-11-04T20:22:58Z","title":"Discovering Closed-Loop Failures of Vision-Based Controllers via\n  Reachability Analysis","summary":"  Machine learning driven image-based controllers allow robotic systems to take\nintelligent actions based on the visual feedback from their environment.\nUnderstanding when these controllers might lead to system safety violations is\nimportant for their integration in safety-critical applications and engineering\ncorrective safety measures for the system. Existing methods leverage\nsimulation-based testing (or falsification) to find the failures of\nvision-based controllers, i.e., the visual inputs that lead to closed-loop\nsafety violations. However, these techniques do not scale well to the scenarios\ninvolving high-dimensional and complex visual inputs, such as RGB images. In\nthis work, we cast the problem of finding closed-loop vision failures as a\nHamilton-Jacobi (HJ) reachability problem. Our approach blends simulation-based\nanalysis with HJ reachability methods to compute an approximation of the\nbackward reachable tube (BRT) of the system, i.e., the set of unsafe states for\nthe system under vision-based controllers. Utilizing the BRT, we can tractably\nand systematically find the system states and corresponding visual inputs that\nlead to closed-loop failures. These visual inputs can be subsequently analyzed\nto find the input characteristics that might have caused the failure. Besides\nits scalability to high-dimensional visual inputs, an explicit computation of\nBRT allows the proposed approach to capture non-trivial system failures that\nare difficult to expose via random simulations. We demonstrate our framework on\ntwo case studies involving an RGB image-based neural network controller for (a)\nautonomous indoor navigation, and (b) autonomous aircraft taxiing.\n","authors":["Kaustav Chakraborty","Somil Bansal"],"pdf_url":"https://arxiv.org/pdf/2211.02736v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04751v1","updated":"2023-03-08T17:34:15Z","published":"2023-03-08T17:34:15Z","title":"Multimodal Parameter-Efficient Few-Shot Class Incremental Learning","summary":"  Few-Shot Class Incremental Learning (FSCIL) is a challenging continual\nlearning task, where limited training examples are available during several\nlearning sessions. To succeed in this task, it is necessary to avoid\nover-fitting new classes caused by biased distributions in the few-shot\ntraining sets. The general approach to address this issue involves enhancing\nthe representational capability of a pre-defined backbone architecture by\nadding special modules for backward compatibility with older classes. However,\nthis approach has not yet solved the dilemma of ensuring high classification\naccuracy over time while reducing the gap between the performance obtained on\nlarger training sets and the smaller ones. In this work, we propose an\nalternative approach called Continual Parameter-Efficient CLIP (CPE-CLIP) to\nreduce the loss of information between different learning sessions. Instead of\nadapting additional modules to address information loss, we leverage the vast\nknowledge acquired by CLIP in large-scale pre-training and its effectiveness in\ngeneralizing to new concepts. Our approach is multimodal and\nparameter-efficient, relying on learnable prompts for both the language and\nvision encoders to enable transfer learning across sessions. We also introduce\nprompt regularization to improve performance and prevent forgetting. Our\nexperimental results demonstrate that CPE-CLIP significantly improves FSCIL\nperformance compared to state-of-the-art proposals while also drastically\nreducing the number of learnable parameters and training costs.\n","authors":["Marco D'Alessandro","Alberto Alonso","Enrique Calabrés","Mikel Galar"],"pdf_url":"https://arxiv.org/pdf/2303.04751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04748v1","updated":"2023-03-08T17:30:58Z","published":"2023-03-08T17:30:58Z","title":"CLIP-FO3D: Learning Free Open-world 3D Scene Representations from 2D\n  Dense CLIP","summary":"  Training a 3D scene understanding model requires complicated human\nannotations, which are laborious to collect and result in a model only encoding\nclose-set object semantics. In contrast, vision-language pre-training models\n(e.g., CLIP) have shown remarkable open-world reasoning properties. To this\nend, we propose directly transferring CLIP's feature space to 3D scene\nunderstanding model without any form of supervision. We first modify CLIP's\ninput and forwarding process so that it can be adapted to extract dense pixel\nfeatures for 3D scene contents. We then project multi-view image features to\nthe point cloud and train a 3D scene understanding model with feature\ndistillation. Without any annotations or additional training, our model\nachieves promising annotation-free semantic segmentation results on\nopen-vocabulary semantics and long-tailed concepts. Besides, serving as a\ncross-modal pre-training framework, our method can be used to improve data\nefficiency during fine-tuning. Our model outperforms previous SOTA methods in\nvarious zero-shot and data-efficient learning benchmarks. Most importantly, our\nmodel successfully inherits CLIP's rich-structured knowledge, allowing 3D scene\nunderstanding models to recognize not only object concepts but also open-world\nsemantics.\n","authors":["Junbo Zhang","Runpei Dong","Kaisheng Ma"],"pdf_url":"https://arxiv.org/pdf/2303.04748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04739v1","updated":"2023-03-08T17:23:39Z","published":"2023-03-08T17:23:39Z","title":"Advancing Direct Convolution using Convolution Slicing Optimization and\n  ISA Extensions","summary":"  Convolution is one of the most computationally intensive operations that must\nbe performed for machine-learning model inference. A traditional approach to\ncompute convolutions is known as the Im2Col + BLAS method. This paper proposes\nSConv: a direct-convolution algorithm based on a MLIR/LLVM code-generation\ntoolchain that can be integrated into machine-learning compilers . This\nalgorithm introduces: (a) Convolution Slicing Analysis (CSA) - a\nconvolution-specific 3D cache-blocking analysis pass that focuses on tile reuse\nover the cache hierarchy; (b) Convolution Slicing Optimization (CSO) - a\ncode-generation pass that uses CSA to generate a tiled direct-convolution\nmacro-kernel; and (c) Vector-Based Packing (VBP) - an architecture-specific\noptimized input-tensor packing solution based on vector-register shift\ninstructions for convolutions with unitary stride. Experiments conducted on 393\nconvolutions from full ONNX-MLIR machine-learning models indicate that the\nelimination of the Im2Col transformation and the use of fast packing routines\nresult in a total packing time reduction, on full model inference, of 2.0x -\n3.9x on Intel x86 and 3.6x - 7.2x on IBM POWER10. The speed-up over an Im2Col +\nBLAS method based on current BLAS implementations for end-to-end\nmachine-learning model inference is in the range of 9% - 25% for Intel x86 and\n10% - 42% for IBM POWER10 architectures. The total convolution speedup for\nmodel inference is 12% - 27% on Intel x86 and 26% - 46% on IBM POWER10. SConv\nalso outperforms BLAS GEMM, when computing pointwise convolutions, in more than\n83% of the 219 tested instances.\n","authors":["Victor Ferrari","Rafael Sousa","Marcio Pereira","João P. L. de Carvalho","José Nelson Amaral","José Moreira","Guido Araujo"],"pdf_url":"https://arxiv.org/pdf/2303.04739v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2303.04737v1","updated":"2023-03-08T17:23:18Z","published":"2023-03-08T17:23:18Z","title":"SoftMatch Distance: A Novel Distance for Weakly-Supervised Trend Change\n  Detection in Bi-Temporal Images","summary":"  General change detection (GCD) and semantic change detection (SCD) are common\nmethods for identifying changes and distinguishing object categories involved\nin those changes, respectively. However, the binary changes provided by GCD is\noften not practical enough, while annotating semantic labels for training SCD\nmodels is very expensive. Therefore, there is a novel solution that intuitively\ndividing changes into three trends (``appear'', ``disappear'' and\n``transform'') instead of semantic categories, named it trend change detection\n(TCD) in this paper. It offers more detailed change information than GCD, while\nrequiring less manual annotation cost than SCD. However, there are limited\npublic data sets with specific trend labels to support TCD application. To\naddress this issue, we propose a softmatch distance which is used to construct\na weakly-supervised TCD branch in a simple GCD model, using GCD labels instead\nof TCD label for training. Furthermore, a strategic approach is presented to\nsuccessfully explore and extract background information, which is crucial for\nthe weakly-supervised TCD task. The experiment results on four public data sets\nare highly encouraging, which demonstrates the effectiveness of our proposed\nmodel.\n","authors":["Yuqun Yang","Xu Tang","Xiangrong Zhang","Jingjing Ma","Licheng Jiao"],"pdf_url":"https://arxiv.org/pdf/2303.04737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04731v1","updated":"2023-03-08T17:18:13Z","published":"2023-03-08T17:18:13Z","title":"Towards Trust of Explainable AI in Thyroid Nodule Diagnosis","summary":"  The ability to explain the prediction of deep learning models to end-users is\nan important feature to leverage the power of artificial intelligence (AI) for\nthe medical decision-making process, which is usually considered\nnon-transparent and challenging to comprehend. In this paper, we apply\nstate-of-the-art eXplainable artificial intelligence (XAI) methods to explain\nthe prediction of the black-box AI models in the thyroid nodule diagnosis\napplication. We propose new statistic-based XAI methods, namely Kernel Density\nEstimation and Density map, to explain the case of no nodule detected. XAI\nmethods' performances are considered under a qualitative and quantitative\ncomparison as feedback to improve the data quality and the model performance.\nFinally, we survey to assess doctors' and patients' trust in XAI explanations\nof the model's decisions on thyroid nodule images.\n","authors":["Truong Thanh Hung Nguyen","Van Binh Truong","Vo Thanh Khang Nguyen","Quoc Hung Cao","Quoc Khanh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2303.04731v1.pdf","comment":"Accepted by AAAI 2023 The 7th International Workshop on Health\n  Intelligence (W3PHIAI-23)"},{"id":"http://arxiv.org/abs/2303.04720v1","updated":"2023-03-08T17:07:02Z","published":"2023-03-08T17:07:02Z","title":"Medical Waste Sorting: a computer vision approach for assisted primary\n  sorting","summary":"  Medical waste, i.e. waste produced during medical activities in hospitals,\nclinics and laboratories, represents hazardous waste whose management involves\nspecial care and high costs. However, this kind of waste contains a significant\nfraction of highly valued materials that can enter a circular economy process.\nTo this end, in this paper, we propose a computer vision approach for assisting\nin the primary sorting of medical waste. The feasibility of our approach is\ndemonstrated on a representative dataset we collected and made available to the\ncommunity, with which we have trained a model that achieves 100\\% accuracy, and\na new dataset on which the trained model exhibits good generalization.\n","authors":["A. Bruno","C. Caudai","G. R. Leone","M. Martinelli","D. Moroni","F. Crotti"],"pdf_url":"https://arxiv.org/pdf/2303.04720v1.pdf","comment":"Submitted to IWCIM 2023"},{"id":"http://arxiv.org/abs/2303.04707v1","updated":"2023-03-08T16:48:24Z","published":"2023-03-08T16:48:24Z","title":"DiM: Distilling Dataset into Generative Model","summary":"  Dataset distillation reduces the network training cost by synthesizing small\nand informative datasets from large-scale ones. Despite the success of the\nrecent dataset distillation algorithms, three drawbacks still limit their wider\napplication: i). the synthetic images perform poorly on large architectures;\nii). they need to be re-optimized when the distillation ratio changes; iii).\nthe limited diversity restricts the performance when the distillation ratio is\nlarge. In this paper, we propose a novel distillation scheme to\n\\textbf{D}istill information of large train sets \\textbf{i}nto generative\n\\textbf{M}odels, named DiM. Specifically, DiM learns to use a generative model\nto store the information of the target dataset. During the distillation phase,\nwe minimize the differences in logits predicted by a models pool between real\nand generated images. At the deployment stage, the generative model synthesizes\nvarious training samples from random noises on the fly. Due to the simple yet\neffective designs, the trained DiM can be directly applied to different\ndistillation ratios and large architectures without extra cost. We validate the\nproposed DiM across 4 datasets and achieve state-of-the-art results on all of\nthem. To the best of our knowledge, we are the first to achieve higher accuracy\non complex architectures than simple ones, such as 75.1\\% with ResNet-18 and\n72.6\\% with ConvNet-3 on ten images per class of CIFAR-10. Besides, DiM\noutperforms previous methods with 10\\% $\\sim$ 22\\% when images per class are 1\nand 10 on the SVHN dataset.\n","authors":["Kai Wang","Jianyang Gu","Daquan Zhou","Zheng Zhu","Wei Jiang","Yang You"],"pdf_url":"https://arxiv.org/pdf/2303.04707v1.pdf","comment":"Distilling datasets into generative models"},{"id":"http://arxiv.org/abs/2302.13961v2","updated":"2023-03-08T16:43:44Z","published":"2023-02-27T17:02:30Z","title":"Soft labelling for semantic segmentation: Bringing coherence to label\n  down-sampling","summary":"  In semantic segmentation, training data down-sampling is commonly performed\ndue to limited resources, the need to adapt image size to the model input, or\nimprove data augmentation. This down-sampling typically employs different\nstrategies for the image data and the annotated labels. Such discrepancy leads\nto mismatches between the down-sampled color and label images. Hence, the\ntraining performance significantly decreases as the down-sampling factor\nincreases. In this paper, we bring together the down-sampling strategies for\nthe image data and the training labels. To that aim, we propose a novel\nframework for label down-sampling via soft-labeling that better conserves label\ninformation after down-sampling. Therefore, fully aligning soft-labels with\nimage data to keep the distribution of the sampled pixels. This proposal also\nproduces reliable annotations for under-represented semantic classes.\nAltogether, it allows training competitive models at lower resolutions.\nExperiments show that the proposal outperforms other down-sampling strategies.\nMoreover, state-of-the-art performance is achieved for reference benchmarks,\nbut employing significantly less computational resources than foremost\napproaches. This proposal enables competitive research for semantic\nsegmentation under resource constraints.\n","authors":["Roberto Alcover-Couso","Marcos Escudero-Vinolo","Juan C. SanMiguel","Jose M. Martinez"],"pdf_url":"https://arxiv.org/pdf/2302.13961v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04696v1","updated":"2023-03-08T16:35:47Z","published":"2023-03-08T16:35:47Z","title":"VOLTA: an Environment-Aware Contrastive Cell Representation Learning for\n  Histopathology","summary":"  In clinical practice, many diagnosis tasks rely on the identification of\ncells in histopathology images. While supervised machine learning techniques\nrequire labels, providing manual cell annotations is time-consuming due to the\nlarge number of cells. In this paper, we propose a self-supervised framework\n(VOLTA) for cell representation learning in histopathology images using a novel\ntechnique that accounts for the cell's mutual relationship with its environment\nfor improved cell representations. We subjected our model to extensive\nexperiments on the data collected from multiple institutions around the world\ncomprising of over 700,000 cells, four cancer types, and cell types ranging\nfrom three to six categories for each dataset. The results show that our model\noutperforms the state-of-the-art models in cell representation learning. To\nshowcase the potential power of our proposed framework, we applied VOLTA to\novarian and endometrial cancers with very small sample sizes (10-20 samples)\nand demonstrated that our cell representations can be utilized to identify the\nknown histotypes of ovarian cancer and provide novel insights that link\nhistopathology and molecular subtypes of endometrial cancer. Unlike supervised\ndeep learning models that require large sample sizes for training, we provide a\nframework that can empower new discoveries without any annotation data in\nsituations where sample sizes are limited.\n","authors":["Ramin Nakhli","Allen Zhang","Hossein Farahani","Amirali Darbandsari","Elahe Shenasa","Sidney Thiessen","Katy Milne","Jessica McAlpine","Brad Nelson","C Blake Gilks","Ali Bashashati"],"pdf_url":"https://arxiv.org/pdf/2303.04696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12093v3","updated":"2023-03-08T16:30:18Z","published":"2023-01-28T05:18:13Z","title":"Local Contrast and Global Contextual Information Make Infrared Small\n  Object Salient Again","summary":"  Infrared small object detection (ISOS) aims to segment small objects only\ncovered with several pixels from clutter background in infrared images. It's of\ngreat challenge due to: 1) small objects lack of sufficient intensity, shape\nand texture information; 2) small objects are easily lost in the process where\ndetection models, say deep neural networks, obtain high-level semantic features\nand image-level receptive fields through successive downsampling. This paper\nproposes a reliable detection model for ISOS, dubbed UCFNet, which can handle\nwell the two issues. It builds upon central difference convolution (CDC) and\nfast Fourier convolution (FFC). On one hand, CDC can effectively guide the\nnetwork to learn the contrast information between small objects and the\nbackground, as the contrast information is very essential in human visual\nsystem dealing with the ISOS task. On the other hand, FFC can gain image-level\nreceptive fields and extract global information while preventing small objects\nfrom being overwhelmed.Experiments on several public datasets demonstrate that\nour method significantly outperforms the state-of-the-art ISOS models, and can\nprovide useful guidelines for designing better ISOS deep models. Code are\navailable at https://github.com/wcyjerry/BasicISOS.\n","authors":["Chenyi Wang","Huan Wang","Peiwen Pan"],"pdf_url":"https://arxiv.org/pdf/2301.12093v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04681v1","updated":"2023-03-08T16:11:46Z","published":"2023-03-08T16:11:46Z","title":"Enhancing Low-resolution Face Recognition with Feature Similarity\n  Knowledge Distillation","summary":"  In this study, we introduce a feature knowledge distillation framework to\nimprove low-resolution (LR) face recognition performance using knowledge\nobtained from high-resolution (HR) images. The proposed framework transfers\ninformative features from an HR-trained network to an LR-trained network by\nreducing the distance between them. A cosine similarity measure was employed as\na distance metric to effectively align the HR and LR features. This approach\ndiffers from conventional knowledge distillation frameworks, which use the L_p\ndistance metrics and offer the advantage of converging well when reducing the\ndistance between features of different resolutions. Our framework achieved a 3%\nimprovement over the previous state-of-the-art method on the AgeDB-30 benchmark\nwithout bells and whistles, while maintaining a strong performance on HR\nimages. The effectiveness of cosine similarity as a distance metric was\nvalidated through statistical analysis, making our approach a promising\nsolution for real-world applications in which LR images are frequently\nencountered. The code and pretrained models will be publicly available on\nGitHub.\n","authors":["Sungho Shin","Yeonguk Yu","Kyoobin Lee"],"pdf_url":"https://arxiv.org/pdf/2303.04681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.00338v2","updated":"2023-03-08T16:09:04Z","published":"2022-12-01T07:55:56Z","title":"3D-Aware Object Goal Navigation via Simultaneous Exploration and\n  Identification","summary":"  Object goal navigation (ObjectNav) in unseen environments is a fundamental\ntask for Embodied AI. Agents in existing works learn ObjectNav policies based\non 2D maps, scene graphs, or image sequences. Considering this task happens in\n3D space, a 3D-aware agent can advance its ObjectNav capability via learning\nfrom fine-grained spatial information. However, leveraging 3D scene\nrepresentation can be prohibitively unpractical for policy learning in this\nfloor-level task, due to low sample efficiency and expensive computational\ncost. In this work, we propose a framework for the challenging 3D-aware\nObjectNav based on two straightforward sub-policies. The two sub-polices,\nnamely corner-guided exploration policy and category-aware identification\npolicy, simultaneously perform by utilizing online fused 3D points as\nobservation. Through extensive experiments, we show that this framework can\ndramatically improve the performance in ObjectNav through learning from 3D\nscene representation. Our framework achieves the best performance among all\nmodular-based methods on the Matterport3D and Gibson datasets, while requiring\n(up to 30x) less computational cost for training.\n","authors":["Jiazhao Zhang","Liu Dai","Fanpeng Meng","Qingnan Fan","Xuelin Chen","Kai Xu","He Wang"],"pdf_url":"https://arxiv.org/pdf/2212.00338v2.pdf","comment":"To appear in CVPR 2023"},{"id":"http://arxiv.org/abs/2301.02789v2","updated":"2023-03-08T16:08:37Z","published":"2023-01-07T06:28:04Z","title":"CGI-Stereo: Accurate and Real-Time Stereo Matching via Context and\n  Geometry Interaction","summary":"  In this paper, we propose CGI-Stereo, a novel neural network architecture\nthat can concurrently achieve real-time performance, competitive accuracy, and\nstrong generalization ability. The core of our CGI-Stereo is a Context and\nGeometry Fusion (CGF) block which adaptively fuses context and geometry\ninformation for more effective cost aggregation and meanwhile provides feedback\nto feature learning to guide more effective contextual feature extraction. The\nproposed CGF can be easily embedded into many existing stereo matching\nnetworks, such as PSMNet, GwcNet and ACVNet. The resulting networks show a\nsignificant improvement in accuracy. Specially, the model which incorporates\nour CGF with ACVNet ranks $1^{st}$ on the KITTI 2012 and 2015 leaderboards\namong all the published methods. We further propose an informative and concise\ncost volume, named Attention Feature Volume (AFV), which exploits a correlation\nvolume as attention weights to filter a feature volume. Based on CGF and AFV,\nthe proposed CGI-Stereo outperforms all other published real-time methods on\nKITTI benchmarks and shows better generalization ability than other real-time\nmethods. Code is available at https://github.com/gangweiX/CGI-Stereo.\n","authors":["Gangwei Xu","Huan Zhou","Xin Yang"],"pdf_url":"https://arxiv.org/pdf/2301.02789v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.04671v1","updated":"2023-03-08T15:50:02Z","published":"2023-03-08T15:50:02Z","title":"Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation\n  Models","summary":"  ChatGPT is attracting a cross-field interest as it provides a language\ninterface with remarkable conversational competency and reasoning capabilities\nacross many domains. However, since ChatGPT is trained with languages, it is\ncurrently not capable of processing or generating images from the visual world.\nAt the same time, Visual Foundation Models, such as Visual Transformers or\nStable Diffusion, although showing great visual understanding and generation\ncapabilities, they are only experts on specific tasks with one-round fixed\ninputs and outputs. To this end, We build a system called \\textbf{Visual\nChatGPT}, incorporating different Visual Foundation Models, to enable the user\nto interact with ChatGPT by 1) sending and receiving not only languages but\nalso images 2) providing complex visual questions or visual editing\ninstructions that require the collaboration of multiple AI models with\nmulti-steps. 3) providing feedback and asking for corrected results. We design\na series of prompts to inject the visual model information into ChatGPT,\nconsidering models of multiple inputs/outputs and models that require visual\nfeedback. Experiments show that Visual ChatGPT opens the door to investigating\nthe visual roles of ChatGPT with the help of Visual Foundation Models. Our\nsystem is publicly available at\n\\url{https://github.com/microsoft/visual-chatgpt}.\n","authors":["Chenfei Wu","Shengming Yin","Weizhen Qi","Xiaodong Wang","Zecheng Tang","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2303.04671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04670v1","updated":"2023-03-08T15:47:13Z","published":"2023-03-08T15:47:13Z","title":"EvConv: Fast CNN Inference on Event Camera Inputs For High-Speed Robot\n  Perception","summary":"  Event cameras capture visual information with a high temporal resolution and\na wide dynamic range. This enables capturing visual information at fine time\ngranularities (e.g., microseconds) in rapidly changing environments. This makes\nevent cameras highly useful for high-speed robotics tasks involving rapid\nmotion, such as high-speed perception, object tracking, and control. However,\nconvolutional neural network inference on event camera streams cannot currently\nperform real-time inference at the high speeds at which event cameras operate -\ncurrent CNN inference times are typically closer in order of magnitude to the\nframe rates of regular frame-based cameras. Real-time inference at event camera\nrates is necessary to fully leverage the high frequency and high temporal\nresolution that event cameras offer. This paper presents EvConv, a new approach\nto enable fast inference on CNNs for inputs from event cameras. We observe that\nconsecutive inputs to the CNN from an event camera have only small differences\nbetween them. Thus, we propose to perform inference on the difference between\nconsecutive input tensors, or the increment. This enables a significant\nreduction in the number of floating-point operations required (and thus the\ninference latency) because increments are very sparse. We design EvConv to\nleverage the irregular sparsity in increments from event cameras and to retain\nthe sparsity of these increments across all layers of the network. We\ndemonstrate a reduction in the number of floating operations required in the\nforward pass by up to 98%. We also demonstrate a speedup of up to 1.6X for\ninference using CNNs for tasks such as depth estimation, object recognition,\nand optical flow estimation, with almost no loss in accuracy.\n","authors":["Sankeerth Durvasula","Yushi Guan","Nandita Vijaykumar"],"pdf_url":"https://arxiv.org/pdf/2303.04670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2011.08682v2","updated":"2023-03-08T15:45:20Z","published":"2020-11-17T15:03:30Z","title":"SeekNet: Improved Human Instance Segmentation and Tracking via\n  Reinforcement Learning Based Optimized Robot Relocation","summary":"  Amodal recognition is the ability of the system to detect occluded objects.\nMost SOTA Visual Recognition systems lack the ability to perform amodal\nrecognition. Few studies have achieved amodal recognition through passive\nprediction or embodied recognition approaches. However, these approaches suffer\nfrom challenges in real-world applications, such as dynamic obstacles. We\npropose SeekNet, an improved optimization method for amodal recognition through\nembodied visual recognition. Additionally, we implement SeekNet for social\nrobots, where there are multiple interactions with crowded pedestrians. We also\ndemonstrate the benefits of our algorithm on occluded human detection and\ntracking over other baselines. Additionally, we set up a multi-robot\nenvironment with SeekNet to identify and track visual disease markers for\nairborne disease in crowded areas. We conduct our experiments in a simulated\nindoor environment and show that our method enhances the overall accuracy of\nthe amodal recognition task and achieves the largest improvement in detection\naccuracy over time in comparison to the baseline approaches.\n","authors":["Venkatraman Narayanan","Bala Murali Manoghar","Rama Prashanth RV","Phu Pham","Aniket Bera"],"pdf_url":"https://arxiv.org/pdf/2011.08682v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04667v1","updated":"2023-03-08T15:43:15Z","published":"2023-03-08T15:43:15Z","title":"STPDnet: Spatial-temporal convolutional primal dual network for dynamic\n  PET image reconstruction","summary":"  Dynamic positron emission tomography (dPET) image reconstruction is extremely\nchallenging due to the limited counts received in individual frame. In this\npaper, we propose a spatial-temporal convolutional primal dual network\n(STPDnet) for dynamic PET image reconstruction. Both spatial and temporal\ncorrelations are encoded by 3D convolution operators. The physical projection\nof PET is embedded in the iterative learning process of the network, which\nprovides the physical constraints and enhances interpretability. The\nexperiments of real rat scan data have shown that the proposed method can\nachieve substantial noise reduction in both temporal and spatial domains and\noutperform the maximum likelihood expectation maximization (MLEM),\nspatial-temporal kernel method (KEM-ST), DeepPET and Learned Primal Dual (LPD).\n","authors":["Rui Hu","Jianan Cui","Chengjin Yu","Yunmei Chen","Huafeng Liu"],"pdf_url":"https://arxiv.org/pdf/2303.04667v1.pdf","comment":"ISBI2023 accepted"},{"id":"http://arxiv.org/abs/2303.04664v1","updated":"2023-03-08T15:34:57Z","published":"2023-03-08T15:34:57Z","title":"Centroid-centered Modeling for Efficient Vision Transformer Pre-training","summary":"  Masked Image Modeling (MIM) is a new self-supervised vision pre-training\nparadigm using Vision Transformer (ViT). Previous works can be pixel-based or\ntoken-based, using original pixels or discrete visual tokens from parametric\ntokenizer models, respectively. Our proposed approach, \\textbf{CCViT},\nleverages k-means clustering to obtain centroids for image modeling without\nsupervised training of tokenizer model. The centroids represent patch pixels\nand index tokens and have the property of local invariance. Non-parametric\ncentroid tokenizer only takes seconds to create and is faster for token\ninference. Specifically, we adopt patch masking and centroid replacement\nstrategies to construct corrupted inputs, and two stacked encoder blocks to\npredict corrupted patch tokens and reconstruct original patch pixels.\nExperiments show that the ViT-B model with only 300 epochs achieves 84.3\\%\ntop-1 accuracy on ImageNet-1K classification and 51.6\\% on ADE20K semantic\nsegmentation. Our approach achieves competitive results with BEiTv2 without\ndistillation training from other models and outperforms other methods such as\nMAE.\n","authors":["Xin Yan","Zuchao Li","Lefei Zhang","Bo Du","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.04664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04661v1","updated":"2023-03-08T15:29:17Z","published":"2023-03-08T15:29:17Z","title":"DULDA: Dual-domain Unsupervised Learned Descent Algorithm for PET image\n  reconstruction","summary":"  Deep learning based PET image reconstruction methods have achieved promising\nresults recently. However, most of these methods follow a supervised learning\nparadigm, which rely heavily on the availability of high-quality training\nlabels. In particular, the long scanning time required and high radiation\nexposure associated with PET scans make obtaining this labels impractical. In\nthis paper, we propose a dual-domain unsupervised PET image reconstruction\nmethod based on learned decent algorithm, which reconstructs high-quality PET\nimages from sinograms without the need for image labels. Specifically, we\nunroll the proximal gradient method with a learnable l2,1 norm for PET image\nreconstruction problem. The training is unsupervised, using measurement domain\nloss based on deep image prior as well as image domain loss based on rotation\nequivariance property. The experimental results domonstrate the superior\nperformance of proposed method compared with maximum likelihood expectation\nmaximazation (MLEM), total-variation regularized EM (EM-TV) and deep image\nprior based method (DIP).\n","authors":["Rui Hu","Yunmei Chen","Kyungsang Kim","Marcio Aloisio Bezerra Cavalcanti Rockenbach","Quanzheng Li","Huafeng Liu"],"pdf_url":"https://arxiv.org/pdf/2303.04661v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.12992v2","updated":"2023-03-08T15:25:18Z","published":"2021-08-30T05:07:59Z","title":"SHIFT15M: Fashion-specific dataset for set-to-set matching with several\n  distribution shifts","summary":"  This paper addresses the problem of set-to-set matching, which involves\nmatching two different sets of items based on some criteria, especially in the\ncase of high-dimensional items like images. Although neural networks have been\napplied to solve this problem, most machine learning-based approaches assume\nthat the training and test data follow the same distribution, which is not\nalways true in real-world scenarios. To address this limitation, we introduce\nSHIFT15M, a dataset that can be used to evaluate set-to-set matching models\nwhen the distribution of data changes between training and testing. We conduct\nbenchmark experiments that demonstrate the performance drop of naive methods\ndue to distribution shift. Additionally, we provide software to handle the\nSHIFT15M dataset in a simple manner, with the URL for the software to be made\navailable after publication of this manuscript. We believe proposed SHIFT15M\ndataset provide a valuable resource for evaluating set-to-set matching models\nunder the distribution shift.\n","authors":["Masanari Kimura","Takuma Nakamura","Yuki Saito"],"pdf_url":"https://arxiv.org/pdf/2108.12992v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04654v1","updated":"2023-03-08T15:21:33Z","published":"2023-03-08T15:21:33Z","title":"Aberration-Aware Depth-from-Focus","summary":"  Computer vision methods for depth estimation usually use simple camera models\nwith idealized optics. For modern machine learning approaches, this creates an\nissue when attempting to train deep networks with simulated data, especially\nfor focus-sensitive tasks like Depth-from-Focus. In this work, we investigate\nthe domain gap caused by off-axis aberrations that will affect the decision of\nthe best-focused frame in a focal stack. We then explore bridging this domain\ngap through aberration-aware training (AAT). Our approach involves a\nlightweight network that models lens aberrations at different positions and\nfocus distances, which is then integrated into the conventional network\ntraining pipeline. We evaluate the generality of pretrained models on both\nsynthetic and real-world data. Our experimental results demonstrate that the\nproposed AAT scheme can improve depth estimation accuracy without fine-tuning\nthe model or modifying the network architecture.\n","authors":["Xinge Yang","Qiang Fu","Mohammed Elhoseiny","Wolfgang Heidrich"],"pdf_url":"https://arxiv.org/pdf/2303.04654v1.pdf","comment":"Considering optical aberrations during network training can improve\n  the generalizability"},{"id":"http://arxiv.org/abs/2303.04634v1","updated":"2023-03-08T14:54:51Z","published":"2023-03-08T14:54:51Z","title":"Transformer-based Image Generation from Scene Graphs","summary":"  Graph-structured scene descriptions can be efficiently used in generative\nmodels to control the composition of the generated image. Previous approaches\nare based on the combination of graph convolutional networks and adversarial\nmethods for layout prediction and image generation, respectively. In this work,\nwe show how employing multi-head attention to encode the graph information, as\nwell as using a transformer-based model in the latent space for image\ngeneration can improve the quality of the sampled data, without the need to\nemploy adversarial models with the subsequent advantage in terms of training\nstability. The proposed approach, specifically, is entirely based on\ntransformer architectures both for encoding scene graphs into intermediate\nobject layouts and for decoding these layouts into images, passing through a\nlower dimensional space learned by a vector-quantized variational autoencoder.\nOur approach shows an improved image quality with respect to state-of-the-art\nmethods as well as a higher degree of diversity among multiple generations from\nthe same scene graph. We evaluate our approach on three public datasets: Visual\nGenome, COCO, and CLEVR. We achieve an Inception Score of 13.7 and 12.8, and an\nFID of 52.3 and 60.3, on COCO and Visual Genome, respectively. We perform\nablation studies on our contributions to assess the impact of each component.\nCode is available at https://github.com/perceivelab/trf-sg2im\n","authors":["Renato Sortino","Simone Palazzo","Concetto Spampinato"],"pdf_url":"https://arxiv.org/pdf/2303.04634v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09555v2","updated":"2023-03-08T14:29:28Z","published":"2022-12-19T15:45:47Z","title":"Interactive Cartoonization with Controllable Perceptual Factors","summary":"  Cartoonization is a task that renders natural photos into cartoon styles.\nPrevious deep cartoonization methods only have focused on end-to-end\ntranslation, which may hinder editability. Instead, we propose a novel solution\nwith editing features of texture and color based on the cartoon creation\nprocess. To do that, we design a model architecture to have separate decoders,\ntexture and color, to decouple these attributes. In the texture decoder, we\npropose a texture controller, which enables a user to control stroke style and\nabstraction to generate diverse cartoon textures. We also introduce an HSV\ncolor augmentation to induce the networks to generate diverse and controllable\ncolor translation. To the best of our knowledge, our work is the first deep\napproach to control the cartoonization at inference while showing profound\nquality improvement over to baselines.\n","authors":["Namhyuk Ahn","Patrick Kwon","Jihye Back","Kibeom Hong","Seungkwon Kim"],"pdf_url":"https://arxiv.org/pdf/2212.09555v2.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2302.01616v2","updated":"2023-03-08T14:26:11Z","published":"2023-02-03T09:28:39Z","title":"A geometrically aware auto-encoder for multi-texture synthesis","summary":"  We propose an auto-encoder architecture for multi-texture synthesis. The\napproach relies on both a compact encoder accounting for second order neural\nstatistics and a generator incorporating adaptive periodic content. Images are\nembedded in a compact and geometrically consistent latent space, where the\ntexture representation and its spatial organisation are disentangled. Texture\nsynthesis and interpolation tasks can be performed directly from these latent\ncodes. Our experiments demonstrate that our model outperforms state-of-the-art\nfeed-forward methods in terms of visual quality and various texture related\nmetrics.\n","authors":["Pierrick Chatillon","Yann Gousseau","Sidonie Lefebvre"],"pdf_url":"https://arxiv.org/pdf/2302.01616v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08428v2","updated":"2023-03-08T14:25:10Z","published":"2022-11-15T05:14:48Z","title":"CaDM: Codec-aware Diffusion Modeling for Neural-enhanced Video Streaming","summary":"  Recent years have witnessed the dramatic growth of Internet video traffic,\nwhere the video bitstreams are often compressed and delivered in low quality to\nfit the streamer's uplink bandwidth. To alleviate the quality degradation, it\ncomes the rise of Neural-enhanced Video Streaming (NVS), which shows great\nprospects for recovering low-quality videos by mostly deploying neural\nsuper-resolution (SR) on the media server. Despite its benefit, we reveal that\ncurrent mainstream works with SR enhancement have not achieved the desired\nrate-distortion trade-off between bitrate saving and quality restoration, due\nto: (1) overemphasizing the enhancement on the decoder side while omitting the\nco-design of encoder, (2) limited generative capacity to recover high-fidelity\nperceptual details, and (3) optimizing the compression-and-restoration pipeline\nfrom the resolution perspective solely, without considering color bit-depth.\nAiming at overcoming these limitations, we are the first to conduct an\nencoder-decoder (i.e., codec) synergy by leveraging the inherent\nvisual-generative property of diffusion models. Specifically, we present the\nCodec-aware Diffusion Modeling (CaDM), a novel NVS paradigm to significantly\nreduce streaming delivery bitrates while holding pretty higher restoration\ncapacity over existing methods. First, CaDM improves the encoder's compression\nefficiency by simultaneously reducing resolution and color bit-depth of video\nframes. Second, CaDM empowers the decoder with high-quality enhancement by\nmaking the denoising diffusion restoration aware of encoder's resolution-color\nconditions. Evaluation on public cloud services with OpenMMLab benchmarks shows\nthat CaDM effectively saves up to 5.12 - 21.44 times bitrates based on common\nvideo standards and achieves much better recovery quality (e.g., FID of 0.61)\nover state-of-the-art neural-enhancing methods.\n","authors":["Qihua Zhou","Ruibin Li","Song Guo","Peiran Dong","Yi Liu","Jingcai Guo","Zhenda Xu"],"pdf_url":"https://arxiv.org/pdf/2211.08428v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03202v2","updated":"2023-03-08T14:21:22Z","published":"2023-03-06T15:02:12Z","title":"Continuous Sign Language Recognition with Correlation Network","summary":"  Human body trajectories are a salient cue to identify actions in the video.\nSuch body trajectories are mainly conveyed by hands and face across consecutive\nframes in sign language. However, current methods in continuous sign language\nrecognition (CSLR) usually process frames independently, thus failing to\ncapture cross-frame trajectories to effectively identify a sign. To handle this\nlimitation, we propose correlation network (CorrNet) to explicitly capture and\nleverage body trajectories across frames to identify signs. In specific, a\ncorrelation module is first proposed to dynamically compute correlation maps\nbetween the current frame and adjacent frames to identify trajectories of all\nspatial patches. An identification module is then presented to dynamically\nemphasize the body trajectories within these correlation maps. As a result, the\ngenerated features are able to gain an overview of local temporal movements to\nidentify a sign. Thanks to its special attention on body trajectories, CorrNet\nachieves new state-of-the-art accuracy on four large-scale datasets, i.e.,\nPHOENIX14, PHOENIX14-T, CSL-Daily, and CSL. A comprehensive comparison with\nprevious spatial-temporal reasoning methods verifies the effectiveness of\nCorrNet. Visualizations demonstrate the effects of CorrNet on emphasizing human\nbody trajectories across adjacent frames.\n","authors":["Lianyu Hu","Liqing Gao","Zekang Liu","Wei Feng"],"pdf_url":"https://arxiv.org/pdf/2303.03202v2.pdf","comment":"CVPR2023, code: https://github.com/hulianyuyy/CorrNet. arXiv admin\n  note: text overlap with arXiv:2211.17081"},{"id":"http://arxiv.org/abs/2303.04604v1","updated":"2023-03-08T14:15:43Z","published":"2023-03-08T14:15:43Z","title":"Simple and Efficient Confidence Score for Grading Whole Slide Images","summary":"  Grading precancerous lesions on whole slide images is a challenging task: the\ncontinuous space of morphological phenotypes makes clear-cut decisions between\ndifferent grades often difficult, leading to low inter- and intra-rater\nagreements. More and more Artificial Intelligence (AI) algorithms are developed\nto help pathologists perform and standardize their diagnosis. However, those\nmodels can render their prediction without consideration of the ambiguity of\nthe classes and can fail without notice which prevent their wider acceptance in\na clinical context. In this paper, we propose a new score to measure the\nconfidence of AI models in grading tasks. Our confidence score is specifically\nadapted to ordinal output variables, is versatile and does not require extra\ntraining or additional inferences nor particular architecture changes.\nComparison to other popular techniques such as Monte Carlo Dropout and deep\nensembles shows that our method provides state-of-the art results, while being\nsimpler, more versatile and less computationally intensive. The score is also\neasily interpretable and consistent with real life hesitations of pathologists.\nWe show that the score is capable of accurately identifying mispredicted slides\nand that accuracy for high confidence decisions is significantly higher than\nfor low-confidence decisions (gap in AUC of 17.1% on the test set). We believe\nthat the proposed confidence score could be leveraged by pathologists directly\nin their workflow and assist them on difficult tasks such as grading\nprecancerous lesions.\n","authors":["Mélanie Lubrano","Yaëlle Bellahsen-Harrar","Rutger Fick","Cécile Badoual","Thomas Walter"],"pdf_url":"https://arxiv.org/pdf/2303.04604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04603v1","updated":"2023-03-08T14:14:49Z","published":"2023-03-08T14:14:49Z","title":"Learning Enhancement From Degradation: A Diffusion Model For Fundus\n  Image Enhancement","summary":"  The quality of a fundus image can be compromised by numerous factors, many of\nwhich are challenging to be appropriately and mathematically modeled. In this\npaper, we introduce a novel diffusion model based framework, named Learning\nEnhancement from Degradation (LED), for enhancing fundus images. Specifically,\nwe first adopt a data-driven degradation framework to learn degradation\nmappings from unpaired high-quality to low-quality images. We then apply a\nconditional diffusion model to learn the inverse enhancement process in a\npaired manner. The proposed LED is able to output enhancement results that\nmaintain clinically important features with better clarity. Moreover, in the\ninference phase, LED can be easily and effectively integrated with any existing\nfundus image enhancement framework. We evaluate the proposed LED on several\ndownstream tasks with respect to various clinically-relevant metrics,\nsuccessfully demonstrating its superiority over existing state-of-the-art\nmethods both quantitatively and qualitatively. The source code is available at\nhttps://github.com/QtacierP/LED.\n","authors":["Puijin Cheng","Li Lin","Yijin Huang","Huaqing He","Wenhan Luo","Xiaoying Tang"],"pdf_url":"https://arxiv.org/pdf/2303.04603v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04599v1","updated":"2023-03-08T14:11:05Z","published":"2023-03-08T14:11:05Z","title":"Point Cloud Classification Using Content-based Transformer via\n  Clustering in Feature Space","summary":"  Recently, there have been some attempts of Transformer in 3D point cloud\nclassification. In order to reduce computations, most existing methods focus on\nlocal spatial attention, but ignore their content and fail to establish\nrelationships between distant but relevant points. To overcome the limitation\nof local spatial attention, we propose a point content-based Transformer\narchitecture, called PointConT for short. It exploits the locality of points in\nthe feature space (content-based), which clusters the sampled points with\nsimilar features into the same class and computes the self-attention within\neach class, thus enabling an effective trade-off between capturing long-range\ndependencies and computational complexity. We further introduce an Inception\nfeature aggregator for point cloud classification, which uses parallel\nstructures to aggregate high-frequency and low-frequency information in each\nbranch separately. Extensive experiments show that our PointConT model achieves\na remarkable performance on point cloud shape classification. Especially, our\nmethod exhibits 90.3% Top-1 accuracy on the hardest setting of ScanObjectNN.\nSource code of this paper is available at\nhttps://github.com/yahuiliu99/PointConT.\n","authors":["Yahui Liu","Bin Tian","Yisheng Lv","Lingxi Li","Feiyue Wang"],"pdf_url":"https://arxiv.org/pdf/2303.04599v1.pdf","comment":"This paper is accepted to IEEE/CAA Journal of Automatica Sinica (JAS)"},{"id":"http://arxiv.org/abs/2303.04595v1","updated":"2023-03-08T14:08:56Z","published":"2023-03-08T14:08:56Z","title":"Structure-aware registration network for liver DCE-CT images","summary":"  Image registration of liver dynamic contrast-enhanced computed tomography\n(DCE-CT) is crucial for diagnosis and image-guided surgical planning of liver\ncancer. However, intensity variations due to the flow of contrast agents\ncombined with complex spatial motion induced by respiration brings great\nchallenge to existing intensity-based registration methods. To address these\nproblems, we propose a novel structure-aware registration method by\nincorporating structural information of related organs with segmentation-guided\ndeep registration network. Existing segmentation-guided registration methods\nonly focus on volumetric registration inside the paired organ segmentations,\nignoring the inherent attributes of their anatomical structures. In addition,\nsuch paired organ segmentations are not always available in DCE-CT images due\nto the flow of contrast agents. Different from existing segmentation-guided\nregistration methods, our proposed method extracts structural information in\nhierarchical geometric perspectives of line and surface. Then, according to the\nextracted structural information, structure-aware constraints are constructed\nand imposed on the forward and backward deformation field simultaneously. In\nthis way, all available organ segmentations, including unpaired ones, can be\nfully utilized to avoid the side effect of contrast agent and preserve the\ntopology of organs during registration. Extensive experiments on an in-house\nliver DCE-CT dataset and a public LiTS dataset show that our proposed method\ncan achieve higher registration accuracy and preserve anatomical structure more\neffectively than state-of-the-art methods.\n","authors":["Peng Xue","Jingyang Zhang","Lei Ma","Mianxin Liu","Yuning Gu","Jiawei Huang","Feihong Liua","Yongsheng Pan","Xiaohuan Cao","Dinggang Shen"],"pdf_url":"https://arxiv.org/pdf/2303.04595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04589v1","updated":"2023-03-08T14:04:07Z","published":"2023-03-08T14:04:07Z","title":"FCN+: Global Receptive Convolution Makes FCN Great Again","summary":"  Fully convolutional network (FCN) is a seminal work for semantic\nsegmentation. However, due to its limited receptive field, FCN cannot\neffectively capture global context information which is vital for semantic\nsegmentation. As a result, it is beaten by state-of-the-art methods which\nleverage different filter sizes for larger receptive fields. However, such a\nstrategy usually introduces more parameters and increases the computational\ncost. In this paper, we propose a novel global receptive convolution (GRC) to\neffectively increase the receptive field of FCN for context information\nextraction, which results in an improved FCN termed FCN+. The GRC provides\nglobal receptive field for convolution without introducing any extra learnable\nparameters. The motivation of GRC is that different channels of a convolutional\nfilter can have different grid sampling locations across the whole input\nfeature map. Specifically, the GRC first divides the channels of the filter\ninto two groups. The grid sampling locations of the first group are shifted to\ndifferent spatial coordinates across the whole feature map, according to their\nchannel indexes. This can help the convolutional filter capture the global\ncontext information. The grid sampling location of the second group remains\nunchanged to keep the original location information. Convolving using these two\ngroups, the GRC can integrate the global context into the original location\ninformation of each pixel for better dense prediction results. With the GRC\nbuilt in, FCN+ can achieve comparable performance to state-of-the-art methods\nfor semantic segmentation tasks, as verified on PASCAL VOC 2012, Cityscapes,\nand ADE20K.\n","authors":["Zhongying Deng","Xiaoyu Ren","Jin Ye","Junjun He","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2303.04589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04587v1","updated":"2023-03-08T13:59:41Z","published":"2023-03-08T13:59:41Z","title":"A Prompt Log Analysis of Text-to-Image Generation Systems","summary":"  Recent developments in diffusion models have unleashed the astonishing\ncapabilities of text-to-image generation systems to synthesize high-quality\nimages that are faithful to a given reference text, known as a \"prompt.\" These\nsystems, once released to the public, have immediately received tons of\nattention from researchers, creators, and common users. Despite the plenty of\nefforts to improve the underneath generative models, there is limited work on\nunderstanding the information needs of the real users of these systems, e.g.,\nby investigating the prompts the users input at scale. In this paper, we take\nthe initiative to conduct a comprehensive analysis of large-scale prompt logs\ncollected from multiple text-to-image generation systems. Our work is analogous\nto analyzing the query log of Web search engines, a line of work that has made\ncritical contributions to the glory of the Web search industry and research. We\nanalyze over two million user-input prompts submitted to three popular\ntext-to-image systems at scale. Compared to Web search queries, text-to-image\nprompts are significantly longer, often organized into unique structures, and\npresent different categories of information needs. Users tend to make more\nedits within creation sessions, showing remarkable exploratory patterns. Our\nfindings provide concrete implications on how to improve text-to-image\ngeneration systems for creation purposes.\n","authors":["Yutong Xie","Zhaoying Pan","Jinge Ma","Jie Luo","Qiaozhu Mei"],"pdf_url":"https://arxiv.org/pdf/2303.04587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.00789v4","updated":"2023-03-08T13:34:28Z","published":"2022-07-28T08:06:24Z","title":"Self-supervised learning with rotation-invariant kernels","summary":"  We introduce a regularization loss based on kernel mean embeddings with\nrotation-invariant kernels on the hypersphere (also known as dot-product\nkernels) for self-supervised learning of image representations. Besides being\nfully competitive with the state of the art, our method significantly reduces\ntime and memory complexity for self-supervised training, making it\nimplementable for very large embedding dimensions on existing devices and more\neasily adjustable than previous methods to settings with limited resources. Our\nwork follows the major paradigm where the model learns to be invariant to some\npredefined image transformations (cropping, blurring, color jittering, etc.),\nwhile avoiding a degenerate solution by regularizing the embedding\ndistribution. Our particular contribution is to propose a loss family promoting\nthe embedding distribution to be close to the uniform distribution on the\nhypersphere, with respect to the maximum mean discrepancy pseudometric. We\ndemonstrate that this family encompasses several regularizers of former\nmethods, including uniformity-based and information-maximization methods, which\nare variants of our flexible regularization loss with different kernels. Beyond\nits practical consequences for state-of-the-art self-supervised learning with\nlimited resources, the proposed generic regularization approach opens\nperspectives to leverage more widely the literature on kernel methods in order\nto improve self-supervised learning methods.\n","authors":["Léon Zheng","Gilles Puy","Elisa Riccietti","Patrick Pérez","Rémi Gribonval"],"pdf_url":"https://arxiv.org/pdf/2208.00789v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04566v1","updated":"2023-03-08T13:23:53Z","published":"2023-03-08T13:23:53Z","title":"Robustness Evaluation in Hand Pose Estimation Models using Metamorphic\n  Testing","summary":"  Hand pose estimation (HPE) is a task that predicts and describes the hand\nposes from images or video frames. When HPE models estimate hand poses captured\nin a laboratory or under controlled environments, they normally deliver good\nperformance. However, the real-world environment is complex, and various\nuncertainties may happen, which could degrade the performance of HPE models.\nFor example, the hands could be occluded, the visibility of hands could be\nreduced by imperfect exposure rate, and the contour of hands prone to be\nblurred during fast hand movements. In this work, we adopt metamorphic testing\nto evaluate the robustness of HPE models and provide suggestions on the choice\nof HPE models for different applications. The robustness evaluation was\nconducted on four state-of-the-art models, namely MediaPipe hands, OpenPose,\nBodyHands, and NSRM hand. We found that on average more than 80\\% of the hands\ncould not be identified by BodyHands, and at least 50\\% of hands could not be\nidentified by MediaPipe hands when diagonal motion blur is introduced, while an\naverage of more than 50\\% of strongly underexposed hands could not be correctly\nestimated by NSRM hand. Similarly, applying occlusions on only four hand joints\nwill also largely degrade the performance of these models. The experimental\nresults show that occlusions, illumination variations, and motion blur are the\nmain obstacles to the performance of existing HPE models. These findings may\npave the way for researchers to improve the performance and robustness of hand\npose estimation models and their applications.\n","authors":["Muxin Pu","Chun Yong Chong","Mei Kuan Lim"],"pdf_url":"https://arxiv.org/pdf/2303.04566v1.pdf","comment":"Accepted at 2023 8th International Workshop on Metamorphic Testing, 8\n  pages"},{"id":"http://arxiv.org/abs/2303.04557v1","updated":"2023-03-08T13:15:19Z","published":"2023-03-08T13:15:19Z","title":"Scene Matters: Model-based Deep Video Compression","summary":"  Video compression has always been a popular research area, where many\ntraditional and deep video compression methods have been proposed. These\nmethods typically rely on signal prediction theory to enhance compression\nperformance by designing high efficient intra and inter prediction strategies\nand compressing video frames one by one. In this paper, we propose a novel\nmodel-based video compression (MVC) framework that regards scenes as the\nfundamental units for video sequences. Our proposed MVC directly models the\nintensity variation of the entire video sequence in one scene, seeking\nnon-redundant representations instead of reducing redundancy through\nspatio-temporal predictions. To achieve this, we employ implicit neural\nrepresentation (INR) as our basic modeling architecture. To improve the\nefficiency of video modeling, we first propose context-related spatial\npositional embedding (CRSPE) and frequency domain supervision (FDS) in spatial\ncontext enhancement. For temporal correlation capturing, we design the scene\nflow constrain mechanism (SFCM) and temporal contrastive loss (TCL). Extensive\nexperimental results demonstrate that our method achieves up to a 20\\% bitrate\nreduction compared to the latest video coding standard H.266 and is more\nefficient in decoding than existing video coding strategies.\n","authors":["Lv Tang","Xinfeng Zhang","Gai Zhang","Xiaoqi Ma"],"pdf_url":"https://arxiv.org/pdf/2303.04557v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04554v1","updated":"2023-03-08T13:09:03Z","published":"2023-03-08T13:09:03Z","title":"RADAM: Texture Recognition through Randomized Aggregated Encoding of\n  Deep Activation Maps","summary":"  Texture analysis is a classical yet challenging task in computer vision for\nwhich deep neural networks are actively being applied. Most approaches are\nbased on building feature aggregation modules around a pre-trained backbone and\nthen fine-tuning the new architecture on specific texture recognition tasks.\nHere we propose a new method named \\textbf{R}andom encoding of\n\\textbf{A}ggregated \\textbf{D}eep \\textbf{A}ctivation \\textbf{M}aps (RADAM)\nwhich extracts rich texture representations without ever changing the backbone.\nThe technique consists of encoding the output at different depths of a\npre-trained deep convolutional network using a Randomized Autoencoder (RAE).\nThe RAE is trained locally to each image using a closed-form solution, and its\ndecoder weights are used to compose a 1-dimensional texture representation that\nis fed into a linear SVM. This means that no fine-tuning or backpropagation is\nneeded. We explore RADAM on several texture benchmarks and achieve\nstate-of-the-art results with different computational budgets. Our results\nsuggest that pre-trained backbones may not require additional fine-tuning for\ntexture recognition if their learned representations are better encoded.\n","authors":["Leonardo Scabini","Kallil M. Zielinski","Lucas C. Ribas","Wesley N. Gonçalves","Bernard De Baets","Odemir M. Bruno"],"pdf_url":"https://arxiv.org/pdf/2303.04554v1.pdf","comment":"17 pages, 3 figures, submitted to peer-review journal"},{"id":"http://arxiv.org/abs/2212.02015v2","updated":"2023-03-08T12:26:15Z","published":"2022-12-05T04:05:32Z","title":"Learning Imbalanced Data with Vision Transformers","summary":"  The real-world data tends to be heavily imbalanced and severely skew the\ndata-driven deep neural networks, which makes Long-Tailed Recognition (LTR) a\nmassive challenging task. Existing LTR methods seldom train Vision Transformers\n(ViTs) with Long-Tailed (LT) data, while the off-the-shelf pretrain weight of\nViTs always leads to unfair comparisons. In this paper, we systematically\ninvestigate the ViTs' performance in LTR and propose LiVT to train ViTs from\nscratch only with LT data. With the observation that ViTs suffer more severe\nLTR problems, we conduct Masked Generative Pretraining (MGP) to learn\ngeneralized features. With ample and solid evidence, we show that MGP is more\nrobust than supervised manners. In addition, Binary Cross Entropy (BCE) loss,\nwhich shows conspicuous performance with ViTs, encounters predicaments in LTR.\nWe further propose the balanced BCE to ameliorate it with strong theoretical\ngroundings. Specially, we derive the unbiased extension of Sigmoid and\ncompensate extra logit margins to deploy it. Our Bal-BCE contributes to the\nquick convergence of ViTs in just a few epochs. Extensive experiments\ndemonstrate that with MGP and Bal-BCE, LiVT successfully trains ViTs well\nwithout any additional data and outperforms comparable state-of-the-art methods\nsignificantly, e.g., our ViT-B achieves 81.0% Top-1 accuracy in iNaturalist\n2018 without bells and whistles. Code is available at\nhttps://github.com/XuZhengzhuo/LiVT.\n","authors":["Zhengzhuo Xu","Ruikang Liu","Shuo Yang","Zenghao Chai","Chun Yuan"],"pdf_url":"https://arxiv.org/pdf/2212.02015v2.pdf","comment":"Accepted to CVPR 2023, camera-ready version; Code:\n  https://github.com/XuZhengzhuo/LiVT"},{"id":"http://arxiv.org/abs/2303.02413v2","updated":"2023-03-08T12:17:04Z","published":"2023-03-04T13:16:02Z","title":"Improved Trajectory Reconstruction for Markerless Pose Estimation","summary":"  Markerless pose estimation allows reconstructing human movement from multiple\nsynchronized and calibrated views, and has the potential to make movement\nanalysis easy and quick, including gait analysis. This could enable much more\nfrequent and quantitative characterization of gait impairments, allowing better\nmonitoring of outcomes and responses to interventions. However, the impact of\ndifferent keypoint detectors and reconstruction algorithms on markerless pose\nestimation accuracy has not been thoroughly evaluated. We tested these\nalgorithmic choices on data acquired from a multicamera system from a\nheterogeneous sample of 25 individuals seen in a rehabilitation hospital. We\nfound that using a top-down keypoint detector and reconstructing trajectories\nwith an implicit function enabled accurate, smooth and anatomically plausible\ntrajectories, with a noise in the step width estimates compared to a GaitRite\nwalkway of only 8mm.\n","authors":["R. James Cotton","Anthony Cimorelli","Kunal Shah","Shawana Anarwala","Scott Uhlrich","Tasos Karakostas"],"pdf_url":"https://arxiv.org/pdf/2303.02413v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04525v1","updated":"2023-03-08T11:42:57Z","published":"2023-03-08T11:42:57Z","title":"Continuity-Aware Latent Interframe Information Mining for Reliable UAV\n  Tracking","summary":"  Unmanned aerial vehicle (UAV) tracking is crucial for autonomous navigation\nand has broad applications in robotic automation fields. However, reliable UAV\ntracking remains a challenging task due to various difficulties like frequent\nocclusion and aspect ratio change. Additionally, most of the existing work\nmainly focuses on explicit information to improve tracking performance,\nignoring potential interframe connections. To address the above issues, this\nwork proposes a novel framework with continuity-aware latent interframe\ninformation mining for reliable UAV tracking, i.e., ClimRT. Specifically, a new\nefficient continuity-aware latent interframe information mining network\n(ClimNet) is proposed for UAV tracking, which can generate highly-effective\nlatent frame between two adjacent frames. Besides, a novel location-continuity\nTransformer (LCT) is designed to fully explore continuity-aware\nspatial-temporal information, thereby markedly enhancing UAV tracking.\nExtensive qualitative and quantitative experiments on three authoritative\naerial benchmarks strongly validate the robustness and reliability of ClimRT in\nUAV tracking performance. Furthermore, real-world tests on the aerial platform\nvalidate its practicability and effectiveness. The code and demo materials are\nreleased at https://github.com/vision4robotics/ClimRT.\n","authors":["Changhong Fu","Mutian Cai","Sihang Li","Kunhan Lu","Haobo Zuo","Chongjun Liu"],"pdf_url":"https://arxiv.org/pdf/2303.04525v1.pdf","comment":"2023 IEEE International Conference on Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2303.03131v2","updated":"2023-03-08T11:35:51Z","published":"2023-03-06T13:49:15Z","title":"Video Question Answering Using CLIP-Guided Visual-Text Attention","summary":"  Cross-modal learning of video and text plays a key role in Video Question\nAnswering (VideoQA). In this paper, we propose a visual-text attention\nmechanism to utilize the Contrastive Language-Image Pre-training (CLIP) trained\non lots of general domain language-image pairs to guide the cross-modal\nlearning for VideoQA. Specifically, we first extract video features using a\nTimeSformer and text features using a BERT from the target application domain,\nand utilize CLIP to extract a pair of visual-text features from the\ngeneral-knowledge domain through the domain-specific learning. We then propose\na Cross-domain Learning to extract the attention information between visual and\nlinguistic features across the target domain and general domain. The set of\nCLIP-guided visual-text features are integrated to predict the answer. The\nproposed method is evaluated on MSVD-QA and MSRVTT-QA datasets, and outperforms\nstate-of-the-art methods.\n","authors":["Shuhong Ye","Weikai Kong","Chenglin Yao","Jianfeng Ren","Xudong Jiang"],"pdf_url":"https://arxiv.org/pdf/2303.03131v2.pdf","comment":"Submitted to the 2023 IEEE International Conference on Image\n  Processing (ICIP 2023)"},{"id":"http://arxiv.org/abs/2303.02688v2","updated":"2023-03-08T11:28:21Z","published":"2023-03-05T15:06:54Z","title":"Text2Face: A Multi-Modal 3D Face Model","summary":"  We present the first 3D morphable modelling approach, whereby 3D face shape\ncan be directly and completely defined using a textual prompt. Building on work\nin multi-modal learning, we extend the FLAME head model to a common\nimage-and-text latent space. This allows for direct 3D Morphable Model (3DMM)\nparameter generation and therefore shape manipulation from textual\ndescriptions. Our method, Text2Face, has many applications; for example:\ngenerating police photofits where the input is already in natural language. It\nfurther enables multi-modal 3DMM image fitting to sketches and sculptures, as\nwell as images.\n","authors":["Will Rowan","Patrik Huber","Nick Pears","Andrew Keeling"],"pdf_url":"https://arxiv.org/pdf/2303.02688v2.pdf","comment":"Fixed formatting and a typo"},{"id":"http://arxiv.org/abs/2303.01894v3","updated":"2023-03-08T11:23:18Z","published":"2023-03-03T12:47:30Z","title":"TRR360D: A dataset for 360 degree rotated rectangular box table\n  detection","summary":"  To address the problem of scarcity and high annotation costs of rotated image\ntable detection datasets, this paper proposes a method for building a rotated\nimage table detection dataset. Based on the ICDAR2019MTD modern table detection\ndataset, we refer to the annotation format of the DOTA dataset to create the\nTRR360D rotated table detection dataset. The training set contains 600 rotated\nimages and 977 annotated instances, and the test set contains 240 rotated\nimages and 499 annotated instances. The AP50(T<90) evaluation metric is\ndefined, and this dataset is available for future researchers to study rotated\ntable detection algorithms and promote the development of table detection\ntechnology. The TRR360D rotated table detection dataset was created by\nconstraining the starting point and annotation direction, and is publicly\navailable at https://github.com/vansin/TRR360D.\n","authors":["Wenxing Hu","Minglei Tong"],"pdf_url":"https://arxiv.org/pdf/2303.01894v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01911v3","updated":"2023-03-08T11:00:55Z","published":"2022-10-04T21:16:48Z","title":"Grounding Language with Visual Affordances over Unstructured Data","summary":"  Recent works have shown that Large Language Models (LLMs) can be applied to\nground natural language to a wide variety of robot skills. However, in\npractice, learning multi-task, language-conditioned robotic skills typically\nrequires large-scale data collection and frequent human intervention to reset\nthe environment or help correcting the current policies. In this work, we\npropose a novel approach to efficiently learn general-purpose\nlanguage-conditioned robot skills from unstructured, offline and reset-free\ndata in the real world by exploiting a self-supervised visuo-lingual affordance\nmodel, which requires annotating as little as 1% of the total data with\nlanguage. We evaluate our method in extensive experiments both in simulated and\nreal-world robotic tasks, achieving state-of-the-art performance on the\nchallenging CALVIN benchmark and learning over 25 distinct visuomotor\nmanipulation tasks with a single policy in the real world. We find that when\npaired with LLMs to break down abstract natural language instructions into\nsubgoals via few-shot prompting, our method is capable of completing\nlong-horizon, multi-tier tasks in the real world, while requiring an order of\nmagnitude less data than previous approaches. Code and videos are available at\nhttp://hulc2.cs.uni-freiburg.de\n","authors":["Oier Mees","Jessica Borja-Diaz","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2210.01911v3.pdf","comment":"Accepted at the 2023 IEEE International Conference on Robotics and\n  Automation (ICRA). Project website: http://hulc2.cs.uni-freiburg.de"},{"id":"http://arxiv.org/abs/2303.04508v1","updated":"2023-03-08T10:57:14Z","published":"2023-03-08T10:57:14Z","title":"FastSurf: Fast Neural RGB-D Surface Reconstruction using Per-Frame\n  Intrinsic Refinement and TSDF Fusion Prior Learning","summary":"  We introduce FastSurf, an accelerated neural radiance field (NeRF) framework\nthat incorporates depth information for 3D reconstruction. A dense feature grid\nand shallow multi-layer perceptron are used for fast and accurate surface\noptimization of the entire scene. Our per-frame intrinsic refinement scheme\ncorrects the frame-specific errors that cannot be handled by global\noptimization. Furthermore, FastSurf utilizes a classical real-time 3D surface\nreconstruction method, the truncated signed distance field (TSDF) Fusion, as\nprior knowledge to pretrain the feature grid to accelerate the training. The\nquantitative and qualitative experiments comparing the performances of FastSurf\nagainst prior work indicate that our method is capable of quickly and\naccurately reconstructing a scene with high-frequency details. We also\ndemonstrate the effectiveness of our per-frame intrinsic refinement and TSDF\nFusion prior learning techniques via an ablation study.\n","authors":["Seunghwan Lee","Gwanmo Park","Hyewon Son","Jiwon Ryu","Han Joo Chae"],"pdf_url":"https://arxiv.org/pdf/2303.04508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04506v1","updated":"2023-03-08T10:55:24Z","published":"2023-03-08T10:55:24Z","title":"Radio astronomical images object detection and segmentation: A benchmark\n  on deep learning methods","summary":"  In recent years, deep learning has been successfully applied in various\nscientific domains. Following these promising results and performances, it has\nrecently also started being evaluated in the domain of radio astronomy. In\nparticular, since radio astronomy is entering the Big Data era, with the advent\nof the largest telescope in the world - the Square Kilometre Array (SKA), the\ntask of automatic object detection and instance segmentation is crucial for\nsource finding and analysis. In this work, we explore the performance of the\nmost affirmed deep learning approaches, applied to astronomical images obtained\nby radio interferometric instrumentation, to solve the task of automatic source\ndetection. This is carried out by applying models designed to accomplish two\ndifferent kinds of tasks: object detection and semantic segmentation. The goal\nis to provide an overview of existing techniques, in terms of prediction\nperformance and computational efficiency, to scientists in the astrophysics\ncommunity who would like to employ machine learning in their research.\n","authors":["Renato Sortino","Daniel Magro","Giuseppe Fiameni","Eva Sciacca","Simone Riggi","Andrea DeMarco","Concetto Spampinato","Andrew M. Hopkins","Filomena Bufano","Francesco Schillirò","Cristobal Bordiu","Carmelo Pino"],"pdf_url":"https://arxiv.org/pdf/2303.04506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04502v1","updated":"2023-03-08T10:47:17Z","published":"2023-03-08T10:47:17Z","title":"Immune Defense: A Novel Adversarial Defense Mechanism for Preventing the\n  Generation of Adversarial Examples","summary":"  The vulnerability of Deep Neural Networks (DNNs) to adversarial examples has\nbeen confirmed. Existing adversarial defenses primarily aim at preventing\nadversarial examples from attacking DNNs successfully, rather than preventing\ntheir generation. If the generation of adversarial examples is unregulated,\nimages within reach are no longer secure and pose a threat to non-robust DNNs.\nAlthough gradient obfuscation attempts to address this issue, it has been shown\nto be circumventable. Therefore, we propose a novel adversarial defense\nmechanism, which is referred to as immune defense and is the example-based\npre-defense. This mechanism applies carefully designed quasi-imperceptible\nperturbations to the raw images to prevent the generation of adversarial\nexamples for the raw images, and thereby protecting both images and DNNs. These\nperturbed images are referred to as Immune Examples (IEs). In the white-box\nimmune defense, we provide a gradient-based and an optimization-based approach,\nrespectively. Additionally, the more complex black-box immune defense is taken\ninto consideration. We propose Masked Gradient Sign Descent (MGSD) to reduce\napproximation error and stabilize the update to improve the transferability of\nIEs and thereby ensure their effectiveness against black-box adversarial\nattacks. The experimental results demonstrate that the optimization-based\napproach has superior performance and better visual quality in white-box immune\ndefense. In contrast, the gradient-based approach has stronger transferability\nand the proposed MGSD significantly improve the transferability of baselines.\n","authors":["Jinwei Wang","Hao Wu","Haihua Wang","Jiawei Zhang","Xiangyang Luo","Bin Ma"],"pdf_url":"https://arxiv.org/pdf/2303.04502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04497v1","updated":"2023-03-08T10:41:22Z","published":"2023-03-08T10:41:22Z","title":"Exploiting the Textual Potential from Vision-Language Pre-training for\n  Text-based Person Search","summary":"  Text-based Person Search (TPS), is targeted on retrieving pedestrians to\nmatch text descriptions instead of query images. Recent Vision-Language\nPre-training (VLP) models can bring transferable knowledge to downstream TPS\ntasks, resulting in more efficient performance gains. However, existing TPS\nmethods improved by VLP only utilize pre-trained visual encoders, neglecting\nthe corresponding textual representation and breaking the significant modality\nalignment learned from large-scale pre-training. In this paper, we explore the\nfull utilization of textual potential from VLP in TPS tasks. We build on the\nproposed VLP-TPS baseline model, which is the first TPS model with both\npre-trained modalities. We propose the Multi-Integrity Description Constraints\n(MIDC) to enhance the robustness of the textual modality by incorporating\ndifferent components of fine-grained corpus during training. Inspired by the\nprompt approach for zero-shot classification with VLP models, we propose the\nDynamic Attribute Prompt (DAP) to provide a unified corpus of fine-grained\nattributes as language hints for the image modality. Extensive experiments show\nthat our proposed TPS framework achieves state-of-the-art performance,\nexceeding the previous best method by a margin.\n","authors":["Guanshuo Wang","Fufu Yu","Junjie Li","Qiong Jia","Shouhong Ding"],"pdf_url":"https://arxiv.org/pdf/2303.04497v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2210.05714v4","updated":"2023-03-08T10:30:41Z","published":"2022-10-11T18:13:20Z","title":"Visual Language Maps for Robot Navigation","summary":"  Grounding language to the visual observations of a navigating agent can be\nperformed using off-the-shelf visual-language models pretrained on\nInternet-scale data (e.g., image captions). While this is useful for matching\nimages to natural language descriptions of object goals, it remains disjoint\nfrom the process of mapping the environment, so that it lacks the spatial\nprecision of classic geometric maps. To address this problem, we propose\nVLMaps, a spatial map representation that directly fuses pretrained\nvisual-language features with a 3D reconstruction of the physical world. VLMaps\ncan be autonomously built from video feed on robots using standard exploration\napproaches and enables natural language indexing of the map without additional\nlabeled data. Specifically, when combined with large language models (LLMs),\nVLMaps can be used to (i) translate natural language commands into a sequence\nof open-vocabulary navigation goals (which, beyond prior work, can be spatial\nby construction, e.g., \"in between the sofa and TV\" or \"three meters to the\nright of the chair\") directly localized in the map, and (ii) can be shared\namong multiple robots with different embodiments to generate new obstacle maps\non-the-fly (by using a list of obstacle categories). Extensive experiments\ncarried out in simulated and real world environments show that VLMaps enable\nnavigation according to more complex language instructions than existing\nmethods. Videos are available at https://vlmaps.github.io.\n","authors":["Chenguang Huang","Oier Mees","Andy Zeng","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2210.05714v4.pdf","comment":"Accepted at the 2023 IEEE International Conference on Robotics and\n  Automation (ICRA). Project page: https://vlmaps.github.io"},{"id":"http://arxiv.org/abs/2206.04667v2","updated":"2023-03-08T09:51:25Z","published":"2022-06-09T17:59:43Z","title":"Extreme Masking for Learning Instance and Distributed Visual\n  Representations","summary":"  The paper presents a scalable approach for learning spatially distributed\nvisual representations over individual tokens and a holistic instance\nrepresentation simultaneously. We use self-attention blocks to represent\nspatially distributed tokens, followed by cross-attention blocks to aggregate\nthe holistic image instance. The core of the approach is the use of extremely\nlarge token masking (75\\%-90\\%) as the data augmentation for supervision. Our\nmodel, named ExtreMA, follows the plain BYOL approach where the instance\nrepresentation from the unmasked subset is trained to predict that from the\nintact input. Instead of encouraging invariance across inputs, the model is\nrequired to capture informative variations in an image. The paper makes three\ncontributions: 1) It presents random masking as a strong and computationally\nefficient data augmentation for siamese representation learning. 2) With\nmultiple sampling per instance, extreme masking greatly speeds up learning and\nimproves performance with more data. 3) ExtreMA obtains stronger linear probing\nperformance than masked modeling methods, and better transfer performance than\nprior contrastive models.\n","authors":["Zhirong Wu","Zihang Lai","Xiao Sun","Stephen Lin"],"pdf_url":"https://arxiv.org/pdf/2206.04667v2.pdf","comment":"Accepted in TMLR"},{"id":"http://arxiv.org/abs/2303.04473v1","updated":"2023-03-08T09:46:31Z","published":"2023-03-08T09:46:31Z","title":"DANet: Density Adaptive Convolutional Network with Interactive Attention\n  for 3D Point Clouds","summary":"  Local features and contextual dependencies are crucial for 3D point cloud\nanalysis. Many works have been devoted to designing better local convolutional\nkernels that exploit the contextual dependencies. However, current point\nconvolutions lack robustness to varying point cloud density. Moreover,\ncontextual modeling is dominated by non-local or self-attention models which\nare computationally expensive. To solve these problems, we propose density\nadaptive convolution, coined DAConv. The key idea is to adaptively learn the\nconvolutional weights from geometric connections obtained from the point\ndensity and position. To extract precise context dependencies with fewer\ncomputations, we propose an interactive attention module (IAM) that embeds\nspatial information into channel attention along different spatial directions.\nDAConv and IAM are integrated in a hierarchical network architecture to achieve\nlocal density and contextual direction-aware learning for point cloud analysis.\nExperiments show that DAConv is significantly more robust to point density\ncompared to existing methods and extensive comparisons on challenging 3D point\ncloud datasets show that our network achieves state-of-the-art classification\nresults of 93.6% on ModelNet40, competitive semantic segmentation results of\n68.71% mIoU on S3DIS and part segmentation results of 86.7% mIoU on ShapeNet.\n","authors":["Yong He","Hongshan Yu","Zhengeng Yang","Wei Sun","Mingtao Feng","Ajmal Mian"],"pdf_url":"https://arxiv.org/pdf/2303.04473v1.pdf","comment":"9"},{"id":"http://arxiv.org/abs/2302.14166v2","updated":"2023-03-08T09:41:14Z","published":"2023-02-27T22:01:34Z","title":"GLOW: Global Layout Aware Attacks on Object Detection","summary":"  Adversarial attacks aim to perturb images such that a predictor outputs\nincorrect results. Due to the limited research in structured attacks, imposing\nconsistency checks on natural multi-object scenes is a promising yet practical\ndefense against conventional adversarial attacks. More desired attacks, to this\nend, should be able to fool defenses with such consistency checks. Therefore,\nwe present the first approach GLOW that copes with various attack requests by\ngenerating global layout-aware adversarial attacks, in which both categorical\nand geometric layout constraints are explicitly established. Specifically, we\nfocus on object detection task and given a victim image, GLOW first localizes\nvictim objects according to target labels. And then it generates multiple\nattack plans, together with their context-consistency scores. Our proposed\nGLOW, on the one hand, is capable of handling various types of requests,\nincluding single or multiple victim objects, with or without specified victim\nobjects. On the other hand, it produces a consistency score for each attack\nplan, reflecting the overall contextual consistency that both semantic category\nand global scene layout are considered. In experiment, we design multiple types\nof attack requests and validate our ideas on MS COCO and Pascal. Extensive\nexperimental results demonstrate that we can achieve about 30$\\%$ average\nrelative improvement compared to state-of-the-art methods in conventional\nsingle object attack request; Moreover, our method outperforms SOTAs\nsignificantly on more generic attack requests by about 20$\\%$ in average;\nFinally, our method produces superior performance under challenging zero-query\nblack-box setting, or 20$\\%$ better than SOTAs. Our code, model and attack\nrequests would be made available.\n","authors":["Buyu Liu"," BaoJun","Jianping Fan","Xi Peng","Kui Ren","Jun Yu"],"pdf_url":"https://arxiv.org/pdf/2302.14166v2.pdf","comment":"ICCV"},{"id":"http://arxiv.org/abs/2303.04458v1","updated":"2023-03-08T09:14:17Z","published":"2023-03-08T09:14:17Z","title":"Full Point Encoding for Local Feature Aggregation in 3D Point Clouds","summary":"  Point cloud processing methods exploit local point features and global\ncontext through aggregation which does not explicity model the internal\ncorrelations between local and global features. To address this problem, we\npropose full point encoding which is applicable to convolution and transformer\narchitectures. Specifically, we propose Full Point Convolution (FPConv) and\nFull Point Transformer (FPTransformer) architectures. The key idea is to\nadaptively learn the weights from local and global geometric connections, where\nthe connections are established through local and global correlation functions\nrespectively. FPConv and FPTransformer simultaneously model the local and\nglobal geometric relationships as well as their internal correlations,\ndemonstrating strong generalization ability and high performance. FPConv is\nincorporated in classical hierarchical network architectures to achieve local\nand global shape-aware learning. In FPTransformer, we introduce full point\nposition encoding in self-attention, that hierarchically encodes each point\nposition in the global and local receptive field. We also propose a shape aware\ndownsampling block which takes into account the local shape and the global\ncontext. Experimental comparison to existing methods on benchmark datasets show\nthe efficacy of FPConv and FPTransformer for semantic segmentation, object\ndetection, classification, and normal estimation tasks. In particular, we\nachieve state-of-the-art semantic segmentation results of 76% mIoU on S3DIS\n6-fold and 72.2% on S3DIS Area5.\n","authors":["Yong He","Hongshan Yu","Zhengeng Yang","Xiaoyan Liu","Wei Sun","Ajmal Mian"],"pdf_url":"https://arxiv.org/pdf/2303.04458v1.pdf","comment":"15"},{"id":"http://arxiv.org/abs/2303.04456v1","updated":"2023-03-08T09:11:50Z","published":"2023-03-08T09:11:50Z","title":"RM-Depth: Unsupervised Learning of Recurrent Monocular Depth in Dynamic\n  Scenes","summary":"  Unsupervised methods have showed promising results on monocular depth\nestimation. However, the training data must be captured in scenes without\nmoving objects. To push the envelope of accuracy, recent methods tend to\nincrease their model parameters. In this paper, an unsupervised learning\nframework is proposed to jointly predict monocular depth and complete 3D motion\nincluding the motions of moving objects and camera. (1) Recurrent modulation\nunits are used to adaptively and iteratively fuse encoder and decoder features.\nThis not only improves the single-image depth inference but also does not\noverspend model parameters. (2) Instead of using a single set of filters for\nupsampling, multiple sets of filters are devised for the residual upsampling.\nThis facilitates the learning of edge-preserving filters and leads to the\nimproved performance. (3) A warping-based network is used to estimate a motion\nfield of moving objects without using semantic priors. This breaks down the\nrequirement of scene rigidity and allows to use general videos for the\nunsupervised learning. The motion field is further regularized by an\noutlier-aware training loss. Despite the depth model just uses a single image\nin test time and 2.97M parameters, it achieves state-of-the-art results on the\nKITTI and Cityscapes benchmarks.\n","authors":["Tak-Wai Hui"],"pdf_url":"https://arxiv.org/pdf/2303.04456v1.pdf","comment":"Accepted to CVPR 2022 (paper is updated)"},{"id":"http://arxiv.org/abs/2303.04452v1","updated":"2023-03-08T09:03:11Z","published":"2023-03-08T09:03:11Z","title":"Grasping Student: semi-supervised learning for robotic manipulation","summary":"  Gathering real-world data from the robot quickly becomes a bottleneck when\nconstructing a robot learning system for grasping. In this work, we design a\nsemi-supervised grasping system that, on top of a small sample of robot\nexperience, takes advantage of images of products to be picked, which are\ncollected without any interactions with the robot. We validate our findings\nboth in the simulation and in the real world. In the regime of a small number\nof robot training samples, taking advantage of the unlabeled data allows us to\nachieve performance at the level of 10-fold bigger dataset size used by the\nbaseline. The code and datasets used in the paper will be released at\nhttps://github.com/nomagiclab/grasping-student.\n","authors":["Piotr Krzywicki","Krzysztof Ciebiera","Rafał Michaluk","Inga Maziarz","Marek Cygan"],"pdf_url":"https://arxiv.org/pdf/2303.04452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04449v1","updated":"2023-03-08T08:59:04Z","published":"2023-03-08T08:59:04Z","title":"Loss-Curvature Matching for Dataset Selection and Condensation","summary":"  Training neural networks on a large dataset requires substantial\ncomputational costs. Dataset reduction selects or synthesizes data instances\nbased on the large dataset, while minimizing the degradation in generalization\nperformance from the full dataset. Existing methods utilize the neural network\nduring the dataset reduction procedure, so the model parameter becomes\nimportant factor in preserving the performance after reduction. By depending\nupon the importance of parameters, this paper introduces a new reduction\nobjective, coined LCMat, which Matches the Loss Curvatures of the original\ndataset and reduced dataset over the model parameter space, more than the\nparameter point. This new objective induces a better adaptation of the reduced\ndataset on the perturbed parameter region than the exact point matching.\nParticularly, we identify the worst case of the loss curvature gap from the\nlocal parameter region, and we derive the implementable upper bound of such\nworst-case with theoretical analyses. Our experiments on both coreset selection\nand condensation benchmarks illustrate that LCMat shows better generalization\nperformances than existing baselines.\n","authors":["Seungjae Shin","Heesun Bae","Donghyeok Shin","Weonyoung Joo","Il-Chul Moon"],"pdf_url":"https://arxiv.org/pdf/2303.04449v1.pdf","comment":"26th International Conference on Artificial Intelligence and\n  Statistics (AISTATS)"},{"id":"http://arxiv.org/abs/2212.02963v2","updated":"2023-03-08T08:52:52Z","published":"2022-12-06T13:30:18Z","title":"Image Inpainting via Iteratively Decoupled Probabilistic Modeling","summary":"  Generative adversarial networks (GANs) have made great success in image\ninpainting yet still have difficulties tackling large missing regions. In\ncontrast, iterative probabilistic algorithms, such as autoregressive and\ndenoising diffusion models, have to be deployed with massive computing\nresources for decent effect. To achieve high-quality results with low\ncomputational cost, we present a novel pixel spread model (PSM) that\niteratively employs decoupled probabilistic modeling, combining the\noptimization efficiency of GANs with the prediction tractability of\nprobabilistic models. As a result, our model selectively spreads informative\npixels throughout the image in a few iterations, largely enhancing the\ncompletion quality and efficiency. On multiple benchmarks, we achieve new\nstate-of-the-art performance. Code is released at\nhttps://github.com/fenglinglwb/PSM.\n","authors":["Wenbo Li","Xin Yu","Kun Zhou","Yibing Song","Zhe Lin","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2212.02963v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2303.04440v1","updated":"2023-03-08T08:42:03Z","published":"2023-03-08T08:42:03Z","title":"HyT-NAS: Hybrid Transformers Neural Architecture Search for Edge Devices","summary":"  Vision Transformers have enabled recent attention-based Deep Learning (DL)\narchitectures to achieve remarkable results in Computer Vision (CV) tasks.\nHowever, due to the extensive computational resources required, these\narchitectures are rarely implemented on resource-constrained platforms. Current\nresearch investigates hybrid handcrafted convolution-based and attention-based\nmodels for CV tasks such as image classification and object detection. In this\npaper, we propose HyT-NAS, an efficient Hardware-aware Neural Architecture\nSearch (HW-NAS) including hybrid architectures targeting vision tasks on tiny\ndevices. HyT-NAS improves state-of-the-art HW-NAS by enriching the search space\nand enhancing the search strategy as well as the performance predictors. Our\nexperiments show that HyT-NAS achieves a similar hypervolume with less than ~5x\ntraining evaluations. Our resulting architecture outperforms MLPerf MobileNetV1\nby 6.3% accuracy improvement with 3.5x less number of parameters on Visual Wake\nWords.\n","authors":["Lotfi Abdelkrim Mecharbat","Hadjer Benmeziane","Hamza Ouranoughi","Smail Niar"],"pdf_url":"https://arxiv.org/pdf/2303.04440v1.pdf","comment":"CODAI 2022 Workshop - Embedded System Week (ESWeek)"},{"id":"http://arxiv.org/abs/2303.04439v1","updated":"2023-03-08T08:40:56Z","published":"2023-03-08T08:40:56Z","title":"A Light Weight Model for Active Speaker Detection","summary":"  Active speaker detection is a challenging task in audio-visual scenario\nunderstanding, which aims to detect who is speaking in one or more speakers\nscenarios. This task has received extensive attention as it is crucial in\napplications such as speaker diarization, speaker tracking, and automatic video\nediting. The existing studies try to improve performance by inputting multiple\ncandidate information and designing complex models. Although these methods\nachieved outstanding performance, their high consumption of memory and\ncomputational power make them difficult to be applied in resource-limited\nscenarios. Therefore, we construct a lightweight active speaker detection\narchitecture by reducing input candidates, splitting 2D and 3D convolutions for\naudio-visual feature extraction, and applying gated recurrent unit (GRU) with\nlow computational complexity for cross-modal modeling. Experimental results on\nthe AVA-ActiveSpeaker dataset show that our framework achieves competitive mAP\nperformance (94.1% vs. 94.2%), while the resource costs are significantly lower\nthan the state-of-the-art method, especially in model parameters (1.0M vs.\n22.5M, about 23x) and FLOPs (0.6G vs. 2.6G, about 4x). In addition, our\nframework also performs well on the Columbia dataset showing good robustness.\nThe code and model weights are available at\nhttps://github.com/Junhua-Liao/Light-ASD.\n","authors":["Junhua Liao","Haihan Duan","Kanghui Feng","Wanbing Zhao","Yanbing Yang","Liangyin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.04439v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2302.13092v2","updated":"2023-03-08T08:33:28Z","published":"2023-02-25T14:49:09Z","title":"JND-Based Perceptual Optimization For Learned Image Compression","summary":"  Recently, learned image compression schemes have achieved remarkable\nimprovements in image fidelity (e.g., PSNR and MS-SSIM) compared to\nconventional hybrid image coding ones due to their high-efficiency non-linear\ntransform, end-to-end optimization frameworks, etc. However, few of them take\nthe Just Noticeable Difference (JND) characteristic of the Human Visual System\n(HVS) into account and optimize learned image compression towards perceptual\nquality. To address this issue, a JND-based perceptual quality loss is\nproposed. Considering that the amounts of distortion in the compressed image at\ndifferent training epochs under different Quantization Parameters (QPs) are\ndifferent, we develop a distortion-aware adjustor. After combining them\ntogether, we can better assign the distortion in the compressed image with the\nguidance of JND to preserve the high perceptual quality. All these designs\nenable the proposed method to be flexibly applied to various learned image\ncompression schemes with high scalability and plug-and-play advantages.\nExperimental results on the Kodak dataset demonstrate that the proposed method\nhas led to better perceptual quality than the baseline model under the same bit\nrate.\n","authors":["Feng Ding","Jian Jin","Lili Meng","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2302.13092v2.pdf","comment":"5 pages, 5 figures, conference"},{"id":"http://arxiv.org/abs/2303.04435v1","updated":"2023-03-08T08:27:31Z","published":"2023-03-08T08:27:31Z","title":"A Message Passing Perspective on Learning Dynamics of Contrastive\n  Learning","summary":"  In recent years, contrastive learning achieves impressive results on\nself-supervised visual representation learning, but there still lacks a\nrigorous understanding of its learning dynamics. In this paper, we show that if\nwe cast a contrastive objective equivalently into the feature space, then its\nlearning dynamics admits an interpretable form. Specifically, we show that its\ngradient descent corresponds to a specific message passing scheme on the\ncorresponding augmentation graph. Based on this perspective, we theoretically\ncharacterize how contrastive learning gradually learns discriminative features\nwith the alignment update and the uniformity update. Meanwhile, this\nperspective also establishes an intriguing connection between contrastive\nlearning and Message Passing Graph Neural Networks (MP-GNNs). This connection\nnot only provides a unified understanding of many techniques independently\ndeveloped in each community, but also enables us to borrow techniques from\nMP-GNNs to design new contrastive learning variants, such as graph attention,\ngraph rewiring, jumpy knowledge techniques, etc. We believe that our message\npassing perspective not only provides a new theoretical understanding of\ncontrastive learning dynamics, but also bridges the two seemingly independent\nareas together, which could inspire more interleaving studies to benefit from\neach other. The code is available at\nhttps://github.com/PKU-ML/Message-Passing-Contrastive-Learning.\n","authors":["Yifei Wang","Qi Zhang","Tianqi Du","Jiansheng Yang","Zhouchen Lin","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2303.04435v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.04427v1","updated":"2023-03-08T08:11:26Z","published":"2023-03-08T08:11:26Z","title":"Self-Supervised Learning for Group Equivariant Neural Networks","summary":"  This paper proposes a method to construct pretext tasks for self-supervised\nlearning on group equivariant neural networks. Group equivariant neural\nnetworks are the models whose structure is restricted to commute with the\ntransformations on the input. Therefore, it is important to construct pretext\ntasks for self-supervised learning that do not contradict this equivariance. To\nensure that training is consistent with the equivariance, we propose two\nconcepts for self-supervised tasks: equivariant pretext labels and invariant\ncontrastive loss. Equivariant pretext labels use a set of labels on which we\ncan define the transformations that correspond to the input change. Invariant\ncontrastive loss uses a modified contrastive loss that absorbs the effect of\ntransformations on each input. Experiments on standard image recognition\nbenchmarks demonstrate that the equivariant neural networks exploit the\nproposed equivariant self-supervised tasks.\n","authors":["Yusuke Mukuta","Tatsuya Harada"],"pdf_url":"https://arxiv.org/pdf/2303.04427v1.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/1906.01857v3","updated":"2023-03-08T07:57:17Z","published":"2019-06-05T07:15:17Z","title":"Invariant Feature Coding using Tensor Product Representation","summary":"  In this study, a novel feature coding method that exploits invariance for\ntransformations represented by a finite group of orthogonal matrices is\nproposed. We prove that the group-invariant feature vector contains sufficient\ndiscriminative information when learning a linear classifier using convex loss\nminimization. Based on this result, a novel feature model that explicitly\nconsider group action is proposed for principal component analysis and k-means\nclustering, which are commonly used in most feature coding methods, and global\nfeature functions. Although the global feature functions are in general complex\nnonlinear functions, the group action on this space can be easily calculated by\nconstructing these functions as tensor-product representations of basic\nrepresentations, resulting in an explicit form of invariant feature functions.\nThe effectiveness of our method is demonstrated on several image datasets.\n","authors":["Yusuke Mukuta","Tatsuya Harada"],"pdf_url":"https://arxiv.org/pdf/1906.01857v3.pdf","comment":"26 pages, 41 figures"},{"id":"http://arxiv.org/abs/2303.00111v2","updated":"2023-03-08T07:55:37Z","published":"2023-02-28T22:26:18Z","title":"PixCUE: Joint Uncertainty Estimation and Image Reconstruction in MRI\n  using Deep Pixel Classification","summary":"  Deep learning (DL) models are capable of successfully exploiting latent\nrepresentations in MR data and have become state-of-the-art for accelerated MRI\nreconstruction. However, undersampling the measurements in k-space as well as\nthe over- or under-parameterized and non-transparent nature of DL make these\nmodels exposed to uncertainty. Consequently, uncertainty estimation has become\na major issue in DL MRI reconstruction. To estimate uncertainty, Monte Carlo\n(MC) inference techniques have become a common practice where multiple\nreconstructions are utilized to compute the variance in reconstruction as a\nmeasurement of uncertainty. However, these methods demand high computational\ncosts as they require multiple inferences through the DL model. To this end, we\nintroduce a method to estimate uncertainty during MRI reconstruction using a\npixel classification framework. The proposed method, PixCUE (stands for Pixel\nClassification Uncertainty Estimation) produces the reconstructed image along\nwith an uncertainty map during a single forward pass through the DL model. We\ndemonstrate that this approach generates uncertainty maps that highly correlate\nwith the reconstruction errors with respect to various MR imaging sequences and\nunder numerous adversarial conditions. We also show that the estimated\nuncertainties are correlated to that of the conventional MC method. We further\nprovide an empirical relationship between the uncertainty estimations using\nPixCUE and well-established reconstruction metrics such as NMSE, PSNR, and\nSSIM. We conclude that PixCUE is capable of reliably estimating the uncertainty\nin MRI reconstruction with a minimum additional computational cost.\n","authors":["Mevan Ekanayake","Kamlesh Pawar","Gary Egan","Zhaolin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00111v2.pdf","comment":"19 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2303.04418v1","updated":"2023-03-08T07:45:06Z","published":"2023-03-08T07:45:06Z","title":"FUSQA: Fetal Ultrasound Segmentation Quality Assessment","summary":"  Deep learning models have been effective for various fetal ultrasound\nsegmentation tasks. However, generalization to new unseen data has raised\nquestions about their effectiveness for clinical adoption. Normally, a\ntransition to new unseen data requires time-consuming and costly quality\nassurance processes to validate the segmentation performance post-transition.\nSegmentation quality assessment efforts have focused on natural images, where\nthe problem has been typically formulated as a dice score regression task. In\nthis paper, we propose a simplified Fetal Ultrasound Segmentation Quality\nAssessment (FUSQA) model to tackle the segmentation quality assessment when no\nmasks exist to compare with. We formulate the segmentation quality assessment\nprocess as an automated classification task to distinguish between good and\npoor-quality segmentation masks for more accurate gestational age estimation.\nWe validate the performance of our proposed approach on two datasets we collect\nfrom two hospitals using different ultrasound machines. We compare different\narchitectures, with our best-performing architecture achieving over 90%\nclassification accuracy on distinguishing between good and poor-quality\nsegmentation masks from an unseen dataset. Additionally, there was only a\n1.45-day difference between the gestational age reported by doctors and\nestimated based on CRL measurements using well-segmented masks. On the other\nhand, this difference increased and reached up to 7.73 days when we calculated\nCRL from the poorly segmented masks. As a result, AI-based approaches can\npotentially aid fetal ultrasound segmentation quality assessment and might\ndetect poor segmentation in real-time screening in the future.\n","authors":["Sevim Cengiz","Ibrahim Almakk","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2303.04418v1.pdf","comment":"13 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.04413v1","updated":"2023-03-08T07:32:01Z","published":"2023-03-08T07:32:01Z","title":"PL-UNeXt: Per-stage Edge Detail and Line Feature Guided Segmentation for\n  Power Line Detection","summary":"  Power line detection is a critical inspection task for electricity companies\nand is also useful in avoiding drone obstacles. Accurately separating power\nlines from the surrounding area in the aerial image is still challenging due to\nthe intricate background and low pixel ratio. In order to properly capture the\nguidance of the spatial edge detail prior and line features, we offer PL-UNeXt,\na power line segmentation model with a booster training strategy. We design\nedge detail heads computing the loss in edge space to guide the lower-level\ndetail learning and line feature heads generating auxiliary segmentation masks\nto supervise higher-level line feature learning. Benefited from this design,\nour model can reach 70.6 F1 score (+1.9%) on TTPLA and 68.41 mIoU (+5.2%) on\nVITL (without utilizing IR images), while preserving a real-time performance\ndue to few inference parameters.\n","authors":["Yang Cheng","Zhen Chen","Daming Liu"],"pdf_url":"https://arxiv.org/pdf/2303.04413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03323v2","updated":"2023-03-08T07:04:14Z","published":"2023-03-06T17:48:32Z","title":"CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive\n  Learning","summary":"  Multimodal contrastive pretraining has been used to train multimodal\nrepresentation models, such as CLIP, on large amounts of paired image-text\ndata. However, previous studies have revealed that such models are vulnerable\nto backdoor attacks. Specifically, when trained on backdoored examples, CLIP\nlearns spurious correlations between the embedded backdoor trigger and the\ntarget label, aligning their representations in the joint embedding space.\nInjecting even a small number of poisoned examples, such as 75 examples in 3\nmillion pretraining data, can significantly manipulate the model's behavior,\nmaking it difficult to detect or unlearn such correlations. To address this\nissue, we propose CleanCLIP, a finetuning framework that weakens the learned\nspurious associations introduced by backdoor attacks by independently\nre-aligning the representations for individual modalities. We demonstrate that\nunsupervised finetuning using a combination of multimodal contrastive and\nunimodal self-supervised objectives for individual modalities can significantly\nreduce the impact of the backdoor attack. Additionally, we show that supervised\nfinetuning on task-specific labeled image data removes the backdoor trigger\nfrom the CLIP vision encoder. We show empirically that CleanCLIP maintains\nmodel performance on benign examples while erasing a range of backdoor attacks\non multimodal contrastive learning.\n","authors":["Hritik Bansal","Nishad Singhi","Yu Yang","Fan Yin","Aditya Grover","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03323v2.pdf","comment":"20 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2303.04405v1","updated":"2023-03-08T06:53:42Z","published":"2023-03-08T06:53:42Z","title":"Intermediate and Future Frame Prediction of Geostationary Satellite\n  Imagery With Warp and Refine Network","summary":"  Geostationary satellite imagery has applications in climate and weather\nforecasting, planning natural energy resources, and predicting extreme weather\nevents. For precise and accurate prediction, higher spatial and temporal\nresolution of geostationary satellite imagery is important. Although recent\ngeostationary satellite resolution has improved, the long-term analysis of\nclimate applications is limited to using multiple satellites from the past to\nthe present due to the different resolutions. To solve this problem, we\nproposed warp and refine network (WR-Net). WR-Net is divided into an optical\nflow warp component and a warp image refinement component. We used the TV-L1\nalgorithm instead of deep learning-based approaches to extract the optical flow\nwarp component. The deep-learning-based model is trained on the human-centric\nview of the RGB channel and does not work on geostationary satellites, which is\ngray-scale one-channel imagery. The refinement network refines the warped image\nthrough a multi-temporal fusion layer. We evaluated WR-Net by interpolation of\ntemporal resolution at 4 min intervals to 2 min intervals in large-scale GK2A\ngeostationary meteorological satellite imagery. Furthermore, we applied WR-Net\nto the future frame prediction task and showed that the explicit use of optical\nflow can help future frame prediction.\n","authors":["Minseok Seo","Yeji Choi","Hyungon Ry","Heesun Park","Hyungkun Bae","Hyesook Lee","Wanseok Seo"],"pdf_url":"https://arxiv.org/pdf/2303.04405v1.pdf","comment":"This paper has been accepted for the AAAI2022 Climate Change Workshop"},{"id":"http://arxiv.org/abs/2212.04148v2","updated":"2023-03-08T06:31:34Z","published":"2022-12-08T09:05:19Z","title":"Relationship Quantification of Image Degradations","summary":"  In this paper, we study two challenging but less-touched problems in image\nrestoration, namely, i) how to quantify the relationship between different\nimage degradations and ii) how to improve the performance on a specific\ndegradation using the quantified relationship. To tackle the first challenge,\nDegradation Relationship Index (DRI) is proposed to measure the degradation\nrelationship, which is defined as the mean drop rate difference in the\nvalidation loss between two models, i.e., one is trained using the anchor\ndegradation only and another is trained based on both the anchor and the\nauxiliary degradations. Through quantifying the relationship between different\ndegradations using DRI, we empirically observe that i) the degradation\ncombination proportion is crucial to the image restoration performance. In\nother words, the combinations with only appropriate degradation proportions\ncould improve the performance of the anchor restoration; ii) a positive DRI\nalways predicts the performance improvement of image restoration. Based on the\nobservations, we propose an adaptive Degradation Proportion Determination\nstrategy (DPD) which could improve the performance on the anchor degradation\nwith the assist of another auxiliary degradation. Extensive experimental\nresults verify the effective of our method by taking haze as the anchor\ndegradation and noise, rain streak, and snow as the auxiliary degradations. The\ncode will be released after acceptance.\n","authors":["Wenxin Wang","Boyun Li","Yuanbiao Gou","Peng Hu","Xi Peng"],"pdf_url":"https://arxiv.org/pdf/2212.04148v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12764v2","updated":"2023-03-08T06:31:05Z","published":"2022-11-23T08:20:29Z","title":"VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval","summary":"  Many recent studies leverage the pre-trained CLIP for text-video cross-modal\nretrieval by tuning the backbone with additional heavy modules, which not only\nbrings huge computational burdens with much more parameters, but also leads to\nthe knowledge forgetting from upstream models.In this work, we propose the VoP:\nText-Video Co-operative Prompt Tuning for efficient tuning on the text-video\nretrieval task. The proposed VoP is an end-to-end framework with both video &\ntext prompts introducing, which can be regarded as a powerful baseline with\nonly 0.1% trainable parameters. Further, based on the spatio-temporal\ncharacteristics of videos, we develop three novel video prompt mechanisms to\nimprove the performance with different scales of trainable parameters. The\nbasic idea of the VoP enhancement is to model the frame position, frame\ncontext, and layer function with specific trainable prompts, respectively.\nExtensive experiments show that compared to full fine-tuning, the enhanced VoP\nachieves a 1.4% average R@1 gain across five text-video retrieval benchmarks\nwith 6x less parameter overhead. The code will be available at\nhttps://github.com/bighuang624/VoP.\n","authors":["Siteng Huang","Biao Gong","Yulin Pan","Jianwen Jiang","Yiliang Lv","Yuyuan Li","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2211.12764v2.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.04393v1","updated":"2023-03-08T05:55:02Z","published":"2023-03-08T05:55:02Z","title":"Imbalanced Open Set Domain Adaptation via Moving-threshold Estimation\n  and Gradual Alignment","summary":"  Multimedia applications are often associated with cross-domain knowledge\ntransfer, where Unsupervised Domain Adaptation (UDA) can be used to reduce the\ndomain shifts. Open Set Domain Adaptation (OSDA) aims to transfer knowledge\nfrom a well-labeled source domain to an unlabeled target domain under the\nassumption that the target domain contains unknown classes. Existing OSDA\nmethods consistently lay stress on the covariate shift, ignoring the potential\nlabel shift problem. The performance of OSDA methods degrades drastically under\nintra-domain class imbalance and inter-domain label shift. However, little\nattention has been paid to this issue in the community. In this paper, the\nImbalanced Open Set Domain Adaptation (IOSDA) is explored where the covariate\nshift, label shift and category mismatch exist simultaneously. To alleviate the\nnegative effects raised by label shift in OSDA, we propose Open-set\nMoving-threshold Estimation and Gradual Alignment (OMEGA) - a novel\narchitecture that improves existing OSDA methods on class-imbalanced data.\nSpecifically, a novel unknown-aware target clustering scheme is proposed to\nform tight clusters in the target domain to reduce the negative effects of\nlabel shift and intra-domain class imbalance. Furthermore, moving-threshold\nestimation is designed to generate specific thresholds for each target sample\nrather than using one for all. Extensive experiments on IOSDA, OSDA and OPDA\nbenchmarks demonstrate that our method could significantly outperform existing\nstate-of-the-arts. Code and data are available at\nhttps://github.com/mendicant04/OMEGA.\n","authors":[" Ru"," Jinghan"," Tian"," Jun"," Du"," Zhekai"," Xiao"," Chengwei"," Li"," Jingjing"," Shen","Heng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.04393v1.pdf","comment":"11 pages, 5 figures, 7 tables"},{"id":"http://arxiv.org/abs/2303.02455v2","updated":"2023-03-08T05:44:22Z","published":"2023-03-04T16:56:29Z","title":"DistilPose: Tokenized Pose Regression with Heatmap Distillation","summary":"  In the field of human pose estimation, regression-based methods have been\ndominated in terms of speed, while heatmap-based methods are far ahead in terms\nof performance. How to take advantage of both schemes remains a challenging\nproblem. In this paper, we propose a novel human pose estimation framework\ntermed DistilPose, which bridges the gaps between heatmap-based and\nregression-based methods. Specifically, DistilPose maximizes the transfer of\nknowledge from the teacher model (heatmap-based) to the student model\n(regression-based) through Token-distilling Encoder (TDE) and Simulated\nHeatmaps. TDE aligns the feature spaces of heatmap-based and regression-based\nmodels by introducing tokenization, while Simulated Heatmaps transfer explicit\nguidance (distribution and confidence) from teacher heatmaps into student\nmodels. Extensive experiments show that the proposed DistilPose can\nsignificantly improve the performance of the regression-based models while\nmaintaining efficiency. Specifically, on the MSCOCO validation dataset,\nDistilPose-S obtains 71.6% mAP with 5.36M parameter, 2.38 GFLOPs and 40.2 FPS,\nwhich saves 12.95x, 7.16x computational cost and is 4.9x faster than its\nteacher model with only 0.9 points performance drop. Furthermore, DistilPose-L\nobtains 74.4% mAP on MSCOCO validation dataset, achieving a new\nstate-of-the-art among predominant regression-based models.\n","authors":["Suhang Ye","Yingyi Zhang","Jie Hu","Liujuan Cao","Shengchuan Zhang","Lei Shen","Jun Wang","Shouhong Ding","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2303.02455v2.pdf","comment":"accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2303.04388v1","updated":"2023-03-08T05:28:01Z","published":"2023-03-08T05:28:01Z","title":"Interpretable Visual Question Answering Referring to Outside Knowledge","summary":"  We present a novel multimodal interpretable VQA model that can answer the\nquestion more accurately and generate diverse explanations. Although\nresearchers have proposed several methods that can generate human-readable and\nfine-grained natural language sentences to explain a model's decision, these\nmethods have focused solely on the information in the image. Ideally, the model\nshould refer to various information inside and outside the image to correctly\ngenerate explanations, just as we use background knowledge daily. The proposed\nmethod incorporates information from outside knowledge and multiple image\ncaptions to increase the diversity of information available to the model. The\ncontribution of this paper is to construct an interpretable visual question\nanswering model using multimodal inputs to improve the rationality of generated\nresults. Experimental results show that our model can outperform\nstate-of-the-art methods regarding answer accuracy and explanation rationality.\n","authors":["He Zhu","Ren Togo","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2303.04388v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2211.04774v5","updated":"2023-03-08T05:18:21Z","published":"2022-11-09T10:01:25Z","title":"IRNet: Iterative Refinement Network for Noisy Partial Label Learning","summary":"  Partial label learning (PLL) is a typical weakly supervised learning, where\neach sample is associated with a set of candidate labels. The basic assumption\nof PLL is that the ground-truth label must reside in the candidate set.\nHowever, this assumption may not be satisfied due to the unprofessional\njudgment of the annotators, thus limiting the practical application of PLL. In\nthis paper, we relax this assumption and focus on a more general problem, noisy\nPLL, where the ground-truth label may not exist in the candidate set. To\naddress this challenging problem, we propose a novel framework called\n\"Iterative Refinement Network (IRNet)\". It aims to purify the noisy samples by\ntwo key modules, i.e., noisy sample detection and label correction. Ideally, we\ncan convert noisy PLL into traditional PLL if all noisy samples are corrected.\nTo guarantee the performance of these modules, we start with warm-up training\nand exploit data augmentation to reduce prediction errors. Through theoretical\nanalysis, we prove that IRNet is able to reduce the noise level of the dataset\nand eventually approximate the Bayes optimal classifier. Experimental results\non multiple benchmark datasets demonstrate the effectiveness of our method.\nIRNet is superior to existing state-of-the-art approaches on noisy PLL.\n","authors":["Zheng Lian","Mingyu Xu","Lan Chen","Licai Sun","Bin Liu","Jianhua Tao"],"pdf_url":"https://arxiv.org/pdf/2211.04774v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04384v1","updated":"2023-03-08T05:15:01Z","published":"2023-03-08T05:15:01Z","title":"SEMv2: Table Separation Line Detection Based on Conditional Convolution","summary":"  Table structure recognition is an indispensable element for enabling machines\nto comprehend tables. Its primary purpose is to identify the internal structure\nof a table. Nevertheless, due to the complexity and diversity of their\nstructure and style, it is highly challenging to parse the tabular data into a\nstructured format that machines can comprehend. In this work, we adhere to the\nprinciple of the split-and-merge based methods and propose an accurate table\nstructure recognizer, termed SEMv2 (SEM: Split, Embed and Merge). Unlike the\nprevious works in the ``split'' stage, we aim to address the table separation\nline instance-level discrimination problem and introduce a table separation\nline detection strategy based on conditional convolution. Specifically, we\ndesign the ``split'' in a top-down manner that detects the table separation\nline instance first and then dynamically predicts the table separation line\nmask for each instance. The final table separation line shape can be accurately\nobtained by processing the table separation line mask in a row-wise/column-wise\nmanner. To comprehensively evaluate the SEMv2, we also present a more\nchallenging dataset for table structure recognition, dubbed iFLYTAB, which\nencompasses multiple style tables in various scenarios such as photos, scanned\ndocuments, etc. Extensive experiments on publicly available datasets (e.g.\nSciTSR, PubTabNet and iFLYTAB) demonstrate the efficacy of our proposed\napproach. The code and iFLYTAB dataset will be made publicly available upon\nacceptance of this paper.\n","authors":["Zhenrong Zhang","Pengfei Hu","Jiefeng Ma","Jun Du","Jianshu Zhang","Huihui Zhu","Baocai Yin","Bing Yin","Cong Liu"],"pdf_url":"https://arxiv.org/pdf/2303.04384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04378v1","updated":"2023-03-08T05:01:00Z","published":"2023-03-08T05:01:00Z","title":"SGDViT: Saliency-Guided Dynamic Vision Transformer for UAV Tracking","summary":"  Vision-based object tracking has boosted extensive autonomous applications\nfor unmanned aerial vehicles (UAVs). However, the dynamic changes in flight\nmaneuver and viewpoint encountered in UAV tracking pose significant\ndifficulties, e.g. , aspect ratio change, and scale variation. The conventional\ncross-correlation operation, while commonly used, has limitations in\neffectively capturing perceptual similarity and incorporates extraneous\nbackground information. To mitigate these limitations, this work presents a\nnovel saliency-guided dynamic vision Transformer (SGDViT) for UAV tracking. The\nproposed method designs a new task-specific object saliency mining network to\nrefine the cross-correlation operation and effectively discriminate foreground\nand background information. Additionally, a saliency adaptation embedding\noperation dynamically generates tokens based on initial saliency, thereby\nreducing the computational complexity of the Transformer architecture. Finally,\na lightweight saliency filtering Transformer further refines saliency\ninformation and increases the focus on appearance information. The efficacy and\nrobustness of the proposed approach have been thoroughly assessed through\nexperiments on three widely-used UAV tracking benchmarks and real-world\nscenarios, with results demonstrating its superiority. The source code and demo\nvideos are available at https://github.com/vision4robotics/SGDViT.\n","authors":["Liangliang Yao","Changhong Fu","Sihang Li","Guangze Zheng","Junjie Ye"],"pdf_url":"https://arxiv.org/pdf/2303.04378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04376v1","updated":"2023-03-08T04:59:43Z","published":"2023-03-08T04:59:43Z","title":"TSANET: Temporal and Scale Alignment for Unsupervised Video Object\n  Segmentation","summary":"  Unsupervised Video Object Segmentation (UVOS) refers to the challenging task\nof segmenting the prominent object in videos without manual guidance. In other\nwords, the network detects the accurate region of the target object in a\nsequence of RGB frames without prior knowledge. In recent works, two approaches\nfor UVOS have been discussed that can be divided into: appearance and\nappearance-motion based methods. Appearance based methods utilize the\ncorrelation information of inter-frames to capture target object that commonly\nappears in a sequence. However, these methods does not consider the motion of\ntarget object due to exploit the correlation information between randomly\npaired frames. Appearance-motion based methods, on the other hand, fuse the\nappearance features from RGB frames with the motion features from optical flow.\nMotion cue provides useful information since salient objects typically show\ndistinctive motion in a sequence. However, these approaches have the limitation\nthat the dependency on optical flow is dominant. In this paper, we propose a\nnovel framework for UVOS that can address aforementioned limitations of two\napproaches in terms of both time and scale. Temporal Alignment Fusion aligns\nthe saliency information of adjacent frames with the target frame to leverage\nthe information of adjacent frames. Scale Alignment Decoder predicts the target\nobject mask precisely by aggregating differently scaled feature maps via\ncontinuous mapping with implicit neural representation. We present experimental\nresults on public benchmark datasets, DAVIS 2016 and FBMS, which demonstrate\nthe effectiveness of our method. Furthermore, we outperform the\nstate-of-the-art methods on DAVIS 2016.\n","authors":["Seunghoon Lee","Suhwan Cho","Dogyoon Lee","Minhyeok Lee","Sangyoun Lee"],"pdf_url":"https://arxiv.org/pdf/2303.04376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04365v1","updated":"2023-03-08T04:12:32Z","published":"2023-03-08T04:12:32Z","title":"SANDFORMER: CNN and Transformer under Gated Fusion for Sand Dust Image\n  Restoration","summary":"  Although Convolutional Neural Networks (CNN) have made good progress in image\nrestoration, the intrinsic equivalence and locality of convolutions still\nconstrain further improvements in image quality. Recent vision transformer and\nself-attention have achieved promising results on various computer vision\ntasks. However, directly utilizing Transformer for image restoration is a\nchallenging task. In this paper, we introduce an effective hybrid architecture\nfor sand image restoration tasks, which leverages local features from CNN and\nlong-range dependencies captured by transformer to improve the results further.\nWe propose an efficient hybrid structure for sand dust image restoration to\nsolve the feature inconsistency issue between Transformer and CNN. The\nframework complements each representation by modulating features from the\nCNN-based and Transformer-based branches rather than simply adding or\nconcatenating features. Experiments demonstrate that SandFormer achieves\nsignificant performance improvements in synthetic and real dust scenes compared\nto previous sand image restoration methods.\n","authors":["Jun Shi","Bingcai Wei","Gang Zhou","Liye Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.04365v1.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.04364v1","updated":"2023-03-08T04:10:04Z","published":"2023-03-08T04:10:04Z","title":"Dynamic Scenario Representation Learning for Motion Forecasting with\n  Heterogeneous Graph Convolutional Recurrent Networks","summary":"  Due to the complex and changing interactions in dynamic scenarios, motion\nforecasting is a challenging problem in autonomous driving. Most existing works\nexploit static road graphs to characterize scenarios and are limited in\nmodeling evolving spatio-temporal dependencies in dynamic scenarios. In this\npaper, we resort to dynamic heterogeneous graphs to model the scenario. Various\nscenario components including vehicles (agents) and lanes, multi-type\ninteractions, and their changes over time are jointly encoded. Furthermore, we\ndesign a novel heterogeneous graph convolutional recurrent network, aggregating\ndiverse interaction information and capturing their evolution, to learn to\nexploit intrinsic spatio-temporal dependencies in dynamic graphs and obtain\neffective representations of dynamic scenarios. Finally, with a motion\nforecasting decoder, our model predicts realistic and multi-modal future\ntrajectories of agents and outperforms state-of-the-art published works on\nseveral motion forecasting benchmarks.\n","authors":["Xing Gao","Xiaogang Jia","Yikang Li","Hongkai Xiong"],"pdf_url":"https://arxiv.org/pdf/2303.04364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2010.01919v3","updated":"2023-03-08T04:09:23Z","published":"2020-10-05T11:01:45Z","title":"Local Label Point Correction for Edge Detection of Overlapping Cervical\n  Cells","summary":"  Accurate labeling is essential for supervised deep learning methods. However,\nit is almost impossible to accurately and manually annotate thousands of\nimages, which results in many labeling errors for most datasets. We proposes a\nlocal label point correction (LLPC) method to improve annotation quality for\nedge detection and image segmentation tasks. Our algorithm contains three\nsteps: gradient-guided point correction, point interpolation and local point\nsmoothing. We correct the labels of object contours by moving the annotated\npoints to the pixel gradient peaks. This can improve the edge localization\naccuracy, but it also causes unsmooth contours due to the interference of image\nnoise. Therefore, we design a point smoothing method based on local linear\nfitting to smooth the corrected edge. To verify the effectiveness of our LLPC,\nwe construct a largest overlapping cervical cell edge detection dataset (CCEDD)\nwith higher precision label corrected by our label correction method. Our LLPC\nonly needs to set three parameters, but yields 30-40$\\%$ average precision\nimprovement on multiple networks. The qualitative and quantitative experimental\nresults show that our LLPC can improve the quality of manual labels and the\naccuracy of overlapping cell edge detection. We hope that our study will give a\nstrong boost to the development of the label correction for edge detection and\nimage segmentation. We will release the dataset and code at\nhttps://github.com/nachifur/LLPC.\n","authors":["Jiawei Liu","Huijie Fan","Qiang Wang","Wentao Li","Yandong Tang","Danbo Wang","Mingyi Zhou","Li Chen"],"pdf_url":"https://arxiv.org/pdf/2010.01919v3.pdf","comment":"Published on Frontiers in Neuroinformatics. Official paper:\n  https://www.frontiersin.org/articles/10.3389/fninf.2022.895290/full. Code and\n  dataset: https://github.com/nachifur/LLPC"},{"id":"http://arxiv.org/abs/2303.04361v1","updated":"2023-03-08T03:58:06Z","published":"2023-03-08T03:58:06Z","title":"Sample Efficient Multimodal Semantic Augmentation for Incremental\n  Summarization","summary":"  In this work, we develop a prompting approach for incremental summarization\nof task videos. We develop a sample-efficient few-shot approach for extracting\nsemantic concepts as an intermediate step. We leverage an existing model for\nextracting the concepts from the images and extend it to videos and introduce a\nclustering and querying approach for sample efficiency, motivated by the recent\nadvances in perceiver-based architectures. Our work provides further evidence\nthat an approach with richer input context with relevant entities and actions\nfrom the videos and using these as prompts could enhance the summaries\ngenerated by the model. We show the results on a relevant dataset and discuss\npossible directions for the work.\n","authors":["Sumanta Bhattacharyya","Ramesh Manuvinakurike","Sahisnu Mazumder","Saurav Sahay"],"pdf_url":"https://arxiv.org/pdf/2303.04361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04351v1","updated":"2023-03-08T03:22:11Z","published":"2023-03-08T03:22:11Z","title":"ElC-OIS: Ellipsoidal Clustering for Open-World Instance Segmentation on\n  LiDAR Data","summary":"  Open-world Instance Segmentation (OIS) is a challenging task that aims to\naccurately segment every object instance appearing in the current observation,\nregardless of whether these instances have been labeled in the training set.\nThis is important for safety-critical applications such as robust autonomous\nnavigation. In this paper, we present a flexible and effective OIS framework\nfor LiDAR point cloud that can accurately segment both known and unknown\ninstances (i.e., seen and unseen instance categories during training). It first\nidentifies points belonging to known classes and removes the background by\nleveraging close-set panoptic segmentation networks. Then, we propose a novel\nellipsoidal clustering method that is more adapted to the characteristic of\nLiDAR scans and allows precise segmentation of unknown instances. Furthermore,\na diffuse searching method is proposed to handle the common over-segmentation\nproblem presented in the known instances. With the combination of these\ntechniques, we are able to achieve accurate segmentation for both known and\nunknown instances. We evaluated our method on the SemanticKITTI open-world\nLiDAR instance segmentation dataset. The experimental results suggest that it\noutperforms current state-of-the-art methods, especially with a 10.0%\nimprovement in association quality. The source code of our method will be\npublicly available at https://github.com/nubot-nudt/ElC-OIS.\n","authors":["Wenbang Deng","Kaihong Huang","Qinghua Yu","Huimin Lu","Zhiqiang Zheng","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2303.04351v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02697v2","updated":"2023-03-08T03:14:59Z","published":"2022-10-06T06:09:16Z","title":"DexGraspNet: A Large-Scale Robotic Dexterous Grasp Dataset for General\n  Objects Based on Simulation","summary":"  Robotic dexterous grasping is the first step to enable human-like dexterous\nobject manipulation and thus a crucial robotic technology. However, dexterous\ngrasping is much more under-explored than object grasping with parallel\ngrippers, partially due to the lack of a large-scale dataset. In this work, we\npresent a large-scale robotic dexterous grasp dataset, DexGraspNet, generated\nby our proposed highly efficient synthesis method that can be generally applied\nto any dexterous hand. Our method leverages a deeply accelerated differentiable\nforce closure estimator and thus can efficiently and robustly synthesize stable\nand diverse grasps on a large scale. We choose ShadowHand and generate 1.32\nmillion grasps for 5355 objects, covering more than 133 object categories and\ncontaining more than 200 diverse grasps for each object instance, with all\ngrasps having been validated by the Isaac Gym simulator. Compared to the\nprevious dataset from Liu et al. generated by GraspIt!, our dataset has not\nonly more objects and grasps, but also higher diversity and quality. Via\nperforming cross-dataset experiments, we show that training several algorithms\nof dexterous grasp synthesis on our dataset significantly outperforms training\non the previous one. To access our data and code, including code for human and\nAllegro grasp synthesis, please visit our project page:\nhttps://pku-epic.github.io/DexGraspNet/.\n","authors":["Ruicheng Wang","Jialiang Zhang","Jiayi Chen","Yinzhen Xu","Puhao Li","Tengyu Liu","He Wang"],"pdf_url":"https://arxiv.org/pdf/2210.02697v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04346v1","updated":"2023-03-08T02:57:05Z","published":"2023-03-08T02:57:05Z","title":"Semi-Supervised 2D Human Pose Estimation Driven by Position\n  Inconsistency Pseudo Label Correction Module","summary":"  In this paper, we delve into semi-supervised 2D human pose estimation. The\nprevious method ignored two problems: (i) When conducting interactive training\nbetween large model and lightweight model, the pseudo label of lightweight\nmodel will be used to guide large models. (ii) The negative impact of noise\npseudo labels on training. Moreover, the labels used for 2D human pose\nestimation are relatively complex: keypoint category and keypoint position. To\nsolve the problems mentioned above, we propose a semi-supervised 2D human pose\nestimation framework driven by a position inconsistency pseudo label correction\nmodule (SSPCM). We introduce an additional auxiliary teacher and use the pseudo\nlabels generated by the two teacher model in different periods to calculate the\ninconsistency score and remove outliers. Then, the two teacher models are\nupdated through interactive training, and the student model is updated using\nthe pseudo labels generated by two teachers. To further improve the performance\nof the student model, we use the semi-supervised Cut-Occlude based on pseudo\nkeypoint perception to generate more hard and effective samples. In addition,\nwe also proposed a new indoor overhead fisheye human keypoint dataset\nWEPDTOF-Pose. Extensive experiments demonstrate that our method outperforms the\nprevious best semi-supervised 2D human pose estimation method. We will release\nthe code and dataset at https://github.com/hlz0606/SSPCM.\n","authors":["Linzhi Huang","Yulong Li","Hongbo Tian","Yue Yang","Xiangang Li","Weihong Deng","Jieping Ye"],"pdf_url":"https://arxiv.org/pdf/2303.04346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04343v1","updated":"2023-03-08T02:38:29Z","published":"2023-03-08T02:38:29Z","title":"M-EBM: Towards Understanding the Manifolds of Energy-Based Models","summary":"  Energy-based models (EBMs) exhibit a variety of desirable properties in\npredictive tasks, such as generality, simplicity and compositionality. However,\ntraining EBMs on high-dimensional datasets remains unstable and expensive. In\nthis paper, we present a Manifold EBM (M-EBM) to boost the overall performance\nof unconditional EBM and Joint Energy-based Model (JEM). Despite its\nsimplicity, M-EBM significantly improves unconditional EBMs in training\nstability and speed on a host of benchmark datasets, such as CIFAR10, CIFAR100,\nCelebA-HQ, and ImageNet 32x32. Once class labels are available,\nlabel-incorporated M-EBM (M-JEM) further surpasses M-EBM in image generation\nquality with an over 40% FID improvement, while enjoying improved accuracy. The\ncode can be found at https://github.com/sndnyang/mebm.\n","authors":["Xiulong Yang","Shihao Ji"],"pdf_url":"https://arxiv.org/pdf/2303.04343v1.pdf","comment":"Accepted to PAKDD 2023"},{"id":"http://arxiv.org/abs/2303.04341v1","updated":"2023-03-08T02:36:09Z","published":"2023-03-08T02:36:09Z","title":"Neural Vector Fields: Implicit Representation by Explicit Learning","summary":"  Deep neural networks (DNNs) are widely applied for nowadays 3D surface\nreconstruction tasks and such methods can be further divided into two\ncategories, which respectively warp templates explicitly by moving vertices or\nrepresent 3D surfaces implicitly as signed or unsigned distance functions.\nTaking advantage of both advanced explicit learning process and powerful\nrepresentation ability of implicit functions, we propose a novel 3D\nrepresentation method, Neural Vector Fields (NVF). It not only adopts the\nexplicit learning process to manipulate meshes directly, but also leverages the\nimplicit representation of unsigned distance functions (UDFs) to break the\nbarriers in resolution and topology. Specifically, our method first predicts\nthe displacements from queries towards the surface and models the shapes as\n\\textit{Vector Fields}. Rather than relying on network differentiation to\nobtain direction fields as most existing UDF-based methods, the produced vector\nfields encode the distance and direction fields both and mitigate the ambiguity\nat \"ridge\" points, such that the calculation of direction fields is\nstraightforward and differentiation-free. The differentiation-free\ncharacteristic enables us to further learn a shape codebook via Vector\nQuantization, which encodes the cross-object priors, accelerates the training\nprocedure, and boosts model generalization on cross-category reconstruction.\nThe extensive experiments on surface reconstruction benchmarks indicate that\nour method outperforms those state-of-the-art methods in different evaluation\nscenarios including watertight vs non-watertight shapes, category-specific vs\ncategory-agnostic reconstruction, category-unseen reconstruction, and\ncross-domain reconstruction. Our code will be publicly released.\n","authors":["Xianghui Yang","Guosheng Lin","Zhenghao Chen","Luping Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.04341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04340v1","updated":"2023-03-08T02:33:17Z","published":"2023-03-08T02:33:17Z","title":"Privacy-preserving and Uncertainty-aware Federated Trajectory Prediction\n  for Connected Autonomous Vehicles","summary":"  Deep learning is the method of choice for trajectory prediction for\nautonomous vehicles. Unfortunately, its data-hungry nature implicitly requires\nthe availability of sufficiently rich and high-quality centralized datasets,\nwhich easily leads to privacy leakage. Besides, uncertainty-awareness becomes\nincreasingly important for safety-crucial cyber physical systems whose\nprediction module heavily relies on machine learning tools. In this paper, we\nrelax the data collection requirement and enhance uncertainty-awareness by\nusing Federated Learning on Connected Autonomous Vehicles with an\nuncertainty-aware global objective. We name our algorithm as FLTP. We further\nintroduce ALFLTP which boosts FLTP via using active learning techniques in\nadaptatively selecting participating clients. We consider both negative\nlog-likelihood (NLL) and aleatoric uncertainty (AU) as client selection\nmetrics. Experiments on Argoverse dataset show that FLTP significantly\noutperforms the model trained on local data. In addition, ALFLTP-AU converges\nfaster in training regression loss and performs better in terms of NLL, minADE\nand MR than FLTP in most rounds, and has more stable round-wise performance\nthan ALFLTP-NLL.\n","authors":["Muzi Peng","Jiangwei Wang","Dongjin Song","Fei Miao","Lili Su"],"pdf_url":"https://arxiv.org/pdf/2303.04340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14589v3","updated":"2023-03-08T02:26:37Z","published":"2023-02-28T14:16:32Z","title":"Focus On Details: Online Multi-object Tracking with Diverse Fine-grained\n  Representation","summary":"  Discriminative representation is essential to keep a unique identifier for\neach target in Multiple object tracking (MOT). Some recent MOT methods extract\nfeatures of the bounding box region or the center point as identity embeddings.\nHowever, when targets are occluded, these coarse-grained global representations\nbecome unreliable. To this end, we propose exploring diverse fine-grained\nrepresentation, which describes appearance comprehensively from global and\nlocal perspectives. This fine-grained representation requires high feature\nresolution and precise semantic information. To effectively alleviate the\nsemantic misalignment caused by indiscriminate contextual information\naggregation, Flow Alignment FPN (FAFPN) is proposed for multi-scale feature\nalignment aggregation. It generates semantic flow among feature maps from\ndifferent resolutions to transform their pixel positions. Furthermore, we\npresent a Multi-head Part Mask Generator (MPMG) to extract fine-grained\nrepresentation based on the aligned feature maps. Multiple parallel branches of\nMPMG allow it to focus on different parts of targets to generate local masks\nwithout label supervision. The diverse details in target masks facilitate\nfine-grained representation. Eventually, benefiting from a Shuffle-Group\nSampling (SGS) training strategy with positive and negative samples balanced,\nwe achieve state-of-the-art performance on MOT17 and MOT20 test sets. Even on\nDanceTrack, where the appearance of targets is extremely similar, our method\nsignificantly outperforms ByteTrack by 5.0% on HOTA and 5.6% on IDF1. Extensive\nexperiments have proved that diverse fine-grained representation makes Re-ID\ngreat again in MOT.\n","authors":["Hao Ren","Shoudong Han","Huilin Ding","Ziwen Zhang","Hongwei Wang","Faquan Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14589v3.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2303.04336v1","updated":"2023-03-08T02:19:54Z","published":"2023-03-08T02:19:54Z","title":"QuickSRNet: Plain Single-Image Super-Resolution Architecture for Faster\n  Inference on Mobile Platforms","summary":"  In this work, we present QuickSRNet, an efficient super-resolution\narchitecture for real-time applications on mobile platforms. Super-resolution\nclarifies, sharpens, and upscales an image to higher resolution. Applications\nsuch as gaming and video playback along with the ever-improving display\ncapabilities of TVs, smartphones, and VR headsets are driving the need for\nefficient upscaling solutions. While existing deep learning-based\nsuper-resolution approaches achieve impressive results in terms of visual\nquality, enabling real-time DL-based super-resolution on mobile devices with\ncompute, thermal, and power constraints is challenging. To address these\nchallenges, we propose QuickSRNet, a simple yet effective architecture that\nprovides better accuracy-to-latency trade-offs than existing neural\narchitectures for single-image super resolution. We present training tricks to\nspeed up existing residual-based super-resolution architectures while\nmaintaining robustness to quantization. Our proposed architecture produces\n1080p outputs via 2x upscaling in 2.2 ms on a modern smartphone, making it\nideal for high-fps real-time applications.\n","authors":["Guillaume Berger","Manik Dhingra","Antoine Mercier","Yashesh Savani","Sunny Panchal","Fatih Porikli"],"pdf_url":"https://arxiv.org/pdf/2303.04336v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2303.04334v1","updated":"2023-03-08T02:11:54Z","published":"2023-03-08T02:11:54Z","title":"Corner Detection Based on Multi-directional Gabor Filters with\n  Multi-scales","summary":"  Gabor wavelet is an essential tool for image analysis and computer vision\ntasks. Local structure tensors with multiple scales are widely used in local\nfeature extraction. Our research indicates that the current corner detection\nmethod based on Gabor wavelets can not effectively apply to complex scenes. In\nthis work, the capability of the Gabor function to discriminate the intensity\nchanges of step edges, L-shaped corners, Y-shaped or T-shaped corners, X-shaped\ncorners, and star-shaped corners are investigated. The properties of Gabor\nwavelets to suppress affine image transformation are investigated and obtained.\nMany properties for edges and corners were discovered, which prompted us to\npropose a new corner extraction method. To fully use the structural information\nfrom the tuned Gabor filters, a novel multi-directional structure tensor is\nconstructed for corner detection, and a multi-scale corner measurement function\nis proposed to remove false candidate corners. Furthermore, we compare the\nproposed method with twelve current state-of-the-art methods, which exhibit\noptimal performance and practical application to 3D reconstruction with good\napplication potential.\n","authors":["Huaqing Wang","Junfeng Jing","Ning Li","Weichuan Zhang","Chao Liu"],"pdf_url":"https://arxiv.org/pdf/2303.04334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09062v2","updated":"2023-03-08T01:45:53Z","published":"2022-12-18T11:02:50Z","title":"Bort: Towards Explainable Neural Networks with Bounded Orthogonal\n  Constraint","summary":"  Deep learning has revolutionized human society, yet the black-box nature of\ndeep neural networks hinders further application to reliability-demanded\nindustries. In the attempt to unpack them, many works observe or impact\ninternal variables to improve the comprehensibility and invertibility of the\nblack-box models. However, existing methods rely on intuitive assumptions and\nlack mathematical guarantees. To bridge this gap, we introduce Bort, an\noptimizer for improving model explainability with boundedness and orthogonality\nconstraints on model parameters, derived from the sufficient conditions of\nmodel comprehensibility and invertibility. We perform reconstruction and\nbacktracking on the model representations optimized by Bort and observe a clear\nimprovement in model explainability. Based on Bort, we are able to synthesize\nexplainable adversarial samples without additional parameters and training.\nSurprisingly, we find Bort constantly improves the classification accuracy of\nvarious architectures including ResNet and DeiT on MNIST, CIFAR-10, and\nImageNet. Code: https://github.com/zbr17/Bort.\n","authors":["Borui Zhang","Wenzhao Zheng","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2212.09062v2.pdf","comment":"ICLR 2023 accepted"},{"id":"http://arxiv.org/abs/2303.04315v1","updated":"2023-03-08T01:29:55Z","published":"2023-03-08T01:29:55Z","title":"A Threefold Review on Deep Semantic Segmentation: Efficiency-oriented,\n  Temporal and Depth-aware design","summary":"  Semantic image and video segmentation stand among the most important tasks in\ncomputer vision nowadays, since they provide a complete and meaningful\nrepresentation of the environment by means of a dense classification of the\npixels in a given scene. Recently, Deep Learning, and more precisely\nConvolutional Neural Networks, have boosted semantic segmentation to a new\nlevel in terms of performance and generalization capabilities. However,\ndesigning Deep Semantic Segmentation models is a complex task, as it may\ninvolve application-dependent aspects. Particularly, when considering\nautonomous driving applications, the robustness-efficiency trade-off, as well\nas intrinsic limitations - computational/memory bounds and data-scarcity - and\nconstraints - real-time inference - should be taken into consideration. In this\nrespect, the use of additional data modalities, such as depth perception for\nreasoning on the geometry of a scene, and temporal cues from videos to explore\nredundancy and consistency, are promising directions yet not explored to their\nfull potential in the literature. In this paper, we conduct a survey on the\nmost relevant and recent advances in Deep Semantic Segmentation in the context\nof vision for autonomous vehicles, from three different perspectives:\nefficiency-oriented model development for real-time operation, RGB-Depth data\nintegration (RGB-D semantic segmentation), and the use of temporal information\nfrom videos in temporally-aware models. Our main objective is to provide a\ncomprehensive discussion on the main methods, advantages, limitations, results\nand challenges faced from each perspective, so that the reader can not only get\nstarted, but also be up to date in respect to recent advances in this exciting\nand challenging research field.\n","authors":["Felipe Manfio Barbosa","Fernando Santos Osório"],"pdf_url":"https://arxiv.org/pdf/2303.04315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02635v2","updated":"2023-03-08T01:14:26Z","published":"2022-10-06T02:01:29Z","title":"Research on the quantity and brightness evolution characteristics of\n  Photospheric Bright Points groups","summary":"  Context. Photospheric bright points (BPs), as the smallest magnetic element\nof the photosphere and the footpoint tracer of the magnetic flux tube, are of\ngreat significance to the study of BPs. Compared with the study of the\ncharacteristics and evolution of a few specific BPs, the study of BPs groups\ncan provide us with a better understanding of the characteristics and overall\nactivities of BPs groups. Aims. We aim to find out the evolution\ncharacteristics of the brightness and number of BPs groups at different\nbrightness levels, and how these characteristics differ between quiet and\nactive regions. Methods. We propose a hybrid BPs detection model (HBD Model)\ncombining traditional technology and neural network. The Model is used to\ndetect and calculate the BPs brightness characteristics of each frame of\ncontinuous high resolution image sequences of active and quiet regions in\nTiO-band of a pair of BBSO. Using machine learning clustering method, the PBs\nof each frame was divided into four levels groups (level1-level4) according to\nthe brightness from low to high. Finally, Fourier transform and inverse Fourier\ntransform are used to analyze the evolution of BPs brightness and quantity in\nthese four levels groups. Results. The activities of BPs groups are not random\nand disorderly. In different levels of brightness, their quantity and\nbrightness evolution show complex changes. Among the four levels of brightness,\nBPs in the active region were more active and intense than those in the quiet\nregion. However, the quantity and brightness evolution of BPs groups in the\nquiet region showed the characteristics of large periodic changes and small\nperiodic changes in the medium and high brightness levels (level3 and level4).\nThe brightness evolution of PBs group in the quiet region has obvious periodic\nchanges, but the active region is in a completely random and violent\nfluctuation state.\n","authors":["HaiCheng Bai"],"pdf_url":"https://arxiv.org/pdf/2210.02635v2.pdf","comment":"The paper was edited using the Latex template from Astronomy &\n  Astrophysics, but this paper has never been published publicly in Astronomy &\n  Astrophysics. This mistake is very misleading. At the same time, there are\n  some errors in the description of the experimental data in the original\n  paper, and the experimental content is also insufficient"},{"id":"http://arxiv.org/abs/2303.04302v1","updated":"2023-03-08T00:48:32Z","published":"2023-03-08T00:48:32Z","title":"Camera-Radar Perception for Autonomous Vehicles and ADAS: Concepts,\n  Datasets and Metrics","summary":"  One of the main paths towards the reduction of traffic accidents is the\nincrease in vehicle safety through driver assistance systems or even systems\nwith a complete level of autonomy. In these types of systems, tasks such as\nobstacle detection and segmentation, especially the Deep Learning-based ones,\nplay a fundamental role in scene understanding for correct and safe navigation.\nBesides that, the wide variety of sensors in vehicles nowadays provides a rich\nset of alternatives for improvement in the robustness of perception in\nchallenging situations, such as navigation under lighting and weather adverse\nconditions. Despite the current focus given to the subject, the literature\nlacks studies on radar-based and radar-camera fusion-based perception. Hence,\nthis work aims to carry out a study on the current scenario of camera and\nradar-based perception for ADAS and autonomous vehicles. Concepts and\ncharacteristics related to both sensors, as well as to their fusion, are\npresented. Additionally, we give an overview of the Deep Learning-based\ndetection and segmentation tasks, and the main datasets, metrics, challenges,\nand open questions in vehicle perception.\n","authors":["Felipe Manfio Barbosa","Fernando Santos Osório"],"pdf_url":"https://arxiv.org/pdf/2303.04302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05638v2","updated":"2023-03-08T00:45:48Z","published":"2022-12-12T00:31:08Z","title":"Cross-Modal Learning with 3D Deformable Attention for Action Recognition","summary":"  An important challenge in vision-based action recognition is the embedding of\nspatiotemporal features with two or more heterogeneous modalities into a single\nfeature. In this study, we propose a new 3D deformable transformer for action\nrecognition with adaptive spatiotemporal receptive fields and a cross-modal\nlearning scheme. The 3D deformable transformer consists of three attention\nmodules: 3D deformability, local joint stride, and temporal stride attention.\nThe two cross-modal tokens are input into the 3D deformable attention module to\ncreate a cross-attention token with a reflected spatiotemporal correlation.\nLocal joint stride attention is applied to spatially combine attention and pose\ntokens. Temporal stride attention temporally reduces the number of input tokens\nin the attention module and supports temporal expression learning without the\nsimultaneous use of all tokens. The deformable transformer iterates L times and\ncombines the last cross-modal token for classification. The proposed 3D\ndeformable transformer was tested on the NTU60, NTU120, FineGYM, and PennAction\ndatasets, and showed results better than or similar to pre-trained\nstate-of-the-art methods even without a pre-training process. In addition, by\nvisualizing important joints and correlations during action recognition through\nspatial joint and temporal stride attention, the possibility of achieving an\nexplainable potential for action recognition is presented.\n","authors":["Sangwon Kim","Dasom Ahn","Byoung Chul Ko"],"pdf_url":"https://arxiv.org/pdf/2212.05638v2.pdf","comment":"10 pages, 8 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2303.04766v1","updated":"2023-03-08T18:03:51Z","published":"2023-03-08T18:03:51Z","title":"FastFill: Efficient Compatible Model Update","summary":"  In many retrieval systems the original high dimensional data (e.g., images)\nis mapped to a lower dimensional feature through a learned embedding model. The\ntask of retrieving the most similar data from a gallery set to a given query\ndata is performed through a similarity comparison on features. When the\nembedding model is updated, it might produce features that are not\ncomparable/compatible with features already in the gallery computed with the\nold model. Subsequently, all features in the gallery need to be re-computed\nusing the new embedding model -- a computationally expensive process called\nbackfilling. Recently, compatible representation learning methods have been\nproposed to avoid backfilling. Despite their relative success, there is an\ninherent trade-off between the new model performance and its compatibility with\nthe old model. In this work, we introduce FastFill: a compatible model update\nprocess using feature alignment and policy based partial backfilling to\npromptly elevate retrieval performance. We show that previous backfilling\nstrategies suffer from decreased performance and demonstrate the importance of\nboth the training objective and the ordering in online partial backfilling. We\npropose a new training method for feature alignment between old and new\nembedding models using uncertainty estimation. Compared to previous works, we\nobtain significantly improved backfilling results on a variety of datasets: mAP\non ImageNet (+4.4\\%), Places-365 (+2.7\\%), and VGG-Face2 (+1.3\\%). Further, we\ndemonstrate that when updating a biased model with FastFill, the minority\nsubgroup accuracy gap promptly vanishes with a small fraction of partial\nbackfilling.\n","authors":["Florian Jaeckle","Fartash Faghri","Ali Farhadi","Oncel Tuzel","Hadi Pouransari"],"pdf_url":"https://arxiv.org/pdf/2303.04766v1.pdf","comment":"To appear in The Eleventh International Conference on Learning\n  Representations"},{"id":"http://arxiv.org/abs/2303.04587v1","updated":"2023-03-08T13:59:41Z","published":"2023-03-08T13:59:41Z","title":"A Prompt Log Analysis of Text-to-Image Generation Systems","summary":"  Recent developments in diffusion models have unleashed the astonishing\ncapabilities of text-to-image generation systems to synthesize high-quality\nimages that are faithful to a given reference text, known as a \"prompt.\" These\nsystems, once released to the public, have immediately received tons of\nattention from researchers, creators, and common users. Despite the plenty of\nefforts to improve the underneath generative models, there is limited work on\nunderstanding the information needs of the real users of these systems, e.g.,\nby investigating the prompts the users input at scale. In this paper, we take\nthe initiative to conduct a comprehensive analysis of large-scale prompt logs\ncollected from multiple text-to-image generation systems. Our work is analogous\nto analyzing the query log of Web search engines, a line of work that has made\ncritical contributions to the glory of the Web search industry and research. We\nanalyze over two million user-input prompts submitted to three popular\ntext-to-image systems at scale. Compared to Web search queries, text-to-image\nprompts are significantly longer, often organized into unique structures, and\npresent different categories of information needs. Users tend to make more\nedits within creation sessions, showing remarkable exploratory patterns. Our\nfindings provide concrete implications on how to improve text-to-image\ngeneration systems for creation purposes.\n","authors":["Yutong Xie","Zhaoying Pan","Jinge Ma","Jie Luo","Qiaozhu Mei"],"pdf_url":"https://arxiv.org/pdf/2303.04587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.11879v4","updated":"2023-03-08T13:45:55Z","published":"2022-10-21T11:08:10Z","title":"GLCC: A General Framework for Graph-Level Clustering","summary":"  This paper studies the problem of graph-level clustering, which is a novel\nyet challenging task. This problem is critical in a variety of real-world\napplications such as protein clustering and genome analysis in bioinformatics.\nRecent years have witnessed the success of deep clustering coupled with graph\nneural networks (GNNs). However, existing methods focus on clustering among\nnodes given a single graph, while exploring clustering on multiple graphs is\nstill under-explored. In this paper, we propose a general graph-level\nclustering framework named Graph-Level Contrastive Clustering (GLCC) given\nmultiple graphs. Specifically, GLCC first constructs an adaptive affinity graph\nto explore instance- and cluster-level contrastive learning (CL).\nInstance-level CL leverages graph Laplacian based contrastive loss to learn\nclustering-friendly representations while cluster-level CL captures\ndiscriminative cluster representations incorporating neighbor information of\neach sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the\noptimization of representation learning. The two steps can be alternatively\ntrained to collaborate and benefit each other. Experiments on a range of\nwell-known datasets demonstrate the superiority of our proposed GLCC over\ncompetitive baselines.\n","authors":["Wei Ju","Yiyang Gu","Binqi Chen","Gongbo Sun","Yifang Qin","Xingyuming Liu","Xiao Luo","Ming Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.11879v4.pdf","comment":"Accepted by Proceedings of the AAAI Conference on Artificial\n  Intelligence (AAAI 2023)"},{"id":"http://arxiv.org/abs/2303.04561v1","updated":"2023-03-08T13:20:53Z","published":"2023-03-08T13:20:53Z","title":"Kernel-CF: Collaborative filtering done right with social network\n  analysis and kernel smoothing","summary":"  Collaborative filtering is the simplest but oldest machine learning algorithm\nin the field of recommender systems. In spite of its long history, it remains a\ndiscussion topic in research venues. Usually people use users/items whose\nsimilarity scores with the target customer greater than 0 to compute the\nalgorithms. However, this might not be the optimal solution after careful\nscrutiny. In this paper, we transform the recommender system input data into a\n2-D social network, and apply kernel smoothing to compute preferences for\nunknown values in the user item rating matrix. We unifies the theoretical\nframework of recommender system and non-parametric statistics and provides an\nalgorithmic procedure with optimal parameter selection method to achieve the\ngoal.\n","authors":["Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2303.04561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04532v1","updated":"2023-03-08T12:04:16Z","published":"2023-03-08T12:04:16Z","title":"Class Cardinality Comparison as a Fermi Problem","summary":"  Questions on class cardinality comparisons are quite tricky to answer and\ncome with its own challenges. They require some kind of reasoning since web\ndocuments and knowledge bases, indispensable sources of information, rarely\nstore direct answers to questions, such as, ``Are there more astronauts or\nPhysics Nobel Laureates?'' We tackle questions on class cardinality comparison\nby tapping into three sources for absolute cardinalities as well as the\ncardinalities of orthogonal subgroups of the classes. We propose novel\ntechniques for aggregating signals with partial coverage for more reliable\nestimates and evaluate them on a dataset of 4005 class pairs, achieving an\naccuracy of 83.7%.\n","authors":["Shrestha Ghosh","Simon Razniewski","Gerhard Weikum"],"pdf_url":"https://arxiv.org/pdf/2303.04532v1.pdf","comment":"Accepted to the Web Conference 2023"},{"id":"http://arxiv.org/abs/2303.04426v1","updated":"2023-03-08T08:08:57Z","published":"2023-03-08T08:08:57Z","title":"NASTyLinker: NIL-Aware Scalable Transformer-based Entity Linker","summary":"  Entity Linking (EL) is the task of detecting mentions of entities in text and\ndisambiguating them to a reference knowledge base. Most prevalent EL approaches\nassume that the reference knowledge base is complete. In practice, however, it\nis necessary to deal with the case of linking to an entity that is not\ncontained in the knowledge base (NIL entity). Recent works have shown that,\ninstead of focusing only on affinities between mentions and entities,\nconsidering inter-mention affinities can be used to represent NIL entities by\nproducing clusters of mentions. At the same time, inter-mention affinities can\nhelp to substantially improve linking performance for known entities. With\nNASTyLinker, we introduce an EL approach that is aware of NIL-entities and\nproduces corresponding mention clusters while maintaining high linking\nperformance for known entities. The approach clusters mentions and entities\nbased on dense representations from Transformers and resolves conflicts (if\nmore than one entity is assigned to a cluster) by computing transitive\nmention-entity affinities. We show the effectiveness and scalability of\nNASTyLinker on NILK, a dataset that is explicitly constructed to evaluate EL\nwith respect to NIL-entities. Further, we apply the presented approach to an\nactual EL task, namely to knowledge graph population by linking entities in\nWikipedia listings, and provide an analysis of the outcome.\n","authors":["Nicolas Heist","Heiko Paulheim"],"pdf_url":"https://arxiv.org/pdf/2303.04426v1.pdf","comment":"Preprint of a paper in the research track of the 20th Extended\n  Semantic Web Conference (ESWC'23)"},{"id":"http://arxiv.org/abs/2303.04392v1","updated":"2023-03-08T05:53:33Z","published":"2023-03-08T05:53:33Z","title":"Achievable Rates and Low-Complexity Encoding of Posterior Matching for\n  the BSC","summary":"  Horstein, Burnashev, Shayevitz and Feder, Naghshvar et al. and others have\nstudied sequential transmission of a K-bit message over the binary symmetric\nchannel (BSC) with full, noiseless feedback using posterior matching. Yang et\nal. provide an improved lower bound on the achievable rate using martingale\nanalysis that relies on the small-enough difference (SED) partitioning\nintroduced by Naghshvar et al. SED requires a relatively complex encoder and\ndecoder. To reduce complexity, this paper replaces SED with relaxed constraints\nthat admit the small enough absolute difference (SEAD) partitioning rule. The\nmain analytical results show that achievable-rate bounds higher than those\nfound by Yang et al. are possible even under the new constraints, which are\nless restrictive than SED. The new analysis does not use martingale theory for\nthe confirmation phase and applies a surrogate channel technique to tighten the\nresults. An initial systematic transmission further increases the achievable\nrate bound. The simplified encoder associated with SEAD has a complexity below\norder O(K^2) and allows simulations for message sizes of at least 1000 bits.\nFor example, simulations achieve 99% of of the channel's 0.50-bit capacity with\nan average block size of 200 bits for a target codeword error rate of 10^(-3).\n","authors":["Amaael Antonini","Rita Gimeshein","Richard Wesel"],"pdf_url":"https://arxiv.org/pdf/2303.04392v1.pdf","comment":"This paper consists of 26 pages and contains 6 figures. An earlier\n  version of the algorithm included in this paper was published at the 2020\n  IEEE International Symposium on Information Theory (ISIT), (DOI:\n  10.1109/ISIT44484.2020.9174232)"},{"id":"http://arxiv.org/abs/2302.13053v2","updated":"2023-03-08T04:13:48Z","published":"2023-02-25T10:42:34Z","title":"RETEXO: Scalable Neural Network Training over Distributed Graphs","summary":"  Graph neural networks offer a promising approach to supervised learning over\ngraph data. Graph data, especially when it is privacy-sensitive or too large to\ntrain on centrally, is often stored partitioned across disparate processing\nunits (clients) which want to minimize the communication costs during\ncollaborative training. The fully-distributed setup takes such partitioning to\nits extreme, wherein features of only a single node and its adjacent edges are\nkept locally with one client processor. Existing GNNs are not architected for\ntraining in such setups and incur prohibitive costs therein. We propose RETEXO,\na novel transformation of existing GNNs that improves the communication\nefficiency during training in the fully-distributed setup. We experimentally\nconfirm that RETEXO offers up to 6 orders of magnitude better communication\nefficiency even when training shallow GNNs, with a minimal trade-off in\naccuracy for supervised node classification tasks.\n","authors":["Aashish Kolluri","Sarthak Choudhary","Bryan Hooi","Prateek Saxena"],"pdf_url":"https://arxiv.org/pdf/2302.13053v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13795v2","updated":"2023-03-08T02:51:32Z","published":"2022-10-25T06:57:00Z","title":"Line Graph Contrastive Learning for Link Prediction","summary":"  Link prediction tasks focus on predicting possible future connections. Most\nexisting researches measure the likelihood of links by different similarity\nscores on node pairs and predict links between nodes. However, the\nsimilarity-based approaches have some challenges in information loss on nodes\nand generalization ability on similarity indexes. To address the above issues,\nwe propose a Line Graph Contrastive Learning(LGCL) method to obtain rich\ninformation with multiple perspectives. LGCL obtains a subgraph view by h-hop\nsubgraph sampling with target node pairs. After transforming the sampled\nsubgraph into a line graph, the link prediction task is converted into a node\nclassification task, which graph convolution progress can learn edge embeddings\nfrom graphs more effectively. Then we design a novel cross-scale contrastive\nlearning framework on the line graph and the subgraph to maximize the mutual\ninformation of them, so that fuses the structure and feature information. The\nexperimental results demonstrate that the proposed LGCL outperforms the\nstate-of-the-art methods and has better performance on generalization and\nrobustness.\n","authors":["Zehua Zhang","Shilin Sun","Guixiang Ma","Caiming Zhong"],"pdf_url":"https://arxiv.org/pdf/2210.13795v2.pdf","comment":"37 pages"},{"id":"http://arxiv.org/abs/2303.04335v1","updated":"2023-03-08T02:14:08Z","published":"2023-03-08T02:14:08Z","title":"Unbiased Learning to Rank with Biased Continuous Feedback","summary":"  It is a well-known challenge to learn an unbiased ranker with biased\nfeedback. Unbiased learning-to-rank(LTR) algorithms, which are verified to\nmodel the relative relevance accurately based on noisy feedback, are appealing\ncandidates and have already been applied in many applications with single\ncategorical labels, such as user click signals. Nevertheless, the existing\nunbiased LTR methods cannot properly handle continuous feedback, which are\nessential for many industrial applications, such as content recommender\nsystems.\n  To provide personalized high-quality recommendation results, recommender\nsystems need model both categorical and continuous biased feedback, such as\nclick and dwell time. Accordingly, we design a novel unbiased LTR algorithm to\ntackle the challenges, which innovatively models position bias in the pairwise\nfashion and introduces the pairwise trust bias to separate the position bias,\ntrust bias, and user relevance explicitly and can work for both continuous and\ncategorical feedback. Experiment results on public benchmark datasets and\ninternal live traffic of a large-scale recommender system at Tencent News show\nsuperior results for continuous labels and also competitive performance for\ncategorical labels of the proposed method.\n","authors":["Yi Ren","Hongyan Tang","Siwen Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.04335v1.pdf","comment":"10 pages. arXiv admin note: substantial text overlap with\n  arXiv:2111.12929"},{"id":"http://arxiv.org/abs/2207.08087v4","updated":"2023-03-08T15:06:11Z","published":"2022-07-17T06:50:35Z","title":"Automatic Context Pattern Generation for Entity Set Expansion","summary":"  Entity Set Expansion (ESE) is a valuable task that aims to find entities of\nthe target semantic class described by given seed entities. Various Natural\nLanguage Processing (NLP) and Information Retrieval (IR) downstream\napplications have benefited from ESE due to its ability to discover knowledge.\nAlthough existing corpus-based ESE methods have achieved great progress, they\nstill rely on corpora with high-quality entity information annotated, because\nmost of them need to obtain the context patterns through the position of the\nentity in a sentence. Therefore, the quality of the given corpora and their\nentity annotation has become the bottleneck that limits the performance of such\nmethods. To overcome this dilemma and make the ESE models free from the\ndependence on entity annotation, our work aims to explore a new ESE paradigm,\nnamely corpus-independent ESE. Specifically, we devise a context pattern\ngeneration module that utilizes autoregressive language models (e.g., GPT-2) to\nautomatically generate high-quality context patterns for entities. In addition,\nwe propose the GAPA, a novel ESE framework that leverages the aforementioned\nGenerAted PAtterns to expand target entities. Extensive experiments and\ndetailed analyses on three widely used datasets demonstrate the effectiveness\nof our method. All the codes of our experiments are available at\nhttps://github.com/geekjuruo/GAPA.\n","authors":["Yinghui Li","Shulin Huang","Xinwei Zhang","Qingyu Zhou","Yangning Li","Ruiyang Liu","Yunbo Cao","Hai-Tao Zheng","Ying Shen"],"pdf_url":"https://arxiv.org/pdf/2207.08087v4.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2303.04797v1","updated":"2023-03-08T18:45:22Z","published":"2023-03-08T18:45:22Z","title":"Automatic Debiased Learning from Positive, Unlabeled, and Exposure Data","summary":"  We address the issue of binary classification from positive and unlabeled\ndata (PU classification) with a selection bias in the positive data. During the\nobservation process, (i) a sample is exposed to a user, (ii) the user then\nreturns the label for the exposed sample, and (iii) we however can only observe\nthe positive samples. Therefore, the positive labels that we observe are a\ncombination of both the exposure and the labeling, which creates a selection\nbias problem for the observed positive samples. This scenario represents a\nconceptual framework for many practical applications, such as recommender\nsystems, which we refer to as ``learning from positive, unlabeled, and exposure\ndata'' (PUE classification). To tackle this problem, we initially assume access\nto data with exposure labels. Then, we propose a method to identify the\nfunction of interest using a strong ignorability assumption and develop an\n``Automatic Debiased PUE'' (ADPUE) learning method. This algorithm directly\ndebiases the selection bias without requiring intermediate estimates, such as\nthe propensity score, which is necessary for other learning methods. Through\nexperiments, we demonstrate that our approach outperforms traditional PU\nlearning methods on various semi-synthetic datasets.\n","authors":["Masahiro Kato","Shuting Wu","Kodai Kureishi","Shota Yasui"],"pdf_url":"https://arxiv.org/pdf/2303.04797v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.05628v2","updated":"2023-03-08T18:45:17Z","published":"2022-05-11T16:54:37Z","title":"Extensible Machine Learning for Encrypted Network Traffic Application\n  Labeling via Uncertainty Quantification","summary":"  With the increasing prevalence of encrypted network traffic, cyber security\nanalysts have been turning to machine learning (ML) techniques to elucidate the\ntraffic on their networks. However, ML models can become stale as new traffic\nemerges that is outside of the distribution of the training set. In order to\nreliably adapt in this dynamic environment, ML models must additionally provide\ncontextualized uncertainty quantification to their predictions, which has\nreceived little attention in the cyber security domain. Uncertainty\nquantification is necessary both to signal when the model is uncertain about\nwhich class to choose in its label assignment and when the traffic is not\nlikely to belong to any pre-trained classes.\n  We present a new, public dataset of network traffic that includes labeled,\nVirtual Private Network (VPN)-encrypted network traffic generated by 10\napplications and corresponding to 5 application categories. We also present an\nML framework that is designed to rapidly train with modest data requirements\nand provide both calibrated, predictive probabilities as well as an\ninterpretable \"out-of-distribution\" (OOD) score to flag novel traffic samples.\nWe describe calibrating OOD scores using p-values of the relative Mahalanobis\ndistance.\n  We demonstrate that our framework achieves an F1 score of 0.98 on our dataset\nand that it can extend to an enterprise network by testing the model: (1) on\ndata from similar applications, (2) on dissimilar application traffic from an\nexisting category, and (3) on application traffic from a new category. The\nmodel correctly flags uncertain traffic and, upon retraining, accurately\nincorporates the new data.\n","authors":["Steven Jorgensen","John Holodnak","Jensen Dempsey","Karla de Souza","Ananditha Raghunath","Vernon Rivet","Noah DeMoes","Andrés Alejos","Allan Wollaber"],"pdf_url":"https://arxiv.org/pdf/2205.05628v2.pdf","comment":"Paper is 15 pages and has 10 figures. Published in IEEE Transactions\n  on Artificial Intelligence (https://doi.org/10.1109/TAI.2023.3244168). For\n  associated dataset, see\n  https://www.ll.mit.edu/r-d/datasets/vpnnonvpn-network-application-traffic-dataset-vnat"},{"id":"http://arxiv.org/abs/2303.04791v1","updated":"2023-03-08T18:41:27Z","published":"2023-03-08T18:41:27Z","title":"Ewald-based Long-Range Message Passing for Molecular Graphs","summary":"  Neural architectures that learn potential energy surfaces from molecular data\nhave undergone fast improvement in recent years. A key driver of this success\nis the Message Passing Neural Network (MPNN) paradigm. Its favorable scaling\nwith system size partly relies upon a spatial distance limit on messages. While\nthis focus on locality is a useful inductive bias, it also impedes the learning\nof long-range interactions such as electrostatics and van der Waals forces. To\naddress this drawback, we propose Ewald message passing: a nonlocal Fourier\nspace scheme which limits interactions via a cutoff on frequency instead of\ndistance, and is theoretically well-founded in the Ewald summation method. It\ncan serve as an augmentation on top of existing MPNN architectures as it is\ncomputationally cheap and agnostic to other architectural details. We test the\napproach with four baseline models and two datasets containing diverse periodic\n(OC20) and aperiodic structures (OE62). We observe robust improvements in\nenergy mean absolute errors across all models and datasets, averaging 10% on\nOC20 and 16% on OE62. Our analysis shows an outsize impact of these\nimprovements on structures with high long-range contributions to the ground\ntruth energy.\n","authors":["Arthur Kosmala","Johannes Gasteiger","Nicholas Gao","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2303.04791v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04788v1","updated":"2023-03-08T18:39:43Z","published":"2023-03-08T18:39:43Z","title":"Enabling Non-Linear Quantum Operations through Variational Quantum\n  Splines","summary":"  The postulates of quantum mechanics impose only unitary transformations on\nquantum states, which is a severe limitation for quantum machine learning\nalgorithms. Quantum Splines (QSplines) have recently been proposed to\napproximate quantum activation functions to introduce non-linearity in quantum\nalgorithms. However, QSplines make use of the HHL as a subroutine and require a\nfault-tolerant quantum computer to be correctly implemented. This work proposes\nthe Generalised QSplines (GQSplines), a novel method for approximating\nnon-linear quantum activation functions using hybrid quantum-classical\ncomputation. The GQSplines overcome the highly demanding requirements of the\noriginal QSplines in terms of quantum hardware and can be implemented using\nnear-term quantum computers. Furthermore, the proposed method relies on a\nflexible problem representation for non-linear approximation and it is suitable\nto be embedded in existing quantum neural network architectures. In addition,\nwe provide a practical implementation of GQSplines using Pennylane and show\nthat our model outperforms the original QSplines in terms of quality of\nfitting.\n","authors":["Matteo Antonio Inajetovic","Filippo Orazi","Antonio Macaluso","Stefano Lodi","Claudio Sartori"],"pdf_url":"https://arxiv.org/pdf/2303.04788v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.12363v2","updated":"2023-03-08T18:27:29Z","published":"2022-06-24T16:25:36Z","title":"From Tensor Network Quantum States to Tensorial Recurrent Neural\n  Networks","summary":"  We show that any matrix product state (MPS) can be exactly represented by a\nrecurrent neural network (RNN) with a linear memory update. We generalize this\nRNN architecture to 2D lattices using a multilinear memory update. It supports\nperfect sampling and wave function evaluation in polynomial time, and can\nrepresent an area law of entanglement entropy. Numerical evidence shows that it\ncan encode the wave function using a bond dimension lower by orders of\nmagnitude when compared to MPS, with an accuracy that can be systematically\nimproved by increasing the bond dimension.\n","authors":["Dian Wu","Riccardo Rossi","Filippo Vicentini","Giuseppe Carleo"],"pdf_url":"https://arxiv.org/pdf/2206.12363v2.pdf","comment":"14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2303.04778v1","updated":"2023-03-08T18:20:56Z","published":"2023-03-08T18:20:56Z","title":"Fourier-MIONet: Fourier-enhanced multiple-input neural operators for\n  multiphase modeling of geological carbon sequestration","summary":"  Geologic Carbon Storage (GCS) is an important technology that aims to reduce\nthe amount of carbon dioxide in the atmosphere. Multiphase flow in porous media\nis essential to understand CO2 migration and pressure fields in the subsurface\nassociated with GCS. However, numerical simulation for such problems in 4D is\ncomputationally challenging and expensive, due to the multiphysics and\nmultiscale nature of the highly nonlinear governing partial differential\nequations (PDEs). It prevents us from considering multiple subsurface scenarios\nand conducting real-time optimization. Here, we develop a Fourier-enhanced\nmultiple-input neural operator (Fourier-MIONet) to learn the solution operator\nof the problem of multiphase flow in porous media. Fourier-MIONet utilizes the\nrecently developed framework of the multiple-input deep neural operators\n(MIONet) and incorporates the Fourier neural operator (FNO) in the network\narchitecture. Once Fourier-MIONet is trained, it can predict the evolution of\nsaturation and pressure of the multiphase flow under various reservoir\nconditions, such as permeability and porosity heterogeneity, anisotropy,\ninjection configurations, and multiphase flow properties. Compared to the\nenhanced FNO (U-FNO), the proposed Fourier-MIONet has 90% fewer unknown\nparameters, and it can be trained in significantly less time (about 3.5 times\nfaster) with much lower CPU memory (< 15%) and GPU memory (< 35%) requirements,\nto achieve similar prediction accuracy. In addition to the lower computational\ncost, Fourier-MIONet can be trained with only 6 snapshots of time to predict\nthe PDE solutions for 30 years. The excellent generalizability of\nFourier-MIONet is enabled by its adherence to the physical principle that the\nsolution to a PDE is continuous over time.\n","authors":["Zhongyi Jiang","Min Zhu","Dongzhuo Li","Qiuzi Li","Yanhua O. Yuan","Lu Lu"],"pdf_url":"https://arxiv.org/pdf/2303.04778v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04777v1","updated":"2023-03-08T18:20:06Z","published":"2023-03-08T18:20:06Z","title":"LMI-based Data-Driven Robust Model Predictive Control","summary":"  Predictive control, which is based on a model of the system to compute the\napplied input optimizing the future system behavior, is by now widely used. If\nthe nominal models are not given or are very uncertain, data-driven model\npredictive control approaches can be employed, where the system model or input\nis directly obtained from past measured trajectories. Using a data\ninformativity framework and Finsler's lemma, we propose a data-driven robust\nlinear matrix inequality-based model predictive control scheme that considers\ninput and state constraints. Using these data, we formulate the problem as a\nsemi-definite optimization problem, whose solution provides the matrix gain for\nthe linear feedback, while the decisive variables are independent of the length\nof the measurement data. The designed controller stabilizes the closed-loop\nsystem asymptotically and guarantees constraint satisfaction. Numerical\nexamples are conducted to illustrate the method.\n","authors":["Hoang Hai Nguyen","Maurice Friedel","Rolf Findeisen"],"pdf_url":"https://arxiv.org/pdf/2303.04777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04772v1","updated":"2023-03-08T18:10:10Z","published":"2023-03-08T18:10:10Z","title":"Multilevel Diffusion: Infinite Dimensional Score-Based Diffusion Models\n  for Image Generation","summary":"  Score-based diffusion models (SBDM) have recently emerged as state-of-the-art\napproaches for image generation. Existing SBDMs are typically formulated in a\nfinite-dimensional setting, where images are considered as tensors of a finite\nsize. This papers develops SBDMs in the infinite-dimensional setting, that is,\nwe model the training data as functions supported on a rectangular domain.\nBesides the quest for generating images at ever higher resolution our primary\nmotivation is to create a well-posed infinite-dimensional learning problem so\nthat we can discretize it consistently on multiple resolution levels. We\nthereby hope to obtain diffusion models that generalize across different\nresolution levels and improve the efficiency of the training process. We\ndemonstrate how to overcome two shortcomings of current SBDM approaches in the\ninfinite-dimensional setting. First, we modify the forward process to ensure\nthat the latent distribution is well-defined in the infinite-dimensional\nsetting using the notion of trace class operators. Second, we illustrate that\napproximating the score function with an operator network, in our case Fourier\nneural operators (FNOs), is beneficial for multilevel training. After deriving\nthe forward and reverse process in the infinite-dimensional setting, we show\ntheir well-posedness, derive adequate discretizations, and investigate the role\nof the latent distributions. We provide first promising numerical results on\ntwo datasets, MNIST and material structures. In particular, we show that\nmultilevel training is feasible within this framework.\n","authors":["Paul Hagemann","Lars Ruthotto","Gabriele Steidl","Nicole Tianjiao Yang"],"pdf_url":"https://arxiv.org/pdf/2303.04772v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04766v1","updated":"2023-03-08T18:03:51Z","published":"2023-03-08T18:03:51Z","title":"FastFill: Efficient Compatible Model Update","summary":"  In many retrieval systems the original high dimensional data (e.g., images)\nis mapped to a lower dimensional feature through a learned embedding model. The\ntask of retrieving the most similar data from a gallery set to a given query\ndata is performed through a similarity comparison on features. When the\nembedding model is updated, it might produce features that are not\ncomparable/compatible with features already in the gallery computed with the\nold model. Subsequently, all features in the gallery need to be re-computed\nusing the new embedding model -- a computationally expensive process called\nbackfilling. Recently, compatible representation learning methods have been\nproposed to avoid backfilling. Despite their relative success, there is an\ninherent trade-off between the new model performance and its compatibility with\nthe old model. In this work, we introduce FastFill: a compatible model update\nprocess using feature alignment and policy based partial backfilling to\npromptly elevate retrieval performance. We show that previous backfilling\nstrategies suffer from decreased performance and demonstrate the importance of\nboth the training objective and the ordering in online partial backfilling. We\npropose a new training method for feature alignment between old and new\nembedding models using uncertainty estimation. Compared to previous works, we\nobtain significantly improved backfilling results on a variety of datasets: mAP\non ImageNet (+4.4\\%), Places-365 (+2.7\\%), and VGG-Face2 (+1.3\\%). Further, we\ndemonstrate that when updating a biased model with FastFill, the minority\nsubgroup accuracy gap promptly vanishes with a small fraction of partial\nbackfilling.\n","authors":["Florian Jaeckle","Fartash Faghri","Ali Farhadi","Oncel Tuzel","Hadi Pouransari"],"pdf_url":"https://arxiv.org/pdf/2303.04766v1.pdf","comment":"To appear in The Eleventh International Conference on Learning\n  Representations"},{"id":"http://arxiv.org/abs/2303.04759v1","updated":"2023-03-08T17:51:13Z","published":"2023-03-08T17:51:13Z","title":"RAF: Holistic Compilation for Deep Learning Model Training","summary":"  As deep learning is pervasive in modern applications, many deep learning\nframeworks are presented for deep learning practitioners to develop and train\nDNN models rapidly. Meanwhile, as training large deep learning models becomes a\ntrend in recent years, the training throughput and memory footprint are getting\ncrucial. Accordingly, optimizing training workloads with compiler optimizations\nis inevitable and getting more and more attentions. However, existing deep\nlearning compilers (DLCs) mainly target inference and do not incorporate\nholistic optimizations, such as automatic differentiation and automatic mixed\nprecision, in training workloads.\n  In this paper, we present RAF, a deep learning compiler for training. Unlike\nexisting DLCs, RAF accepts a forward model and in-house generates a training\ngraph. Accordingly, RAF is able to systematically consolidate graph\noptimizations for performance, memory and distributed training. In addition, to\ncatch up to the state-of-the-art performance with hand-crafted kernel libraries\nas well as tensor compilers, RAF proposes an operator dialect mechanism to\nseamlessly integrate all possible kernel implementations. We demonstrate that\nby in-house training graph generation and operator dialect mechanism, we are\nable to perform holistic optimizations and achieve either better training\nthroughput or larger batch size against PyTorch (eager and torchscript mode),\nXLA, and DeepSpeed for popular transformer models on GPUs.\n","authors":["Cody Hao Yu","Haozheng Fan","Guangtai Huang","Zhen Jia","Yizhi Liu","Jie Wang","Zach Zheng","Yuan Zhou","Haichen Shen","Junru Shao","Mu Li","Yida Wang"],"pdf_url":"https://arxiv.org/pdf/2303.04759v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02736v3","updated":"2023-03-08T17:46:27Z","published":"2022-11-04T20:22:58Z","title":"Discovering Closed-Loop Failures of Vision-Based Controllers via\n  Reachability Analysis","summary":"  Machine learning driven image-based controllers allow robotic systems to take\nintelligent actions based on the visual feedback from their environment.\nUnderstanding when these controllers might lead to system safety violations is\nimportant for their integration in safety-critical applications and engineering\ncorrective safety measures for the system. Existing methods leverage\nsimulation-based testing (or falsification) to find the failures of\nvision-based controllers, i.e., the visual inputs that lead to closed-loop\nsafety violations. However, these techniques do not scale well to the scenarios\ninvolving high-dimensional and complex visual inputs, such as RGB images. In\nthis work, we cast the problem of finding closed-loop vision failures as a\nHamilton-Jacobi (HJ) reachability problem. Our approach blends simulation-based\nanalysis with HJ reachability methods to compute an approximation of the\nbackward reachable tube (BRT) of the system, i.e., the set of unsafe states for\nthe system under vision-based controllers. Utilizing the BRT, we can tractably\nand systematically find the system states and corresponding visual inputs that\nlead to closed-loop failures. These visual inputs can be subsequently analyzed\nto find the input characteristics that might have caused the failure. Besides\nits scalability to high-dimensional visual inputs, an explicit computation of\nBRT allows the proposed approach to capture non-trivial system failures that\nare difficult to expose via random simulations. We demonstrate our framework on\ntwo case studies involving an RGB image-based neural network controller for (a)\nautonomous indoor navigation, and (b) autonomous aircraft taxiing.\n","authors":["Kaustav Chakraborty","Somil Bansal"],"pdf_url":"https://arxiv.org/pdf/2211.02736v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04756v1","updated":"2023-03-08T17:45:48Z","published":"2023-03-08T17:45:48Z","title":"Meta-learning Control Variates: Variance Reduction with Limited Data","summary":"  Control variates can be a powerful tool to reduce the variance of Monte Carlo\nestimators, but constructing effective control variates can be challenging when\nthe number of samples is small. In this paper, we show that when a large number\nof related integrals need to be computed, it is possible to leverage the\nsimilarity between these integration tasks to improve performance even when the\nnumber of samples per task is very small. Our approach, called meta learning\nCVs (Meta-CVs), can be used for up to hundreds or thousands of tasks. Our\nempirical assessment indicates that Meta-CVs can lead to significant variance\nreduction in such settings, and our theoretical analysis establishes general\nconditions under which Meta-CVs can be successfully trained.\n","authors":["Zhuo Sun","Chris J. Oates","François-Xavier Briol"],"pdf_url":"https://arxiv.org/pdf/2303.04756v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2011.08485v5","updated":"2023-03-08T17:37:32Z","published":"2020-11-17T07:42:27Z","title":"Probing Predictions on OOD Images via Nearest Categories","summary":"  We study out-of-distribution (OOD) prediction behavior of neural networks\nwhen they classify images from unseen classes or corrupted images. To probe the\nOOD behavior, we introduce a new measure, nearest category generalization\n(NCG), where we compute the fraction of OOD inputs that are classified with the\nsame label as their nearest neighbor in the training set. Our motivation stems\nfrom understanding the prediction patterns of adversarially robust networks,\nsince previous work has identified unexpected consequences of training to be\nrobust to norm-bounded perturbations. We find that robust networks have\nconsistently higher NCG accuracy than natural training, even when the OOD data\nis much farther away than the robustness radius. This implies that the local\nregularization of robust training has a significant impact on the network's\ndecision regions. We replicate our findings using many datasets, comparing new\nand existing training methods. Overall, adversarially robust networks resemble\na nearest neighbor classifier when it comes to OOD data. Code available at\nhttps://github.com/yangarbiter/nearest-category-generalization.\n","authors":["Yao-Yuan Yang","Cyrus Rashtchian","Ruslan Salakhutdinov","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2011.08485v5.pdf","comment":"Accepted by Transactions on Machine Learning Research"},{"id":"http://arxiv.org/abs/2303.04745v1","updated":"2023-03-08T17:28:54Z","published":"2023-03-08T17:28:54Z","title":"A General Theory of Correct, Incorrect, and Extrinsic Equivariance","summary":"  Although equivariant machine learning has proven effective at many tasks,\nsuccess depends heavily on the assumption that the ground truth function is\nsymmetric over the entire domain matching the symmetry in an equivariant neural\nnetwork. A missing piece in the equivariant learning literature is the analysis\nof equivariant networks when symmetry exists only partially in the domain. In\nthis work, we present a general theory for such a situation. We propose\npointwise definitions of correct, incorrect, and extrinsic equivariance, which\nallow us to quantify continuously the degree of each type of equivariance a\nfunction displays. We then study the impact of various degrees of incorrect or\nextrinsic symmetry on model error. We prove error lower bounds for invariant or\nequivariant networks in classification or regression settings with partially\nincorrect symmetry. We also analyze the potentially harmful effects of\nextrinsic equivariance. Experiments validate these results in three different\nenvironments.\n","authors":["Dian Wang","Xupeng Zhu","Jung Yeon Park","Robert Platt","Robin Walters"],"pdf_url":"https://arxiv.org/pdf/2303.04745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04743v1","updated":"2023-03-08T17:27:39Z","published":"2023-03-08T17:27:39Z","title":"Vector Quantized Time Series Generation with a Bidirectional Prior Model","summary":"  Time series generation (TSG) studies have mainly focused on the use of\nGenerative Adversarial Networks (GANs) combined with recurrent neural network\n(RNN) variants. However, the fundamental limitations and challenges of training\nGANs still remain. In addition, the RNN-family typically has difficulties with\ntemporal consistency between distant timesteps. Motivated by the successes in\nthe image generation (IMG) domain, we propose TimeVQVAE, the first work, to our\nknowledge, that uses vector quantization (VQ) techniques to address the TSG\nproblem. Moreover, the priors of the discrete latent spaces are learned with\nbidirectional transformer models that can better capture global temporal\nconsistency. We also propose VQ modeling in a time-frequency domain, separated\ninto low-frequency (LF) and high-frequency (HF). This allows us to retain\nimportant characteristics of the time series and, in turn, generate new\nsynthetic signals that are of better quality, with sharper changes in\nmodularity, than its competing TSG methods. Our experimental evaluation is\nconducted on all datasets from the UCR archive, using well-established metrics\nin the IMG literature, such as Fr\\'echet inception distance and inception\nscores. Our implementation on GitHub:\n\\url{https://github.com/ML4ITS/TimeVQVAE}.\n","authors":["Daesoo Lee","Sara Malacarne","Erlend Aune"],"pdf_url":"https://arxiv.org/pdf/2303.04743v1.pdf","comment":"accepted at AISTATS 2023"},{"id":"http://arxiv.org/abs/2303.04739v1","updated":"2023-03-08T17:23:39Z","published":"2023-03-08T17:23:39Z","title":"Advancing Direct Convolution using Convolution Slicing Optimization and\n  ISA Extensions","summary":"  Convolution is one of the most computationally intensive operations that must\nbe performed for machine-learning model inference. A traditional approach to\ncompute convolutions is known as the Im2Col + BLAS method. This paper proposes\nSConv: a direct-convolution algorithm based on a MLIR/LLVM code-generation\ntoolchain that can be integrated into machine-learning compilers . This\nalgorithm introduces: (a) Convolution Slicing Analysis (CSA) - a\nconvolution-specific 3D cache-blocking analysis pass that focuses on tile reuse\nover the cache hierarchy; (b) Convolution Slicing Optimization (CSO) - a\ncode-generation pass that uses CSA to generate a tiled direct-convolution\nmacro-kernel; and (c) Vector-Based Packing (VBP) - an architecture-specific\noptimized input-tensor packing solution based on vector-register shift\ninstructions for convolutions with unitary stride. Experiments conducted on 393\nconvolutions from full ONNX-MLIR machine-learning models indicate that the\nelimination of the Im2Col transformation and the use of fast packing routines\nresult in a total packing time reduction, on full model inference, of 2.0x -\n3.9x on Intel x86 and 3.6x - 7.2x on IBM POWER10. The speed-up over an Im2Col +\nBLAS method based on current BLAS implementations for end-to-end\nmachine-learning model inference is in the range of 9% - 25% for Intel x86 and\n10% - 42% for IBM POWER10 architectures. The total convolution speedup for\nmodel inference is 12% - 27% on Intel x86 and 26% - 46% on IBM POWER10. SConv\nalso outperforms BLAS GEMM, when computing pointwise convolutions, in more than\n83% of the 219 tested instances.\n","authors":["Victor Ferrari","Rafael Sousa","Marcio Pereira","João P. L. de Carvalho","José Nelson Amaral","José Moreira","Guido Araujo"],"pdf_url":"https://arxiv.org/pdf/2303.04739v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2207.06940v2","updated":"2023-03-08T17:21:55Z","published":"2022-07-14T14:06:15Z","title":"PASHA: Efficient HPO and NAS with Progressive Resource Allocation","summary":"  Hyperparameter optimization (HPO) and neural architecture search (NAS) are\nmethods of choice to obtain the best-in-class machine learning models, but in\npractice they can be costly to run. When models are trained on large datasets,\ntuning them with HPO or NAS rapidly becomes prohibitively expensive for\npractitioners, even when efficient multi-fidelity methods are employed. We\npropose an approach to tackle the challenge of tuning machine learning models\ntrained on large datasets with limited computational resources. Our approach,\nnamed PASHA, extends ASHA and is able to dynamically allocate maximum resources\nfor the tuning procedure depending on the need. The experimental comparison\nshows that PASHA identifies well-performing hyperparameter configurations and\narchitectures while consuming significantly fewer computational resources than\nASHA.\n","authors":["Ondrej Bohdal","Lukas Balles","Martin Wistuba","Beyza Ermis","Cédric Archambeau","Giovanni Zappella"],"pdf_url":"https://arxiv.org/pdf/2207.06940v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.08347v2","updated":"2023-03-08T17:17:24Z","published":"2023-02-16T15:05:37Z","title":"The autoregressive neural network architecture of the Boltzmann\n  distribution of pairwise interacting spins systems","summary":"  Generative Autoregressive Neural Networks (ARNN) have recently demonstrated\nexceptional results in image and language generation tasks, contributing to the\ngrowing popularity of generative models in both scientific and commercial\napplications. This work presents a physical interpretation of the ARNNs by\nreformulating the Boltzmann distribution of binary pairwise interacting systems\ninto autoregressive form. The resulting ARNN architecture has weights and\nbiases of its first layer corresponding to the Hamiltonian's couplings and\nexternal fields, featuring widely used structures like the residual connections\nand a recurrent architecture with clear physical meanings. However, the\nexponential growth, with system size, of the number of parameters of the hidden\nlayers makes its direct application unfeasible. Nevertheless, its\narchitecture's explicit formulation allows using statistical physics techniques\nto derive new ARNNs for specific systems. As examples, new effective ARNN\narchitectures are derived from two well-known mean-field systems, the\nCurie-Weiss and Sherrington-Kirkpatrick models, showing superior performances\nin approximating the Boltzmann distributions of the corresponding physics model\ncompared to other commonly used ARNN architectures. The connection established\nbetween the physics of the system and the ARNN architecture provides a way to\nderive new neural network architectures for different interacting systems and\ninterpret existing ones from a physical perspective.\n","authors":["Indaco Biazzo"],"pdf_url":"https://arxiv.org/pdf/2302.08347v2.pdf","comment":"10 pages, 6 figure plus the Supplementary Information"},{"id":"http://arxiv.org/abs/2303.04729v1","updated":"2023-03-08T17:15:58Z","published":"2023-03-08T17:15:58Z","title":"On the Risks of Stealing the Decoding Algorithms of Language Models","summary":"  A key component of generating text from modern language models (LM) is the\nselection and tuning of decoding algorithms. These algorithms determine how to\ngenerate text from the internal probability distribution generated by the LM.\nThe process of choosing a decoding algorithm and tuning its hyperparameters\ntakes significant time, manual effort, and computation, and it also requires\nextensive human evaluation. Therefore, the identity and hyperparameters of such\ndecoding algorithms are considered to be extremely valuable to their owners. In\nthis work, we show, for the first time, that an adversary with typical API\naccess to an LM can steal the type and hyperparameters of its decoding\nalgorithms at very low monetary costs. Our attack is effective against popular\nLMs used in text generation APIs, including GPT-2 and GPT-3. We demonstrate the\nfeasibility of stealing such information with only a few dollars, e.g.,\n$\\$0.8$, $\\$1$, $\\$4$, and $\\$40$ for the four versions of GPT-3.\n","authors":["Ali Naseh","Kalpesh Krishna","Mohit Iyyer","Amir Houmansadr"],"pdf_url":"https://arxiv.org/pdf/2303.04729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04725v1","updated":"2023-03-08T17:14:57Z","published":"2023-03-08T17:14:57Z","title":"Model Predictive Control with Gaussian-Process-Supported Dynamical\n  Constraints for Autonomous Vehicles","summary":"  We propose a model predictive control approach for autonomous vehicles that\nexploits learned Gaussian processes for predicting human driving behavior. The\nproposed approach employs the uncertainty about the GP's prediction to achieve\nsafety. A multi-mode predictive control approach considers the possible\nintentions of the human drivers. While the intentions are represented by\ndifferent Gaussian processes, their probabilities foreseen in the observed\nbehaviors are determined by a suitable online classification. Intentions below\na certain probability threshold are neglected to improve performance. The\nproposed multi-mode model predictive control approach with Gaussian process\nregression support enables repeated feasibility and probabilistic constraint\nsatisfaction with high probability. The approach is underlined in simulation,\nconsidering real-world measurements for training the Gaussian processes.\n","authors":["Johanna Bethge","Maik Pfefferkorn","Alexander Rose","Jan Peters","Rolf Findeisen"],"pdf_url":"https://arxiv.org/pdf/2303.04725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04721v1","updated":"2023-03-08T17:07:09Z","published":"2023-03-08T17:07:09Z","title":"Fast offset corrected in-memory training","summary":"  In-memory computing with resistive crossbar arrays has been suggested to\naccelerate deep-learning workloads in highly efficient manner. To unleash the\nfull potential of in-memory computing, it is desirable to accelerate the\ntraining as well as inference for large deep neural networks (DNNs). In the\npast, specialized in-memory training algorithms have been proposed that not\nonly accelerate the forward and backward passes, but also establish tricks to\nupdate the weight in-memory and in parallel. However, the state-of-the-art\nalgorithm (Tiki-Taka version 2 (TTv2)) still requires near perfect offset\ncorrection and suffers from potential biases that might occur due to\nprogramming and estimation inaccuracies, as well as longer-term instabilities\nof the device materials. Here we propose and describe two new and improved\nalgorithms for in-memory computing (Chopped-TTv2 (c-TTv2) and Analog Gradient\nAccumulation with Dynamic reference (AGAD)), that retain the same runtime\ncomplexity but correct for any remaining offsets using choppers. These\nalgorithms greatly relax the device requirements and thus expanding the scope\nof possible materials potentially employed for such fast in-memory DNN\ntraining.\n","authors":["Malte J. Rasch","Fabio Carta","Omebayode Fagbohungbe","Tayfun Gokmen"],"pdf_url":"https://arxiv.org/pdf/2303.04721v1.pdf","comment":"14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2206.05077v3","updated":"2023-03-08T16:52:48Z","published":"2022-06-10T13:18:26Z","title":"Tensor Train for Global Optimization Problems in Robotics","summary":"  The convergence of many numerical optimization techniques is highly dependent\non the initial guess given to the solver. To address this issue, we propose a\nnovel approach that utilizes tensor methods to initialize existing optimization\nsolvers near global optima. Our method does not require access to a database of\ngood solutions. We first transform the cost function, which depends on both\ntask parameters and optimization variables, into a probability density\nfunction. The joint probability distribution of the task parameters and\noptimization variables is approximated using the Tensor Train model which\nenables efficient conditioning and sampling. Unlike existing methods, we treat\nthe task parameters as random variables and for a given task we generate\nsamples for decision variables from the conditional distribution to initialize\nthe optimization solver. Our method can produce multiple solutions for a given\ntask from different modes when they exist. We first evaluate the approach on\nbenchmark functions for numerical optimization that are hard to solve using\ngradient-based optimization solvers with a naive initialization. The results\nshow that the proposed method can generate samples close to global optima and\nfrom multiple modes. We then demonstrate the generality and relevance of our\nframework to robotics by applying it to inverse kinematics with obstacles and\nmotion planning problems with a 7-DoF manipulator.\n","authors":["Suhan Shetty","Teguh Lembono","Tobias Loew","Sylvain Calinon"],"pdf_url":"https://arxiv.org/pdf/2206.05077v3.pdf","comment":"26 pages, 21 figures"},{"id":"http://arxiv.org/abs/2303.04696v1","updated":"2023-03-08T16:35:47Z","published":"2023-03-08T16:35:47Z","title":"VOLTA: an Environment-Aware Contrastive Cell Representation Learning for\n  Histopathology","summary":"  In clinical practice, many diagnosis tasks rely on the identification of\ncells in histopathology images. While supervised machine learning techniques\nrequire labels, providing manual cell annotations is time-consuming due to the\nlarge number of cells. In this paper, we propose a self-supervised framework\n(VOLTA) for cell representation learning in histopathology images using a novel\ntechnique that accounts for the cell's mutual relationship with its environment\nfor improved cell representations. We subjected our model to extensive\nexperiments on the data collected from multiple institutions around the world\ncomprising of over 700,000 cells, four cancer types, and cell types ranging\nfrom three to six categories for each dataset. The results show that our model\noutperforms the state-of-the-art models in cell representation learning. To\nshowcase the potential power of our proposed framework, we applied VOLTA to\novarian and endometrial cancers with very small sample sizes (10-20 samples)\nand demonstrated that our cell representations can be utilized to identify the\nknown histotypes of ovarian cancer and provide novel insights that link\nhistopathology and molecular subtypes of endometrial cancer. Unlike supervised\ndeep learning models that require large sample sizes for training, we provide a\nframework that can empower new discoveries without any annotation data in\nsituations where sample sizes are limited.\n","authors":["Ramin Nakhli","Allen Zhang","Hossein Farahani","Amirali Darbandsari","Elahe Shenasa","Sidney Thiessen","Katy Milne","Jessica McAlpine","Brad Nelson","C Blake Gilks","Ali Bashashati"],"pdf_url":"https://arxiv.org/pdf/2303.04696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04693v1","updated":"2023-03-08T16:34:12Z","published":"2023-03-08T16:34:12Z","title":"A path in regression Random Forest looking for spatial dependence: a\n  taxonomy and a systematic review","summary":"  Random Forest (RF) is a well-known data-driven algorithm applied in several\nfields thanks to its flexibility in modeling the relationship between the\nresponse variable and the predictors, also in case of strong non-linearities.\nIn environmental applications, it often occurs that the phenomenon of interest\nmay present spatial and/or temporal dependence that is not taken explicitly\ninto account by RF in its standard version. In this work, we propose a taxonomy\nto classify strategies according to when (Pre-, In- and/or Post-processing)\nthey try to include the spatial information into regression RF. Moreover, we\nprovide a systematic review and classify the most recent strategies adopted to\n\"adjust\" regression RF to spatially dependent data, based on the criteria\nprovided by the Preferred Reporting Items for Systematic reviews and\nMeta-Analysis (PRISMA). The latter consists of a reproducible methodology for\ncollecting and processing existing literature on a specified topic from\ndifferent sources. PRISMA starts with a query and ends with a set of scientific\ndocuments to review: we performed an online query on the 25$^{th}$ October 2022\nand, in the end, 32 documents were considered for review. The employed\nmethodological strategies and the application fields considered in the 32\nscientific documents are described and discussed.\n","authors":["Luca Patelli","Michela Cameletti","Natalia Golini","Rosaria Ignaccolo"],"pdf_url":"https://arxiv.org/pdf/2303.04693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.13545v4","updated":"2023-03-08T16:33:15Z","published":"2022-07-27T14:36:35Z","title":"Learning Hyper Label Model for Programmatic Weak Supervision","summary":"  To reduce the human annotation efforts, the programmatic weak supervision\n(PWS) paradigm abstracts weak supervision sources as labeling functions (LFs)\nand involves a label model to aggregate the output of multiple LFs to produce\ntraining labels. Most existing label models require a parameter learning step\nfor each dataset. In this work, we present a hyper label model that (once\nlearned) infers the ground-truth labels for each dataset in a single forward\npass without dataset-specific parameter learning. The hyper label model\napproximates an optimal analytical (yet computationally intractable) solution\nof the ground-truth labels. We train the model on synthetic data generated in\nthe way that ensures the model approximates the analytical optimal solution,\nand build the model upon Graph Neural Network (GNN) to ensure the model\nprediction being invariant (or equivariant) to the permutation of LFs (or data\npoints). On 14 real-world datasets, our hyper label model outperforms the best\nexisting methods in both accuracy (by 1.4 points on average) and efficiency (by\nsix times on average). Our code is available at\nhttps://github.com/wurenzhi/hyper_label_model\n","authors":["Renzhi Wu","Shen-En Chen","Jieyu Zhang","Xu Chu"],"pdf_url":"https://arxiv.org/pdf/2207.13545v4.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.04676v1","updated":"2023-03-08T15:56:27Z","published":"2023-03-08T15:56:27Z","title":"Considerations on the Theory of Training Models with Differential\n  Privacy","summary":"  In federated learning collaborative learning takes place by a set of clients\nwho each want to remain in control of how their local training data is used, in\nparticular, how can each client's local training data remain private?\nDifferential privacy is one method to limit privacy leakage. We provide a\ngeneral overview of its framework and provable properties, adopt the more\nrecent hypothesis based definition called Gaussian DP or $f$-DP, and discuss\nDifferentially Private Stochastic Gradient Descent (DP-SGD). We stay at a meta\nlevel and attempt intuitive explanations and insights \\textit{in this book\nchapter}.\n","authors":["Marten van Dijk","Phuong Ha Nguyen"],"pdf_url":"https://arxiv.org/pdf/2303.04676v1.pdf","comment":"18 pages, a book chapter. arXiv admin note: text overlap with\n  arXiv:2212.05796"},{"id":"http://arxiv.org/abs/2303.04673v1","updated":"2023-03-08T15:52:14Z","published":"2023-03-08T15:52:14Z","title":"Cost-Effective Hyperparameter Optimization for Large Language Model\n  Generation Inference","summary":"  Large Language Models (LLMs) like GPT-3 have sparked significant interest in\ntheir generative capabilities, leading to the development of various commercial\napplications. The high cost of using the models drives application builders to\nmaximize the value of generation under a limited inference budget. This paper\npresents a study of optimizing inference hyperparameters like the number of\nresponses, temperature and max tokens, which significantly affects the\nutility/cost of text generation. We design a framework named EcoOptiGen which\nleverages economical hyperparameter optimization and cost-based pruning.\nExperiments with the latest GPT-3.5 models on a variety of tasks verify its\neffectiveness. EcoOptiGen is implemented in the FLAML library:\nhttps://github.com/microsoft/FLAML, and we provide one example of using it at:\nhttps://microsoft.github.io/FLAML/docs/Examples/Integrate%20-%20OpenAI.\n","authors":["Chi Wang","Susan Xueqing Liu","Ahmed H. Awadallah"],"pdf_url":"https://arxiv.org/pdf/2303.04673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00631v2","updated":"2023-03-08T15:36:57Z","published":"2023-01-02T12:49:48Z","title":"Stochastic Variable Metric Proximal Gradient with variance reduction for\n  non-convex composite optimization","summary":"  This paper introduces a novel algorithm, the Perturbed Proximal\nPreconditioned SPIDER algorithm (3P-SPIDER), designed to solve finite sum\nnon-convex composite optimization. It is a stochastic Variable Metric\nForward-Backward algorithm, which allows approximate preconditioned forward\noperator and uses a variable metric proximity operator as the backward\noperator; it also proposes a mini-batch strategy with variance reduction to\naddress the finite sum setting. We show that 3P-SPIDER extends some Stochastic\npreconditioned Gradient Descent-based algorithms and some Incremental\nExpectation Maximization algorithms to composite optimization and to the case\nthe forward operator can not be computed in closed form. We also provide an\nexplicit control of convergence in expectation of 3P-SPIDER, and study its\ncomplexity in order to satisfy the epsilon-approximate stationary condition.\nOur results are the first to combine the composite non-convex optimization\nsetting, a variance reduction technique to tackle the finite sum setting by\nusing a minibatch strategy and, to allow deterministic or random approximations\nof the preconditioned forward operator. Finally, through an application to\ninference in a logistic regression model with random effects, we numerically\ncompare 3P-SPIDER to other stochastic forward-backward algorithms and discuss\nthe role of some design parameters of 3P-SPIDER.\n","authors":["Gersende Fort","Eric Moulines"],"pdf_url":"https://arxiv.org/pdf/2301.00631v2.pdf","comment":"Statistics and Computing, In press"},{"id":"http://arxiv.org/abs/2303.04660v1","updated":"2023-03-08T15:27:29Z","published":"2023-03-08T15:27:29Z","title":"Neural Probabilistic Logic Programming in Discrete-Continuous Domains","summary":"  Neural-symbolic AI (NeSy) allows neural networks to exploit symbolic\nbackground knowledge in the form of logic. It has been shown to aid learning in\nthe limited data regime and to facilitate inference on out-of-distribution\ndata. Probabilistic NeSy focuses on integrating neural networks with both logic\nand probability theory, which additionally allows learning under uncertainty. A\nmajor limitation of current probabilistic NeSy systems, such as DeepProbLog, is\ntheir restriction to finite probability distributions, i.e., discrete random\nvariables. In contrast, deep probabilistic programming (DPP) excels in\nmodelling and optimising continuous probability distributions. Hence, we\nintroduce DeepSeaProbLog, a neural probabilistic logic programming language\nthat incorporates DPP techniques into NeSy. Doing so results in the support of\ninference and learning of both discrete and continuous probability\ndistributions under logical constraints. Our main contributions are 1) the\nsemantics of DeepSeaProbLog and its corresponding inference algorithm, 2) a\nproven asymptotically unbiased learning algorithm, and 3) a series of\nexperiments that illustrate the versatility of our approach.\n","authors":["Lennert De Smet","Pedro Zuidberg Dos Martires","Robin Manhaeve","Giuseppe Marra","Angelika Kimmig","Luc De Readt"],"pdf_url":"https://arxiv.org/pdf/2303.04660v1.pdf","comment":"27 pages, 9 figures"},{"id":"http://arxiv.org/abs/2108.12992v2","updated":"2023-03-08T15:25:18Z","published":"2021-08-30T05:07:59Z","title":"SHIFT15M: Fashion-specific dataset for set-to-set matching with several\n  distribution shifts","summary":"  This paper addresses the problem of set-to-set matching, which involves\nmatching two different sets of items based on some criteria, especially in the\ncase of high-dimensional items like images. Although neural networks have been\napplied to solve this problem, most machine learning-based approaches assume\nthat the training and test data follow the same distribution, which is not\nalways true in real-world scenarios. To address this limitation, we introduce\nSHIFT15M, a dataset that can be used to evaluate set-to-set matching models\nwhen the distribution of data changes between training and testing. We conduct\nbenchmark experiments that demonstrate the performance drop of naive methods\ndue to distribution shift. Additionally, we provide software to handle the\nSHIFT15M dataset in a simple manner, with the URL for the software to be made\navailable after publication of this manuscript. We believe proposed SHIFT15M\ndataset provide a valuable resource for evaluating set-to-set matching models\nunder the distribution shift.\n","authors":["Masanari Kimura","Takuma Nakamura","Yuki Saito"],"pdf_url":"https://arxiv.org/pdf/2108.12992v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04651v1","updated":"2023-03-08T15:19:27Z","published":"2023-03-08T15:19:27Z","title":"MCTS-GEB: Monte Carlo Tree Search is a Good E-graph Builder","summary":"  Rewrite systems [6, 10, 12] have been widely employing equality saturation\n[9], which is an optimisation methodology that uses a saturated e-graph to\nrepresent all possible sequences of rewrite simultaneously, and then extracts\nthe optimal one. As such, optimal results can be achieved by avoiding the\nphase-ordering problem. However, we observe that when the e-graph is not\nsaturated, it cannot represent all possible rewrite opportunities and therefore\nthe phase-ordering problem is re-introduced during the construction phase of\nthe e-graph. To address this problem, we propose MCTS-GEB, a domain-general\nrewrite system that applies reinforcement learning (RL) to e-graph\nconstruction. At its core, MCTS-GEB uses a Monte Carlo Tree Search (MCTS) [3]\nto efficiently plan for the optimal e-graph construction, and therefore it can\neffectively eliminate the phase-ordering problem at the construction phase and\nachieve better performance within a reasonable time. Evaluation in two\ndifferent domains shows MCTS-GEB can outperform the state-of-the-art rewrite\nsystems by up to 49x, while the optimisation can generally take less than an\nhour, indicating MCTS-GEB is a promising building block for the future\ngeneration of rewrite systems.\n","authors":["Guoliang He","Zak Singh","Eiko Yoneki"],"pdf_url":"https://arxiv.org/pdf/2303.04651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.09142v3","updated":"2023-03-08T15:17:51Z","published":"2022-03-17T07:51:52Z","title":"Covid19 Reproduction Number: Credibility Intervals by Blockwise Proximal\n  Monte Carlo Samplers","summary":"  Monitoring the Covid19 pandemic constitutes a critical societal stake that\nreceived considerable research efforts. The intensity of the pandemic on a\ngiven territory is efficiently measured by the reproduction number, quantifying\nthe rate of growth of daily new infections. Recently, estimates for the time\nevolution of the reproduction number were produced using an inverse problem\nformulation with a nonsmooth functional minimization. While it was designed to\nbe robust to the limited quality of the Covid19 data (outliers, missing\ncounts), the procedure lacks the ability to output credibility interval based\nestimates. This remains a severe limitation for practical use in actual\npandemic monitoring by epidemiologists that the present work aims to overcome\nby use of Monte Carlo sampling. After interpretation of the nonsmooth\nfunctional into a Bayesian framework, several sampling schemes are tailored to\nadjust the nonsmooth nature of the resulting posterior distribution. The\noriginality of the devised algorithms stems from combining a Langevin Monte\nCarlo sampling scheme with Proximal operators. Performance of the new\nalgorithms in producing relevant credibility intervals for the reproduction\nnumber estimates and denoised counts are compared. Assessment is conducted on\nreal daily new infection counts made available by the Johns Hopkins University.\nThe interest of the devised monitoring tools are illustrated on Covid19 data\nfrom several different countries.\n","authors":["Gersende Fort","Barbara Pascal","Patrice Abry","Nelly Pustelnik"],"pdf_url":"https://arxiv.org/pdf/2203.09142v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04642v1","updated":"2023-03-08T15:01:51Z","published":"2023-03-08T15:01:51Z","title":"Forecasting the movements of Bitcoin prices: an application of machine\n  learning algorithms","summary":"  Cryptocurrencies, such as Bitcoin, are one of the most controversial and\ncomplex technological innovations in today's financial system. This study aims\nto forecast the movements of Bitcoin prices at a high degree of accuracy. To\nthis aim, four different Machine Learning (ML) algorithms are applied, namely,\nthe Support Vector Machines (SVM), the Artificial Neural Network (ANN), the\nNaive Bayes (NB) and the Random Forest (RF) besides the logistic regression\n(LR) as a benchmark model. In order to test these algorithms, besides existing\ncontinuous dataset, discrete dataset was also created and used. For the\nevaluations of algorithm performances, the F statistic, accuracy statistic, the\nMean Absolute Error (MAE), the Root Mean Square Error (RMSE) and the Root\nAbsolute Error (RAE) metrics were used. The t test was used to compare the\nperformances of the SVM, ANN, NB and RF with the performance of the LR.\nEmpirical findings reveal that, while the RF has the highest forecasting\nperformance in the continuous dataset, the NB has the lowest. On the other\nhand, while the ANN has the highest and the NB the lowest performance in the\ndiscrete dataset. Furthermore, the discrete dataset improves the overall\nforecasting performance in all algorithms (models) estimated.\n","authors":["Hakan Pabuccu","Serdar Ongan","Ayse Ongan"],"pdf_url":"https://arxiv.org/pdf/2303.04642v1.pdf","comment":"14 pages, 2 figures and 15 tables"},{"id":"http://arxiv.org/abs/2303.04636v1","updated":"2023-03-08T14:56:11Z","published":"2023-03-08T14:56:11Z","title":"Robust Multimodal Fusion for Human Activity Recognition","summary":"  The proliferation of IoT and mobile devices equipped with heterogeneous\nsensors has enabled new applications that rely on the fusion of time-series\ndata generated by multiple sensors with different modalities. While there are\npromising deep neural network architectures for multimodal fusion, their\nperformance falls apart quickly in the presence of consecutive missing data and\nnoise across multiple modalities/sensors, the issues that are prevalent in\nreal-world settings. We propose Centaur, a multimodal fusion model for human\nactivity recognition (HAR) that is robust to these data quality issues. Centaur\ncombines a data cleaning module, which is a denoising autoencoder with\nconvolutional layers, and a multimodal fusion module, which is a deep\nconvolutional neural network with the self-attention mechanism to capture\ncross-sensor correlation. We train Centaur using a stochastic data corruption\nscheme and evaluate it on three datasets that contain data generated by\nmultiple inertial measurement units. Centaur's data cleaning module outperforms\n2 state-of-the-art autoencoder-based models and its multimodal fusion module\noutperforms 4 strong baselines. Compared to 2 related robust fusion\narchitectures, Centaur is more robust, achieving 11.59-17.52% higher accuracy\nin HAR, especially in the presence of consecutive missing data in multiple\nsensor channels.\n","authors":["Sanju Xaviar","Xin Yang","Omid Ardakanian"],"pdf_url":"https://arxiv.org/pdf/2303.04636v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2303.04635v1","updated":"2023-03-08T14:55:32Z","published":"2023-03-08T14:55:32Z","title":"Diffusing Gaussian Mixtures for Generating Categorical Data","summary":"  Learning a categorical distribution comes with its own set of challenges. A\nsuccessful approach taken by state-of-the-art works is to cast the problem in a\ncontinuous domain to take advantage of the impressive performance of the\ngenerative models for continuous data. Amongst them are the recently emerging\ndiffusion probabilistic models, which have the observed advantage of generating\nhigh-quality samples. Recent advances for categorical generative models have\nfocused on log likelihood improvements. In this work, we propose a generative\nmodel for categorical data based on diffusion models with a focus on\nhigh-quality sample generation, and propose sampled-based evaluation methods.\nThe efficacy of our method stems from performing diffusion in the continuous\ndomain while having its parameterization informed by the structure of the\ncategorical nature of the target distribution. Our method of evaluation\nhighlights the capabilities and limitations of different generative models for\ngenerating categorical data, and includes experiments on synthetic and\nreal-world protein datasets.\n","authors":["Florence Regol","Mark Coates"],"pdf_url":"https://arxiv.org/pdf/2303.04635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04630v1","updated":"2023-03-08T14:48:30Z","published":"2023-03-08T14:48:30Z","title":"Contribution of clinical course to outcome after traumatic brain injury:\n  mining patient trajectories from European intensive care unit data","summary":"  Existing methods to characterise the evolving condition of traumatic brain\ninjury (TBI) patients in the intensive care unit (ICU) do not capture the\ncontext necessary for individualising treatment. We aimed to develop a\nmodelling strategy which integrates all data stored in medical records to\nproduce an interpretable disease course for each TBI patient's ICU stay. From a\nprospective, European cohort (n=1,550, 65 centres, 19 countries) of TBI\npatients, we extracted all 1,166 variables collected before or during ICU stay\nas well as 6-month functional outcome on the Glasgow Outcome Scale-Extended\n(GOSE). We trained recurrent neural network models to map a token-embedded time\nseries representation of all variables (including missing data) to an ordinal\nGOSE prognosis every 2 hours. With repeated cross-validation, we evaluated\ncalibration and the explanation of ordinal variance in GOSE with Somers' Dxy.\nFurthermore, we applied TimeSHAP to calculate the contribution of variables and\nprior timepoints towards transitions in patient trajectories. Our modelling\nstrategy achieved calibration at 8 hours, and the full range of variables\nexplained up to 52% (95% CI: 50-54%) of the variance in ordinal functional\noutcome. Up to 91% (90-91%) of this explanation was derived from pre-ICU and\nadmission information. Information collected in the ICU increased explanation\n(by up to 5% [4-6%]), though not enough to counter poorer performance in\nlonger-stay (>5.75 days) patients. Static variables with the highest\ncontributions were physician prognoses and certain demographic and CT features.\nAmong dynamic variables, markers of intracranial hypertension and neurological\nfunction contributed the most. Whilst static information currently accounts for\nthe majority of functional outcome explanation, our data-driven analysis\nhighlights investigative avenues to improve dynamic characterisation of\nlonger-stay patients.\n","authors":["Shubhayu Bhattacharyay","Pier Francesco Caruso","Cecilia Åkerlund","Lindsay Wilson","Robert D Stevens","David K Menon","Ewout W Steyerberg","David W Nelson","Ari Ercole","the CENTER-TBI investigators/participants"],"pdf_url":"https://arxiv.org/pdf/2303.04630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04622v1","updated":"2023-03-08T14:40:15Z","published":"2023-03-08T14:40:15Z","title":"ELF: Federated Langevin Algorithms with Primal, Dual and Bidirectional\n  Compression","summary":"  Federated sampling algorithms have recently gained great popularity in the\ncommunity of machine learning and statistics. This paper studies variants of\nsuch algorithms called Error Feedback Langevin algorithms (ELF). In particular,\nwe analyze the combinations of EF21 and EF21-P with the federated Langevin\nMonte-Carlo. We propose three algorithms: P-ELF, D-ELF, and B-ELF that use,\nrespectively, primal, dual, and bidirectional compressors. We analyze the\nproposed methods under Log-Sobolev inequality and provide non-asymptotic\nconvergence guarantees.\n","authors":["Avetik Karagulyan","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2303.04622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04614v1","updated":"2023-03-08T14:35:03Z","published":"2023-03-08T14:35:03Z","title":"Densely Connected $G$-invariant Deep Neural Networks with Signed\n  Permutation Representations","summary":"  We introduce and investigate, for finite groups $G$, $G$-invariant deep\nneural network ($G$-DNN) architectures with ReLU activation that are densely\nconnected -- i.e., include all possible skip connections. In contrast to other\n$G$-invariant architectures in the literature, the preactivations of\nthe$G$-DNNs presented here are able to transform by \\emph{signed} permutation\nrepresentations (signed perm-reps) of $G$. Moreover, the individual layers of\nthe $G$-DNNs are not required to be $G$-equivariant; instead, the\npreactivations are constrained to be $G$-equivariant functions of the network\ninput in a way that couples weights across all layers. The result is a richer\nfamily of $G$-invariant architectures never seen previously. We derive an\nefficient implementation of $G$-DNNs after a reparameterization of weights, as\nwell as necessary and sufficient conditions for an architecture to be\n\"admissible\" -- i.e., nondegenerate and inequivalent to smaller architectures.\nWe include code that allows a user to build a $G$-DNN interactively\nlayer-by-layer, with the final architecture guaranteed to be admissible.\nFinally, we apply $G$-DNNs to two example problems -- (1) multiplication in\n$\\{-1, 1\\}$ (with theoretical guarantees) and (2) 3D object classification --\nfinding that the inclusion of signed perm-reps significantly boosts predictive\nperformance compared to baselines with only ordinary (i.e., unsigned)\nperm-reps.\n","authors":["Devanshu Agrawal","James Ostrowski"],"pdf_url":"https://arxiv.org/pdf/2303.04614v1.pdf","comment":"33 pages, 2 figures. For associated code repository see\n  https://github.com/dagrawa2/gdnn_code"},{"id":"http://arxiv.org/abs/2303.04613v1","updated":"2023-03-08T14:32:59Z","published":"2023-03-08T14:32:59Z","title":"The Descriptive Complexity of Graph Neural Networks","summary":"  We analyse the power of graph neural networks (GNNs) in terms of Boolean\ncircuit complexity and descriptive complexity.\n  We prove that the graph queries that can be computed by a polynomial-size\nbounded-depth family of GNNs are exactly those definable in the guarded\nfragment GFO+C of first-order logic with counting and with built-in relations.\nThis puts GNNs in the circuit complexity class TC^0. Remarkably, the GNN\nfamilies may use arbitrary real weights and a wide class of activation\nfunctions that includes the standard ReLU, logistic \"sigmoid\", and hyperbolic\ntangent functions. If the GNNs are allowed to use random initialisation and\nglobal readout (both standard features of GNNs widely used in practice), they\ncan compute exactly the same queries as bounded depth Boolean circuits with\nthreshold gates, that is, exactly the queries in TC^0. Moreover, we show that\nqueries computable by a single GNN with piecewise linear activations and\nrational weights are definable in GFO+C without built-in relations. Therefore,\nthey are contained in uniform TC^0.\n","authors":["Martin Grohe"],"pdf_url":"https://arxiv.org/pdf/2303.04613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04612v1","updated":"2023-03-08T14:27:35Z","published":"2023-03-08T14:27:35Z","title":"Differential Privacy Meets Neural Network Pruning","summary":"  A major challenge in applying differential privacy to training deep neural\nnetwork models is scalability.The widely-used training algorithm,\ndifferentially private stochastic gradient descent (DP-SGD), struggles with\ntraining moderately-sized neural network models for a value of epsilon\ncorresponding to a high level of privacy protection. In this paper, we explore\nthe idea of dimensionality reduction inspired by neural network pruning to\nimprove the scalability of DP-SGD. We study the interplay between neural\nnetwork pruning and differential privacy, through the two modes of parameter\nupdates. We call the first mode, parameter freezing, where we pre-prune the\nnetwork and only update the remaining parameters using DP-SGD. We call the\nsecond mode, parameter selection, where we select which parameters to update at\neach step of training and update only those selected using DP-SGD. In these\nmodes, we use public data for freezing or selecting parameters to avoid privacy\nloss incurring in these steps. Naturally, the closeness between the private and\npublic data plays an important role in the success of this paradigm. Our\nexperimental results demonstrate how decreasing the parameter space improves\ndifferentially private training. Moreover, by studying two popular forms of\npruning which do not rely on gradients and do not incur an additional privacy\nloss, we show that random selection performs on par with magnitude-based\nselection when it comes to DP-SGD training.\n","authors":["Kamil Adamczewski","Mijung Park"],"pdf_url":"https://arxiv.org/pdf/2303.04612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08428v2","updated":"2023-03-08T14:25:10Z","published":"2022-11-15T05:14:48Z","title":"CaDM: Codec-aware Diffusion Modeling for Neural-enhanced Video Streaming","summary":"  Recent years have witnessed the dramatic growth of Internet video traffic,\nwhere the video bitstreams are often compressed and delivered in low quality to\nfit the streamer's uplink bandwidth. To alleviate the quality degradation, it\ncomes the rise of Neural-enhanced Video Streaming (NVS), which shows great\nprospects for recovering low-quality videos by mostly deploying neural\nsuper-resolution (SR) on the media server. Despite its benefit, we reveal that\ncurrent mainstream works with SR enhancement have not achieved the desired\nrate-distortion trade-off between bitrate saving and quality restoration, due\nto: (1) overemphasizing the enhancement on the decoder side while omitting the\nco-design of encoder, (2) limited generative capacity to recover high-fidelity\nperceptual details, and (3) optimizing the compression-and-restoration pipeline\nfrom the resolution perspective solely, without considering color bit-depth.\nAiming at overcoming these limitations, we are the first to conduct an\nencoder-decoder (i.e., codec) synergy by leveraging the inherent\nvisual-generative property of diffusion models. Specifically, we present the\nCodec-aware Diffusion Modeling (CaDM), a novel NVS paradigm to significantly\nreduce streaming delivery bitrates while holding pretty higher restoration\ncapacity over existing methods. First, CaDM improves the encoder's compression\nefficiency by simultaneously reducing resolution and color bit-depth of video\nframes. Second, CaDM empowers the decoder with high-quality enhancement by\nmaking the denoising diffusion restoration aware of encoder's resolution-color\nconditions. Evaluation on public cloud services with OpenMMLab benchmarks shows\nthat CaDM effectively saves up to 5.12 - 21.44 times bitrates based on common\nvideo standards and achieves much better recovery quality (e.g., FID of 0.61)\nover state-of-the-art neural-enhancing methods.\n","authors":["Qihua Zhou","Ruibin Li","Song Guo","Peiran Dong","Yi Liu","Jingcai Guo","Zhenda Xu"],"pdf_url":"https://arxiv.org/pdf/2211.08428v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04581v1","updated":"2023-03-08T13:56:53Z","published":"2023-03-08T13:56:53Z","title":"Application of supervised learning models in the Chinese futures market","summary":"  Based on the characteristics of the Chinese futures market, this paper builds\na supervised learning model to predict the trend of futures prices and then\ndesigns a trading strategy based on the prediction results. The Precision,\nRecall and F1-score of the classification problem show that our model can meet\nthe accuracy requirements for the classification of futures price movements in\nterms of test data. The backtest results show that our trading system has an\nupward trending return curve with low capital retracement.\n","authors":["Fuquan Tang"],"pdf_url":"https://arxiv.org/pdf/2303.04581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04579v1","updated":"2023-03-08T13:54:57Z","published":"2023-03-08T13:54:57Z","title":"\"How to make them stay?\" -- Diverse Counterfactual Explanations of\n  Employee Attrition","summary":"  Employee attrition is an important and complex problem that can directly\naffect an organisation's competitiveness and performance. Explaining the\nreasons why employees leave an organisation is a key human resource management\nchallenge due to the high costs and time required to attract and keep talented\nemployees. Businesses therefore aim to increase employee retention rates to\nminimise their costs and maximise their performance. Machine learning (ML) has\nbeen applied in various aspects of human resource management including\nattrition prediction to provide businesses with insights on proactive measures\non how to prevent talented employees from quitting. Among these ML methods, the\nbest performance has been reported by ensemble or deep neural networks, which\nby nature constitute black box techniques and thus cannot be easily\ninterpreted. To enable the understanding of these models' reasoning several\nexplainability frameworks have been proposed. Counterfactual explanation\nmethods have attracted considerable attention in recent years since they can be\nused to explain and recommend actions to be performed to obtain the desired\noutcome. However current counterfactual explanations methods focus on\noptimising the changes to be made on individual cases to achieve the desired\noutcome. In the attrition problem it is important to be able to foresee what\nwould be the effect of an organisation's action to a group of employees where\nthe goal is to prevent them from leaving the company. Therefore, in this paper\nwe propose the use of counterfactual explanations focusing on multiple\nattrition cases from historical data, to identify the optimum interventions\nthat an organisation needs to make to its practices/policies to prevent or\nminimise attrition probability for these cases.\n","authors":["André Artelt","Andreas Gregoriades"],"pdf_url":"https://arxiv.org/pdf/2303.04579v1.pdf","comment":"Accepted as a short paper at ICEIS 2023"},{"id":"http://arxiv.org/abs/2102.08183v2","updated":"2023-03-08T13:54:33Z","published":"2021-02-16T14:33:05Z","title":"Comparison of semi-supervised deep learning algorithms for audio\n  classification","summary":"  In this article, we adapted five recent SSL methods to the task of audio\nclassification. The first two methods, namely Deep Co-Training (DCT) and Mean\nTeacher (MT), involve two collaborative neural networks. The three other\nalgorithms, called MixMatch (MM), ReMixMatch (RMM), and FixMatch (FM), are\nsingle-model methods that rely primarily on data augmentation strategies. Using\nthe Wide-ResNet-28-2 architecture in all our experiments, 10% of labeled data\nand the remaining 90% as unlabeled data for training, we first compare the\nerror rates of the five methods on three standard benchmark audio datasets:\nEnvironmental Sound Classification (ESC-10), UrbanSound8K (UBS8K), and Google\nSpeech Commands (GSC). In all but one cases, MM, RMM, and FM outperformed MT\nand DCT significantly, MM and RMM being the best methods in most experiments.\nOn UBS8K and GSC, MM achieved 18.02% and 3.25% error rate (ER), respectively,\noutperforming models trained with 100% of the available labeled data, which\nreached 23.29% and 4.94%, respectively. RMM achieved the best results on ESC-10\n(12.00% ER), followed by FM which reached 13.33%. Second, we explored adding\nthe mixup augmentation, used in MM and RMM, to DCT, MT, and FM. In almost all\ncases, mixup brought consistent gains. For instance, on GSC, FM reached 4.44%\nand 3.31% ER without and with mixup. Our PyTorch code will be made available\nupon paper acceptance at https:// github. com/ Labbe ti/ SSLH.\n","authors":["Léo Cances","Etienne Labbé","Thomas Pellegrini"],"pdf_url":"https://arxiv.org/pdf/2102.08183v2.pdf","comment":"9 pages, 5 figures, 5 tables. This is the version 3 of the paper.\n  Contains minor fixes compared to the EURASIP one (which is the version 2 of\n  the paper)"},{"id":"http://arxiv.org/abs/2210.11879v4","updated":"2023-03-08T13:45:55Z","published":"2022-10-21T11:08:10Z","title":"GLCC: A General Framework for Graph-Level Clustering","summary":"  This paper studies the problem of graph-level clustering, which is a novel\nyet challenging task. This problem is critical in a variety of real-world\napplications such as protein clustering and genome analysis in bioinformatics.\nRecent years have witnessed the success of deep clustering coupled with graph\nneural networks (GNNs). However, existing methods focus on clustering among\nnodes given a single graph, while exploring clustering on multiple graphs is\nstill under-explored. In this paper, we propose a general graph-level\nclustering framework named Graph-Level Contrastive Clustering (GLCC) given\nmultiple graphs. Specifically, GLCC first constructs an adaptive affinity graph\nto explore instance- and cluster-level contrastive learning (CL).\nInstance-level CL leverages graph Laplacian based contrastive loss to learn\nclustering-friendly representations while cluster-level CL captures\ndiscriminative cluster representations incorporating neighbor information of\neach sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the\noptimization of representation learning. The two steps can be alternatively\ntrained to collaborate and benefit each other. Experiments on a range of\nwell-known datasets demonstrate the superiority of our proposed GLCC over\ncompetitive baselines.\n","authors":["Wei Ju","Yiyang Gu","Binqi Chen","Gongbo Sun","Yifang Qin","Xingyuming Liu","Xiao Luo","Ming Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.11879v4.pdf","comment":"Accepted by Proceedings of the AAAI Conference on Artificial\n  Intelligence (AAAI 2023)"},{"id":"http://arxiv.org/abs/2206.00529v3","updated":"2023-03-08T13:43:24Z","published":"2022-06-01T14:40:29Z","title":"Variance Reduction is an Antidote to Byzantines: Better Rates, Weaker\n  Assumptions and Communication Compression as a Cherry on the Top","summary":"  Byzantine-robustness has been gaining a lot of attention due to the growth of\nthe interest in collaborative and federated learning. However, many fruitful\ndirections, such as the usage of variance reduction for achieving robustness\nand communication compression for reducing communication costs, remain weakly\nexplored in the field. This work addresses this gap and proposes Byz-VR-MARINA\n- a new Byzantine-tolerant method with variance reduction and compression. A\nkey message of our paper is that variance reduction is key to fighting\nByzantine workers more effectively. At the same time, communication compression\nis a bonus that makes the process more communication efficient. We derive\ntheoretical convergence guarantees for Byz-VR-MARINA outperforming previous\nstate-of-the-art for general non-convex and Polyak-Lojasiewicz loss functions.\nUnlike the concurrent Byzantine-robust methods with variance reduction and/or\ncompression, our complexity results are tight and do not rely on restrictive\nassumptions such as boundedness of the gradients or limited compression.\nMoreover, we provide the first analysis of a Byzantine-tolerant method\nsupporting non-uniform sampling of stochastic gradients. Numerical experiments\ncorroborate our theoretical findings.\n","authors":["Eduard Gorbunov","Samuel Horváth","Peter Richtárik","Gauthier Gidel"],"pdf_url":"https://arxiv.org/pdf/2206.00529v3.pdf","comment":"ICLR 2023. 42 pages, 8 figures. Changes in v2: few typos and\n  inaccuracies were fixed, more clarifications were added. Changes in v3: ICLR\n  formatting was applied, additional experiments were added (Appendix B.4-B.5)\n  and extra discussion of the results was added to Appendix E.5. Code:\n  https://github.com/SamuelHorvath/VR_Byzantine"},{"id":"http://arxiv.org/abs/2303.03590v2","updated":"2023-03-08T13:33:25Z","published":"2023-03-07T01:52:55Z","title":"Research on Efficient Fuzzy Clustering Method Based on Local Fuzzy\n  Granular balls","summary":"  In recent years, the problem of fuzzy clustering has been widely concerned.\nThe membership iteration of existing methods is mostly considered globally,\nwhich has considerable problems in noisy environments, and iterative\ncalculations for clusters with a large number of different sample sizes are not\naccurate and efficient. In this paper, starting from the strategy of\nlarge-scale priority, the data is fuzzy iterated using granular-balls, and the\nmembership degree of data only considers the two granular-balls where it is\nlocated, thus improving the efficiency of iteration. The formed fuzzy\ngranular-balls set can use more processing methods in the face of different\ndata scenarios, which enhances the practicability of fuzzy clustering\ncalculations.\n","authors":["Jiang Xie","Qiao Deng","Shuyin Xia","Yangzhou Zhao","Guoyin Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2303.03590v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07262v3","updated":"2023-03-08T13:33:09Z","published":"2022-02-15T09:17:39Z","title":"Stochastic Gradient Descent-Ascent: Unified Theory and New Efficient\n  Methods","summary":"  Stochastic Gradient Descent-Ascent (SGDA) is one of the most prominent\nalgorithms for solving min-max optimization and variational inequalities\nproblems (VIP) appearing in various machine learning tasks. The success of the\nmethod led to several advanced extensions of the classical SGDA, including\nvariants with arbitrary sampling, variance reduction, coordinate randomization,\nand distributed variants with compression, which were extensively studied in\nthe literature, especially during the last few years. In this paper, we propose\na unified convergence analysis that covers a large variety of stochastic\ngradient descent-ascent methods, which so far have required different\nintuitions, have different applications and have been developed separately in\nvarious communities. A key to our unified framework is a parametric assumption\non the stochastic estimates. Via our general theoretical framework, we either\nrecover the sharpest known rates for the known special cases or tighten them.\nMoreover, to illustrate the flexibility of our approach we develop several new\nvariants of SGDA such as a new variance-reduced method (L-SVRGDA), new\ndistributed methods with compression (QSGDA, DIANA-SGDA, VR-DIANA-SGDA), and a\nnew method with coordinate randomization (SEGA-SGDA). Although variants of the\nnew methods are known for solving minimization problems, they were never\nconsidered or analyzed for solving min-max problems and VIPs. We also\ndemonstrate the most important properties of the new methods through extensive\nnumerical experiments.\n","authors":["Aleksandr Beznosikov","Eduard Gorbunov","Hugo Berard","Nicolas Loizou"],"pdf_url":"https://arxiv.org/pdf/2202.07262v3.pdf","comment":"AISTATS 2023. 65 pages, 5 figures, 3 tables. Changes in v2: new\n  results were added (Theorem 2.5 and its corollaries), few typos were fixed,\n  more clarifications were added. Changes in v3: AISTATS formatting was\n  applied, small clarifications were added. Code:\n  https://github.com/hugobb/sgda"},{"id":"http://arxiv.org/abs/2303.04569v1","updated":"2023-03-08T13:30:02Z","published":"2023-03-08T13:30:02Z","title":"Safe Machine-Learning-supported Model Predictive Force and Motion\n  Control in Robotics","summary":"  Many robotic tasks, such as human-robot interactions or the handling of\nfragile objects, require tight control and limitation of appearing forces and\nmoments alongside sensible motion control to achieve safe yet high-performance\noperation. We propose a learning-supported model predictive force and motion\ncontrol scheme that provides stochastic safety guarantees while adapting to\nchanging situations. Gaussian processes are used to learn the uncertain\nrelations that map the robot's states to the forces and moments. The model\npredictive controller uses these Gaussian process models to achieve precise\nmotion and force control under stochastic constraint satisfaction. As the\nuncertainty only occurs in the static model parts -- the output equations -- a\ncomputationally efficient stochastic MPC formulation is used. Analysis of\nrecursive feasibility of the optimal control problem and convergence of the\nclosed loop system for the static uncertainty case are given. Chance constraint\nformulation and back-offs are constructed based on the variance of the Gaussian\nprocess to guarantee safe operation. The approach is illustrated on a\nlightweight robot in simulations and experiments.\n","authors":["Janine Matschek","Johanna Bethge","Rolf Findeisen"],"pdf_url":"https://arxiv.org/pdf/2303.04569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04562v1","updated":"2023-03-08T13:21:27Z","published":"2023-03-08T13:21:27Z","title":"Extrapolative Controlled Sequence Generation via Iterative Refinement","summary":"  We study the problem of extrapolative controlled generation, i.e., generating\nsequences with attribute values beyond the range seen in training. This task is\nof significant importance in automated design, especially drug discovery, where\nthe goal is to design novel proteins that are \\textit{better} (e.g., more\nstable) than existing sequences. Thus, by definition, the target sequences and\ntheir attribute values are out of the training distribution, posing challenges\nto existing methods that aim to directly generate the target sequence. Instead,\nin this work, we propose Iterative Controlled Extrapolation (ICE) which\niteratively makes local edits to a sequence to enable extrapolation. We train\nthe model on synthetically generated sequence pairs that demonstrate small\nimprovement in the attribute value. Results on one natural language task\n(sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV\nfitness) show that ICE considerably outperforms state-of-the-art approaches\ndespite its simplicity. Our code and models are available at:\nhttps://github.com/vishakhpk/iter-extrapolation.\n","authors":["Vishakh Padmakumar","Richard Yuanzhe Pang","He He","Ankur P. Parikh"],"pdf_url":"https://arxiv.org/pdf/2303.04562v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2205.05469v2","updated":"2023-03-08T13:21:23Z","published":"2022-05-11T13:09:47Z","title":"Generation of non-stationary stochastic fields using Generative\n  Adversarial Networks","summary":"  In the context of generating geological facies conditioned on observed data,\nsamples corresponding to all possible conditions are not generally available in\nthe training set and hence the generation of these realizations depends primary\non the generalization capability of the trained generative model. The problem\nbecomes more complex when applied on non-stationary fields. In this work, we\ninvestigate the problem of using Generative Adversarial Networks (GANs) models\nto generate non-stationary geological channelized patterns and examine the\nmodels generalization capability at new spatial modes that were never seen in\nthe given training set. The developed training method based on\nspatial-conditioning allowed for effective learning of the correlation between\nthe spatial conditions (i.e. non-stationary maps) and the realizations\nimplicitly without using additional loss terms or solving optimization problems\nfor every new given data after training. In addition, our models can be trained\non 2D and 3D samples. The results on real and artificial datasets show that we\nwere able to generate geologically-plausible realizations beyond the training\nsamples and with a strong correlation with the target maps.\n","authors":["Alhasan Abdellatif","Ahmed H. Elsheikh","Daniel Busby","Philippe Berthet"],"pdf_url":"https://arxiv.org/pdf/2205.05469v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04560v1","updated":"2023-03-08T13:20:49Z","published":"2023-03-08T13:20:49Z","title":"Byzantine-Robust Loopless Stochastic Variance-Reduced Gradient","summary":"  Distributed optimization with open collaboration is a popular field since it\nprovides an opportunity for small groups/companies/universities, and\nindividuals to jointly solve huge-scale problems. However, standard\noptimization algorithms are fragile in such settings due to the possible\npresence of so-called Byzantine workers -- participants that can send\n(intentionally or not) incorrect information instead of the one prescribed by\nthe protocol (e.g., send anti-gradient instead of stochastic gradients). Thus,\nthe problem of designing distributed methods with provable robustness to\nByzantine workers has been receiving a lot of attention recently. In\nparticular, several works consider a very promising way to achieve Byzantine\ntolerance via exploiting variance reduction and robust aggregation. The\nexisting approaches use SAGA- and SARAH-type variance-reduced estimators, while\nanother popular estimator -- SVRG -- is not studied in the context of\nByzantine-robustness. In this work, we close this gap in the literature and\npropose a new method -- Byzantine-Robust Loopless Stochastic Variance Reduced\nGradient (BR-LSVRG). We derive non-asymptotic convergence guarantees for the\nnew method in the strongly convex case and compare its performance with\nexisting approaches in numerical experiments.\n","authors":["Nikita Fedin","Eduard Gorbunov"],"pdf_url":"https://arxiv.org/pdf/2303.04560v1.pdf","comment":"15 pages, 2 figures. Code: https://github.com/Nikosimus/BR-LSVRG"},{"id":"http://arxiv.org/abs/2303.04555v1","updated":"2023-03-08T13:13:33Z","published":"2023-03-08T13:13:33Z","title":"Streaming Kernel PCA Algorithm With Small Space","summary":"  Principal Component Analysis (PCA) is a widely used technique in machine\nlearning, data analysis and signal processing. With the increase in the size\nand complexity of datasets, it has become important to develop low-space usage\nalgorithms for PCA. Streaming PCA has gained significant attention in recent\nyears, as it can handle large datasets efficiently. The kernel method, which is\ncommonly used in learning algorithms such as Support Vector Machines (SVMs),\nhas also been applied in PCA algorithms.\n  We propose a streaming algorithm for Kernel PCA problems based on the\ntraditional scheme by Oja. Our algorithm addresses the challenge of reducing\nthe memory usage of PCA while maintaining its accuracy. We analyze the\nperformance of our algorithm by studying the conditions under which it\nsucceeds. Specifically, we show that, when the spectral ratio $R :=\n\\lambda_1/\\lambda_2$ of the target covariance matrix is lower bounded by $C\n\\cdot \\log n\\cdot \\log d$, the streaming PCA can be solved with $O(d)$ space\ncost.\n  Our proposed algorithm has several advantages over existing methods. First,\nit is a streaming algorithm that can handle large datasets efficiently. Second,\nit employs the kernel method, which allows it to capture complex nonlinear\nrelationships among data points. Third, it has a low-space usage, making it\nsuitable for applications where memory is limited.\n","authors":["Yichuan Deng","Zhao Song","Zifan Wang","Han Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.04555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04550v1","updated":"2023-03-08T13:03:45Z","published":"2023-03-08T13:03:45Z","title":"Sketching with Spherical Designs for Noisy Data Fitting on Spheres","summary":"  This paper proposes a sketching strategy based on spherical designs, which is\napplied to the classical spherical basis function approach for massive\nspherical data fitting. We conduct theoretical analysis and numerical\nverifications to demonstrate the feasibility of the proposed { sketching}\nstrategy. From the theoretical side, we prove that sketching based on spherical\ndesigns can reduce the computational burden of the spherical basis function\napproach without sacrificing its approximation capability. In particular, we\nprovide upper and lower bounds for the proposed { sketching} strategy to fit\nnoisy data on spheres. From the experimental side, we numerically illustrate\nthe feasibility of the sketching strategy by showing its comparable fitting\nperformance with the spherical basis function approach.\n  These interesting findings show that the proposed sketching strategy is\ncapable of fitting massive and noisy data on spheres.\n","authors":["Shao-Bo Lin","Di Wang","Ding-Xuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.04550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04547v1","updated":"2023-03-08T13:00:40Z","published":"2023-03-08T13:00:40Z","title":"Unimodal Distributions for Ordinal Regression","summary":"  In many real-world prediction tasks, class labels contain information about\nthe relative order between labels that are not captured by commonly used loss\nfunctions such as multicategory cross-entropy. Recently, the preference for\nunimodal distributions in the output space has been incorporated into models\nand loss functions to account for such ordering information. However, current\napproaches rely on heuristics that lack a theoretical foundation. Here, we\npropose two new approaches to incorporate the preference for unimodal\ndistributions into the predictive model. We analyse the set of unimodal\ndistributions in the probability simplex and establish fundamental properties.\nWe then propose a new architecture that imposes unimodal distributions and a\nnew loss term that relies on the notion of projection in a set to promote\nunimodality. Experiments show the new architecture achieves top-2 performance,\nwhile the proposed new loss term is very competitive while maintaining high\nunimodality.\n","authors":["Jaime S. Cardoso","Ricardo Cruz","Tomé Albuquerque"],"pdf_url":"https://arxiv.org/pdf/2303.04547v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2303.04545v1","updated":"2023-03-08T12:55:40Z","published":"2023-03-08T12:55:40Z","title":"A robust method for reliability updating with equality information using\n  sequential adaptive importance sampling","summary":"  Reliability updating refers to a problem that integrates Bayesian updating\ntechnique with structural reliability analysis and cannot be directly solved by\nstructural reliability methods (SRMs) when it involves equality information.\nThe state-of-the-art approaches transform equality information into inequality\ninformation by introducing an auxiliary standard normal parameter. These\nmethods, however, encounter the loss of computational efficiency due to the\ndifficulty in finding the maximum of the likelihood function, the large\ncoefficient of variation (COV) associated with the posterior failure\nprobability and the inapplicability to dynamic updating problems where new\ninformation is constantly available. To overcome these limitations, this paper\nproposes an innovative method called RU-SAIS (reliability updating using\nsequential adaptive importance sampling), which combines elements of sequential\nimportance sampling and K-means clustering to construct a series of important\nsampling densities (ISDs) using Gaussian mixture. The last ISD of the sequence\nis further adaptively modified through application of the cross entropy method.\nThe performance of RU-SAIS is demonstrated by three examples. Results show that\nRU-SAIS achieves a more accurate and robust estimator of the posterior failure\nprobability than the existing methods such as subset simulation.\n","authors":["Xiong Xiao","Zeyu Wang","Quanwang Li"],"pdf_url":"https://arxiv.org/pdf/2303.04545v1.pdf","comment":"38 pages, 6 tables, 9 figures"},{"id":"http://arxiv.org/abs/2112.11602v3","updated":"2023-03-08T12:39:14Z","published":"2021-12-22T01:04:50Z","title":"Causal Inference Despite Limited Global Confounding via Mixture Models","summary":"  A Bayesian Network is a directed acyclic graph (DAG) on a set of $n$ random\nvariables (the vertices); a Bayesian Network Distribution (BND) is a\nprobability distribution on the random variables that is Markovian on the\ngraph. A finite $k$-mixture of such models is graphically represented by a\nlarger graph which has an additional \"hidden\" (or \"latent\") random variable\n$U$, ranging in $\\{1,\\ldots,k\\}$, and a directed edge from $U$ to every other\nvertex. Models of this type are fundamental to causal inference, where $U$\nmodels an unobserved confounding effect of multiple populations, obscuring the\ncausal relationships in the observable DAG. By solving the mixture problem and\nrecovering the joint probability distribution on $U$, traditionally\nunidentifiable causal relationships become identifiable. Using a reduction to\nthe more well-studied \"product\" case on empty graphs, we give the first\nalgorithm to learn mixtures of non-empty DAGs.\n","authors":["Spencer L. Gordon","Bijan Mazaheri","Yuval Rabani","Leonard J. Schulman"],"pdf_url":"https://arxiv.org/pdf/2112.11602v3.pdf","comment":"Paper to appear in CLEAR 2023"},{"id":"http://arxiv.org/abs/2212.05764v2","updated":"2023-03-08T12:29:29Z","published":"2022-12-12T08:32:28Z","title":"Domain Adaptation of Transformer-Based Models using Unlabeled Data for\n  Relevance and Polarity Classification of German Customer Feedback","summary":"  Understanding customer feedback is becoming a necessity for companies to\nidentify problems and improve their products and services. Text classification\nand sentiment analysis can play a major role in analyzing this data by using a\nvariety of machine and deep learning approaches. In this work, different\ntransformer-based models are utilized to explore how efficient these models are\nwhen working with a German customer feedback dataset. In addition, these\npre-trained models are further analyzed to determine if adapting them to a\nspecific domain using unlabeled data can yield better results than\noff-the-shelf pre-trained models. To evaluate the models, two downstream tasks\nfrom the GermEval 2017 are considered. The experimental results show that\ntransformer-based models can reach significant improvements compared to a\nfastText baseline and outperform the published scores and previous models. For\nthe subtask Relevance Classification, the best models achieve a micro-averaged\n$F1$-Score of 96.1 % on the first test set and 95.9 % on the second one, and a\nscore of 85.1 % and 85.3 % for the subtask Polarity Classification.\n","authors":["Ahmad Idrissi-Yaghir","Henning Schäfer","Nadja Bauer","Christoph M. Friedrich"],"pdf_url":"https://arxiv.org/pdf/2212.05764v2.pdf","comment":"Complete"},{"id":"http://arxiv.org/abs/2212.02015v2","updated":"2023-03-08T12:26:15Z","published":"2022-12-05T04:05:32Z","title":"Learning Imbalanced Data with Vision Transformers","summary":"  The real-world data tends to be heavily imbalanced and severely skew the\ndata-driven deep neural networks, which makes Long-Tailed Recognition (LTR) a\nmassive challenging task. Existing LTR methods seldom train Vision Transformers\n(ViTs) with Long-Tailed (LT) data, while the off-the-shelf pretrain weight of\nViTs always leads to unfair comparisons. In this paper, we systematically\ninvestigate the ViTs' performance in LTR and propose LiVT to train ViTs from\nscratch only with LT data. With the observation that ViTs suffer more severe\nLTR problems, we conduct Masked Generative Pretraining (MGP) to learn\ngeneralized features. With ample and solid evidence, we show that MGP is more\nrobust than supervised manners. In addition, Binary Cross Entropy (BCE) loss,\nwhich shows conspicuous performance with ViTs, encounters predicaments in LTR.\nWe further propose the balanced BCE to ameliorate it with strong theoretical\ngroundings. Specially, we derive the unbiased extension of Sigmoid and\ncompensate extra logit margins to deploy it. Our Bal-BCE contributes to the\nquick convergence of ViTs in just a few epochs. Extensive experiments\ndemonstrate that with MGP and Bal-BCE, LiVT successfully trains ViTs well\nwithout any additional data and outperforms comparable state-of-the-art methods\nsignificantly, e.g., our ViT-B achieves 81.0% Top-1 accuracy in iNaturalist\n2018 without bells and whistles. Code is available at\nhttps://github.com/XuZhengzhuo/LiVT.\n","authors":["Zhengzhuo Xu","Ruikang Liu","Shuo Yang","Zenghao Chai","Chun Yuan"],"pdf_url":"https://arxiv.org/pdf/2212.02015v2.pdf","comment":"Accepted to CVPR 2023, camera-ready version; Code:\n  https://github.com/XuZhengzhuo/LiVT"},{"id":"http://arxiv.org/abs/2302.04054v4","updated":"2023-03-08T11:37:27Z","published":"2023-02-08T13:47:00Z","title":"Towards Inferential Reproducibility of Machine Learning Research","summary":"  Reliability of machine learning evaluation -- the consistency of observed\nevaluation scores across replicated model training runs -- is affected by\nseveral sources of nondeterminism which can be regarded as measurement noise.\nCurrent tendencies to remove noise in order to enforce reproducibility of\nresearch results neglect inherent nondeterminism at the implementation level\nand disregard crucial interaction effects between algorithmic noise factors and\ndata properties. This limits the scope of conclusions that can be drawn from\nsuch experiments. Instead of removing noise, we propose to incorporate several\nsources of variance, including their interaction with data properties, into an\nanalysis of significance and reliability of machine learning evaluation, with\nthe aim to draw inferences beyond particular instances of trained models. We\nshow how to use linear mixed effects models (LMEMs) to analyze performance\nevaluation scores, and to conduct statistical inference with a generalized\nlikelihood ratio test (GLRT). This allows us to incorporate arbitrary sources\nof noise like meta-parameter variations into statistical significance testing,\nand to assess performance differences conditional on data properties.\nFurthermore, a variance component analysis (VCA) enables the analysis of the\ncontribution of noise sources to overall variance and the computation of a\nreliability coefficient by the ratio of substantial to total variance.\n","authors":["Michael Hagmann","Philipp Meier","Stefan Riezler"],"pdf_url":"https://arxiv.org/pdf/2302.04054v4.pdf","comment":"Published at ICLR 2023 (see https://openreview.net/pdf?id=li4GQCQWkv)"},{"id":"http://arxiv.org/abs/2303.02223v2","updated":"2023-03-08T11:30:54Z","published":"2023-03-03T21:33:38Z","title":"Feature Selection for Forecasting","summary":"  This work investigates the importance of feature selection for improving the\nforecasting performance of machine learning algorithms for financial data.\nArtificial neural networks (ANN), convolutional neural networks (CNN),\nlong-short term memory (LSTM) networks, as well as linear models were applied\nfor forecasting purposes. The Feature Selection with Annealing (FSA) algorithm\nwas used to select the features from about 1000 possible predictors obtained\nfrom 26 technical indicators with specific periods and their lags. In addition\nto this, the Boruta feature selection algorithm was applied as a baseline\nfeature selection method. The dependent variables consisted of daily\nlogarithmic returns and daily trends of ten financial data sets, including\ncryptocurrency and different stocks. Experiments indicate that the FSA\nalgorithm increased the performance of ML models regardless of the problem\ntype. The FSA hybrid machine learning models showed better performance in 10\nout of 10 data sets for regression and 8 out of 10 data sets for\nclassification. None of the hybrid Boruta models outperformed the hybrid FSA\nmodels. However, the BORCNN model performance was comparable to the best model\nfor 4 out of 10 data sets for regression estimates. BOR-LR and BOR-CNN models\nshowed comparable performance with the best hybrid FSA models in 2 out of 10\ndatasets for classification. FSA was observed to improve the model performance\nin both better performance metrics as well as a decreased computation time by\nproviding a lower dimensional input feature space.\n","authors":["Hakan Pabuccu","Adrian Barbu"],"pdf_url":"https://arxiv.org/pdf/2303.02223v2.pdf","comment":"21 pages, 2 figures and 12 tables"},{"id":"http://arxiv.org/abs/2302.05942v2","updated":"2023-03-08T11:19:59Z","published":"2023-02-12T15:45:50Z","title":"SpReME: Sparse Regression for Multi-Environment Dynamic Systems","summary":"  Learning dynamical systems is a promising avenue for scientific discoveries.\nHowever, capturing the governing dynamics in multiple environments still\nremains a challenge: model-based approaches rely on the fidelity of assumptions\nmade for a single environment, whereas data-driven approaches based on neural\nnetworks are often fragile on extrapolating into the future. In this work, we\ndevelop a method of sparse regression dubbed SpReME to discover the major\ndynamics that underlie multiple environments. Specifically, SpReME shares a\nsparse structure of ordinary differential equation (ODE) across different\nenvironments in common while allowing each environment to keep the coefficients\nof ODE terms independently. We demonstrate that the proposed model captures the\ncorrect dynamics from multiple environments over four different dynamic systems\nwith improved prediction performance.\n","authors":["MoonJeong Park","Youngbin Choi","Namhoon Lee","Dongwoo Kim"],"pdf_url":"https://arxiv.org/pdf/2302.05942v2.pdf","comment":"The code is available at https://github.com/ml-postech/SpReME"},{"id":"http://arxiv.org/abs/2303.00529v2","updated":"2023-03-08T11:12:03Z","published":"2023-03-01T14:10:21Z","title":"Extending DNN-based Multiplicative Masking to Deep Subband Filtering for\n  Improved Dereverberation","summary":"  In this paper, we present a scheme for extending deep neural network-based\nmultiplicative maskers to deep subband filters for speech restoration in the\ntime-frequency domain. The resulting method can be generically applied to any\ndeep neural network providing masks in the time-frequency domain, while\nrequiring only few more trainable parameters and a computational overhead that\nis negligible for state-of-the-art neural networks. We demonstrate that the\nresulting deep subband filtering scheme outperforms multiplicative masking for\ndereverberation, while leaving the denoising performance virtually the same. We\nargue that this is because deep subband filtering in the time-frequency domain\nfits the subband approximation often assumed in the dereverberation literature,\nwhereas multiplicative masking corresponds to the narrowband approximation\ngenerally employed in denoising.\n","authors":["Jean-Marie Lemercier","Julian Tobergte","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2303.00529v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08624v3","updated":"2023-03-08T11:09:25Z","published":"2022-11-16T02:29:05Z","title":"Leveraging Heteroscedastic Uncertainty in Learning Complex Spectral\n  Mapping for Single-channel Speech Enhancement","summary":"  Most speech enhancement (SE) models learn a point estimate and do not make\nuse of uncertainty estimation in the learning process. In this paper, we show\nthat modeling heteroscedastic uncertainty by minimizing a multivariate Gaussian\nnegative log-likelihood (NLL) improves SE performance at no extra cost. During\ntraining, our approach augments a model learning complex spectral mapping with\na temporary submodel to predict the covariance of the enhancement error at each\ntime-frequency bin. Due to unrestricted heteroscedastic uncertainty, the\ncovariance introduces an undersampling effect, detrimental to SE performance.\nTo mitigate undersampling, our approach inflates the uncertainty lower bound\nand weights each loss component with their uncertainty, effectively\ncompensating severely undersampled components with more penalties. Our\nmultivariate setting reveals common covariance assumptions such as scalar and\ndiagonal matrices. By weakening these assumptions, we show that the NLL\nachieves superior performance compared to popular loss functions including the\nmean squared error (MSE), mean absolute error (MAE), and scale-invariant\nsignal-to-distortion ratio (SI-SDR).\n","authors":["Kuan-Lin Chen","Daniel D. E. Wong","Ke Tan","Buye Xu","Anurag Kumar","Vamsi Krishna Ithapu"],"pdf_url":"https://arxiv.org/pdf/2211.08624v3.pdf","comment":"5 pages. Accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2210.01911v3","updated":"2023-03-08T11:00:55Z","published":"2022-10-04T21:16:48Z","title":"Grounding Language with Visual Affordances over Unstructured Data","summary":"  Recent works have shown that Large Language Models (LLMs) can be applied to\nground natural language to a wide variety of robot skills. However, in\npractice, learning multi-task, language-conditioned robotic skills typically\nrequires large-scale data collection and frequent human intervention to reset\nthe environment or help correcting the current policies. In this work, we\npropose a novel approach to efficiently learn general-purpose\nlanguage-conditioned robot skills from unstructured, offline and reset-free\ndata in the real world by exploiting a self-supervised visuo-lingual affordance\nmodel, which requires annotating as little as 1% of the total data with\nlanguage. We evaluate our method in extensive experiments both in simulated and\nreal-world robotic tasks, achieving state-of-the-art performance on the\nchallenging CALVIN benchmark and learning over 25 distinct visuomotor\nmanipulation tasks with a single policy in the real world. We find that when\npaired with LLMs to break down abstract natural language instructions into\nsubgoals via few-shot prompting, our method is capable of completing\nlong-horizon, multi-tier tasks in the real world, while requiring an order of\nmagnitude less data than previous approaches. Code and videos are available at\nhttp://hulc2.cs.uni-freiburg.de\n","authors":["Oier Mees","Jessica Borja-Diaz","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2210.01911v3.pdf","comment":"Accepted at the 2023 IEEE International Conference on Robotics and\n  Automation (ICRA). Project website: http://hulc2.cs.uni-freiburg.de"},{"id":"http://arxiv.org/abs/2210.05714v4","updated":"2023-03-08T10:30:41Z","published":"2022-10-11T18:13:20Z","title":"Visual Language Maps for Robot Navigation","summary":"  Grounding language to the visual observations of a navigating agent can be\nperformed using off-the-shelf visual-language models pretrained on\nInternet-scale data (e.g., image captions). While this is useful for matching\nimages to natural language descriptions of object goals, it remains disjoint\nfrom the process of mapping the environment, so that it lacks the spatial\nprecision of classic geometric maps. To address this problem, we propose\nVLMaps, a spatial map representation that directly fuses pretrained\nvisual-language features with a 3D reconstruction of the physical world. VLMaps\ncan be autonomously built from video feed on robots using standard exploration\napproaches and enables natural language indexing of the map without additional\nlabeled data. Specifically, when combined with large language models (LLMs),\nVLMaps can be used to (i) translate natural language commands into a sequence\nof open-vocabulary navigation goals (which, beyond prior work, can be spatial\nby construction, e.g., \"in between the sofa and TV\" or \"three meters to the\nright of the chair\") directly localized in the map, and (ii) can be shared\namong multiple robots with different embodiments to generate new obstacle maps\non-the-fly (by using a list of obstacle categories). Extensive experiments\ncarried out in simulated and real world environments show that VLMaps enable\nnavigation according to more complex language instructions than existing\nmethods. Videos are available at https://vlmaps.github.io.\n","authors":["Chenguang Huang","Oier Mees","Andy Zeng","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2210.05714v4.pdf","comment":"Accepted at the 2023 IEEE International Conference on Robotics and\n  Automation (ICRA). Project page: https://vlmaps.github.io"},{"id":"http://arxiv.org/abs/2303.04488v1","updated":"2023-03-08T10:22:00Z","published":"2023-03-08T10:22:00Z","title":"Magnushammer: A Transformer-based Approach to Premise Selection","summary":"  Premise selection is a fundamental problem of automated theorem proving.\nPrevious works often use intricate symbolic methods, rely on domain knowledge,\nand require significant engineering effort to solve this task. In this work, we\nshow that Magnushammer, a neural transformer-based approach, can outperform\ntraditional symbolic systems by a large margin. Tested on the PISA benchmark,\nMagnushammer achieves $59.5\\%$ proof rate compared to a $38.3\\%$ proof rate of\nSledgehammer, the most mature and popular symbolic-based solver. Furthermore,\nby combining Magnushammer with a neural formal prover based on a language\nmodel, we significantly improve the previous state-of-the-art proof rate from\n$57.0\\%$ to $71.0\\%$.\n","authors":["Maciej Mikuła","Szymon Antoniak","Szymon Tworkowski","Albert Qiaochu Jiang","Jin Peng Zhou","Christian Szegedy","Łukasz Kuciński","Piotr Miłoś","Yuhuai Wu"],"pdf_url":"https://arxiv.org/pdf/2303.04488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04486v1","updated":"2023-03-08T10:19:55Z","published":"2023-03-08T10:19:55Z","title":"Better Together: Using Multi-task Learning to Improve Feature Selection\n  within Structural Datasets","summary":"  There have been recent efforts to move to population-based structural health\nmonitoring (PBSHM) systems. One area of PBSHM which has been recognised for\npotential development is the use of multi-task learning (MTL); algorithms which\ndiffer from traditional independent learning algorithms. Presented here is the\nuse of the MTL, ''Joint Feature Selection with LASSO'', to provide automatic\nfeature selection for a structural dataset. The classification task is to\ndifferentiate between the port and starboard side of a tailplane, for samples\nfrom two aircraft of the same model. The independent learner produced perfect\nF1 scores but had poor engineering insight; whereas the MTL results were\ninterpretable, highlighting structural differences as opposed to differences in\nexperimental set-up.\n","authors":["S. C. Bee","E. Papatheou","M Haywood-Alexander","R. S. Mills","L. A. Bull","K. Worden","N. Dervilis"],"pdf_url":"https://arxiv.org/pdf/2303.04486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04484v1","updated":"2023-03-08T10:14:58Z","published":"2023-03-08T10:14:58Z","title":"Extracting Digital Biomarkers for Unobtrusive Stress State Screening\n  from Multimodal Wearable Data","summary":"  With the development of wearable technologies, a new kind of healthcare data\nhas become valuable as medical information. These data provide meaningful\ninformation regarding an individual's physiological and psychological states,\nsuch as activity level, mood, stress, and cognitive health. These biomarkers\nare named digital since they are collected from digital devices integrated with\nvarious sensors. In this study, we explore digital biomarkers related to stress\nmodality by examining data collected from mobile phones and smartwatches. We\nutilize machine learning techniques on the Tesserae dataset, precisely Random\nForest, to extract stress biomarkers. Using feature selection techniques, we\nutilize weather, activity, heart rate (HR), stress, sleep, and location\n(work-home) measurements from wearables to determine the most important\nstress-related biomarkers. We believe we contribute to interpreting stress\nbiomarkers with a high range of features from different devices. In addition,\nwe classify the $5$ different stress levels with the most important features,\nand our results show that we can achieve $85\\%$ overall class accuracy by\nadjusting class imbalance and adding extra features related to personality\ncharacteristics. We perform similar and even better results in recognizing\nstress states with digital biomarkers in a daily-life scenario targeting a\nhigher number of classes compared to the related studies.\n","authors":["Berrenur Saylam","Özlem Durmaz İncel"],"pdf_url":"https://arxiv.org/pdf/2303.04484v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13298v4","updated":"2023-03-08T10:05:38Z","published":"2022-08-28T22:01:10Z","title":"Goal-Conditioned Q-Learning as Knowledge Distillation","summary":"  Many applications of reinforcement learning can be formalized as\ngoal-conditioned environments, where, in each episode, there is a \"goal\" that\naffects the rewards obtained during that episode but does not affect the\ndynamics. Various techniques have been proposed to improve performance in\ngoal-conditioned environments, such as automatic curriculum generation and goal\nrelabeling. In this work, we explore a connection between off-policy\nreinforcement learning in goal-conditioned settings and knowledge distillation.\nIn particular: the current Q-value function and the target Q-value estimate are\nboth functions of the goal, and we would like to train the Q-value function to\nmatch its target for all goals. We therefore apply Gradient-Based Attention\nTransfer (Zagoruyko and Komodakis 2017), a knowledge distillation technique, to\nthe Q-function update. We empirically show that this can improve the\nperformance of goal-conditioned off-policy reinforcement learning when the\nspace of goals is high-dimensional. We also show that this technique can be\nadapted to allow for efficient learning in the case of multiple simultaneous\nsparse goals, where the agent can attain a reward by achieving any one of a\nlarge set of objectives, all specified at test time. Finally, to provide\ntheoretical support, we give examples of classes of environments where (under\nsome assumptions) standard off-policy algorithms such as DDPG require at least\nO(d^2) replay buffer transitions to learn an optimal policy, while our proposed\ntechnique requires only O(d) transitions, where d is the dimensionality of the\ngoal and state space. Code is available at\nhttps://github.com/alevine0/ReenGAGE.\n","authors":["Alexander Levine","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2208.13298v4.pdf","comment":"AAAI 2023 Accepted paper"},{"id":"http://arxiv.org/abs/2303.04477v1","updated":"2023-03-08T09:58:58Z","published":"2023-03-08T09:58:58Z","title":"Graph Neural Networks Enhanced Smart Contract Vulnerability Detection of\n  Educational Blockchain","summary":"  With the development of blockchain technology, more and more attention has\nbeen paid to the intersection of blockchain and education, and various\neducational evaluation systems and E-learning systems are developed based on\nblockchain technology. Among them, Ethereum smart contract is favored by\ndevelopers for its ``event-triggered\" mechanism for building education\nintelligent trading systems and intelligent learning platforms. However, due to\nthe immutability of blockchain, published smart contracts cannot be modified,\nso problematic contracts cannot be fixed by modifying the code in the\neducational blockchain. In recent years, security incidents due to smart\ncontract vulnerabilities have caused huge property losses, so the detection of\nsmart contract vulnerabilities in educational blockchain has become a great\nchallenge. To solve this problem, this paper proposes a graph neural network\n(GNN) based vulnerability detection for smart contracts in educational\nblockchains. Firstly, the bytecodes are decompiled to get the opcode. Secondly,\nthe basic blocks are divided, and the edges between the basic blocks according\nto the opcode execution logic are added. Then, the control flow graphs (CFG)\nare built. Finally, we designed a GNN-based model for vulnerability detection.\nThe experimental results show that the proposed method is effective for the\nvulnerability detection of smart contracts. Compared with the traditional\napproaches, it can get good results with fewer layers of the GCN model, which\nshows that the contract bytecode and GCN model are efficient in vulnerability\ndetection.\n","authors":["Zhifeng Wang","Wanxuan Wu","Chunyan Zeng","Jialong Yao","Yang Yang","Hongmin Xu"],"pdf_url":"https://arxiv.org/pdf/2303.04477v1.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2206.07376v3","updated":"2023-03-08T09:47:11Z","published":"2022-06-15T08:32:53Z","title":"Mean-Semivariance Policy Optimization via Risk-Averse Reinforcement\n  Learning","summary":"  Keeping risk under control is often more crucial than maximizing expected\nrewards in real-world decision-making situations, such as finance, robotics,\nautonomous driving, etc. The most natural choice of risk measures is variance,\nwhich penalizes the upside volatility as much as the downside part. Instead,\nthe (downside) semivariance, which captures the negative deviation of a random\nvariable under its mean, is more suitable for risk-averse proposes. This paper\naims at optimizing the mean-semivariance (MSV) criterion in reinforcement\nlearning w.r.t. steady reward distribution. Since semivariance is\ntime-inconsistent and does not satisfy the standard Bellman equation, the\ntraditional dynamic programming methods are inapplicable to MSV problems\ndirectly. To tackle this challenge, we resort to Perturbation Analysis (PA)\ntheory and establish the performance difference formula for MSV. We reveal that\nthe MSV problem can be solved by iteratively solving a sequence of RL problems\nwith a policy-dependent reward function. Further, we propose two on-policy\nalgorithms based on the policy gradient theory and the trust region method.\nFinally, we conduct diverse experiments from simple bandit problems to\ncontinuous control tasks in MuJoCo, which demonstrate the effectiveness of our\nproposed methods.\n","authors":["Xiaoteng Ma","Shuai Ma","Li Xia","Qianchuan Zhao"],"pdf_url":"https://arxiv.org/pdf/2206.07376v3.pdf","comment":"Accecpted by Journal of Artificial Intelligence Research"},{"id":"http://arxiv.org/abs/2303.04475v1","updated":"2023-03-08T09:47:00Z","published":"2023-03-08T09:47:00Z","title":"RACCER: Towards Reachable and Certain Counterfactual Explanations for\n  Reinforcement Learning","summary":"  While reinforcement learning (RL) algorithms have been successfully applied\nto numerous tasks, their reliance on neural networks makes their behavior\ndifficult to understand and trust. Counterfactual explanations are\nhuman-friendly explanations that offer users actionable advice on how to alter\nthe model inputs to achieve the desired output from a black-box system.\nHowever, current approaches to generating counterfactuals in RL ignore the\nstochastic and sequential nature of RL tasks and can produce counterfactuals\nwhich are difficult to obtain or do not deliver the desired outcome. In this\nwork, we propose RACCER, the first RL-specific approach to generating\ncounterfactual explanations for the behaviour of RL agents. We first propose\nand implement a set of RL-specific counterfactual properties that ensure easily\nreachable counterfactuals with highly-probable desired outcomes. We use a\nheuristic tree search of agent's execution trajectories to find the most\nsuitable counterfactuals based on the defined properties. We evaluate RACCER in\ntwo tasks as well as conduct a user study to show that RL-specific\ncounterfactuals help users better understand agent's behavior compared to the\ncurrent state-of-the-art approaches.\n","authors":["Jasmina Gajcin","Ivana Dusparic"],"pdf_url":"https://arxiv.org/pdf/2303.04475v1.pdf","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.03953v2","updated":"2023-03-08T09:35:09Z","published":"2023-03-07T14:59:33Z","title":"ChatGPT: Beginning of an End of Manual Linguistic Data Annotation? Use\n  Case of Automatic Genre Identification","summary":"  ChatGPT has shown strong capabilities in natural language generation tasks,\nwhich naturally leads researchers to explore where its abilities end. In this\npaper, we examine whether ChatGPT can be used for zero-shot text\nclassification, more specifically, automatic genre identification. We compare\nChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on\ndatasets, manually annotated with genres. The models are compared on test sets\nin two languages: English and Slovenian. Results show that ChatGPT outperforms\nthe fine-tuned model when applied to the dataset which was not seen before by\neither of the models. Even when applied on Slovenian language as an\nunder-resourced language, ChatGPT's performance is no worse than when applied\nto English. However, if the model is fully prompted in Slovenian, the\nperformance drops significantly, showing the current limitations of ChatGPT\nusage on smaller languages. The presented results lead us to questioning\nwhether this is the beginning of an end of laborious manual annotation\ncampaigns even for smaller languages, such as Slovenian.\n","authors":["Taja Kuzman","Igor Mozetič","Nikola Ljubešić"],"pdf_url":"https://arxiv.org/pdf/2303.03953v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02101v2","updated":"2023-03-08T09:27:36Z","published":"2023-03-03T17:35:42Z","title":"Configurable calorimeter simulation for AI applications","summary":"  A configurable calorimeter simulation for AI (COCOA) applications is\npresented, based on the Geant4 toolkit and interfaced with the Pythia event\ngenerator. This open-source project is aimed to support the development of\nmachine learning algorithms in high energy physics that rely on realistic\nparticle shower descriptions, such as reconstruction, fast simulation, and\nlow-level analysis. Specifications such as the granularity and material of its\nnearly hermetic geometry are user-configurable. The tool is supplemented with\nsimple event processing including topological clustering, jet algorithms, and a\nnearest-neighbors graph construction. Formatting is also provided to visualise\nevents using the Phoenix event display software.\n","authors":["Francesco Armando Di Bello","Anton Charkin-Gorbulin","Kyle Cranmer","Etienne Dreyer","Sanmay Ganguly","Eilam Gross","Lukas Heinrich","Lorenzo Santi","Marumi Kado","Nilotpal Kakati","Patrick Rieck","Matteo Tusoni"],"pdf_url":"https://arxiv.org/pdf/2303.02101v2.pdf","comment":"9 pages, 11 figures"},{"id":"http://arxiv.org/abs/2303.00573v2","updated":"2023-03-08T09:03:51Z","published":"2023-03-01T15:16:27Z","title":"Dimension-reduced KRnet maps for high-dimensional Bayesian inverse\n  problems","summary":"  We present a dimension-reduced KRnet map approach (DR-KRnet) for\nhigh-dimensional Bayesian inverse problems, which is based on an explicit\nconstruction of a map that pushes forward the prior measure to the posterior\nmeasure in the latent space. Our approach consists of two main components:\ndata-driven VAE prior and density approximation of the posterior of the latent\nvariable. In reality, it may not be trivial to initialize a prior distribution\nthat is consistent with available prior data; in other words, the complex prior\ninformation is often beyond simple hand-crafted priors. We employ variational\nautoencoder (VAE) to approximate the underlying distribution of the prior\ndataset, which is achieved through a latent variable and a decoder. Using the\ndecoder provided by the VAE prior, we reformulate the problem in a\nlow-dimensional latent space. In particular, we seek an invertible transport\nmap given by KRnet to approximate the posterior distribution of the latent\nvariable. Moreover, an efficient physics-constrained surrogate model without\nany labeled data is constructed to reduce the computational cost of solving\nboth forward and adjoint problems involved in likelihood computation. With\nnumerical experiments, we demonstrate the accuracy and efficiency of DR-KRnet\nfor high-dimensional Bayesian inverse problems.\n","authors":["Yani Feng","Kejun Tang","Xiaoliang Wan","Qifeng Liao"],"pdf_url":"https://arxiv.org/pdf/2303.00573v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04452v1","updated":"2023-03-08T09:03:11Z","published":"2023-03-08T09:03:11Z","title":"Grasping Student: semi-supervised learning for robotic manipulation","summary":"  Gathering real-world data from the robot quickly becomes a bottleneck when\nconstructing a robot learning system for grasping. In this work, we design a\nsemi-supervised grasping system that, on top of a small sample of robot\nexperience, takes advantage of images of products to be picked, which are\ncollected without any interactions with the robot. We validate our findings\nboth in the simulation and in the real world. In the regime of a small number\nof robot training samples, taking advantage of the unlabeled data allows us to\nachieve performance at the level of 10-fold bigger dataset size used by the\nbaseline. The code and datasets used in the paper will be released at\nhttps://github.com/nomagiclab/grasping-student.\n","authors":["Piotr Krzywicki","Krzysztof Ciebiera","Rafał Michaluk","Inga Maziarz","Marek Cygan"],"pdf_url":"https://arxiv.org/pdf/2303.04452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04450v1","updated":"2023-03-08T09:00:29Z","published":"2023-03-08T09:00:29Z","title":"Nonlinear Kalman Filtering with Reparametrization Gradients","summary":"  We introduce a novel nonlinear Kalman filter that utilizes reparametrization\ngradients. The widely used parametric approximation is based on a jointly\nGaussian assumption of the state-space model, which is in turn equivalent to\nminimizing an approximation to the Kullback-Leibler divergence. It is possible\nto obtain better approximations using the alpha divergence, but the resulting\nproblem is substantially more complex. In this paper, we introduce an alternate\nformulation based on an energy function, which can be optimized instead of the\nalpha divergence. The optimization can be carried out using reparametrization\ngradients, a technique that has recently been utilized in a number of deep\nlearning models.\n","authors":["San Gultekin","Brendan Kitts","Aaron Flores","John Paisley"],"pdf_url":"https://arxiv.org/pdf/2303.04450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04449v1","updated":"2023-03-08T08:59:04Z","published":"2023-03-08T08:59:04Z","title":"Loss-Curvature Matching for Dataset Selection and Condensation","summary":"  Training neural networks on a large dataset requires substantial\ncomputational costs. Dataset reduction selects or synthesizes data instances\nbased on the large dataset, while minimizing the degradation in generalization\nperformance from the full dataset. Existing methods utilize the neural network\nduring the dataset reduction procedure, so the model parameter becomes\nimportant factor in preserving the performance after reduction. By depending\nupon the importance of parameters, this paper introduces a new reduction\nobjective, coined LCMat, which Matches the Loss Curvatures of the original\ndataset and reduced dataset over the model parameter space, more than the\nparameter point. This new objective induces a better adaptation of the reduced\ndataset on the perturbed parameter region than the exact point matching.\nParticularly, we identify the worst case of the loss curvature gap from the\nlocal parameter region, and we derive the implementable upper bound of such\nworst-case with theoretical analyses. Our experiments on both coreset selection\nand condensation benchmarks illustrate that LCMat shows better generalization\nperformances than existing baselines.\n","authors":["Seungjae Shin","Heesun Bae","Donghyeok Shin","Weonyoung Joo","Il-Chul Moon"],"pdf_url":"https://arxiv.org/pdf/2303.04449v1.pdf","comment":"26th International Conference on Artificial Intelligence and\n  Statistics (AISTATS)"},{"id":"http://arxiv.org/abs/1610.05446v4","updated":"2023-03-08T08:52:31Z","published":"2016-10-18T06:11:23Z","title":"Improving Covariance-Regularized Discriminant Analysis for EHR-based\n  Predictive Analytics of Diseases","summary":"  Linear Discriminant Analysis (LDA) is a well-known technique for feature\nextraction and dimension reduction. The performance of classical LDA, however,\nsignificantly degrades on the High Dimension Low Sample Size (HDLSS) data for\nthe ill-posed inverse problem. Existing approaches for HDLSS data\nclassification typically assume the data in question are with Gaussian\ndistribution and deal the HDLSS classification problem with regularization.\nHowever, these assumptions are too strict to hold in many emerging real-life\napplications, such as enabling personalized predictive analysis using\nElectronic Health Records (EHRs) data collected from an extremely limited\nnumber of patients who have been diagnosed with or without the target disease\nfor prediction. In this paper, we revised the problem of predictive analysis of\ndisease using personal EHR data and LDA classifier. To fill the gap, in this\npaper, we first studied an analytical model that understands the accuracy of\nLDA for classifying data with arbitrary distribution. The model gives a\ntheoretical upper bound of LDA error rate that is controlled by two factors:\n(1) the statistical convergence rate of (inverse) covariance matrix estimators\nand (2) the divergence of the training/testing datasets to fitted\ndistributions. To this end, we could lower the error rate by balancing the two\nfactors for better classification performance. Hereby, we further proposed a\nnovel LDA classifier De-Sparse that leverages De-sparsified Graphical Lasso to\nimprove the estimation of LDA, which outperforms state-of-the-art LDA\napproaches developed for HDLSS data. Such advances and effectiveness are\nfurther demonstrated by both theoretical analysis and extensive experiments on\nEHR datasets.\n","authors":["Sijia Yang","Haoyi Xiong","Kaibo Xu","Licheng Wang","Jiang Bian","Zeyi Sun"],"pdf_url":"https://arxiv.org/pdf/1610.05446v4.pdf","comment":"Sijia Yang wrote the manuscript into to the current version"},{"id":"http://arxiv.org/abs/2303.04445v1","updated":"2023-03-08T08:48:02Z","published":"2023-03-08T08:48:02Z","title":"MKL-$L_{0/1}$-SVM","summary":"  We formulate the Multiple Kernel Learning (abbreviated as MKL) problem for\nthe support vector machine with the infamous $(0,1)$-loss function. Some\nfirst-order optimality conditions are given, which could be readily exploited\nto develop fast numerical solvers e.g., of the ADMM type.\n","authors":["Bin Zhu","Yijie Shi"],"pdf_url":"https://arxiv.org/pdf/2303.04445v1.pdf","comment":"4 pages, 2 figures. Submitted to the 3rd Chinese Conference on\n  Predictive Control and Intelligent Decision (CPCID)"},{"id":"http://arxiv.org/abs/2205.15043v2","updated":"2023-03-08T08:47:23Z","published":"2022-05-30T12:18:43Z","title":"RLx2: Training a Sparse Deep Reinforcement Learning Model from Scratch","summary":"  Training deep reinforcement learning (DRL) models usually requires high\ncomputation costs. Therefore, compressing DRL models possesses immense\npotential for training acceleration and model deployment. However, existing\nmethods that generate small models mainly adopt the knowledge\ndistillation-based approach by iteratively training a dense network. As a\nresult, the training process still demands massive computing resources. Indeed,\nsparse training from scratch in DRL has not been well explored and is\nparticularly challenging due to non-stationarity in bootstrap training. In this\nwork, we propose a novel sparse DRL training framework, \"the Rigged\nReinforcement Learning Lottery\" (RLx2), which builds upon gradient-based\ntopology evolution and is capable of training a sparse DRL model based entirely\non a sparse network. Specifically, RLx2 introduces a novel multi-step TD target\nmechanism with a dynamic-capacity replay buffer to achieve robust value\nlearning and efficient topology exploration in sparse models. It also reaches\nstate-of-the-art sparse training performance in several tasks, showing\n7.5\\times-20\\times model compression with less than 3% performance degradation\nand up to 20\\times and 50\\times FLOPs reduction for training and inference,\nrespectively.\n","authors":["Yiqin Tan","Pihe Hu","Ling Pan","Jiatai Huang","Longbo Huang"],"pdf_url":"https://arxiv.org/pdf/2205.15043v2.pdf","comment":"ICLR 2023 spotlight"},{"id":"http://arxiv.org/abs/2303.04440v1","updated":"2023-03-08T08:42:03Z","published":"2023-03-08T08:42:03Z","title":"HyT-NAS: Hybrid Transformers Neural Architecture Search for Edge Devices","summary":"  Vision Transformers have enabled recent attention-based Deep Learning (DL)\narchitectures to achieve remarkable results in Computer Vision (CV) tasks.\nHowever, due to the extensive computational resources required, these\narchitectures are rarely implemented on resource-constrained platforms. Current\nresearch investigates hybrid handcrafted convolution-based and attention-based\nmodels for CV tasks such as image classification and object detection. In this\npaper, we propose HyT-NAS, an efficient Hardware-aware Neural Architecture\nSearch (HW-NAS) including hybrid architectures targeting vision tasks on tiny\ndevices. HyT-NAS improves state-of-the-art HW-NAS by enriching the search space\nand enhancing the search strategy as well as the performance predictors. Our\nexperiments show that HyT-NAS achieves a similar hypervolume with less than ~5x\ntraining evaluations. Our resulting architecture outperforms MLPerf MobileNetV1\nby 6.3% accuracy improvement with 3.5x less number of parameters on Visual Wake\nWords.\n","authors":["Lotfi Abdelkrim Mecharbat","Hadjer Benmeziane","Hamza Ouranoughi","Smail Niar"],"pdf_url":"https://arxiv.org/pdf/2303.04440v1.pdf","comment":"CODAI 2022 Workshop - Embedded System Week (ESWeek)"},{"id":"http://arxiv.org/abs/2303.04437v1","updated":"2023-03-08T08:35:29Z","published":"2023-03-08T08:35:29Z","title":"Learning Hybrid Interpretable Models: Theory, Taxonomy, and Methods","summary":"  A hybrid model involves the cooperation of an interpretable model and a\ncomplex black box. At inference, any input of the hybrid model is assigned to\neither its interpretable or complex component based on a gating mechanism. The\nadvantages of such models over classical ones are two-fold: 1) They grant users\nprecise control over the level of transparency of the system and 2) They can\npotentially perform better than a standalone black box since redirecting some\nof the inputs to an interpretable model implicitly acts as regularization.\nStill, despite their high potential, hybrid models remain under-studied in the\ninterpretability/explainability literature. In this paper, we remedy this fact\nby presenting a thorough investigation of such models from three perspectives:\nTheory, Taxonomy, and Methods. First, we explore the theory behind the\ngeneralization of hybrid models from the Probably-Approximately-Correct (PAC)\nperspective. A consequence of our PAC guarantee is the existence of a sweet\nspot for the optimal transparency of the system. When such a sweet spot is\nattained, a hybrid model can potentially perform better than a standalone black\nbox. Secondly, we provide a general taxonomy for the different ways of training\nhybrid models: the Post-Black-Box and Pre-Black-Box paradigms. These approaches\ndiffer in the order in which the interpretable and complex components are\ntrained. We show where the state-of-the-art hybrid models Hybrid-Rule-Set and\nCompanion-Rule-List fall in this taxonomy. Thirdly, we implement the two\nparadigms in a single method: HybridCORELS, which extends the CORELS algorithm\nto hybrid modeling. By leveraging CORELS, HybridCORELS provides a certificate\nof optimality of its interpretable component and precise control over\ntransparency. We finally show empirically that HybridCORELS is competitive with\nexisting hybrid models, and performs just as well as a standalone black box (or\neven better) while being partly transparent.\n","authors":["Julien Ferry","Gabriel Laberge","Ulrich Aïvodji"],"pdf_url":"https://arxiv.org/pdf/2303.04437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04436v1","updated":"2023-03-08T08:31:06Z","published":"2023-03-08T08:31:06Z","title":"A comparison of rational and neural network based approximations","summary":"  Rational and neural network based approximations are efficient tools in\nmodern approximation. These approaches are able to produce accurate\napproximations to nonsmooth and non-Lipschitz functions, including multivariate\ndomain functions. In this paper we compare the efficiency of function\napproximation using rational approximation, neural network and their\ncombinations. It was found that rational approximation is superior to neural\nnetwork based approaches with the same number of decision variables. Our\nnumerical experiments demonstrate the efficiency of rational approximation,\neven when the number of approximation parameters (that is, the dimension of the\ncorresponding optimisation problems) is small. Another important contribution\nof this paper lies in the improvement of rational approximation algorithms.\nNamely, the optimisation based algorithms for rational approximation can be\nadjusted to in such a way that the conditioning number of the constraint\nmatrices are controlled. This simple adjustment enables us to work with high\ndimension optimisation problems and improve the design of the neural network.\nThe main strength of neural networks is in their ability to handle models with\na large number of variables: complex models are decomposed in several simple\noptimisation problems. Therefore the the large number of decision variables is\nin the nature of neural networks.\n","authors":["Vinesha Peiris","Reinier Diaz Millan","Nadezda Sukhorukova","Julien Ugon"],"pdf_url":"https://arxiv.org/pdf/2303.04436v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2303.04435v1","updated":"2023-03-08T08:27:31Z","published":"2023-03-08T08:27:31Z","title":"A Message Passing Perspective on Learning Dynamics of Contrastive\n  Learning","summary":"  In recent years, contrastive learning achieves impressive results on\nself-supervised visual representation learning, but there still lacks a\nrigorous understanding of its learning dynamics. In this paper, we show that if\nwe cast a contrastive objective equivalently into the feature space, then its\nlearning dynamics admits an interpretable form. Specifically, we show that its\ngradient descent corresponds to a specific message passing scheme on the\ncorresponding augmentation graph. Based on this perspective, we theoretically\ncharacterize how contrastive learning gradually learns discriminative features\nwith the alignment update and the uniformity update. Meanwhile, this\nperspective also establishes an intriguing connection between contrastive\nlearning and Message Passing Graph Neural Networks (MP-GNNs). This connection\nnot only provides a unified understanding of many techniques independently\ndeveloped in each community, but also enables us to borrow techniques from\nMP-GNNs to design new contrastive learning variants, such as graph attention,\ngraph rewiring, jumpy knowledge techniques, etc. We believe that our message\npassing perspective not only provides a new theoretical understanding of\ncontrastive learning dynamics, but also bridges the two seemingly independent\nareas together, which could inspire more interleaving studies to benefit from\neach other. The code is available at\nhttps://github.com/PKU-ML/Message-Passing-Contrastive-Learning.\n","authors":["Yifei Wang","Qi Zhang","Tianqi Du","Jiansheng Yang","Zhouchen Lin","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2303.04435v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00111v2","updated":"2023-03-08T07:55:37Z","published":"2023-02-28T22:26:18Z","title":"PixCUE: Joint Uncertainty Estimation and Image Reconstruction in MRI\n  using Deep Pixel Classification","summary":"  Deep learning (DL) models are capable of successfully exploiting latent\nrepresentations in MR data and have become state-of-the-art for accelerated MRI\nreconstruction. However, undersampling the measurements in k-space as well as\nthe over- or under-parameterized and non-transparent nature of DL make these\nmodels exposed to uncertainty. Consequently, uncertainty estimation has become\na major issue in DL MRI reconstruction. To estimate uncertainty, Monte Carlo\n(MC) inference techniques have become a common practice where multiple\nreconstructions are utilized to compute the variance in reconstruction as a\nmeasurement of uncertainty. However, these methods demand high computational\ncosts as they require multiple inferences through the DL model. To this end, we\nintroduce a method to estimate uncertainty during MRI reconstruction using a\npixel classification framework. The proposed method, PixCUE (stands for Pixel\nClassification Uncertainty Estimation) produces the reconstructed image along\nwith an uncertainty map during a single forward pass through the DL model. We\ndemonstrate that this approach generates uncertainty maps that highly correlate\nwith the reconstruction errors with respect to various MR imaging sequences and\nunder numerous adversarial conditions. We also show that the estimated\nuncertainties are correlated to that of the conventional MC method. We further\nprovide an empirical relationship between the uncertainty estimations using\nPixCUE and well-established reconstruction metrics such as NMSE, PSNR, and\nSSIM. We conclude that PixCUE is capable of reliably estimating the uncertainty\nin MRI reconstruction with a minimum additional computational cost.\n","authors":["Mevan Ekanayake","Kamlesh Pawar","Gary Egan","Zhaolin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00111v2.pdf","comment":"19 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2303.04418v1","updated":"2023-03-08T07:45:06Z","published":"2023-03-08T07:45:06Z","title":"FUSQA: Fetal Ultrasound Segmentation Quality Assessment","summary":"  Deep learning models have been effective for various fetal ultrasound\nsegmentation tasks. However, generalization to new unseen data has raised\nquestions about their effectiveness for clinical adoption. Normally, a\ntransition to new unseen data requires time-consuming and costly quality\nassurance processes to validate the segmentation performance post-transition.\nSegmentation quality assessment efforts have focused on natural images, where\nthe problem has been typically formulated as a dice score regression task. In\nthis paper, we propose a simplified Fetal Ultrasound Segmentation Quality\nAssessment (FUSQA) model to tackle the segmentation quality assessment when no\nmasks exist to compare with. We formulate the segmentation quality assessment\nprocess as an automated classification task to distinguish between good and\npoor-quality segmentation masks for more accurate gestational age estimation.\nWe validate the performance of our proposed approach on two datasets we collect\nfrom two hospitals using different ultrasound machines. We compare different\narchitectures, with our best-performing architecture achieving over 90%\nclassification accuracy on distinguishing between good and poor-quality\nsegmentation masks from an unseen dataset. Additionally, there was only a\n1.45-day difference between the gestational age reported by doctors and\nestimated based on CRL measurements using well-segmented masks. On the other\nhand, this difference increased and reached up to 7.73 days when we calculated\nCRL from the poorly segmented masks. As a result, AI-based approaches can\npotentially aid fetal ultrasound segmentation quality assessment and might\ndetect poor segmentation in real-time screening in the future.\n","authors":["Sevim Cengiz","Ibrahim Almakk","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2303.04418v1.pdf","comment":"13 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.04416v1","updated":"2023-03-08T07:42:47Z","published":"2023-03-08T07:42:47Z","title":"Inference on Optimal Dynamic Policies via Softmax Approximation","summary":"  Estimating optimal dynamic policies from offline data is a fundamental\nproblem in dynamic decision making. In the context of causal inference, the\nproblem is known as estimating the optimal dynamic treatment regime. Even\nthough there exists a plethora of methods for estimation, constructing\nconfidence intervals for the value of the optimal regime and structural\nparameters associated with it is inherently harder, as it involves non-linear\nand non-differentiable functionals of un-known quantities that need to be\nestimated. Prior work resorted to sub-sample approaches that can deteriorate\nthe quality of the estimate. We show that a simple soft-max approximation to\nthe optimal treatment regime, for an appropriately fast growing temperature\nparameter, can achieve valid inference on the truly optimal regime. We\nillustrate our result for a two-period optimal dynamic regime, though our\napproach should directly extend to the finite horizon case. Our work combines\ntechniques from semi-parametric inference and $g$-estimation, together with an\nappropriate triangular array central limit theorem, as well as a novel analysis\nof the asymptotic influence and asymptotic bias of softmax approximations.\n","authors":["Qizhao Chen","Morgane Austern","Vasilis Syrgkanis"],"pdf_url":"https://arxiv.org/pdf/2303.04416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03323v2","updated":"2023-03-08T07:04:14Z","published":"2023-03-06T17:48:32Z","title":"CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive\n  Learning","summary":"  Multimodal contrastive pretraining has been used to train multimodal\nrepresentation models, such as CLIP, on large amounts of paired image-text\ndata. However, previous studies have revealed that such models are vulnerable\nto backdoor attacks. Specifically, when trained on backdoored examples, CLIP\nlearns spurious correlations between the embedded backdoor trigger and the\ntarget label, aligning their representations in the joint embedding space.\nInjecting even a small number of poisoned examples, such as 75 examples in 3\nmillion pretraining data, can significantly manipulate the model's behavior,\nmaking it difficult to detect or unlearn such correlations. To address this\nissue, we propose CleanCLIP, a finetuning framework that weakens the learned\nspurious associations introduced by backdoor attacks by independently\nre-aligning the representations for individual modalities. We demonstrate that\nunsupervised finetuning using a combination of multimodal contrastive and\nunimodal self-supervised objectives for individual modalities can significantly\nreduce the impact of the backdoor attack. Additionally, we show that supervised\nfinetuning on task-specific labeled image data removes the backdoor trigger\nfrom the CLIP vision encoder. We show empirically that CleanCLIP maintains\nmodel performance on benign examples while erasing a range of backdoor attacks\non multimodal contrastive learning.\n","authors":["Hritik Bansal","Nishad Singhi","Yu Yang","Fan Yin","Aditya Grover","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03323v2.pdf","comment":"20 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2303.02918v2","updated":"2023-03-08T06:37:55Z","published":"2023-03-06T06:28:20Z","title":"Graph Positional Encoding via Random Feature Propagation","summary":"  Two main families of node feature augmentation schemes have been explored for\nenhancing GNNs: random features and spectral positional encoding. Surprisingly,\nhowever, there is still no clear understanding of the relation between these\ntwo augmentation schemes. Here we propose a novel family of positional encoding\nschemes which draws a link between the above two approaches and improves over\nboth. The new approach, named Random Feature Propagation (RFP), is inspired by\nthe power iteration method and its generalizations. It concatenates several\nintermediate steps of an iterative algorithm for computing the dominant\neigenvectors of a propagation matrix, starting from random node features.\nNotably, these propagation steps are based on graph-dependent propagation\noperators that can be either predefined or learned. We explore the theoretical\nand empirical benefits of RFP. First, we provide theoretical justifications for\nusing random features, for incorporating early propagation steps, and for using\nmultiple random initializations. Then, we empirically demonstrate that RFP\nsignificantly outperforms both spectral PE and random features in multiple node\nclassification and graph classification benchmarks.\n","authors":["Moshe Eliasof","Fabrizio Frasca","Beatrice Bevilacqua","Eran Treister","Gal Chechik","Haggai Maron"],"pdf_url":"https://arxiv.org/pdf/2303.02918v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04397v1","updated":"2023-03-08T06:14:55Z","published":"2023-03-08T06:14:55Z","title":"The Lie-Group Bayesian Learning Rule","summary":"  The Bayesian Learning Rule provides a framework for generic algorithm design\nbut can be difficult to use for three reasons. First, it requires a specific\nparameterization of exponential family. Second, it uses gradients which can be\ndifficult to compute. Third, its update may not always stay on the manifold. We\naddress these difficulties by proposing an extension based on Lie-groups where\nposteriors are parametrized through transformations of an arbitrary base\ndistribution and updated via the group's exponential map. This simplifies all\nthree difficulties for many cases, providing flexible parametrizations through\ngroup's action, simple gradient computation through reparameterization, and\nupdates that always stay on the manifold. We use the new learning rule to\nderive a new algorithm for deep learning with desirable biologically-plausible\nattributes to learn sparse features. Our work opens a new frontier for the\ndesign of new algorithms by exploiting Lie-group structures.\n","authors":["Eren Mehmet Kıral","Thomas Möllenhoff","Mohammad Emtiyaz Khan"],"pdf_url":"https://arxiv.org/pdf/2303.04397v1.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2206.08289v3","updated":"2023-03-08T06:00:29Z","published":"2022-06-16T16:46:32Z","title":"Switchable Representation Learning Framework with Self-compatibility","summary":"  Real-world visual search systems involve deployments on multiple platforms\nwith different computing and storage resources. Deploying a unified model that\nsuits the minimal-constrain platforms leads to limited accuracy. It is expected\nto deploy models with different capacities adapting to the resource\nconstraints, which requires features extracted by these models to be aligned in\nthe metric space. The method to achieve feature alignments is called\n``compatible learning''. Existing research mainly focuses on the one-to-one\ncompatible paradigm, which is limited in learning compatibility among multiple\nmodels. We propose a Switchable representation learning Framework with\nSelf-Compatibility (SFSC). SFSC generates a series of compatible sub-models\nwith different capacities through one training process. The optimization of\nsub-models faces gradients conflict, and we mitigate this problem from the\nperspective of the magnitude and direction. We adjust the priorities of\nsub-models dynamically through uncertainty estimation to co-optimize sub-models\nproperly. Besides, the gradients with conflicting directions are projected to\navoid mutual interference. SFSC achieves state-of-the-art performance on the\nevaluated datasets.\n","authors":["Shengsen Wu","Yan Bai","Yihang Lou","Xiongkun Linghu","Jianzhong He","Ling-Yu Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08289v3.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.04391v1","updated":"2023-03-08T05:52:58Z","published":"2023-03-08T05:52:58Z","title":"A Deep-Learning-Based Neural Decoding Framework for Emotional\n  Brain-Computer Interfaces","summary":"  Reading emotions precisely from segments of neural activity is crucial for\nthe development of emotional brain-computer interfaces. Among all neural\ndecoding algorithms, deep learning (DL) holds the potential to become the most\npromising one, yet progress has been limited in recent years. One possible\nreason is that the efficacy of DL strongly relies on training samples, yet the\nneural data used for training are often from non-human primates and mixed with\nplenty of noise, which in turn mislead the training of DL models. Given it is\ndifficult to accurately determine animals' emotions from humans' perspective,\nwe assume the dominant noise in neural data representing different emotions is\nthe labeling error. Here, we report the development and application of a neural\ndecoding framework called Emo-Net that consists of a confidence learning (CL)\ncomponent and a DL component. The framework is fully data-driven and is capable\nof decoding emotions from multiple datasets obtained from behaving monkeys. In\naddition to improving the decoding ability, Emo-Net significantly improves the\nperformance of the base DL models, making emotion recognition in animal models\npossible. In summary, this framework may inspire novel understandings of the\nneural basis of emotion and drive the realization of close-loop emotional\nbrain-computer interfaces.\n","authors":["Xinming Wu","Ji Dai"],"pdf_url":"https://arxiv.org/pdf/2303.04391v1.pdf","comment":"22 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.11231v2","updated":"2023-03-08T05:52:48Z","published":"2023-02-22T09:22:13Z","title":"Drugs Resistance Analysis from Scarce Health Records via Multi-task\n  Graph Representation","summary":"  Clinicians prescribe antibiotics by looking at the patient's health record\nwith an experienced eye. However, the therapy might be rendered futile if the\npatient has drug resistance. Determining drug resistance requires\ntime-consuming laboratory-level testing while applying clinicians' heuristics\nin an automated way is difficult due to the categorical or binary medical\nevents that constitute health records. In this paper, we propose a novel\nframework for rapid clinical intervention by viewing health records as graphs\nwhose nodes are mapped from medical events and edges as correspondence between\nevents in given a time window. A novel graph-based model is then proposed to\nextract informative features and yield automated drug resistance analysis from\nthose high-dimensional and scarce graphs. The proposed method integrates\nmulti-task learning into a common feature extracting graph encoder for\nsimultaneous analyses of multiple drugs as well as stabilizing learning. On a\nmassive dataset comprising over 110,000 patients with urinary tract infections,\nwe verify the proposed method is capable of attaining superior performance on\nthe drug resistance prediction problem. Furthermore, automated drug\nrecommendations resemblant to laboratory-level testing can also be made based\non the model resistance analysis.\n","authors":["Honglin Shu","Pei Gao","Lingwei Zhu","Zheng Chen"],"pdf_url":"https://arxiv.org/pdf/2302.11231v2.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.04386v1","updated":"2023-03-08T05:19:08Z","published":"2023-03-08T05:19:08Z","title":"Policy Mirror Descent Inherently Explores Action Space","summary":"  Designing computationally efficient exploration strategies for on-policy\nfirst-order methods that attain optimal $\\mathcal{O}(1/\\epsilon^2)$ sample\ncomplexity remains open for solving Markov decision processes (MDP). This\nmanuscript provides an answer to this question from a perspective of\nsimplicity, by showing that whenever exploration over the state space is\nimplied by the MDP structure, there seems to be little need for sophisticated\nexploration strategies. We revisit a stochastic policy gradient method, named\nstochastic policy mirror descent, applied to the infinite horizon, discounted\nMDP with finite state and action spaces. Accompanying SPMD we present two\non-policy evaluation operators, both simply following the policy for trajectory\ncollection with no explicit exploration, or any form of intervention. SPMD with\nthe first evaluation operator, named value-based estimation, tailors to the\nKullback-Leibler (KL) divergence. Provided the Markov chains on the state space\nof generated policies are uniformly mixing with non-diminishing minimal\nvisitation measure, an $\\tilde{\\mathcal{O}}( 1 / \\epsilon^2)$ sample complexity\nis obtained with a linear dependence on the size of the action space. SPMD with\nthe second evaluation operator, named truncated on-policy Monte Carlo, attains\nan $\\tilde{\\mathcal{O}}(\\mathcal{H}_{\\mathcal{D}} / \\epsilon^2)$ sample\ncomplexity, with the same assumption on the state chains of generated policies.\nWe characterize $\\mathcal{H}_{\\mathcal{D}}$ as a divergence-dependent function\nof the effective horizon and the size of the action space, which leads to an\nexponential dependence of the latter two quantities for the KL divergence, and\na polynomial dependence for the divergence induced by negative Tsallis entropy.\nThese obtained sample complexities seem to be new among on-policy stochastic\npolicy gradient methods without explicit explorations.\n","authors":["Yan Li","Guanghui Lan"],"pdf_url":"https://arxiv.org/pdf/2303.04386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04381v1","updated":"2023-03-08T05:09:59Z","published":"2023-03-08T05:09:59Z","title":"Automatically Auditing Large Language Models via Discrete Optimization","summary":"  Auditing large language models for unexpected behaviors is critical to\npreempt catastrophic deployments, yet remains challenging. In this work, we\ncast auditing as an optimization problem, where we automatically search for\ninput-output pairs that match a desired target behavior. For example, we might\naim to find a non-toxic input that starts with \"Barack Obama\" that a model maps\nto a toxic output. This optimization problem is difficult to solve as the set\nof feasible points is sparse, the space is discrete, and the language models we\naudit are non-linear and high-dimensional. To combat these challenges, we\nintroduce a discrete optimization algorithm, ARCA, that jointly and efficiently\noptimizes over inputs and outputs. Our approach automatically uncovers\nderogatory completions about celebrities (e.g. \"Barack Obama is a legalized\nunborn\" -> \"child murderer\"), produces French inputs that complete to English\noutputs, and finds inputs that generate a specific name. Our work offers a\npromising new tool to uncover models' failure-modes before deployment.\n","authors":["Erik Jones","Anca Dragan","Aditi Raghunathan","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2303.04381v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04379v1","updated":"2023-03-08T05:05:01Z","published":"2023-03-08T05:05:01Z","title":"HappyMap: A Generalized Multi-calibration Method","summary":"  Multi-calibration is a powerful and evolving concept originating in the field\nof algorithmic fairness. For a predictor $f$ that estimates the outcome $y$\ngiven covariates $x$, and for a function class $\\mathcal{C}$, multi-calibration\nrequires that the predictor $f(x)$ and outcome $y$ are indistinguishable under\nthe class of auditors in $\\mathcal{C}$. Fairness is captured by incorporating\ndemographic subgroups into the class of functions~$\\mathcal{C}$. Recent work\nhas shown that, by enriching the class $\\mathcal{C}$ to incorporate appropriate\npropensity re-weighting functions, multi-calibration also yields\ntarget-independent learning, wherein a model trained on a source domain\nperforms well on unseen, future, target domains(approximately) captured by the\nre-weightings.\n  Formally, multi-calibration with respect to $\\mathcal{C}$ bounds\n$\\big|\\mathbb{E}_{(x,y)\\sim \\mathcal{D}}[c(f(x),x)\\cdot(f(x)-y)]\\big|$ for all\n$c \\in \\mathcal{C}$. In this work, we view the term $(f(x)-y)$ as just one\nspecific mapping, and explore the power of an enriched class of mappings. We\npropose \\textit{HappyMap}, a generalization of multi-calibration, which yields\na wide range of new applications, including a new fairness notion for\nuncertainty quantification (conformal prediction), a novel technique for\nconformal prediction under covariate shift, and a different approach to\nanalyzing missing data, while also yielding a unified understanding of several\nexisting seemingly disparate algorithmic fairness notions and\ntarget-independent learning approaches.\n  We give a single \\textit{HappyMap} meta-algorithm that captures all these\nresults, together with a sufficiency condition for its success.\n","authors":["Zhun Deng","Cynthia Dwork","Linjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.04379v1.pdf","comment":"Appeared at ITCS 2023 (submitted on Sept. 8th, 2022)"},{"id":"http://arxiv.org/abs/2202.12872v2","updated":"2023-03-08T04:39:40Z","published":"2022-02-25T18:27:27Z","title":"AutoFR: Automated Filter Rule Generation for Adblocking","summary":"  Adblocking relies on filter lists, which are manually curated and maintained\nby a community of filter list authors. Filter list curation is a laborious\nprocess that does not scale well to a large number of sites or over time. In\nthis paper, we introduce AutoFR, a reinforcement learning framework to fully\nautomate the process of filter rule creation and evaluation for sites of\ninterest. We design an algorithm based on multi-arm bandits to generate filter\nrules that block ads while controlling the trade-off between blocking ads and\navoiding visual breakage. We test AutoFR on thousands of sites and we show that\nit is efficient: it takes only a few minutes to generate filter rules for a\nsite of interest. AutoFR is effective: it generates filter rules that can block\n86% of the ads, as compared to 87% by EasyList, while achieving comparable\nvisual breakage. Furthermore, AutoFR generates filter rules that generalize\nwell to new sites. We envision that AutoFR can assist the adblocking community\nin filter rule generation at scale.\n","authors":["Hieu Le","Salma Elmalaki","Athina Markopoulou","Zubair Shafiq"],"pdf_url":"https://arxiv.org/pdf/2202.12872v2.pdf","comment":"16 pages with 13 figures, 3 tables, 1 algorithm. 3.5 pages of\n  references. Appendices include 10 pages of appendices with 11 figures and 3\n  tables"},{"id":"http://arxiv.org/abs/2303.04366v1","updated":"2023-03-08T04:27:46Z","published":"2023-03-08T04:27:46Z","title":"Semantically Consistent Multi-view Representation Learning","summary":"  In this work, we devote ourselves to the challenging task of Unsupervised\nMulti-view Representation Learning (UMRL), which requires learning a unified\nfeature representation from multiple views in an unsupervised manner. Existing\nUMRL methods mainly concentrate on the learning process in the feature space\nwhile ignoring the valuable semantic information hidden in different views. To\naddress this issue, we propose a novel Semantically Consistent Multi-view\nRepresentation Learning (SCMRL), which makes efforts to excavate underlying\nmulti-view semantic consensus information and utilize the information to guide\nthe unified feature representation learning. Specifically, SCMRL consists of a\nwithin-view reconstruction module and a unified feature representation learning\nmodule, which are elegantly integrated by the contrastive learning strategy to\nsimultaneously align semantic labels of both view-specific feature\nrepresentations and the learned unified feature representation. In this way,\nthe consensus information in the semantic space can be effectively exploited to\nconstrain the learning process of unified feature representation. Compared with\nseveral state-of-the-art algorithms, extensive experiments demonstrate its\nsuperiority.\n","authors":["Yiyang Zhou","Qinghai Zheng","Shunshun Bai","Jihua Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.04366v1.pdf","comment":"19 pages, 4figures"},{"id":"http://arxiv.org/abs/2302.13053v2","updated":"2023-03-08T04:13:48Z","published":"2023-02-25T10:42:34Z","title":"RETEXO: Scalable Neural Network Training over Distributed Graphs","summary":"  Graph neural networks offer a promising approach to supervised learning over\ngraph data. Graph data, especially when it is privacy-sensitive or too large to\ntrain on centrally, is often stored partitioned across disparate processing\nunits (clients) which want to minimize the communication costs during\ncollaborative training. The fully-distributed setup takes such partitioning to\nits extreme, wherein features of only a single node and its adjacent edges are\nkept locally with one client processor. Existing GNNs are not architected for\ntraining in such setups and incur prohibitive costs therein. We propose RETEXO,\na novel transformation of existing GNNs that improves the communication\nefficiency during training in the fully-distributed setup. We experimentally\nconfirm that RETEXO offers up to 6 orders of magnitude better communication\nefficiency even when training shallow GNNs, with a minimal trade-off in\naccuracy for supervised node classification tasks.\n","authors":["Aashish Kolluri","Sarthak Choudhary","Bryan Hooi","Prateek Saxena"],"pdf_url":"https://arxiv.org/pdf/2302.13053v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04364v1","updated":"2023-03-08T04:10:04Z","published":"2023-03-08T04:10:04Z","title":"Dynamic Scenario Representation Learning for Motion Forecasting with\n  Heterogeneous Graph Convolutional Recurrent Networks","summary":"  Due to the complex and changing interactions in dynamic scenarios, motion\nforecasting is a challenging problem in autonomous driving. Most existing works\nexploit static road graphs to characterize scenarios and are limited in\nmodeling evolving spatio-temporal dependencies in dynamic scenarios. In this\npaper, we resort to dynamic heterogeneous graphs to model the scenario. Various\nscenario components including vehicles (agents) and lanes, multi-type\ninteractions, and their changes over time are jointly encoded. Furthermore, we\ndesign a novel heterogeneous graph convolutional recurrent network, aggregating\ndiverse interaction information and capturing their evolution, to learn to\nexploit intrinsic spatio-temporal dependencies in dynamic graphs and obtain\neffective representations of dynamic scenarios. Finally, with a motion\nforecasting decoder, our model predicts realistic and multi-modal future\ntrajectories of agents and outperforms state-of-the-art published works on\nseveral motion forecasting benchmarks.\n","authors":["Xing Gao","Xiaogang Jia","Yikang Li","Hongkai Xiong"],"pdf_url":"https://arxiv.org/pdf/2303.04364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04360v1","updated":"2023-03-08T03:56:31Z","published":"2023-03-08T03:56:31Z","title":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining?","summary":"  Recent advancements in large language models (LLMs) have led to the\ndevelopment of highly potent models like OpenAI's ChatGPT. These models have\nexhibited exceptional performance in a variety of tasks, such as question\nanswering, essay composition, and code generation. However, their effectiveness\nin the healthcare sector remains uncertain. In this study, we seek to\ninvestigate the potential of ChatGPT to aid in clinical text mining by\nexamining its ability to extract structured information from unstructured\nhealthcare texts, with a focus on biological named entity recognition and\nrelation extraction. However, our preliminary results indicate that employing\nChatGPT directly for these tasks resulted in poor performance and raised\nprivacy concerns associated with uploading patients' information to the ChatGPT\nAPI. To overcome these limitations, we propose a new training paradigm that\ninvolves generating a vast quantity of high-quality synthetic data with labels\nutilizing ChatGPT and fine-tuning a local model for the downstream task. Our\nmethod has resulted in significant improvements in the performance of\ndownstream tasks, improving the F1-score from 23.37% to 63.99% for the named\nentity recognition task and from 75.86% to 83.59% for the relation extraction\ntask. Furthermore, generating data using ChatGPT can significantly reduce the\ntime and effort required for data collection and labeling, as well as mitigate\ndata privacy concerns. In summary, the proposed framework presents a promising\nsolution to enhance the applicability of LLM models to clinical text mining.\n","authors":["Ruixiang Tang","Xiaotian Han","Xiaoqian Jiang","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2303.04360v1.pdf","comment":"10 pages, 8 tables, 4 figures"},{"id":"http://arxiv.org/abs/2303.03648v2","updated":"2023-03-08T03:54:29Z","published":"2023-03-07T04:36:35Z","title":"Can Membership Inferencing be Refuted?","summary":"  Membership inference (MI) attack is currently the most popular test for\nmeasuring privacy leakage in machine learning models. Given a machine learning\nmodel, a data point and some auxiliary information, the goal of an MI attack is\nto determine whether the data point was used to train the model. In this work,\nwe study the reliability of membership inference attacks in practice.\nSpecifically, we show that a model owner can plausibly refute the result of a\nmembership inference test on a data point $x$ by constructing a proof of\nrepudiation that proves that the model was trained without $x$. We design\nefficient algorithms to construct proofs of repudiation for all data points of\nthe training dataset. Our empirical evaluation demonstrates the practical\nfeasibility of our algorithm by constructing proofs of repudiation for popular\nmachine learning models on MNIST and CIFAR-10. Consequently, our results call\nfor a re-evaluation of the implications of membership inference attacks in\npractice.\n","authors":["Zhifeng Kong","Amrita Roy Chowdhury","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2303.03648v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04356v1","updated":"2023-03-08T03:32:50Z","published":"2023-03-08T03:32:50Z","title":"Soft Actor-Critic Algorithm with Truly Inequality Constraint","summary":"  Soft actor-critic (SAC) in reinforcement learning is expected to be one of\nthe next-generation robot control schemes. Its ability to maximize policy\nentropy would make a robotic controller robust to noise and perturbation, which\nis useful for real-world robot applications. However, the priority of\nmaximizing the policy entropy is automatically tuned in the current\nimplementation, the rule of which can be interpreted as one for equality\nconstraint, binding the policy entropy into its specified target value. The\ncurrent SAC is therefore no longer maximize the policy entropy, contrary to our\nexpectation. To resolve this issue in SAC, this paper improves its\nimplementation with a slack variable for appropriately handling the inequality\nconstraint to maximize the policy entropy. In Mujoco and Pybullet simulators,\nthe modified SAC achieved the higher robustness and the more stable learning\nthan before while regularizing the norm of action. In addition, a real-robot\nvariable impedance task was demonstrated for showing the applicability of the\nmodified SAC to real-world robot control.\n","authors":["Taisuke Kobayashi"],"pdf_url":"https://arxiv.org/pdf/2303.04356v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.04345v1","updated":"2023-03-08T02:52:40Z","published":"2023-03-08T02:52:40Z","title":"Federated Learning via Variational Bayesian Inference: Personalization,\n  Sparsity and Clustering","summary":"  Federated learning (FL) is a promising framework that models distributed\nmachine learning while protecting the privacy of clients. However, FL suffers\nperformance degradation from heterogeneous and limited data. To alleviate the\ndegradation, we present a novel personalized Bayesian FL approach named\npFedBayes. By using the trained global distribution from the server as the\nprior distribution of each client, each client adjusts its own distribution by\nminimizing the sum of the reconstruction error over its personalized data and\nthe KL divergence with the downloaded global distribution. Then, we propose a\nsparse personalized Bayesian FL approach named sFedBayes. To overcome the\nextreme heterogeneity in non-i.i.d. data, we propose a clustered Bayesian FL\nmodel named cFedbayes by learning different prior distributions for different\nclients. Theoretical analysis gives the generalization error bound of three\napproaches and shows that the generalization error convergence rates of the\nproposed approaches achieve minimax optimality up to a logarithmic factor.\nMoreover, the analysis presents that cFedbayes has a tighter generalization\nerror rate than pFedBayes. Numerous experiments are provided to demonstrate\nthat the proposed approaches have better performance than other advanced\npersonalized methods on private models in the presence of heterogeneous and\nlimited data.\n","authors":["Xu Zhang","Wenpeng Li","Yunfeng Shao","Yinchuan Li"],"pdf_url":"https://arxiv.org/pdf/2303.04345v1.pdf","comment":"17 pages, 19 figures"},{"id":"http://arxiv.org/abs/2210.13795v2","updated":"2023-03-08T02:51:32Z","published":"2022-10-25T06:57:00Z","title":"Line Graph Contrastive Learning for Link Prediction","summary":"  Link prediction tasks focus on predicting possible future connections. Most\nexisting researches measure the likelihood of links by different similarity\nscores on node pairs and predict links between nodes. However, the\nsimilarity-based approaches have some challenges in information loss on nodes\nand generalization ability on similarity indexes. To address the above issues,\nwe propose a Line Graph Contrastive Learning(LGCL) method to obtain rich\ninformation with multiple perspectives. LGCL obtains a subgraph view by h-hop\nsubgraph sampling with target node pairs. After transforming the sampled\nsubgraph into a line graph, the link prediction task is converted into a node\nclassification task, which graph convolution progress can learn edge embeddings\nfrom graphs more effectively. Then we design a novel cross-scale contrastive\nlearning framework on the line graph and the subgraph to maximize the mutual\ninformation of them, so that fuses the structure and feature information. The\nexperimental results demonstrate that the proposed LGCL outperforms the\nstate-of-the-art methods and has better performance on generalization and\nrobustness.\n","authors":["Zehua Zhang","Shilin Sun","Guixiang Ma","Caiming Zhong"],"pdf_url":"https://arxiv.org/pdf/2210.13795v2.pdf","comment":"37 pages"},{"id":"http://arxiv.org/abs/2303.04340v1","updated":"2023-03-08T02:33:17Z","published":"2023-03-08T02:33:17Z","title":"Privacy-preserving and Uncertainty-aware Federated Trajectory Prediction\n  for Connected Autonomous Vehicles","summary":"  Deep learning is the method of choice for trajectory prediction for\nautonomous vehicles. Unfortunately, its data-hungry nature implicitly requires\nthe availability of sufficiently rich and high-quality centralized datasets,\nwhich easily leads to privacy leakage. Besides, uncertainty-awareness becomes\nincreasingly important for safety-crucial cyber physical systems whose\nprediction module heavily relies on machine learning tools. In this paper, we\nrelax the data collection requirement and enhance uncertainty-awareness by\nusing Federated Learning on Connected Autonomous Vehicles with an\nuncertainty-aware global objective. We name our algorithm as FLTP. We further\nintroduce ALFLTP which boosts FLTP via using active learning techniques in\nadaptatively selecting participating clients. We consider both negative\nlog-likelihood (NLL) and aleatoric uncertainty (AU) as client selection\nmetrics. Experiments on Argoverse dataset show that FLTP significantly\noutperforms the model trained on local data. In addition, ALFLTP-AU converges\nfaster in training regression loss and performs better in terms of NLL, minADE\nand MR than FLTP in most rounds, and has more stable round-wise performance\nthan ALFLTP-NLL.\n","authors":["Muzi Peng","Jiangwei Wang","Dongjin Song","Fei Miao","Lili Su"],"pdf_url":"https://arxiv.org/pdf/2303.04340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04339v1","updated":"2023-03-08T02:31:49Z","published":"2023-03-08T02:31:49Z","title":"Learning the Finer Things: Bayesian Structure Learning at the\n  Instantiation Level","summary":"  Successful machine learning methods require a trade-off between memorization\nand generalization. Too much memorization and the model cannot generalize to\nunobserved examples. Too much over-generalization and we risk under-fitting the\ndata. While we commonly measure their performance through cross validation and\naccuracy metrics, how should these algorithms cope in domains that are\nextremely under-determined where accuracy is always unsatisfactory? We present\na novel probabilistic graphical model structure learning approach that can\nlearn, generalize and explain in these elusive domains by operating at the\nrandom variable instantiation level. Using Minimum Description Length (MDL)\nanalysis, we propose a new decomposition of the learning problem over all\ntraining exemplars, fusing together minimal entropy inferences to construct a\nfinal knowledge base. By leveraging Bayesian Knowledge Bases (BKBs), a\nframework that operates at the instantiation level and inherently subsumes\nBayesian Networks (BNs), we develop both a theoretical MDL score and associated\nstructure learning algorithm that demonstrates significant improvements over\nlearned BNs on 40 benchmark datasets. Further, our algorithm incorporates\nrecent off-the-shelf DAG learning techniques enabling tractable results even on\nlarge problems. We then demonstrate the utility of our approach in a\nsignificantly under-determined domain by learning gene regulatory networks on\nbreast cancer gene mutational data available from The Cancer Genome Atlas\n(TCGA).\n","authors":["Chase Yakaboski","Eugene Santos Jr"],"pdf_url":"https://arxiv.org/pdf/2303.04339v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04338v1","updated":"2023-03-08T02:25:28Z","published":"2023-03-08T02:25:28Z","title":"Provable Pathways: Learning Multiple Tasks over Multiple Paths","summary":"  Constructing useful representations across a large number of tasks is a key\nrequirement for sample-efficient intelligent systems. A traditional idea in\nmultitask learning (MTL) is building a shared representation across tasks which\ncan then be adapted to new tasks by tuning last layers. A desirable refinement\nof using a shared one-fits-all representation is to construct task-specific\nrepresentations. To this end, recent PathNet/muNet architectures represent\nindividual tasks as pathways within a larger supernet. The subnetworks induced\nby pathways can be viewed as task-specific representations that are composition\nof modules within supernet's computation graph. This work explores the pathways\nproposal from the lens of statistical learning: We first develop novel\ngeneralization bounds for empirical risk minimization problems learning\nmultiple tasks over multiple paths (Multipath MTL). In conjunction, we\nformalize the benefits of resulting multipath representation when adapting to\nnew downstream tasks. Our bounds are expressed in terms of Gaussian complexity,\nlead to tangible guarantees for the class of linear representations, and\nprovide novel insights into the quality and benefits of a multipath\nrepresentation. When computation graph is a tree, Multipath MTL hierarchically\nclusters the tasks and builds cluster-specific representations. We provide\nfurther discussion and experiments for hierarchical MTL and rigorously identify\nthe conditions under which Multipath MTL is provably superior to traditional\nMTL approaches with shallow supernets.\n","authors":["Yingcong Li","Samet Oymak"],"pdf_url":"https://arxiv.org/pdf/2303.04338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.08330v3","updated":"2023-03-08T02:22:16Z","published":"2021-11-16T10:01:08Z","title":"Bayesian Optimization for Cascade-type Multi-stage Processes","summary":"  Complex processes in science and engineering are often formulated as\nmultistage decision-making problems. In this paper, we consider a type of\nmultistage decision-making process called a cascade process. A cascade process\nis a multistage process in which the output of one stage is used as an input\nfor the subsequent stage. When the cost of each stage is expensive, it is\ndifficult to search for the optimal controllable parameters for each stage\nexhaustively. To address this problem, we formulate the optimization of the\ncascade process as an extension of the Bayesian optimization framework and\npropose two types of acquisition functions based on credible intervals and\nexpected improvement. We investigate the theoretical properties of the proposed\nacquisition functions and demonstrate their effectiveness through numerical\nexperiments. In addition, we consider an extension called suspension setting in\nwhich we are allowed to suspend the cascade process at the middle of the\nmultistage decision-making process that often arises in practical problems. We\napply the proposed method in a test problem involving a solar cell simulator,\nwhich was the motivation for this study.\n","authors":["Shunya Kusakawa","Shion Takeno","Yu Inatsu","Kentaro Kutsukake","Shogo Iwazaki","Takashi Nakano","Toru Ujihara","Masayuki Karasuyama","Ichiro Takeuchi"],"pdf_url":"https://arxiv.org/pdf/2111.08330v3.pdf","comment":"70pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.04336v1","updated":"2023-03-08T02:19:54Z","published":"2023-03-08T02:19:54Z","title":"QuickSRNet: Plain Single-Image Super-Resolution Architecture for Faster\n  Inference on Mobile Platforms","summary":"  In this work, we present QuickSRNet, an efficient super-resolution\narchitecture for real-time applications on mobile platforms. Super-resolution\nclarifies, sharpens, and upscales an image to higher resolution. Applications\nsuch as gaming and video playback along with the ever-improving display\ncapabilities of TVs, smartphones, and VR headsets are driving the need for\nefficient upscaling solutions. While existing deep learning-based\nsuper-resolution approaches achieve impressive results in terms of visual\nquality, enabling real-time DL-based super-resolution on mobile devices with\ncompute, thermal, and power constraints is challenging. To address these\nchallenges, we propose QuickSRNet, a simple yet effective architecture that\nprovides better accuracy-to-latency trade-offs than existing neural\narchitectures for single-image super resolution. We present training tricks to\nspeed up existing residual-based super-resolution architectures while\nmaintaining robustness to quantization. Our proposed architecture produces\n1080p outputs via 2x upscaling in 2.2 ms on a modern smartphone, making it\nideal for high-fps real-time applications.\n","authors":["Guillaume Berger","Manik Dhingra","Antoine Mercier","Yashesh Savani","Sunny Panchal","Fatih Porikli"],"pdf_url":"https://arxiv.org/pdf/2303.04336v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2303.04335v1","updated":"2023-03-08T02:14:08Z","published":"2023-03-08T02:14:08Z","title":"Unbiased Learning to Rank with Biased Continuous Feedback","summary":"  It is a well-known challenge to learn an unbiased ranker with biased\nfeedback. Unbiased learning-to-rank(LTR) algorithms, which are verified to\nmodel the relative relevance accurately based on noisy feedback, are appealing\ncandidates and have already been applied in many applications with single\ncategorical labels, such as user click signals. Nevertheless, the existing\nunbiased LTR methods cannot properly handle continuous feedback, which are\nessential for many industrial applications, such as content recommender\nsystems.\n  To provide personalized high-quality recommendation results, recommender\nsystems need model both categorical and continuous biased feedback, such as\nclick and dwell time. Accordingly, we design a novel unbiased LTR algorithm to\ntackle the challenges, which innovatively models position bias in the pairwise\nfashion and introduces the pairwise trust bias to separate the position bias,\ntrust bias, and user relevance explicitly and can work for both continuous and\ncategorical feedback. Experiment results on public benchmark datasets and\ninternal live traffic of a large-scale recommender system at Tencent News show\nsuperior results for continuous labels and also competitive performance for\ncategorical labels of the proposed method.\n","authors":["Yi Ren","Hongyan Tang","Siwen Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.04335v1.pdf","comment":"10 pages. arXiv admin note: substantial text overlap with\n  arXiv:2111.12929"},{"id":"http://arxiv.org/abs/2303.04333v1","updated":"2023-03-08T02:10:59Z","published":"2023-03-08T02:10:59Z","title":"Preference-Aware Delivery Planning for Last-Mile Logistics","summary":"  Optimizing delivery routes for last-mile logistics service is challenging and\nhas attracted the attention of many researchers. These problems are usually\nmodeled and solved as variants of vehicle routing problems (VRPs) with\nchallenging real-world constraints (e.g., time windows, precedence). However,\ndespite many decades of solid research on solving these VRP instances, we still\nsee significant gaps between optimized routes and the routes that are actually\npreferred by the practitioners. Most of these gaps are due to the difference\nbetween what's being optimized, and what the practitioners actually care about,\nwhich is hard to be defined exactly in many instances. In this paper, we\npropose a novel hierarchical route optimizer with learnable parameters that\ncombines the strength of both the optimization and machine learning approaches.\nOur hierarchical router first solves a zone-level Traveling Salesman Problem\nwith learnable weights on various zone-level features; with the zone visit\nsequence fixed, we then solve the stop-level vehicle routing problem as a\nShortest Hamiltonian Path problem. The Bayesian optimization approach is then\nintroduced to allow us to adjust the weights to be assigned to different zone\nfeatures used in solving the zone-level Traveling Salesman Problem. By using a\nreal-world delivery dataset provided by the Amazon Last Mile Routing Research\nChallenge, we demonstrate the importance of having both the optimization and\nthe machine learning components. We also demonstrate how we can use\nroute-related features to identify instances that we might have difficulty\nwith. This paves ways to further research on how we can tackle these difficult\ninstances.\n","authors":["Qian Shao","Shih-Fen Cheng"],"pdf_url":"https://arxiv.org/pdf/2303.04333v1.pdf","comment":"Accepted to the 22nd International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS-23)"},{"id":"http://arxiv.org/abs/2303.04328v1","updated":"2023-03-08T02:03:30Z","published":"2023-03-08T02:03:30Z","title":"The Novel Adaptive Fractional Order Gradient Decent Algorithms Design\n  via Robust Control","summary":"  The vanilla fractional order gradient descent may oscillatively converge to a\nregion around the global minimum instead of converging to the exact minimum\npoint, or even diverge, in the case where the objective function is strongly\nconvex. To address this problem, a novel adaptive fractional order gradient\ndescent (AFOGD) method and a novel adaptive fractional order accelerated\ngradient descent (AFOAGD) method are proposed in this paper. Inspired by the\nquadratic constraints and Lyapunov stability analysis from robust control\ntheory, we establish a linear matrix inequality to analyse the convergence of\nour proposed algorithms. We prove that the proposed algorithms can achieve\nR-linear convergence when the objective function is $\\textbf{L-}$smooth and\n$\\textbf{m-}$strongly-convex. Several numerical simulations are demonstrated to\nverify the effectiveness and superiority of our proposed algorithms.\n","authors":["Jiaxu Liu","Song Chen","Shengze Cai","Chao Xu"],"pdf_url":"https://arxiv.org/pdf/2303.04328v1.pdf","comment":"8pages,5 figures"},{"id":"http://arxiv.org/abs/2303.04327v1","updated":"2023-03-08T02:00:26Z","published":"2023-03-08T02:00:26Z","title":"Using Memory-Based Learning to Solve Tasks with State-Action Constraints","summary":"  Tasks where the set of possible actions depend discontinuously on the state\npose a significant challenge for current reinforcement learning algorithms. For\nexample, a locked door must be first unlocked, and then the handle turned\nbefore the door can be opened. The sequential nature of these tasks makes\nobtaining final rewards difficult, and transferring information between task\nvariants using continuous learned values such as weights rather than discrete\nsymbols can be inefficient. Our key insight is that agents that act and think\nsymbolically are often more effective in dealing with these tasks. We propose a\nmemory-based learning approach that leverages the symbolic nature of\nconstraints and temporal ordering of actions in these tasks to quickly acquire\nand transfer high-level information. We evaluate the performance of\nmemory-based learning on both real and simulated tasks with approximately\ndiscontinuous constraints between states and actions, and show our method\nlearns to solve these tasks an order of magnitude faster than both model-based\nand model-free deep reinforcement learning methods.\n","authors":["Mrinal Verghese","Chris Atkeson"],"pdf_url":"https://arxiv.org/pdf/2303.04327v1.pdf","comment":"8 pages, 3 figures, accepted to the International Conference on\n  Robotics and Automation 2023"},{"id":"http://arxiv.org/abs/2302.08447v2","updated":"2023-03-08T01:50:46Z","published":"2023-02-16T17:40:23Z","title":"AirGNNs: Graph Neural Networks over the Air","summary":"  Graph neural networks (GNNs) are information processing architectures that\nmodel representations from networked data and allow for decentralized\nimplementation through localized communications. Existing GNN architectures\noften assume ideal communication links and ignore channel effects, such as\nfading and noise, leading to performance degradation in real-world\nimplementation. This paper proposes graph neural networks over the air\n(AirGNNs), a novel GNN architecture that incorporates the communication model\ninto the architecture. AirGNN modifies the graph convolutional operation that\nshifts graph signals over random communication graphs to take into account\nchannel fading and noise when aggregating features from neighbors, thus,\nimproving the architecture robustness to channel impairments during testing. We\npropose a stochastic gradient descent based method to train the AirGNN, and\nshow that the training procedure converges to a stationary solution. Numerical\nsimulations on decentralized source localization and multi-robot flocking\ncorroborate theoretical findings and show superior performance of the AirGNN\nover wireless communication channels.\n","authors":["Zhan Gao","Deniz Gunduz"],"pdf_url":"https://arxiv.org/pdf/2302.08447v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03592v2","updated":"2023-03-08T01:50:21Z","published":"2023-03-07T01:55:26Z","title":"Exploring the Limits of Indiscriminate Data Poisoning Attacks","summary":"  Indiscriminate data poisoning attacks aim to decrease a model's test accuracy\nby injecting a small amount of corrupted training data. Despite significant\ninterest, existing attacks remain relatively ineffective against modern machine\nlearning (ML) architectures. In this work, we introduce the notion of model\npoisonability as a technical tool to explore the intrinsic limits of data\npoisoning attacks. We derive an easily computable threshold to establish and\nquantify a surprising phase transition phenomenon among popular ML models: data\npoisoning attacks become effective only when the poisoning ratio exceeds our\nthreshold. Building on existing parameter corruption attacks and refining the\nGradient Canceling attack, we perform extensive experiments to confirm our\ntheoretical findings, test the predictability of our transition threshold, and\nsignificantly improve existing data poisoning baselines over a range of\ndatasets and models. Our work highlights the critical role played by the\npoisoning ratio, and sheds new insights on existing empirical results, attacks\nand mitigation strategies in data poisoning.\n","authors":["Yiwei Lu","Gautam Kamath","Yaoliang Yu"],"pdf_url":"https://arxiv.org/pdf/2303.03592v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09062v2","updated":"2023-03-08T01:45:53Z","published":"2022-12-18T11:02:50Z","title":"Bort: Towards Explainable Neural Networks with Bounded Orthogonal\n  Constraint","summary":"  Deep learning has revolutionized human society, yet the black-box nature of\ndeep neural networks hinders further application to reliability-demanded\nindustries. In the attempt to unpack them, many works observe or impact\ninternal variables to improve the comprehensibility and invertibility of the\nblack-box models. However, existing methods rely on intuitive assumptions and\nlack mathematical guarantees. To bridge this gap, we introduce Bort, an\noptimizer for improving model explainability with boundedness and orthogonality\nconstraints on model parameters, derived from the sufficient conditions of\nmodel comprehensibility and invertibility. We perform reconstruction and\nbacktracking on the model representations optimized by Bort and observe a clear\nimprovement in model explainability. Based on Bort, we are able to synthesize\nexplainable adversarial samples without additional parameters and training.\nSurprisingly, we find Bort constantly improves the classification accuracy of\nvarious architectures including ResNet and DeiT on MNIST, CIFAR-10, and\nImageNet. Code: https://github.com/zbr17/Bort.\n","authors":["Borui Zhang","Wenzhao Zheng","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2212.09062v2.pdf","comment":"ICLR 2023 accepted"},{"id":"http://arxiv.org/abs/2208.00081v2","updated":"2023-03-08T01:29:10Z","published":"2022-07-29T21:29:29Z","title":"Sampling Attacks on Meta Reinforcement Learning: A Minimax Formulation\n  and Complexity Analysis","summary":"  Meta reinforcement learning (meta RL), as a combination of meta-learning\nideas and reinforcement learning (RL), enables the agent to adapt to different\ntasks using a few samples. However, this sampling-based adaptation also makes\nmeta RL vulnerable to adversarial attacks. By manipulating the reward feedback\nfrom sampling processes in meta RL, an attacker can mislead the agent into\nbuilding wrong knowledge from training experience, which deteriorates the\nagent's performance when dealing with different tasks after adaptation. This\npaper provides a game-theoretical underpinning for understanding this type of\nsecurity risk. In particular, we formally define the sampling attack model as a\nStackelberg game between the attacker and the agent, which yields a minimax\nformulation. It leads to two online attack schemes: Intermittent Attack and\nPersistent Attack, which enable the attacker to learn an optimal sampling\nattack, defined by an $\\epsilon$-first-order stationary point, within\n$\\mathcal{O}(\\epsilon^{-2})$ iterations. These attack schemes freeride the\nlearning progress concurrently without extra interactions with the environment.\nBy corroborating the convergence results with numerical experiments, we observe\nthat a minor effort of the attacker can significantly deteriorate the learning\nperformance, and the minimax approach can also help robustify the meta RL\nalgorithms.\n","authors":["Tao Li","Haozhe Lei","Quanyan Zhu"],"pdf_url":"https://arxiv.org/pdf/2208.00081v2.pdf","comment":"updates: github repo posted"},{"id":"http://arxiv.org/abs/2303.04313v1","updated":"2023-03-08T01:28:18Z","published":"2023-03-08T01:28:18Z","title":"Learning Environment-Aware Control Barrier Functions for Safe and\n  Feasible Multi-Robot Navigation","summary":"  Control Barrier Functions (CBFs) have been applied to provide safety\nguarantees for robot navigation. Traditional approaches consider fixed CBFs\nduring navigation and hand-tune the underlying parameters apriori. Such\napproaches are inefficient and vulnerable to changes in the environment. The\ngoal of this paper is to learn CBFs for multi-robot navigation based on what\nrobots perceive about their environment. In order to guarantee the feasibility\nof the navigation task, while ensuring robot safety, we pursue a trade-off\nbetween conservativeness and aggressiveness in robot behavior by defining\ndynamic environment-aware CBF constraints. Since the explicit relationship\nbetween CBF constraints and navigation performance is challenging to model, we\nleverage reinforcement learning to learn time-varying CBFs in a model-free\nmanner. We parameterize the CBF policy with graph neural networks (GNNs), and\ndesign GNNs that are translation invariant and permutation equivariant, to\nsynthesize decentralized policies that generalize across environments. The\nproposed approach maintains safety guarantees (due to the underlying CBFs),\nwhile optimizing navigation performance (due to the reward-based learning). We\nperform simulations that compare the proposed approach with fixed CBFs tuned by\nexhaustive grid-search. The results show that environment-aware CBFs are\ncapable of adapting to robot movements and obstacle changes, yielding improved\nnavigation performance and robust generalization.\n","authors":["Zhan Gao","Guang Yang","Amanda Prorok"],"pdf_url":"https://arxiv.org/pdf/2303.04313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09757v2","updated":"2023-03-08T01:28:06Z","published":"2023-02-20T04:45:13Z","title":"An ODE Model for Dynamic Matching in Heterogeneous Networks","summary":"  We study the problem of dynamic matching in heterogeneous networks, where\nagents are subject to compatibility restrictions and stochastic arrival and\ndeparture times. In particular, we consider networks with one type of\neasy-to-match agents and multiple types of hard-to-match agents, each subject\nto its own compatibility constraints. Such a setting arises in many real-world\napplications, including kidney exchange programs and carpooling platforms. We\nintroduce a novel approach to modeling dynamic matching by establishing the\nordinary differential equation (ODE) model, which offers a new perspective for\nevaluating various matching algorithms. We study two algorithms, namely the\nGreedy and Patient Algorithms, where both algorithms prioritize matching\ncompatible hard-to-match agents over easy-to-match agents in heterogeneous\nnetworks. Our results demonstrate the trade-off between the conflicting goals\nof matching agents quickly and optimally, offering insights into the design of\nreal-world dynamic matching systems. We provide simulations and a real-world\ncase study using data from the Organ Procurement and Transplantation Network to\nvalidate theoretical predictions.\n","authors":["Xiaowu Dai","Hengzhi He"],"pdf_url":"https://arxiv.org/pdf/2302.09757v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11446v2","updated":"2023-03-08T00:44:12Z","published":"2022-12-22T01:30:54Z","title":"Commitment with Signaling under Double-sided Information Asymmetry","summary":"  Information asymmetry in games enables players with the information advantage\nto manipulate others' beliefs by strategically revealing information to other\nplayers. This work considers a double-sided information asymmetry in a Bayesian\nStackelberg game, where the leader's realized action, sampled from the mixed\nstrategy commitment, is hidden from the follower. In contrast, the follower\nholds private information about his payoff. Given asymmetric information on\nboth sides, an important question arises: \\emph{Does the leader's information\nadvantage outweigh the follower's?} We answer this question affirmatively in\nthis work, where we demonstrate that by adequately designing a signaling device\nthat reveals partial information regarding the leader's realized action to the\nfollower, the leader can achieve a higher expected utility than that without\nsignaling. Moreover, unlike previous works on the Bayesian Stackelberg game\nwhere mathematical programming tools are utilized, we interpret the leader's\ncommitment as a probability measure over the belief space. Such a probabilistic\nlanguage greatly simplifies the analysis and allows an indirect signaling\nscheme, leading to a geometric characterization of the equilibrium under the\nproposed game model.\n","authors":["Tao Li","Quanyan Zhu"],"pdf_url":"https://arxiv.org/pdf/2212.11446v2.pdf","comment":"Working paper; 18 pages"},{"id":"http://arxiv.org/abs/2303.04301v1","updated":"2023-03-08T00:43:06Z","published":"2023-03-08T00:43:06Z","title":"Optimal Sparse Recovery with Decision Stumps","summary":"  Decision trees are widely used for their low computational cost, good\npredictive performance, and ability to assess the importance of features.\nThough often used in practice for feature selection, the theoretical guarantees\nof these methods are not well understood. We here obtain a tight finite sample\nbound for the feature selection problem in linear regression using single-depth\ndecision trees. We examine the statistical properties of these \"decision\nstumps\" for the recovery of the $s$ active features from $p$ total features,\nwhere $s \\ll p$. Our analysis provides tight sample performance guarantees on\nhigh-dimensional sparse systems which align with the finite sample bound of\n$O(s \\log p)$ as obtained by Lasso, improving upon previous bounds for both the\nmedian and optimal splitting criteria. Our results extend to the non-linear\nregime as well as arbitrary sub-Gaussian distributions, demonstrating that tree\nbased methods attain strong feature selection properties under a wide variety\nof settings and further shedding light on the success of these methods in\npractice. As a byproduct of our analysis, we show that we can provably\nguarantee recovery even when the number of active features $s$ is unknown. We\nfurther validate our theoretical results and proof methodology using\ncomputational experiments.\n","authors":["Kiarash Banihashem","MohammadTaghi Hajiaghayi","Max Springer"],"pdf_url":"https://arxiv.org/pdf/2303.04301v1.pdf","comment":"Accepted to AAAI 2023"},{"id":"http://arxiv.org/abs/2202.05612v2","updated":"2023-03-08T00:09:18Z","published":"2022-02-11T13:49:08Z","title":"Inference and FDR Control for Simulated Markov Random Fields in\n  High-dimension","summary":"  This paper studies the consistency and statistical inference of simulated\nMarkov random fields (MRFs) in a high dimensional background. Our estimators\nare based on the Markov chain Monte Carlo maximum likelihood estimation\n(MCMC-MLE) method, penalized by the Elastic-net. Under mild conditions that\nensure a specific convergence rate of the MCMC method, the $\\ell_{1}$\nconsistency of Elastic-net-penalized MCMC-MLE is obtained. We further propose a\ndecorrelated score test based on the decorrelated score function and prove the\nasymptotic normality of the score function without the influence of many\nnuisance parameters under the assumption that it accelerates the convergence of\nthe MCMC method. The one-step estimator for a single parameter of interest is\nconstructed by linearizing the decorrelated score function to solve its root,\nand the normality and confidence interval for the true value, is established.\nWe use different algorithms to control the false discovery rate (FDR) for\nmultiple testing problems via classic p-values and novel e-values. Finally, we\nempirically validate the asymptotic theories and demonstrate both FDR control\nprocedures in our article have good performance.\n","authors":["Haoyu Wei","Xiaoyu Lei","Huiming Zhang"],"pdf_url":"https://arxiv.org/pdf/2202.05612v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/1901.09146v4","updated":"2023-03-08T23:46:09Z","published":"2019-01-26T02:48:08Z","title":"End-to-End Multi-Task Denoising for joint SDR and PESQ Optimization","summary":"  Supervised learning based on a deep neural network recently has achieved\nsubstantial improvement on speech enhancement. Denoising networks learn mapping\nfrom noisy speech to clean one directly, or to a spectrum mask which is the\nratio between clean and noisy spectra. In either case, the network is optimized\nby minimizing mean square error (MSE) between ground-truth labels and\ntime-domain or spectrum output. However, existing schemes have either of two\ncritical issues: spectrum and metric mismatches. The spectrum mismatch is a\nwell known issue that any spectrum modification after short-time Fourier\ntransform (STFT), in general, cannot be fully recovered after inverse\nshort-time Fourier transform (ISTFT). The metric mismatch is that a\nconventional MSE metric is sub-optimal to maximize our target metrics,\nsignal-to-distortion ratio (SDR) and perceptual evaluation of speech quality\n(PESQ). This paper presents a new end-to-end denoising framework with the goal\nof joint SDR and PESQ optimization. First, the network optimization is\nperformed on the time-domain signals after ISTFT to avoid spectrum mismatch.\nSecond, two loss functions which have improved correlations with SDR and PESQ\nmetrics are proposed to minimize metric mismatch. The experimental result\nshowed that the proposed denoising scheme significantly improved both SDR and\nPESQ performance over the existing methods.\n","authors":["Jaeyoung Kim","Mostafa El-Khamy","Jungwon Lee"],"pdf_url":"https://arxiv.org/pdf/1901.09146v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04946v1","updated":"2023-03-08T23:40:18Z","published":"2023-03-08T23:40:18Z","title":"ATM Fraud Detection using Streaming Data Analytics","summary":"  Gaining the trust and confidence of customers is the essence of the growth\nand success of financial institutions and organizations. Of late, the financial\nindustry is significantly impacted by numerous instances of fraudulent\nactivities. Further, owing to the generation of large voluminous datasets, it\nis highly essential that underlying framework is scalable and meet real time\nneeds. To address this issue, in the study, we proposed ATM fraud detection in\nstatic and streaming contexts respectively. In the static context, we\ninvestigated a parallel and scalable machine learning algorithms for ATM fraud\ndetection that is built on Spark and trained with a variety of machine learning\n(ML) models including Naive Bayes (NB), Logistic Regression (LR), Support\nVector Machine (SVM), Decision Tree (DT), Random Forest (RF), Gradient Boosting\nTree (GBT), and Multi-layer perceptron (MLP). We also employed several\nbalancing techniques like Synthetic Minority Oversampling Technique (SMOTE) and\nits variants, Generative Adversarial Networks (GAN), to address the rarity in\nthe dataset. In addition, we proposed a streaming based ATM fraud detection in\nthe streaming context. Our sliding window based method collects ATM\ntransactions that are performed within a specified time interval and then\nutilizes to train several ML models, including NB, RF, DT, and K-Nearest\nNeighbour (KNN). We selected these models based on their less model complexity\nand quicker response time. In both contexts, RF turned out to be the best\nmodel. RF obtained the best mean AUC of 0.975 in the static context and mean\nAUC of 0.910 in the streaming context. RF is also empirically proven to be\nstatistically significant than the next-best performing models.\n","authors":["Yelleti Vivek","Vadlamani Ravi","Abhay Anand Mane","Laveti Ramesh Naidu"],"pdf_url":"https://arxiv.org/pdf/2303.04946v1.pdf","comment":"25 pages, 15 figures, 10 tables. arXiv admin note: text overlap with\n  arXiv:2211.10595"},{"id":"http://arxiv.org/abs/2303.04944v1","updated":"2023-03-08T23:39:37Z","published":"2023-03-08T23:39:37Z","title":"On the Benefits of Biophysical Synapses","summary":"  The approximation capability of ANNs and their RNN instantiations, is\nstrongly correlated with the number of parameters packed into these networks.\nHowever, the complexity barrier for human understanding, is arguably related to\nthe number of neurons and synapses in the networks, and to the associated\nnonlinear transformations. In this paper we show that the use of biophysical\nsynapses, as found in LTCs, have two main benefits. First, they allow to pack\nmore parameters for a given number of neurons and synapses. Second, they allow\nto formulate the nonlinear-network transformation, as a linear system with\nstate-dependent coefficients. Both increase interpretability, as for a given\ntask, they allow to learn a system linear in its input features, that is\nsmaller in size compared to the state of the art. We substantiate the above\nclaims on various time-series prediction tasks, but we believe that our results\nare applicable to any feedforward or recurrent ANN.\n","authors":["Julian Lemmel","Radu Grosu"],"pdf_url":"https://arxiv.org/pdf/2303.04944v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04942v1","updated":"2023-03-08T23:32:43Z","published":"2023-03-08T23:32:43Z","title":"A Study of Variable-Role-based Feature Enrichment in Neural Models of\n  Code","summary":"  Although deep neural models substantially reduce the overhead of feature\nengineering, the features readily available in the inputs might significantly\nimpact training cost and the performance of the models. In this paper, we\nexplore the impact of an unsuperivsed feature enrichment approach based on\nvariable roles on the performance of neural models of code. The notion of\nvariable roles (as introduced in the works of Sajaniemi et al. [Refs. 1,2]) has\nbeen found to help students' abilities in programming. In this paper, we\ninvestigate if this notion would improve the performance of neural models of\ncode. To the best of our knowledge, this is the first work to investigate how\nSajaniemi et al.'s concept of variable roles can affect neural models of code.\nIn particular, we enrich a source code dataset by adding the role of individual\nvariables in the dataset programs, and thereby conduct a study on the impact of\nvariable role enrichment in training the Code2Seq model. In addition, we shed\nlight on some challenges and opportunities in feature enrichment for neural\ncode intelligence models.\n","authors":["Aftab Hussain","Md Rafiqul Islam Rabin","Bowen Xu","David Lo","Mohammad Amin Alipour"],"pdf_url":"https://arxiv.org/pdf/2303.04942v1.pdf","comment":"Accepted in the 1st International Workshop on Interpretability and\n  Robustness in Neural Software Engineering (InteNSE'23), Co-located with ICSE"},{"id":"http://arxiv.org/abs/2209.05274v3","updated":"2023-03-08T23:14:14Z","published":"2022-09-12T14:32:12Z","title":"Fairness in Forecasting of Observations of Linear Dynamical Systems","summary":"  In machine learning, training data often capture the behaviour of multiple\nsubgroups of some underlying human population. When the nature of training data\nfor subgroups are not controlled carefully, under-representation bias arises.\nTo counter this effect we introduce two natural notions of subgroup fairness\nand instantaneous fairness to address such under-representation bias in\ntime-series forecasting problems. Here we show globally convergent methods for\nthe fairness-constrained learning problems using hierarchies of\nconvexifications of non-commutative polynomial optimisation problems. Our\nempirical results on a biased data set motivated by insurance applications and\nthe well-known COMPAS data set demonstrate the efficacy of our methods. We also\nshow that by exploiting sparsity in the convexifications, we can reduce the run\ntime of our methods considerably.\n","authors":["Quan Zhou","Jakub Marecek","Robert N. Shorten"],"pdf_url":"https://arxiv.org/pdf/2209.05274v3.pdf","comment":"Journal version of Zhou et al. [arXiv:2006.07315, AAAI 2021]"},{"id":"http://arxiv.org/abs/2206.11600v4","updated":"2023-03-08T23:13:41Z","published":"2022-06-23T10:24:20Z","title":"Disentangling representations in Restricted Boltzmann Machines without\n  adversaries","summary":"  A goal of unsupervised machine learning is to build representations of\ncomplex high-dimensional data, with simple relations to their properties. Such\ndisentangled representations make easier to interpret the significant latent\nfactors of variation in the data, as well as to generate new data with\ndesirable features. Methods for disentangling representations often rely on an\nadversarial scheme, in which representations are tuned to avoid discriminators\nfrom being able to reconstruct information about the data properties (labels).\nUnfortunately adversarial training is generally difficult to implement in\npractice. Here we propose a simple, effective way of disentangling\nrepresentations without any need to train adversarial discriminators, and apply\nour approach to Restricted Boltzmann Machines (RBM), one of the simplest\nrepresentation-based generative models. Our approach relies on the introduction\nof adequate constraints on the weights during training, which allows us to\nconcentrate information about labels on a small subset of latent variables. The\neffectiveness of the approach is illustrated with four examples: the CelebA\ndataset of facial images, the two-dimensional Ising model, the MNIST dataset of\nhandwritten digits, and the taxonomy of protein families. In addition, we show\nhow our framework allows for analytically computing the cost, in terms of\nlog-likelihood of the data, associated to the disentanglement of their\nrepresentations.\n","authors":["Jorge Fernandez-de-Cossio-Diaz","Simona Cocco","Remi Monasson"],"pdf_url":"https://arxiv.org/pdf/2206.11600v4.pdf","comment":"Minor corrections. Accepted for publication in Physical Review X"},{"id":"http://arxiv.org/abs/2303.04930v1","updated":"2023-03-08T22:58:55Z","published":"2023-03-08T22:58:55Z","title":"Multimodal Multi-User Surface Recognition with the Kernel Two-Sample\n  Test","summary":"  Machine learning and deep learning have been used extensively to classify\nphysical surfaces through images and time-series contact data. However, these\nmethods rely on human expertise and entail the time-consuming processes of data\nand parameter tuning. To overcome these challenges, we propose an easily\nimplemented framework that can directly handle heterogeneous data sources for\nclassification tasks. Our data-versus-data approach automatically quantifies\ndistinctive differences in distributions in a high-dimensional space via kernel\ntwo-sample testing between two sets extracted from multimodal data (e.g.,\nimages, sounds, haptic signals). We demonstrate the effectiveness of our\ntechnique by benchmarking against expertly engineered classifiers for\nvisual-audio-haptic surface recognition due to the industrial relevance,\ndifficulty, and competitive baselines of this application; ablation studies\nconfirm the utility of key components of our pipeline. As shown in our\nopen-source code, we achieve 97.2% accuracy on a standard multi-user dataset\nwith 108 surface classes, outperforming the state-of-the-art machine-learning\nalgorithm by 6% on a more difficult version of the task. The fact that our\nclassifier obtains this performance with minimal data processing in the\nstandard algorithm setting reinforces the powerful nature of kernel methods for\nlearning to recognize complex patterns.\n","authors":["Behnam Khojasteh","Friedrich Solowjow","Sebastian Trimpe","Katherine J. Kuchenbecker"],"pdf_url":"https://arxiv.org/pdf/2303.04930v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.04122v4","updated":"2023-03-08T22:29:41Z","published":"2022-01-11T18:44:17Z","title":"In Defense of the Unitary Scalarization for Deep Multi-Task Learning","summary":"  Recent multi-task learning research argues against unitary scalarization,\nwhere training simply minimizes the sum of the task losses. Several ad-hoc\nmulti-task optimization algorithms have instead been proposed, inspired by\nvarious hypotheses about what makes multi-task settings difficult. The majority\nof these optimizers require per-task gradients, and introduce significant\nmemory, runtime, and implementation overhead. We show that unitary\nscalarization, coupled with standard regularization and stabilization\ntechniques from single-task learning, matches or improves upon the performance\nof complex multi-task optimizers in popular supervised and reinforcement\nlearning settings. We then present an analysis suggesting that many specialized\nmulti-task optimizers can be partly interpreted as forms of regularization,\npotentially explaining our surprising results. We believe our results call for\na critical reevaluation of recent research in the area.\n","authors":["Vitaly Kurin","Alessandro De Palma","Ilya Kostrikov","Shimon Whiteson","M. Pawan Kumar"],"pdf_url":"https://arxiv.org/pdf/2201.04122v4.pdf","comment":"NeurIPS 2022 camera-ready version, fixed training loss y axis scale"},{"id":"http://arxiv.org/abs/2301.01481v3","updated":"2023-03-08T22:08:13Z","published":"2023-01-04T08:11:11Z","title":"On Fairness of Medical Image Classification with Multiple Sensitive\n  Attributes via Learning Orthogonal Representations","summary":"  Mitigating the discrimination of machine learning models has gained\nincreasing attention in medical image analysis. However, rare works focus on\nfair treatments for patients with multiple sensitive demographic ones, which is\na crucial yet challenging problem for real-world clinical applications. In this\npaper, we propose a novel method for fair representation learning with respect\nto multi-sensitive attributes. We pursue the independence between target and\nmulti-sensitive representations by achieving orthogonality in the\nrepresentation space. Concretely, we enforce the column space orthogonality by\nkeeping target information on the complement of a low-rank sensitive space.\nFurthermore, in the row space, we encourage feature dimensions between target\nand sensitive representations to be orthogonal. The effectiveness of the\nproposed method is demonstrated with extensive experiments on the CheXpert\ndataset. To our best knowledge, this is the first work to mitigate unfairness\nwith respect to multiple sensitive attributes in the field of medical imaging.\n","authors":["Wenlong Deng","Yuan Zhong","Qi Dou","Xiaoxiao Li"],"pdf_url":"https://arxiv.org/pdf/2301.01481v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04912v1","updated":"2023-03-08T22:04:31Z","published":"2023-03-08T22:04:31Z","title":"Embodied Active Learning of Relational State Abstractions for Bilevel\n  Planning","summary":"  State abstraction is an effective technique for planning in robotics\nenvironments with continuous states and actions, long task horizons, and sparse\nfeedback. In object-oriented environments, predicates are a particularly useful\nform of state abstraction because of their compatibility with symbolic planners\nand their capacity for relational generalization. However, to plan with\npredicates, the agent must be able to interpret them in continuous environment\nstates (i.e., ground the symbols). Manually programming predicate\ninterpretations can be difficult, so we would instead like to learn them from\ndata. We propose an embodied active learning paradigm where the agent learns\npredicate interpretations through online interaction with an expert. For\nexample, after taking actions in a block stacking environment, the agent may\nask the expert: \"Is On(block1, block2) true?\" From this experience, the agent\nlearns to plan: it learns neural predicate interpretations, symbolic planning\noperators, and neural samplers that can be used for bilevel planning. During\nexploration, the agent plans to learn: it uses its current models to select\nactions towards generating informative expert queries. We learn predicate\ninterpretations as ensembles of neural networks and use their entropy to\nmeasure the informativeness of potential queries. We evaluate this approach in\nthree robotic environments and find that it consistently outperforms six\nbaselines while exhibiting sample efficiency in two key metrics: number of\nenvironment interactions, and number of queries to the expert. Code:\nhttps://tinyurl.com/active-predicates\n","authors":["Amber Li","Tom Silver"],"pdf_url":"https://arxiv.org/pdf/2303.04912v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04911v1","updated":"2023-03-08T22:02:15Z","published":"2023-03-08T22:02:15Z","title":"Reverse Engineering Breast MRIs: Predicting Acquisition Parameters\n  Directly from Images","summary":"  The image acquisition parameters (IAPs) used to create MRI scans are central\nto defining the appearance of the images. Deep learning models trained on data\nacquired using certain parameters might not generalize well to images acquired\nwith different parameters. Being able to recover such parameters directly from\nan image could help determine whether a deep learning model is applicable, and\ncould assist with data harmonization and/or domain adaptation. Here, we\nintroduce a neural network model that can predict many complex IAPs used to\ngenerate an MR image with high accuracy solely using the image, with a single\nforward pass. These predicted parameters include field strength, echo and\nrepetition times, acquisition matrix, scanner model, scan options, and others.\nEven challenging parameters such as contrast agent type can be predicted with\ngood accuracy. We perform a variety of experiments and analyses of our model's\nability to predict IAPs on many MRI scans of new patients, and demonstrate its\nusage in a realistic application. Predicting IAPs from the images is an\nimportant step toward better understanding the relationship between image\nappearance and IAPs. This in turn will advance the understanding of many\nconcepts related to the generalizability of neural network models on medical\nimages, including domain shift, domain adaptation, and data harmonization.\n","authors":["Nicholas Konz","Maciej A. Mazurowski"],"pdf_url":"https://arxiv.org/pdf/2303.04911v1.pdf","comment":"Paper accepted at MIDL 2023. Code available at\n  https://github.com/mazurowski-lab/MRI-IAP-prediction"},{"id":"http://arxiv.org/abs/2303.04910v1","updated":"2023-03-08T22:00:15Z","published":"2023-03-08T22:00:15Z","title":"Baldur: Whole-Proof Generation and Repair with Large Language Models","summary":"  Formally verifying software properties is a highly desirable but\nlabor-intensive task. Recent work has developed methods to automate formal\nverification using proof assistants, such as Coq and Isabelle/HOL, e.g., by\ntraining a model to predict one proof step at a time, and using that model to\nsearch through the space of possible proofs. This paper introduces a new method\nto automate formal verification: We use large language models, trained on\nnatural language text and code and fine-tuned on proofs, to generate whole\nproofs for theorems at once, rather than one step at a time. We combine this\nproof generation model with a fine-tuned repair model to repair generated\nproofs, further increasing proving power. As its main contributions, this paper\ndemonstrates for the first time that: (1) Whole-proof generation using\ntransformers is possible and is as effective as search-based techniques without\nrequiring costly search. (2) Giving the learned model additional context, such\nas a prior failed proof attempt and the ensuing error message, results in proof\nrepair and further improves automated proof generation. (3) We establish a new\nstate of the art for fully automated proof synthesis. We reify our method in a\nprototype, Baldur, and evaluate it on a benchmark of 6,336 Isabelle/HOL\ntheorems and their proofs. In addition to empirically showing the effectiveness\nof whole-proof generation, repair, and added context, we show that Baldur\nimproves on the state-of-the-art tool, Thor, by automatically generating proofs\nfor an additional 8.7% of the theorems. Together, Baldur and Thor can prove\n65.7% of the theorems fully automatically. This paper paves the way for new\nresearch into using large language models for automating formal verification.\n","authors":["Emily First","Markus N. Rabe","Talia Ringer","Yuriy Brun"],"pdf_url":"https://arxiv.org/pdf/2303.04910v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11006v2","updated":"2023-03-08T21:58:26Z","published":"2023-02-21T21:18:17Z","title":"Data-driven reduced-order modelling for blood flow simulations with\n  geometry-informed snapshots","summary":"  Computational fluid dynamics is a common tool in cardiovascular science and\nengineering to simulate, predict and study hemodynamics in arteries. However,\nowing to the complexity and scale of cardiovascular flow problems, the\nevaluation of the model could be computationally expensive, especially in those\ncases where a large number of evaluations are required, such as uncertainty\nquantification and design optimisation. In such scenarios, the model may have\nto be repeatedly evaluated due to the changes or distinctions of simulation\ndomains. In this work, a data-driven surrogate model is proposed for the\nefficient prediction of blood flow simulations on similar but distinct domains.\nThe proposed surrogate model leverages surface registration to parameterise\nthose similar but distinct shapes and formulate corresponding hemodynamics\ninformation into geometry-informed snapshots by the diffeomorphism constructed\nbetween the reference domain and target domain. A non-intrusive reduced-order\nmodel for geometrical parameters is subsequently constructed using proper\northogonal decomposition, and a radial basis function interpolator is trained\nfor predicting the reduced coefficients of the reduced-order model based on\nreduced coefficients of geometrical parameters of the shape. Two examples of\nblood flowing through a stenosis and a bifurcation are presented and analysed.\nThe proposed surrogate model demonstrates its accuracy and efficiency in\nhemodynamics prediction and shows its potential application toward real-time\nsimulation or uncertainty quantification for complex patient-specific\nscenarios.\n","authors":["Dongwei Ye","Valeria Krzhizhanovskaya","Alfons G. Hoekstra"],"pdf_url":"https://arxiv.org/pdf/2302.11006v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04906v1","updated":"2023-03-08T21:51:14Z","published":"2023-03-08T21:51:14Z","title":"Model-Agnostic Federated Learning","summary":"  Since its debut in 2016, Federated Learning (FL) has been tied to the inner\nworkings of Deep Neural Networks (DNNs). On the one hand, this allowed its\ndevelopment and widespread use as DNNs proliferated. On the other hand, it\nneglected all those scenarios in which using DNNs is not possible or\nadvantageous. The fact that most current FL frameworks only allow training DNNs\nreinforces this problem. To address the lack of FL solutions for non-DNN-based\nuse cases, we propose MAFL (Model-Agnostic Federated Learning). MAFL marries a\nmodel-agnostic FL algorithm, AdaBoost.F, with an open industry-grade FL\nframework: Intel OpenFL. MAFL is the first FL system not tied to any specific\ntype of machine learning model, allowing exploration of FL scenarios beyond\nDNNs and trees. We test MAFL from multiple points of view, assessing its\ncorrectness, flexibility and scaling properties up to 64 nodes. We optimised\nthe base software achieving a 5.5x speedup on a standard FL scenario. MAFL is\ncompatible with x86-64, ARM-v8, Power and RISC-V.\n","authors":["Gianluca Mittone","Walter Riviera","Iacopo Colonnelli","Robert Birke","Marco Aldinucci"],"pdf_url":"https://arxiv.org/pdf/2303.04906v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01560v2","updated":"2023-03-08T21:34:04Z","published":"2023-03-02T20:22:40Z","title":"Active Learning and Bayesian Optimization: a Unified Perspective to\n  Learn with a Goal","summary":"  Both Bayesian optimization and active learning realize an adaptive sampling\nscheme to achieve a specific learning goal. However, while the two fields have\nseen an exponential growth in popularity in the past decade, their dualism has\nreceived relatively little attention. In this paper, we argue for an original\nunified perspective of Bayesian optimization and active learning based on the\nsynergy between the principles driving the sampling policies. This symbiotic\nrelationship is demonstrated through the substantial analogy between the infill\ncriteria of Bayesian optimization and the learning criteria in active learning,\nand is formalized for the case of single information source and when multiple\nsources at different levels of fidelity are available. We further investigate\nthe capabilities of each infill criteria both individually and in combination\non a variety of analytical benchmark problems, to highlight benefits and\nlimitations over mathematical properties that characterize real-world\napplications.\n","authors":["Francesco Di Fiore","Michela Nardelli","Laura Mainini"],"pdf_url":"https://arxiv.org/pdf/2303.01560v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.03211v7","updated":"2023-03-08T21:21:49Z","published":"2022-08-05T14:54:08Z","title":"Why do networks have inhibitory/negative connections?","summary":"  Why do brains have inhibitory connections? Why do deep networks have negative\nweights? We believe representing functions is the primary role of both (i) the\nbrain in natural intelligence, and (ii) deep networks in artificial\nintelligence. Our answer to why there are inhibitory/negative weights is: to\nlearn more functions. We prove that, in the absence of negative weights, neural\nnetworks with non-decreasing activation functions are not universal\napproximators. While this may be an intuitive result to some, to the best of\nour knowledge, there is no formal theory, in either machine learning or\nneuroscience, that demonstrates why negative weights are crucial in the context\nof representation capacity. Further, we provide insights on the geometric\nproperties of the representation space that non-negative deep networks cannot\nrepresent. We expect these insights will yield a deeper understanding of more\nsophisticated inductive priors imposed on the distribution of weights that lead\nto more efficient biological and machine learning.\n","authors":["Qingyang Wang","Michael A. Powell","Ali Geisa","Eric Bridgeford","Carey E. Priebe","Joshua T. Vogelstein"],"pdf_url":"https://arxiv.org/pdf/2208.03211v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04891v1","updated":"2023-03-08T21:11:51Z","published":"2023-03-08T21:11:51Z","title":"You Only Crash Once: Improved Object Detection for Real-Time,\n  Sim-to-Real Hazardous Terrain Detection and Classification for Autonomous\n  Planetary Landings","summary":"  The detection of hazardous terrain during the planetary landing of spacecraft\nplays a critical role in assuring vehicle safety and mission success. A cheap\nand effective way of detecting hazardous terrain is through the use of visual\ncameras, which ensure operational ability from atmospheric entry through\ntouchdown. Plagued by resource constraints and limited computational power,\ntraditional techniques for visual hazardous terrain detection focus on template\nmatching and registration to pre-built hazard maps. Although successful on\nprevious missions, this approach is restricted to the specificity of the\ntemplates and limited by the fidelity of the underlying hazard map, which both\nrequire extensive pre-flight cost and effort to obtain and develop. Terrestrial\nsystems that perform a similar task in applications such as autonomous driving\nutilize state-of-the-art deep learning techniques to successfully localize and\nclassify navigation hazards. Advancements in spacecraft co-processors aimed at\naccelerating deep learning inference enable the application of these methods in\nspace for the first time. In this work, we introduce You Only Crash Once\n(YOCO), a deep learning-based visual hazardous terrain detection and\nclassification technique for autonomous spacecraft planetary landings. Through\nthe use of unsupervised domain adaptation we tailor YOCO for training by\nsimulation, removing the need for real-world annotated data and expensive\nmission surveying phases. We further improve the transfer of representative\nterrain knowledge between simulation and the real world through visual\nsimilarity clustering. We demonstrate the utility of YOCO through a series of\nterrestrial and extraterrestrial simulation-to-real experiments and show\nsubstantial improvements toward the ability to both detect and accurately\nclassify instances of planetary terrain.\n","authors":["Timothy Chase Jr","Chris Gnam","John Crassidis","Karthik Dantu"],"pdf_url":"https://arxiv.org/pdf/2303.04891v1.pdf","comment":"To be published in proceedings of AAS/AIAA Astrodynamics Specialist\n  Conference 2022"},{"id":"http://arxiv.org/abs/2208.10609v2","updated":"2023-03-08T21:10:38Z","published":"2022-08-22T21:30:55Z","title":"Global Concept-Based Interpretability for Graph Neural Networks via\n  Neuron Analysis","summary":"  Graph neural networks (GNNs) are highly effective on a variety of\ngraph-related tasks; however, they lack interpretability and transparency.\nCurrent explainability approaches are typically local and treat GNNs as\nblack-boxes. They do not look inside the model, inhibiting human trust in the\nmodel and explanations. Motivated by the ability of neurons to detect\nhigh-level semantic concepts in vision models, we perform a novel analysis on\nthe behaviour of individual GNN neurons to answer questions about GNN\ninterpretability, and propose new metrics for evaluating the interpretability\nof GNN neurons. We propose a novel approach for producing global explanations\nfor GNNs using neuron-level concepts to enable practitioners to have a\nhigh-level view of the model. Specifically, (i) to the best of our knowledge,\nthis is the first work which shows that GNN neurons act as concept detectors\nand have strong alignment with concepts formulated as logical compositions of\nnode degree and neighbourhood properties; (ii) we quantitatively assess the\nimportance of detected concepts, and identify a trade-off between training\nduration and neuron-level interpretability; (iii) we demonstrate that our\nglobal explainability approach has advantages over the current state-of-the-art\n-- we can disentangle the explanation into individual interpretable concepts\nbacked by logical descriptions, which reduces potential for bias and improves\nuser-friendliness.\n","authors":["Han Xuanyuan","Pietro Barbiero","Dobrik Georgiev","Lucie Charlotte Magister","Pietro Lió"],"pdf_url":"https://arxiv.org/pdf/2208.10609v2.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2203.13848v3","updated":"2023-03-08T20:54:36Z","published":"2022-03-25T18:26:44Z","title":"Compositional optimization of quantum circuits for quantum kernels of\n  support vector machines","summary":"  While quantum machine learning (ML) has been proposed to be one of the most\npromising applications of quantum computing, how to build quantum ML models\nthat outperform classical ML remains a major open question. Here, we\ndemonstrate a Bayesian algorithm for constructing quantum kernels for support\nvector machines that adapts quantum gate sequences to data. The algorithm\nincreases the complexity of quantum circuits incrementally by appending quantum\ngates selected with Bayesian information criterion as circuit selection metric\nand Bayesian optimization of the parameters of the locally optimal quantum\ncircuits identified. The goal is to build quantum kernels for SVM that can\nsolve classification problems with as little training data as possible. The\nperformance of the resulting quantum models for the classification problems\nconsidered here significantly exceeds that of optimized classical models with\nconventional kernels.\n","authors":["Elham Torabian","Roman V. Krems"],"pdf_url":"https://arxiv.org/pdf/2203.13848v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04887v1","updated":"2023-03-08T20:52:57Z","published":"2023-03-08T20:52:57Z","title":"Memory-adaptive Depth-wise Heterogenous Federated Learning","summary":"  Federated learning is a promising paradigm that allows multiple clients to\ncollaboratively train a model without sharing the local data. However, the\npresence of heterogeneous devices in federated learning, such as mobile phones\nand IoT devices with varying memory capabilities, would limit the scale and\nhence the performance of the model could be trained. The mainstream approaches\nto address memory limitations focus on width-slimming techniques, where\ndifferent clients train subnetworks with reduced widths locally and then the\nserver aggregates the subnetworks. The global model produced from these methods\nsuffers from performance degradation due to the negative impact of the actions\ntaken to handle the varying subnetwork widths in the aggregation phase. In this\npaper, we introduce a memory-adaptive depth-wise learning solution in FL called\nFeDepth, which adaptively decomposes the full model into blocks according to\nthe memory budgets of each client and trains blocks sequentially to obtain a\nfull inference model. Our method outperforms state-of-the-art approaches,\nachieving 5% and more than 10% improvements in top-1 accuracy on CIFAR-10 and\nCIFAR-100, respectively. We also demonstrate the effectiveness of depth-wise\nfine-tuning on ViT. Our findings highlight the importance of memory-aware\ntechniques for federated learning with heterogeneous devices and the success of\ndepth-wise training strategy in improving the global model's performance.\n","authors":["Kai Zhang","Yutong Dai","Hongyi Wang","Eric Xing","Xun Chen","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2303.04887v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.11440v5","updated":"2023-03-08T20:43:36Z","published":"2020-06-19T23:50:51Z","title":"Local Convolutions Cause an Implicit Bias towards High Frequency\n  Adversarial Examples","summary":"  Adversarial Attacks are still a significant challenge for neural networks.\nRecent work has shown that adversarial perturbations typically contain\nhigh-frequency features, but the root cause of this phenomenon remains unknown.\nInspired by theoretical work on linear full-width convolutional models, we\nhypothesize that the local (i.e. bounded-width) convolutional operations\ncommonly used in current neural networks are implicitly biased to learn high\nfrequency features, and that this is one of the root causes of high frequency\nadversarial examples. To test this hypothesis, we analyzed the impact of\ndifferent choices of linear and nonlinear architectures on the implicit bias of\nthe learned features and the adversarial perturbations, in both spatial and\nfrequency domains. We find that the high-frequency adversarial perturbations\nare critically dependent on the convolution operation because the\nspatially-limited nature of local convolutions induces an implicit bias towards\nhigh frequency features. The explanation for the latter involves the Fourier\nUncertainty Principle: a spatially-limited (local in the space domain) filter\ncannot also be frequency-limited (local in the frequency domain). Furthermore,\nusing larger convolution kernel sizes or avoiding convolutions (e.g. by using\nVision Transformers architecture) significantly reduces this high frequency\nbias, but not the overall susceptibility to attacks. Looking forward, our work\nstrongly suggests that understanding and controlling the implicit bias of\narchitectures will be essential for achieving adversarial robustness.\n","authors":["Josue Ortega Caro","Yilong Ju","Ryan Pyle","Sourav Dey","Wieland Brendel","Fabio Anselmi","Ankit Patel"],"pdf_url":"https://arxiv.org/pdf/2006.11440v5.pdf","comment":"23 pages, 11 figures, 12 Tables"},{"id":"http://arxiv.org/abs/2205.15372v3","updated":"2023-03-08T20:35:40Z","published":"2022-05-30T18:32:20Z","title":"Optimistic Whittle Index Policy: Online Learning for Restless Bandits","summary":"  Restless multi-armed bandits (RMABs) extend multi-armed bandits to allow for\nstateful arms, where the state of each arm evolves restlessly with different\ntransitions depending on whether that arm is pulled. Solving RMABs requires\ninformation on transition dynamics, which are often unknown upfront. To plan in\nRMAB settings with unknown transitions, we propose the first online learning\nalgorithm based on the Whittle index policy, using an upper confidence bound\n(UCB) approach to learn transition dynamics. Specifically, we estimate\nconfidence bounds of the transition probabilities and formulate a bilinear\nprogram to compute optimistic Whittle indices using these estimates. Our\nalgorithm, UCWhittle, achieves sublinear $O(H \\sqrt{T \\log T})$ frequentist\nregret to solve RMABs with unknown transitions in $T$ episodes with a constant\nhorizon $H$. Empirically, we demonstrate that UCWhittle leverages the structure\nof RMABs and the Whittle index policy solution to achieve better performance\nthan existing online learning baselines across three domains, including one\nconstructed from a real-world maternal and childcare dataset.\n","authors":["Kai Wang*","Lily Xu","Aparna Taneja","Milind Tambe"],"pdf_url":"https://arxiv.org/pdf/2205.15372v3.pdf","comment":"Accepted at AAAI 2023. 7 page paper, 2 page references, 9 page\n  appendix. Code available. Proceedings of the Thirty-Seventh AAAI Conference\n  on Artificial Intelligence (AAAI 2023)"},{"id":"http://arxiv.org/abs/2303.04878v1","updated":"2023-03-08T20:33:09Z","published":"2023-03-08T20:33:09Z","title":"DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep\n  Neural Networks","summary":"  Deep neural networks (DNNs) are widely used in various application domains\nsuch as image processing, speech recognition, and natural language processing.\nHowever, testing DNN models may be challenging due to the complexity and size\nof their input domain. Particularly, testing DNN models often requires\ngenerating or exploring large unlabeled datasets. In practice, DNN test\noracles, which identify the correct outputs for inputs, often require expensive\nmanual effort to label test data, possibly involving multiple experts to ensure\nlabeling correctness.\n  In this paper, we propose DeepGD, a black-box multi-objective test selection\napproach for DNN models. It reduces the cost of labeling by prioritizing the\nselection of test inputs with high fault revealing power from large unlabeled\ndatasets. DeepGD not only selects test inputs with high uncertainty scores to\ntrigger as many mispredicted inputs as possible but also maximizes the\nprobability of revealing distinct faults in the DNN model by selecting diverse\nmispredicted inputs.\n  The experimental results conducted on four widely used datasets and five DNN\nmodels show that in terms of fault-revealing ability: (1) White-box,\ncoverage-based approaches fare poorly, (2) DeepGD outperforms existing\nblack-box test selection approaches in terms of fault detection, and (3) DeepGD\nalso leads to better guidance for DNN model retraining when using selected\ninputs to augment the training set.\n","authors":["Zohreh Aghababaeyan","Manel Abdellatif","Mahboubeh Dadkhah","Lionel Briand"],"pdf_url":"https://arxiv.org/pdf/2303.04878v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2206.02169v2","updated":"2023-03-08T18:36:51Z","published":"2022-06-05T13:03:34Z","title":"Formally Verified Solution Methods for Infinite-Horizon Markov Decision\n  Processes","summary":"  We formally verify executable algorithms for solving Markov decision\nprocesses (MDPs) in the interactive theorem prover Isabelle/HOL. We build on\nexisting formalizations of probability theory to analyze the expected total\nreward criterion on infinite-horizon problems. Our developments formalize the\nBellman equation and give conditions under which optimal policies exist. Based\non this analysis, we verify dynamic programming algorithms to solve tabular\nMDPs. We evaluate the formally verified implementations experimentally on\nstandard problems and show they are practical. Furthermore, we show that,\ncombined with efficient unverified implementations, our system can compete with\nand even outperform state-of-the-art systems.\n","authors":["Maximilian Schäfeller","Mohammad Abdulaziz"],"pdf_url":"https://arxiv.org/pdf/2206.02169v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07845v2","updated":"2023-03-08T18:07:33Z","published":"2023-01-19T01:51:37Z","title":"Foresee What You Will Learn: Data Augmentation for Domain Generalization\n  in Non-stationary Environment","summary":"  Existing domain generalization aims to learn a generalizable model to perform\nwell even on unseen domains. For many real-world machine learning applications,\nthe data distribution often shifts gradually along domain indices. For example,\na self-driving car with a vision system drives from dawn to dusk, with the sky\ndarkening gradually. Therefore, the system must be able to adapt to changes in\nambient illumination and continue to drive safely on the road. In this paper,\nwe formulate such problems as Evolving Domain Generalization, where a model\naims to generalize well on a target domain by discovering and leveraging the\nevolving pattern of the environment. We then propose Directional Domain\nAugmentation (DDA), which simulates the unseen target features by mapping\nsource data as augmentations through a domain transformer. Specifically, we\nformulate DDA as a bi-level optimization problem and solve it through a novel\nmeta-learning approach in the representation space. We evaluate the proposed\nmethod on both synthetic datasets and realworld datasets, and empirical results\nshow that our approach can outperform other existing methods.\n","authors":["Qiuhao Zeng","Wei Wang","Fan Zhou","Charles Ling","Boyu Wang"],"pdf_url":"https://arxiv.org/pdf/2301.07845v2.pdf","comment":"12 pages, 6 figures, accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2211.02736v3","updated":"2023-03-08T17:46:27Z","published":"2022-11-04T20:22:58Z","title":"Discovering Closed-Loop Failures of Vision-Based Controllers via\n  Reachability Analysis","summary":"  Machine learning driven image-based controllers allow robotic systems to take\nintelligent actions based on the visual feedback from their environment.\nUnderstanding when these controllers might lead to system safety violations is\nimportant for their integration in safety-critical applications and engineering\ncorrective safety measures for the system. Existing methods leverage\nsimulation-based testing (or falsification) to find the failures of\nvision-based controllers, i.e., the visual inputs that lead to closed-loop\nsafety violations. However, these techniques do not scale well to the scenarios\ninvolving high-dimensional and complex visual inputs, such as RGB images. In\nthis work, we cast the problem of finding closed-loop vision failures as a\nHamilton-Jacobi (HJ) reachability problem. Our approach blends simulation-based\nanalysis with HJ reachability methods to compute an approximation of the\nbackward reachable tube (BRT) of the system, i.e., the set of unsafe states for\nthe system under vision-based controllers. Utilizing the BRT, we can tractably\nand systematically find the system states and corresponding visual inputs that\nlead to closed-loop failures. These visual inputs can be subsequently analyzed\nto find the input characteristics that might have caused the failure. Besides\nits scalability to high-dimensional visual inputs, an explicit computation of\nBRT allows the proposed approach to capture non-trivial system failures that\nare difficult to expose via random simulations. We demonstrate our framework on\ntwo case studies involving an RGB image-based neural network controller for (a)\nautonomous indoor navigation, and (b) autonomous aircraft taxiing.\n","authors":["Kaustav Chakraborty","Somil Bansal"],"pdf_url":"https://arxiv.org/pdf/2211.02736v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04751v1","updated":"2023-03-08T17:34:15Z","published":"2023-03-08T17:34:15Z","title":"Multimodal Parameter-Efficient Few-Shot Class Incremental Learning","summary":"  Few-Shot Class Incremental Learning (FSCIL) is a challenging continual\nlearning task, where limited training examples are available during several\nlearning sessions. To succeed in this task, it is necessary to avoid\nover-fitting new classes caused by biased distributions in the few-shot\ntraining sets. The general approach to address this issue involves enhancing\nthe representational capability of a pre-defined backbone architecture by\nadding special modules for backward compatibility with older classes. However,\nthis approach has not yet solved the dilemma of ensuring high classification\naccuracy over time while reducing the gap between the performance obtained on\nlarger training sets and the smaller ones. In this work, we propose an\nalternative approach called Continual Parameter-Efficient CLIP (CPE-CLIP) to\nreduce the loss of information between different learning sessions. Instead of\nadapting additional modules to address information loss, we leverage the vast\nknowledge acquired by CLIP in large-scale pre-training and its effectiveness in\ngeneralizing to new concepts. Our approach is multimodal and\nparameter-efficient, relying on learnable prompts for both the language and\nvision encoders to enable transfer learning across sessions. We also introduce\nprompt regularization to improve performance and prevent forgetting. Our\nexperimental results demonstrate that CPE-CLIP significantly improves FSCIL\nperformance compared to state-of-the-art proposals while also drastically\nreducing the number of learnable parameters and training costs.\n","authors":["Marco D'Alessandro","Alberto Alonso","Enrique Calabrés","Mikel Galar"],"pdf_url":"https://arxiv.org/pdf/2303.04751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04743v1","updated":"2023-03-08T17:27:39Z","published":"2023-03-08T17:27:39Z","title":"Vector Quantized Time Series Generation with a Bidirectional Prior Model","summary":"  Time series generation (TSG) studies have mainly focused on the use of\nGenerative Adversarial Networks (GANs) combined with recurrent neural network\n(RNN) variants. However, the fundamental limitations and challenges of training\nGANs still remain. In addition, the RNN-family typically has difficulties with\ntemporal consistency between distant timesteps. Motivated by the successes in\nthe image generation (IMG) domain, we propose TimeVQVAE, the first work, to our\nknowledge, that uses vector quantization (VQ) techniques to address the TSG\nproblem. Moreover, the priors of the discrete latent spaces are learned with\nbidirectional transformer models that can better capture global temporal\nconsistency. We also propose VQ modeling in a time-frequency domain, separated\ninto low-frequency (LF) and high-frequency (HF). This allows us to retain\nimportant characteristics of the time series and, in turn, generate new\nsynthetic signals that are of better quality, with sharper changes in\nmodularity, than its competing TSG methods. Our experimental evaluation is\nconducted on all datasets from the UCR archive, using well-established metrics\nin the IMG literature, such as Fr\\'echet inception distance and inception\nscores. Our implementation on GitHub:\n\\url{https://github.com/ML4ITS/TimeVQVAE}.\n","authors":["Daesoo Lee","Sara Malacarne","Erlend Aune"],"pdf_url":"https://arxiv.org/pdf/2303.04743v1.pdf","comment":"accepted at AISTATS 2023"},{"id":"http://arxiv.org/abs/2303.04731v1","updated":"2023-03-08T17:18:13Z","published":"2023-03-08T17:18:13Z","title":"Towards Trust of Explainable AI in Thyroid Nodule Diagnosis","summary":"  The ability to explain the prediction of deep learning models to end-users is\nan important feature to leverage the power of artificial intelligence (AI) for\nthe medical decision-making process, which is usually considered\nnon-transparent and challenging to comprehend. In this paper, we apply\nstate-of-the-art eXplainable artificial intelligence (XAI) methods to explain\nthe prediction of the black-box AI models in the thyroid nodule diagnosis\napplication. We propose new statistic-based XAI methods, namely Kernel Density\nEstimation and Density map, to explain the case of no nodule detected. XAI\nmethods' performances are considered under a qualitative and quantitative\ncomparison as feedback to improve the data quality and the model performance.\nFinally, we survey to assess doctors' and patients' trust in XAI explanations\nof the model's decisions on thyroid nodule images.\n","authors":["Truong Thanh Hung Nguyen","Van Binh Truong","Vo Thanh Khang Nguyen","Quoc Hung Cao","Quoc Khanh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2303.04731v1.pdf","comment":"Accepted by AAAI 2023 The 7th International Workshop on Health\n  Intelligence (W3PHIAI-23)"},{"id":"http://arxiv.org/abs/2303.04715v1","updated":"2023-03-08T16:53:19Z","published":"2023-03-08T16:53:19Z","title":"Extending the Pre-Training of BLOOM for Improved Support of Traditional\n  Chinese: Models, Methods and Results","summary":"  In this paper we present the multilingual language model BLOOM-zh that\nfeatures enhanced support for Traditional Chinese. BLOOM-zh has its origins in\nthe open-source BLOOM models presented by BigScience in 2022. Starting from\nreleased models, we extended the pre-training of BLOOM by additional 7.4\nbillion tokens in Traditional Chinese and English covering a variety of domains\nsuch as news articles, books, encyclopedias, educational materials as well as\nspoken language. In order to show the properties of BLOOM-zh, both existing and\nnewly created benchmark scenarios are used for evaluating the performance.\nBLOOM-zh outperforms its predecessor on most Traditional Chinese benchmarks\nwhile maintaining its English capability. We release all our models to the\nresearch community.\n","authors":["Philipp Ennen","Po-Chun Hsu","Chan-Jan Hsu","Chang-Le Liu","Yen-Chen Wu","Yin-Hsiang Liao","Chin-Tung Lin","Da-Shan Shiu","Wei-Yun Ma"],"pdf_url":"https://arxiv.org/pdf/2303.04715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.17517v2","updated":"2023-03-08T16:47:46Z","published":"2022-10-31T17:41:26Z","title":"Lila: A Unified Benchmark for Mathematical Reasoning","summary":"  Mathematical reasoning skills are essential for general-purpose intelligent\nsystems to perform tasks from grocery shopping to climate modeling. Towards\nevaluating and improving AI systems in this domain, we propose LILA, a unified\nmathematical reasoning benchmark consisting of 23 diverse tasks along four\ndimensions: (i) mathematical abilities e.g., arithmetic, calculus (ii) language\nformat e.g., question-answering, fill-in-the-blanks (iii) language diversity\ne.g., no language, simple language (iv) external knowledge e.g., commonsense,\nphysics. We construct our benchmark by extending 20 datasets benchmark by\ncollecting task instructions and solutions in the form of Python programs,\nthereby obtaining explainable solutions in addition to the correct answer. We\nadditionally introduce two evaluation datasets to measure out-of-distribution\nperformance and robustness to language perturbation. Finally, we introduce\nBHASKARA, a general-purpose mathematical reasoning model trained on LILA.\nImportantly, we find that multi-tasking leads to significant improvements\n(average relative improvement of 21.83% F1 score vs. single-task models), while\nthe best performing model only obtains 60.40%, indicating the room for\nimprovement in general mathematical reasoning and understanding.\n","authors":["Swaroop Mishra","Matthew Finlayson","Pan Lu","Leonard Tang","Sean Welleck","Chitta Baral","Tanmay Rajpurohit","Oyvind Tafjord","Ashish Sabharwal","Peter Clark","Ashwin Kalyan"],"pdf_url":"https://arxiv.org/pdf/2210.17517v2.pdf","comment":"EMNLP 2022"},{"id":"http://arxiv.org/abs/2301.12093v3","updated":"2023-03-08T16:30:18Z","published":"2023-01-28T05:18:13Z","title":"Local Contrast and Global Contextual Information Make Infrared Small\n  Object Salient Again","summary":"  Infrared small object detection (ISOS) aims to segment small objects only\ncovered with several pixels from clutter background in infrared images. It's of\ngreat challenge due to: 1) small objects lack of sufficient intensity, shape\nand texture information; 2) small objects are easily lost in the process where\ndetection models, say deep neural networks, obtain high-level semantic features\nand image-level receptive fields through successive downsampling. This paper\nproposes a reliable detection model for ISOS, dubbed UCFNet, which can handle\nwell the two issues. It builds upon central difference convolution (CDC) and\nfast Fourier convolution (FFC). On one hand, CDC can effectively guide the\nnetwork to learn the contrast information between small objects and the\nbackground, as the contrast information is very essential in human visual\nsystem dealing with the ISOS task. On the other hand, FFC can gain image-level\nreceptive fields and extract global information while preventing small objects\nfrom being overwhelmed.Experiments on several public datasets demonstrate that\nour method significantly outperforms the state-of-the-art ISOS models, and can\nprovide useful guidelines for designing better ISOS deep models. Code are\navailable at https://github.com/wcyjerry/BasicISOS.\n","authors":["Chenyi Wang","Huan Wang","Peiwen Pan"],"pdf_url":"https://arxiv.org/pdf/2301.12093v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04673v1","updated":"2023-03-08T15:52:14Z","published":"2023-03-08T15:52:14Z","title":"Cost-Effective Hyperparameter Optimization for Large Language Model\n  Generation Inference","summary":"  Large Language Models (LLMs) like GPT-3 have sparked significant interest in\ntheir generative capabilities, leading to the development of various commercial\napplications. The high cost of using the models drives application builders to\nmaximize the value of generation under a limited inference budget. This paper\npresents a study of optimizing inference hyperparameters like the number of\nresponses, temperature and max tokens, which significantly affects the\nutility/cost of text generation. We design a framework named EcoOptiGen which\nleverages economical hyperparameter optimization and cost-based pruning.\nExperiments with the latest GPT-3.5 models on a variety of tasks verify its\neffectiveness. EcoOptiGen is implemented in the FLAML library:\nhttps://github.com/microsoft/FLAML, and we provide one example of using it at:\nhttps://microsoft.github.io/FLAML/docs/Examples/Integrate%20-%20OpenAI.\n","authors":["Chi Wang","Susan Xueqing Liu","Ahmed H. Awadallah"],"pdf_url":"https://arxiv.org/pdf/2303.04673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01509v2","updated":"2023-03-08T15:35:56Z","published":"2022-12-03T02:24:59Z","title":"Reinforcement learning with Demonstrations from Mismatched Task under\n  Sparse Reward","summary":"  Reinforcement learning often suffer from the sparse reward issue in\nreal-world robotics problems. Learning from demonstration (LfD) is an effective\nway to eliminate this problem, which leverages collected expert data to aid\nonline learning. Prior works often assume that the learning agent and the\nexpert aim to accomplish the same task, which requires collecting new data for\nevery new task. In this paper, we consider the case where the target task is\nmismatched from but similar with that of the expert. Such setting can be\nchallenging and we found existing LfD methods can not effectively guide\nlearning in mismatched new tasks with sparse rewards. We propose conservative\nreward shaping from demonstration (CRSfD), which shapes the sparse rewards\nusing estimated expert value function. To accelerate learning processes, CRSfD\nguides the agent to conservatively explore around demonstrations. Experimental\nresults of robot manipulation tasks show that our approach outperforms baseline\nLfD methods when transferring demonstrations collected in a single task to\nother different but similar tasks.\n","authors":["Yanjiang Guo","Jingyue Gao","Zheng Wu","Chengming Shi","Jianyu Chen"],"pdf_url":"https://arxiv.org/pdf/2212.01509v2.pdf","comment":"11 pages, 5 figures, CoRL 2022"},{"id":"http://arxiv.org/abs/2303.04660v1","updated":"2023-03-08T15:27:29Z","published":"2023-03-08T15:27:29Z","title":"Neural Probabilistic Logic Programming in Discrete-Continuous Domains","summary":"  Neural-symbolic AI (NeSy) allows neural networks to exploit symbolic\nbackground knowledge in the form of logic. It has been shown to aid learning in\nthe limited data regime and to facilitate inference on out-of-distribution\ndata. Probabilistic NeSy focuses on integrating neural networks with both logic\nand probability theory, which additionally allows learning under uncertainty. A\nmajor limitation of current probabilistic NeSy systems, such as DeepProbLog, is\ntheir restriction to finite probability distributions, i.e., discrete random\nvariables. In contrast, deep probabilistic programming (DPP) excels in\nmodelling and optimising continuous probability distributions. Hence, we\nintroduce DeepSeaProbLog, a neural probabilistic logic programming language\nthat incorporates DPP techniques into NeSy. Doing so results in the support of\ninference and learning of both discrete and continuous probability\ndistributions under logical constraints. Our main contributions are 1) the\nsemantics of DeepSeaProbLog and its corresponding inference algorithm, 2) a\nproven asymptotically unbiased learning algorithm, and 3) a series of\nexperiments that illustrate the versatility of our approach.\n","authors":["Lennert De Smet","Pedro Zuidberg Dos Martires","Robin Manhaeve","Giuseppe Marra","Angelika Kimmig","Luc De Readt"],"pdf_url":"https://arxiv.org/pdf/2303.04660v1.pdf","comment":"27 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.04651v1","updated":"2023-03-08T15:19:27Z","published":"2023-03-08T15:19:27Z","title":"MCTS-GEB: Monte Carlo Tree Search is a Good E-graph Builder","summary":"  Rewrite systems [6, 10, 12] have been widely employing equality saturation\n[9], which is an optimisation methodology that uses a saturated e-graph to\nrepresent all possible sequences of rewrite simultaneously, and then extracts\nthe optimal one. As such, optimal results can be achieved by avoiding the\nphase-ordering problem. However, we observe that when the e-graph is not\nsaturated, it cannot represent all possible rewrite opportunities and therefore\nthe phase-ordering problem is re-introduced during the construction phase of\nthe e-graph. To address this problem, we propose MCTS-GEB, a domain-general\nrewrite system that applies reinforcement learning (RL) to e-graph\nconstruction. At its core, MCTS-GEB uses a Monte Carlo Tree Search (MCTS) [3]\nto efficiently plan for the optimal e-graph construction, and therefore it can\neffectively eliminate the phase-ordering problem at the construction phase and\nachieve better performance within a reasonable time. Evaluation in two\ndifferent domains shows MCTS-GEB can outperform the state-of-the-art rewrite\nsystems by up to 49x, while the optimisation can generally take less than an\nhour, indicating MCTS-GEB is a promising building block for the future\ngeneration of rewrite systems.\n","authors":["Guoliang He","Zak Singh","Eiko Yoneki"],"pdf_url":"https://arxiv.org/pdf/2303.04651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01616v2","updated":"2023-03-08T14:26:11Z","published":"2023-02-03T09:28:39Z","title":"A geometrically aware auto-encoder for multi-texture synthesis","summary":"  We propose an auto-encoder architecture for multi-texture synthesis. The\napproach relies on both a compact encoder accounting for second order neural\nstatistics and a generator incorporating adaptive periodic content. Images are\nembedded in a compact and geometrically consistent latent space, where the\ntexture representation and its spatial organisation are disentangled. Texture\nsynthesis and interpolation tasks can be performed directly from these latent\ncodes. Our experiments demonstrate that our model outperforms state-of-the-art\nfeed-forward methods in terms of visual quality and various texture related\nmetrics.\n","authors":["Pierrick Chatillon","Yann Gousseau","Sidonie Lefebvre"],"pdf_url":"https://arxiv.org/pdf/2302.01616v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04587v1","updated":"2023-03-08T13:59:41Z","published":"2023-03-08T13:59:41Z","title":"A Prompt Log Analysis of Text-to-Image Generation Systems","summary":"  Recent developments in diffusion models have unleashed the astonishing\ncapabilities of text-to-image generation systems to synthesize high-quality\nimages that are faithful to a given reference text, known as a \"prompt.\" These\nsystems, once released to the public, have immediately received tons of\nattention from researchers, creators, and common users. Despite the plenty of\nefforts to improve the underneath generative models, there is limited work on\nunderstanding the information needs of the real users of these systems, e.g.,\nby investigating the prompts the users input at scale. In this paper, we take\nthe initiative to conduct a comprehensive analysis of large-scale prompt logs\ncollected from multiple text-to-image generation systems. Our work is analogous\nto analyzing the query log of Web search engines, a line of work that has made\ncritical contributions to the glory of the Web search industry and research. We\nanalyze over two million user-input prompts submitted to three popular\ntext-to-image systems at scale. Compared to Web search queries, text-to-image\nprompts are significantly longer, often organized into unique structures, and\npresent different categories of information needs. Users tend to make more\nedits within creation sessions, showing remarkable exploratory patterns. Our\nfindings provide concrete implications on how to improve text-to-image\ngeneration systems for creation purposes.\n","authors":["Yutong Xie","Zhaoying Pan","Jinge Ma","Jie Luo","Qiaozhu Mei"],"pdf_url":"https://arxiv.org/pdf/2303.04587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04585v1","updated":"2023-03-08T13:58:55Z","published":"2023-03-08T13:58:55Z","title":"New Audio Representations Image Gan Generation from BriVL","summary":"  Recently, researchers have gradually realized that in some cases, the\nself-supervised pre-training on large-scale Internet data is better than that\nof high-quality/manually labeled data sets, and multimodal/large models are\nbetter than single or bimodal/small models. In this paper, we propose a robust\naudio representation learning method WavBriVL based on\nBridging-Vision-and-Language (BriVL). WavBriVL projects audio, image and text\ninto a shared embedded space, so that multi-modal applications can be realized.\nWe demonstrate the qualitative evaluation of the image generated from WavBriVL\nas a shared embedded space, with the main purposes of this paper: (1) Learning\nthe correlation between audio and image; (2) Explore a new way of image\ngeneration, that is, use audio to generate pictures. Experimental results show\nthat this method can effectively generate appropriate images from audio.\n","authors":["Sen Fang","Yangjian Wu","Bowen Gao","Teik Toe Teoh"],"pdf_url":"https://arxiv.org/pdf/2303.04585v1.pdf","comment":"ICASSP Workshop submission"},{"id":"http://arxiv.org/abs/2303.04579v1","updated":"2023-03-08T13:54:57Z","published":"2023-03-08T13:54:57Z","title":"\"How to make them stay?\" -- Diverse Counterfactual Explanations of\n  Employee Attrition","summary":"  Employee attrition is an important and complex problem that can directly\naffect an organisation's competitiveness and performance. Explaining the\nreasons why employees leave an organisation is a key human resource management\nchallenge due to the high costs and time required to attract and keep talented\nemployees. Businesses therefore aim to increase employee retention rates to\nminimise their costs and maximise their performance. Machine learning (ML) has\nbeen applied in various aspects of human resource management including\nattrition prediction to provide businesses with insights on proactive measures\non how to prevent talented employees from quitting. Among these ML methods, the\nbest performance has been reported by ensemble or deep neural networks, which\nby nature constitute black box techniques and thus cannot be easily\ninterpreted. To enable the understanding of these models' reasoning several\nexplainability frameworks have been proposed. Counterfactual explanation\nmethods have attracted considerable attention in recent years since they can be\nused to explain and recommend actions to be performed to obtain the desired\noutcome. However current counterfactual explanations methods focus on\noptimising the changes to be made on individual cases to achieve the desired\noutcome. In the attrition problem it is important to be able to foresee what\nwould be the effect of an organisation's action to a group of employees where\nthe goal is to prevent them from leaving the company. Therefore, in this paper\nwe propose the use of counterfactual explanations focusing on multiple\nattrition cases from historical data, to identify the optimum interventions\nthat an organisation needs to make to its practices/policies to prevent or\nminimise attrition probability for these cases.\n","authors":["André Artelt","Andreas Gregoriades"],"pdf_url":"https://arxiv.org/pdf/2303.04579v1.pdf","comment":"Accepted as a short paper at ICEIS 2023"},{"id":"http://arxiv.org/abs/2210.11879v4","updated":"2023-03-08T13:45:55Z","published":"2022-10-21T11:08:10Z","title":"GLCC: A General Framework for Graph-Level Clustering","summary":"  This paper studies the problem of graph-level clustering, which is a novel\nyet challenging task. This problem is critical in a variety of real-world\napplications such as protein clustering and genome analysis in bioinformatics.\nRecent years have witnessed the success of deep clustering coupled with graph\nneural networks (GNNs). However, existing methods focus on clustering among\nnodes given a single graph, while exploring clustering on multiple graphs is\nstill under-explored. In this paper, we propose a general graph-level\nclustering framework named Graph-Level Contrastive Clustering (GLCC) given\nmultiple graphs. Specifically, GLCC first constructs an adaptive affinity graph\nto explore instance- and cluster-level contrastive learning (CL).\nInstance-level CL leverages graph Laplacian based contrastive loss to learn\nclustering-friendly representations while cluster-level CL captures\ndiscriminative cluster representations incorporating neighbor information of\neach sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the\noptimization of representation learning. The two steps can be alternatively\ntrained to collaborate and benefit each other. Experiments on a range of\nwell-known datasets demonstrate the superiority of our proposed GLCC over\ncompetitive baselines.\n","authors":["Wei Ju","Yiyang Gu","Binqi Chen","Gongbo Sun","Yifang Qin","Xingyuming Liu","Xiao Luo","Ming Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.11879v4.pdf","comment":"Accepted by Proceedings of the AAAI Conference on Artificial\n  Intelligence (AAAI 2023)"},{"id":"http://arxiv.org/abs/2303.04571v1","updated":"2023-03-08T13:37:01Z","published":"2023-03-08T13:37:01Z","title":"A Categorical Framework of General Intelligence","summary":"  Can machines think? Since Alan Turing asked this question in 1950, nobody is\nable to give a direct answer, due to the lack of solid mathematical foundations\nfor general intelligence. In this paper, we introduce a categorical framework\ntowards this goal, consisting of four components: the sensor, world category,\nplanner with objectives, and actor. By leveraging category theory, many\nimportant notions in general intelligence can be rigorously defined and\nanalyzed. For instance, we introduce the concept of self-state awareness as a\ncategorical analogy for self-consciousness and provide algorithms for learning\nand evaluating it. For communication with other agents, we propose to use\ndiagrams that capture the exact representation of the context, instead of using\nnatural languages. Additionally, we demonstrate that by designing the\nobjectives as the output of function over self-state, the model's\nhuman-friendliness is guaranteed. Most importantly, our framework naturally\nintroduces various constraints based on categorical invariance that can serve\nas the alignment signals for training a model that fits into the framework.\n","authors":["Yang Yuan"],"pdf_url":"https://arxiv.org/pdf/2303.04571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.15720v3","updated":"2023-03-08T13:35:04Z","published":"2021-10-08T20:17:10Z","title":"Weakly Supervised Concept Map Generation through Task-Guided Graph\n  Translation","summary":"  Recent years have witnessed the rapid development of concept map generation\ntechniques due to their advantages in providing well-structured summarization\nof knowledge from free texts. Traditional unsupervised methods do not generate\ntask-oriented concept maps, whereas deep generative models require large\namounts of training data. In this work, we present GT-D2G (Graph\nTranslation-based Document To Graph), an automatic concept map generation\nframework that leverages generalized NLP pipelines to derive semantic-rich\ninitial graphs, and translates them into more concise structures under the weak\nsupervision of downstream task labels. The concept maps generated by GT-D2G can\nprovide interpretable summarization of structured knowledge for the input\ntexts, which are demonstrated through human evaluation and case studies on\nthree real-world corpora. Further experiments on the downstream task of\ndocument classification show that GT-D2G beats other concept map generation\nmethods. Moreover, we specifically validate the labeling efficiency of GT-D2G\nin the label-efficient learning setting and the flexibility of generated graph\nsizes in controlled hyper-parameter studies.\n","authors":["Jiaying Lu","Xiangjue Dong","Carl Yang"],"pdf_url":"https://arxiv.org/pdf/2110.15720v3.pdf","comment":"Accepted by IEEE TKDE. All code and data available at\n  https://github.com/lujiaying/GT-doc2graph"},{"id":"http://arxiv.org/abs/2208.00789v4","updated":"2023-03-08T13:34:28Z","published":"2022-07-28T08:06:24Z","title":"Self-supervised learning with rotation-invariant kernels","summary":"  We introduce a regularization loss based on kernel mean embeddings with\nrotation-invariant kernels on the hypersphere (also known as dot-product\nkernels) for self-supervised learning of image representations. Besides being\nfully competitive with the state of the art, our method significantly reduces\ntime and memory complexity for self-supervised training, making it\nimplementable for very large embedding dimensions on existing devices and more\neasily adjustable than previous methods to settings with limited resources. Our\nwork follows the major paradigm where the model learns to be invariant to some\npredefined image transformations (cropping, blurring, color jittering, etc.),\nwhile avoiding a degenerate solution by regularizing the embedding\ndistribution. Our particular contribution is to propose a loss family promoting\nthe embedding distribution to be close to the uniform distribution on the\nhypersphere, with respect to the maximum mean discrepancy pseudometric. We\ndemonstrate that this family encompasses several regularizers of former\nmethods, including uniformity-based and information-maximization methods, which\nare variants of our flexible regularization loss with different kernels. Beyond\nits practical consequences for state-of-the-art self-supervised learning with\nlimited resources, the proposed generic regularization approach opens\nperspectives to leverage more widely the literature on kernel methods in order\nto improve self-supervised learning methods.\n","authors":["Léon Zheng","Gilles Puy","Elisa Riccietti","Patrick Pérez","Rémi Gribonval"],"pdf_url":"https://arxiv.org/pdf/2208.00789v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04548v1","updated":"2023-03-08T13:01:05Z","published":"2023-03-08T13:01:05Z","title":"Estimation of the qualification and behavior of a contributor and\n  aggregation of his answers in a crowdsourcing context","summary":"  Crowdsourcing is the outsourcing of tasks to a crowd of contributors on a\ndedicated platform. The crowd on these platforms is very diversified and\nincludes various profiles of contributors which generates data of uneven\nquality. However, majority voting, which is the aggregating method commonly\nused in platforms, gives equal weight to each contribution. To overcome this\nproblem, we propose a method, MONITOR, which estimates the contributor's\nprofile and aggregates the collected data by taking into account their possible\nimperfections thanks to the theory of belief functions. To do so, MONITOR\nstarts by estimating the profile of the contributor through his qualification\nfor the task and his behavior.Crowdsourcing campaigns have been carried out to\ncollect the necessary data to test MONITOR on real data in order to compare it\nto existing approaches. The results of the experiments show that thanks to the\nuse of the MONITOR method, we obtain a better rate of correct answer after\naggregation of the contributions compared to the majority voting. Our\ncontributions in this article are for the first time the proposal of a model\nthat takes into account both the qualification of the contributor and his\nbehavior in the estimation of his profile. For the second one, the weakening\nand the aggregation of the answers according to the estimated profiles.\n","authors":["Constance Thierry","Arnaud Martin","Jean-Christophe Dubois","Yolande Le Gall"],"pdf_url":"https://arxiv.org/pdf/2303.04548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04547v1","updated":"2023-03-08T13:00:40Z","published":"2023-03-08T13:00:40Z","title":"Unimodal Distributions for Ordinal Regression","summary":"  In many real-world prediction tasks, class labels contain information about\nthe relative order between labels that are not captured by commonly used loss\nfunctions such as multicategory cross-entropy. Recently, the preference for\nunimodal distributions in the output space has been incorporated into models\nand loss functions to account for such ordering information. However, current\napproaches rely on heuristics that lack a theoretical foundation. Here, we\npropose two new approaches to incorporate the preference for unimodal\ndistributions into the predictive model. We analyse the set of unimodal\ndistributions in the probability simplex and establish fundamental properties.\nWe then propose a new architecture that imposes unimodal distributions and a\nnew loss term that relies on the notion of projection in a set to promote\nunimodality. Experiments show the new architecture achieves top-2 performance,\nwhile the proposed new loss term is very competitive while maintaining high\nunimodality.\n","authors":["Jaime S. Cardoso","Ricardo Cruz","Tomé Albuquerque"],"pdf_url":"https://arxiv.org/pdf/2303.04547v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2303.04544v1","updated":"2023-03-08T12:53:03Z","published":"2023-03-08T12:53:03Z","title":"Models of symbol emergence in communication: a conceptual review and a\n  guide for avoiding local minima","summary":"  Computational simulations are a popular method for testing hypotheses about\nthe emergence of communication. This kind of research is performed in a variety\nof traditions including language evolution, developmental psychology, cognitive\nscience, machine learning, robotics, etc. The motivations for the models are\ndifferent, but the operationalizations and methods used are often similar. We\nidentify the assumptions and explanatory targets of several most representative\nmodels and summarise the known results. We claim that some of the assumptions\n-- such as portraying meaning in terms of mapping, focusing on the descriptive\nfunction of communication, modelling signals with amodal tokens -- may hinder\nthe success of modelling. Relaxing these assumptions and foregrounding the\ninteractions of embodied and situated agents allows one to systematise the\nmultiplicity of pressures under which symbolic systems evolve. In line with\nthis perspective, we sketch the road towards modelling the emergence of\nmeaningful symbolic communication, where symbols are simultaneously grounded in\naction and perception and form an abstract system.\n","authors":["Julian Zubek","Tomasz Korbak","Joanna Rączaszek-Leonardi"],"pdf_url":"https://arxiv.org/pdf/2303.04544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04534v1","updated":"2023-03-08T12:08:53Z","published":"2023-03-08T12:08:53Z","title":"Complexity and scalability of defeasible reasoning in 1 many-valued\n  weighted knowledge bases","summary":"  Weighted knowledge bases for description logics with typicality under a\n\"concept-wise'' multi-preferential semantics provide a logical interpretation\nof MultiLayer Perceptrons. In this context, Answer Set Programming (ASP) has\nbeen shown to be suitable for addressing defeasible reasoning in the finitely\nmany-valued case, providing a $\\Pi^p_2$ upper bound on the complexity of the\nproblem, nonetheless leaving unknown the exact complexity and only providing a\nproof-of-concept implementation. This paper fulfils the lack by providing a\n$P^{NP[log]}$-completeness result and new ASP encodings that deal with weighted\nknowledge bases with large search spaces.\n","authors":["Mario Alviano","Laura Giordano","Daniele Theseider Dupré"],"pdf_url":"https://arxiv.org/pdf/2303.04534v1.pdf","comment":"14 pages 4, figures"},{"id":"http://arxiv.org/abs/2303.04532v1","updated":"2023-03-08T12:04:16Z","published":"2023-03-08T12:04:16Z","title":"Class Cardinality Comparison as a Fermi Problem","summary":"  Questions on class cardinality comparisons are quite tricky to answer and\ncome with its own challenges. They require some kind of reasoning since web\ndocuments and knowledge bases, indispensable sources of information, rarely\nstore direct answers to questions, such as, ``Are there more astronauts or\nPhysics Nobel Laureates?'' We tackle questions on class cardinality comparison\nby tapping into three sources for absolute cardinalities as well as the\ncardinalities of orthogonal subgroups of the classes. We propose novel\ntechniques for aggregating signals with partial coverage for more reliable\nestimates and evaluate them on a dataset of 4005 class pairs, achieving an\naccuracy of 83.7%.\n","authors":["Shrestha Ghosh","Simon Razniewski","Gerhard Weikum"],"pdf_url":"https://arxiv.org/pdf/2303.04532v1.pdf","comment":"Accepted to the Web Conference 2023"},{"id":"http://arxiv.org/abs/2302.04054v4","updated":"2023-03-08T11:37:27Z","published":"2023-02-08T13:47:00Z","title":"Towards Inferential Reproducibility of Machine Learning Research","summary":"  Reliability of machine learning evaluation -- the consistency of observed\nevaluation scores across replicated model training runs -- is affected by\nseveral sources of nondeterminism which can be regarded as measurement noise.\nCurrent tendencies to remove noise in order to enforce reproducibility of\nresearch results neglect inherent nondeterminism at the implementation level\nand disregard crucial interaction effects between algorithmic noise factors and\ndata properties. This limits the scope of conclusions that can be drawn from\nsuch experiments. Instead of removing noise, we propose to incorporate several\nsources of variance, including their interaction with data properties, into an\nanalysis of significance and reliability of machine learning evaluation, with\nthe aim to draw inferences beyond particular instances of trained models. We\nshow how to use linear mixed effects models (LMEMs) to analyze performance\nevaluation scores, and to conduct statistical inference with a generalized\nlikelihood ratio test (GLRT). This allows us to incorporate arbitrary sources\nof noise like meta-parameter variations into statistical significance testing,\nand to assess performance differences conditional on data properties.\nFurthermore, a variance component analysis (VCA) enables the analysis of the\ncontribution of noise sources to overall variance and the computation of a\nreliability coefficient by the ratio of substantial to total variance.\n","authors":["Michael Hagmann","Philipp Meier","Stefan Riezler"],"pdf_url":"https://arxiv.org/pdf/2302.04054v4.pdf","comment":"Published at ICLR 2023 (see https://openreview.net/pdf?id=li4GQCQWkv)"},{"id":"http://arxiv.org/abs/2303.03131v2","updated":"2023-03-08T11:35:51Z","published":"2023-03-06T13:49:15Z","title":"Video Question Answering Using CLIP-Guided Visual-Text Attention","summary":"  Cross-modal learning of video and text plays a key role in Video Question\nAnswering (VideoQA). In this paper, we propose a visual-text attention\nmechanism to utilize the Contrastive Language-Image Pre-training (CLIP) trained\non lots of general domain language-image pairs to guide the cross-modal\nlearning for VideoQA. Specifically, we first extract video features using a\nTimeSformer and text features using a BERT from the target application domain,\nand utilize CLIP to extract a pair of visual-text features from the\ngeneral-knowledge domain through the domain-specific learning. We then propose\na Cross-domain Learning to extract the attention information between visual and\nlinguistic features across the target domain and general domain. The set of\nCLIP-guided visual-text features are integrated to predict the answer. The\nproposed method is evaluated on MSVD-QA and MSRVTT-QA datasets, and outperforms\nstate-of-the-art methods.\n","authors":["Shuhong Ye","Weikai Kong","Chenglin Yao","Jianfeng Ren","Xudong Jiang"],"pdf_url":"https://arxiv.org/pdf/2303.03131v2.pdf","comment":"Submitted to the 2023 IEEE International Conference on Image\n  Processing (ICIP 2023)"},{"id":"http://arxiv.org/abs/2303.04519v1","updated":"2023-03-08T11:18:27Z","published":"2023-03-08T11:18:27Z","title":"An Annexure to the Paper \"Driving the Technology Value Stream by\n  Analyzing App Reviews\"","summary":"  This paper presents a novel framework that utilizes Natural Language\nProcessing (NLP) techniques to understand user feedback on mobile applications.\nThe framework allows software companies to drive their technology value stream\nbased on user reviews, which can highlight areas for improvement. The framework\nis analyzed in depth, and its modules are evaluated for their effectiveness.\nThe proposed approach is demonstrated to be effective through an analysis of\nreviews for sixteen popular Android Play Store applications over a long period\nof time.\n","authors":["Souvick Das","Novarun Deb","Agostino Cortesi","Nabendu Chaki"],"pdf_url":"https://arxiv.org/pdf/2303.04519v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01911v3","updated":"2023-03-08T11:00:55Z","published":"2022-10-04T21:16:48Z","title":"Grounding Language with Visual Affordances over Unstructured Data","summary":"  Recent works have shown that Large Language Models (LLMs) can be applied to\nground natural language to a wide variety of robot skills. However, in\npractice, learning multi-task, language-conditioned robotic skills typically\nrequires large-scale data collection and frequent human intervention to reset\nthe environment or help correcting the current policies. In this work, we\npropose a novel approach to efficiently learn general-purpose\nlanguage-conditioned robot skills from unstructured, offline and reset-free\ndata in the real world by exploiting a self-supervised visuo-lingual affordance\nmodel, which requires annotating as little as 1% of the total data with\nlanguage. We evaluate our method in extensive experiments both in simulated and\nreal-world robotic tasks, achieving state-of-the-art performance on the\nchallenging CALVIN benchmark and learning over 25 distinct visuomotor\nmanipulation tasks with a single policy in the real world. We find that when\npaired with LLMs to break down abstract natural language instructions into\nsubgoals via few-shot prompting, our method is capable of completing\nlong-horizon, multi-tier tasks in the real world, while requiring an order of\nmagnitude less data than previous approaches. Code and videos are available at\nhttp://hulc2.cs.uni-freiburg.de\n","authors":["Oier Mees","Jessica Borja-Diaz","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2210.01911v3.pdf","comment":"Accepted at the 2023 IEEE International Conference on Robotics and\n  Automation (ICRA). Project website: http://hulc2.cs.uni-freiburg.de"},{"id":"http://arxiv.org/abs/2303.04496v1","updated":"2023-03-08T10:39:38Z","published":"2023-03-08T10:39:38Z","title":"MenuCraft: Interactive Menu System Design with Large Language Models","summary":"  Menu system design is a challenging task involving many design options and\nvarious human factors. For example, one crucial factor that designers need to\nconsider is the semantic and systematic relation of menu commands. However,\ncapturing these relations can be challenging due to limited available\nresources. With the advancement of neural language models, large language\nmodels can utilize their vast pre-existing knowledge in designing and refining\nmenu systems.\n  In this paper, we propose MenuCraft, an AI-assisted designer for menu design\nthat enables collaboration between the designer and a dialogue system to design\nmenus. MenuCraft offers an interactive language-based menu design tool that\nsimplifies the menu design process and enables easy customization of design\noptions. MenuCraft supports a variety of interactions through dialog that\nallows performing few-shot learning.\n","authors":["Amir Hossein Kargaran","Nafiseh Nikeghbal","Abbas Heydarnoori","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2303.04496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05714v4","updated":"2023-03-08T10:30:41Z","published":"2022-10-11T18:13:20Z","title":"Visual Language Maps for Robot Navigation","summary":"  Grounding language to the visual observations of a navigating agent can be\nperformed using off-the-shelf visual-language models pretrained on\nInternet-scale data (e.g., image captions). While this is useful for matching\nimages to natural language descriptions of object goals, it remains disjoint\nfrom the process of mapping the environment, so that it lacks the spatial\nprecision of classic geometric maps. To address this problem, we propose\nVLMaps, a spatial map representation that directly fuses pretrained\nvisual-language features with a 3D reconstruction of the physical world. VLMaps\ncan be autonomously built from video feed on robots using standard exploration\napproaches and enables natural language indexing of the map without additional\nlabeled data. Specifically, when combined with large language models (LLMs),\nVLMaps can be used to (i) translate natural language commands into a sequence\nof open-vocabulary navigation goals (which, beyond prior work, can be spatial\nby construction, e.g., \"in between the sofa and TV\" or \"three meters to the\nright of the chair\") directly localized in the map, and (ii) can be shared\namong multiple robots with different embodiments to generate new obstacle maps\non-the-fly (by using a list of obstacle categories). Extensive experiments\ncarried out in simulated and real world environments show that VLMaps enable\nnavigation according to more complex language instructions than existing\nmethods. Videos are available at https://vlmaps.github.io.\n","authors":["Chenguang Huang","Oier Mees","Andy Zeng","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2210.05714v4.pdf","comment":"Accepted at the 2023 IEEE International Conference on Robotics and\n  Automation (ICRA). Project page: https://vlmaps.github.io"},{"id":"http://arxiv.org/abs/2303.04488v1","updated":"2023-03-08T10:22:00Z","published":"2023-03-08T10:22:00Z","title":"Magnushammer: A Transformer-based Approach to Premise Selection","summary":"  Premise selection is a fundamental problem of automated theorem proving.\nPrevious works often use intricate symbolic methods, rely on domain knowledge,\nand require significant engineering effort to solve this task. In this work, we\nshow that Magnushammer, a neural transformer-based approach, can outperform\ntraditional symbolic systems by a large margin. Tested on the PISA benchmark,\nMagnushammer achieves $59.5\\%$ proof rate compared to a $38.3\\%$ proof rate of\nSledgehammer, the most mature and popular symbolic-based solver. Furthermore,\nby combining Magnushammer with a neural formal prover based on a language\nmodel, we significantly improve the previous state-of-the-art proof rate from\n$57.0\\%$ to $71.0\\%$.\n","authors":["Maciej Mikuła","Szymon Antoniak","Szymon Tworkowski","Albert Qiaochu Jiang","Jin Peng Zhou","Christian Szegedy","Łukasz Kuciński","Piotr Miłoś","Yuhuai Wu"],"pdf_url":"https://arxiv.org/pdf/2303.04488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04487v1","updated":"2023-03-08T10:21:45Z","published":"2023-03-08T10:21:45Z","title":"Query-Utterance Attention with Joint modeling for Query-Focused Meeting\n  Summarization","summary":"  Query-focused meeting summarization (QFMS) aims to generate summaries from\nmeeting transcripts in response to a given query. Previous works typically\nconcatenate the query with meeting transcripts and implicitly model the query\nrelevance only at the token level with attention mechanism. However, due to the\ndilution of key query-relevant information caused by long meeting transcripts,\nthe original transformer-based model is insufficient to highlight the key parts\nrelated to the query. In this paper, we propose a query-aware framework with\njoint modeling token and utterance based on Query-Utterance Attention. It\ncalculates the utterance-level relevance to the query with a dense retrieval\nmodule. Then both token-level query relevance and utterance-level query\nrelevance are combined and incorporated into the generation process with\nattention mechanism explicitly. We show that the query relevance of different\ngranularities contributes to generating a summary more related to the query.\nExperimental results on the QMSum dataset show that the proposed model achieves\nnew state-of-the-art performance.\n","authors":["Xingxian Liu","Bin Duan","Bo Xiao","Yajing Xu"],"pdf_url":"https://arxiv.org/pdf/2303.04487v1.pdf","comment":"icassp 2023"},{"id":"http://arxiv.org/abs/2301.10823v2","updated":"2023-03-08T10:15:15Z","published":"2023-01-25T20:50:26Z","title":"Reflective Artificial Intelligence","summary":"  Artificial Intelligence (AI) is about making computers that do the sorts of\nthings that minds can do, and as we progress towards this goal, we tend to\nincreasingly delegate human tasks to machines. However, AI systems usually do\nthese tasks with an unusual imbalance of insight and understanding: new, deeper\ninsights are present, yet many important qualities that a human mind would have\npreviously brought to the activity are utterly absent. Therefore, it is crucial\nto ask which features of minds have we replicated, which are missing, and if\nthat matters. One core feature that humans bring to tasks, when dealing with\nthe ambiguity, emergent knowledge, and social context presented by the world,\nis reflection. Yet this capability is utterly missing from current mainstream\nAI. In this paper we ask what reflective AI might look like. Then, drawing on\nnotions of reflection in complex systems, cognitive science, and agents, we\nsketch an architecture for reflective AI agents, and highlight ways forward.\n","authors":["Peter R. Lewis","Stefan Sarkadi"],"pdf_url":"https://arxiv.org/pdf/2301.10823v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.07376v3","updated":"2023-03-08T09:47:11Z","published":"2022-06-15T08:32:53Z","title":"Mean-Semivariance Policy Optimization via Risk-Averse Reinforcement\n  Learning","summary":"  Keeping risk under control is often more crucial than maximizing expected\nrewards in real-world decision-making situations, such as finance, robotics,\nautonomous driving, etc. The most natural choice of risk measures is variance,\nwhich penalizes the upside volatility as much as the downside part. Instead,\nthe (downside) semivariance, which captures the negative deviation of a random\nvariable under its mean, is more suitable for risk-averse proposes. This paper\naims at optimizing the mean-semivariance (MSV) criterion in reinforcement\nlearning w.r.t. steady reward distribution. Since semivariance is\ntime-inconsistent and does not satisfy the standard Bellman equation, the\ntraditional dynamic programming methods are inapplicable to MSV problems\ndirectly. To tackle this challenge, we resort to Perturbation Analysis (PA)\ntheory and establish the performance difference formula for MSV. We reveal that\nthe MSV problem can be solved by iteratively solving a sequence of RL problems\nwith a policy-dependent reward function. Further, we propose two on-policy\nalgorithms based on the policy gradient theory and the trust region method.\nFinally, we conduct diverse experiments from simple bandit problems to\ncontinuous control tasks in MuJoCo, which demonstrate the effectiveness of our\nproposed methods.\n","authors":["Xiaoteng Ma","Shuai Ma","Li Xia","Qianchuan Zhao"],"pdf_url":"https://arxiv.org/pdf/2206.07376v3.pdf","comment":"Accecpted by Journal of Artificial Intelligence Research"},{"id":"http://arxiv.org/abs/2303.04475v1","updated":"2023-03-08T09:47:00Z","published":"2023-03-08T09:47:00Z","title":"RACCER: Towards Reachable and Certain Counterfactual Explanations for\n  Reinforcement Learning","summary":"  While reinforcement learning (RL) algorithms have been successfully applied\nto numerous tasks, their reliance on neural networks makes their behavior\ndifficult to understand and trust. Counterfactual explanations are\nhuman-friendly explanations that offer users actionable advice on how to alter\nthe model inputs to achieve the desired output from a black-box system.\nHowever, current approaches to generating counterfactuals in RL ignore the\nstochastic and sequential nature of RL tasks and can produce counterfactuals\nwhich are difficult to obtain or do not deliver the desired outcome. In this\nwork, we propose RACCER, the first RL-specific approach to generating\ncounterfactual explanations for the behaviour of RL agents. We first propose\nand implement a set of RL-specific counterfactual properties that ensure easily\nreachable counterfactuals with highly-probable desired outcomes. We use a\nheuristic tree search of agent's execution trajectories to find the most\nsuitable counterfactuals based on the defined properties. We evaluate RACCER in\ntwo tasks as well as conduct a user study to show that RL-specific\ncounterfactuals help users better understand agent's behavior compared to the\ncurrent state-of-the-art approaches.\n","authors":["Jasmina Gajcin","Ivana Dusparic"],"pdf_url":"https://arxiv.org/pdf/2303.04475v1.pdf","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.04449v1","updated":"2023-03-08T08:59:04Z","published":"2023-03-08T08:59:04Z","title":"Loss-Curvature Matching for Dataset Selection and Condensation","summary":"  Training neural networks on a large dataset requires substantial\ncomputational costs. Dataset reduction selects or synthesizes data instances\nbased on the large dataset, while minimizing the degradation in generalization\nperformance from the full dataset. Existing methods utilize the neural network\nduring the dataset reduction procedure, so the model parameter becomes\nimportant factor in preserving the performance after reduction. By depending\nupon the importance of parameters, this paper introduces a new reduction\nobjective, coined LCMat, which Matches the Loss Curvatures of the original\ndataset and reduced dataset over the model parameter space, more than the\nparameter point. This new objective induces a better adaptation of the reduced\ndataset on the perturbed parameter region than the exact point matching.\nParticularly, we identify the worst case of the loss curvature gap from the\nlocal parameter region, and we derive the implementable upper bound of such\nworst-case with theoretical analyses. Our experiments on both coreset selection\nand condensation benchmarks illustrate that LCMat shows better generalization\nperformances than existing baselines.\n","authors":["Seungjae Shin","Heesun Bae","Donghyeok Shin","Weonyoung Joo","Il-Chul Moon"],"pdf_url":"https://arxiv.org/pdf/2303.04449v1.pdf","comment":"26th International Conference on Artificial Intelligence and\n  Statistics (AISTATS)"},{"id":"http://arxiv.org/abs/2303.04435v1","updated":"2023-03-08T08:27:31Z","published":"2023-03-08T08:27:31Z","title":"A Message Passing Perspective on Learning Dynamics of Contrastive\n  Learning","summary":"  In recent years, contrastive learning achieves impressive results on\nself-supervised visual representation learning, but there still lacks a\nrigorous understanding of its learning dynamics. In this paper, we show that if\nwe cast a contrastive objective equivalently into the feature space, then its\nlearning dynamics admits an interpretable form. Specifically, we show that its\ngradient descent corresponds to a specific message passing scheme on the\ncorresponding augmentation graph. Based on this perspective, we theoretically\ncharacterize how contrastive learning gradually learns discriminative features\nwith the alignment update and the uniformity update. Meanwhile, this\nperspective also establishes an intriguing connection between contrastive\nlearning and Message Passing Graph Neural Networks (MP-GNNs). This connection\nnot only provides a unified understanding of many techniques independently\ndeveloped in each community, but also enables us to borrow techniques from\nMP-GNNs to design new contrastive learning variants, such as graph attention,\ngraph rewiring, jumpy knowledge techniques, etc. We believe that our message\npassing perspective not only provides a new theoretical understanding of\ncontrastive learning dynamics, but also bridges the two seemingly independent\nareas together, which could inspire more interleaving studies to benefit from\neach other. The code is available at\nhttps://github.com/PKU-ML/Message-Passing-Contrastive-Learning.\n","authors":["Yifei Wang","Qi Zhang","Tianqi Du","Jiansheng Yang","Zhouchen Lin","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2303.04435v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01860v2","updated":"2023-03-08T08:19:23Z","published":"2023-03-03T11:26:28Z","title":"Rule-based Out-Of-Distribution Detection","summary":"  Out-of-distribution detection is one of the most critical issue in the\ndeployment of machine learning. The data analyst must assure that data in\noperation should be compliant with the training phase as well as understand if\nthe environment has changed in a way that autonomous decisions would not be\nsafe anymore. The method of the paper is based on eXplainable Artificial\nIntelligence (XAI); it takes into account different metrics to identify any\nresemblance between in-distribution and out of, as seen by the XAI model. The\napproach is non-parametric and distributional assumption free. The validation\nover complex scenarios (predictive maintenance, vehicle platooning, covert\nchannels in cybersecurity) corroborates both precision in detection and\nevaluation of training-operation conditions proximity. Results are available\nvia open source and open data at the following link:\nhttps://github.com/giacomo97cnr/Rule-based-ODD.\n","authors":["Giacomo De Bernardi","Sara Narteni","Enrico Cambiaso","Maurizio Mongelli"],"pdf_url":"https://arxiv.org/pdf/2303.01860v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04426v1","updated":"2023-03-08T08:08:57Z","published":"2023-03-08T08:08:57Z","title":"NASTyLinker: NIL-Aware Scalable Transformer-based Entity Linker","summary":"  Entity Linking (EL) is the task of detecting mentions of entities in text and\ndisambiguating them to a reference knowledge base. Most prevalent EL approaches\nassume that the reference knowledge base is complete. In practice, however, it\nis necessary to deal with the case of linking to an entity that is not\ncontained in the knowledge base (NIL entity). Recent works have shown that,\ninstead of focusing only on affinities between mentions and entities,\nconsidering inter-mention affinities can be used to represent NIL entities by\nproducing clusters of mentions. At the same time, inter-mention affinities can\nhelp to substantially improve linking performance for known entities. With\nNASTyLinker, we introduce an EL approach that is aware of NIL-entities and\nproduces corresponding mention clusters while maintaining high linking\nperformance for known entities. The approach clusters mentions and entities\nbased on dense representations from Transformers and resolves conflicts (if\nmore than one entity is assigned to a cluster) by computing transitive\nmention-entity affinities. We show the effectiveness and scalability of\nNASTyLinker on NILK, a dataset that is explicitly constructed to evaluate EL\nwith respect to NIL-entities. Further, we apply the presented approach to an\nactual EL task, namely to knowledge graph population by linking entities in\nWikipedia listings, and provide an analysis of the outcome.\n","authors":["Nicolas Heist","Heiko Paulheim"],"pdf_url":"https://arxiv.org/pdf/2303.04426v1.pdf","comment":"Preprint of a paper in the research track of the 20th Extended\n  Semantic Web Conference (ESWC'23)"},{"id":"http://arxiv.org/abs/2303.00111v2","updated":"2023-03-08T07:55:37Z","published":"2023-02-28T22:26:18Z","title":"PixCUE: Joint Uncertainty Estimation and Image Reconstruction in MRI\n  using Deep Pixel Classification","summary":"  Deep learning (DL) models are capable of successfully exploiting latent\nrepresentations in MR data and have become state-of-the-art for accelerated MRI\nreconstruction. However, undersampling the measurements in k-space as well as\nthe over- or under-parameterized and non-transparent nature of DL make these\nmodels exposed to uncertainty. Consequently, uncertainty estimation has become\na major issue in DL MRI reconstruction. To estimate uncertainty, Monte Carlo\n(MC) inference techniques have become a common practice where multiple\nreconstructions are utilized to compute the variance in reconstruction as a\nmeasurement of uncertainty. However, these methods demand high computational\ncosts as they require multiple inferences through the DL model. To this end, we\nintroduce a method to estimate uncertainty during MRI reconstruction using a\npixel classification framework. The proposed method, PixCUE (stands for Pixel\nClassification Uncertainty Estimation) produces the reconstructed image along\nwith an uncertainty map during a single forward pass through the DL model. We\ndemonstrate that this approach generates uncertainty maps that highly correlate\nwith the reconstruction errors with respect to various MR imaging sequences and\nunder numerous adversarial conditions. We also show that the estimated\nuncertainties are correlated to that of the conventional MC method. We further\nprovide an empirical relationship between the uncertainty estimations using\nPixCUE and well-established reconstruction metrics such as NMSE, PSNR, and\nSSIM. We conclude that PixCUE is capable of reliably estimating the uncertainty\nin MRI reconstruction with a minimum additional computational cost.\n","authors":["Mevan Ekanayake","Kamlesh Pawar","Gary Egan","Zhaolin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00111v2.pdf","comment":"19 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2303.03323v2","updated":"2023-03-08T07:04:14Z","published":"2023-03-06T17:48:32Z","title":"CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive\n  Learning","summary":"  Multimodal contrastive pretraining has been used to train multimodal\nrepresentation models, such as CLIP, on large amounts of paired image-text\ndata. However, previous studies have revealed that such models are vulnerable\nto backdoor attacks. Specifically, when trained on backdoored examples, CLIP\nlearns spurious correlations between the embedded backdoor trigger and the\ntarget label, aligning their representations in the joint embedding space.\nInjecting even a small number of poisoned examples, such as 75 examples in 3\nmillion pretraining data, can significantly manipulate the model's behavior,\nmaking it difficult to detect or unlearn such correlations. To address this\nissue, we propose CleanCLIP, a finetuning framework that weakens the learned\nspurious associations introduced by backdoor attacks by independently\nre-aligning the representations for individual modalities. We demonstrate that\nunsupervised finetuning using a combination of multimodal contrastive and\nunimodal self-supervised objectives for individual modalities can significantly\nreduce the impact of the backdoor attack. Additionally, we show that supervised\nfinetuning on task-specific labeled image data removes the backdoor trigger\nfrom the CLIP vision encoder. We show empirically that CleanCLIP maintains\nmodel performance on benign examples while erasing a range of backdoor attacks\non multimodal contrastive learning.\n","authors":["Hritik Bansal","Nishad Singhi","Yu Yang","Fan Yin","Aditya Grover","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03323v2.pdf","comment":"20 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2211.12764v2","updated":"2023-03-08T06:31:05Z","published":"2022-11-23T08:20:29Z","title":"VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval","summary":"  Many recent studies leverage the pre-trained CLIP for text-video cross-modal\nretrieval by tuning the backbone with additional heavy modules, which not only\nbrings huge computational burdens with much more parameters, but also leads to\nthe knowledge forgetting from upstream models.In this work, we propose the VoP:\nText-Video Co-operative Prompt Tuning for efficient tuning on the text-video\nretrieval task. The proposed VoP is an end-to-end framework with both video &\ntext prompts introducing, which can be regarded as a powerful baseline with\nonly 0.1% trainable parameters. Further, based on the spatio-temporal\ncharacteristics of videos, we develop three novel video prompt mechanisms to\nimprove the performance with different scales of trainable parameters. The\nbasic idea of the VoP enhancement is to model the frame position, frame\ncontext, and layer function with specific trainable prompts, respectively.\nExtensive experiments show that compared to full fine-tuning, the enhanced VoP\nachieves a 1.4% average R@1 gain across five text-video retrieval benchmarks\nwith 6x less parameter overhead. The code will be available at\nhttps://github.com/bighuang624/VoP.\n","authors":["Siteng Huang","Biao Gong","Yulin Pan","Jianwen Jiang","Yiliang Lv","Yuyuan Li","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2211.12764v2.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2206.08289v3","updated":"2023-03-08T06:00:29Z","published":"2022-06-16T16:46:32Z","title":"Switchable Representation Learning Framework with Self-compatibility","summary":"  Real-world visual search systems involve deployments on multiple platforms\nwith different computing and storage resources. Deploying a unified model that\nsuits the minimal-constrain platforms leads to limited accuracy. It is expected\nto deploy models with different capacities adapting to the resource\nconstraints, which requires features extracted by these models to be aligned in\nthe metric space. The method to achieve feature alignments is called\n``compatible learning''. Existing research mainly focuses on the one-to-one\ncompatible paradigm, which is limited in learning compatibility among multiple\nmodels. We propose a Switchable representation learning Framework with\nSelf-Compatibility (SFSC). SFSC generates a series of compatible sub-models\nwith different capacities through one training process. The optimization of\nsub-models faces gradients conflict, and we mitigate this problem from the\nperspective of the magnitude and direction. We adjust the priorities of\nsub-models dynamically through uncertainty estimation to co-optimize sub-models\nproperly. Besides, the gradients with conflicting directions are projected to\navoid mutual interference. SFSC achieves state-of-the-art performance on the\nevaluated datasets.\n","authors":["Shengsen Wu","Yan Bai","Yihang Lou","Xiongkun Linghu","Jianzhong He","Ling-Yu Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08289v3.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2302.11231v2","updated":"2023-03-08T05:52:48Z","published":"2023-02-22T09:22:13Z","title":"Drugs Resistance Analysis from Scarce Health Records via Multi-task\n  Graph Representation","summary":"  Clinicians prescribe antibiotics by looking at the patient's health record\nwith an experienced eye. However, the therapy might be rendered futile if the\npatient has drug resistance. Determining drug resistance requires\ntime-consuming laboratory-level testing while applying clinicians' heuristics\nin an automated way is difficult due to the categorical or binary medical\nevents that constitute health records. In this paper, we propose a novel\nframework for rapid clinical intervention by viewing health records as graphs\nwhose nodes are mapped from medical events and edges as correspondence between\nevents in given a time window. A novel graph-based model is then proposed to\nextract informative features and yield automated drug resistance analysis from\nthose high-dimensional and scarce graphs. The proposed method integrates\nmulti-task learning into a common feature extracting graph encoder for\nsimultaneous analyses of multiple drugs as well as stabilizing learning. On a\nmassive dataset comprising over 110,000 patients with urinary tract infections,\nwe verify the proposed method is capable of attaining superior performance on\nthe drug resistance prediction problem. Furthermore, automated drug\nrecommendations resemblant to laboratory-level testing can also be made based\non the model resistance analysis.\n","authors":["Honglin Shu","Pei Gao","Lingwei Zhu","Zheng Chen"],"pdf_url":"https://arxiv.org/pdf/2302.11231v2.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.04386v1","updated":"2023-03-08T05:19:08Z","published":"2023-03-08T05:19:08Z","title":"Policy Mirror Descent Inherently Explores Action Space","summary":"  Designing computationally efficient exploration strategies for on-policy\nfirst-order methods that attain optimal $\\mathcal{O}(1/\\epsilon^2)$ sample\ncomplexity remains open for solving Markov decision processes (MDP). This\nmanuscript provides an answer to this question from a perspective of\nsimplicity, by showing that whenever exploration over the state space is\nimplied by the MDP structure, there seems to be little need for sophisticated\nexploration strategies. We revisit a stochastic policy gradient method, named\nstochastic policy mirror descent, applied to the infinite horizon, discounted\nMDP with finite state and action spaces. Accompanying SPMD we present two\non-policy evaluation operators, both simply following the policy for trajectory\ncollection with no explicit exploration, or any form of intervention. SPMD with\nthe first evaluation operator, named value-based estimation, tailors to the\nKullback-Leibler (KL) divergence. Provided the Markov chains on the state space\nof generated policies are uniformly mixing with non-diminishing minimal\nvisitation measure, an $\\tilde{\\mathcal{O}}( 1 / \\epsilon^2)$ sample complexity\nis obtained with a linear dependence on the size of the action space. SPMD with\nthe second evaluation operator, named truncated on-policy Monte Carlo, attains\nan $\\tilde{\\mathcal{O}}(\\mathcal{H}_{\\mathcal{D}} / \\epsilon^2)$ sample\ncomplexity, with the same assumption on the state chains of generated policies.\nWe characterize $\\mathcal{H}_{\\mathcal{D}}$ as a divergence-dependent function\nof the effective horizon and the size of the action space, which leads to an\nexponential dependence of the latter two quantities for the KL divergence, and\na polynomial dependence for the divergence induced by negative Tsallis entropy.\nThese obtained sample complexities seem to be new among on-policy stochastic\npolicy gradient methods without explicit explorations.\n","authors":["Yan Li","Guanghui Lan"],"pdf_url":"https://arxiv.org/pdf/2303.04386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.04774v5","updated":"2023-03-08T05:18:21Z","published":"2022-11-09T10:01:25Z","title":"IRNet: Iterative Refinement Network for Noisy Partial Label Learning","summary":"  Partial label learning (PLL) is a typical weakly supervised learning, where\neach sample is associated with a set of candidate labels. The basic assumption\nof PLL is that the ground-truth label must reside in the candidate set.\nHowever, this assumption may not be satisfied due to the unprofessional\njudgment of the annotators, thus limiting the practical application of PLL. In\nthis paper, we relax this assumption and focus on a more general problem, noisy\nPLL, where the ground-truth label may not exist in the candidate set. To\naddress this challenging problem, we propose a novel framework called\n\"Iterative Refinement Network (IRNet)\". It aims to purify the noisy samples by\ntwo key modules, i.e., noisy sample detection and label correction. Ideally, we\ncan convert noisy PLL into traditional PLL if all noisy samples are corrected.\nTo guarantee the performance of these modules, we start with warm-up training\nand exploit data augmentation to reduce prediction errors. Through theoretical\nanalysis, we prove that IRNet is able to reduce the noise level of the dataset\nand eventually approximate the Bayes optimal classifier. Experimental results\non multiple benchmark datasets demonstrate the effectiveness of our method.\nIRNet is superior to existing state-of-the-art approaches on noisy PLL.\n","authors":["Zheng Lian","Mingyu Xu","Lan Chen","Licai Sun","Bin Liu","Jianhua Tao"],"pdf_url":"https://arxiv.org/pdf/2211.04774v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13053v2","updated":"2023-03-08T04:13:48Z","published":"2023-02-25T10:42:34Z","title":"RETEXO: Scalable Neural Network Training over Distributed Graphs","summary":"  Graph neural networks offer a promising approach to supervised learning over\ngraph data. Graph data, especially when it is privacy-sensitive or too large to\ntrain on centrally, is often stored partitioned across disparate processing\nunits (clients) which want to minimize the communication costs during\ncollaborative training. The fully-distributed setup takes such partitioning to\nits extreme, wherein features of only a single node and its adjacent edges are\nkept locally with one client processor. Existing GNNs are not architected for\ntraining in such setups and incur prohibitive costs therein. We propose RETEXO,\na novel transformation of existing GNNs that improves the communication\nefficiency during training in the fully-distributed setup. We experimentally\nconfirm that RETEXO offers up to 6 orders of magnitude better communication\nefficiency even when training shallow GNNs, with a minimal trade-off in\naccuracy for supervised node classification tasks.\n","authors":["Aashish Kolluri","Sarthak Choudhary","Bryan Hooi","Prateek Saxena"],"pdf_url":"https://arxiv.org/pdf/2302.13053v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04364v1","updated":"2023-03-08T04:10:04Z","published":"2023-03-08T04:10:04Z","title":"Dynamic Scenario Representation Learning for Motion Forecasting with\n  Heterogeneous Graph Convolutional Recurrent Networks","summary":"  Due to the complex and changing interactions in dynamic scenarios, motion\nforecasting is a challenging problem in autonomous driving. Most existing works\nexploit static road graphs to characterize scenarios and are limited in\nmodeling evolving spatio-temporal dependencies in dynamic scenarios. In this\npaper, we resort to dynamic heterogeneous graphs to model the scenario. Various\nscenario components including vehicles (agents) and lanes, multi-type\ninteractions, and their changes over time are jointly encoded. Furthermore, we\ndesign a novel heterogeneous graph convolutional recurrent network, aggregating\ndiverse interaction information and capturing their evolution, to learn to\nexploit intrinsic spatio-temporal dependencies in dynamic graphs and obtain\neffective representations of dynamic scenarios. Finally, with a motion\nforecasting decoder, our model predicts realistic and multi-modal future\ntrajectories of agents and outperforms state-of-the-art published works on\nseveral motion forecasting benchmarks.\n","authors":["Xing Gao","Xiaogang Jia","Yikang Li","Hongkai Xiong"],"pdf_url":"https://arxiv.org/pdf/2303.04364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04360v1","updated":"2023-03-08T03:56:31Z","published":"2023-03-08T03:56:31Z","title":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining?","summary":"  Recent advancements in large language models (LLMs) have led to the\ndevelopment of highly potent models like OpenAI's ChatGPT. These models have\nexhibited exceptional performance in a variety of tasks, such as question\nanswering, essay composition, and code generation. However, their effectiveness\nin the healthcare sector remains uncertain. In this study, we seek to\ninvestigate the potential of ChatGPT to aid in clinical text mining by\nexamining its ability to extract structured information from unstructured\nhealthcare texts, with a focus on biological named entity recognition and\nrelation extraction. However, our preliminary results indicate that employing\nChatGPT directly for these tasks resulted in poor performance and raised\nprivacy concerns associated with uploading patients' information to the ChatGPT\nAPI. To overcome these limitations, we propose a new training paradigm that\ninvolves generating a vast quantity of high-quality synthetic data with labels\nutilizing ChatGPT and fine-tuning a local model for the downstream task. Our\nmethod has resulted in significant improvements in the performance of\ndownstream tasks, improving the F1-score from 23.37% to 63.99% for the named\nentity recognition task and from 75.86% to 83.59% for the relation extraction\ntask. Furthermore, generating data using ChatGPT can significantly reduce the\ntime and effort required for data collection and labeling, as well as mitigate\ndata privacy concerns. In summary, the proposed framework presents a promising\nsolution to enhance the applicability of LLM models to clinical text mining.\n","authors":["Ruixiang Tang","Xiaotian Han","Xiaoqian Jiang","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2303.04360v1.pdf","comment":"10 pages, 8 tables, 4 figures"},{"id":"http://arxiv.org/abs/2303.04356v1","updated":"2023-03-08T03:32:50Z","published":"2023-03-08T03:32:50Z","title":"Soft Actor-Critic Algorithm with Truly Inequality Constraint","summary":"  Soft actor-critic (SAC) in reinforcement learning is expected to be one of\nthe next-generation robot control schemes. Its ability to maximize policy\nentropy would make a robotic controller robust to noise and perturbation, which\nis useful for real-world robot applications. However, the priority of\nmaximizing the policy entropy is automatically tuned in the current\nimplementation, the rule of which can be interpreted as one for equality\nconstraint, binding the policy entropy into its specified target value. The\ncurrent SAC is therefore no longer maximize the policy entropy, contrary to our\nexpectation. To resolve this issue in SAC, this paper improves its\nimplementation with a slack variable for appropriately handling the inequality\nconstraint to maximize the policy entropy. In Mujoco and Pybullet simulators,\nthe modified SAC achieved the higher robustness and the more stable learning\nthan before while regularizing the norm of action. In addition, a real-robot\nvariable impedance task was demonstrated for showing the applicability of the\nmodified SAC to real-world robot control.\n","authors":["Taisuke Kobayashi"],"pdf_url":"https://arxiv.org/pdf/2303.04356v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.04352v1","updated":"2023-03-08T03:25:24Z","published":"2023-03-08T03:25:24Z","title":"Computational-level Analysis of Constraint Compliance for General\n  Intelligence","summary":"  Human behavior is conditioned by codes and norms that constrain action.\nRules, ``manners,'' laws, and moral imperatives are examples of classes of\nconstraints that govern human behavior. These systems of constraints are\n``messy:'' individual constraints are often poorly defined, what constraints\nare relevant in a particular situation may be unknown or ambiguous, constraints\ninteract and conflict with one another, and determining how to act within the\nbounds of the relevant constraints may be a significant challenge, especially\nwhen rapid decisions are needed. Despite such messiness, humans incorporate\nconstraints in their decisions robustly and rapidly. General,\nartificially-intelligent agents must also be able to navigate the messiness of\nsystems of real-world constraints in order to behave predictability and\nreliably. In this paper, we characterize sources of complexity in constraint\nprocessing for general agents and describe a computational-level analysis for\nsuch \\textit{constraint compliance}. We identify key algorithmic requirements\nbased on the computational-level analysis and outline an initial, exploratory\nimplementation of a general approach to constraint compliance.\n","authors":["Robert E. Wray Steven J. Jones John E. Laird"],"pdf_url":"https://arxiv.org/pdf/2303.04352v1.pdf","comment":"10 pages, 2 figures. Submitted to AGI 2023"},{"id":"http://arxiv.org/abs/2303.04349v1","updated":"2023-03-08T03:10:41Z","published":"2023-03-08T03:10:41Z","title":"Virtual Reality in Metaverse over Wireless Networks with User-centered\n  Deep Reinforcement Learning","summary":"  The Metaverse and its promises are fast becoming reality as maturing\ntechnologies are empowering the different facets. One of the highlights of the\nMetaverse is that it offers the possibility for highly immersive and\ninteractive socialization. Virtual reality (VR) technologies are the backbone\nfor the virtual universe within the Metaverse as they enable a hyper-realistic\nand immersive experience, and especially so in the context of socialization. As\nthe virtual world 3D scenes to be rendered are of high resolution and frame\nrate, these scenes will be offloaded to an edge server for computation.\nBesides, the metaverse is user-center by design, and human users are always the\ncore. In this work, we introduce a multi-user VR computation offloading over\nwireless communication scenario. In addition, we devised a novel user-centered\ndeep reinforcement learning approach to find a near-optimal solution. Extensive\nexperiments demonstrate that our approach can lead to remarkable results under\nvarious requirements and constraints.\n","authors":["Wenhan Yu","Terence Jie Chua","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.04349v1.pdf","comment":"This paper has been accepted by IEEE International Conference on\n  Communications (ICC), 2023. arXiv admin note: text overlap with\n  arXiv:2302.01471"},{"id":"http://arxiv.org/abs/2303.04341v1","updated":"2023-03-08T02:36:09Z","published":"2023-03-08T02:36:09Z","title":"Neural Vector Fields: Implicit Representation by Explicit Learning","summary":"  Deep neural networks (DNNs) are widely applied for nowadays 3D surface\nreconstruction tasks and such methods can be further divided into two\ncategories, which respectively warp templates explicitly by moving vertices or\nrepresent 3D surfaces implicitly as signed or unsigned distance functions.\nTaking advantage of both advanced explicit learning process and powerful\nrepresentation ability of implicit functions, we propose a novel 3D\nrepresentation method, Neural Vector Fields (NVF). It not only adopts the\nexplicit learning process to manipulate meshes directly, but also leverages the\nimplicit representation of unsigned distance functions (UDFs) to break the\nbarriers in resolution and topology. Specifically, our method first predicts\nthe displacements from queries towards the surface and models the shapes as\n\\textit{Vector Fields}. Rather than relying on network differentiation to\nobtain direction fields as most existing UDF-based methods, the produced vector\nfields encode the distance and direction fields both and mitigate the ambiguity\nat \"ridge\" points, such that the calculation of direction fields is\nstraightforward and differentiation-free. The differentiation-free\ncharacteristic enables us to further learn a shape codebook via Vector\nQuantization, which encodes the cross-object priors, accelerates the training\nprocedure, and boosts model generalization on cross-category reconstruction.\nThe extensive experiments on surface reconstruction benchmarks indicate that\nour method outperforms those state-of-the-art methods in different evaluation\nscenarios including watertight vs non-watertight shapes, category-specific vs\ncategory-agnostic reconstruction, category-unseen reconstruction, and\ncross-domain reconstruction. Our code will be publicly released.\n","authors":["Xianghui Yang","Guosheng Lin","Zhenghao Chen","Luping Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.04341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04339v1","updated":"2023-03-08T02:31:49Z","published":"2023-03-08T02:31:49Z","title":"Learning the Finer Things: Bayesian Structure Learning at the\n  Instantiation Level","summary":"  Successful machine learning methods require a trade-off between memorization\nand generalization. Too much memorization and the model cannot generalize to\nunobserved examples. Too much over-generalization and we risk under-fitting the\ndata. While we commonly measure their performance through cross validation and\naccuracy metrics, how should these algorithms cope in domains that are\nextremely under-determined where accuracy is always unsatisfactory? We present\na novel probabilistic graphical model structure learning approach that can\nlearn, generalize and explain in these elusive domains by operating at the\nrandom variable instantiation level. Using Minimum Description Length (MDL)\nanalysis, we propose a new decomposition of the learning problem over all\ntraining exemplars, fusing together minimal entropy inferences to construct a\nfinal knowledge base. By leveraging Bayesian Knowledge Bases (BKBs), a\nframework that operates at the instantiation level and inherently subsumes\nBayesian Networks (BNs), we develop both a theoretical MDL score and associated\nstructure learning algorithm that demonstrates significant improvements over\nlearned BNs on 40 benchmark datasets. Further, our algorithm incorporates\nrecent off-the-shelf DAG learning techniques enabling tractable results even on\nlarge problems. We then demonstrate the utility of our approach in a\nsignificantly under-determined domain by learning gene regulatory networks on\nbreast cancer gene mutational data available from The Cancer Genome Atlas\n(TCGA).\n","authors":["Chase Yakaboski","Eugene Santos Jr"],"pdf_url":"https://arxiv.org/pdf/2303.04339v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02562v2","updated":"2023-03-08T02:31:01Z","published":"2023-03-05T03:12:57Z","title":"The First Comprehensive Dataset with Multiple Distortion Types for\n  Visual Just-Noticeable Differences","summary":"  Recently, with the development of deep learning, a number of Just Noticeable\nDifference (JND) datasets have been built for JND modeling. However, all the\nexisting JND datasets only label the JND points based on the level of\ncompression distortion. Hence, JND models learned from such datasets can only\nbe used for image/video compression. As known, JND is a major characteristic of\nthe human visual system (HVS), which reflects the maximum visual distortion\nthat the HVS can tolerate. Hence, a generalized JND modeling should take more\nkinds of distortion types into account. To benefit JND modeling, this work\nestablishes a generalized JND dataset with a coarse-to-fine JND selection,\nwhich contains 106 source images and 1,642 JND maps, covering 25 distortion\ntypes. To this end, we proposed a coarse JND candidate selection scheme to\nselect the distorted images from the existing Image Quality Assessment (IQA)\ndatasets as JND candidates instead of generating JND maps ourselves. Then, a\nfine JND selection is carried out on the JND candidates with a crowdsourced\nsubjective assessment.\n","authors":["Yaxuan Liu","Jian Jin","Yuan Xue","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2303.02562v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04333v1","updated":"2023-03-08T02:10:59Z","published":"2023-03-08T02:10:59Z","title":"Preference-Aware Delivery Planning for Last-Mile Logistics","summary":"  Optimizing delivery routes for last-mile logistics service is challenging and\nhas attracted the attention of many researchers. These problems are usually\nmodeled and solved as variants of vehicle routing problems (VRPs) with\nchallenging real-world constraints (e.g., time windows, precedence). However,\ndespite many decades of solid research on solving these VRP instances, we still\nsee significant gaps between optimized routes and the routes that are actually\npreferred by the practitioners. Most of these gaps are due to the difference\nbetween what's being optimized, and what the practitioners actually care about,\nwhich is hard to be defined exactly in many instances. In this paper, we\npropose a novel hierarchical route optimizer with learnable parameters that\ncombines the strength of both the optimization and machine learning approaches.\nOur hierarchical router first solves a zone-level Traveling Salesman Problem\nwith learnable weights on various zone-level features; with the zone visit\nsequence fixed, we then solve the stop-level vehicle routing problem as a\nShortest Hamiltonian Path problem. The Bayesian optimization approach is then\nintroduced to allow us to adjust the weights to be assigned to different zone\nfeatures used in solving the zone-level Traveling Salesman Problem. By using a\nreal-world delivery dataset provided by the Amazon Last Mile Routing Research\nChallenge, we demonstrate the importance of having both the optimization and\nthe machine learning components. We also demonstrate how we can use\nroute-related features to identify instances that we might have difficulty\nwith. This paves ways to further research on how we can tackle these difficult\ninstances.\n","authors":["Qian Shao","Shih-Fen Cheng"],"pdf_url":"https://arxiv.org/pdf/2303.04333v1.pdf","comment":"Accepted to the 22nd International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS-23)"},{"id":"http://arxiv.org/abs/2303.04327v1","updated":"2023-03-08T02:00:26Z","published":"2023-03-08T02:00:26Z","title":"Using Memory-Based Learning to Solve Tasks with State-Action Constraints","summary":"  Tasks where the set of possible actions depend discontinuously on the state\npose a significant challenge for current reinforcement learning algorithms. For\nexample, a locked door must be first unlocked, and then the handle turned\nbefore the door can be opened. The sequential nature of these tasks makes\nobtaining final rewards difficult, and transferring information between task\nvariants using continuous learned values such as weights rather than discrete\nsymbols can be inefficient. Our key insight is that agents that act and think\nsymbolically are often more effective in dealing with these tasks. We propose a\nmemory-based learning approach that leverages the symbolic nature of\nconstraints and temporal ordering of actions in these tasks to quickly acquire\nand transfer high-level information. We evaluate the performance of\nmemory-based learning on both real and simulated tasks with approximately\ndiscontinuous constraints between states and actions, and show our method\nlearns to solve these tasks an order of magnitude faster than both model-based\nand model-free deep reinforcement learning methods.\n","authors":["Mrinal Verghese","Chris Atkeson"],"pdf_url":"https://arxiv.org/pdf/2303.04327v1.pdf","comment":"8 pages, 3 figures, accepted to the International Conference on\n  Robotics and Automation 2023"},{"id":"http://arxiv.org/abs/2303.04322v1","updated":"2023-03-08T01:46:19Z","published":"2023-03-08T01:46:19Z","title":"DroNeRF: Real-time Multi-agent Drone Pose Optimization for Computing\n  Neural Radiance Fields","summary":"  We present a novel optimization algorithm called DroNeRF for the autonomous\npositioning of monocular camera drones around an object for real-time 3D\nreconstruction using only a few images. Neural Radiance Fields or NeRF, is a\nnovel view synthesis technique used to generate new views of an object or scene\nfrom a set of input images. Using drones in conjunction with NeRF provides a\nunique and dynamic way to generate novel views of a scene, especially with\nlimited scene capabilities of restricted movements. Our approach focuses on\ncalculating optimized pose for individual drones while solely depending on the\nobject geometry without using any external localization system. The unique\ncamera positioning during the data-capturing phase significantly impacts the\nquality of the 3D model. To evaluate the quality of our generated novel views,\nwe compute different perceptual metrics like the Peak Signal-to-Noise Ratio\n(PSNR) and Structural Similarity Index Measure(SSIM). Our work demonstrates the\nbenefit of using an optimal placement of various drones with limited mobility\nto generate perceptually better results.\n","authors":["Dipam Patel","Phu Pham","Aniket Bera"],"pdf_url":"https://arxiv.org/pdf/2303.04322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04320v1","updated":"2023-03-08T01:38:20Z","published":"2023-03-08T01:38:20Z","title":"SG-LSTM: Social Group LSTM for Robot Navigation Through Dense Crowds","summary":"  With the increasing availability and affordability of personal robots, they\nwill no longer be confined to large corporate warehouses or factories but will\ninstead be expected to operate in less controlled environments alongside larger\ngroups of people. In addition to ensuring safety and efficiency, it is crucial\nto minimize any negative psychological impact robots may have on humans and\nfollow unwritten social norms in these situations. Our research aims to develop\na model that can predict the movements of pedestrians and perceptually-social\ngroups in crowded environments. We introduce a new Social Group Long Short-term\nMemory (SG-LSTM) model that models human groups and interactions in dense\nenvironments using a socially-aware LSTM to produce more accurate trajectory\npredictions. Our approach enables navigation algorithms to calculate\ncollision-free paths faster and more accurately in crowded environments.\nAdditionally, we also release a large video dataset with labeled pedestrian\ngroups for the broader social navigation community. We show comparisons with\ndifferent metrics on different datasets (ETH, Hotel, MOT15) and different\nprediction approaches (LIN, LSTM, O-LSTM, S-LSTM) as well as runtime\nperformance.\n","authors":["Rashmi Bhaskara","Maurice Chiu","Aniket Bera"],"pdf_url":"https://arxiv.org/pdf/2303.04320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04315v1","updated":"2023-03-08T01:29:55Z","published":"2023-03-08T01:29:55Z","title":"A Threefold Review on Deep Semantic Segmentation: Efficiency-oriented,\n  Temporal and Depth-aware design","summary":"  Semantic image and video segmentation stand among the most important tasks in\ncomputer vision nowadays, since they provide a complete and meaningful\nrepresentation of the environment by means of a dense classification of the\npixels in a given scene. Recently, Deep Learning, and more precisely\nConvolutional Neural Networks, have boosted semantic segmentation to a new\nlevel in terms of performance and generalization capabilities. However,\ndesigning Deep Semantic Segmentation models is a complex task, as it may\ninvolve application-dependent aspects. Particularly, when considering\nautonomous driving applications, the robustness-efficiency trade-off, as well\nas intrinsic limitations - computational/memory bounds and data-scarcity - and\nconstraints - real-time inference - should be taken into consideration. In this\nrespect, the use of additional data modalities, such as depth perception for\nreasoning on the geometry of a scene, and temporal cues from videos to explore\nredundancy and consistency, are promising directions yet not explored to their\nfull potential in the literature. In this paper, we conduct a survey on the\nmost relevant and recent advances in Deep Semantic Segmentation in the context\nof vision for autonomous vehicles, from three different perspectives:\nefficiency-oriented model development for real-time operation, RGB-Depth data\nintegration (RGB-D semantic segmentation), and the use of temporal information\nfrom videos in temporally-aware models. Our main objective is to provide a\ncomprehensive discussion on the main methods, advantages, limitations, results\nand challenges faced from each perspective, so that the reader can not only get\nstarted, but also be up to date in respect to recent advances in this exciting\nand challenging research field.\n","authors":["Felipe Manfio Barbosa","Fernando Santos Osório"],"pdf_url":"https://arxiv.org/pdf/2303.04315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10447v2","updated":"2023-03-08T01:01:51Z","published":"2023-02-21T05:24:00Z","title":"Mask-guided BERT for Few Shot Text Classification","summary":"  Transformer-based language models have achieved significant success in\nvarious domains. However, the data-intensive nature of the transformer\narchitecture requires much labeled data, which is challenging in low-resource\nscenarios (i.e., few-shot learning (FSL)). The main challenge of FSL is the\ndifficulty of training robust models on small amounts of samples, which\nfrequently leads to overfitting. Here we present Mask-BERT, a simple and\nmodular framework to help BERT-based architectures tackle FSL. The proposed\napproach fundamentally differs from existing FSL strategies such as prompt\ntuning and meta-learning. The core idea is to selectively apply masks on text\ninputs and filter out irrelevant information, which guides the model to focus\non discriminative tokens that influence prediction results. In addition, to\nmake the text representations from different categories more separable and the\ntext representations from the same category more compact, we introduce a\ncontrastive learning loss function. Experimental results on public-domain\nbenchmark datasets demonstrate the effectiveness of Mask-BERT.\n","authors":["Wenxiong Liao","Zhengliang Liu","Haixing Dai","Zihao Wu","Yiyang Zhang","Xiaoke Huang","Yuzhong Chen","Xi Jiang","Wei Liu","Dajiang Zhu","Tianming Liu","Sheng Li","Xiang Li","Hongmin Cai"],"pdf_url":"https://arxiv.org/pdf/2302.10447v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04302v1","updated":"2023-03-08T00:48:32Z","published":"2023-03-08T00:48:32Z","title":"Camera-Radar Perception for Autonomous Vehicles and ADAS: Concepts,\n  Datasets and Metrics","summary":"  One of the main paths towards the reduction of traffic accidents is the\nincrease in vehicle safety through driver assistance systems or even systems\nwith a complete level of autonomy. In these types of systems, tasks such as\nobstacle detection and segmentation, especially the Deep Learning-based ones,\nplay a fundamental role in scene understanding for correct and safe navigation.\nBesides that, the wide variety of sensors in vehicles nowadays provides a rich\nset of alternatives for improvement in the robustness of perception in\nchallenging situations, such as navigation under lighting and weather adverse\nconditions. Despite the current focus given to the subject, the literature\nlacks studies on radar-based and radar-camera fusion-based perception. Hence,\nthis work aims to carry out a study on the current scenario of camera and\nradar-based perception for ADAS and autonomous vehicles. Concepts and\ncharacteristics related to both sensors, as well as to their fusion, are\npresented. Additionally, we give an overview of the Deep Learning-based\ndetection and segmentation tasks, and the main datasets, metrics, challenges,\nand open questions in vehicle perception.\n","authors":["Felipe Manfio Barbosa","Fernando Santos Osório"],"pdf_url":"https://arxiv.org/pdf/2303.04302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12813v3","updated":"2023-03-08T23:41:49Z","published":"2023-02-24T18:48:43Z","title":"Check Your Facts and Try Again: Improving Large Language Models with\n  External Knowledge and Automated Feedback","summary":"  Large language models (LLMs), such as ChatGPT, are able to generate\nhuman-like, fluent responses for many downstream tasks, e.g., task-oriented\ndialog and question answering. However, applying LLMs to real-world,\nmission-critical applications remains challenging mainly due to their tendency\nto generate hallucinations and their inability to use external knowledge. This\npaper proposes a LLM-Augmenter system, which augments a black-box LLM with a\nset of plug-and-play modules. Our system makes the LLM generate responses\ngrounded in external knowledge, e.g., stored in task-specific databases. It\nalso iteratively revises LLM prompts to improve model responses using feedback\ngenerated by utility functions, e.g., the factuality score of a LLM-generated\nresponse. The effectiveness of LLM-Augmenter is empirically validated on two\ntypes of scenarios, task-oriented dialog and open-domain question answering.\nLLM-Augmenter significantly reduces ChatGPT's hallucinations without\nsacrificing the fluency and informativeness of its responses. We make the\nsource code and models publicly available.\n","authors":["Baolin Peng","Michel Galley","Pengcheng He","Hao Cheng","Yujia Xie","Yu Hu","Qiuyuan Huang","Lars Liden","Zhou Yu","Weizhu Chen","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2302.12813v3.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2303.04939v1","updated":"2023-03-08T23:21:19Z","published":"2023-03-08T23:21:19Z","title":"UT-Net: Combining U-Net and Transformer for Joint Optic Disc and Cup\n  Segmentation and Glaucoma Detection","summary":"  Glaucoma is a chronic visual disease that may cause permanent irreversible\nblindness. Measurement of the cup-to-disc ratio (CDR) plays a pivotal role in\nthe detection of glaucoma in its early stage, preventing visual disparities.\nTherefore, accurate and automatic segmentation of optic disc (OD) and optic cup\n(OC) from retinal fundus images is a fundamental requirement. Existing\nCNN-based segmentation frameworks resort to building deep encoders with\naggressive downsampling layers, which suffer from a general limitation on\nmodeling explicit long-range dependency. To this end, in this paper, we propose\na new segmentation pipeline, called UT-Net, availing the advantages of U-Net\nand transformer both in its encoding layer, followed by an attention-gated\nbilinear fusion scheme. In addition to this, we incorporate Multi-Head\nContextual attention to enhance the regular self-attention used in traditional\nvision transformers. Thus low-level features along with global dependencies are\ncaptured in a shallow manner. Besides, we extract context information at\nmultiple encoding layers for better exploration of receptive fields, and to aid\nthe model to learn deep hierarchical representations. Finally, an enhanced\nmixing loss is proposed to tightly supervise the overall learning process. The\nproposed model has been implemented for joint OD and OC segmentation on three\npublicly available datasets: DRISHTI-GS, RIM-ONE R3, and REFUGE. Additionally,\nto validate our proposal, we have performed exhaustive experimentation on\nGlaucoma detection from all three datasets by measuring the Cup to Disc Ratio\n(CDR) value. Experimental results demonstrate the superiority of UT-Net as\ncompared to the state-of-the-art methods.\n","authors":["Rukhshanda Hussain","Hritam Basak"],"pdf_url":"https://arxiv.org/pdf/2303.04939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04926v1","updated":"2023-03-08T22:37:50Z","published":"2023-03-08T22:37:50Z","title":"Automated Cyber Defence: A Review","summary":"  Within recent times, cybercriminals have curated a variety of organised and\nresolute cyber attacks within a range of cyber systems, leading to\nconsequential ramifications to private and governmental institutions. Current\nsecurity-based automation and orchestrations focus on automating fixed purpose\nand hard-coded solutions, which are easily surpassed by modern-day cyber\nattacks. Research within Automated Cyber Defence will allow the development and\nenabling intelligence response by autonomously defending networked systems\nthrough sequential decision-making agents. This article comprehensively\nelaborates the developments within Automated Cyber Defence through a\nrequirement analysis divided into two sub-areas, namely, automated defence and\nattack agents and Autonomous Cyber Operation (ACO) Gyms. The requirement\nanalysis allows the comparison of automated agents and highlights the\nimportance of ACO Gyms for their continual development. The requirement\nanalysis is also used to critique ACO Gyms with an overall aim to develop them\nfor deploying automated agents within real-world networked systems. Relevant\nfuture challenges were addressed from the overall analysis to accelerate\ndevelopment within the area of Automated Cyber Defence.\n","authors":["Sanyam Vyas","John Hannay","Andrew Bolton","Professor Pete Burnap"],"pdf_url":"https://arxiv.org/pdf/2303.04926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.04122v4","updated":"2023-03-08T22:29:41Z","published":"2022-01-11T18:44:17Z","title":"In Defense of the Unitary Scalarization for Deep Multi-Task Learning","summary":"  Recent multi-task learning research argues against unitary scalarization,\nwhere training simply minimizes the sum of the task losses. Several ad-hoc\nmulti-task optimization algorithms have instead been proposed, inspired by\nvarious hypotheses about what makes multi-task settings difficult. The majority\nof these optimizers require per-task gradients, and introduce significant\nmemory, runtime, and implementation overhead. We show that unitary\nscalarization, coupled with standard regularization and stabilization\ntechniques from single-task learning, matches or improves upon the performance\nof complex multi-task optimizers in popular supervised and reinforcement\nlearning settings. We then present an analysis suggesting that many specialized\nmulti-task optimizers can be partly interpreted as forms of regularization,\npotentially explaining our surprising results. We believe our results call for\na critical reevaluation of recent research in the area.\n","authors":["Vitaly Kurin","Alessandro De Palma","Ilya Kostrikov","Shimon Whiteson","M. Pawan Kumar"],"pdf_url":"https://arxiv.org/pdf/2201.04122v4.pdf","comment":"NeurIPS 2022 camera-ready version, fixed training loss y axis scale"},{"id":"http://arxiv.org/abs/2303.04912v1","updated":"2023-03-08T22:04:31Z","published":"2023-03-08T22:04:31Z","title":"Embodied Active Learning of Relational State Abstractions for Bilevel\n  Planning","summary":"  State abstraction is an effective technique for planning in robotics\nenvironments with continuous states and actions, long task horizons, and sparse\nfeedback. In object-oriented environments, predicates are a particularly useful\nform of state abstraction because of their compatibility with symbolic planners\nand their capacity for relational generalization. However, to plan with\npredicates, the agent must be able to interpret them in continuous environment\nstates (i.e., ground the symbols). Manually programming predicate\ninterpretations can be difficult, so we would instead like to learn them from\ndata. We propose an embodied active learning paradigm where the agent learns\npredicate interpretations through online interaction with an expert. For\nexample, after taking actions in a block stacking environment, the agent may\nask the expert: \"Is On(block1, block2) true?\" From this experience, the agent\nlearns to plan: it learns neural predicate interpretations, symbolic planning\noperators, and neural samplers that can be used for bilevel planning. During\nexploration, the agent plans to learn: it uses its current models to select\nactions towards generating informative expert queries. We learn predicate\ninterpretations as ensembles of neural networks and use their entropy to\nmeasure the informativeness of potential queries. We evaluate this approach in\nthree robotic environments and find that it consistently outperforms six\nbaselines while exhibiting sample efficiency in two key metrics: number of\nenvironment interactions, and number of queries to the expert. Code:\nhttps://tinyurl.com/active-predicates\n","authors":["Amber Li","Tom Silver"],"pdf_url":"https://arxiv.org/pdf/2303.04912v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10157v3","updated":"2023-03-08T21:59:38Z","published":"2022-11-17T05:09:58Z","title":"UMFuse: Unified Multi View Fusion for Human Editing applications","summary":"  Numerous pose-guided human editing methods have been explored by the vision\ncommunity due to their extensive practical applications. However, most of these\nmethods still use an image-to-image formulation in which a single image is\ngiven as input to produce an edited image as output. This objective becomes\nill-defined in cases when the target pose differs significantly from the input\npose. Existing methods then resort to in-painting or style transfer to handle\nocclusions and preserve content. In this paper, we explore the utilization of\nmultiple views to minimize the issue of missing information and generate an\naccurate representation of the underlying human model. To fuse knowledge from\nmultiple viewpoints, we design a multi-view fusion network that takes the pose\nkey points and texture from multiple source images and generates an explainable\nper-pixel appearance retrieval map. Thereafter, the encodings from a separate\nnetwork (trained on a single-view human reposing task) are merged in the latent\nspace. This enables us to generate accurate, precise, and visually coherent\nimages for different editing tasks. We show the application of our network on\ntwo newly proposed tasks - Multi-view human reposing and Mix&Match Human Image\ngeneration. Additionally, we study the limitations of single-view editing and\nscenarios in which multi-view provides a better alternative.\n","authors":["Rishabh Jain","Mayur Hemani","Duygu Ceylan","Krishna Kumar Singh","Jingwan Lu","Mausooom Sarkar","Balaji Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2211.10157v3.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.04896v1","updated":"2023-03-08T21:28:02Z","published":"2023-03-08T21:28:02Z","title":"Using Positive Matching Contrastive Loss with Facial Action Units to\n  mitigate bias in Facial Expression Recognition","summary":"  Machine learning models automatically learn discriminative features from the\ndata, and are therefore susceptible to learn strongly-correlated biases, such\nas using protected attributes like gender and race. Most existing bias\nmitigation approaches aim to explicitly reduce the model's focus on these\nprotected features. In this work, we propose to mitigate bias by explicitly\nguiding the model's focus towards task-relevant features using domain\nknowledge, and we hypothesize that this can indirectly reduce the dependence of\nthe model on spurious correlations it learns from the data. We explore bias\nmitigation in facial expression recognition systems using facial Action Units\n(AUs) as the task-relevant feature. To this end, we introduce Feature-based\nPositive Matching Contrastive Loss which learns the distances between the\npositives of a sample based on the similarity between their corresponding AU\nembeddings. We compare our approach with representative baselines and show that\nincorporating task-relevant features via our method can improve model fairness\nat minimal cost to classification performance.\n","authors":["Varsha Suresh","Desmond C. Ong"],"pdf_url":"https://arxiv.org/pdf/2303.04896v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04895v1","updated":"2023-03-08T21:24:25Z","published":"2023-03-08T21:24:25Z","title":"Morpho-logic from a Topos Perspective: Application to symbolic AI","summary":"  Modal logics have proved useful for many reasoning tasks in symbolic\nartificial intelligence (AI), such as belief revision, spatial reasoning, among\nothers. On the other hand, mathematical morphology (MM) is a theory for\nnon-linear analysis of structures, that was widely developed and applied in\nimage analysis. Its mathematical bases rely on algebra, complete lattices,\ntopology. Strong links have been established between MM and mathematical\nlogics, mostly modal logics. In this paper, we propose to further develop and\ngeneralize this link between mathematical morphology and modal logic from a\ntopos perspective, i.e. categorial structures generalizing space, and\nconnecting logics, sets and topology. Furthermore, we rely on the internal\nlanguage and logic of topos. We define structuring elements, dilations and\nerosions as morphisms. Then we introduce the notion of structuring\nneighborhoods, and show that the dilations and erosions based on them lead to a\nconstructive modal logic, for which a sound and complete proof system is\nproposed. We then show that the modal logic thus defined (called morpho-logic\nhere), is well adapted to define concrete and efficient operators for revision,\nmerging, and abduction of new knowledge, or even spatial reasoning.\n","authors":["Marc Aiguier","Isabelle Bloch","Salim Nibouche","Ramon Pino Perez"],"pdf_url":"https://arxiv.org/pdf/2303.04895v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.03211v7","updated":"2023-03-08T21:21:49Z","published":"2022-08-05T14:54:08Z","title":"Why do networks have inhibitory/negative connections?","summary":"  Why do brains have inhibitory connections? Why do deep networks have negative\nweights? We believe representing functions is the primary role of both (i) the\nbrain in natural intelligence, and (ii) deep networks in artificial\nintelligence. Our answer to why there are inhibitory/negative weights is: to\nlearn more functions. We prove that, in the absence of negative weights, neural\nnetworks with non-decreasing activation functions are not universal\napproximators. While this may be an intuitive result to some, to the best of\nour knowledge, there is no formal theory, in either machine learning or\nneuroscience, that demonstrates why negative weights are crucial in the context\nof representation capacity. Further, we provide insights on the geometric\nproperties of the representation space that non-negative deep networks cannot\nrepresent. We expect these insights will yield a deeper understanding of more\nsophisticated inductive priors imposed on the distribution of weights that lead\nto more efficient biological and machine learning.\n","authors":["Qingyang Wang","Michael A. Powell","Ali Geisa","Eric Bridgeford","Carey E. Priebe","Joshua T. Vogelstein"],"pdf_url":"https://arxiv.org/pdf/2208.03211v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04891v1","updated":"2023-03-08T21:11:51Z","published":"2023-03-08T21:11:51Z","title":"You Only Crash Once: Improved Object Detection for Real-Time,\n  Sim-to-Real Hazardous Terrain Detection and Classification for Autonomous\n  Planetary Landings","summary":"  The detection of hazardous terrain during the planetary landing of spacecraft\nplays a critical role in assuring vehicle safety and mission success. A cheap\nand effective way of detecting hazardous terrain is through the use of visual\ncameras, which ensure operational ability from atmospheric entry through\ntouchdown. Plagued by resource constraints and limited computational power,\ntraditional techniques for visual hazardous terrain detection focus on template\nmatching and registration to pre-built hazard maps. Although successful on\nprevious missions, this approach is restricted to the specificity of the\ntemplates and limited by the fidelity of the underlying hazard map, which both\nrequire extensive pre-flight cost and effort to obtain and develop. Terrestrial\nsystems that perform a similar task in applications such as autonomous driving\nutilize state-of-the-art deep learning techniques to successfully localize and\nclassify navigation hazards. Advancements in spacecraft co-processors aimed at\naccelerating deep learning inference enable the application of these methods in\nspace for the first time. In this work, we introduce You Only Crash Once\n(YOCO), a deep learning-based visual hazardous terrain detection and\nclassification technique for autonomous spacecraft planetary landings. Through\nthe use of unsupervised domain adaptation we tailor YOCO for training by\nsimulation, removing the need for real-world annotated data and expensive\nmission surveying phases. We further improve the transfer of representative\nterrain knowledge between simulation and the real world through visual\nsimilarity clustering. We demonstrate the utility of YOCO through a series of\nterrestrial and extraterrestrial simulation-to-real experiments and show\nsubstantial improvements toward the ability to both detect and accurately\nclassify instances of planetary terrain.\n","authors":["Timothy Chase Jr","Chris Gnam","John Crassidis","Karthik Dantu"],"pdf_url":"https://arxiv.org/pdf/2303.04891v1.pdf","comment":"To be published in proceedings of AAS/AIAA Astrodynamics Specialist\n  Conference 2022"},{"id":"http://arxiv.org/abs/2208.10609v2","updated":"2023-03-08T21:10:38Z","published":"2022-08-22T21:30:55Z","title":"Global Concept-Based Interpretability for Graph Neural Networks via\n  Neuron Analysis","summary":"  Graph neural networks (GNNs) are highly effective on a variety of\ngraph-related tasks; however, they lack interpretability and transparency.\nCurrent explainability approaches are typically local and treat GNNs as\nblack-boxes. They do not look inside the model, inhibiting human trust in the\nmodel and explanations. Motivated by the ability of neurons to detect\nhigh-level semantic concepts in vision models, we perform a novel analysis on\nthe behaviour of individual GNN neurons to answer questions about GNN\ninterpretability, and propose new metrics for evaluating the interpretability\nof GNN neurons. We propose a novel approach for producing global explanations\nfor GNNs using neuron-level concepts to enable practitioners to have a\nhigh-level view of the model. Specifically, (i) to the best of our knowledge,\nthis is the first work which shows that GNN neurons act as concept detectors\nand have strong alignment with concepts formulated as logical compositions of\nnode degree and neighbourhood properties; (ii) we quantitatively assess the\nimportance of detected concepts, and identify a trade-off between training\nduration and neuron-level interpretability; (iii) we demonstrate that our\nglobal explainability approach has advantages over the current state-of-the-art\n-- we can disentangle the explanation into individual interpretable concepts\nbacked by logical descriptions, which reduces potential for bias and improves\nuser-friendliness.\n","authors":["Han Xuanyuan","Pietro Barbiero","Dobrik Georgiev","Lucie Charlotte Magister","Pietro Lió"],"pdf_url":"https://arxiv.org/pdf/2208.10609v2.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2106.15453v2","updated":"2023-03-08T20:54:12Z","published":"2021-06-29T14:41:19Z","title":"Critically examining the Domain Generalizability of Facial Expression\n  Recognition models","summary":"  Facial Expression Recognition is a commercially-important application, but\none under-appreciated limitation is that such applications require making\npredictions on out-of-sample distributions, where target images have different\nproperties from the images the model was trained on. How well -- or how badly\n-- do facial expression recognition models do on unseen target domains? We\nprovide a systematic and critical evaluation of transfer learning --\nspecifically, domain generalization -- in facial expression recognition. Using\na state-of-the-art model with twelve datasets (six collected in-lab and six\n``in-the-wild\"), we conduct extensive round-robin-style experiments to evaluate\nclassification accuracies when given new data from an unseen dataset. We also\nperform multi-source experiments to examine a model's ability to generalize\nfrom multiple source datasets, including (i) within-setting (e.g., lab to lab),\n(ii) cross-setting (e.g., in-the-wild to lab), and (iii) leave-one-out\nsettings. Finally, we compare our results with three commercially-available\nsoftware. We find sobering results: the accuracy of single- and multi-source\ndomain generalization is only modest. Even for the best-performing multi-source\nsettings, we observe average classification accuracies of 65.6% (range:\n34.6%-88.6%; chance: 14.3%), corresponding to an average drop of 10.8\npercentage points from the within-corpus classification performance (mean:\n76.4%). We discuss the need for regular, systematic investigations into the\ngeneralizability of affective computing models and applications.\n","authors":["Varsha Suresh","Gerard Yeo","Desmond C. Ong"],"pdf_url":"https://arxiv.org/pdf/2106.15453v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2303.04873v1","updated":"2023-03-08T20:26:55Z","published":"2023-03-08T20:26:55Z","title":"MOREA: a GPU-accelerated Evolutionary Algorithm for Multi-Objective\n  Deformable Registration of 3D Medical Images","summary":"  Finding a realistic deformation that transforms one image into another, in\ncase large deformations are required, is considered a key challenge in medical\nimage analysis. Having a proper image registration approach to achieve this\ncould unleash a number of applications requiring information to be transferred\nbetween images. Clinical adoption is currently hampered by many existing\nmethods requiring extensive configuration effort before each use, or not being\nable to (realistically) capture large deformations. A recent multi-objective\napproach that uses the Multi-Objective Real-Valued Gene-pool Optimal Mixing\nEvolutionary Algorithm (MO-RV-GOMEA) and a dual-dynamic mesh transformation\nmodel has shown promise, exposing the trade-offs inherent to image registration\nproblems and modeling large deformations in 2D. This work builds on this\npromise and introduces MOREA: the first evolutionary algorithm-based\nmulti-objective approach to deformable registration of 3D images capable of\ntackling large deformations. MOREA includes a 3D biomechanical mesh model for\nphysical plausibility and is fully GPU-accelerated. We compare MOREA to two\nstate-of-the-art approaches on abdominal CT scans of 4 cervical cancer\npatients, with the latter two approaches configured for the best results per\npatient. Without requiring per-patient configuration, MOREA significantly\noutperforms these approaches on 3 of the 4 patients that represent the most\ndifficult cases.\n","authors":["Georgios Andreadis","Peter A. N. Bosman","Tanja Alderliesten"],"pdf_url":"https://arxiv.org/pdf/2303.04873v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04865v1","updated":"2023-03-08T20:09:58Z","published":"2023-03-08T20:09:58Z","title":"Convergence Rates for Localized Actor-Critic in Networked Markov\n  Potential Games","summary":"  We introduce a class of networked Markov potential games where agents are\nassociated with nodes in a network. Each agent has its own local potential\nfunction, and the reward of each agent depends only on the states and actions\nof agents within a $\\kappa$-hop neighborhood. In this context, we propose a\nlocalized actor-critic algorithm. The algorithm is scalable since each agent\nuses only local information and does not need access to the global state.\nFurther, the algorithm overcomes the curse of dimensionality through the use of\nfunction approximation. Our main results provide finite-sample guarantees up to\na localization error and a function approximation error. Specifically, we\nachieve an $\\tilde{\\mathcal{O}}(\\epsilon^{-4})$ sample complexity measured by\nthe averaged Nash regret. This is the first finite-sample bound for multi-agent\ncompetitive games that does not depend on the number of agents.\n","authors":["Zhaoyi Zhou","Zaiwei Chen","Yiheng Lin","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2303.04865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04864v1","updated":"2023-03-08T20:08:53Z","published":"2023-03-08T20:08:53Z","title":"nl2spec: Interactively Translating Unstructured Natural Language to\n  Temporal Logics with Large Language Models","summary":"  A rigorous formalization of desired system requirements is indispensable when\nperforming any verification task. This often limits the application of\nverification techniques, as writing formal specifications is an error-prone and\ntime-consuming manual task. To facilitate this, we present nl2spec, a framework\nfor applying Large Language Models (LLMs) to derive formal specifications (in\ntemporal logics) from unstructured natural language. In particular, we\nintroduce a new methodology to detect and resolve the inherent ambiguity of\nsystem requirements in natural language: we utilize LLMs to map subformulas of\nthe formalization back to the corresponding natural language fragments of the\ninput. Users iteratively add, delete, and edit these sub-translations to amend\nerroneous formalizations, which is easier than manually redrafting the entire\nformalization. The framework is agnostic to specific application domains and\ncan be extended to similar specification languages and new neural models. We\nperform a user study to obtain a challenging dataset, which we use to run\nexperiments on the quality of translations. We provide an open-source\nimplementation, including a web-based frontend.\n","authors":["Matthias Cosler","Christopher Hahn","Daniel Mendoza","Frederik Schmitt","Caroline Trippel"],"pdf_url":"https://arxiv.org/pdf/2303.04864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.10832v3","updated":"2023-03-08T19:45:11Z","published":"2021-11-21T14:57:11Z","title":"Automated Controller Calibration by Kalman Filtering","summary":"  This paper proposes a method for calibrating control parameters. Examples of\nsuch control parameters are gains of PID controllers, weights of a cost\nfunction for optimal control, filter coefficients, the sliding surface of a\nsliding mode controller, or weights of a neural network. Hence, the proposed\nmethod can be applied to a wide range of controllers. The method uses a Kalman\nfilter that estimates control parameters, using data of closed-loop system\noperation. The control parameter calibration is driven by a training objective,\nwhich encompasses specifications on the performance of the dynamical system.\nThe performance-driven calibration method tunes the parameters online and\nrobustly, is computationally efficient, has low data storage requirements, and\nis easy to implement making it appealing for many real-time applications.\nSimulation results show that the method is able to learn control parameters\nquickly, is able to tune the parameters to compensate for disturbances, and is\nrobust to noise. A simulation study with the high-fidelity vehicle simulator\nCarSim shows that the method can calibrate controllers of a complex dynamical\nsystem online, which indicates its applicability to a real-world system. We\nalso verify the real-time feasibility on an embedded platform with\nautomotive-grade processors by implementing our method on a dSPACE\nMicroAutoBox-II rapid prototyping unit.\n","authors":["Marcel Menner","Karl Berntorp","Stefano Di Cairano"],"pdf_url":"https://arxiv.org/pdf/2111.10832v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04838v1","updated":"2023-03-08T19:17:05Z","published":"2023-03-08T19:17:05Z","title":"The Casual Conversations v2 Dataset","summary":"  This paper introduces a new large consent-driven dataset aimed at assisting\nin the evaluation of algorithmic bias and robustness of computer vision and\naudio speech models in regards to 11 attributes that are self-provided or\nlabeled by trained annotators. The dataset includes 26,467 videos of 5,567\nunique paid participants, with an average of almost 5 videos per person,\nrecorded in Brazil, India, Indonesia, Mexico, Vietnam, Philippines, and the\nUSA, representing diverse demographic characteristics. The participants agreed\nfor their data to be used in assessing fairness of AI models and provided\nself-reported age, gender, language/dialect, disability status, physical\nadornments, physical attributes and geo-location information, while trained\nannotators labeled apparent skin tone using the Fitzpatrick Skin Type and Monk\nSkin Tone scales, and voice timbre. Annotators also labeled for different\nrecording setups and per-second activity annotations.\n","authors":["Bilal Porgali","Vítor Albiero","Jordan Ryda","Cristian Canton Ferrer","Caner Hazirbas"],"pdf_url":"https://arxiv.org/pdf/2303.04838v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05431v1","updated":"2023-03-08T18:58:52Z","published":"2023-03-08T18:58:52Z","title":"disco: a toolkit for Distributional Control of Generative Models","summary":"  Pre-trained language models and other generative models have revolutionized\nNLP and beyond. However, these models tend to reproduce undesirable biases\npresent in their training data. Also, they may overlook patterns that are\nimportant but challenging to capture. To address these limitations, researchers\nhave introduced distributional control techniques. These techniques, not\nlimited to language, allow controlling the prevalence (i.e., expectations) of\nany features of interest in the model's outputs. Despite their potential, the\nwidespread adoption of these techniques has been hindered by the difficulty in\nadapting complex, disconnected code. Here, we present disco, an open-source\nPython library that brings these techniques to the broader public.\n","authors":["Germán Kruszewski","Jos Rozen","Marc Dymetman"],"pdf_url":"https://arxiv.org/pdf/2303.05431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15280v2","updated":"2023-03-08T11:20:46Z","published":"2022-09-30T07:39:48Z","title":"Learning Transferable Spatiotemporal Representations from Natural Script\n  Knowledge","summary":"  Pre-training on large-scale video data has become a common recipe for\nlearning transferable spatiotemporal representations in recent years. Despite\nsome progress, existing methods are mostly limited to highly curated datasets\n(e.g., K400) and exhibit unsatisfactory out-of-the-box representations. We\nargue that it is due to the fact that they only capture pixel-level knowledge\nrather than spatiotemporal semantics, which hinders further progress in video\nunderstanding. Inspired by the great success of image-text pre-training (e.g.,\nCLIP), we take the first step to exploit language semantics to boost\ntransferable spatiotemporal representation learning. We introduce a new pretext\ntask, Turning to Video for Transcript Sorting (TVTS), which sorts shuffled ASR\nscripts by attending to learned video representations. We do not rely on\ndescriptive captions and learn purely from video, i.e., leveraging the natural\ntranscribed speech knowledge to provide noisy but useful semantics over time.\nOur method enforces the vision model to contextualize what is happening over\ntime so that it can re-organize the narrative transcripts, and can seamlessly\napply to large-scale uncurated video data in the real world. Our method\ndemonstrates strong out-of-the-box spatiotemporal representations on diverse\nbenchmarks, e.g., +13.6% gains over VideoMAE on SSV2 via linear probing. The\ncode is available at https://github.com/TencentARC/TVTS.\n","authors":["Ziyun Zeng","Yuying Ge","Xihui Liu","Bin Chen","Ping Luo","Shu-Tao Xia","Yixiao Ge"],"pdf_url":"https://arxiv.org/pdf/2209.15280v2.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.05397v1","updated":"2023-03-08T05:05:26Z","published":"2023-03-08T05:05:26Z","title":"TOLD: A Novel Two-Stage Overlap-Aware Framework for Speaker Diarization","summary":"  Recently, end-to-end neural diarization (EEND) is introduced and achieves\npromising results in speaker-overlapped scenarios. In EEND, speaker diarization\nis formulated as a multi-label prediction problem, where speaker activities are\nestimated independently and their dependency are not well considered. To\novercome these disadvantages, we employ the power set encoding to reformulate\nspeaker diarization as a single-label classification problem and propose the\noverlap-aware EEND (EEND-OLA) model, in which speaker overlaps and dependency\ncan be modeled explicitly. Inspired by the success of two-stage hybrid systems,\nwe further propose a novel Two-stage OverLap-aware Diarization framework (TOLD)\nby involving a speaker overlap-aware post-processing (SOAP) model to\niteratively refine the diarization results of EEND-OLA. Experimental results\nshow that, compared with the original EEND, the proposed EEND-OLA achieves a\n14.39% relative improvement in terms of diarization error rates (DER), and\nutilizing SOAP provides another 19.33% relative improvement. As a result, our\nmethod TOLD achieves a DER of 10.14% on the CALLHOME dataset, which is a new\nstate-of-the-art result on this benchmark to the best of our knowledge.\n","authors":["Jiaming Wang","Zhihao Du","Shiliang Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05397v1.pdf","comment":"Accepted by ICASSP2023"}]},"2023-03-09T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2303.05510v1","updated":"2023-03-09T18:59:47Z","published":"2023-03-09T18:59:47Z","title":"Planning with Large Language Models for Code Generation","summary":"  Existing large language model-based code generation pipelines typically use\nbeam search or sampling algorithms during the decoding process. Although the\nprograms they generate achieve high token-matching-based scores, they often\nfail to compile or generate incorrect outputs. The main reason is that\nconventional Transformer decoding algorithms may not be the best choice for\ncode generation. In this work, we propose a novel Transformer decoding\nalgorithm, Planning-Guided Transformer Decoding (PG-TD), that uses a planning\nalgorithm to do lookahead search and guide the Transformer to generate better\nprograms. Specifically, instead of simply optimizing the likelihood of the\ngenerated sequences, the Transformer makes use of a planner to generate\ncandidate programs and test them on public test cases. The Transformer can\ntherefore make more informed decisions and generate tokens that will eventually\nlead to higher-quality programs. We also design a mechanism that shares\ninformation between the Transformer and the planner to make our algorithm\ncomputationally efficient. We empirically evaluate our framework with several\nlarge language models as backbones on public coding challenge benchmarks,\nshowing that 1) it can generate programs that consistently achieve higher\nperformance compared with competing baseline methods; 2) it enables\ncontrollable code generation, such as concise codes and highly-commented codes\nby optimizing modified objective.\n","authors":["Shun Zhang","Zhenfang Chen","Yikang Shen","Mingyu Ding","Joshua B. Tenenbaum","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2303.05510v1.pdf","comment":"ICLR 2023. Project page:https://codeaimcts.github.io"},{"id":"http://arxiv.org/abs/2303.05453v1","updated":"2023-03-09T17:52:07Z","published":"2023-03-09T17:52:07Z","title":"Personalisation within bounds: A risk taxonomy and policy framework for\n  the alignment of large language models with personalised feedback","summary":"  Large language models (LLMs) are used to generate content for a wide range of\ntasks, and are set to reach a growing audience in coming years due to\nintegration in product interfaces like ChatGPT or search engines like Bing.\nThis intensifies the need to ensure that models are aligned with human\npreferences and do not produce unsafe, inaccurate or toxic outputs. While\nalignment techniques like reinforcement learning with human feedback (RLHF) and\nred-teaming can mitigate some safety concerns and improve model capabilities,\nit is unlikely that an aggregate fine-tuning process can adequately represent\nthe full range of users' preferences and values. Different people may\nlegitimately disagree on their preferences for language and conversational\nnorms, as well as on values or ideologies which guide their communication.\nPersonalising LLMs through micro-level preference learning processes may result\nin models that are better aligned with each user. However, there are several\nnormative challenges in defining the bounds of a societally-acceptable and safe\ndegree of personalisation. In this paper, we ask how, and in what ways, LLMs\nshould be personalised. First, we review literature on current paradigms for\naligning LLMs with human feedback, and identify issues including (i) a lack of\nclarity regarding what alignment means; (ii) a tendency of technology providers\nto prescribe definitions of inherently subjective preferences and values; and\n(iii) a 'tyranny of the crowdworker', exacerbated by a lack of documentation in\nwho we are really aligning to. Second, we present a taxonomy of benefits and\nrisks associated with personalised LLMs, for individuals and society at large.\nFinally, we propose a three-tiered policy framework that allows users to\nexperience the benefits of personalised alignment, while restraining unsafe and\nundesirable LLM-behaviours within (supra-)national and organisational bounds.\n","authors":["Hannah Rose Kirk","Bertie Vidgen","Paul Röttger","Scott A. Hale"],"pdf_url":"https://arxiv.org/pdf/2303.05453v1.pdf","comment":"19 pages, 1 table"},{"id":"http://arxiv.org/abs/2303.03836v2","updated":"2023-03-09T17:33:31Z","published":"2023-03-07T12:03:58Z","title":"Exploring the Feasibility of ChatGPT for Event Extraction","summary":"  Event extraction is a fundamental task in natural language processing that\ninvolves identifying and extracting information about events mentioned in text.\nHowever, it is a challenging task due to the lack of annotated data, which is\nexpensive and time-consuming to obtain. The emergence of large language models\n(LLMs) such as ChatGPT provides an opportunity to solve language tasks with\nsimple prompts without the need for task-specific datasets and fine-tuning.\nWhile ChatGPT has demonstrated impressive results in tasks like machine\ntranslation, text summarization, and question answering, it presents challenges\nwhen used for complex tasks like event extraction. Unlike other tasks, event\nextraction requires the model to be provided with a complex set of instructions\ndefining all event types and their schemas. To explore the feasibility of\nChatGPT for event extraction and the challenges it poses, we conducted a series\nof experiments. Our results show that ChatGPT has, on average, only 51.04% of\nthe performance of a task-specific model such as EEQA in long-tail and complex\nscenarios. Our usability testing experiments indicate that ChatGPT is not\nrobust enough, and continuous refinement of the prompt does not lead to stable\nperformance improvements, which can result in a poor user experience. Besides,\nChatGPT is highly sensitive to different prompt styles.\n","authors":["Jun Gao","Huan Zhao","Changlong Yu","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2303.03836v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09051v3","updated":"2023-03-09T17:25:10Z","published":"2023-02-17T18:31:31Z","title":"Complex QA and language models hybrid architectures, Survey","summary":"  This paper reviews the state-of-the-art of hybrid language models\narchitectures and strategies for \"complex\" question-answering (QA, CQA, CPS).\nLarge Language Models (LLM) are good at leveraging public data on standard\nproblems but once you want to tackle more specific complex questions or\nproblems you may need specific architecture, knowledge, skills, methods,\nsensitive data protection, explainability, human approval and versatile\nfeedback... We identify key elements augmenting LLM to solve complex questions\nor problems. We extend findings from the robust community edited research\npapers BIG, BLOOM and HELM which open source, benchmark and analyze limits and\nchallenges of LLM in terms of tasks complexity and strict evaluation on\naccuracy (e.g. fairness, robustness, toxicity, ...). Recent projects like\nChatGPT and GALACTICA have allowed non-specialists to grasp the great potential\nas well as the equally strong limitations of language models in complex QA.\nHybridizing these models with different components could allow to overcome\nthese different limits and go much further. We discuss some challenges\nassociated with complex QA, including domain adaptation, decomposition and\nefficient multi-step QA, long form and non-factoid QA, safety and\nmulti-sensitivity data protection, multimodal search, hallucinations,\nexplainability and truthfulness, temproal reasoning. Therefore, we analyze\ncurrent solutions and promising research trends, using elements such as: hybrid\nLLM architectures, active human reinforcement learning supervised with AI,\nprompting adaptation, neuro-symbolic and structured knowledge grounding,\nprogram synthesis, iterated decomposition and others.\n","authors":["Xavier Daull","Patrice Bellot","Emmanuel Bruno","Vincent Martin","Elisabeth Murisasco"],"pdf_url":"https://arxiv.org/pdf/2302.09051v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04001v2","updated":"2023-03-09T17:10:27Z","published":"2023-03-07T16:00:26Z","title":"ELODIN: Naming Concepts in Embedding Spaces","summary":"  Despite recent advancements, the field of text-to-image synthesis still\nsuffers from lack of fine-grained control. Using only text, it remains\nchallenging to deal with issues such as concept coherence and concept\ncontamination. We propose a method to enhance control by generating specific\nconcepts that can be reused throughout multiple images, effectively expanding\nnatural language with new words that can be combined much like a painter's\npalette. Unlike previous contributions, our method does not copy visuals from\ninput data and can generate concepts through text alone. We perform a set of\ncomparisons that finds our method to be a significant improvement over\ntext-only prompts.\n","authors":["Rodrigo Mello","Filipe Calegario","Geber Ramalho"],"pdf_url":"https://arxiv.org/pdf/2303.04001v2.pdf","comment":"Added quantitative data, fixed formatting issues"},{"id":"http://arxiv.org/abs/2303.05349v1","updated":"2023-03-09T15:46:54Z","published":"2023-03-09T15:46:54Z","title":"Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data","summary":"  Advanced large language models like ChatGPT have gained considerable\nattention recently, including among students. However, while the debate on\nChatGPT in academia is making waves, more understanding is needed among\nlecturers and teachers on how students use and perceive ChatGPT. To address\nthis gap, we analyzed the content on ChatGPT available on TikTok in February\n2023. TikTok is a rapidly growing social media platform popular among\nindividuals under 30. Specifically, we analyzed the content of the 100 most\npopular videos in English tagged with #chatgpt, which collectively garnered\nover 250 million views. Most of the videos we studied promoted the use of\nChatGPT for tasks like writing essays or code. In addition, many videos\ndiscussed AI detectors, with a focus on how other tools can help to transform\nChatGPT output to fool these detectors. This also mirrors the discussion among\neducators on how to treat ChatGPT as lecturers and teachers in teaching and\ngrading. What is, however, missing from the analyzed clips on TikTok are videos\nthat discuss ChatGPT producing content that is nonsensical or unfaithful to the\ntraining data.\n","authors":["Anna-Carolina Haensch","Sarah Ball","Markus Herklotz","Frauke Kreuter"],"pdf_url":"https://arxiv.org/pdf/2303.05349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15162v3","updated":"2023-03-09T15:02:07Z","published":"2022-09-30T01:17:18Z","title":"Linearly Mapping from Image to Text Space","summary":"  The extent to which text-only language models (LMs) learn to represent\nfeatures of the non-linguistic world is an open question. Prior work has shown\nthat pretrained LMs can be taught to caption images when a vision model's\nparameters are optimized to encode images in the language space. We test a\nstronger hypothesis: that the conceptual representations learned by frozen\ntext-only models and vision-only models are similar enough that this can be\nachieved with a linear map. We show that the image representations from vision\nmodels can be transferred as continuous prompts to frozen LMs by training only\na single linear projection. Using these to prompt the LM achieves competitive\nperformance on captioning and visual question answering tasks compared to\nmodels that tune both the image encoder and text decoder (such as the MAGMA\nmodel). We compare three image encoders with increasing amounts of linguistic\nsupervision seen during pretraining: BEIT (no linguistic information),\nNF-ResNET (lexical category information), and CLIP (full natural language\ndescriptions). We find that all three encoders perform equally well at\ntransferring visual property information to the language model (e.g., whether\nan animal is large or small), but that image encoders pretrained with\nlinguistic supervision more saliently encode category information (e.g.,\ndistinguishing hippo vs. elephant) and thus perform significantly better on\nbenchmark language-and-vision tasks. Our results indicate that LMs encode\nconceptual information structurally similarly to vision-based models, even\nthose that are solely trained on images. Code is available here:\nhttps://github.com/jmerullo/limber\n","authors":["Jack Merullo","Louis Castricato","Carsten Eickhoff","Ellie Pavlick"],"pdf_url":"https://arxiv.org/pdf/2209.15162v3.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.05313v1","updated":"2023-03-09T15:01:12Z","published":"2023-03-09T15:01:12Z","title":"Replacement as a Self-supervision for Fine-grained Vision-language\n  Pre-training","summary":"  Fine-grained supervision based on object annotations has been widely used for\nvision and language pre-training (VLP). However, in real-world application\nscenarios, aligned multi-modal data is usually in the image-caption format,\nwhich only provides coarse-grained supervision. It is cost-expensive to collect\nobject annotations and build object annotation pre-extractor for different\nscenarios. In this paper, we propose a fine-grained self-supervision signal\nwithout object annotations from a replacement perspective. First, we propose a\nhomonym sentence rewriting (HSR) algorithm to provide token-level supervision.\nThe algorithm replaces a verb/noun/adjective/quantifier word of the caption\nwith its homonyms from WordNet. Correspondingly, we propose a replacement\nvision-language modeling (RVLM) framework to exploit the token-level\nsupervision. Two replaced modeling tasks, i.e., replaced language contrastive\n(RLC) and replaced language modeling (RLM), are proposed to learn the\nfine-grained alignment. Extensive experiments on several downstream tasks\ndemonstrate the superior performance of the proposed method.\n","authors":["Lisai Zhang","Qingcai Chen","Zhijian Chen","Yunpeng Han","Zhonghua Li","Zhao Cao"],"pdf_url":"https://arxiv.org/pdf/2303.05313v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2303.05309v1","updated":"2023-03-09T14:58:29Z","published":"2023-03-09T14:58:29Z","title":"MixSpeech: Cross-Modality Self-Learning with Audio-Visual Stream Mixup\n  for Visual Speech Translation and Recognition","summary":"  Multi-media communications facilitate global interaction among people.\nHowever, despite researchers exploring cross-lingual translation techniques\nsuch as machine translation and audio speech translation to overcome language\nbarriers, there is still a shortage of cross-lingual studies on visual speech.\nThis lack of research is mainly due to the absence of datasets containing\nvisual speech and translated text pairs. In this paper, we present\n\\textbf{AVMuST-TED}, the first dataset for \\textbf{A}udio-\\textbf{V}isual\n\\textbf{Mu}ltilingual \\textbf{S}peech \\textbf{T}ranslation, derived from\n\\textbf{TED} talks. Nonetheless, visual speech is not as distinguishable as\naudio speech, making it difficult to develop a mapping from source speech\nphonemes to the target language text. To address this issue, we propose\nMixSpeech, a cross-modality self-learning framework that utilizes audio speech\nto regularize the training of visual speech tasks. To further minimize the\ncross-modality gap and its impact on knowledge transfer, we suggest adopting\nmixed speech, which is created by interpolating audio and visual streams, along\nwith a curriculum learning strategy to adjust the mixing ratio as needed.\nMixSpeech enhances speech translation in noisy environments, improving BLEU\nscores for four languages on AVMuST-TED by +1.4 to +4.2. Moreover, it achieves\nstate-of-the-art performance in lip reading on CMLR (11.1\\%), LRS2 (25.5\\%),\nand LRS3 (28.0\\%).\n","authors":["Xize Cheng","Linjun Li","Tao Jin","Rongjie Huang","Wang Lin","Zehan Wang","Huangdai Liu","Ye Wang","Aoxiong Yin","Zhou Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.05309v1.pdf","comment":"https://github.com/Exgc/AVMuST-TED"},{"id":"http://arxiv.org/abs/2303.05295v1","updated":"2023-03-09T14:44:31Z","published":"2023-03-09T14:44:31Z","title":"Dynamic Stashing Quantization for Efficient Transformer Training","summary":"  Large Language Models (LLMs) have demonstrated impressive performance on a\nrange of Natural Language Processing (NLP) tasks. Unfortunately, the immense\namount of computations and memory accesses required for LLM training makes them\nprohibitively expensive in terms of hardware cost, and thus challenging to\ndeploy in use cases such as on-device learning. In this paper, motivated by the\nobservation that LLM training is memory-bound, we propose a novel dynamic\nquantization strategy, termed Dynamic Stashing Quantization (DSQ), that puts a\nspecial focus on reducing the memory operations, but also enjoys the other\nbenefits of low precision training, such as the reduced arithmetic cost. We\nconduct a thorough study on two translation tasks (trained-from-scratch) and\nthree classification tasks (fine-tuning). DSQ reduces the amount of arithmetic\noperations by $20.95\\times$ and the number of DRAM operations by $2.55\\times$\non IWSLT17 compared to the standard 16-bit fixed-point, which is widely used in\non-device learning.\n","authors":["Guo Yang","Daniel Lo","Robert Mullins","Yiren Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.05295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05221v1","updated":"2023-03-09T12:50:34Z","published":"2023-03-09T12:50:34Z","title":"SEAM: An Integrated Activation-Coupled Model of Sentence Processing and\n  Eye Movements in Reading","summary":"  Models of eye-movement control during reading, developed largely within\npsychology, usually focus on visual, attentional, and motor processes but\nneglect post-lexical language processing; by contrast, models of sentence\ncomprehension processes, developed largely within psycholinguistics, generally\nfocus only on post-lexical language processes. We present a model that combines\nthese two research threads, by integrating eye-movement control and sentence\nprocessing. Developing such an integrated model is extremely challenging and\ncomputationally demanding, but such an integration is an important step toward\ncomplete mathematical models of natural language comprehension in reading. We\ncombine the SWIFT model of eye-movement control (Engbert et al., Psychological\nReview, 112, 2005, pp. 777-813) with key components of the Lewis and Vasishth\nsentence processing model (Lewis and Vasishth, Cognitive Science, 29, 2005, pp.\n375-419). This integration becomes possible, for the first time, due in part to\nrecent advances in successful parameter identification in dynamical models,\nwhich allows us to investigate profile log-likelihoods for individual model\nparameters. We present a fully implemented proof-of-concept model demonstrating\nhow such an integrated model can be achieved; our approach includes Bayesian\nmodel inference with Markov Chain Monte Carlo (MCMC) sampling as a key\ncomputational tool. The integrated model, SEAM, can successfully reproduce eye\nmovement patterns that arise due to similarity-based interference in reading.\nTo our knowledge, this is the first-ever integration of a complete process\nmodel of eye-movement control with linguistic dependency completion processes\nin sentence comprehension. In future work, this proof of concept model will\nneed to be evaluated using a comprehensive set of benchmark data.\n","authors":["Maximilian M. Rabe","Dario Paape","Daniela Mertzen","Shravan Vasishth","Ralf Engbert"],"pdf_url":"https://arxiv.org/pdf/2303.05221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.02228v2","updated":"2023-03-09T12:45:10Z","published":"2023-01-05T18:55:09Z","title":"MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training","summary":"  In this paper, we consider enhancing medical visual-language pre-training\n(VLP) with domain-specific knowledge, by exploiting the paired image-text\nreports from the radiological daily practice. In particular, we make the\nfollowing contributions: First, unlike existing works that directly process the\nraw reports, we adopt a novel triplet extraction module to extract the\nmedical-related information, avoiding unnecessary complexity from language\ngrammar and enhancing the supervision signals; Second, we propose a novel\ntriplet encoding module with entity translation by querying a knowledge base,\nto exploit the rich domain knowledge in medical field, and implicitly build\nrelationships between medical entities in the language embedding space; Third,\nwe propose to use a Transformer-based fusion model for spatially aligning the\nentity description with visual signals at the image patch level, enabling the\nability for medical diagnosis; Fourth, we conduct thorough experiments to\nvalidate the effectiveness of our architecture, and benchmark on numerous\npublic benchmarks, e.g., ChestX-ray14, RSNA Pneumonia, SIIM-ACR Pneumothorax,\nCOVIDx CXR-2, COVID Rural, and EdemaSeverity. In both zero-shot and fine-tuning\nsettings, our model has demonstrated strong performance compared with the\nformer methods on disease classification and grounding.\n","authors":["Chaoyi Wu","Xiaoman Zhang","Ya Zhang","Yanfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2301.02228v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05208v1","updated":"2023-03-09T12:22:28Z","published":"2023-03-09T12:22:28Z","title":"Geometry of Language","summary":"  In this article, we present a fresh perspective on language, combining ideas\nfrom various sources, but mixed in a new synthesis. As in the minimalist\nprogram, the question is whether we can formulate an elegant formalism, a\nuniversal grammar or a mechanism which explains significant aspects of the\nhuman faculty of language, which in turn can be considered a natural\ndisposition for the evolution and deployment of the diverse human languages. We\ndescribe such a mechanism, which differs from existing logical and grammatical\napproaches by its geometric nature. Our main contribution is to explore the\nassumption that sentence recognition takes place by forming chains of tokens\nrepresenting words, followed by matching these chains with pre-existing chains\nrepresenting grammatical word orders. The aligned chains of tokens give rise to\ntwo- and three-dimensional complexes. The resulting model gives an alternative\npresentation for subtle rules, traditionally formalized using categorial\ngrammar.\n","authors":["Loe Feijs"],"pdf_url":"https://arxiv.org/pdf/2303.05208v1.pdf","comment":"17 pages, 24 figures"},{"id":"http://arxiv.org/abs/2210.15282v2","updated":"2023-03-09T11:41:34Z","published":"2022-10-27T09:31:37Z","title":"Weight Averaging: A Simple Yet Effective Method to Overcome Catastrophic\n  Forgetting in Automatic Speech Recognition","summary":"  Adapting a trained Automatic Speech Recognition (ASR) model to new tasks\nresults in catastrophic forgetting of old tasks, limiting the model's ability\nto learn continually and to be extended to new speakers, dialects, languages,\netc. Focusing on End-to-End ASR, in this paper, we propose a simple yet\neffective method to overcome catastrophic forgetting: weight averaging. By\nsimply taking the average of the previous and the adapted model, our method\nachieves high performance on both the old and new tasks. It can be further\nimproved by introducing a knowledge distillation loss during the adaptation. We\nillustrate the effectiveness of our method on both monolingual and multilingual\nASR. In both cases, our method strongly outperforms all baselines, even in its\nsimplest form.\n","authors":["Steven Vander Eeckt","Hugo Van hamme"],"pdf_url":"https://arxiv.org/pdf/2210.15282v2.pdf","comment":"Accepted at ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2112.09427v4","updated":"2023-03-09T11:34:24Z","published":"2021-12-17T10:47:17Z","title":"Continual Learning for Monolingual End-to-End Automatic Speech\n  Recognition","summary":"  Adapting Automatic Speech Recognition (ASR) models to new domains results in\na deterioration of performance on the original domain(s), a phenomenon called\nCatastrophic Forgetting (CF). Even monolingual ASR models cannot be extended to\nnew accents, dialects, topics, etc. without suffering from CF, making them\nunable to be continually enhanced without storing all past data. Fortunately,\nContinual Learning (CL) methods, which aim to enable continual adaptation while\novercoming CF, can be used. In this paper, we implement an extensive number of\nCL methods for End-to-End ASR and test and compare their ability to extend a\nmonolingual Hybrid CTC-Transformer model across four new tasks. We find that\nthe best performing CL method closes the gap between the fine-tuned model\n(lower bound) and the model trained jointly on all tasks (upper bound) by more\nthan 40%, while requiring access to only 0.6% of the original data.\n","authors":["Steven Vander Eeckt","Hugo Van hamme"],"pdf_url":"https://arxiv.org/pdf/2112.09427v4.pdf","comment":"Published at EUSIPCO 2022. 5 pages, 1 figure"},{"id":"http://arxiv.org/abs/2203.10854v2","updated":"2023-03-09T11:08:39Z","published":"2022-03-21T10:20:30Z","title":"Paraphrasing Techniques for Maritime QA system","summary":"  There has been an increasing interest in incorporating Artificial\nIntelligence (AI) into Defence and military systems to complement and augment\nhuman intelligence and capabilities. However, much work still needs to be done\ntoward achieving an effective human-machine partnership. This work is aimed at\nenhancing human-machine communications by developing a capability for\nautomatically translating human natural language into a machine-understandable\nlanguage (e.g., SQL queries). Techniques toward achieving this goal typically\ninvolve building a semantic parser trained on a very large amount of\nhigh-quality manually-annotated data. However, in many real-world Defence\nscenarios, it is not feasible to obtain such a large amount of training data.\nTo the best of our knowledge, there are few works trying to explore the\npossibility of training a semantic parser with limited manually-paraphrased\ndata, in other words, zero-shot. In this paper, we investigate how to exploit\nparaphrasing methods for the automated generation of large-scale training\ndatasets (in the form of paraphrased utterances and their corresponding logical\nforms in SQL format) and present our experimental results using real-world data\nin the maritime domain.\n","authors":["Fatemeh Shiri","Terry Yue Zhuo","Zhuang Li","Van Nguyen","Shirui Pan","Weiqing Wang","Reza Haffari","Yuan-Fang Li"],"pdf_url":"https://arxiv.org/pdf/2203.10854v2.pdf","comment":"8 pages. The first three authors contribute equally"},{"id":"http://arxiv.org/abs/2210.05556v4","updated":"2023-03-09T11:04:07Z","published":"2022-10-11T15:50:51Z","title":"ViLPAct: A Benchmark for Compositional Generalization on Multimodal\n  Human Activities","summary":"  We introduce ViLPAct, a novel vision-language benchmark for human activity\nplanning. It is designed for a task where embodied AI agents can reason and\nforecast future actions of humans based on video clips about their initial\nactivities and intents in text. The dataset consists of 2.9k videos from\n\\charades extended with intents via crowdsourcing, a multi-choice question test\nset, and four strong baselines. One of the baselines implements a neurosymbolic\napproach based on a multi-modal knowledge base (MKB), while the other ones are\ndeep generative models adapted from recent state-of-the-art (SOTA) methods.\nAccording to our extensive experiments, the key challenges are compositional\ngeneralization and effective use of information from both modalities.\n","authors":["Terry Yue Zhuo","Yaqing Liao","Yuecheng Lei","Lizhen Qu","Gerard de Melo","Xiaojun Chang","Yazhou Ren","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2210.05556v4.pdf","comment":"Accepted at EACL2023 (Findings)"},{"id":"http://arxiv.org/abs/2301.12868v3","updated":"2023-03-09T11:01:02Z","published":"2023-01-30T13:21:00Z","title":"On Robustness of Prompt-based Semantic Parsing with Large Pre-trained\n  Language Model: An Empirical Study on Codex","summary":"  Semantic parsing is a technique aimed at constructing a structured\nrepresentation of the meaning of a natural-language question. Recent\nadvancements in few-shot language models trained on code have demonstrated\nsuperior performance in generating these representations compared to\ntraditional unimodal language models, which are trained on downstream tasks.\nDespite these advancements, existing fine-tuned neural semantic parsers are\nsusceptible to adversarial attacks on natural-language inputs. While it has\nbeen established that the robustness of smaller semantic parsers can be\nenhanced through adversarial training, this approach is not feasible for large\nlanguage models in real-world scenarios, as it requires both substantial\ncomputational resources and expensive human annotation on in-domain semantic\nparsing data. This paper presents the first empirical study on the adversarial\nrobustness of a large prompt-based language model of code, \\codex. Our results\ndemonstrate that the state-of-the-art (SOTA) code-language models are\nvulnerable to carefully crafted adversarial examples. To address this\nchallenge, we propose methods for improving robustness without the need for\nsignificant amounts of labeled data or heavy computational resources.\n","authors":["Terry Yue Zhuo","Zhuang Li","Yujin Huang","Fatemeh Shiri","Weiqing Wang","Gholamreza Haffari","Yuan-Fang Li"],"pdf_url":"https://arxiv.org/pdf/2301.12868v3.pdf","comment":"Accepted at EACL2023 (main)"},{"id":"http://arxiv.org/abs/2303.05160v1","updated":"2023-03-09T10:33:31Z","published":"2023-03-09T10:33:31Z","title":"$π$-augmented pregroups and applications to linguistics","summary":"  We enrich pregroups with a mapping which allows us to locally apply precyclic\npermutations to designated substrings. We prove a normalisation theorem for\nsuch algebraic structures and briefly formalise some known applications of\npregroups to the analysis of clitic pronouns in certain natural languages.\n","authors":["Valentin Boboc"],"pdf_url":"https://arxiv.org/pdf/2303.05160v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2303.05153v1","updated":"2023-03-09T10:12:18Z","published":"2023-03-09T10:12:18Z","title":"Can a Frozen Pretrained Language Model be used for Zero-shot Neural\n  Retrieval on Entity-centric Questions?","summary":"  Neural document retrievers, including dense passage retrieval (DPR), have\noutperformed classical lexical-matching retrievers, such as BM25, when\nfine-tuned and tested on specific question-answering datasets. However, it has\nbeen shown that the existing dense retrievers do not generalize well not only\nout of domain but even in domain such as Wikipedia, especially when a named\nentity in a question is a dominant clue for retrieval. In this paper, we\npropose an approach toward in-domain generalization using the embeddings\ngenerated by the frozen language model trained with the entities in the domain.\nBy not fine-tuning, we explore the possibility that the rich knowledge\ncontained in a pretrained language model can be used for retrieval tasks. The\nproposed method outperforms conventional DPRs on entity-centric questions in\nWikipedia domain and achieves almost comparable performance to BM25 and\nstate-of-the-art SPAR model. We also show that the contextualized keys lead to\nstrong improvements compared to BM25 when the entity names consist of common\nwords. Our results demonstrate the feasibility of the zero-shot retrieval\nmethod for entity-centric questions of Wikipedia domain, where DPR has\nstruggled to perform.\n","authors":["Yasuto Hoshi","Daisuke Miyashita","Yasuhiro Morioka","Youyang Ng","Osamu Torii","Jun Deguchi"],"pdf_url":"https://arxiv.org/pdf/2303.05153v1.pdf","comment":"Accepted to Workshop on Knowledge Augmented Methods for Natural\n  Language Processing, in conjunction with AAAI 2023"},{"id":"http://arxiv.org/abs/2303.05143v1","updated":"2023-03-09T09:52:28Z","published":"2023-03-09T09:52:28Z","title":"ESCL: Equivariant Self-Contrastive Learning for Sentence Representations","summary":"  Previous contrastive learning methods for sentence representations often\nfocus on insensitive transformations to produce positive pairs, but neglect the\nrole of sensitive transformations that are harmful to semantic representations.\nTherefore, we propose an Equivariant Self-Contrastive Learning (ESCL) method to\nmake full use of sensitive transformations, which encourages the learned\nrepresentations to be sensitive to certain types of transformations with an\nadditional equivariant learning task. Meanwhile, in order to improve\npracticability and generality, ESCL simplifies the implementations of\ntraditional equivariant contrastive methods to share model parameters from the\nperspective of multi-task learning. We evaluate our ESCL on semantic textual\nsimilarity tasks. The proposed method achieves better results while using fewer\nlearning parameters compared to previous methods.\n","authors":["Jie Liu","Yixuan Liu","Xue Han","Chao Deng","Junlan Feng"],"pdf_url":"https://arxiv.org/pdf/2303.05143v1.pdf","comment":"accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2112.03073v2","updated":"2023-03-09T09:22:29Z","published":"2021-11-26T07:58:11Z","title":"Active Learning for Event Extraction with Memory-based Loss Prediction\n  Model","summary":"  Event extraction (EE) plays an important role in many industrial application\nscenarios, and high-quality EE methods require a large amount of manual\nannotation data to train supervised learning models. However, the cost of\nobtaining annotation data is very high, especially for annotation of domain\nevents, which requires the participation of experts from corresponding domain.\nSo we introduce active learning (AL) technology to reduce the cost of event\nannotation. But the existing AL methods have two main problems, which make them\nnot well used for event extraction. Firstly, the existing pool-based selection\nstrategies have limitations in terms of computational cost and sample validity.\nSecondly, the existing evaluation of sample importance lacks the use of local\nsample information. In this paper, we present a novel deep AL method for EE. We\npropose a batch-based selection strategy and a Memory-Based Loss Prediction\nmodel (MBLP) to select unlabeled samples efficiently. During the selection\nprocess, we use an internal-external sample loss ranking method to evaluate the\nsample importance by using local information. Finally, we propose a delayed\ntraining strategy to train the MBLP model. Extensive experiments are performed\non three domain datasets, and our method outperforms other state-of-the-art\nmethods.\n","authors":["Shirong Shen","Zhen Li","Guilin Qi"],"pdf_url":"https://arxiv.org/pdf/2112.03073v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07126v2","updated":"2023-03-09T09:17:25Z","published":"2022-10-13T16:06:59Z","title":"Challenges in Explanation Quality Evaluation","summary":"  While much research focused on producing explanations, it is still unclear\nhow the produced explanations' quality can be evaluated in a meaningful way.\nToday's predominant approach is to quantify explanations using proxy scores\nwhich compare explanations to (human-annotated) gold explanations. This\napproach assumes that explanations which reach higher proxy scores will also\nprovide a greater benefit to human users. In this paper, we present problems of\nthis approach. Concretely, we (i) formulate desired characteristics of\nexplanation quality, (ii) describe how current evaluation practices violate\nthem, and (iii) support our argumentation with initial evidence from a\ncrowdsourcing case study in which we investigate the explanation quality of\nstate-of-the-art explainable question answering systems. We find that proxy\nscores correlate poorly with human quality ratings and, additionally, become\nless expressive the more often they are used (i.e. following Goodhart's law).\nFinally, we propose guidelines to enable a meaningful evaluation of\nexplanations to drive the development of systems that provide tangible benefits\nto human users.\n","authors":["Hendrik Schuff","Heike Adel","Peng Qi","Ngoc Thang Vu"],"pdf_url":"https://arxiv.org/pdf/2210.07126v2.pdf","comment":"41 pages, 11 figures"},{"id":"http://arxiv.org/abs/2303.05093v1","updated":"2023-03-09T08:07:38Z","published":"2023-03-09T08:07:38Z","title":"Improving Video Retrieval by Adaptive Margin","summary":"  Video retrieval is becoming increasingly important owing to the rapid\nemergence of videos on the Internet. The dominant paradigm for video retrieval\nlearns video-text representations by pushing the distance between the\nsimilarity of positive pairs and that of negative pairs apart from a fixed\nmargin. However, negative pairs used for training are sampled randomly, which\nindicates that the semantics between negative pairs may be related or even\nequivalent, while most methods still enforce dissimilar representations to\ndecrease their similarity. This phenomenon leads to inaccurate supervision and\npoor performance in learning video-text representations.\n  While most video retrieval methods overlook that phenomenon, we propose an\nadaptive margin changed with the distance between positive and negative pairs\nto solve the aforementioned issue. First, we design the calculation framework\nof the adaptive margin, including the method of distance measurement and the\nfunction between the distance and the margin. Then, we explore a novel\nimplementation called \"Cross-Modal Generalized Self-Distillation\" (CMGSD),\nwhich can be built on the top of most video retrieval models with few\nmodifications. Notably, CMGSD adds few computational overheads at train time\nand adds no computational overhead at test time. Experimental results on three\nwidely used datasets demonstrate that the proposed method can yield\nsignificantly better performance than the corresponding backbone model, and it\noutperforms state-of-the-art methods by a large margin.\n","authors":["Feng He","Qi Wang","Zhifan Feng","Wenbin Jiang","Yajuan Lv","Yong zhu","Xiao Tan"],"pdf_url":"https://arxiv.org/pdf/2303.05093v1.pdf","comment":"Accepted by SIGIR 2021"},{"id":"http://arxiv.org/abs/2303.05082v1","updated":"2023-03-09T07:35:31Z","published":"2023-03-09T07:35:31Z","title":"Dynamic Multi-View Fusion Mechanism For Chinese Relation Extraction","summary":"  Recently, many studies incorporate external knowledge into character-level\nfeature based models to improve the performance of Chinese relation extraction.\nHowever, these methods tend to ignore the internal information of the Chinese\ncharacter and cannot filter out the noisy information of external knowledge. To\naddress these issues, we propose a mixture-of-view-experts framework (MoVE) to\ndynamically learn multi-view features for Chinese relation extraction. With\nboth the internal and external knowledge of Chinese characters, our framework\ncan better capture the semantic information of Chinese characters. To\ndemonstrate the effectiveness of the proposed framework, we conduct extensive\nexperiments on three real-world datasets in distinct domains. Experimental\nresults show consistent and significant superiority and robustness of our\nproposed framework. Our code and dataset will be released at:\nhttps://gitee.com/tmg-nudt/multi-view-of-expert-for-chineserelation-extraction\n","authors":["Jing Yang","Bin Ji","Shasha Li","Jun Ma","Long Peng","Jie Yu"],"pdf_url":"https://arxiv.org/pdf/2303.05082v1.pdf","comment":"This paper has been accepted by PAKDD 2023"},{"id":"http://arxiv.org/abs/2303.05080v1","updated":"2023-03-09T07:31:56Z","published":"2023-03-09T07:31:56Z","title":"Revisiting the relevance of traditional genres: a network analysis of\n  fiction readers' preferences","summary":"  We investigate how well traditional fiction genres like Fantasy, Thriller,\nand Literature represent readers' preferences. Using user data from Goodreads\nwe construct a book network where two books are strongly linked if the same\npeople tend to read or enjoy them both. We then partition this network into\ncommunities of similar books and assign each a list of subjects from The Open\nLibrary to serve as a proxy for traditional genres. Our analysis reveals that\nthe network communities correspond to existing combinations of traditional\ngenres, but that the exact communities differ depending on whether we consider\nbooks that people read or books that people enjoy.\n  In addition, we apply principal component analysis to the data and find that\nthe variance in the book communities is best explained by two factors: the\nmaturity/childishness and realism/fantastical nature of the books. We propose\nusing this maturity-realism plane as a coarse classification tool for stories.\n","authors":["Taom Sakal","Stephen Proulx"],"pdf_url":"https://arxiv.org/pdf/2303.05080v1.pdf","comment":"Supplementary materials at https://github.com/taomsakal/book-networks"},{"id":"http://arxiv.org/abs/2303.05077v1","updated":"2023-03-09T07:22:07Z","published":"2023-03-09T07:22:07Z","title":"Learning the Legibility of Visual Text Perturbations","summary":"  Many adversarial attacks in NLP perturb inputs to produce visually similar\nstrings ('ergo' $\\rightarrow$ '$\\epsilon$rgo') which are legible to humans but\ndegrade model performance. Although preserving legibility is a necessary\ncondition for text perturbation, little work has been done to systematically\ncharacterize it; instead, legibility is typically loosely enforced via\nintuitions around the nature and extent of perturbations. Particularly, it is\nunclear to what extent can inputs be perturbed while preserving legibility, or\nhow to quantify the legibility of a perturbed string. In this work, we address\nthis gap by learning models that predict the legibility of a perturbed string,\nand rank candidate perturbations based on their legibility. To do so, we\ncollect and release \\dataset, a human-annotated dataset comprising the\nlegibility of visually perturbed text. Using this dataset, we build both text-\nand vision-based models which achieve up to $0.91$ F1 score in predicting\nwhether an input is legible, and an accuracy of $0.86$ in predicting which of\ntwo given perturbations is more legible. Additionally, we discover that legible\nperturbations from the \\dataset dataset are more effective at lowering the\nperformance of NLP models than best-known attack strategies, suggesting that\ncurrent models may be vulnerable to a broad range of perturbations beyond what\nis captured by existing visual attacks. Data, code, and models are available at\nhttps://github.com/dvsth/learning-legibility-2023.\n","authors":["Dev Seth","Rickard Stureborg","Danish Pruthi","Bhuwan Dhingra"],"pdf_url":"https://arxiv.org/pdf/2303.05077v1.pdf","comment":"9 pages, 11 figures. Long paper at EACL 2023"},{"id":"http://arxiv.org/abs/2303.03840v2","updated":"2023-03-09T06:28:38Z","published":"2023-03-07T12:10:47Z","title":"A Challenging Benchmark for Low-Resource Learning","summary":"  With promising yet saturated results in high-resource settings, low-resource\ndatasets have gradually become popular benchmarks for evaluating the learning\nability of advanced neural networks (e.g., BigBench, superGLUE). Some models\neven surpass humans according to benchmark test results. However, we find that\nthere exists a set of hard examples in low-resource settings that challenge\nneural networks but are not well evaluated, which causes over-estimated\nperformance. We first give a theoretical analysis on which factors bring the\ndifficulty of low-resource learning. It then motivate us to propose a\nchallenging benchmark hardBench to better evaluate the learning ability, which\ncovers 11 datasets, including 3 computer vision (CV) datasets and 8 natural\nlanguage process (NLP) datasets. Experiments on a wide range of models show\nthat neural networks, even pre-trained language models, have sharp performance\ndrops on our benchmark, demonstrating the effectiveness on evaluating the\nweaknesses of neural networks. On NLP tasks, we surprisingly find that despite\nbetter results on traditional low-resource benchmarks, pre-trained networks,\ndoes not show performance improvements on our benchmarks. These results\ndemonstrate that there are still a large robustness gap between existing models\nand human-level performance.\n","authors":["Yudong Wang","Chang Ma","Qingxiu Dong","Lingpeng Kong","Jingjing Xu"],"pdf_url":"https://arxiv.org/pdf/2303.03840v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05063v1","updated":"2023-03-09T06:24:50Z","published":"2023-03-09T06:24:50Z","title":"ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for\n  Document Information Extraction","summary":"  Large language models (LLMs), such as GPT-3 and ChatGPT, have demonstrated\nremarkable results in various natural language processing (NLP) tasks with\nin-context learning, which involves inference based on a few demonstration\nexamples. Despite their successes in NLP tasks, no investigation has been\nconducted to assess the ability of LLMs to perform document information\nextraction (DIE) using in-context learning. Applying LLMs to DIE poses two\nchallenges: the modality and task gap. To this end, we propose a simple but\neffective in-context learning framework called ICL-D3IE, which enables LLMs to\nperform DIE with different types of demonstration examples. Specifically, we\nextract the most difficult and distinct segments from hard training documents\nas hard demonstrations for benefiting all test instances. We design\ndemonstrations describing relationships that enable LLMs to understand\npositional relationships. We introduce formatting demonstrations for easy\nanswer extraction. Additionally, the framework improves diverse demonstrations\nby updating them iteratively. Our experiments on three widely used benchmark\ndatasets demonstrate that the ICL-D3IE framework enables GPT-3/ChatGPT to\nachieve superior performance when compared to previous pre-trained methods\nfine-tuned with full training in both the in-distribution (ID) setting and in\nthe out-of-distribution (OOD) setting.\n","authors":["Jiabang He","Lei Wang","Yi Hu","Ning Liu","Hui Liu","Xing Xu","Heng Tao Shen"],"pdf_url":"https://arxiv.org/pdf/2303.05063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05046v1","updated":"2023-03-09T05:50:54Z","published":"2023-03-09T05:50:54Z","title":"Unsupervised Language agnostic WER Standardization","summary":"  Word error rate (WER) is a standard metric for the evaluation of Automated\nSpeech Recognition (ASR) systems. However, WER fails to provide a fair\nevaluation of human perceived quality in presence of spelling variations,\nabbreviations, or compound words arising out of agglutination. Multiple\nspelling variations might be acceptable based on locale/geography, alternative\nabbreviations, borrowed words, and transliteration of code-mixed words from a\nforeign language to the target language script. Similarly, in case of\nagglutination, often times the agglutinated, as well as the split forms, are\nacceptable. Previous work handled this problem by using manually identified\nnormalization pairs and applying them to both the transcription and the\nhypothesis before computing WER. In this paper, we propose an automatic WER\nnormalization system consisting of two modules: spelling normalization and\nsegmentation normalization. The proposed system is unsupervised and language\nagnostic, and therefore scalable. Experiments with ASR on 35K utterances across\nfour languages yielded an average WER reduction of 13.28%. Human judgements of\nthese automatically identified normalization pairs show that our WER-normalized\nevaluation is highly consistent with the perceived quality of ASR output.\n","authors":["Satarupa Guha","Rahul Ambavat","Ankur Gupta","Manish Gupta","Rupeshkumar Mehta"],"pdf_url":"https://arxiv.org/pdf/2303.05046v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.11039v2","updated":"2023-03-09T05:48:21Z","published":"2022-08-23T15:25:44Z","title":"Flat Multi-modal Interaction Transformer for Named Entity Recognition","summary":"  Multi-modal named entity recognition (MNER) aims at identifying entity spans\nand recognizing their categories in social media posts with the aid of images.\nHowever, in dominant MNER approaches, the interaction of different modalities\nis usually carried out through the alternation of self-attention and\ncross-attention or over-reliance on the gating machine, which results in\nimprecise and biased correspondence between fine-grained semantic units of text\nand image. To address this issue, we propose a Flat Multi-modal Interaction\nTransformer (FMIT) for MNER. Specifically, we first utilize noun phrases in\nsentences and general domain words to obtain visual cues. Then, we transform\nthe fine-grained semantic representation of the vision and text into a unified\nlattice structure and design a novel relative position encoding to match\ndifferent modalities in Transformer. Meanwhile, we propose to leverage entity\nboundary detection as an auxiliary task to alleviate visual bias. Experiments\nshow that our methods achieve the new state-of-the-art performance on two\nbenchmark datasets.\n","authors":["Junyu Lu","Dixiang Zhang","Pingjian Zhang"],"pdf_url":"https://arxiv.org/pdf/2208.11039v2.pdf","comment":"Accepted by COLING 2022, oral paper"},{"id":"http://arxiv.org/abs/2303.05034v1","updated":"2023-03-09T04:51:27Z","published":"2023-03-09T04:51:27Z","title":"Multi-Stage Coarse-to-Fine Contrastive Learning for Conversation Intent\n  Induction","summary":"  Intent recognition is critical for task-oriented dialogue systems. However,\nfor emerging domains and new services, it is difficult to accurately identify\nthe key intent of a conversation due to time-consuming data annotation and\ncomparatively poor model transferability. Therefore, the automatic induction of\ndialogue intention is very important for intelligent dialogue systems. This\npaper presents our solution to Track 2 of Intent Induction from Conversations\nfor Task-Oriented Dialogue at the Eleventh Dialogue System Technology Challenge\n(DSTC11). The essence of intention clustering lies in distinguishing the\nrepresentation of different dialogue utterances. The key to automatic intention\ninduction is that, for any given set of new data, the sentence representation\nobtained by the model can be well distinguished from different labels.\nTherefore, we propose a multi-stage coarse-to-fine contrastive learning model\ntraining scheme including unsupervised contrastive learning pre-training,\nsupervised contrastive learning pre-training, and fine-tuning with joint\ncontrastive learning and clustering to obtain a better dialogue utterance\nrepresentation model for the clustering task. In the released DSTC11 Track 2\nevaluation results, our proposed system ranked first on both of the two\nsubtasks of this Track.\n","authors":["Caiyuan Chu","Ya Li","Yifan Liu","Jia-Chen Gu","Quan Liu","Yongxin Ge","Guoping Hu"],"pdf_url":"https://arxiv.org/pdf/2303.05034v1.pdf","comment":"Ranked 1st on Track 2 at DSTC 11, Accepted by DSTC 11 Workshop"},{"id":"http://arxiv.org/abs/2303.04729v2","updated":"2023-03-09T02:40:44Z","published":"2023-03-08T17:15:58Z","title":"On the Risks of Stealing the Decoding Algorithms of Language Models","summary":"  A key component of generating text from modern language models (LM) is the\nselection and tuning of decoding algorithms. These algorithms determine how to\ngenerate text from the internal probability distribution generated by the LM.\nThe process of choosing a decoding algorithm and tuning its hyperparameters\ntakes significant time, manual effort, and computation, and it also requires\nextensive human evaluation. Therefore, the identity and hyperparameters of such\ndecoding algorithms are considered to be extremely valuable to their owners. In\nthis work, we show, for the first time, that an adversary with typical API\naccess to an LM can steal the type and hyperparameters of its decoding\nalgorithms at very low monetary costs. Our attack is effective against popular\nLMs used in text generation APIs, including GPT-2 and GPT-3. We demonstrate the\nfeasibility of stealing such information with only a few dollars, e.g.,\n$\\$0.8$, $\\$1$, $\\$4$, and $\\$40$ for the four versions of GPT-3.\n","authors":["Ali Naseh","Kalpesh Krishna","Mohit Iyyer","Amir Houmansadr"],"pdf_url":"https://arxiv.org/pdf/2303.04729v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10447v3","updated":"2023-03-09T01:38:38Z","published":"2023-02-21T05:24:00Z","title":"Mask-guided BERT for Few Shot Text Classification","summary":"  Transformer-based language models have achieved significant success in\nvarious domains. However, the data-intensive nature of the transformer\narchitecture requires much labeled data, which is challenging in low-resource\nscenarios (i.e., few-shot learning (FSL)). The main challenge of FSL is the\ndifficulty of training robust models on small amounts of samples, which\nfrequently leads to overfitting. Here we present Mask-BERT, a simple and\nmodular framework to help BERT-based architectures tackle FSL. The proposed\napproach fundamentally differs from existing FSL strategies such as prompt\ntuning and meta-learning. The core idea is to selectively apply masks on text\ninputs and filter out irrelevant information, which guides the model to focus\non discriminative tokens that influence prediction results. In addition, to\nmake the text representations from different categories more separable and the\ntext representations from the same category more compact, we introduce a\ncontrastive learning loss function. Experimental results on public-domain\nbenchmark datasets demonstrate the effectiveness of Mask-BERT.\n","authors":["Wenxiong Liao","Zhengliang Liu","Haixing Dai","Zihao Wu","Yiyang Zhang","Xiaoke Huang","Yuzhong Chen","Xi Jiang","Wei Liu","Dajiang Zhu","Tianming Liu","Sheng Li","Xiang Li","Hongmin Cai"],"pdf_url":"https://arxiv.org/pdf/2302.10447v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04953v1","updated":"2023-03-09T00:10:29Z","published":"2023-03-09T00:10:29Z","title":"Let's Get Personal: Personal Questions Improve SocialBot Performance in\n  the Alexa Prize","summary":"  There has been an increased focus on creating conversational open-domain\ndialogue systems in the spoken dialogue community. Unlike traditional dialogue\nsystems, these conversational systems cannot assume any specific information\nneed or domain restrictions, i.e., the only inherent goal is to converse with\nthe user on an unknown set of topics. While massive improvements in Natural\nLanguage Understanding (NLU) and the growth of available knowledge resources\ncan partially support a robust conversation, these conversations generally lack\nthe rapport between two humans that know each other. We developed a robust\nopen-domain conversational system, Athena, that real Amazon Echo users access\nand evaluate at scale in the context of the Alexa Prize competition. We\nexperiment with methods intended to increase intimacy between Athena and the\nuser by heuristically developing a rule-based user model that personalizes both\nthe current and subsequent conversations and evaluating specific personal\nopinion question strategies in A/B studies. Our results show a statistically\nsignificant positive impact on perceived conversation quality and length when\nemploying these strategies.\n","authors":["Kevin K. Bowden","Marilyn Walker"],"pdf_url":"https://arxiv.org/pdf/2303.04953v1.pdf","comment":"Won Best Paper at IWSDS '23"},{"id":"http://arxiv.org/abs/2303.05581v1","updated":"2023-03-09T21:12:46Z","published":"2023-03-09T21:12:46Z","title":"Open World Classification with Adaptive Negative Samples","summary":"  Open world classification is a task in natural language processing with key\npractical relevance and impact. Since the open or {\\em unknown} category data\nonly manifests in the inference phase, finding a model with a suitable decision\nboundary accommodating for the identification of known classes and\ndiscrimination of the open category is challenging. The performance of existing\nmodels is limited by the lack of effective open category data during the\ntraining stage or the lack of a good mechanism to learn appropriate decision\nboundaries. We propose an approach based on \\underline{a}daptive\n\\underline{n}egative \\underline{s}amples (ANS) designed to generate effective\nsynthetic open category samples in the training stage and without requiring any\nprior knowledge or external datasets. Empirically, we find a significant\nadvantage in using auxiliary one-versus-rest binary classifiers, which\neffectively utilize the generated negative samples and avoid the complex\nthreshold-seeking stage in previous works. Extensive experiments on three\nbenchmark datasets show that ANS achieves significant improvements over\nstate-of-the-art methods.\n","authors":["Ke Bai","Guoyin Wang","Jiwei Li","Sunghyun Park","Sungjin Lee","Puyang Xu","Ricardo Henao","Lawrence Carin"],"pdf_url":"https://arxiv.org/pdf/2303.05581v1.pdf","comment":"Accepted by EMNLP 2021 (Main Track, Long Paper)"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.05512v1","updated":"2023-03-09T18:59:50Z","published":"2023-03-09T18:59:50Z","title":"PAC-NeRF: Physics Augmented Continuum Neural Radiance Fields for\n  Geometry-Agnostic System Identification","summary":"  Existing approaches to system identification (estimating the physical\nparameters of an object) from videos assume known object geometries. This\nprecludes their applicability in a vast majority of scenes where object\ngeometries are complex or unknown. In this work, we aim to identify parameters\ncharacterizing a physical system from a set of multi-view videos without any\nassumption on object geometry or topology. To this end, we propose \"Physics\nAugmented Continuum Neural Radiance Fields\" (PAC-NeRF), to estimate both the\nunknown geometry and physical parameters of highly dynamic objects from\nmulti-view videos. We design PAC-NeRF to only ever produce physically plausible\nstates by enforcing the neural radiance field to follow the conservation laws\nof continuum mechanics. For this, we design a hybrid Eulerian-Lagrangian\nrepresentation of the neural radiance field, i.e., we use the Eulerian grid\nrepresentation for NeRF density and color fields, while advecting the neural\nradiance fields via Lagrangian particles. This hybrid Eulerian-Lagrangian\nrepresentation seamlessly blends efficient neural rendering with the material\npoint method (MPM) for robust differentiable physics simulation. We validate\nthe effectiveness of our proposed framework on geometry and physical parameter\nestimation over a vast range of materials, including elastic bodies,\nplasticine, sand, Newtonian and non-Newtonian fluids, and demonstrate\nsignificant performance gain on most tasks.\n","authors":["Xuan Li","Yi-Ling Qiao","Peter Yichen Chen","Krishna Murthy Jatavallabhula","Ming Lin","Chenfanfu Jiang","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2303.05512v1.pdf","comment":"ICLR 2023 Spotlight. Project page:\n  https://sites.google.com/view/PAC-NeRF"},{"id":"http://arxiv.org/abs/2303.05511v1","updated":"2023-03-09T18:59:47Z","published":"2023-03-09T18:59:47Z","title":"Scaling up GANs for Text-to-Image Synthesis","summary":"  The recent success of text-to-image synthesis has taken the world by storm\nand captured the general public's imagination. From a technical standpoint, it\nalso marked a drastic change in the favored architecture to design generative\nimage models. GANs used to be the de facto choice, with techniques like\nStyleGAN. With DALL-E 2, auto-regressive and diffusion models became the new\nstandard for large-scale generative models overnight. This rapid shift raises a\nfundamental question: can we scale up GANs to benefit from large datasets like\nLAION? We find that na\\\"Ively increasing the capacity of the StyleGAN\narchitecture quickly becomes unstable. We introduce GigaGAN, a new GAN\narchitecture that far exceeds this limit, demonstrating GANs as a viable option\nfor text-to-image synthesis. GigaGAN offers three major advantages. First, it\nis orders of magnitude faster at inference time, taking only 0.13 seconds to\nsynthesize a 512px image. Second, it can synthesize high-resolution images, for\nexample, 16-megapixel pixels in 3.66 seconds. Finally, GigaGAN supports various\nlatent space editing applications such as latent interpolation, style mixing,\nand vector arithmetic operations.\n","authors":["Minguk Kang","Jun-Yan Zhu","Richard Zhang","Jaesik Park","Eli Shechtman","Sylvain Paris","Taesung Park"],"pdf_url":"https://arxiv.org/pdf/2303.05511v1.pdf","comment":"CVPR 2023. Project webpage at https://mingukkang.github.io/GigaGAN/"},{"id":"http://arxiv.org/abs/2303.05503v1","updated":"2023-03-09T18:55:03Z","published":"2023-03-09T18:55:03Z","title":"Open-world Instance Segmentation: Top-down Learning with Bottom-up\n  Supervision","summary":"  Many top-down architectures for instance segmentation achieve significant\nsuccess when trained and tested on pre-defined closed-world taxonomy. However,\nwhen deployed in the open world, they exhibit notable bias towards seen classes\nand suffer from significant performance drop. In this work, we propose a novel\napproach for open world instance segmentation called bottom-Up and top-Down\nOpen-world Segmentation (UDOS) that combines classical bottom-up segmentation\nalgorithms within a top-down learning framework. UDOS first predicts parts of\nobjects using a top-down network trained with weak supervision from bottom-up\nsegmentations. The bottom-up segmentations are class-agnostic and do not\noverfit to specific taxonomies. The part-masks are then fed into affinity-based\ngrouping and refinement modules to predict robust instance-level segmentations.\nUDOS enjoys both the speed and efficiency from the top-down architectures and\nthe generalization ability to unseen categories from bottom-up supervision. We\nvalidate the strengths of UDOS on multiple cross-category as well as\ncross-dataset transfer tasks from 5 challenging datasets including MS-COCO,\nLVIS, ADE20k, UVO and OpenImages, achieving significant improvements over\nstate-of-the-art across the board. Our code and models are available on our\nproject page.\n","authors":["Tarun Kalluri","Weiyao Wang","Heng Wang","Manmohan Chandraker","Lorenzo Torresani","Du Tran"],"pdf_url":"https://arxiv.org/pdf/2303.05503v1.pdf","comment":"Project page: https://tarun005.github.io/UDOS"},{"id":"http://arxiv.org/abs/2301.03561v2","updated":"2023-03-09T18:55:02Z","published":"2023-01-09T18:21:22Z","title":"Ancilia: Scalable Intelligent Video Surveillance for the Artificial\n  Intelligence of Things","summary":"  With the advancement of vision-based artificial intelligence, the\nproliferation of the Internet of Things connected cameras, and the increasing\nsocietal need for rapid and equitable security, the demand for accurate\nreal-time intelligent surveillance has never been higher. This article presents\nAncilia, an end-to-end scalable, intelligent video surveillance system for the\nArtificial Intelligence of Things. Ancilia brings state-of-the-art artificial\nintelligence to real-world surveillance applications while respecting ethical\nconcerns and performing high-level cognitive tasks in real-time. Ancilia aims\nto revolutionize the surveillance landscape, to bring more effective,\nintelligent, and equitable security to the field, resulting in safer and more\nsecure communities without requiring people to compromise their right to\nprivacy.\n","authors":["Armin Danesh Pazho","Christopher Neff","Ghazal Alinezhad Noghre","Babak Rahimi Ardabili","Shanle Yao","Mohammadreza Baharani","Hamed Tabkhi"],"pdf_url":"https://arxiv.org/pdf/2301.03561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03369v2","updated":"2023-03-09T18:52:25Z","published":"2023-03-06T18:54:46Z","title":"Multimodal Prompting with Missing Modalities for Visual Recognition","summary":"  In this paper, we tackle two challenges in multimodal learning for visual\nrecognition: 1) when missing-modality occurs either during training or testing\nin real-world situations; and 2) when the computation resources are not\navailable to finetune on heavy transformer models. To this end, we propose to\nutilize prompt learning and mitigate the above two challenges together.\nSpecifically, our modality-missing-aware prompts can be plugged into multimodal\ntransformers to handle general missing-modality cases, while only requiring\nless than 1% learnable parameters compared to training the entire model. We\nfurther explore the effect of different prompt configurations and analyze the\nrobustness to missing modality. Extensive experiments are conducted to show the\neffectiveness of our prompt learning framework that improves the performance\nunder various missing-modality cases, while alleviating the requirement of\nheavy model re-training. Code is available.\n","authors":["Yi-Lun Lee","Yi-Hsuan Tsai","Wei-Chen Chiu","Chen-Yu Lee"],"pdf_url":"https://arxiv.org/pdf/2303.03369v2.pdf","comment":"Accepted by CVPR 2023. Codes are available at\n  https://github.com/YiLunLee/Missing_aware_prompts"},{"id":"http://arxiv.org/abs/2303.05499v1","updated":"2023-03-09T18:52:16Z","published":"2023-03-09T18:52:16Z","title":"Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set\n  Object Detection","summary":"  In this paper, we present an open-set object detector, called Grounding DINO,\nby marrying Transformer-based detector DINO with grounded pre-training, which\ncan detect arbitrary objects with human inputs such as category names or\nreferring expressions. The key solution of open-set object detection is\nintroducing language to a closed-set detector for open-set concept\ngeneralization. To effectively fuse language and vision modalities, we\nconceptually divide a closed-set detector into three phases and propose a tight\nfusion solution, which includes a feature enhancer, a language-guided query\nselection, and a cross-modality decoder for cross-modality fusion. While\nprevious works mainly evaluate open-set object detection on novel categories,\nwe propose to also perform evaluations on referring expression comprehension\nfor objects specified with attributes. Grounding DINO performs remarkably well\non all three settings, including benchmarks on COCO, LVIS, ODinW, and\nRefCOCO/+/g. Grounding DINO achieves a $52.5$ AP on the COCO detection\nzero-shot transfer benchmark, i.e., without any training data from COCO. It\nsets a new record on the ODinW zero-shot benchmark with a mean $26.1$ AP. Code\nwill be available at \\url{https://github.com/IDEA-Research/GroundingDINO}.\n","authors":["Shilong Liu","Zhaoyang Zeng","Tianhe Ren","Feng Li","Hao Zhang","Jie Yang","Chunyuan Li","Jianwei Yang","Hang Su","Jun Zhu","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05499v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05498v1","updated":"2023-03-09T18:51:31Z","published":"2023-03-09T18:51:31Z","title":"Mark My Words: Dangers of Watermarked Images in ImageNet","summary":"  The utilization of pre-trained networks, especially those trained on\nImageNet, has become a common practice in Computer Vision. However, prior\nresearch has indicated that a significant number of images in the ImageNet\ndataset contain watermarks, making pre-trained networks susceptible to learning\nartifacts such as watermark patterns within their latent spaces. In this paper,\nwe aim to assess the extent to which popular pre-trained architectures display\nsuch behavior and to determine which classes are most affected. Additionally,\nwe examine the impact of watermarks on the extracted features. Contrary to the\npopular belief that the Chinese logographic watermarks impact the \"carton\"\nclass only, our analysis reveals that a variety of ImageNet classes, such as\n\"monitor\", \"broom\", \"apron\" and \"safe\" rely on spurious correlations. Finally,\nwe propose a simple approach to mitigate this issue in fine-tuned networks by\nignoring the encodings from the feature-extractor layer of ImageNet pre-trained\nnetworks that are most susceptible to watermark imprints.\n","authors":["Kirill Bykov","Klaus-Robert Müller","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2303.05498v1.pdf","comment":"5 pages, 4 figures, Accepted to the ICLR 2023 TrustML-(un)Limited\n  workshop"},{"id":"http://arxiv.org/abs/2212.09258v2","updated":"2023-03-09T18:29:47Z","published":"2022-12-19T06:05:34Z","title":"CHAD: Charlotte Anomaly Dataset","summary":"  In recent years, we have seen a significant interest in data-driven deep\nlearning approaches for video anomaly detection, where an algorithm must\ndetermine if specific frames of a video contain abnormal behaviors. However,\nvideo anomaly detection is particularly context-specific, and the availability\nof representative datasets heavily limits real-world accuracy. Additionally,\nthe metrics currently reported by most state-of-the-art methods often do not\nreflect how well the model will perform in real-world scenarios. In this\narticle, we present the Charlotte Anomaly Dataset (CHAD). CHAD is a\nhigh-resolution, multi-camera anomaly dataset in a commercial parking lot\nsetting. In addition to frame-level anomaly labels, CHAD is the first anomaly\ndataset to include bounding box, identity, and pose annotations for each actor.\nThis is especially beneficial for skeleton-based anomaly detection, which is\nuseful for its lower computational demand in real-world settings. CHAD is also\nthe first anomaly dataset to contain multiple views of the same scene. With\nfour camera views and over 1.15 million frames, CHAD is the largest fully\nannotated anomaly detection dataset including person annotations, collected\nfrom continuous video streams from stationary cameras for smart video\nsurveillance applications. To demonstrate the efficacy of CHAD for training and\nevaluation, we benchmark two state-of-the-art skeleton-based anomaly detection\nalgorithms on CHAD and provide comprehensive analysis, including both\nquantitative results and qualitative examination. The dataset is available at\nhttps://github.com/TeCSAR-UNCC/CHAD.\n","authors":["Armin Danesh Pazho","Ghazal Alinezhad Noghre","Babak Rahimi Ardabili","Christopher Neff","Hamed Tabkhi"],"pdf_url":"https://arxiv.org/pdf/2212.09258v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05475v1","updated":"2023-03-09T18:28:18Z","published":"2023-03-09T18:28:18Z","title":"Mimic before Reconstruct: Enhancing Masked Autoencoders with Feature\n  Mimicking","summary":"  Masked Autoencoders (MAE) have been popular paradigms for large-scale vision\nrepresentation pre-training. However, MAE solely reconstructs the low-level RGB\nsignals after the decoder and lacks supervision upon high-level semantics for\nthe encoder, thus suffering from sub-optimal learned representations and long\npre-training epochs. To alleviate this, previous methods simply replace the\npixel reconstruction targets of 75% masked tokens by encoded features from\npre-trained image-image (DINO) or image-language (CLIP) contrastive learning.\nDifferent from those efforts, we propose to Mimic before Reconstruct for Masked\nAutoencoders, named as MR-MAE, which jointly learns high-level and low-level\nrepresentations without interference during pre-training. For high-level\nsemantics, MR-MAE employs a mimic loss over 25% visible tokens from the encoder\nto capture the pre-trained patterns encoded in CLIP and DINO. For low-level\nstructures, we inherit the reconstruction loss in MAE to predict RGB pixel\nvalues for 75% masked tokens after the decoder. As MR-MAE applies high-level\nand low-level targets respectively at different partitions, the learning\nconflicts between them can be naturally overcome and contribute to superior\nvisual representations for various downstream tasks. On ImageNet-1K, the MR-MAE\nbase pre-trained for only 400 epochs achieves 85.8% top-1 accuracy after\nfine-tuning, surpassing the 1600-epoch MAE base by +2.2% and the previous\nstate-of-the-art BEiT V2 base by +0.3%. Code and pre-trained models will be\nreleased at https://github.com/Alpha-VL/ConvMAE.\n","authors":["Peng Gao","Renrui Zhang","Rongyao Fang","Ziyi Lin","Hongyang Li","Hongsheng Li","Qiao Yu"],"pdf_url":"https://arxiv.org/pdf/2303.05475v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.05470v1","updated":"2023-03-09T18:22:12Z","published":"2023-03-09T18:22:12Z","title":"Spawrious: A Benchmark for Fine Control of Spurious Correlation Biases","summary":"  The problem of spurious correlations (SCs) arises when a classifier relies on\nnon-predictive features that happen to be correlated with the labels in the\ntraining data. For example, a classifier may misclassify dog breeds based on\nthe background of dog images. This happens when the backgrounds are correlated\nwith other breeds in the training data, leading to misclassifications during\ntest time. Previous SC benchmark datasets suffer from varying issues, e.g.,\nover-saturation or only containing one-to-one (O2O) SCs, but no many-to-many\n(M2M) SCs arising between groups of spurious attributes and classes. In this\npaper, we present Spawrious-{O2O, M2M}-{Easy, Medium, Hard}, an image\nclassification benchmark suite containing spurious correlations among different\ndog breeds and background locations. To create this dataset, we employ a\ntext-to-image model to generate photo-realistic images, and an image captioning\nmodel to filter out unsuitable ones. The resulting dataset is of high quality,\ncontaining approximately 152,000 images. Our experimental results demonstrate\nthat state-of-the-art group robustness methods struggle with Spawrious, most\nnotably on the Hard-splits with $<60\\%$ accuracy. By examining model\nmisclassifications, we detect reliances on spurious backgrounds, demonstrating\nthat our dataset provides a significant challenge to drive future research.\n","authors":["Aengus Lynch","Gbètondji J-S Dovonon","Jean Kaddour","Ricardo Silva"],"pdf_url":"https://arxiv.org/pdf/2303.05470v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05463v1","updated":"2023-03-09T18:09:45Z","published":"2023-03-09T18:09:45Z","title":"Understanding the Challenges and Opportunities of Pose-based Anomaly\n  Detection","summary":"  Pose-based anomaly detection is a video-analysis technique for detecting\nanomalous events or behaviors by examining human pose extracted from the video\nframes. Utilizing pose data alleviates privacy and ethical issues. Also,\ncomputation-wise, the complexity of pose-based models is lower than pixel-based\napproaches. However, it introduces more challenges, such as noisy skeleton\ndata, losing important pixel information, and not having enriched enough\nfeatures. These problems are exacerbated by a lack of anomaly detection\ndatasets that are good enough representatives of real-world scenarios. In this\nwork, we analyze and quantify the characteristics of two well-known video\nanomaly datasets to better understand the difficulties of pose-based anomaly\ndetection. We take a step forward, exploring the discriminating power of pose\nand trajectory for video anomaly detection and their effectiveness based on\ncontext. We believe these experiments are beneficial for a better comprehension\nof pose-based anomaly detection and the datasets currently available. This will\naid researchers in tackling the task of anomaly detection with a more lucid\nperspective, accelerating the development of robust models with better\nperformance.\n","authors":["Ghazal Alinezhad Noghre","Armin Danesh Pazho","Vinit Katariya","Hamed Tabkhi"],"pdf_url":"https://arxiv.org/pdf/2303.05463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05459v1","updated":"2023-03-09T18:01:10Z","published":"2023-03-09T18:01:10Z","title":"Presentation Attack Detection with Advanced CNN Models for\n  Noncontact-based Fingerprint Systems","summary":"  Touch-based fingerprint biometrics is one of the most popular biometric\nmodalities with applications in several fields. Problems associated with\ntouch-based techniques such as the presence of latent fingerprints and hygiene\nissues due to many people touching the same surface motivated the community to\nlook for non-contact-based solutions. For the last few years, contactless\nfingerprint systems are on the rise and in demand because of the ability to\nturn any device with a camera into a fingerprint reader. Yet, before we can\nfully utilize the benefit of noncontact-based methods, the biometric community\nneeds to resolve a few concerns such as the resiliency of the system against\npresentation attacks. One of the major obstacles is the limited publicly\navailable data sets with inadequate spoof and live data. In this publication,\nwe have developed a Presentation attack detection (PAD) dataset of more than\n7500 four-finger images and more than 14,000 manually segmented\nsingle-fingertip images, and 10,000 synthetic fingertips (deepfakes). The PAD\ndataset was collected from six different Presentation Attack Instruments (PAI)\nof three different difficulty levels according to FIDO protocols, with five\ndifferent types of PAI materials, and different smartphone cameras with manual\nfocusing. We have utilized DenseNet-121 and NasNetMobile models and our\nproposed dataset to develop PAD algorithms and achieved PAD accuracy of Attack\npresentation classification error rate (APCER) 0.14\\% and Bonafide presentation\nclassification error rate (BPCER) 0.18\\%. We have also reported the test\nresults of the models against unseen spoof types to replicate uncertain\nreal-world testing scenarios.\n","authors":["Sandip Purnapatra","Conor Miller-Lynch","Stephen Miner","Yu Liu","Keivan Bahmani","Soumyabrata Dey","Stephanie Schuckers"],"pdf_url":"https://arxiv.org/pdf/2303.05459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.10276v2","updated":"2023-03-09T17:41:34Z","published":"2022-01-25T12:41:11Z","title":"City3D: Large-Scale Building Reconstruction from Airborne LiDAR Point\n  Clouds","summary":"  We present a fully automatic approach for reconstructing compact 3D building\nmodels from large-scale airborne point clouds. A major challenge of urban\nreconstruction from airborne LiDAR point clouds lies in that the vertical walls\nare typically missing. Based on the observation that urban buildings typically\nconsist of planar roofs connected with vertical walls to the ground, we propose\nan approach to infer the vertical walls directly from the data. With the planar\nsegments of both roofs and walls, we hypothesize the faces of the building\nsurface, and the final model is obtained by using an extended\nhypothesis-and-selection-based polygonal surface reconstruction framework.\nSpecifically, we introduce a new energy term to encourage roof preferences and\ntwo additional hard constraints into the optimization step to ensure correct\ntopology and enhance detail recovery. Experiments on various large-scale\nairborne LiDAR point clouds have demonstrated that the method is superior to\nthe state-of-the-art methods in terms of reconstruction accuracy and\nrobustness. In addition, we have generated a new dataset with our method\nconsisting of the point clouds and 3D models of 20k real-world buildings. We\nbelieve this dataset can stimulate research in urban reconstruction from\nairborne LiDAR point clouds and the use of 3D city models in urban\napplications.\n","authors":["Jin Huang","Jantien Stoter","Ravi Peters","Liangliang Nan"],"pdf_url":"https://arxiv.org/pdf/2201.10276v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05420v1","updated":"2023-03-09T17:11:31Z","published":"2023-03-09T17:11:31Z","title":"Kernel Regression with Infinite-Width Neural Networks on Millions of\n  Examples","summary":"  Neural kernels have drastically increased performance on diverse and\nnonstandard data modalities but require significantly more compute, which\npreviously limited their application to smaller datasets. In this work, we\naddress this by massively parallelizing their computation across many GPUs. We\ncombine this with a distributed, preconditioned conjugate gradients algorithm\nto enable kernel regression at a large scale (i.e. up to five million\nexamples). Using this approach, we study scaling laws of several neural kernels\nacross many orders of magnitude for the CIFAR-5m dataset. Using data\naugmentation to expand the original CIFAR-10 training dataset by a factor of\n20, we obtain a test accuracy of 91.2\\% (SotA for a pure kernel method).\nMoreover, we explore neural kernels on other data modalities, obtaining results\non protein and small molecule prediction tasks that are competitive with SotA\nmethods.\n","authors":["Ben Adlam","Jaehoon Lee","Shreyas Padhy","Zachary Nado","Jasper Snoek"],"pdf_url":"https://arxiv.org/pdf/2303.05420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04001v2","updated":"2023-03-09T17:10:27Z","published":"2023-03-07T16:00:26Z","title":"ELODIN: Naming Concepts in Embedding Spaces","summary":"  Despite recent advancements, the field of text-to-image synthesis still\nsuffers from lack of fine-grained control. Using only text, it remains\nchallenging to deal with issues such as concept coherence and concept\ncontamination. We propose a method to enhance control by generating specific\nconcepts that can be reused throughout multiple images, effectively expanding\nnatural language with new words that can be combined much like a painter's\npalette. Unlike previous contributions, our method does not copy visuals from\ninput data and can generate concepts through text alone. We perform a set of\ncomparisons that finds our method to be a significant improvement over\ntext-only prompts.\n","authors":["Rodrigo Mello","Filipe Calegario","Geber Ramalho"],"pdf_url":"https://arxiv.org/pdf/2303.04001v2.pdf","comment":"Added quantitative data, fixed formatting issues"},{"id":"http://arxiv.org/abs/2212.05561v2","updated":"2023-03-09T17:08:24Z","published":"2022-12-11T18:01:11Z","title":"Using Multiple Instance Learning to Build Multimodal Representations","summary":"  Image-text multimodal representation learning aligns data across modalities\nand enables important medical applications, e.g., image classification, visual\ngrounding, and cross-modal retrieval. In this work, we establish a connection\nbetween multimodal representation learning and multiple instance learning.\nBased on this connection, we propose a generic framework for constructing\npermutation-invariant score functions with many existing multimodal\nrepresentation learning approaches as special cases. Furthermore, we use the\nframework to derive a novel contrastive learning approach and demonstrate that\nour method achieves state-of-the-art results in several downstream tasks.\n","authors":["Peiqi Wang","William M. Wells","Seth Berkowitz","Steven Horng","Polina Golland"],"pdf_url":"https://arxiv.org/pdf/2212.05561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05416v1","updated":"2023-03-09T17:05:19Z","published":"2023-03-09T17:05:19Z","title":"FaceXHuBERT: Text-less Speech-driven E(X)pressive 3D Facial Animation\n  Synthesis Using Self-Supervised Speech Representation Learning","summary":"  This paper presents FaceXHuBERT, a text-less speech-driven 3D facial\nanimation generation method that allows to capture personalized and subtle cues\nin speech (e.g. identity, emotion and hesitation). It is also very robust to\nbackground noise and can handle audio recorded in a variety of situations (e.g.\nmultiple people speaking). Recent approaches employ end-to-end deep learning\ntaking into account both audio and text as input to generate facial animation\nfor the whole face. However, scarcity of publicly available expressive audio-3D\nfacial animation datasets poses a major bottleneck. The resulting animations\nstill have issues regarding accurate lip-synching, expressivity,\nperson-specific information and generalizability. We effectively employ\nself-supervised pretrained HuBERT model in the training process that allows us\nto incorporate both lexical and non-lexical information in the audio without\nusing a large lexicon. Additionally, guiding the training with a binary emotion\ncondition and speaker identity distinguishes the tiniest subtle facial motion.\nWe carried out extensive objective and subjective evaluation in comparison to\nground-truth and state-of-the-art work. A perceptual user study demonstrates\nthat our approach produces superior results with respect to the realism of the\nanimation 78% of the time in comparison to the state-of-the-art. In addition,\nour method is 4 times faster eliminating the use of complex sequential models\nsuch as transformers. We strongly recommend watching the supplementary video\nbefore reading the paper. We also provide the implementation and evaluation\ncodes with a GitHub repository link.\n","authors":["Kazi Injamamul Haque","Zerrin Yumak"],"pdf_url":"https://arxiv.org/pdf/2303.05416v1.pdf","comment":"13 pages, 4 figures, code included"},{"id":"http://arxiv.org/abs/2208.07360v3","updated":"2023-03-09T16:42:28Z","published":"2022-08-15T17:55:26Z","title":"Three New Validators and a Large-Scale Benchmark Ranking for\n  Unsupervised Domain Adaptation","summary":"  Changes to hyperparameters can have a dramatic effect on model accuracy.\nThus, the tuning of hyperparameters plays an important role in optimizing\nmachine-learning models. An integral part of the hyperparameter-tuning process\nis the evaluation of model checkpoints, which is done through the use of\n\"validators\". In a supervised setting, these validators evaluate checkpoints by\ncomputing accuracy on a validation set that has labels. In contrast, in an\nunsupervised setting, the validation set has no such labels. Without any\nlabels, it is impossible to compute accuracy, so validators must estimate\naccuracy instead. But what is the best approach to estimating accuracy? In this\npaper, we consider this question in the context of unsupervised domain\nadaptation (UDA). Specifically, we propose three new validators, and we compare\nand rank them against five other existing validators, on a large dataset of\n1,000,000 checkpoints. Extensive experimental results show that two of our\nproposed validators achieve state-of-the-art performance in various settings.\nFinally, we find that in many cases, the state-of-the-art is obtained by a\nsimple baseline method. To the best of our knowledge, this is the largest\nempirical study of UDA validators to date. Code is available at\nhttps://www.github.com/KevinMusgrave/powerful-benchmarker.\n","authors":["Kevin Musgrave","Serge Belongie","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2208.07360v3.pdf","comment":"This paper was previously titled Benchmarking Validation Methods for\n  Unsupervised Domain Adaptation. This version contains new experiments,\n  analysis, and figures"},{"id":"http://arxiv.org/abs/2205.10120v6","updated":"2023-03-09T16:39:58Z","published":"2022-05-17T14:00:58Z","title":"Privacy Preserving Image Registration","summary":"  Image registration is a key task in medical imaging applications, allowing to\nrepresent medical images in a common spatial reference frame. Current\napproaches to image registration are generally based on the assumption that the\ncontent of the images is usually accessible in clear form, from which the\nspatial transformation is subsequently estimated. This common assumption may\nnot be met in practical applications, since the sensitive nature of medical\nimages may ultimately require their analysis under privacy constraints,\npreventing to openly share the image content.In this work, we formulate the\nproblem of image registration under a privacy preserving regime, where images\nare assumed to be confidential and cannot be disclosed in clear. We derive our\nprivacy preserving image registration framework by extending classical\nregistration paradigms to account for advanced cryptographic tools, such as\nsecure multi-party computation and homomorphic encryption, that enable the\nexecution of operations without leaking the underlying data. To overcome the\nproblem of performance and scalability of cryptographic tools in high\ndimensions, we propose several techniques to optimize the image registration\noperations by using gradient approximations, and by revisiting the use of\nhomomorphic encryption trough packing, to allow the efficient encryption and\nmultiplication of large matrices. We demonstrate our privacy preserving\nframework in linear and non-linear registration problems, evaluating its\naccuracy and scalability with respect to standard, non-private counterparts.\nOur results show that privacy preserving image registration is feasible and can\nbe adopted in sensitive medical imaging applications.\n","authors":["Riccardo Taiello","Melek Önen","Francesco Capano","Olivier Humbert","Marco Lorenzi"],"pdf_url":"https://arxiv.org/pdf/2205.10120v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03709v2","updated":"2023-03-09T16:23:02Z","published":"2023-03-07T07:47:41Z","title":"Bootstrap The Original Latent: Learning a Private Model from a Black-box\n  Model","summary":"  In this paper, considering the balance of data/model privacy of model owners\nand user needs, we propose a new setting called Back-Propagated Black-Box\nAdaptation (BPBA) for users to better train their private models via the\nguidance of the back-propagated results of a Black-box foundation/source model.\nOur setting can ease the usage of foundation/source models as well as prevent\nthe leakage and misuse of foundation/source models. Moreover, we also propose a\nnew training strategy called Bootstrap The Original Latent (BTOL) to fully\nutilize the foundation/source models. Our strategy consists of a domain adapter\nand a freeze-and-thaw strategy. We apply our BTOL under BPBA and Black-box UDA\nsettings on three different datasets. Experiments show that our strategy is\nefficient and robust in various settings without manual augmentations.\n","authors":["Shuai Wang","Daoan Zhang","Jianguo Zhang","Weiwei Zhang","Rui Li"],"pdf_url":"https://arxiv.org/pdf/2303.03709v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.02842v4","updated":"2023-03-09T16:20:21Z","published":"2022-04-06T14:06:43Z","title":"Open-Source Tools for Behavioral Video Analysis: Setup, Methods, and\n  Development","summary":"  Recently developed methods for video analysis, especially models for pose\nestimation and behavior classification, are transforming behavioral\nquantification to be more precise, scalable, and reproducible in fields such as\nneuroscience and ethology. These tools overcome long-standing limitations of\nmanual scoring of video frames and traditional \"center of mass\" tracking\nalgorithms to enable video analysis at scale. The expansion of open-source\ntools for video acquisition and analysis has led to new experimental approaches\nto understand behavior. Here, we review currently available open-source tools\nfor video analysis and discuss how to set up these methods for labs new to\nvideo recording. We also discuss best practices for developing and using video\nanalysis methods, including community-wide standards and critical needs for the\nopen sharing of datasets and code, more widespread comparisons of video\nanalysis methods, and better documentation for these methods especially for new\nusers. We encourage broader adoption and continued development of these tools,\nwhich have tremendous potential for accelerating scientific progress in\nunderstanding the brain and behavior.\n","authors":["Kevin Luxem","Jennifer J. Sun","Sean P. Bradley","Keerthi Krishnan","Eric A. Yttri","Jan Zimmermann","Talmo D. Pereira","Mark Laubach"],"pdf_url":"https://arxiv.org/pdf/2204.02842v4.pdf","comment":"26 pages, 2 figures, 3 tables; this is a commentary on video methods\n  for analyzing behavior in animals that emerged from a working group organized\n  by the OpenBehavior project (openbehavior.com)"},{"id":"http://arxiv.org/abs/2303.05371v1","updated":"2023-03-09T16:18:14Z","published":"2023-03-09T16:18:14Z","title":"3DGen: Triplane Latent Diffusion for Textured Mesh Generation","summary":"  Latent diffusion models for image generation have crossed a quality threshold\nwhich enabled them to achieve mass adoption. Recently, a series of works have\nmade advancements towards replicating this success in the 3D domain,\nintroducing techniques such as point cloud VAE, triplane representation, neural\nimplicit surfaces and differentiable rendering based training. We take another\nstep along this direction, combining these developments in a two-step pipeline\nconsisting of 1) a triplane VAE which can learn latent representations of\ntextured meshes and 2) a conditional diffusion model which generates the\ntriplane features. For the first time this architecture allows conditional and\nunconditional generation of high quality textured or untextured 3D meshes\nacross multiple diverse categories in a few seconds on a single GPU. It\noutperforms previous work substantially on image-conditioned and unconditional\ngeneration on mesh quality as well as texture generation. Furthermore, we\ndemonstrate the scalability of our model to large datasets for increased\nquality and diversity. We will release our code and trained models.\n","authors":["Anchit Gupta","Wenhan Xiong","Yixin Nie","Ian Jones","Barlas Oğuz"],"pdf_url":"https://arxiv.org/pdf/2303.05371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05370v1","updated":"2023-03-09T16:17:52Z","published":"2023-03-09T16:17:52Z","title":"Rethinking Self-Supervised Visual Representation Learning in\n  Pre-training for 3D Human Pose and Shape Estimation","summary":"  Recently, a few self-supervised representation learning (SSL) methods have\noutperformed the ImageNet classification pre-training for vision tasks such as\nobject detection. However, its effects on 3D human body pose and shape\nestimation (3DHPSE) are open to question, whose target is fixed to a unique\nclass, the human, and has an inherent task gap with SSL. We empirically study\nand analyze the effects of SSL and further compare it with other pre-training\nalternatives for 3DHPSE. The alternatives are 2D annotation-based pre-training\nand synthetic data pre-training, which share the motivation of SSL that aims to\nreduce the labeling cost. They have been widely utilized as a source of\nweak-supervision or fine-tuning, but have not been remarked as a pre-training\nsource. SSL methods underperform the conventional ImageNet classification\npre-training on multiple 3DHPSE benchmarks by 7.7% on average. In contrast,\ndespite a much less amount of pre-training data, the 2D annotation-based\npre-training improves accuracy on all benchmarks and shows faster convergence\nduring fine-tuning. Our observations challenge the naive application of the\ncurrent SSL pre-training to 3DHPSE and relight the value of other data types in\nthe pre-training aspect.\n","authors":["Hongsuk Choi","Hyeongjin Nam","Taeryung Lee","Gyeongsik Moon","Kyoung Mu Lee"],"pdf_url":"https://arxiv.org/pdf/2303.05370v1.pdf","comment":"Accepted to ICLR 2023, 18 pages including the appendix"},{"id":"http://arxiv.org/abs/2303.05367v1","updated":"2023-03-09T16:13:27Z","published":"2023-03-09T16:13:27Z","title":"Rethinking Range View Representation for LiDAR Segmentation","summary":"  LiDAR segmentation is crucial for autonomous driving perception. Recent\ntrends favor point- or voxel-based methods as they often yield better\nperformance than the traditional range view representation. In this work, we\nunveil several key factors in building powerful range view models. We observe\nthat the \"many-to-one\" mapping, semantic incoherence, and shape deformation are\npossible impediments against effective learning from range view projections. We\npresent RangeFormer -- a full-cycle framework comprising novel designs across\nnetwork architecture, data augmentation, and post-processing -- that better\nhandles the learning and processing of LiDAR point clouds from the range view.\nWe further introduce a Scalable Training from Range view (STR) strategy that\ntrains on arbitrary low-resolution 2D range images, while still maintaining\nsatisfactory 3D segmentation accuracy. We show that, for the first time, a\nrange view method is able to surpass the point, voxel, and multi-view fusion\ncounterparts in the competing LiDAR semantic and panoptic segmentation\nbenchmarks, i.e., SemanticKITTI, nuScenes, and ScribbleKITTI.\n","authors":["Lingdong Kong","Youquan Liu","Runnan Chen","Yuexin Ma","Xinge Zhu","Yikang Li","Yuenan Hou","Yu Qiao","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2303.05367v1.pdf","comment":"19 pages, 9 figures, 11 tables, project website at\n  https://ldkong.com/RangeFormer"},{"id":"http://arxiv.org/abs/2212.06858v2","updated":"2023-03-09T16:00:00Z","published":"2022-12-13T19:02:35Z","title":"LidarCLIP or: How I Learned to Talk to Point Clouds","summary":"  Research connecting text and images has recently seen several breakthroughs,\nwith models like CLIP, DALL-E 2, and Stable Diffusion. However, the connection\nbetween text and other visual modalities, such as lidar data, has received less\nattention, prohibited by the lack of text-lidar datasets. In this work, we\npropose LidarCLIP, a mapping from automotive point clouds to a pre-existing\nCLIP embedding space. Using image-lidar pairs, we supervise a point cloud\nencoder with the image CLIP embeddings, effectively relating text and lidar\ndata with the image domain as an intermediary. We show the effectiveness of\nLidarCLIP by demonstrating that lidar-based retrieval is generally on par with\nimage-based retrieval, but with complementary strengths and weaknesses. By\ncombining image and lidar features, we improve upon both single-modality\nmethods and enable a targeted search for challenging detection scenarios under\nadverse sensor conditions. We also explore zero-shot classification and show\nthat LidarCLIP outperforms existing attempts to use CLIP for point clouds by a\nlarge margin. Finally, we leverage our compatibility with CLIP to explore a\nrange of applications, such as point cloud captioning and lidar-to-image\ngeneration, without any additional training. Code and pre-trained models are\navailable at https://github.com/atonderski/lidarclip.\n","authors":["Georg Hess","Adam Tonderski","Christoffer Petersson","Kalle Åström","Lennart Svensson"],"pdf_url":"https://arxiv.org/pdf/2212.06858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14416v2","updated":"2023-03-09T15:53:56Z","published":"2023-02-28T08:48:45Z","title":"DREAM: Efficient Dataset Distillation by Representative Matching","summary":"  Dataset distillation aims to synthesize small datasets with little\ninformation loss from original large-scale ones for reducing storage and\ntraining costs. Recent state-of-the-art methods mainly constrain the sample\nsynthesis process by matching synthetic images and the original ones regarding\ngradients, embedding distributions, or training trajectories. Although there\nare various matching objectives, currently the strategy for selecting original\nimages is limited to naive random sampling.\n  We argue that random sampling overlooks the evenness of the selected sample\ndistribution, which may result in noisy or biased matching targets.\n  Besides, the sample diversity is also not constrained by random sampling.\nThese factors together lead to optimization instability in the distilling\nprocess and degrade the training efficiency. Accordingly, we propose a novel\nmatching strategy named as \\textbf{D}ataset distillation by\n\\textbf{RE}present\\textbf{A}tive \\textbf{M}atching (DREAM), where only\nrepresentative original images are selected for matching. DREAM is able to be\neasily plugged into popular dataset distillation frameworks and reduce the\ndistilling iterations by more than 8 times without performance drop. Given\nsufficient training time, DREAM further provides significant improvements and\nachieves state-of-the-art performances.\n","authors":["Yanqing Liu","Jianyang Gu","Kai Wang","Zheng Zhu","Wei Jiang","Yang You"],"pdf_url":"https://arxiv.org/pdf/2302.14416v2.pdf","comment":"Efficient matching for dataset distillation"},{"id":"http://arxiv.org/abs/2303.05342v1","updated":"2023-03-09T15:38:40Z","published":"2023-03-09T15:38:40Z","title":"Knowledge-augmented Few-shot Visual Relation Detection","summary":"  Visual Relation Detection (VRD) aims to detect relationships between objects\nfor image understanding. Most existing VRD methods rely on thousands of\ntraining samples of each relationship to achieve satisfactory performance. Some\nrecent papers tackle this problem by few-shot learning with elaborately\ndesigned pipelines and pre-trained word vectors. However, the performance of\nexisting few-shot VRD models is severely hampered by the poor generalization\ncapability, as they struggle to handle the vast semantic diversity of visual\nrelationships. Nonetheless, humans have the ability to learn new relationships\nwith just few examples based on their knowledge. Inspired by this, we devise a\nknowledge-augmented, few-shot VRD framework leveraging both textual knowledge\nand visual relation knowledge to improve the generalization ability of few-shot\nVRD. The textual knowledge and visual relation knowledge are acquired from a\npre-trained language model and an automatically constructed visual relation\nknowledge graph, respectively. We extensively validate the effectiveness of our\nframework. Experiments conducted on three benchmarks from the commonly used\nVisual Genome dataset show that our performance surpasses existing\nstate-of-the-art models with a large improvement.\n","authors":["Tianyu Yu","Yangning Li","Jiaoyan Chen","Yinghui Li","Hai-Tao Zheng","Xi Chen","Qingbin Liu","Wenqiang Liu","Dongxiao Huang","Bei Wu","Yexin Wang"],"pdf_url":"https://arxiv.org/pdf/2303.05342v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2303.05334v1","updated":"2023-03-09T15:24:26Z","published":"2023-03-09T15:24:26Z","title":"Brain-Diffuser: Natural scene reconstruction from fMRI signals using\n  generative latent diffusion","summary":"  In neural decoding research, one of the most intriguing topics is the\nreconstruction of perceived natural images based on fMRI signals. Previous\nstudies have succeeded in re-creating different aspects of the visuals, such as\nlow-level properties (shape, texture, layout) or high-level features (category\nof objects, descriptive semantics of scenes) but have typically failed to\nreconstruct these properties together for complex scene images. Generative AI\nhas recently made a leap forward with latent diffusion models capable of\ngenerating high-complexity images. Here, we investigate how to take advantage\nof this innovative technology for brain decoding. We present a two-stage scene\nreconstruction framework called ``Brain-Diffuser''. In the first stage,\nstarting from fMRI signals, we reconstruct images that capture low-level\nproperties and overall layout using a VDVAE (Very Deep Variational Autoencoder)\nmodel. In the second stage, we use the image-to-image framework of a latent\ndiffusion model (Versatile Diffusion) conditioned on predicted multimodal (text\nand visual) features, to generate final reconstructed images. On the publicly\navailable Natural Scenes Dataset benchmark, our method outperforms previous\nmodels both qualitatively and quantitatively. When applied to synthetic fMRI\npatterns generated from individual ROI (region-of-interest) masks, our trained\nmodel creates compelling ``ROI-optimal'' scenes consistent with neuroscientific\nknowledge. Thus, the proposed methodology can have an impact on both applied\n(e.g. brain-computer interface) and fundamental neuroscience.\n","authors":["Furkan Ozcelik","Rufin VanRullen"],"pdf_url":"https://arxiv.org/pdf/2303.05334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05331v1","updated":"2023-03-09T15:22:02Z","published":"2023-03-09T15:22:02Z","title":"Adaptive Calibrator Ensemble for Model Calibration under Distribution\n  Shift","summary":"  Model calibration usually requires optimizing some parameters (e.g.,\ntemperature) w.r.t an objective function (e.g., negative log-likelihood). In\nthis paper, we report a plain, important but often neglected fact that the\nobjective function is influenced by calibration set difficulty, i.e., the ratio\nof the number of incorrectly classified samples to that of correctly classified\nsamples. If a test set has a drastically different difficulty level from the\ncalibration set, the optimal calibration parameters of the two datasets would\nbe different. In other words, a calibrator optimal on the calibration set would\nbe suboptimal on the OOD test set and thus has degraded performance. With this\nknowledge, we propose a simple and effective method named adaptive calibrator\nensemble (ACE) to calibrate OOD datasets whose difficulty is usually higher\nthan the calibration set. Specifically, two calibration functions are trained,\none for in-distribution data (low difficulty), and the other for severely OOD\ndata (high difficulty). To achieve desirable calibration on a new OOD dataset,\nACE uses an adaptive weighting method that strikes a balance between the two\nextreme functions. When plugged in, ACE generally improves the performance of a\nfew state-of-the-art calibration schemes on a series of OOD benchmarks.\nImportantly, such improvement does not come at the cost of the in-distribution\ncalibration accuracy.\n","authors":["Yuli Zou","Weijian Deng","Liang Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.05331v1.pdf","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.05329v1","updated":"2023-03-09T15:20:03Z","published":"2023-03-09T15:20:03Z","title":"Tucker Bilinear Attention Network for Multi-scale Remote Sensing Object\n  Detection","summary":"  Object detection on VHR remote sensing images plays a vital role in\napplications such as urban planning, land resource management, and rescue\nmissions. The large-scale variation of the remote-sensing targets is one of the\nmain challenges in VHR remote-sensing object detection. Existing methods\nimprove the detection accuracy of high-resolution remote sensing objects by\nimproving the structure of feature pyramids and adopting different attention\nmodules. However, for small targets, there still be seriously missed detections\ndue to the loss of key detail features. There is still room for improvement in\nthe way of multiscale feature fusion and balance. To address this issue, this\npaper proposes two novel modules: Guided Attention and Tucker Bilinear\nAttention, which are applied to the stages of early fusion and late fusion\nrespectively. The former can effectively retain clean key detail features, and\nthe latter can better balance features through semantic-level correlation\nmining. Based on two modules, we build a new multi-scale remote sensing object\ndetection framework. No bells and whistles. The proposed method largely\nimproves the average precisions of small objects and achieves the highest mean\naverage precisions compared with 9 state-of-the-art methods on DOTA, DIOR, and\nNWPU VHR-10.Code and models are available at\nhttps://github.com/Shinichict/GTNet.\n","authors":["Tao Chen","Ruirui Li","Jiafeng Fu","Daguang Jiang"],"pdf_url":"https://arxiv.org/pdf/2303.05329v1.pdf","comment":"arXiv admin note: text overlap with arXiv:1705.06676,\n  arXiv:2209.13351 by other authors"},{"id":"http://arxiv.org/abs/2207.00531v3","updated":"2023-03-09T15:16:24Z","published":"2022-07-01T16:31:45Z","title":"Masked Autoencoder for Self-Supervised Pre-training on Lidar Point\n  Clouds","summary":"  Masked autoencoding has become a successful pretraining paradigm for\nTransformer models for text, images, and, recently, point clouds. Raw\nautomotive datasets are suitable candidates for self-supervised pre-training as\nthey generally are cheap to collect compared to annotations for tasks like 3D\nobject detection (OD). However, the development of masked autoencoders for\npoint clouds has focused solely on synthetic and indoor data. Consequently,\nexisting methods have tailored their representations and models toward small\nand dense point clouds with homogeneous point densities. In this work, we study\nmasked autoencoding for point clouds in an automotive setting, which are sparse\nand for which the point density can vary drastically among objects in the same\nscene. To this end, we propose Voxel-MAE, a simple masked autoencoding\npre-training scheme designed for voxel representations. We pre-train the\nbackbone of a Transformer-based 3D object detector to reconstruct masked voxels\nand to distinguish between empty and non-empty voxels. Our method improves the\n3D OD performance by 1.75 mAP points and 1.05 NDS on the challenging nuScenes\ndataset. Further, we show that by pre-training with Voxel-MAE, we require only\n40% of the annotated data to outperform a randomly initialized equivalent. Code\navailable at https://github.com/georghess/voxel-mae\n","authors":["Georg Hess","Johan Jaxing","Elias Svensson","David Hagerman","Christoffer Petersson","Lennart Svensson"],"pdf_url":"https://arxiv.org/pdf/2207.00531v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05325v1","updated":"2023-03-09T15:15:55Z","published":"2023-03-09T15:15:55Z","title":"BaDLAD: A Large Multi-Domain Bengali Document Layout Analysis Dataset","summary":"  While strides have been made in deep learning based Bengali Optical Character\nRecognition (OCR) in the past decade, the absence of large Document Layout\nAnalysis (DLA) datasets has hindered the application of OCR in document\ntranscription, e.g., transcribing historical documents and newspapers.\nMoreover, rule-based DLA systems that are currently being employed in practice\nare not robust to domain variations and out-of-distribution layouts. To this\nend, we present the first multidomain large Bengali Document Layout Analysis\nDataset: BaDLAD. This dataset contains 33,695 human annotated document samples\nfrom six domains - i) books and magazines, ii) public domain govt. documents,\niii) liberation war documents, iv) newspapers, v) historical newspapers, and\nvi) property deeds, with 710K polygon annotations for four unit types:\ntext-box, paragraph, image, and table. Through preliminary experiments\nbenchmarking the performance of existing state-of-the-art deep learning\narchitectures for English DLA, we demonstrate the efficacy of our dataset in\ntraining deep learning based Bengali document digitization models.\n","authors":["Md. Istiak Hossain Shihab","Md. Rakibul Hasan","Mahfuzur Rahman Emon","Syed Mobassir Hossen","Md. Nazmuddoha Ansary","Intesur Ahmed","Fazle Rabbi Rakib","Shahriar Elahi Dhruvo","Souhardya Saha Dip","Akib Hasan Pavel","Marsia Haque Meghla","Md. Rezwanul Haque1","Sayma Sultana Chowdhury","Farig Sadeque","Tahsin Reasat","Ahmed Imtiaz Humayun","Asif Shahriyar Sushmit"],"pdf_url":"https://arxiv.org/pdf/2303.05325v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05323v1","updated":"2023-03-09T15:13:51Z","published":"2023-03-09T15:13:51Z","title":"Controllable Video Generation by Learning the Underlying Dynamical\n  System with Neural ODE","summary":"  Videos depict the change of complex dynamical systems over time in the form\nof discrete image sequences. Generating controllable videos by learning the\ndynamical system is an important yet underexplored topic in the computer vision\ncommunity. This paper presents a novel framework, TiV-ODE, to generate highly\ncontrollable videos from a static image and a text caption. Specifically, our\nframework leverages the ability of Neural Ordinary Differential\nEquations~(Neural ODEs) to represent complex dynamical systems as a set of\nnonlinear ordinary differential equations. The resulting framework is capable\nof generating videos with both desired dynamics and content. Experiments\ndemonstrate the ability of the proposed method in generating highly\ncontrollable and visually consistent videos, and its capability of modeling\ndynamical systems. Overall, this work is a significant step towards developing\nadvanced controllable video generation models that can handle complex and\ndynamic scenes.\n","authors":["Yucheng Xu","Nanbo Li","Arushi Goel","Zijian Guo","Zonghai Yao","Hamidreza Kasaei","Mohammadreze Kasaei","Zhibin Li"],"pdf_url":"https://arxiv.org/pdf/2303.05323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05321v1","updated":"2023-03-09T15:13:22Z","published":"2023-03-09T15:13:22Z","title":"WASD: A Wilder Active Speaker Detection Dataset","summary":"  Current Active Speaker Detection (ASD) models achieve great results on\nAVA-ActiveSpeaker (AVA), using only sound and facial features. Although this\napproach is applicable in movie setups (AVA), it is not suited for less\nconstrained conditions. To demonstrate this limitation, we propose a Wilder\nActive Speaker Detection (WASD) dataset, with increased difficulty by targeting\nthe two key components of current ASD: audio and face. Grouped into 5\ncategories, ranging from optimal conditions to surveillance settings, WASD\ncontains incremental challenges for ASD with tactical impairment of audio and\nface data. We select state-of-the-art models and assess their performance in\ntwo groups of WASD: Easy (cooperative settings) and Hard (audio and/or face are\nspecifically degraded). The results show that: 1) AVA trained models maintain a\nstate-of-the-art performance in WASD Easy group, while underperforming in the\nHard one, showing the 2) similarity between AVA and Easy data; and 3) training\nin WASD does not improve models performance to AVA levels, particularly for\naudio impairment and surveillance settings. This shows that AVA does not\nprepare models for wild ASD and current approaches are subpar to deal with such\nconditions. The proposed dataset also contains body data annotations to provide\na new source for ASD, and is available at https://github.com/Tiago-Roxo/WASD.\n","authors":["Tiago Roxo","Joana C. Costa","Pedro R. M. Inácio","Hugo Proença"],"pdf_url":"https://arxiv.org/pdf/2303.05321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05313v1","updated":"2023-03-09T15:01:12Z","published":"2023-03-09T15:01:12Z","title":"Replacement as a Self-supervision for Fine-grained Vision-language\n  Pre-training","summary":"  Fine-grained supervision based on object annotations has been widely used for\nvision and language pre-training (VLP). However, in real-world application\nscenarios, aligned multi-modal data is usually in the image-caption format,\nwhich only provides coarse-grained supervision. It is cost-expensive to collect\nobject annotations and build object annotation pre-extractor for different\nscenarios. In this paper, we propose a fine-grained self-supervision signal\nwithout object annotations from a replacement perspective. First, we propose a\nhomonym sentence rewriting (HSR) algorithm to provide token-level supervision.\nThe algorithm replaces a verb/noun/adjective/quantifier word of the caption\nwith its homonyms from WordNet. Correspondingly, we propose a replacement\nvision-language modeling (RVLM) framework to exploit the token-level\nsupervision. Two replaced modeling tasks, i.e., replaced language contrastive\n(RLC) and replaced language modeling (RLM), are proposed to learn the\nfine-grained alignment. Extensive experiments on several downstream tasks\ndemonstrate the superior performance of the proposed method.\n","authors":["Lisai Zhang","Qingcai Chen","Zhijian Chen","Yunpeng Han","Zhonghua Li","Zhao Cao"],"pdf_url":"https://arxiv.org/pdf/2303.05313v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2303.05312v1","updated":"2023-03-09T15:00:12Z","published":"2023-03-09T15:00:12Z","title":"3D Video Loops from Asynchronous Input","summary":"  Looping videos are short video clips that can be looped endlessly without\nvisible seams or artifacts. They provide a very attractive way to capture the\ndynamism of natural scenes. Existing methods have been mostly limited to 2D\nrepresentations. In this paper, we take a step forward and propose a practical\nsolution that enables an immersive experience on dynamic 3D looping scenes. The\nkey challenge is to consider the per-view looping conditions from asynchronous\ninput while maintaining view consistency for the 3D representation. We propose\na novel sparse 3D video representation, namely Multi-Tile Video (MTV), which\nnot only provides a view-consistent prior, but also greatly reduces memory\nusage, making the optimization of a 4D volume tractable. Then, we introduce a\ntwo-stage pipeline to construct the 3D looping MTV from completely asynchronous\nmulti-view videos with no time overlap. A novel looping loss based on video\ntemporal retargeting algorithms is adopted during the optimization to loop the\n3D scene. Experiments of our framework have shown promise in successfully\ngenerating and rendering photorealistic 3D looping videos in real time even on\nmobile devices. The code, dataset, and live demos are available in\nhttps://limacv.github.io/VideoLoop3D_web/.\n","authors":["Li Ma","Xiaoyu Li","Jing Liao","Pedro V. Sander"],"pdf_url":"https://arxiv.org/pdf/2303.05312v1.pdf","comment":"For more information, please visit the homepage at\n  https://limacv.github.io/VideoLoop3D_web/"},{"id":"http://arxiv.org/abs/2303.05309v1","updated":"2023-03-09T14:58:29Z","published":"2023-03-09T14:58:29Z","title":"MixSpeech: Cross-Modality Self-Learning with Audio-Visual Stream Mixup\n  for Visual Speech Translation and Recognition","summary":"  Multi-media communications facilitate global interaction among people.\nHowever, despite researchers exploring cross-lingual translation techniques\nsuch as machine translation and audio speech translation to overcome language\nbarriers, there is still a shortage of cross-lingual studies on visual speech.\nThis lack of research is mainly due to the absence of datasets containing\nvisual speech and translated text pairs. In this paper, we present\n\\textbf{AVMuST-TED}, the first dataset for \\textbf{A}udio-\\textbf{V}isual\n\\textbf{Mu}ltilingual \\textbf{S}peech \\textbf{T}ranslation, derived from\n\\textbf{TED} talks. Nonetheless, visual speech is not as distinguishable as\naudio speech, making it difficult to develop a mapping from source speech\nphonemes to the target language text. To address this issue, we propose\nMixSpeech, a cross-modality self-learning framework that utilizes audio speech\nto regularize the training of visual speech tasks. To further minimize the\ncross-modality gap and its impact on knowledge transfer, we suggest adopting\nmixed speech, which is created by interpolating audio and visual streams, along\nwith a curriculum learning strategy to adjust the mixing ratio as needed.\nMixSpeech enhances speech translation in noisy environments, improving BLEU\nscores for four languages on AVMuST-TED by +1.4 to +4.2. Moreover, it achieves\nstate-of-the-art performance in lip reading on CMLR (11.1\\%), LRS2 (25.5\\%),\nand LRS3 (28.0\\%).\n","authors":["Xize Cheng","Linjun Li","Tao Jin","Rongjie Huang","Wang Lin","Zehan Wang","Huangdai Liu","Ye Wang","Aoxiong Yin","Zhou Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.05309v1.pdf","comment":"https://github.com/Exgc/AVMuST-TED"},{"id":"http://arxiv.org/abs/2303.05308v1","updated":"2023-03-09T14:58:01Z","published":"2023-03-09T14:58:01Z","title":"SpyroPose: Importance Sampling Pyramids for Object Pose Distribution\n  Estimation in SE(3)","summary":"  Object pose estimation is a core computer vision problem and often an\nessential component in robotics. Pose estimation is usually approached by\nseeking the single best estimate of an object's pose, but this approach is\nill-suited for tasks involving visual ambiguity. In such cases it is desirable\nto estimate the uncertainty as a pose distribution to allow downstream tasks to\nmake informed decisions. Pose distributions can have arbitrary complexity which\nmotivates estimating unparameterized distributions, however, until now they\nhave only been used for orientation estimation on SO(3) due to the difficulty\nin training on and normalizing over SE(3). We propose a novel method for pose\ndistribution estimation on SE(3). We use a hierarchical grid, a pyramid, which\nenables efficient importance sampling during training and sparse evaluation of\nthe pyramid at inference, allowing real time 6D pose distribution estimation.\nOur method outperforms state-of-the-art methods on SO(3), and to the best of\nour knowledge, we provide the first quantitative results on pose distribution\nestimation on SE(3). Code will be available at spyropose.github.io\n","authors":["Rasmus Laurvig Haugaard","Frederik Hagelskjær","Thorbjørn Mosekjær Iversen"],"pdf_url":"https://arxiv.org/pdf/2303.05308v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2303.05305v1","updated":"2023-03-09T14:55:53Z","published":"2023-03-09T14:55:53Z","title":"National-scale 1-m resolution land-cover mapping for the entire China\n  based on a low-cost solution and open-access data","summary":"  Nowadays, many large-scale land-cover (LC) products have been released,\nhowever, current LC products for China either lack a fine resolution or\nnationwide coverage. With the rapid urbanization of China, there is an urgent\nneed for creating a very-high-resolution (VHR) national-scale LC map for China.\nIn this study, a novel 1-m resolution LC map of China covering $9,600,000\nkm^2$, called SinoLC-1, was produced by using a deep learning framework and\nmulti-source open-access data. To efficiently generate the VHR national-scale\nLC map, firstly, the reliable LC labels were collected from three 10-m LC\nproducts and Open Street Map data. Secondly, the collected 10-m labels and 1-m\nGoogle Earth imagery were utilized in the proposed low-to-high (L2H) framework\nfor training. With weak and self-supervised strategies, the L2H framework\nresolves the label noise brought by the mismatched resolution between training\npairs and produces VHR results. Lastly, we compare the SinoLC-1 with five\nwidely used products and validate it with a sample set including 10,6852 points\nand a statistical report collected from the government. The results show the\nSinoLC-1 achieved an OA of 74\\% and a Kappa of 0.65. Moreover, as the first 1-m\nnational-scale LC map for China, the SinoLC-1 shows overall acceptable results\nwith the finest landscape details.\n","authors":["Zhuohong Li","Wei He","Hongyan Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05305v1.pdf","comment":"4 pages, 3 figures, conference paper"},{"id":"http://arxiv.org/abs/2303.05302v1","updated":"2023-03-09T14:54:30Z","published":"2023-03-09T14:54:30Z","title":"M3AE: Multimodal Representation Learning for Brain Tumor Segmentation\n  with Missing Modalities","summary":"  Multimodal magnetic resonance imaging (MRI) provides complementary\ninformation for sub-region analysis of brain tumors. Plenty of methods have\nbeen proposed for automatic brain tumor segmentation using four common MRI\nmodalities and achieved remarkable performance. In practice, however, it is\ncommon to have one or more modalities missing due to image corruption,\nartifacts, acquisition protocols, allergy to contrast agents, or simply cost.\nIn this work, we propose a novel two-stage framework for brain tumor\nsegmentation with missing modalities. In the first stage, a multimodal masked\nautoencoder (M3AE) is proposed, where both random modalities (i.e., modality\ndropout) and random patches of the remaining modalities are masked for a\nreconstruction task, for self-supervised learning of robust multimodal\nrepresentations against missing modalities. To this end, we name our framework\nM3AE. Meanwhile, we employ model inversion to optimize a representative\nfull-modal image at marginal extra cost, which will be used to substitute for\nthe missing modalities and boost performance during inference. Then in the\nsecond stage, a memory-efficient self distillation is proposed to distill\nknowledge between heterogenous missing-modal situations while fine-tuning the\nmodel for supervised segmentation. Our M3AE belongs to the 'catch-all' genre\nwhere a single model can be applied to all possible subsets of modalities, thus\nis economic for both training and deployment. Extensive experiments on BraTS\n2018 and 2020 datasets demonstrate its superior performance to existing\nstate-of-the-art methods with missing modalities, as well as the efficacy of\nits components. Our code is available at: https://github.com/ccarliu/m3ae.\n","authors":["Hong Liu","Dong Wei","Donghuan Lu","Jinghan Sun","Liansheng Wang","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.05302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05297v1","updated":"2023-03-09T14:45:25Z","published":"2023-03-09T14:45:25Z","title":"Perspective Projection-Based 3D CT Reconstruction from Biplanar X-rays","summary":"  X-ray computed tomography (CT) is one of the most common imaging techniques\nused to diagnose various diseases in the medical field. Its high contrast\nsensitivity and spatial resolution allow the physician to observe details of\nbody parts such as bones, soft tissue, blood vessels, etc. As it involves\npotentially harmful radiation exposure to patients and surgeons, however,\nreconstructing 3D CT volume from perpendicular 2D X-ray images is considered a\npromising alternative, thanks to its lower radiation risk and better\naccessibility. This is highly challenging though, since it requires\nreconstruction of 3D anatomical information from 2D images with limited views,\nwhere all the information is overlapped. In this paper, we propose PerX2CT, a\nnovel CT reconstruction framework from X-ray that reflects the perspective\nprojection scheme. Our proposed method provides a different combination of\nfeatures for each coordinate which implicitly allows the model to obtain\ninformation about the 3D location. We reveal the potential to reconstruct the\nselected part of CT with high resolution by properly using the coordinate-wise\nlocal and global features. Our approach shows potential for use in clinical\napplications with low computational complexity and fast inference time,\ndemonstrating superior performance than baselines in multiple evaluation\nmetrics.\n","authors":["Daeun Kyung","Kyungmin Jo","Jaegul Choo","Joonseok Lee","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2303.05297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.08323v2","updated":"2023-03-09T14:32:56Z","published":"2022-09-17T12:59:08Z","title":"RGB-Event Fusion for Moving Object Detection in Autonomous Driving","summary":"  Moving Object Detection (MOD) is a critical vision task for successfully\nachieving safe autonomous driving. Despite plausible results of deep learning\nmethods, most existing approaches are only frame-based and may fail to reach\nreasonable performance when dealing with dynamic traffic participants. Recent\nadvances in sensor technologies, especially the Event camera, can naturally\ncomplement the conventional camera approach to better model moving objects.\nHowever, event-based works often adopt a pre-defined time window for event\nrepresentation, and simply integrate it to estimate image intensities from\nevents, neglecting much of the rich temporal information from the available\nasynchronous events. Therefore, from a new perspective, we propose RENet, a\nnovel RGB-Event fusion Network, that jointly exploits the two complementary\nmodalities to achieve more robust MOD under challenging scenarios for\nautonomous driving. Specifically, we first design a temporal multi-scale\naggregation module to fully leverage event frames from both the RGB exposure\ntime and larger intervals. Then we introduce a bi-directional fusion module to\nattentively calibrate and fuse multi-modal features. To evaluate the\nperformance of our network, we carefully select and annotate a sub-MOD dataset\nfrom the commonly used DSEC dataset. Extensive experiments demonstrate that our\nproposed method performs significantly better than the state-of-the-art\nRGB-Event fusion alternatives. The source code and dataset are publicly\navailable at: https://github.com/ZZY-Zhou/RENet.\n","authors":["Zhuyun Zhou","Zongwei Wu","Rémi Boutteau","Fan Yang","Cédric Demonceaux","Dominique Ginhac"],"pdf_url":"https://arxiv.org/pdf/2209.08323v2.pdf","comment":"ICRA'23"},{"id":"http://arxiv.org/abs/2203.08147v3","updated":"2023-03-09T14:16:03Z","published":"2022-03-14T17:18:10Z","title":"Energy-Latency Attacks via Sponge Poisoning","summary":"  Sponge examples are test-time inputs carefully optimized to increase energy\nconsumption and latency of neural networks when deployed on hardware\naccelerators. In this work, we are the first to demonstrate that sponge\nexamples can also be injected at training time, via an attack that we call\nsponge poisoning. This attack allows one to increase the energy consumption and\nlatency of machine-learning models indiscriminately on each test-time input. We\npresent a novel formalization for sponge poisoning, overcoming the limitations\nrelated to the optimization of test-time sponge examples, and show that this\nattack is possible even if the attacker only controls a few model updates; for\ninstance, if model training is outsourced to an untrusted third-party or\ndistributed via federated learning. Our extensive experimental analysis shows\nthat sponge poisoning can almost completely vanish the effect of hardware\naccelerators. We also analyze the activations of poisoned models, identifying\nwhich components are more vulnerable to this attack. Finally, we examine the\nfeasibility of countermeasures against sponge poisoning to decrease energy\nconsumption, showing that sanitization methods may be overly expensive for most\nof the users.\n","authors":["Antonio Emanuele Cinà","Ambra Demontis","Battista Biggio","Fabio Roli","Marcello Pelillo"],"pdf_url":"https://arxiv.org/pdf/2203.08147v3.pdf","comment":"Preprint;16 pages"},{"id":"http://arxiv.org/abs/2303.05275v1","updated":"2023-03-09T14:14:29Z","published":"2023-03-09T14:14:29Z","title":"Detecting Images Generated by Diffusers","summary":"  This paper explores the task of detecting images generated by text-to-image\ndiffusion models. To evaluate this, we consider images generated from captions\nin the MSCOCO and Wikimedia datasets using two state-of-the-art models: Stable\nDiffusion and GLIDE. Our experiments show that it is possible to detect the\ngenerated images using simple Multi-Layer Perceptrons (MLPs), starting from\nfeatures extracted by CLIP, or traditional Convolutional Neural Networks\n(CNNs). We also observe that models trained on images generated by Stable\nDiffusion can detect images generated by GLIDE relatively well, however, the\nreverse is not true. Lastly, we find that incorporating the associated textual\ninformation with the images rarely leads to significant improvement in\ndetection results but that the type of subject depicted in the image can have a\nsignificant impact on performance. This work provides insights into the\nfeasibility of detecting generated images, and has implications for security\nand privacy concerns in real-world applications.\n","authors":["Davide Alessandro Coccomini","Andrea Esuli","Fabrizio Falchi","Claudio Gennaro","Giuseppe Amato"],"pdf_url":"https://arxiv.org/pdf/2303.05275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05269v1","updated":"2023-03-09T14:03:58Z","published":"2023-03-09T14:03:58Z","title":"Effective Pseudo-Labeling based on Heatmap for Unsupervised Domain\n  Adaptation in Cell Detection","summary":"  Cell detection is an important task in biomedical research. Recently, deep\nlearning methods have made it possible to improve the performance of cell\ndetection. However, a detection network trained with training data under a\nspecific condition (source domain) may not work well on data under other\nconditions (target domains), which is called the domain shift problem. In\nparticular, cells are cultured under different conditions depending on the\npurpose of the research. Characteristics, e.g., the shapes and density of the\ncells, change depending on the conditions, and such changes may cause domain\nshift problems. Here, we propose an unsupervised domain adaptation method for\ncell detection using a pseudo-cell-position heatmap, where the cell centroid is\nat the peak of a Gaussian distribution in the map and selective\npseudo-labeling. In the prediction result for the target domain, even if the\npeak location is correct, the signal distribution around the peak often has a\nnon-Gaussian shape. The pseudo-cell-position heatmap is thus re-generated using\nthe peak positions in the predicted heatmap to have a clear Gaussian shape. Our\nmethod selects confident pseudo-cell-position heatmaps based on uncertainty and\ncurriculum learning. We conducted numerous experiments showing that, compared\nwith the existing methods, our method improved detection performance under\ndifferent conditions.\n","authors":["Hyeonwoo Cho","Kazuya Nishimura","Kazuhide Watanabe","Ryoma Bise"],"pdf_url":"https://arxiv.org/pdf/2303.05269v1.pdf","comment":"16 pages, 18 figures, Accepted in Medical Image Analysis 2022"},{"id":"http://arxiv.org/abs/2303.05266v1","updated":"2023-03-09T13:59:49Z","published":"2023-03-09T13:59:49Z","title":"From Visual Prompt Learning to Zero-Shot Transfer: Mapping Is All You\n  Need","summary":"  Visual prompt learning, as a newly emerged technique, leverages the knowledge\nlearned by a large-scale pre-trained model and adapts it to downstream tasks\nthrough the usage of prompts. While previous research has focused on designing\neffective prompts, in this work, we argue that compared to prompt design, a\ngood mapping strategy matters more. In this sense, we propose SeMap, a more\neffective mapping using the semantic alignment between the pre-trained model's\nknowledge and the downstream task. Our experimental results show that SeMap can\nlargely boost the performance of visual prompt learning. Moreover, our\nexperiments show that SeMap is capable of achieving competitive zero-shot\ntransfer, indicating that it can perform the downstream task without any\nfine-tuning on the corresponding dataset. This demonstrates the potential of\nour proposed method to be used in a broader range of applications where the\nzero-shot transfer is desired. Results suggest that our proposed SeMap could\nlead to significant advancements in both visual prompt learning and zero-shot\ntransfer. We hope with SeMap, we can help the community move forward to more\nefficient and lightweight utilization of large vision models.\n","authors":["Ziqing Yang","Zeyang Sha","Michael Backes","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.05986v2","updated":"2023-03-09T13:51:06Z","published":"2022-04-12T17:52:09Z","title":"Machine Learning Security against Data Poisoning: Are We There Yet?","summary":"  The recent success of machine learning (ML) has been fueled by the increasing\navailability of computing power and large amounts of data in many different\napplications. However, the trustworthiness of the resulting models can be\ncompromised when such data is maliciously manipulated to mislead the learning\nprocess. In this article, we first review poisoning attacks that compromise the\ntraining data used to learn ML models, including attacks that aim to reduce the\noverall performance, manipulate the predictions on specific test samples, and\neven implant backdoors in the model. We then discuss how to mitigate these\nattacks using basic security principles, or by deploying ML-oriented defensive\nmechanisms. We conclude our article by formulating some relevant open\nchallenges which are hindering the development of testing methods and\nbenchmarks suitable for assessing and improving the trustworthiness of ML\nmodels against data poisoning attacks\n","authors":["Antonio Emanuele Cinà","Kathrin Grosse","Ambra Demontis","Battista Biggio","Fabio Roli","Marcello Pelillo"],"pdf_url":"https://arxiv.org/pdf/2204.05986v2.pdf","comment":"preprint, 10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2211.13203v2","updated":"2023-03-09T13:44:11Z","published":"2022-11-23T18:44:25Z","title":"Inversion-Based Style Transfer with Diffusion Models","summary":"  The artistic style within a painting is the means of expression, which\nincludes not only the painting material, colors, and brushstrokes, but also the\nhigh-level attributes including semantic elements, object shapes, etc. Previous\narbitrary example-guided artistic image generation methods often fail to\ncontrol shape changes or convey elements. The pre-trained text-to-image\nsynthesis diffusion probabilistic models have achieved remarkable quality, but\nit often requires extensive textual descriptions to accurately portray\nattributes of a particular painting. We believe that the uniqueness of an\nartwork lies precisely in the fact that it cannot be adequately explained with\nnormal language. Our key idea is to learn artistic style directly from a single\npainting and then guide the synthesis without providing complex textual\ndescriptions. Specifically, we assume style as a learnable textual description\nof a painting. We propose an inversion-based style transfer method (InST),\nwhich can efficiently and accurately learn the key information of an image,\nthus capturing and transferring the artistic style of a painting. We\ndemonstrate the quality and efficiency of our method on numerous paintings of\nvarious artists and styles. Code and models are available at\nhttps://github.com/zyxElsa/InST.\n","authors":["Yuxin Zhang","Nisha Huang","Fan Tang","Haibin Huang","Chongyang Ma","Weiming Dong","Changsheng Xu"],"pdf_url":"https://arxiv.org/pdf/2211.13203v2.pdf","comment":"accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.05251v1","updated":"2023-03-09T13:42:04Z","published":"2023-03-09T13:42:04Z","title":"Masked Image Modeling with Local Multi-Scale Reconstruction","summary":"  Masked Image Modeling (MIM) achieves outstanding success in self-supervised\nrepresentation learning. Unfortunately, MIM models typically have huge\ncomputational burden and slow learning process, which is an inevitable obstacle\nfor their industrial applications. Although the lower layers play the key role\nin MIM, existing MIM models conduct reconstruction task only at the top layer\nof encoder. The lower layers are not explicitly guided and the interaction\namong their patches is only used for calculating new activations. Considering\nthe reconstruction task requires non-trivial inter-patch interactions to reason\ntarget signals, we apply it to multiple local layers including lower and upper\nlayers. Further, since the multiple layers expect to learn the information of\ndifferent scales, we design local multi-scale reconstruction, where the lower\nand upper layers reconstruct fine-scale and coarse-scale supervision signals\nrespectively. This design not only accelerates the representation learning\nprocess by explicitly guiding multiple layers, but also facilitates multi-scale\nsemantical understanding to the input. Extensive experiments show that with\nsignificantly less pre-training burden, our model achieves comparable or better\nperformance on classification, detection and segmentation tasks than existing\nMIM models.\n","authors":["Haoqing Wang","Yehui Tang","Yunhe Wang","Jianyuan Guo","Zhi-Hong Deng","Kai Han"],"pdf_url":"https://arxiv.org/pdf/2303.05251v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.05245v1","updated":"2023-03-09T13:32:18Z","published":"2023-03-09T13:32:18Z","title":"Probabilistic 3d regression with projected huber distribution","summary":"  Estimating probability distributions which describe where an object is likely\nto be from camera data is a task with many applications. In this work we\ndescribe properties which we argue such methods should conform to. We also\ndesign a method which conform to these properties. In our experiments we show\nthat our method produces uncertainties which correlate well with empirical\nerrors. We also show that the mode of the predicted distribution outperform our\nregression baselines. The code for our implementation is available online.\n","authors":["David Mohlin","Josephine Sullivan"],"pdf_url":"https://arxiv.org/pdf/2303.05245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05240v1","updated":"2023-03-09T13:22:50Z","published":"2023-03-09T13:22:50Z","title":"Intriguing Property of GAN for Remote Sensing Image Generation","summary":"  Generative adversarial networks (GANs) have achieved remarkable progress in\nthe natural image field. However, when applying GANs in the remote sensing (RS)\nimage generation task, we discover an extraordinary phenomenon: the GAN model\nis more sensitive to the size of training data for RS image generation than for\nnatural image generation. In other words, the generation quality of RS images\nwill change significantly with the number of training categories or samples per\ncategory. In this paper, we first analyze this phenomenon from two kinds of toy\nexperiments and conclude that the amount of feature information contained in\nthe GAN model decreases with reduced training data. Based on this discovery, we\npropose two innovative adjustment schemes, namely Uniformity Regularization\n(UR) and Entropy Regularization (ER), to increase the information learned by\nthe GAN model at the distributional and sample levels, respectively. We\ntheoretically and empirically demonstrate the effectiveness and versatility of\nour methods. Extensive experiments on the NWPU-RESISC45 and PatternNet datasets\nshow that our methods outperform the well-established models on RS image\ngeneration tasks.\n","authors":["Xingzhe Su","Lingyu Si","Wenwen Qiang","Junzhi Yu","Fengge Wu","Changwen Zheng","Fuchun Sun"],"pdf_url":"https://arxiv.org/pdf/2303.05240v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05234v1","updated":"2023-03-09T13:17:13Z","published":"2023-03-09T13:17:13Z","title":"GPGait: Generalized Pose-based Gait Recognition","summary":"  Recent works on pose-based gait recognition have demonstrated the potential\nof using such simple information to achieve results comparable to\nsilhouette-based methods. However, the generalization ability of pose-based\nmethods on different datasets is undesirably inferior to that of\nsilhouette-based ones, which has received little attention but hinders the\napplication of these methods in real-world scenarios. To improve the\ngeneralization ability of pose-based methods across datasets, we propose a\nGeneralized Pose-based Gait recognition (GPGait) framework. First, a\nHuman-Oriented Transformation (HOT) and a series of Human-Oriented Descriptors\n(HOD) are proposed to obtain a unified pose representation with discriminative\nmulti-features. Then, given the slight variations in the unified representation\nafter HOT and HOD, it becomes crucial for the network to extract local-global\nrelationships between the keypoints. To this end, a Part-Aware Graph\nConvolutional Network (PAGCN) is proposed to enable efficient graph partition\nand local-global spatial feature extraction. Experiments on four public gait\nrecognition datasets, CASIA-B, OUMVLP-Pose, Gait3D and GREW, show that our\nmodel demonstrates better and more stable cross-domain capabilities compared to\nexisting skeleton-based methods, achieving comparable recognition results to\nsilhouette-based ones. The code will be released.\n","authors":["Yang Fu","Shibei Meng","Saihui Hou","Xuecai Hu","Yongzhen Huang"],"pdf_url":"https://arxiv.org/pdf/2303.05234v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.04805v2","updated":"2023-03-09T13:13:07Z","published":"2023-03-08T18:59:39Z","title":"X-Avatar: Expressive Human Avatars","summary":"  We present X-Avatar, a novel avatar model that captures the full\nexpressiveness of digital humans to bring about life-like experiences in\ntelepresence, AR/VR and beyond. Our method models bodies, hands, facial\nexpressions and appearance in a holistic fashion and can be learned from either\nfull 3D scans or RGB-D data. To achieve this, we propose a part-aware learned\nforward skinning module that can be driven by the parameter space of SMPL-X,\nallowing for expressive animation of X-Avatars. To efficiently learn the neural\nshape and deformation fields, we propose novel part-aware sampling and\ninitialization strategies. This leads to higher fidelity results, especially\nfor smaller body parts while maintaining efficient training despite increased\nnumber of articulated bones. To capture the appearance of the avatar with\nhigh-frequency details, we extend the geometry and deformation fields with a\ntexture network that is conditioned on pose, facial expression, geometry and\nthe normals of the deformed surface. We show experimentally that our method\noutperforms strong baselines in both data domains both quantitatively and\nqualitatively on the animation task. To facilitate future research on\nexpressive avatars we contribute a new dataset, called X-Humans, containing 233\nsequences of high-quality textured scans from 20 participants, totalling 35,500\ndata frames.\n","authors":["Kaiyue Shen","Chen Guo","Manuel Kaufmann","Juan Jose Zarate","Julien Valentin","Jie Song","Otmar Hilliges"],"pdf_url":"https://arxiv.org/pdf/2303.04805v2.pdf","comment":"Project page: https://skype-line.github.io/projects/X-Avatar/"},{"id":"http://arxiv.org/abs/2301.01953v3","updated":"2023-03-09T13:08:48Z","published":"2023-01-05T08:21:01Z","title":"Learning Trajectory-Word Alignments for Video-Language Tasks","summary":"  In a video, an object usually appears as the trajectory, i.e., it spans over\na few spatial but longer temporal patches, that contains abundant\nspatiotemporal contexts. However, modern Video-Language BERTs (VDL-BERTs)\nneglect this trajectory characteristic that they usually follow image-language\nBERTs (IL-BERTs) to deploy the patch-to-word (P2W) attention that may\nover-exploit trivial spatial contexts and neglect significant temporal\ncontexts. To amend this, we propose a novel TW-BERT to learn Trajectory-Word\nalignment by a newly designed trajectory-to-word (T2W) attention for solving\nvideo-language tasks. Moreover, previous VDL-BERTs usually uniformly sample a\nfew frames into the model while different trajectories have diverse graininess,\ni.e., some trajectories span longer frames and some span shorter, and using a\nfew frames will lose certain useful temporal contexts. However, simply sampling\nmore frames will also make pre-training infeasible due to the largely increased\ntraining burdens. To alleviate the problem, during the fine-tuning stage, we\ninsert a novel Hierarchical Frame-Selector (HFS) module into the video encoder.\nHFS gradually selects the suitable frames conditioned on the text context for\nthe later cross-modal encoder to learn better trajectory-word alignments. By\nthe proposed T2W attention and HFS, our TW-BERT achieves SOTA performances on\ntext-to-video retrieval tasks, and comparable performances on video\nquestion-answering tasks with some VDL-BERTs trained on much more data. The\ncode will be available in the supplementary material.\n","authors":["Xu Yang","Zhangzikang Li","Haiyang Xu","Hanwang Zhang","Qinghao Ye","Chenliang Li","Ming Yan","Yu Zhang","Fei Huang","Songfang Huang"],"pdf_url":"https://arxiv.org/pdf/2301.01953v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01932v2","updated":"2023-03-09T13:08:22Z","published":"2023-03-03T14:02:50Z","title":"MobileBrick: Building LEGO for 3D Reconstruction on Mobile Devices","summary":"  High-quality 3D ground-truth shapes are critical for 3D object reconstruction\nevaluation. However, it is difficult to create a replica of an object in\nreality, and even 3D reconstructions generated by 3D scanners have artefacts\nthat cause biases in evaluation. To address this issue, we introduce a novel\nmulti-view RGBD dataset captured using a mobile device, which includes highly\nprecise 3D ground-truth annotations for 153 object models featuring a diverse\nset of 3D structures. We obtain precise 3D ground-truth shape without relying\non high-end 3D scanners by utilising LEGO models with known geometry as the 3D\nstructures for image capture. The distinct data modality offered by\nhigh-resolution RGB images and low-resolution depth maps captured on a mobile\ndevice, when combined with precise 3D geometry annotations, presents a unique\nopportunity for future research on high-fidelity 3D reconstruction.\nFurthermore, we evaluate a range of 3D reconstruction algorithms on the\nproposed dataset. Project page: http://code.active.vision/MobileBrick/\n","authors":["Kejie Li","Jia-Wang Bian","Robert Castle","Philip H. S. Torr","Victor Adrian Prisacariu"],"pdf_url":"https://arxiv.org/pdf/2303.01932v2.pdf","comment":"To be appeared at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.02437v2","updated":"2023-03-09T13:03:37Z","published":"2023-03-04T14:59:25Z","title":"ConZIC: Controllable Zero-shot Image Captioning by Sampling-Based\n  Polishing","summary":"  Zero-shot capability has been considered as a new revolution of deep\nlearning, letting machines work on tasks without curated training data. As a\ngood start and the only existing outcome of zero-shot image captioning (IC),\nZeroCap abandons supervised training and sequentially searches every word in\nthe caption using the knowledge of large-scale pretrained models. Though\neffective, its autoregressive generation and gradient-directed searching\nmechanism limit the diversity of captions and inference speed, respectively.\nMoreover, ZeroCap does not consider the controllability issue of zero-shot IC.\nTo move forward, we propose a framework for Controllable Zero-shot IC, named\nConZIC. The core of ConZIC is a novel sampling-based non-autoregressive\nlanguage model named GibbsBERT, which can generate and continuously polish\nevery word. Extensive quantitative and qualitative results demonstrate the\nsuperior performance of our proposed ConZIC for both zero-shot IC and\ncontrollable zero-shot IC. Especially, ConZIC achieves about 5x faster\ngeneration speed than ZeroCap, and about 1.5x higher diversity scores, with\naccurate generation given different control signals.\n","authors":["Zequn Zeng","Hao Zhang","Zhengjue Wang","Ruiying Lu","Dongsheng Wang","Bo Chen"],"pdf_url":"https://arxiv.org/pdf/2303.02437v2.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2303.05225v1","updated":"2023-03-09T13:03:01Z","published":"2023-03-09T13:03:01Z","title":"Active Learning Based Domain Adaptation for Tissue Segmentation of\n  Histopathological Images","summary":"  Accurate segmentation of tissue in histopathological images can be very\nbeneficial for defining regions of interest (ROI) for streamline of diagnostic\nand prognostic tasks. Still, adapting to different domains is essential for\nhistopathology image analysis, as the visual characteristics of tissues can\nvary significantly across datasets. Yet, acquiring sufficient annotated data in\nthe medical domain is cumbersome and time-consuming. The labeling effort can be\nsignificantly reduced by leveraging active learning, which enables the\nselective annotation of the most informative samples. Our proposed method\nallows for fine-tuning a pre-trained deep neural network using a small set of\nlabeled data from the target domain, while also actively selecting the most\ninformative samples to label next. We demonstrate that our approach performs\nwith significantly fewer labeled samples compared to traditional supervised\nlearning approaches for similar F1-scores, using barely a 59\\% of the training\nset. We also investigate the distribution of class balance to establish\nannotation guidelines.\n","authors":["Saul Fuster","Farbod Khoraminia","Trygve Eftestøl","Tahlita C. M. Zuiverloon","Kjersti Engan"],"pdf_url":"https://arxiv.org/pdf/2303.05225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.02228v2","updated":"2023-03-09T12:45:10Z","published":"2023-01-05T18:55:09Z","title":"MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training","summary":"  In this paper, we consider enhancing medical visual-language pre-training\n(VLP) with domain-specific knowledge, by exploiting the paired image-text\nreports from the radiological daily practice. In particular, we make the\nfollowing contributions: First, unlike existing works that directly process the\nraw reports, we adopt a novel triplet extraction module to extract the\nmedical-related information, avoiding unnecessary complexity from language\ngrammar and enhancing the supervision signals; Second, we propose a novel\ntriplet encoding module with entity translation by querying a knowledge base,\nto exploit the rich domain knowledge in medical field, and implicitly build\nrelationships between medical entities in the language embedding space; Third,\nwe propose to use a Transformer-based fusion model for spatially aligning the\nentity description with visual signals at the image patch level, enabling the\nability for medical diagnosis; Fourth, we conduct thorough experiments to\nvalidate the effectiveness of our architecture, and benchmark on numerous\npublic benchmarks, e.g., ChestX-ray14, RSNA Pneumonia, SIIM-ACR Pneumothorax,\nCOVIDx CXR-2, COVID Rural, and EdemaSeverity. In both zero-shot and fine-tuning\nsettings, our model has demonstrated strong performance compared with the\nformer methods on disease classification and grounding.\n","authors":["Chaoyi Wu","Xiaoman Zhang","Ya Zhang","Yanfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2301.02228v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05214v1","updated":"2023-03-09T12:37:33Z","published":"2023-03-09T12:37:33Z","title":"Taming Contrast Maximization for Learning Sequential, Low-latency,\n  Event-based Optical Flow","summary":"  Event cameras have recently gained significant traction since they open up\nnew avenues for low-latency and low-power solutions to complex computer vision\nproblems. To unlock these solutions, it is necessary to develop algorithms that\ncan leverage the unique nature of event data. However, the current\nstate-of-the-art is still highly influenced by the frame-based literature, and\nusually fails to deliver on these promises. In this work, we take this into\nconsideration and propose a novel self-supervised learning pipeline for the\nsequential estimation of event-based optical flow that allows for the scaling\nof the models to high inference frequencies. At its core, we have a\ncontinuously-running stateful neural model that is trained using a novel\nformulation of contrast maximization that makes it robust to nonlinearities and\nvarying statistics in the input events. Results across multiple datasets\nconfirm the effectiveness of our method, which establishes a new state of the\nart in terms of accuracy for approaches trained or optimized without ground\ntruth.\n","authors":["Federico Paredes-Vallés","Kirk Y. W. Scheper","Christophe De Wagter","Guido C. H. E. de Croon"],"pdf_url":"https://arxiv.org/pdf/2303.05214v1.pdf","comment":"15 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2303.02370v2","updated":"2023-03-09T12:33:10Z","published":"2023-03-04T10:14:47Z","title":"Self-Supervised Learning for Place Representation Generalization across\n  Appearance Changes","summary":"  Visual place recognition is a key to unlocking spatial navigation for\nanimals, humans and robots. While state-of-the-art approaches are trained in a\nsupervised manner and therefore hardly capture the information needed for\ngeneralizing to unusual conditions, we argue that self-supervised learning may\nhelp abstracting the place representation so that it can be foreseen,\nirrespective of the conditions. More precisely, in this paper, we investigate\nlearning features that are robust to appearance modifications while sensitive\nto geometric transformations in a self-supervised manner. This dual-purpose\ntraining is made possible by combining the two self-supervision main paradigms,\n\\textit{i.e.} contrastive and predictive learning. Our results on standard\nbenchmarks reveal that jointly learning such appearance-robust and\ngeometry-sensitive image descriptors leads to competitive visual place\nrecognition results across adverse seasonal and illumination conditions,\nwithout requiring any human-annotated labels.\n","authors":["Mohamed Adel Musallam","Vincent Gaudillière","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2303.02370v2.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2211.01234v2","updated":"2023-03-09T12:30:37Z","published":"2022-11-02T16:15:28Z","title":"Uncertainty-Aware DNN for Multi-Modal Camera Localization","summary":"  Camera localization, i.e., camera pose regression, represents an important\ntask in computer vision since it has many practical applications such as in the\ncontext of intelligent vehicles and their localization. Having reliable\nestimates of the regression uncertainties is also important, as it would allow\nus to catch dangerous localization failures. In the literature, uncertainty\nestimation in Deep Neural Networks (DNNs) is often performed through sampling\nmethods, such as Monte Carlo Dropout (MCD) and Deep Ensemble (DE), at the\nexpense of undesirable execution time or an increase in hardware resources. In\nthis work, we considered an uncertainty estimation approach named Deep\nEvidential Regression (DER) that avoids any sampling technique, providing\ndirect uncertainty estimates. Our goal is to provide a systematic approach to\nintercept localization failures of camera localization systems based on DNNs\narchitectures, by analyzing the generated uncertainties. We propose to exploit\nCMRNet, a DNN approach for multi-modal image to LiDAR map registration, by\nmodifying its internal configuration to allow for extensive experimental\nactivity on the KITTI dataset. The experimental section highlights CMRNet's\nmajor flaws and proves that our proposal does not compromise the original\nlocalization performances but also provides, at the same time, the necessary\nintrospection measures that would allow end-users to act accordingly.\n","authors":["Matteo Vaghi","Augusto Luis Ballardini","Simone Fontana","Domenico Giorgio Sorrenti"],"pdf_url":"https://arxiv.org/pdf/2211.01234v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14456v2","updated":"2023-03-09T12:29:26Z","published":"2022-11-26T02:15:35Z","title":"TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud\n  Classification","summary":"  Rotation invariance is an important requirement for the analysis of 3D point\nclouds. In this paper, we present a learnable descriptor for rotation- and\nreflection-invariant 3D point cloud classification based on recently introduced\nsteerable 3D spherical neurons and vector neurons. Specifically, we show that\nthe two approaches are compatible, and we show how to apply steerable neurons\nin an end-to-end method for the first time. In our approach, we perform\nTetraTransform -- which lifts the 3D input to an equivariant 4D representation,\nconstructed by the steerable neurons -- and extract deeper rotation-equivariant\nfeatures using vector neurons, subsequently computing pair-wise O(3)-invariant\ninner products of these features. This integration of the TetraTransform into\nthe VN-DGCNN framework, termed TetraSphere, is used to classify synthetic and\nreal-world data in arbitrary orientations. Taking only 3D coordinates as input,\nTetraSphere sets a new state-of-the-art classification performance on randomly\nrotated objects of the hardest subset of ScanObjectNN, even when trained on\ndata without additional rotation augmentation. Our results reveal the practical\nvalue of spherical decision surfaces for learning in 3D Euclidean space.\n","authors":["Pavlo Melnyk","Andreas Robinson","Mårten Wadenbäck","Michael Felsberg"],"pdf_url":"https://arxiv.org/pdf/2211.14456v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05195v1","updated":"2023-03-09T11:51:20Z","published":"2023-03-09T11:51:20Z","title":"Revisiting Rotation Averaging: Uncertainties and Robust Losses","summary":"  In this paper, we revisit the rotation averaging problem applied in global\nStructure-from-Motion pipelines. We argue that the main problem of current\nmethods is the minimized cost function that is only weakly connected with the\ninput data via the estimated epipolar geometries.We propose to better model the\nunderlying noise distributions by directly propagating the uncertainty from the\npoint correspondences into the rotation averaging. Such uncertainties are\nobtained for free by considering the Jacobians of two-view refinements.\nMoreover, we explore integrating a variant of the MAGSAC loss into the rotation\naveraging problem, instead of using classical robust losses employed in current\nframeworks. The proposed method leads to results superior to baselines, in\nterms of accuracy, on large-scale public benchmarks. The code is public.\nhttps://github.com/zhangganlin/GlobalSfMpy\n","authors":["Ganlin Zhang","Viktor Larsson","Daniel Barath"],"pdf_url":"https://arxiv.org/pdf/2303.05195v1.pdf","comment":"submitted to CVPR2023"},{"id":"http://arxiv.org/abs/2303.05194v1","updated":"2023-03-09T11:48:29Z","published":"2023-03-09T11:48:29Z","title":"Contrastive Model Adaptation for Cross-Condition Robustness in Semantic\n  Segmentation","summary":"  Standard unsupervised domain adaptation methods adapt models from a source to\na target domain using labeled source data and unlabeled target data jointly. In\nmodel adaptation, on the other hand, access to the labeled source data is\nprohibited, i.e., only the source-trained model and unlabeled target data are\navailable. We investigate normal-to-adverse condition model adaptation for\nsemantic segmentation, whereby image-level correspondences are available in the\ntarget domain. The target set consists of unlabeled pairs of adverse- and\nnormal-condition street images taken at GPS-matched locations. Our method --\nCMA -- leverages such image pairs to learn condition-invariant features via\ncontrastive learning. In particular, CMA encourages features in the embedding\nspace to be grouped according to their condition-invariant semantic content and\nnot according to the condition under which respective inputs are captured. To\nobtain accurate cross-domain semantic correspondences, we warp the normal image\nto the viewpoint of the adverse image and leverage warp-confidence scores to\ncreate robust, aggregated features. With this approach, we achieve\nstate-of-the-art semantic segmentation performance for model adaptation on\nseveral normal-to-adverse adaptation benchmarks, such as ACDC and Dark Zurich.\nWe also evaluate CMA on a newly procured adverse-condition generalization\nbenchmark and report favorable results compared to standard unsupervised domain\nadaptation methods, despite the comparative handicap of CMA due to source data\ninaccessibility. Code is available at https://github.com/brdav/cma.\n","authors":["David Bruggemann","Christos Sakaridis","Tim Brödermann","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2303.05194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05192v1","updated":"2023-03-09T11:45:00Z","published":"2023-03-09T11:45:00Z","title":"Virtual Inverse Perspective Mapping for Simultaneous Pose and Motion\n  Estimation","summary":"  We propose an automatic method for pose and motion estimation against a\nground surface for a ground-moving robot-mounted monocular camera. The\nframework adopts a semi-dense approach that benefits from both a feature-based\nmethod and an image-registration-based method by setting multiple patches in\nthe image for displacement computation through a highly accurate\nimage-registration technique. To improve accuracy, we introduce virtual inverse\nperspective mapping (IPM) in the refinement step to eliminate the perspective\neffect on image registration. The pose and motion are jointly and robustly\nestimated by a formulation of geometric bundle adjustment via virtual IPM.\nUnlike conventional visual odometry methods, the proposed method is free from\ncumulative error because it directly estimates pose and motion against the\nground by taking advantage of a camera configuration mounted on a ground-moving\nrobot where the camera's vertical motion is ignorable compared to its height\nwithin the frame interval and the nearby ground surface is approximately flat.\nWe conducted experiments in which the relative mean error of the pitch and roll\nangles was approximately 1.0 degrees and the absolute mean error of the travel\ndistance was 0.3 mm, even under camera shaking within a short period.\n","authors":["Masahiro Hirano","Taku Senoo","Norimasa Kishi","Masatoshi Ishikawa"],"pdf_url":"https://arxiv.org/pdf/2303.05192v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05183v1","updated":"2023-03-09T11:21:59Z","published":"2023-03-09T11:21:59Z","title":"Blind2Sound: Self-Supervised Image Denoising without Residual Noise","summary":"  Self-supervised blind denoising for Poisson-Gaussian noise remains a\nchallenging task. Pseudo-supervised pairs constructed from single noisy images\nre-corrupt the signal and degrade the performance. The visible blindspots solve\nthe information loss in masked inputs. However, without explicitly noise\nsensing, mean square error as an objective function cannot adjust denoising\nintensities for dynamic noise levels, leading to noticeable residual noise. In\nthis paper, we propose Blind2Sound, a simple yet effective approach to overcome\nresidual noise in denoised images. The proposed adaptive re-visible loss senses\nnoise levels and performs personalized denoising without noise residues while\nretaining the signal lossless. The theoretical analysis of intermediate medium\ngradients guarantees stable training, while the Cramer Gaussian loss acts as a\nregularization to facilitate the accurate perception of noise levels and\nimprove the performance of the denoiser. Experiments on synthetic and\nreal-world datasets show the superior performance of our method, especially for\nsingle-channel images.\n","authors":["Zejin Wang","Jiazheng Liu","Jiazheng Liu","Hua Han"],"pdf_url":"https://arxiv.org/pdf/2303.05183v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05180v1","updated":"2023-03-09T11:19:42Z","published":"2023-03-09T11:19:42Z","title":"Classification in Histopathology: A unique deep embeddings extractor for\n  multiple classification tasks","summary":"  In biomedical imaging, deep learning-based methods are state-of-the-art for\nevery modality (virtual slides, MRI, etc.) In histopathology, these methods can\nbe used to detect certain biomarkers or classify lesions. However, such\ntechniques require large amounts of data to train high-performing models which\ncan be intrinsically difficult to acquire, especially when it comes to scarce\nbiomarkers. To address this challenge, we use a single, pre-trained, deep\nembeddings extractor to convert images into deep features and train small,\ndedicated classification head on these embeddings for each classification task.\nThis approach offers several benefits such as the ability to reuse a single\npre-trained deep network for various tasks; reducing the amount of labeled data\nneeded as classification heads have fewer parameters; and accelerating training\ntime by up to 1000 times, which allows for much more tuning of the\nclassification head. In this work, we perform an extensive comparison of\nvarious open-source backbones and assess their fit to the target histological\nimage domain. This is achieved using a novel method based on a proxy\nclassification task. We demonstrate that thanks to this selection method, an\noptimal feature extractor can be selected for different tasks on the target\ndomain. We also introduce a feature space augmentation strategy which proves to\nsubstantially improve the final metrics computed for the different tasks\nconsidered. To demonstrate the benefit of such backbone selection and\nfeature-space augmentation, our experiments are carried out on three separate\nclassification tasks and show a clear improvement on each of them:\nmicrocalcifications (29.1% F1-score increase), lymph nodes metastasis (12.5%\nF1-score increase), mitosis (15.0% F1-score increase).\n","authors":["Adrien Nivaggioli","Nicolas Pozin","Rémy Peyret","Stéphane Sockeel","Marie Sockeel","Nicolas Nerrienet","Marceau Clavel","Clara Simmat","Catherine Miquel"],"pdf_url":"https://arxiv.org/pdf/2303.05180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04238v2","updated":"2023-03-09T11:14:06Z","published":"2023-03-07T21:03:48Z","title":"Patch of Invisibility: Naturalistic Black-Box Adversarial Attacks on\n  Object Detectors","summary":"  Adversarial attacks on deep-learning models have been receiving increased\nattention in recent years. Work in this area has mostly focused on\ngradient-based techniques, so-called white-box attacks, wherein the attacker\nhas access to the targeted model's internal parameters; such an assumption is\nusually unrealistic in the real world. Some attacks additionally use the entire\npixel space to fool a given model, which is neither practical nor physical\n(i.e., real-world). On the contrary, we propose herein a gradient-free method\nthat uses the learned image manifold of a pretrained generative adversarial\nnetwork (GAN) to generate naturalistic physical adversarial patches for object\ndetectors. We show that our proposed method works both digitally and\nphysically.\n","authors":["Raz Lapid","Moshe Sipper"],"pdf_url":"https://arxiv.org/pdf/2303.04238v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09041v2","updated":"2023-03-09T11:09:54Z","published":"2022-11-16T16:58:04Z","title":"Anomaly Detection via Multi-Scale Contrasted Memory","summary":"  Deep anomaly detection (AD) aims to provide robust and efficient classifiers\nfor one-class and unbalanced settings. However current AD models still struggle\non edge-case normal samples and are often unable to keep high performance over\ndifferent scales of anomalies. Moreover, there currently does not exist a\nunified framework efficiently covering both one-class and unbalanced learnings.\nIn the light of these limitations, we introduce a new two-stage anomaly\ndetector which memorizes during training multi-scale normal prototypes to\ncompute an anomaly deviation score. First, we simultaneously learn\nrepresentations and memory modules on multiple scales using a novel\nmemory-augmented contrastive learning. Then, we train an anomaly distance\ndetector on the spatial deviation maps between prototypes and observations. Our\nmodel highly improves the state-of-the-art performance on a wide range of\nobject, style and local anomalies with up to 50% error relative improvement on\nCIFAR-100. It is also the first model to keep high performance across the\none-class and unbalanced settings.\n","authors":["Loic Jezequel","Ngoc-Son Vu","Jean Beaudet","Aymeric Histace"],"pdf_url":"https://arxiv.org/pdf/2211.09041v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05556v4","updated":"2023-03-09T11:04:07Z","published":"2022-10-11T15:50:51Z","title":"ViLPAct: A Benchmark for Compositional Generalization on Multimodal\n  Human Activities","summary":"  We introduce ViLPAct, a novel vision-language benchmark for human activity\nplanning. It is designed for a task where embodied AI agents can reason and\nforecast future actions of humans based on video clips about their initial\nactivities and intents in text. The dataset consists of 2.9k videos from\n\\charades extended with intents via crowdsourcing, a multi-choice question test\nset, and four strong baselines. One of the baselines implements a neurosymbolic\napproach based on a multi-modal knowledge base (MKB), while the other ones are\ndeep generative models adapted from recent state-of-the-art (SOTA) methods.\nAccording to our extensive experiments, the key challenges are compositional\ngeneralization and effective use of information from both modalities.\n","authors":["Terry Yue Zhuo","Yaqing Liao","Yuecheng Lei","Lizhen Qu","Gerard de Melo","Xiaojun Chang","Yazhou Ren","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2210.05556v4.pdf","comment":"Accepted at EACL2023 (Findings)"},{"id":"http://arxiv.org/abs/2303.05171v1","updated":"2023-03-09T11:03:52Z","published":"2023-03-09T11:03:52Z","title":"RiDDLE: Reversible and Diversified De-identification with Latent\n  Encryptor","summary":"  This work presents RiDDLE, short for Reversible and Diversified\nDe-identification with Latent Encryptor, to protect the identity information of\npeople from being misused. Built upon a pre-learned StyleGAN2 generator, RiDDLE\nmanages to encrypt and decrypt the facial identity within the latent space. The\ndesign of RiDDLE has three appealing properties. First, the encryption process\nis cipher-guided and hence allows diverse anonymization using different\npasswords. Second, the true identity can only be decrypted with the correct\npassword, otherwise the system will produce another de-identified face to\nmaintain the privacy. Third, both encryption and decryption share an efficient\nimplementation, benefiting from a carefully tailored lightweight encryptor.\nComparisons with existing alternatives confirm that our approach accomplishes\nthe de-identification task with better quality, higher diversity, and stronger\nreversibility. We further demonstrate the effectiveness of RiDDLE in\nanonymizing videos. Code and models will be made publicly available.\n","authors":["Dongze Li","Wei Wang","Kang Zhao","Jing Dong","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2303.05171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05166v1","updated":"2023-03-09T10:46:23Z","published":"2023-03-09T10:46:23Z","title":"TAEC: Unsupervised Action Segmentation with Temporal-Aware Embedding and\n  Clustering","summary":"  Temporal action segmentation in untrimmed videos has gained increased\nattention recently. However, annotating action classes and frame-wise\nboundaries is extremely time consuming and cost intensive, especially on\nlarge-scale datasets. To address this issue, we propose an unsupervised\napproach for learning action classes from untrimmed video sequences. In\nparticular, we propose a temporal embedding network that combines relative time\nprediction, feature reconstruction, and sequence-to-sequence learning, to\npreserve the spatial layout and sequential nature of the video features. A\ntwo-step clustering pipeline on these embedded feature representations then\nallows us to enforce temporal consistency within, as well as across videos.\nBased on the identified clusters, we decode the video into coherent temporal\nsegments that correspond to semantically meaningful action classes. Our\nevaluation on three challenging datasets shows the impact of each component\nand, furthermore, demonstrates our state-of-the-art unsupervised action\nsegmentation results.\n","authors":["Wei Lin","Anna Kukleva","Horst Possegger","Hilde Kuehne","Horst Bischof"],"pdf_url":"https://arxiv.org/pdf/2303.05166v1.pdf","comment":"Computer Vision Winter Workshop 2023"},{"id":"http://arxiv.org/abs/2303.05164v1","updated":"2023-03-09T10:41:57Z","published":"2023-03-09T10:41:57Z","title":"Reliability-Adaptive Consistency Regularization for Weakly-Supervised\n  Point Cloud Segmentation","summary":"  Weakly-supervised point cloud segmentation with extremely limited labels is\nhighly desirable to alleviate the expensive costs of collecting densely\nannotated 3D points. This paper explores to apply the consistency\nregularization that is commonly used in weakly-supervised learning, for its\npoint cloud counterpart with multiple data-specific augmentations, which has\nnot been well studied. We observe that the straightforward way of applying\nconsistency constraints to weakly-supervised point cloud segmentation has two\nmajor limitations: noisy pseudo labels due to the conventional confidence-based\nselection and insufficient consistency constraints due to discarding unreliable\npseudo labels. Therefore, we propose a novel Reliability-Adaptive Consistency\nNetwork (RAC-Net) to use both prediction confidence and model uncertainty to\nmeasure the reliability of pseudo labels and apply consistency training on all\nunlabeled points while with different consistency constraints for different\npoints based on the reliability of corresponding pseudo labels. Experimental\nresults on the S3DIS and ScanNet-v2 benchmark datasets show that our model\nachieves superior performance in weakly-supervised point cloud segmentation.\nThe code will be released.\n","authors":["Zhonghua Wu","Yicheng Wu","Guosheng Lin","Jianfei Cai"],"pdf_url":"https://arxiv.org/pdf/2303.05164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05162v1","updated":"2023-03-09T10:39:43Z","published":"2023-03-09T10:39:43Z","title":"EVOLIN Benchmark: Evaluation of Line Detection and Association","summary":"  Lines are interesting geometrical features commonly seen in indoor and urban\nenvironments. There is missing a complete benchmark where one can evaluate\nlines from a sequential stream of images in all its stages: Line detection,\nLine Association and Pose error. To do so, we present a complete and exhaustive\nbenchmark for visual lines in a SLAM front-end, both for RGB and RGBD, by\nproviding a plethora of complementary metrics. We have also labelled data from\nwell-known SLAM datasets in order to have all in one poses and accurately\nannotated lines. In particular, we have evaluated 17 line detection algorithms,\n5 line associations methods and the resultant pose error for aligning a pair of\nframes with several combinations of detector-association. We have packaged all\nmethods and evaluations metrics and made them publicly available on web-page\nhttps://prime-slam.github.io/evolin/.\n","authors":["Kirill Ivanov","Gonzalo Ferrer","Anastasiia Kornilova"],"pdf_url":"https://arxiv.org/pdf/2303.05162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05156v1","updated":"2023-03-09T10:20:07Z","published":"2023-03-09T10:20:07Z","title":"Local Implicit Normalizing Flow for Arbitrary-Scale Image\n  Super-Resolution","summary":"  Flow-based methods have demonstrated promising results in addressing the\nill-posed nature of super-resolution (SR) by learning the distribution of\nhigh-resolution (HR) images with the normalizing flow. However, these methods\ncan only perform a predefined fixed-scale SR, limiting their potential in\nreal-world applications. Meanwhile, arbitrary-scale SR has gained more\nattention and achieved great progress. Nonetheless, previous arbitrary-scale SR\nmethods ignore the ill-posed problem and train the model with per-pixel L1\nloss, leading to blurry SR outputs. In this work, we propose \"Local Implicit\nNormalizing Flow\" (LINF) as a unified solution to the above problems. LINF\nmodels the distribution of texture details under different scaling factors with\nnormalizing flow. Thus, LINF can generate photo-realistic HR images with rich\ntexture details in arbitrary scale factors. We evaluate LINF with extensive\nexperiments and show that LINF achieves the state-of-the-art perceptual quality\ncompared with prior arbitrary-scale SR methods.\n","authors":["Jie-En Yao","Li-Yuan Tsao","Yi-Chen Lo","Roy Tseng","Chia-Che Chang","Chun-Yi Lee"],"pdf_url":"https://arxiv.org/pdf/2303.05156v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.05154v1","updated":"2023-03-09T10:14:25Z","published":"2023-03-09T10:14:25Z","title":"3D wind field profiles from hyperspectral sounders: revisiting\n  optic-flow from a meteorological perspective","summary":"  In this work, we present an efficient optic flow algorithm for the extraction\nof vertically resolved 3D atmospheric motion vector (AMV) fields from\nincomplete hyperspectral image data measures by infrared sounders. The model at\nthe heart of the energy to be minimized is consistent with atmospheric\ndynamics, incorporating ingredients of thermodynamics, hydrostatic equilibrium\nand statistical turbulence. Modern optimization techniques are deployed to\ndesign a low-complexity solver for the energy minimization problem, which is\nnon-convex, non-differentiable, high-dimensional and subject to physical\nconstraints. In particular, taking advantage of the alternate direction of\nmultipliers methods (ADMM), we show how to split the original high-dimensional\nproblem into a recursion involving a set of standard and tractable optic-flow\nsub-problems. By comparing with the ground truth provided by the operational\nnumerical simulation of the European Centre for Medium-Range Weather Forecasts\n(ECMWF), we show that the performance of the proposed method is superior to\nstate-of-the-art optical flow algorithms in the context of real infrared\natmospheric sounding interferometer (IASI) observations.\n","authors":["P. Héas","O. Hautecoeur","R. Borde"],"pdf_url":"https://arxiv.org/pdf/2303.05154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13510v2","updated":"2023-03-09T10:08:19Z","published":"2023-01-31T09:54:20Z","title":"3D Former: Monocular Scene Reconstruction with 3D SDF Transformers","summary":"  Monocular scene reconstruction from posed images is challenging due to the\ncomplexity of a large environment. Recent volumetric methods learn to directly\npredict the TSDF volume and have demonstrated promising results in this task.\nHowever, most methods focus on how to extract and fuse the 2D features to a 3D\nfeature volume, but none of them improve the way how the 3D volume is\naggregated. In this work, we propose an SDF transformer network, which replaces\nthe role of 3D CNN for better 3D feature aggregation. To reduce the explosive\ncomputation complexity of the 3D multi-head attention, we propose a sparse\nwindow attention module, where the attention is only calculated between the\nnon-empty voxels within a local window. Then a top-down-bottom-up 3D attention\nnetwork is built for 3D feature aggregation, where a dilate-attention structure\nis proposed to prevent geometry degeneration, and two global modules are\nemployed to equip with global receptive fields. The experiments on multiple\ndatasets show that this 3D transformer network generates a more accurate and\ncomplete reconstruction, which outperforms previous methods by a large margin.\nRemarkably, the mesh accuracy is improved by 41.8%, and the mesh completeness\nis improved by 25.3% on the ScanNet dataset. Project page:\nhttps://weihaosky.github.io/sdfformer.\n","authors":["Weihao Yuan","Xiaodong Gu","Heng Li","Zilong Dong","Siyu Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.13510v2.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2208.08829v2","updated":"2023-03-09T10:05:38Z","published":"2022-08-18T13:46:12Z","title":"Learning Spatial-Frequency Transformer for Visual Object Tracking","summary":"  Recent trackers adopt the Transformer to combine or replace the widely used\nResNet as their new backbone network. Although their trackers work well in\nregular scenarios, however, they simply flatten the 2D features into a sequence\nto better match the Transformer. We believe these operations ignore the spatial\nprior of the target object which may lead to sub-optimal results only. In\naddition, many works demonstrate that self-attention is actually a low-pass\nfilter, which is independent of input features or key/queries. That is to say,\nit may suppress the high-frequency component of the input features and preserve\nor even amplify the low-frequency information. To handle these issues, in this\npaper, we propose a unified Spatial-Frequency Transformer that models the\nGaussian spatial Prior and High-frequency emphasis Attention (GPHA)\nsimultaneously. To be specific, Gaussian spatial prior is generated using dual\nMulti-Layer Perceptrons (MLPs) and injected into the similarity matrix produced\nby multiplying Query and Key features in self-attention. The output will be fed\ninto a Softmax layer and then decomposed into two components, i.e., the direct\nsignal and high-frequency signal. The low- and high-pass branches are rescaled\nand combined to achieve all-pass, therefore, the high-frequency features will\nbe protected well in stacked self-attention layers. We further integrate the\nSpatial-Frequency Transformer into the Siamese tracking framework and propose a\nnovel tracking algorithm, termed SFTransT. The cross-scale fusion based\nSwinTransformer is adopted as the backbone, and also a multi-head\ncross-attention module is used to boost the interaction between search and\ntemplate features. The output will be fed into the tracking head for target\nlocalization. Extensive experiments on both short-term and long-term tracking\nbenchmarks all demonstrate the effectiveness of our proposed framework.\n","authors":["Chuanming Tang","Xiao Wang","Yuanchao Bai","Zhe Wu","Jianlin Zhang","Yongmei Huang"],"pdf_url":"https://arxiv.org/pdf/2208.08829v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05148v1","updated":"2023-03-09T10:03:02Z","published":"2023-03-09T10:03:02Z","title":"Weakly Supervised Knowledge Transfer with Probabilistic Logical\n  Reasoning for Object Detection","summary":"  Training object detection models usually requires instance-level annotations,\nsuch as the positions and labels of all objects present in each image. Such\nsupervision is unfortunately not always available and, more often, only\nimage-level information is provided, also known as weak supervision. Recent\nworks have addressed this limitation by leveraging knowledge from a richly\nannotated domain. However, the scope of weak supervision supported by these\napproaches has been very restrictive, preventing them to use all available\ninformation. In this work, we propose ProbKT, a framework based on\nprobabilistic logical reasoning that allows to train object detection models\nwith arbitrary types of weak supervision. We empirically show on different\ndatasets that using all available information is beneficial as our ProbKT leads\nto significant improvement on target domain and better generalization compared\nto existing baselines. We also showcase the ability of our approach to handle\ncomplex logic statements as supervision signal.\n","authors":["Martijn Oldenhof","Adam Arany","Yves Moreau","Edward De Brouwer"],"pdf_url":"https://arxiv.org/pdf/2303.05148v1.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2212.03185v2","updated":"2023-03-09T09:59:43Z","published":"2022-12-06T17:58:38Z","title":"Rethinking the Objectives of Vector-Quantized Tokenizers for Image\n  Synthesis","summary":"  Vector-Quantized (VQ-based) generative models usually consist of two basic\ncomponents, i.e., VQ tokenizers and generative transformers. Prior research\nfocuses on improving the reconstruction fidelity of VQ tokenizers but rarely\nexamines how the improvement in reconstruction affects the generation ability\nof generative transformers. In this paper, we surprisingly find that improving\nthe reconstruction fidelity of VQ tokenizers does not necessarily improve the\ngeneration. Instead, learning to compress semantic features within VQ\ntokenizers significantly improves generative transformers' ability to capture\ntextures and structures. We thus highlight two competing objectives of VQ\ntokenizers for image synthesis: semantic compression and details preservation.\nDifferent from previous work that only pursues better details preservation, we\npropose Semantic-Quantized GAN (SeQ-GAN) with two learning phases to balance\nthe two objectives. In the first phase, we propose a semantic-enhanced\nperceptual loss for better semantic compression. In the second phase, we fix\nthe encoder and codebook, but enhance and finetune the decoder to achieve\nbetter details preservation. The proposed SeQ-GAN greatly improves VQ-based\ngenerative models and surpasses the GAN and Diffusion Models on both\nunconditional and conditional image generation. Our SeQ-GAN (364M) achieves\nFrechet Inception Distance (FID) of 6.25 and Inception Score (IS) of 140.9 on\n256x256 ImageNet generation, a remarkable improvement over VIT-VQGAN (714M),\nwhich obtains 11.2 FID and 97.2 IS.\n","authors":["Yuchao Gu","Xintao Wang","Yixiao Ge","Ying Shan","Xiaohu Qie","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2212.03185v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.03694v3","updated":"2023-03-09T09:51:34Z","published":"2022-09-08T10:27:53Z","title":"Aerial View Localization with Reinforcement Learning: Towards Emulating\n  Search-and-Rescue","summary":"  Climate-induced disasters are and will continue to be on the rise, and thus\nsearch-and-rescue (SAR) operations, where the task is to localize and assist\none or several people who are missing, become increasingly relevant. In many\ncases the rough location may be known and a UAV can be deployed to explore a\ngiven, confined area to precisely localize the missing people. Due to time and\nbattery constraints it is often critical that localization is performed as\nefficiently as possible. In this work we approach this type of problem by\nabstracting it as an aerial view goal localization task in a framework that\nemulates a SAR-like setup without requiring access to actual UAVs. In this\nframework, an agent operates on top of an aerial image (proxy for a search\narea) and is tasked with localizing a goal that is described in terms of visual\ncues. To further mimic the situation on an actual UAV, the agent is not able to\nobserve the search area in its entirety, not even at low resolution, and thus\nit has to operate solely based on partial glimpses when navigating towards the\ngoal. To tackle this task, we propose AiRLoc, a reinforcement learning\n(RL)-based model that decouples exploration (searching for distant goals) and\nexploitation (localizing nearby goals). Extensive evaluations show that AiRLoc\noutperforms heuristic search methods as well as alternative learnable\napproaches, and that it generalizes across datasets, e.g. to disaster-hit areas\nwithout seeing a single disaster scenario during training. We also conduct a\nproof-of-concept study which indicates that the learnable methods outperform\nhumans on average. Code and models have been made publicly available at\nhttps://github.com/aleksispi/airloc.\n","authors":["Aleksis Pirinen","Anton Samuelsson","John Backsund","Kalle Åström"],"pdf_url":"https://arxiv.org/pdf/2209.03694v3.pdf","comment":"Accepted to ICLR 2023 Workshop on Machine Learning for Remote Sensing"},{"id":"http://arxiv.org/abs/2208.14288v2","updated":"2023-03-09T09:51:27Z","published":"2022-08-30T14:17:15Z","title":"6IMPOSE: Bridging the Reality Gap in 6D Pose Estimation for Robotic\n  Grasping","summary":"  6D pose recognition has been a crucial factor in the success of robotic\ngrasping, and recent deep learning based approaches have achieved remarkable\nresults on benchmarks. However, their generalization capabilities in real-world\napplications remain unclear. To overcome this gap, we introduce 6IMPOSE, a\nnovel framework for sim-to-real data generation and 6D pose estimation. 6IMPOSE\nconsists of four modules: First, a data generation pipeline that employs the 3D\nsoftware suite Blender to create synthetic RGBD image datasets with 6D pose\nannotations. Second, an annotated RGBD dataset of five household objects\ngenerated using the proposed pipeline. Third, a real-time two-stage 6D pose\nestimation approach that integrates the object detector YOLO-V4 and a\nstreamlined, real-time version of the 6D pose estimation algorithm PVN3D\noptimized for time-sensitive robotics applications. Fourth, a codebase designed\nto facilitate the integration of the vision system into a robotic grasping\nexperiment. Our approach demonstrates the efficient generation of large amounts\nof photo-realistic RGBD images and the successful transfer of the trained\ninference model to robotic grasping experiments, achieving an overall success\nrate of 87% in grasping five different household objects from cluttered\nbackgrounds under varying lighting conditions. This is made possible by the\nfine-tuning of data generation and domain randomization techniques, and the\noptimization of the inference pipeline, overcoming the generalization and\nperformance shortcomings of the original PVN3D algorithm. Finally, we make the\ncode, synthetic dataset, and all the pretrained models available on Github.\n","authors":["Hongpeng Cao","Lukas Dirnberger","Daniele Bernardini","Cristina Piazza","Marco Caccamo"],"pdf_url":"https://arxiv.org/pdf/2208.14288v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09565v2","updated":"2023-03-09T09:31:24Z","published":"2022-11-17T14:40:31Z","title":"Towards Good Practices in Evaluating Transfer Adversarial Attacks","summary":"  Transfer adversarial attacks raise critical security concerns in real-world,\nblack-box scenarios. However, the actual progress of this field is difficult to\nassess due to two common limitations in existing evaluations. First, different\nmethods are often not systematically and fairly evaluated in a one-to-one\ncomparison. Second, only transferability is evaluated but another key attack\nproperty, stealthiness, is largely overlooked. In this work, we design good\npractices to address these limitations, and we present the first comprehensive\nevaluation of transfer attacks, covering 23 representative attacks against 9\ndefenses on ImageNet. In particular, we propose to categorize existing attacks\ninto five categories, which enables our systematic category-wise analyses.\nThese analyses lead to new findings that even challenge existing knowledge and\nalso help determine the optimal attack hyperparameters for our attack-wise\ncomprehensive evaluation. We also pay particular attention to stealthiness, by\nadopting diverse imperceptibility metrics and looking into new, finer-grained\ncharacteristics. Overall, our new insights into transferability and\nstealthiness lead to actionable good practices for future evaluations.\n","authors":["Zhengyu Zhao","Hanwei Zhang","Renjue Li","Ronan Sicre","Laurent Amsaleg","Michael Backes"],"pdf_url":"https://arxiv.org/pdf/2211.09565v2.pdf","comment":"Our code and a list of categorized attacks are publicly available at\n  https://github.com/ZhengyuZhao/TransferAttackEval"},{"id":"http://arxiv.org/abs/2303.05130v1","updated":"2023-03-09T09:31:13Z","published":"2023-03-09T09:31:13Z","title":"Blind deblurring of hyperspectral document images","summary":"  Most computer vision and machine learning-based approaches for historical\ndocument analysis are tailored to grayscale or RGB images and thus, mostly\nexploit their spatial information. Multispectral (MS) and hyperspectral (HS)\nimages contain, next to the spatial information, much richer spectral\ninformation than RGB images (usually spreading beyond the visible spectral\nrange) that can facilitate more effective feature extraction, more accurate\nclassification and recognition, and thus, improved analysis. Although\nutilization of rich spectral information can improve historical document\nanalysis tremendously, there are still some potential limitations of HS imagery\nsuch as camera-induced noise and blur that require a carefully designed\npreprocessing step. Here, we propose novel blind HS image deblurring methods\ntailored to document images. We exploit a low-rank property of HS images (i.e.,\nby projecting an HS image to a lower dimensional subspace) and utilize a text\ntailor image prior to performing a PSF estimation and deblurring of subspace\ncomponents. The preliminary results show that the proposed approach gives good\nresults over all spectral bands, removing successfully image artefacts\nintroduced by blur and noise and significantly increasing the number of bands\nthat can be used in further analysis.\n","authors":["M. Ljubenovic","P. Guzzonato","G. Franceschin","A. Traviglia"],"pdf_url":"https://arxiv.org/pdf/2303.05130v1.pdf","comment":"This project has received funding from the European Union's Horizon\n  2020 research and innovation programme under grant agreement No. 101026453.\n  This work is published in the Lecture Notes in Computer Science book series\n  (LNCS, volume 13373) as part of the Image Analysis and Processing, ICIAP 2022\n  Workshops"},{"id":"http://arxiv.org/abs/2301.00122v2","updated":"2023-03-09T09:17:51Z","published":"2022-12-31T04:45:45Z","title":"Hair and Scalp Disease Detection using Machine Learning and Image\n  Processing","summary":"  Almost 80 million Americans suffer from hair loss due to aging, stress,\nmedication, or genetic makeup. Hair and scalp-related diseases often go\nunnoticed in the beginning. Sometimes, a patient cannot differentiate between\nhair loss and regular hair fall. Diagnosing hair-related diseases is\ntime-consuming as it requires professional dermatologists to perform visual and\nmedical tests. Because of that, the overall diagnosis gets delayed, which\nworsens the severity of the illness. Due to the image-processing ability,\nneural network-based applications are used in various sectors, especially\nhealthcare and health informatics, to predict deadly diseases like cancers and\ntumors. These applications assist clinicians and patients and provide an\ninitial insight into early-stage symptoms. In this study, we used a deep\nlearning approach that successfully predicts three main types of hair loss and\nscalp-related diseases: alopecia, psoriasis, and folliculitis. However, limited\nstudy in this area, unavailability of a proper dataset, and degree of variety\namong the images scattered over the internet made the task challenging. 150\nimages were obtained from various sources and then preprocessed by denoising,\nimage equalization, enhancement, and data balancing, thereby minimizing the\nerror rate. After feeding the processed data into the 2D convolutional neural\nnetwork (CNN) model, we obtained overall training accuracy of 96.2%, with a\nvalidation accuracy of 91.1%. The precision and recall score of alopecia,\npsoriasis, and folliculitis are 0.895, 0.846, and 1.0, respectively. We also\ncreated a dataset of the scalp images for future prospective researchers.\n","authors":["Mrinmoy Roy","Anica Tasnim Protity"],"pdf_url":"https://arxiv.org/pdf/2301.00122v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05126v1","updated":"2023-03-09T09:16:39Z","published":"2023-03-09T09:16:39Z","title":"Hybrid Dual Mean-Teacher Network With Double-Uncertainty Guidance for\n  Semi-Supervised Segmentation of MRI Scans","summary":"  Semi-supervised learning has made significant progress in medical image\nsegmentation. However, existing methods primarily utilize information acquired\nfrom a single dimensionality (2D/3D), resulting in sub-optimal performance on\nchallenging data, such as magnetic resonance imaging (MRI) scans with multiple\nobjects and highly anisotropic resolution. To address this issue, we present a\nHybrid Dual Mean-Teacher (HD-Teacher) model with hybrid, semi-supervised, and\nmulti-task learning to achieve highly effective semi-supervised segmentation.\nHD-Teacher employs a 2D and a 3D mean-teacher network to produce segmentation\nlabels and signed distance fields from the hybrid information captured in both\ndimensionalities. This hybrid learning mechanism allows HD-Teacher to combine\nthe `best of both worlds', utilizing features extracted from either 2D, 3D, or\nboth dimensions to produce outputs as it sees fit. Outputs from 2D and 3D\nteacher models are also dynamically combined, based on their individual\nuncertainty scores, into a single hybrid prediction, where the hybrid\nuncertainty is estimated. We then propose a hybrid regularization module to\nencourage both student models to produce results close to the\nuncertainty-weighted hybrid prediction. The hybrid uncertainty suppresses\nunreliable knowledge in the hybrid prediction, leaving only useful information\nto improve network performance further. Extensive experiments of binary and\nmulti-class segmentation conducted on three MRI datasets demonstrate the\neffectiveness of the proposed framework. Code is available at\nhttps://github.com/ThisGame42/Hybrid-Teacher.\n","authors":["Jiayi Zhu","Bart Bolsterlee","Brian V. Y. Chow","Yang Song","Erik Meijering"],"pdf_url":"https://arxiv.org/pdf/2303.05126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05125v1","updated":"2023-03-09T09:16:04Z","published":"2023-03-09T09:16:04Z","title":"Cones: Concept Neurons in Diffusion Models for Customized Generation","summary":"  Human brains respond to semantic features of presented stimuli with different\nneurons. It is then curious whether modern deep neural networks admit a similar\nbehavior pattern. Specifically, this paper finds a small cluster of neurons in\na diffusion model corresponding to a particular subject. We call those neurons\nthe concept neurons. They can be identified by statistics of network gradients\nto a stimulation connected with the given subject. The concept neurons\ndemonstrate magnetic properties in interpreting and manipulating generation\nresults. Shutting them can directly yield the related subject contextualized in\ndifferent scenes. Concatenating multiple clusters of concept neurons can\nvividly generate all related concepts in a single image. A few steps of further\nfine-tuning can enhance the multi-concept capability, which may be the first to\nmanage to generate up to four different subjects in a single image. For\nlarge-scale applications, the concept neurons are environmentally friendly as\nwe only need to store a sparse cluster of int index instead of dense float32\nvalues of the parameters, which reduces storage consumption by 90\\% compared\nwith previous subject-driven generation methods. Extensive qualitative and\nquantitative studies on diverse scenarios show the superiority of our method in\ninterpreting and manipulating diffusion models.\n","authors":["Zhiheng Liu","Ruili Feng","Kai Zhu","Yifei Zhang","Kecheng Zheng","Yu Liu","Deli Zhao","Jingren Zhou","Yang Cao"],"pdf_url":"https://arxiv.org/pdf/2303.05125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.14519v2","updated":"2023-03-09T09:13:47Z","published":"2021-07-30T10:01:52Z","title":"Fourier Series Expansion Based Filter Parametrization for Equivariant\n  Convolutions","summary":"  It has been shown that equivariant convolution is very helpful for many types\nof computer vision tasks. Recently, the 2D filter parametrization technique\nplays an important role when designing equivariant convolutions. However, the\ncurrent filter parametrization method still has its evident drawbacks, where\nthe most critical one lies in the accuracy problem of filter representation.\nAgainst this issue, in this paper we modify the classical Fourier series\nexpansion for 2D filters, and propose a new set of atomic basis functions for\nfilter parametrization. The proposed filter parametrization method not only\nfinely represents 2D filters with zero error when the filter is not rotated,\nbut also substantially alleviates the fence-effect-caused quality degradation\nwhen the filter is rotated. Accordingly, we construct a new equivariant\nconvolution method based on the proposed filter parametrization method, named\nF-Conv. We prove that the equivariance of the proposed F-Conv is exact in the\ncontinuous domain, which becomes approximate only after discretization.\nExtensive experiments show the superiority of the proposed method.\nParticularly, we adopt rotation equivariant convolution methods to image\nsuper-resolution task, and F-Conv evidently outperforms previous filter\nparametrization based method in this task, reflecting its intrinsic capability\nof faithfully preserving rotation symmetries in local image features.\n","authors":["Qi Xie","Qian Zhao","Zongben Xu","Deyu Meng"],"pdf_url":"https://arxiv.org/pdf/2107.14519v2.pdf","comment":"15 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.05123v1","updated":"2023-03-09T09:12:21Z","published":"2023-03-09T09:12:21Z","title":"Dominating Set Database Selection for Visual Place Recognition","summary":"  This paper presents an approach for creating a visual place recognition (VPR)\ndatabase for localization in indoor environments from RGBD scanning sequences.\nThe proposed approach is formulated as a minimization problem in terms of\ndominating set algorithm for graph, constructed from spatial information, and\nreferred as DominatingSet. Our algorithm shows better scene coverage in\ncomparison to other methodologies that are used for database creation. Also, we\ndemonstrate that using DominatingSet, a database size could be up to 250-1400\ntimes smaller than the original scanning sequence while maintaining a recall\nrate of more than 80% on testing sequences. We evaluated our algorithm on\n7-scenes and BundleFusion datasets and an additionally recorded sequence in a\nhighly repetitive office setting. In addition, the database selection can\nproduce weakly-supervised labels for fine-tuning neural place recognition\nalgorithms to particular settings, improving even more their accuracy. The\npaper also presents a fully automated pipeline for VPR database creation from\nRGBD scanning sequences, as well as a set of metrics for VPR database\nevaluation. The code and released data are available on our web-page~ --\nhttps://prime-slam.github.io/place-recognition-db/\n","authors":["Anastasiia Kornilova","Ivan Moskalenko","Timofei Pushkin","Fakhriddin Tojiboev","Rahim Tariverdizadeh","Gonzalo Ferrer"],"pdf_url":"https://arxiv.org/pdf/2303.05123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05122v1","updated":"2023-03-09T09:05:47Z","published":"2023-03-09T09:05:47Z","title":"R-Tuning: Regularized Prompt Tuning in Open-Set Scenarios","summary":"  In realistic open-set scenarios where labels of a part of testing data are\ntotally unknown, current prompt methods on vision-language (VL) models always\npredict the unknown classes as the downstream training classes. The exhibited\nlabel bias causes difficulty in the open set recognition (OSR), by which an\nimage should be correctly predicted as one of the known classes or the unknown\none. To learn prompts in open-set scenarios, we propose the Regularized prompt\nTuning (R-Tuning) to mitigate the label bias. It introduces open words from the\nWordNet to extend the range of words forming the prompt texts from only\nclosed-set label words to more. Thus, prompts are tuned in a simulated open-set\nscenario. Besides, inspired by the observation that classifying directly on\nlarge datasets causes a much higher false positive rate than on small datasets,\nwe propose the Combinatorial Tuning and Testing (CTT) strategy for improving\nperformance. CTT decomposes R-Tuning on large datasets as multiple independent\ngroup-wise tuning on fewer classes, then makes comprehensive predictions by\nselecting the optimal sub-prompt. For fair comparisons, we construct new\nbaselines for OSR based on VL models, especially for prompt methods. Our method\nachieves the best results on datasets with various scales. Extensive ablation\nstudies validate the effectiveness of our method.\n","authors":["Ning Liao","Xiaopeng Zhang","Min Cao","Qi Tian","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2303.05122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05118v1","updated":"2023-03-09T08:57:01Z","published":"2023-03-09T08:57:01Z","title":"SLCA: Slow Learner with Classifier Alignment for Continual Learning on a\n  Pre-trained Model","summary":"  The goal of continual learning is to improve the performance of recognition\nmodels in learning sequentially arrived data. Although most existing works are\nestablished on the premise of learning from scratch, growing efforts have been\ndevoted to incorporating the benefits of pre-training. However, how to\nadaptively exploit the pre-trained knowledge for each incremental task while\nmaintaining its generalizability remains an open question. In this work, we\npresent an extensive analysis for continual learning on a pre-trained model\n(CLPM), and attribute the key challenge to a progressive overfitting problem.\nObserving that selectively reducing the learning rate can almost resolve this\nissue in the representation layer, we propose a simple but extremely effective\napproach named Slow Learner with Classifier Alignment (SLCA), which further\nimproves the classification layer by modeling the class-wise distributions and\naligning the classification layers in a post-hoc fashion. Across a variety of\nscenarios, our proposal provides substantial improvements for CLPM (e.g., up to\n49.76%, 50.05%, 44.69% and 40.16% on Split CIFAR-100, Split ImageNet-R, Split\nCUB-200 and Split Cars-196, respectively), and thus outperforms\nstate-of-the-art approaches by a large margin. Based on such a strong baseline,\ncritical factors and promising directions are analyzed in-depth to facilitate\nsubsequent research.\n","authors":["Gengwei Zhang","Liyuan Wang","Guoliang Kang","Ling Chen","Yunchao Wei"],"pdf_url":"https://arxiv.org/pdf/2303.05118v1.pdf","comment":"Tech report. 11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.13136v2","updated":"2023-03-09T08:55:01Z","published":"2022-12-26T12:49:47Z","title":"Fewer is More: Efficient Object Detection in Large Aerial Images","summary":"  Current mainstream object detection methods for large aerial images usually\ndivide large images into patches and then exhaustively detect the objects of\ninterest on all patches, no matter whether there exist objects or not. This\nparadigm, although effective, is inefficient because the detectors have to go\nthrough all patches, severely hindering the inference speed. This paper\npresents an Objectness Activation Network (OAN) to help detectors focus on\nfewer patches but achieve more efficient inference and more accurate results,\nenabling a simple and effective solution to object detection in large images.\nIn brief, OAN is a light fully-convolutional network for judging whether each\npatch contains objects or not, which can be easily integrated into many object\ndetectors and jointly trained with them end-to-end. We extensively evaluate our\nOAN with five advanced detectors. Using OAN, all five detectors acquire more\nthan 30.0% speed-up on three large-scale aerial image datasets, meanwhile with\nconsistent accuracy improvements. On extremely large Gaofen-2 images\n(29200$\\times$27620 pixels), our OAN improves the detection speed by 70.5%.\nMoreover, we extend our OAN to driving-scene object detection and 4K video\nobject detection, boosting the detection speed by 112.1% and 75.0%,\nrespectively, without sacrificing the accuracy. Code is available at\nhttps://github.com/Ranchosky/OAN.\n","authors":["Xingxing Xie","Gong Cheng","Qingyang Li","Shicheng Miao","Ke Li","Junwei Han"],"pdf_url":"https://arxiv.org/pdf/2212.13136v2.pdf","comment":"This manuscript is the accepted version for SCIENCE CHINA Information\n  Sciences"},{"id":"http://arxiv.org/abs/2303.05116v1","updated":"2023-03-09T08:43:06Z","published":"2023-03-09T08:43:06Z","title":"Multi-level Memory-augmented Appearance-Motion Correspondence Framework\n  for Video Anomaly Detection","summary":"  Frame prediction based on AutoEncoder plays a significant role in\nunsupervised video anomaly detection. Ideally, the models trained on the normal\ndata could generate larger prediction errors of anomalies. However, the\ncorrelation between appearance and motion information is underutilized, which\nmakes the models lack an understanding of normal patterns. Moreover, the models\ndo not work well due to the uncontrollable generalizability of deep\nAutoEncoder. To tackle these problems, we propose a multi-level\nmemory-augmented appearance-motion correspondence framework. The latent\ncorrespondence between appearance and motion is explored via appearance-motion\nsemantics alignment and semantics replacement training. Besides, we also\nintroduce a Memory-Guided Suppression Module, which utilizes the difference\nfrom normal prototype features to suppress the reconstruction capacity caused\nby skip-connection, achieving the tradeoff between the good reconstruction of\nnormal data and the poor reconstruction of abnormal data. Experimental results\nshow that our framework outperforms the state-of-the-art methods, achieving\nAUCs of 99.6\\%, 93.8\\%, and 76.3\\% on UCSD Ped2, CUHK Avenue, and ShanghaiTech\ndatasets.\n","authors":["Xiangyu Huang","Caidan Zhao","Jinghui Yu","Chenxing Gao","Zhiqiang Wu"],"pdf_url":"https://arxiv.org/pdf/2303.05116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05113v1","updated":"2023-03-09T08:34:21Z","published":"2023-03-09T08:34:21Z","title":"Segmentation method for cerebral blood vessels from MRA using hysteresis","summary":"  Segmentation of cerebral blood vessels from Magnetic Resonance Imaging (MRI)\nis an open problem that could be solved with deep learning (DL). However,\nannotated data for training is often scarce. Due to the absence of open-source\ntools, we aim to develop a classical segmentation method that generates vessel\nground truth from Magnetic Resonance Angiography for DL training of\nsegmentation across a variety of modalities. The method combines size-specific\nHessian filters, hysteresis thresholding and connected component correction.\nThe optimal choice of processing steps was evaluated with a blinded scoring by\na clinician using 24 3D images. The results show that all method steps are\nnecessary to produce the highest (14.2/15) vessel segmentation quality score.\nOmitting the connected component correction caused the largest quality loss.\nThe method, which is available on GitHub, can be used to train DL models for\nvessel segmentation.\n","authors":["Georgia Kenyon","Stephan Lau","Michael A. Chappell","Mark Jenkinson"],"pdf_url":"https://arxiv.org/pdf/2303.05113v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05112v1","updated":"2023-03-09T08:33:38Z","published":"2023-03-09T08:33:38Z","title":"Synthetic Pseudo Anomalies for Unsupervised Video Anomaly Detection: A\n  Simple yet Efficient Framework based on Masked Autoencoder","summary":"  Due to the limited availability of anomalous samples for training, video\nanomaly detection is commonly viewed as a one-class classification problem.\nMany prevalent methods investigate the reconstruction difference produced by\nAutoEncoders (AEs) under the assumption that the AEs would reconstruct the\nnormal data well while reconstructing anomalies poorly. However, even with only\nnormal data training, the AEs often reconstruct anomalies well, which depletes\ntheir anomaly detection performance. To alleviate this issue, we propose a\nsimple yet efficient framework for video anomaly detection. The pseudo anomaly\nsamples are introduced, which are synthesized from only normal data by\nembedding random mask tokens without extra data processing. We also propose a\nnormalcy consistency training strategy that encourages the AEs to better learn\nthe regular knowledge from normal and corresponding pseudo anomaly data. This\nway, the AEs learn more distinct reconstruction boundaries between normal and\nabnormal data, resulting in superior anomaly discrimination capability.\nExperimental results demonstrate the effectiveness of the proposed method.\n","authors":["Xiangyu Huang","Caidan Zhao","Chenxing Gao","Lvdong Chen","Zhiqiang Wu"],"pdf_url":"https://arxiv.org/pdf/2303.05112v1.pdf","comment":"Accepted to ICASSP2023"},{"id":"http://arxiv.org/abs/2303.05110v1","updated":"2023-03-09T08:32:14Z","published":"2023-03-09T08:32:14Z","title":"Retinal Image Segmentation with Small Datasets","summary":"  Many eye diseases like Diabetic Macular Edema (DME), Age-related Macular\nDegeneration (AMD), and Glaucoma manifest in the retina, can cause irreversible\nblindness or severely impair the central version. The Optical Coherence\nTomography (OCT), a 3D scan of the retina with high qualitative information\nabout the retinal morphology, can be used to diagnose and monitor changes in\nthe retinal anatomy. Many Deep Learning (DL) methods have shared the success of\ndeveloping an automated tool to monitor pathological changes in the retina.\nHowever, the success of these methods depend mainly on large datasets. To\naddress the challenge from very small and limited datasets, we proposed a DL\narchitecture termed CoNet (Coherent Network) for joint segmentation of layers\nand fluids in retinal OCT images on very small datasets (less than a hundred\ntraining samples). The proposed model was evaluated on the publicly available\nDuke DME dataset consisting of 110 B-Scans from 10 patients suffering from DME.\nExperimental results show that the proposed model outperformed both the human\nexperts' annotation and the current state-of-the-art architectures by a clear\nmargin with a mean Dice Score of 88% when trained on 55 images without any data\naugmentation.\n","authors":["Nchongmaje Ndipenoch","Alina Miron","Zidong Wang","Yongmin Li"],"pdf_url":"https://arxiv.org/pdf/2303.05110v1.pdf","comment":"Submitted to Bioimaging 2023"},{"id":"http://arxiv.org/abs/2303.05109v1","updated":"2023-03-09T08:28:34Z","published":"2023-03-09T08:28:34Z","title":"Updated version: A Video Anomaly Detection Framework based on\n  Appearance-Motion Semantics Representation Consistency","summary":"  Video anomaly detection is an essential but challenging task. The prevalent\nmethods mainly investigate the reconstruction difference between normal and\nabnormal patterns but ignore the semantics consistency between appearance and\nmotion information of behavior patterns, making the results highly dependent on\nthe local context of frame sequences and lacking the understanding of behavior\nsemantics. To address this issue, we propose a framework of Appearance-Motion\nSemantics Representation Consistency that uses the gap of appearance and motion\nsemantic representation consistency between normal and abnormal data. The\ntwo-stream structure is designed to encode the appearance and motion\ninformation representation of normal samples, and a novel consistency loss is\nproposed to enhance the consistency of feature semantics so that anomalies with\nlow consistency can be identified. Moreover, the lower consistency features of\nanomalies can be used to deteriorate the quality of the predicted frame, which\nmakes anomalies easier to spot. Experimental results demonstrate the\neffectiveness of the proposed method.\n","authors":["Xiangyu Huang","Caidan Zhao","Zhiqiang Wu"],"pdf_url":"https://arxiv.org/pdf/2303.05109v1.pdf","comment":"Accepted to ICASSP2023. arXiv admin note: substantial text overlap\n  with arXiv:2204.04151"},{"id":"http://arxiv.org/abs/2303.05105v1","updated":"2023-03-09T08:24:02Z","published":"2023-03-09T08:24:02Z","title":"MaskDiff: Modeling Mask Distribution with Diffusion Probabilistic Model\n  for Few-Shot Instance Segmentation","summary":"  Few-shot instance segmentation extends the few-shot learning paradigm to the\ninstance segmentation task, which tries to segment instance objects from a\nquery image with a few annotated examples of novel categories. Conventional\napproaches have attempted to address the task via prototype learning, known as\npoint estimation. However, this mechanism is susceptible to noise and suffers\nfrom bias due to a significant scarcity of data. To overcome the disadvantages\nof the point estimation mechanism, we propose a novel approach, dubbed\nMaskDiff, which models the underlying conditional distribution of a binary\nmask, which is conditioned on an object region and $K$-shot information.\nInspired by augmentation approaches that perturb data with Gaussian noise for\npopulating low data density regions, we model the mask distribution with a\ndiffusion probabilistic model. In addition, we propose to utilize\nclassifier-free guided mask sampling to integrate category information into the\nbinary mask generation process. Without bells and whistles, our proposed method\nconsistently outperforms state-of-the-art methods on both base and novel\nclasses of the COCO dataset while simultaneously being more stable than\nexisting methods.\n","authors":["Minh-Quan Le","Tam V. Nguyen","Trung-Nghia Le","Thanh-Toan Do","Minh N. Do","Minh-Triet Tran"],"pdf_url":"https://arxiv.org/pdf/2303.05105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05361v3","updated":"2023-03-09T08:22:29Z","published":"2022-10-09T11:10:59Z","title":"Uncertainty-Aware Unsupervised Image Deblurring with Deep Residual Prior","summary":"  Non-blind deblurring methods achieve decent performance under the accurate\nblur kernel assumption. Since the kernel uncertainty (i.e. kernel error) is\ninevitable in practice, semi-blind deblurring is suggested to handle it by\nintroducing the prior of the kernel (or induced) error. However, how to design\na suitable prior for the kernel (or induced) error remains challenging.\nHand-crafted prior, incorporating domain knowledge, generally performs well but\nmay lead to poor performance when kernel (or induced) error is complex.\nData-driven prior, which excessively depends on the diversity and abundance of\ntraining data, is vulnerable to out-of-distribution blurs and images. To\naddress this challenge, we suggest a dataset-free deep residual prior for the\nkernel induced error (termed as residual) expressed by a customized untrained\ndeep neural network, which allows us to flexibly adapt to different blurs and\nimages in real scenarios. By organically integrating the respective strengths\nof deep priors and hand-crafted priors, we propose an unsupervised semi-blind\ndeblurring model which recovers the latent image from the blurry image and\ninaccurate blur kernel. To tackle the formulated model, an efficient\nalternating minimization algorithm is developed. Extensive experiments\ndemonstrate the favorable performance of the proposed method as compared to\ndata-driven and model-driven methods in terms of image quality and the\nrobustness to the kernel error.\n","authors":["Xiaole Tang","Xile Zhao","Jun Liu","Jianli Wang","Yuchun Miao","Tieyong Zeng"],"pdf_url":"https://arxiv.org/pdf/2210.05361v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05102v1","updated":"2023-03-09T08:21:50Z","published":"2023-03-09T08:21:50Z","title":"StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent\n  Disentangled Space","summary":"  One major challenge in machine learning applications is coping with\nmismatches between the datasets used in the development and those obtained in\nreal-world applications. These mismatches may lead to inaccurate predictions\nand errors, resulting in poor product quality and unreliable systems. In this\nstudy, we propose StyleDiff to inform developers of the differences between the\ntwo datasets for the steady development of machine learning systems. Using\ndisentangled image spaces obtained from recently proposed generative models,\nStyleDiff compares the two datasets by focusing on attributes in the images and\nprovides an easy-to-understand analysis of the differences between the\ndatasets. The proposed StyleDiff performs in $O (d N\\log N)$, where $N$ is the\nsize of the datasets and $d$ is the number of attributes, enabling the\napplication to large datasets. We demonstrate that StyleDiff accurately detects\ndifferences between datasets and presents them in an understandable format\nusing, for example, driving scenes datasets.\n","authors":["Keisuke Kawano","Takuro Kutsuna","Ryoko Tokuhisa","Akihiro Nakamura","Yasushi Esaki"],"pdf_url":"https://arxiv.org/pdf/2303.05102v1.pdf","comment":"23 pages, 16 figures, under review"},{"id":"http://arxiv.org/abs/2303.05095v1","updated":"2023-03-09T08:13:06Z","published":"2023-03-09T08:13:06Z","title":"Trajectory-Aware Body Interaction Transformer for Multi-Person Pose\n  Forecasting","summary":"  Multi-person pose forecasting remains a challenging problem, especially in\nmodeling fine-grained human body interaction in complex crowd scenarios.\nExisting methods typically represent the whole pose sequence as a temporal\nseries, yet overlook interactive influences among people based on skeletal body\nparts. In this paper, we propose a novel Trajectory-Aware Body Interaction\nTransformer (TBIFormer) for multi-person pose forecasting via effectively\nmodeling body part interactions. Specifically, we construct a Temporal Body\nPartition Module that transforms all the pose sequences into a Multi-Person\nBody-Part sequence to retain spatial and temporal information based on body\nsemantics. Then, we devise a Social Body Interaction Self-Attention (SBI-MSA)\nmodule, utilizing the transformed sequence to learn body part dynamics for\ninter- and intra-individual interactions. Furthermore, different from prior\nEuclidean distance-based spatial encodings, we present a novel and efficient\nTrajectory-Aware Relative Position Encoding for SBI-MSA to offer discriminative\nspatial information and additional interactive clues. On both short- and\nlong-term horizons, we empirically evaluate our framework on CMU-Mocap,\nMuPoTS-3D as well as synthesized datasets (6 ~ 10 persons), and demonstrate\nthat our method greatly outperforms the state-of-the-art methods. Code will be\nmade publicly available upon acceptance.\n","authors":["Xiaogang Peng","Siyuan Mao","Zizhao Wu"],"pdf_url":"https://arxiv.org/pdf/2303.05095v1.pdf","comment":"Accepted by CVPR2023, 10 pages, 8 figures. arXiv admin note: text\n  overlap with arXiv:2208.09224"},{"id":"http://arxiv.org/abs/2303.05093v1","updated":"2023-03-09T08:07:38Z","published":"2023-03-09T08:07:38Z","title":"Improving Video Retrieval by Adaptive Margin","summary":"  Video retrieval is becoming increasingly important owing to the rapid\nemergence of videos on the Internet. The dominant paradigm for video retrieval\nlearns video-text representations by pushing the distance between the\nsimilarity of positive pairs and that of negative pairs apart from a fixed\nmargin. However, negative pairs used for training are sampled randomly, which\nindicates that the semantics between negative pairs may be related or even\nequivalent, while most methods still enforce dissimilar representations to\ndecrease their similarity. This phenomenon leads to inaccurate supervision and\npoor performance in learning video-text representations.\n  While most video retrieval methods overlook that phenomenon, we propose an\nadaptive margin changed with the distance between positive and negative pairs\nto solve the aforementioned issue. First, we design the calculation framework\nof the adaptive margin, including the method of distance measurement and the\nfunction between the distance and the margin. Then, we explore a novel\nimplementation called \"Cross-Modal Generalized Self-Distillation\" (CMGSD),\nwhich can be built on the top of most video retrieval models with few\nmodifications. Notably, CMGSD adds few computational overheads at train time\nand adds no computational overhead at test time. Experimental results on three\nwidely used datasets demonstrate that the proposed method can yield\nsignificantly better performance than the corresponding backbone model, and it\noutperforms state-of-the-art methods by a large margin.\n","authors":["Feng He","Qi Wang","Zhifan Feng","Wenbin Jiang","Yajuan Lv","Yong zhu","Xiao Tan"],"pdf_url":"https://arxiv.org/pdf/2303.05093v1.pdf","comment":"Accepted by SIGIR 2021"},{"id":"http://arxiv.org/abs/2303.05079v1","updated":"2023-03-09T07:30:53Z","published":"2023-03-09T07:30:53Z","title":"DDS3D: Dense Pseudo-Labels with Dynamic Threshold for Semi-Supervised 3D\n  Object Detection","summary":"  In this paper, we present a simple yet effective semi-supervised 3D object\ndetector named DDS3D. Our main contributions have two-fold. On the one hand,\ndifferent from previous works using Non-Maximal Suppression (NMS) or its\nvariants for obtaining the sparse pseudo labels, we propose a dense\npseudo-label generation strategy to get dense pseudo-labels, which can retain\nmore potential supervision information for the student network. On the other\nhand, instead of traditional fixed thresholds, we propose a dynamic threshold\nmanner to generate pseudo-labels, which can guarantee the quality and quantity\nof pseudo-labels during the whole training process. Benefiting from these two\ncomponents, our DDS3D outperforms the state-of-the-art semi-supervised 3d\nobject detection with mAP of 3.1% on the pedestrian and 2.1% on the cyclist\nunder the same configuration of 1% samples. Extensive ablation studies on the\nKITTI dataset demonstrate the effectiveness of our DDS3D. The code and models\nwill be made publicly available at https://github.com/hust-jy/DDS3D\n","authors":["Jingyu Li1","Zhe Liu1","Jinghua Hou1","Dingkang Liang"],"pdf_url":"https://arxiv.org/pdf/2303.05079v1.pdf","comment":"Accepted for publication in 2023 IEEE International Conference on\n  Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2303.05078v1","updated":"2023-03-09T07:26:49Z","published":"2023-03-09T07:26:49Z","title":"Efficient Transformer-based 3D Object Detection with Dynamic Token\n  Halting","summary":"  Balancing efficiency and accuracy is a long-standing problem for deploying\ndeep learning models. The trade-off is even more important for real-time\nsafety-critical systems like autonomous vehicles. In this paper, we propose an\neffective approach for accelerating transformer-based 3D object detectors by\ndynamically halting tokens at different layers depending on their contribution\nto the detection task. Although halting a token is a non-differentiable\noperation, our method allows for differentiable end-to-end learning by\nleveraging an equivalent differentiable forward-pass. Furthermore, our\nframework allows halted tokens to be reused to inform the model's predictions\nthrough a straightforward token recycling mechanism. Our method significantly\nimproves the Pareto frontier of efficiency versus accuracy when compared with\nthe existing approaches. By halting tokens and increasing model capacity, we\nare able to improve the baseline model's performance without increasing the\nmodel's latency on the Waymo Open Dataset.\n","authors":["Mao Ye","Gregory P. Meyer","Yuning Chai","Qiang Liu"],"pdf_url":"https://arxiv.org/pdf/2303.05078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05077v1","updated":"2023-03-09T07:22:07Z","published":"2023-03-09T07:22:07Z","title":"Learning the Legibility of Visual Text Perturbations","summary":"  Many adversarial attacks in NLP perturb inputs to produce visually similar\nstrings ('ergo' $\\rightarrow$ '$\\epsilon$rgo') which are legible to humans but\ndegrade model performance. Although preserving legibility is a necessary\ncondition for text perturbation, little work has been done to systematically\ncharacterize it; instead, legibility is typically loosely enforced via\nintuitions around the nature and extent of perturbations. Particularly, it is\nunclear to what extent can inputs be perturbed while preserving legibility, or\nhow to quantify the legibility of a perturbed string. In this work, we address\nthis gap by learning models that predict the legibility of a perturbed string,\nand rank candidate perturbations based on their legibility. To do so, we\ncollect and release \\dataset, a human-annotated dataset comprising the\nlegibility of visually perturbed text. Using this dataset, we build both text-\nand vision-based models which achieve up to $0.91$ F1 score in predicting\nwhether an input is legible, and an accuracy of $0.86$ in predicting which of\ntwo given perturbations is more legible. Additionally, we discover that legible\nperturbations from the \\dataset dataset are more effective at lowering the\nperformance of NLP models than best-known attack strategies, suggesting that\ncurrent models may be vulnerable to a broad range of perturbations beyond what\nis captured by existing visual attacks. Data, code, and models are available at\nhttps://github.com/dvsth/learning-legibility-2023.\n","authors":["Dev Seth","Rickard Stureborg","Danish Pruthi","Bhuwan Dhingra"],"pdf_url":"https://arxiv.org/pdf/2303.05077v1.pdf","comment":"9 pages, 11 figures. Long paper at EACL 2023"},{"id":"http://arxiv.org/abs/2303.03301v2","updated":"2023-03-09T07:20:53Z","published":"2023-03-06T17:19:28Z","title":"Exploring Deep Models for Practical Gait Recognition","summary":"  Gait recognition is a rapidly advancing vision technique for person\nidentification from a distance. Prior studies predominantly employed relatively\nsmall and shallow neural networks to extract subtle gait features, achieving\nimpressive successes in indoor settings. Nevertheless, experiments revealed\nthat these existing methods mostly produce unsatisfactory results when applied\nto newly released in-the-wild gait datasets. This paper presents a unified\nperspective to explore how to construct deep models for state-of-the-art\noutdoor gait recognition, including the classical CNN-based and emerging\nTransformer-based architectures. Consequently, we emphasize the importance of\nsuitable network capacity, explicit temporal modeling, and deep transformer\nstructure for discriminative gait representation learning. Our proposed\nCNN-based DeepGaitV2 series and Transformer-based SwinGait series exhibit\nsignificant performance gains in outdoor scenarios, \\textit{e.g.}, about +30\\%\nrank-1 accuracy compared with many state-of-the-art methods on the challenging\nGREW dataset. This work is expected to further boost the research and\napplication of gait recognition. Code will be available at\nhttps://github.com/ShiqiYu/OpenGait.\n","authors":["Chao Fan","Saihui Hou","Yongzhen Huang","Shiqi Yu"],"pdf_url":"https://arxiv.org/pdf/2303.03301v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05076v1","updated":"2023-03-09T07:20:37Z","published":"2023-03-09T07:20:37Z","title":"GaitEditer: Attribute Editing for Gait Representation Learning","summary":"  Gait pattern is a promising biometric for applications, as it can be captured\nfrom a distance without requiring individual cooperation. Nevertheless,\nexisting gait datasets typically suffer from limited diversity, with indoor\ndatasets requiring participants to walk along a fixed route in a restricted\nsetting, and outdoor datasets containing only few walking sequences per\nsubject. Prior generative methods have attempted to mitigate these limitations\nby building virtual gait datasets. They primarily focus on manipulating a\nsingle, specific gait attribute (e.g., viewpoint or carrying), and require the\nsupervised data pairs for training, thus lacking the flexibility and diversity\nfor practical usage. In contrast, our GaitEditer can act as an online module to\nedit a broad range of gait attributes, such as pants, viewpoint, and even age,\nin an unsupervised manner, which current gait generative methods struggle with.\nAdditionally, GaitEidter also finely preserves both temporal continuity and\nidentity characteristics in generated gait sequences. Experiments show that\nGaitEditer provides extensive knowledge for clothing-invariant and\nview-invariant gait representation learning under various challenging\nscenarios. The source code will be available.\n","authors":["Dingqiang Ye","Jingzhe Ma","Chao Fan","Shiqi Yu"],"pdf_url":"https://arxiv.org/pdf/2303.05076v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04016v2","updated":"2023-03-09T07:14:20Z","published":"2023-03-07T16:31:13Z","title":"Decoupling Skill Learning from Robotic Control for Generalizable Object\n  Manipulation","summary":"  Recent works in robotic manipulation through reinforcement learning (RL) or\nimitation learning (IL) have shown potential for tackling a range of tasks\ne.g., opening a drawer or a cupboard. However, these techniques generalize\npoorly to unseen objects. We conjecture that this is due to the\nhigh-dimensional action space for joint control. In this paper, we take an\nalternative approach and separate the task of learning 'what to do' from 'how\nto do it' i.e., whole-body control. We pose the RL problem as one of\ndetermining the skill dynamics for a disembodied virtual manipulator\ninteracting with articulated objects. The whole-body robotic kinematic control\nis optimized to execute the high-dimensional joint motion to reach the goals in\nthe workspace. It does so by solving a quadratic programming (QP) model with\nrobotic singularity and kinematic constraints. Our experiments on manipulating\ncomplex articulated objects show that the proposed approach is more\ngeneralizable to unseen objects with large intra-class variations,\noutperforming previous approaches. The evaluation results indicate that our\napproach generates more compliant robotic motion and outperforms the pure RL\nand IL baselines in task success rates. Additional information and videos are\navailable at https://kl-research.github.io/decoupskill\n","authors":["Kai Lu","Bo Yang","Bing Wang","Andrew Markham"],"pdf_url":"https://arxiv.org/pdf/2303.04016v2.pdf","comment":"Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2303.05073v1","updated":"2023-03-09T07:11:30Z","published":"2023-03-09T07:11:30Z","title":"Learn More for Food Recognition via Progressive Self-Distillation","summary":"  Food recognition has a wide range of applications, such as health-aware\nrecommendation and self-service restaurants. Most previous methods of food\nrecognition firstly locate informative regions in some weakly-supervised\nmanners and then aggregate their features. However, location errors of\ninformative regions limit the effectiveness of these methods to some extent.\nInstead of locating multiple regions, we propose a Progressive\nSelf-Distillation (PSD) method, which progressively enhances the ability of\nnetwork to mine more details for food recognition. The training of PSD\nsimultaneously contains multiple self-distillations, in which a teacher network\nand a student network share the same embedding network. Since the student\nnetwork receives a modified image from its teacher network by masking some\ninformative regions, the teacher network outputs stronger semantic\nrepresentations than the student network. Guided by such teacher network with\nstronger semantics, the student network is encouraged to mine more useful\nregions from the modified image by enhancing its own ability. The ability of\nthe teacher network is also enhanced with the shared embedding network. By\nusing progressive training, the teacher network incrementally improves its\nability to mine more discriminative regions. In inference phase, only the\nteacher network is used without the help of the student network. Extensive\nexperiments on three datasets demonstrate the effectiveness of our proposed\nmethod and state-of-the-art performance.\n","authors":["Yaohui Zhu","Linhu Liu","Jiang Tian"],"pdf_url":"https://arxiv.org/pdf/2303.05073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05072v1","updated":"2023-03-09T07:08:25Z","published":"2023-03-09T07:08:25Z","title":"Identification of Systematic Errors of Image Classifiers on Rare\n  Subgroups","summary":"  Despite excellent average-case performance of many image classifiers, their\nperformance can substantially deteriorate on semantically coherent subgroups of\nthe data that were under-represented in the training data. These systematic\nerrors can impact both fairness for demographic minority groups as well as\nrobustness and safety under domain shift. A major challenge is to identify such\nsubgroups with subpar performance when the subgroups are not annotated and\ntheir occurrence is very rare. We leverage recent advances in text-to-image\nmodels and search in the space of textual descriptions of subgroups (\"prompts\")\nfor subgroups where the target model has low performance on the\nprompt-conditioned synthesized data. To tackle the exponentially growing number\nof subgroups, we employ combinatorial testing. We denote this procedure as\nPromptAttack as it can be interpreted as an adversarial attack in a prompt\nspace. We study subgroup coverage and identifiability with PromptAttack in a\ncontrolled setting and find that it identifies systematic errors with high\naccuracy. Thereupon, we apply PromptAttack to ImageNet classifiers and identify\nnovel systematic errors on rare subgroups.\n","authors":["Jan Hendrik Metzen","Robin Hutmacher","N. Grace Hua","Valentyn Boreiko","Dan Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05071v1","updated":"2023-03-09T07:07:39Z","published":"2023-03-09T07:07:39Z","title":"MBPTrack: Improving 3D Point Cloud Tracking with Memory Networks and Box\n  Priors","summary":"  3D single object tracking has been a crucial problem for decades with\nnumerous applications such as autonomous driving. Despite its wide-ranging use,\nthis task remains challenging due to the significant appearance variation\ncaused by occlusion and size differences among tracked targets. To address\nthese issues, we present MBPTrack, which adopts a Memory mechanism to utilize\npast information and formulates localization in a coarse-to-fine scheme using\nBox Priors given in the first frame. Specifically, past frames with targetness\nmasks serve as an external memory, and a transformer-based module propagates\ntracked target cues from the memory to the current frame. To precisely localize\nobjects of all sizes, MBPTrack first predicts the target center via Hough\nvoting. By leveraging box priors given in the first frame, we adaptively sample\nreference points around the target center that roughly cover the target of\ndifferent sizes. Then, we obtain dense feature maps by aggregating point\nfeatures into the reference points, where localization can be performed more\neffectively. Extensive experiments demonstrate that MBPTrack achieves\nstate-of-the-art performance on KITTI, nuScenes and Waymo Open Dataset, while\nrunning at 50 FPS on a single RTX3090 GPU.\n","authors":["Tian-Xing Xu","Yuan-Chen Guo","Yu-Kun Lai","Song-Hai Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09590v3","updated":"2023-03-09T06:59:47Z","published":"2022-11-17T15:36:48Z","title":"Hypergraph Transformer for Skeleton-based Action Recognition","summary":"  Skeleton-based action recognition aims to predict human actions given human\njoint coordinates with skeletal interconnections. To model such off-grid data\npoints and their co-occurrences, Transformer-based formulations would be a\nnatural choice. However, Transformers still lag behind state-of-the-art methods\nusing graph convolutional networks (GCNs). Transformers assume that the input\nis permutation-invariant and homogeneous (partially alleviated by positional\nencoding), which ignores an important characteristic of skeleton data, i.e.,\nbone connectivity. Furthermore, each type of body joint has a clear physical\nmeaning in human motion, i.e., motion retains an intrinsic relationship\nregardless of the joint coordinates, which is not explored in Transformers. In\nfact, certain re-occurring groups of body joints are often involved in specific\nactions, such as the subconscious hand movement for keeping balance. Vanilla\nattention is incapable of describing such underlying relations that are\npersistent and beyond pair-wise. In this work, we aim to exploit these unique\naspects of skeleton data to close the performance gap between Transformers and\nGCNs. Specifically, we propose a new self-attention (SA) extension, named\nHypergraph Self-Attention (HyperSA), to incorporate inherently higher-order\nrelations into the model. The K-hop relative positional embeddings are also\nemployed to take bone connectivity into account. We name the resulting model\nHyperformer, and it achieves comparable or better performance w.r.t. accuracy\nand efficiency than state-of-the-art GCN architectures on NTU RGB+D, NTU RGB+D\n120, and Northwestern-UCLA datasets. On the largest NTU RGB+D 120 dataset, the\nsignificantly improved performance reached by our Hyperformer demonstrates the\nunderestimated potential of Transformer models in this field.\n","authors":["Yuxuan Zhou","Chao Li","Zhi-Qi Cheng","Yifeng Geng","Xuansong Xie","Margret Keuper"],"pdf_url":"https://arxiv.org/pdf/2211.09590v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05068v1","updated":"2023-03-09T06:58:29Z","published":"2023-03-09T06:58:29Z","title":"Toward Unsupervised Realistic Visual Question Answering","summary":"  The problem of realistic VQA (RVQA), where a model has to reject unanswerable\nquestions (UQs) and answer answerable ones (AQs), is studied. We first point\nout 2 drawbacks in current RVQA research, where (1) datasets contain too many\nunchallenging UQs and (2) a large number of annotated UQs are required for\ntraining. To resolve the first drawback, we propose a new testing dataset,\nRGQA, which combines AQs from an existing VQA dataset with around 29K\nhuman-annotated UQs. These UQs consist of both fine-grained and coarse-grained\nimage-question pairs generated with 2 approaches: CLIP-based and\nPerturbation-based. To address the second drawback, we introduce an\nunsupervised training approach. This combines pseudo UQs obtained by randomly\npairing images and questions, with an RoI Mixup procedure to generate more\nfine-grained pseudo UQs, and model ensembling to regularize model confidence.\nExperiments show that using pseudo UQs significantly outperforms RVQA\nbaselines. RoI Mixup and model ensembling further increase the gain. Finally,\nhuman evaluation reveals a performance gap between humans and models, showing\nthat more RVQA research is needed.\n","authors":["Yuwei Zhang","Chih-Hui Ho","Nuno Vasconcelos"],"pdf_url":"https://arxiv.org/pdf/2303.05068v1.pdf","comment":"Yuwei Zhang and Chih-Hui Ho contributed equally to this work"},{"id":"http://arxiv.org/abs/2212.05946v2","updated":"2023-03-09T06:44:42Z","published":"2022-12-12T14:59:11Z","title":"Evaluation and Improvement of Interpretability for Self-Explainable\n  Part-Prototype Networks","summary":"  Part-prototype networks (e.g., ProtoPNet, ProtoTree and ProtoPool) have\nattracted broad research interest for their intrinsic interpretability and\ncomparable accuracy to non-interpretable counterparts. However, recent works\nfind that the interpretability from prototypes is fragile, due to the semantic\ngap between the similarities in the feature space and that in the input space.\nIn this work, we strive to address this challenge by making the first attempt\nto quantitatively and objectively evaluate the interpretability of the\npart-prototype networks. Specifically, we propose two evaluation metrics,\ntermed as consistency score and stability score, to evaluate the explanation\nconsistency across images and the explanation robustness against perturbations,\nrespectively, both of which are essential for explanations taken into practice.\nFurthermore, we propose an elaborated part-prototype network with a\nshallow-deep feature alignment (SDFA) module and a score aggregation (SA)\nmodule to improve the interpretability of prototypes. We conduct systematical\nevaluation experiments and provide substantial discussions to uncover the\ninterpretability of existing part-prototype networks. Experiments on three\nbenchmarks across nine architectures demonstrate that our model achieves\nsignificantly superior performance to the state of the art, in both the\naccuracy and interpretability. Codes are available at\nhttps://github.com/hqhQAQ/EvalProtoPNet.\n","authors":["Qihan Huang","Mengqi Xue","Wenqi Huang","Haofei Zhang","Jie Song","Yongcheng Jing","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2212.05946v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05066v1","updated":"2023-03-09T06:33:31Z","published":"2023-03-09T06:33:31Z","title":"Distortion-Disentangled Contrastive Learning","summary":"  Self-supervised learning is well known for its remarkable performance in\nrepresentation learning and various downstream computer vision tasks. Recently,\nPositive-pair-Only Contrastive Learning (POCL) has achieved reliable\nperformance without the need to construct positive-negative training sets. It\nreduces memory requirements by lessening the dependency on the batch size. The\nPOCL method typically uses a single loss function to extract the distortion\ninvariant representation (DIR) which describes the proximity of positive-pair\nrepresentations affected by different distortions. This loss function\nimplicitly enables the model to filter out or ignore the distortion variant\nrepresentation (DVR) affected by different distortions. However, existing POCL\nmethods do not explicitly enforce the disentanglement and exploitation of the\nactually valuable DVR. In addition, these POCL methods have been observed to be\nsensitive to augmentation strategies. To address these limitations, we propose\na novel POCL framework named Distortion-Disentangled Contrastive Learning\n(DDCL) and a Distortion-Disentangled Loss (DDL). Our approach is the first to\nexplicitly disentangle and exploit the DVR inside the model and feature stream\nto improve the overall representation utilization efficiency, robustness and\nrepresentation ability. Experiments carried out demonstrate the superiority of\nour framework to Barlow Twins and Simsiam in terms of convergence,\nrepresentation quality, and robustness on several benchmark datasets.\n","authors":["Jinfeng Wang","Sifan Song","Jionglong Su","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.05066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06891v2","updated":"2023-03-09T06:20:10Z","published":"2023-02-14T08:27:42Z","title":"UKnow: A Unified Knowledge Protocol for Common-Sense Reasoning and\n  Vision-Language Pre-training","summary":"  This work presents a unified knowledge protocol, called UKnow, which\nfacilitates knowledge-based studies from the perspective of data. Particularly\nfocusing on visual and linguistic modalities, we categorize data knowledge into\nfive unit types, namely, in-image, in-text, cross-image, cross-text, and\nimage-text, and set up an efficient pipeline to help construct the multimodal\nknowledge graph from any data collection. Thanks to the logical information\nnaturally contained in knowledge graph, organizing datasets under UKnow format\nopens up more possibilities of data usage compared to the commonly used\nimage-text pairs. Following UKnow protocol, we collect, from public\ninternational news, a large-scale multimodal knowledge graph dataset that\nconsists of 1,388,568 nodes (with 571,791 vision-related ones) and 3,673,817\ntriplets. The dataset is also annotated with rich event tags, including 11\ncoarse labels and 9,185 fine labels. Experiments on four benchmarks demonstrate\nthe potential of UKnow in supporting common-sense reasoning and boosting\nvision-language pre-training with a single dataset, benefiting from its unified\nform of knowledge organization. Code, dataset, and models will be made publicly\navailable.\n","authors":["Biao Gong","Xiaoying Xie","Yutong Feng","Yiliang Lv","Yujun Shen","Deli Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.06891v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05050v1","updated":"2023-03-09T05:54:42Z","published":"2023-03-09T05:54:42Z","title":"Lifelong-MonoDepth: Lifelong Learning for Multi-Domain Monocular Metric\n  Depth Estimation","summary":"  In recent years, monocular depth estimation (MDE) has gained significant\nprogress in a data-driven learning fashion. Previous methods can infer depth\nmaps for specific domains based on the paradigm of single-domain or\njoint-domain training with mixed data. However, they suffer from low\nscalability to new domains. In reality, target domains often dynamically change\nor increase, raising the requirement of incremental multi-domain/task learning.\nIn this paper, we seek to enable lifelong learning for MDE, which performs\ncross-domain depth learning sequentially, to achieve high plasticity on a new\ndomain and maintain good stability on original domains. To overcome significant\ndomain gaps and enable scale-aware depth prediction, we design a lightweight\nmulti-head framework that consists of a domain-shared encoder for feature\nextraction and domain-specific predictors for metric depth estimation.\nMoreover, given an input image, we propose an efficient predictor selection\napproach that automatically identifies the corresponding predictor for depth\ninference. Through extensive numerical studies, we show that the proposed\nmethod can achieve good efficiency, stability, and plasticity, leading the\nbenchmarks by 8% to 15%.\n","authors":["Junjie Hu","Chenyou Fan","Liguang Zhou","Qing Gao","Honghai Liu","Tin Lun Lam"],"pdf_url":"https://arxiv.org/pdf/2303.05050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05049v1","updated":"2023-03-09T05:53:32Z","published":"2023-03-09T05:53:32Z","title":"Unifying Layout Generation with a Decoupled Diffusion Model","summary":"  Layout generation aims to synthesize realistic graphic scenes consisting of\nelements with different attributes including category, size, position, and\nbetween-element relation. It is a crucial task for reducing the burden on\nheavy-duty graphic design works for formatted scenes, e.g., publications,\ndocuments, and user interfaces (UIs). Diverse application scenarios impose a\nbig challenge in unifying various layout generation subtasks, including\nconditional and unconditional generation. In this paper, we propose a Layout\nDiffusion Generative Model (LDGM) to achieve such unification with a single\ndecoupled diffusion model. LDGM views a layout of arbitrary missing or coarse\nelement attributes as an intermediate diffusion status from a completed layout.\nSince different attributes have their individual semantics and characteristics,\nwe propose to decouple the diffusion processes for them to improve the\ndiversity of training samples and learn the reverse process jointly to exploit\nglobal-scope contexts for facilitating generation. As a result, our LDGM can\ngenerate layouts either from scratch or conditional on arbitrary available\nattributes. Extensive qualitative and quantitative experiments demonstrate our\nproposed LDGM outperforms existing layout generation models in both\nfunctionality and performance.\n","authors":["Mude Hui","Zhizheng Zhang","Xiaoyi Zhang","Wenxuan Xie","Yuwang Wang","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2303.05049v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2303.05047v1","updated":"2023-03-09T05:52:42Z","published":"2023-03-09T05:52:42Z","title":"Diversity-Measurable Anomaly Detection","summary":"  Reconstruction-based anomaly detection models achieve their purpose by\nsuppressing the generalization ability for anomaly. However, diverse normal\npatterns are consequently not well reconstructed as well. Although some efforts\nhave been made to alleviate this problem by modeling sample diversity, they\nsuffer from shortcut learning due to undesired transmission of abnormal\ninformation. In this paper, to better handle the tradeoff problem, we propose\nDiversity-Measurable Anomaly Detection (DMAD) framework to enhance\nreconstruction diversity while avoid the undesired generalization on anomalies.\nTo this end, we design Pyramid Deformation Module (PDM), which models diverse\nnormals and measures the severity of anomaly by estimating multi-scale\ndeformation fields from reconstructed reference to original input. Integrated\nwith an information compression module, PDM essentially decouples deformation\nfrom prototypical embedding and makes the final anomaly score more reliable.\nExperimental results on both surveillance videos and industrial images\ndemonstrate the effectiveness of our method. In addition, DMAD works equally\nwell in front of contaminated data and anomaly-like normal samples.\n","authors":["Wenrui Liu","Hong Chang","Bingpeng Ma","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.05047v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2208.11039v2","updated":"2023-03-09T05:48:21Z","published":"2022-08-23T15:25:44Z","title":"Flat Multi-modal Interaction Transformer for Named Entity Recognition","summary":"  Multi-modal named entity recognition (MNER) aims at identifying entity spans\nand recognizing their categories in social media posts with the aid of images.\nHowever, in dominant MNER approaches, the interaction of different modalities\nis usually carried out through the alternation of self-attention and\ncross-attention or over-reliance on the gating machine, which results in\nimprecise and biased correspondence between fine-grained semantic units of text\nand image. To address this issue, we propose a Flat Multi-modal Interaction\nTransformer (FMIT) for MNER. Specifically, we first utilize noun phrases in\nsentences and general domain words to obtain visual cues. Then, we transform\nthe fine-grained semantic representation of the vision and text into a unified\nlattice structure and design a novel relative position encoding to match\ndifferent modalities in Transformer. Meanwhile, we propose to leverage entity\nboundary detection as an auxiliary task to alleviate visual bias. Experiments\nshow that our methods achieve the new state-of-the-art performance on two\nbenchmark datasets.\n","authors":["Junyu Lu","Dixiang Zhang","Pingjian Zhang"],"pdf_url":"https://arxiv.org/pdf/2208.11039v2.pdf","comment":"Accepted by COLING 2022, oral paper"},{"id":"http://arxiv.org/abs/2202.11202v3","updated":"2023-03-09T05:16:49Z","published":"2022-02-22T22:31:57Z","title":"Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning","summary":"  Indiscriminate data poisoning attacks are quite effective against supervised\nlearning. However, not much is known about their impact on unsupervised\ncontrastive learning (CL). This paper is the first to consider indiscriminate\npoisoning attacks of contrastive learning. We propose Contrastive Poisoning\n(CP), the first effective such attack on CL. We empirically show that\nContrastive Poisoning, not only drastically reduces the performance of CL\nalgorithms, but also attacks supervised learning models, making it the most\ngeneralizable indiscriminate poisoning attack. We also show that CL algorithms\nwith a momentum encoder are more robust to indiscriminate poisoning, and\npropose a new countermeasure based on matrix completion. Code is available at:\nhttps://github.com/kaiwenzha/contrastive-poisoning.\n","authors":["Hao He","Kaiwen Zha","Dina Katabi"],"pdf_url":"https://arxiv.org/pdf/2202.11202v3.pdf","comment":"ICLR 2023 Spotlight (notable top 25%). The first two authors\n  contributed equally to this paper"},{"id":"http://arxiv.org/abs/2302.02350v3","updated":"2023-03-09T05:00:27Z","published":"2023-02-05T09:48:57Z","title":"Aggregation of Disentanglement: Reconsidering Domain Variations in\n  Domain Generalization","summary":"  Domain Generalization (DG) is a fundamental challenge for machine learning\nmodels, which aims to improve model generalization on various domains. Previous\nmethods focus on generating domain invariant features from various source\ndomains. However, we argue that the domain variantions also contain useful\ninformation, ie, classification-aware information, for downstream tasks, which\nhas been largely ignored. Different from learning domain invariant features\nfrom source domains, we decouple the input images into Domain Expert Features\nand noise. The proposed domain expert features lie in a learned latent space\nwhere the images in each domain can be classified independently, enabling the\nimplicit use of classification-aware domain variations. Based on the analysis,\nwe proposed a novel paradigm called Domain Disentanglement Network (DDN) to\ndisentangle the domain expert features from the source domain images and\naggregate the source domain expert features for representing the target test\ndomain. We also propound a new contrastive learning method to guide the domain\nexpert features to form a more balanced and separable feature space.\nExperiments on the widely-used benchmarks of PACS, VLCS, OfficeHome, DomainNet,\nand TerraIncognita demonstrate the competitive performance of our method\ncompared to the recently proposed alternatives.\n","authors":["Daoan Zhang","Mingkai Chen","Chenming Li","Lingyun Huang","Jianguo Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.02350v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05036v1","updated":"2023-03-09T05:00:17Z","published":"2023-03-09T05:00:17Z","title":"Generative Model-Based Attack on Learnable Image Encryption for\n  Privacy-Preserving Deep Learning","summary":"  In this paper, we propose a novel generative model-based attack on learnable\nimage encryption methods proposed for privacy-preserving deep learning. Various\nlearnable encryption methods have been studied to protect the sensitive visual\ninformation of plain images, and some of them have been investigated to be\nrobust enough against all existing attacks. However, previous attacks on image\nencryption focus only on traditional cryptanalytic attacks or reverse\ntranslation models, so these attacks cannot recover any visual information if a\nblock-scrambling encryption step, which effectively destroys global\ninformation, is applied. Accordingly, in this paper, generative models are\nexplored to evaluate whether such models can restore sensitive visual\ninformation from encrypted images for the first time. We first point out that\nencrypted images have some similarity with plain images in the embedding space.\nBy taking advantage of leaked information from encrypted images, we propose a\nguided generative model as an attack on learnable image encryption to recover\npersonally identifiable visual information. We implement the proposed attack in\ntwo ways by utilizing two state-of-the-art generative models: a StyleGAN-based\nmodel and latent diffusion-based one. Experiments were carried out on the\nCelebA-HQ and ImageNet datasets. Results show that images reconstructed by the\nproposed method have perceptual similarities to plain images.\n","authors":["AprilPyone MaungMaung","Hitoshi Kiya"],"pdf_url":"https://arxiv.org/pdf/2303.05036v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2209.07953"},{"id":"http://arxiv.org/abs/2211.12046v4","updated":"2023-03-09T04:46:50Z","published":"2022-11-22T06:40:53Z","title":"DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors","summary":"  Neural Radiance Field (NeRF) has exhibited outstanding three-dimensional (3D)\nreconstruction quality via the novel view synthesis from multi-view images and\npaired calibrated camera parameters. However, previous NeRF-based systems have\nbeen demonstrated under strictly controlled settings, with little attention\npaid to less ideal scenarios, including with the presence of noise such as\nexposure, illumination changes, and blur. In particular, though blur frequently\noccurs in real situations, NeRF that can handle blurred images has received\nlittle attention. The few studies that have investigated NeRF for blurred\nimages have not considered geometric and appearance consistency in 3D space,\nwhich is one of the most important factors in 3D reconstruction. This leads to\ninconsistency and the degradation of the perceptual quality of the constructed\nscene. Hence, this paper proposes a DP-NeRF, a novel clean NeRF framework for\nblurred images, which is constrained with two physical priors. These priors are\nderived from the actual blurring process during image acquisition by the\ncamera. DP-NeRF proposes rigid blurring kernel to impose 3D consistency\nutilizing the physical priors and adaptive weight proposal to refine the color\ncomposition error in consideration of the relationship between depth and blur.\nWe present extensive experimental results for synthetic and real scenes with\ntwo types of blur: camera motion blur and defocus blur. The results demonstrate\nthat DP-NeRF successfully improves the perceptual quality of the constructed\nNeRF ensuring 3D geometric and appearance consistency. We further demonstrate\nthe effectiveness of our model with comprehensive ablation analysis.\n","authors":["Dogyoon Lee","Minhyeok Lee","Chajin Shin","Sangyoun Lee"],"pdf_url":"https://arxiv.org/pdf/2211.12046v4.pdf","comment":"Accepted at CVPR 2023, Code: https://github.com/dogyoonlee/DP-NeRF,\n  Project page: https://dogyoonlee.github.io/dpnerf/"},{"id":"http://arxiv.org/abs/2303.05031v1","updated":"2023-03-09T04:35:03Z","published":"2023-03-09T04:35:03Z","title":"CoralStyleCLIP: Co-optimized Region and Layer Selection for Image\n  Editing","summary":"  Edit fidelity is a significant issue in open-world controllable generative\nimage editing. Recently, CLIP-based approaches have traded off simplicity to\nalleviate these problems by introducing spatial attention in a handpicked layer\nof a StyleGAN. In this paper, we propose CoralStyleCLIP, which incorporates a\nmulti-layer attention-guided blending strategy in the feature space of\nStyleGAN2 for obtaining high-fidelity edits. We propose multiple forms of our\nco-optimized region and layer selection strategy to demonstrate the variation\nof time complexity with the quality of edits over different architectural\nintricacies while preserving simplicity. We conduct extensive experimental\nanalysis and benchmark our method against state-of-the-art CLIP-based methods.\nOur findings suggest that CoralStyleCLIP results in high-quality edits while\npreserving the ease of use.\n","authors":["Ambareesh Revanur","Debraj Basu","Shradha Agrawal","Dhwanit Agarwal","Deepak Pai"],"pdf_url":"https://arxiv.org/pdf/2303.05031v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.05026v1","updated":"2023-03-09T04:20:16Z","published":"2023-03-09T04:20:16Z","title":"SSL^2: Self-Supervised Learning meets Semi-Supervised Learning: Multiple\n  Sclerosis Segmentation in 7T-MRI from large-scale 3T-MRI","summary":"  Automated segmentation of multiple sclerosis (MS) lesions from MRI scans is\nimportant to quantify disease progression. In recent years, convolutional\nneural networks (CNNs) have shown top performance for this task when a large\namount of labeled data is available. However, the accuracy of CNNs suffers when\ndealing with few and/or sparsely labeled datasets. A potential solution is to\nleverage the information available in large public datasets in conjunction with\na target dataset which only has limited labeled data. In this paper, we propose\na training framework, SSL2 (self-supervised-semi-supervised), for\nmulti-modality MS lesion segmentation with limited supervision. We adopt\nself-supervised learning to leverage the knowledge from large public 3T\ndatasets to tackle the limitations of a small 7T target dataset. To leverage\nthe information from unlabeled 7T data, we also evaluate state-of-the-art\nsemi-supervised methods for other limited annotation settings, such as small\nlabeled training size and sparse annotations. We use the shifted-window (Swin)\ntransformer1 as our backbone network. The effectiveness of self-supervised and\nsemi-supervised training strategies is evaluated in our in-house 7T MRI\ndataset. The results indicate that each strategy improves lesion segmentation\nfor both limited training data size and for sparse labeling scenarios. The\ncombined overall framework further improves the performance substantially\ncompared to either of its components alone. Our proposed framework thus\nprovides a promising solution for future data/label-hungry 7T MS studies.\n","authors":["Jiacheng Wang","Hao Li","Han Liu","Dewei Hu","Daiwei Lu","Keejin Yoon","Kelsey Barter","Francesca Bagnato","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2303.05026v1.pdf","comment":"Accepted at the International Society for Optics and Photonics -\n  Medical Imaging (SPIE-MI) 2023"},{"id":"http://arxiv.org/abs/2209.08355v3","updated":"2023-03-09T04:06:16Z","published":"2022-09-17T15:47:01Z","title":"Towards Connectivity-Aware Pulmonary Airway Segmentation","summary":"  Detailed pulmonary airway segmentation is a clinically important task for\nendobronchial intervention and treatment of peripheral pulmonary lesions.\nConvolutional Neural Networks (CNNs) are promising for automated analysis of\nmedical imaging, which however performs poorly on airway segmentation.\nSpecifically, breakage of small bronchi distals cannot be effectively\neliminated in the prediction results of CNNs, which is detrimental to use as a\nreference for bronchoscopic-assisted surgery. In this paper, we proposed a\nconnectivity-aware segmentation framework to improve the performance of airway\nsegmentation. A Connectivity-Aware Surrogate (CAS) module is first proposed to\nbalance the training progress within-class distribution. Furthermore, a\nLocal-Sensitive Distance (LSD) module is designed to identify the breakage and\nminimize the variation of the distance map between the prediction and\nground-truth. The proposed method is validated with the publically available\nreference airway segmentation datasets. The detected rate of branch and length\non public EXACT'09 and BAS datasets are 82.1%/79.6% and 96.5%/91.5%\nrespectively, demonstrating the effectiveness of the method in terms of\nimproving the connectedness of the segmentation performance.\n","authors":["Minghui Zhang","Yun Gu"],"pdf_url":"https://arxiv.org/pdf/2209.08355v3.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.05021v1","updated":"2023-03-09T03:48:24Z","published":"2023-03-09T03:48:24Z","title":"DiffusionDepth: Diffusion Denoising Approach for Monocular Depth\n  Estimation","summary":"  Monocular depth estimation is a challenging task that predicts the pixel-wise\ndepth from a single 2D image. Current methods typically model this problem as a\nregression or classification task. We propose DiffusionDepth, a new approach\nthat reformulates monocular depth estimation as a denoising diffusion process.\nIt learns an iterative denoising process to `denoise' random depth distribution\ninto a depth map with the guidance of monocular visual conditions. The process\nis performed in the latent space encoded by a dedicated depth encoder and\ndecoder. Instead of diffusing ground truth (GT) depth, the model learns to\nreverse the process of diffusing the refined depth of itself into random depth\ndistribution. This self-diffusion formulation overcomes the difficulty of\napplying generative models to sparse GT depth scenarios. The proposed approach\nbenefits this task by refining depth estimation step by step, which is superior\nfor generating accurate and highly detailed depth maps. Experimental results on\nKITTI and NYU-Depth-V2 datasets suggest that a simple yet efficient diffusion\napproach could reach state-of-the-art performance in both indoor and outdoor\nscenarios with acceptable inference time.\n","authors":["Yiqun Duan","Xianda Guo","Zheng Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.05021v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05015v1","updated":"2023-03-09T03:33:56Z","published":"2023-03-09T03:33:56Z","title":"Smooth and Stepwise Self-Distillation for Object Detection","summary":"  Distilling the structured information captured in feature maps has\ncontributed to improved results for object detection tasks, but requires\ncareful selection of baseline architectures and substantial pre-training.\nSelf-distillation addresses these limitations and has recently achieved\nstate-of-the-art performance for object detection despite making several\nsimplifying architectural assumptions. Building on this work, we propose Smooth\nand Stepwise Self-Distillation (SSSD) for object detection. Our SSSD\narchitecture forms an implicit teacher from object labels and a feature pyramid\nnetwork backbone to distill label-annotated feature maps using Jensen-Shannon\ndistance, which is smoother than distillation losses used in prior work. We\nadditionally add a distillation coefficient that is adaptively configured based\non the learning rate. We extensively benchmark SSSD against a baseline and two\nstate-of-the-art object detector architectures on the COCO dataset by varying\nthe coefficients and backbone and detector networks. We demonstrate that SSSD\nachieves higher average precision in most experimental settings, is robust to a\nwide range of coefficients, and benefits from our stepwise distillation\nprocedure.\n","authors":["Jieren Deng","Xin Zhou","Hao Tian","Zhihong Pan","Derek Aguiar"],"pdf_url":"https://arxiv.org/pdf/2303.05015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10705v3","updated":"2023-03-09T03:26:02Z","published":"2022-11-19T14:06:58Z","title":"TORE: Token Reduction for Efficient Human Mesh Recovery with Transformer","summary":"  In this paper, we introduce a set of simple yet effective TOken REduction\n(TORE) strategies for Transformer-based Human Mesh Recovery from monocular\nimages. Current SOTA performance is achieved by Transformer-based structures.\nHowever, they suffer from high model complexity and computation cost caused by\nredundant tokens. We propose token reduction strategies based on two important\naspects, i.e., the 3D geometry structure and 2D image feature, where we\nhierarchically recover the mesh geometry with priors from body structure and\nconduct token clustering to pass fewer but more discriminative image feature\ntokens to the Transformer. Our method massively reduces the number of tokens\ninvolved in high-complexity interactions in the Transformer. This leads to a\nsignificantly reduced computational cost while still achieving competitive or\neven higher accuracy in shape recovery. Extensive experiments across a wide\nrange of benchmarks validate the superior effectiveness of the proposed method.\nWe further demonstrate the generalizability of our method on hand mesh\nrecovery. Our code will be publicly available once the paper is published.\n","authors":["Zhiyang Dou","Qingxuan Wu","Cheng Lin","Zeyu Cao","Qiangqiang Wu","Weilin Wan","Taku Komura","Wenping Wang"],"pdf_url":"https://arxiv.org/pdf/2211.10705v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.13056v2","updated":"2023-03-09T03:20:02Z","published":"2022-12-26T09:20:55Z","title":"MonoNeRF: Learning a Generalizable Dynamic Radiance Field from Monocular\n  Videos","summary":"  In this paper, we target at the problem of learning a generalizable dynamic\nradiance field from monocular videos. Different from most existing NeRF methods\nthat are based on multiple views, monocular videos only contain one view at\neach timestamp, thereby suffering from ambiguity along the view direction in\nestimating point features and scene flows. Previous studies such as DynNeRF\ndisambiguate point features by positional encoding, which is not transferable\nand severely limits the generalization ability. As a result, these methods have\nto train one independent model for each scene and suffer from heavy\ncomputational costs when applying to increasing monocular videos in real-world\napplications. To address this, We propose MonoNeRF to simultaneously learn\npoint features and scene flows with point trajectory and feature correspondence\nconstraints across frames. More specifically, we learn an implicit velocity\nfield to estimate point trajectory from temporal features with Neural ODE,\nwhich is followed by a flow-based feature aggregation module to obtain spatial\nfeatures along the point trajectory. We jointly optimize temporal and spatial\nfeatures in an end-to-end manner. Experiments show that our MonoNeRF is able to\nlearn from multiple scenes and support new applications such as scene editing,\nunseen frame synthesis, and fast novel scene adaptation.\n","authors":["Fengrui Tian","Shaoyi Du","Yueqi Duan"],"pdf_url":"https://arxiv.org/pdf/2212.13056v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09430v3","updated":"2023-03-09T03:19:30Z","published":"2023-01-23T13:34:01Z","title":"RainDiffusion: When Unsupervised Learning Meets Diffusion Models for\n  Real-world Image Deraining","summary":"  Recent diffusion models show great potential in generative modeling tasks.\nThis motivates us to raise an intriguing question - What will happen when\nunsupervised learning meets diffusion models for real-world image deraining?\nBefore answering it, we observe two major obstacles of diffusion models in\nreal-world image deraining: the need for paired training data and the limited\nutilization of multi-scale rain patterns. To overcome the obstacles, we propose\nRainDiffusion, the first real-world image deraining paradigm based on diffusion\nmodels. RainDiffusion is a non-adversarial training paradigm that introduces\nstable training of unpaired real-world data, rather than weakly adversarial\ntraining, serving as a new standard bar for real-world image deraining. It\nconsists of two cooperative branches: Non-diffusive Translation Branch (NTB)\nand Diffusive Translation Branch (DTB). NTB exploits a cycle-consistent\narchitecture to bypass the difficulty in unpaired training of regular diffusion\nmodels by generating initial clean/rainy image pairs. Given initial image\npairs, DTB leverages multi-scale diffusion models to progressively refine the\ndesired output via diffusive generative and multi-scale priors, to obtain a\nbetter generalization capacity of real-world image deraining. Extensive\nexperiments confirm the superiority of our RainDiffusion over eight\nun/semi-supervised methods and show its competitive advantages over seven\nfully-supervised ones.\n","authors":["Mingqiang Wei","Yiyang Shen","Yongzhen Wang","Haoran Xie","Jing Qin","Fu Lee Wang"],"pdf_url":"https://arxiv.org/pdf/2301.09430v3.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2302.05881v2","updated":"2023-03-09T03:18:25Z","published":"2023-02-12T09:50:32Z","title":"Low-Rank Tensor Completion With Generalized CP Decomposition and\n  Nonnegative Integer Tensor Completion","summary":"  Tensor completion is important to many areas such as computer vision, data\nanalysis, and signal processing. Previously, a category of methods known as\nlow-rank tensor completion has been proposed and developed, involving the\nenforcement of low-rank structures on completed tensors. While such methods\nhave been constantly improved, none considered exploiting the numerical\nproperties of tensor elements. This work attempts to construct a new\nmethodological framework called GCDTC (Generalized CP Decomposition Tensor\nCompletion) based on numerical properties to achieve higher accuracy in tensor\ncompletion. In this newly introduced framework, a generalized form of the CP\nDecomposition is applied to low-rank tensor completion. This paper also\nproposes an algorithm known as SPTC (Smooth Poisson Tensor Completion) for\nnonnegative integer tensor completion as an application of the GCDTC framework.\nThrough experimentation with real-life data, it is verified that this method\ncould produce results superior in completion accuracy to current\nstate-of-the-art methodologies.\n","authors":["Shiran Yuan"],"pdf_url":"https://arxiv.org/pdf/2302.05881v2.pdf","comment":"10 pages, 4 figures, and 1 table"},{"id":"http://arxiv.org/abs/2303.05007v1","updated":"2023-03-09T03:16:04Z","published":"2023-03-09T03:16:04Z","title":"Towards Robust Image-in-Audio Deep Steganography","summary":"  The field of steganography has experienced a surge of interest due to the\nrecent advancements in AI-powered techniques, particularly in the context of\nmultimodal setups that enable the concealment of signals within signals of a\ndifferent nature. The primary objectives of all steganographic methods are to\nachieve perceptual transparency, robustness, and large embedding capacity -\nwhich often present conflicting goals that classical methods have struggled to\nreconcile. This paper extends and enhances an existing image-in-audio deep\nsteganography method by focusing on improving its robustness. The proposed\nenhancements include modifications to the loss function, utilization of the\nShort-Time Fourier Transform (STFT), introduction of redundancy in the encoding\nprocess for error correction, and buffering of additional information in the\npixel subconvolution operation. The results demonstrate that our approach\noutperforms the existing method in terms of robustness and perceptual\ntransparency.\n","authors":["Jaume Ros Alonso","Margarita Geleta","Jordi Pons","Xavier Giro-i-Nieto"],"pdf_url":"https://arxiv.org/pdf/2303.05007v1.pdf","comment":"8 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2206.03196v2","updated":"2023-03-09T02:46:41Z","published":"2022-06-07T11:38:03Z","title":"Improving Image Captioning with Control Signal of Sentence Quality","summary":"  In the dataset of image captioning, each image is aligned with several\ndescriptions. Despite the fact that the quality of these descriptions varies,\nexisting captioning models treat them equally in the training process. In this\npaper, we propose a new control signal of sentence quality, which is taken as\nan additional input to the captioning model. By integrating the control signal\ninformation, captioning models are aware of the quality level of the target\nsentences and handle them differently. Moreover, we propose a novel\nreinforcement training method specially designed for the control signal of\nsentence quality: Quality-oriented Self-Annotated Training (Q-SAT). Extensive\nexperiments on MSCOCO dataset show that without extra information from ground\ntruth captions, models controlled by the highest quality level outperform\nbaseline models on accuracy-based evaluation metrics, which validates the\neffectiveness of our proposed methods.\n","authors":["Zhangzi Zhu","Hong Qu"],"pdf_url":"https://arxiv.org/pdf/2206.03196v2.pdf","comment":"Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2303.04998v1","updated":"2023-03-09T02:43:10Z","published":"2023-03-09T02:43:10Z","title":"Rethinking Visual Prompt Learning as Masked Visual Token Modeling","summary":"  Prompt learning has achieved great success in efficiently exploiting\nlarge-scale pre-trained models in natural language processing (NLP). It\nreformulates the downstream tasks as the generative pre-training ones, thus\nnarrowing down the gap between them and improving the performance stably.\nHowever, when transferring it to the vision area, current visual prompt\nlearning methods are all designed on discriminative pre-trained models, and\nthere is also a lack of careful design to unify the forms of pre-training and\ndownstream tasks. To explore prompt learning on the generative pre-trained\nvisual model as well as keeping the task consistency, we propose Visual Prompt\nlearning as masked visual Token Modeling (VPTM) to transform the downstream\nvisual classification into the pre-trained masked visual token prediction. In\naddition, we develop the prototypical verbalizer for mapping the predicted\nvisual token with implicit semantics to explicit downstream labels. To our best\nknowledge, VPTM is the first visual prompt method on the generative pre-trained\nvisual model, and the first to achieve consistency between pre-training and\ndownstream visual classification by task reformulation. Experiments show that\nVPTM outperforms other visual prompt methods and achieves excellent efficiency.\nMoreover, the task consistency of VPTM contributes to the robustness against\nprompt location, prompt length and prototype dimension, and could be deployed\nuniformly.\n","authors":["Ning Liao","Bowen Shi","Min Cao","Xiaopeng Zhang","Qi Tian","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2303.04998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04997v1","updated":"2023-03-09T02:41:13Z","published":"2023-03-09T02:41:13Z","title":"Optimization-Based Eye Tracking using Deflectometric Information","summary":"  Eye tracking is an important tool with a wide range of applications in\nVirtual, Augmented, and Mixed Reality (VR/AR/MR) technologies. State-of-the-art\neye tracking methods are either reflection-based and track reflections of\nsparse point light sources, or image-based and exploit 2D features of the\nacquired eye image. In this work, we attempt to significantly improve\nreflection-based methods by utilizing pixel-dense deflectometric surface\nmeasurements in combination with optimization-based inverse rendering\nalgorithms. Utilizing the known geometry of our deflectometric setup, we\ndevelop a differentiable rendering pipeline based on PyTorch3D that simulates a\nvirtual eye under screen illumination. Eventually, we exploit the\nimage-screen-correspondence information from the captured measurements to find\nthe eye's rotation, translation, and shape parameters with our renderer via\ngradient descent. In general, our method does not require a specific pattern\nand can work with ordinary video frames of the main VR/AR/MR screen itself. We\ndemonstrate real-world experiments with evaluated mean relative gaze errors\nbelow 0.45 degrees at a precision better than 0.11 degrees. Moreover, we show\nan improvement of 6X over a representative reflection-based state-of-the-art\nmethod in simulation.\n","authors":["Tianfu Wang","Jiazhang Wang","Oliver Cossairt","Florian Willomitzer"],"pdf_url":"https://arxiv.org/pdf/2303.04997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04995v1","updated":"2023-03-09T02:38:32Z","published":"2023-03-09T02:38:32Z","title":"Text-Visual Prompting for Efficient 2D Temporal Video Grounding","summary":"  In this paper, we study the problem of temporal video grounding (TVG), which\naims to predict the starting/ending time points of moments described by a text\nsentence within a long untrimmed video. Benefiting from fine-grained 3D visual\nfeatures, the TVG techniques have achieved remarkable progress in recent years.\nHowever, the high complexity of 3D convolutional neural networks (CNNs) makes\nextracting dense 3D visual features time-consuming, which calls for intensive\nmemory and computing resources. Towards efficient TVG, we propose a novel\ntext-visual prompting (TVP) framework, which incorporates optimized\nperturbation patterns (that we call 'prompts') into both visual inputs and\ntextual features of a TVG model. In sharp contrast to 3D CNNs, we show that TVP\nallows us to effectively co-train vision encoder and language encoder in a 2D\nTVG model and improves the performance of crossmodal feature fusion using only\nlow-complexity sparse 2D visual features. The proposed prompts also compensate\nfor the lack of spatiotemporal information in 2D CNNs for visual feature\nextraction. Further, we propose a TemporalDistance IoU (TDIoU) loss for\nefficient learning of TVG. Last but not least, extensive experiments on two\nbenchmark datasets, Charades-STA and ActivityNet Captions datasets, empirically\nshow that the proposed TVP significantly boosts the performance of 2D TVG\n(e.g., 9.79% improvement in Charades-STA and 30.77% improvement in ActivityNet\nCaptions) and achieves 5x inference acceleration over TVG of using 3D visual\nfeatures. Code and model will be released.\n","authors":["Yimeng Zhang","Xin Chen","Jinghan Jia","Sijia Liu","Ke Ding"],"pdf_url":"https://arxiv.org/pdf/2303.04995v1.pdf","comment":"Accepted into the CVPR 2023"},{"id":"http://arxiv.org/abs/2301.01955v2","updated":"2023-03-09T02:34:59Z","published":"2023-01-05T08:37:36Z","title":"Adaptively Clustering Neighbor Elements for Image Captioning","summary":"  We design a novel global-local Transformer named \\textbf{Ada-ClustFormer}\n(\\textbf{ACF}) to generate captions. We use this name since each layer of ACF\ncan adaptively cluster input elements to carry self-attention (Self-ATT) for\nlearning local context. Compared with other global-local Transformers which\ncarry Self-ATT in fixed-size windows, ACF can capture varying graininess, \\eg,\nan object may cover different numbers of grids or a phrase may contain diverse\nnumbers of words. To build ACF, we insert a probabilistic matrix C into the\nSelf-ATT layer. For an input sequence {{s}_1,...,{s}_N , C_{i,j} softly\ndetermines whether the sub-sequence {s_i,...,s_j} should be clustered for\ncarrying Self-ATT. For implementation, {C}_{i,j} is calculated from the\ncontexts of {{s}_i,...,{s}_j}, thus ACF can exploit the input itself to decide\nwhich local contexts should be learned. By using ACF to build the vision\nencoder and language decoder, the captioning model can automatically discover\nthe hidden structures in both vision and language, which encourages the model\nto learn a unified structural space for transferring more structural\ncommonalities. The experiment results demonstrate the effectiveness of ACF that\nwe achieve CIDEr of 137.8, which outperforms most SOTA captioning models and\nachieve comparable scores compared with some BERT-based models. The code will\nbe available in the supplementary material.\n","authors":["Zihua Wang","Xu Yang","Haiyang Xu","Hanwang Zhang","and Qinghao Ye","Chenliang Li","and Weiwei Sun","Ming Yan","Songfang Huang","Fei Huang","Yu Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.01955v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04991v1","updated":"2023-03-09T02:24:30Z","published":"2023-03-09T02:24:30Z","title":"Deformer: Dynamic Fusion Transformer for Robust Hand Pose Estimation","summary":"  Accurately estimating 3D hand pose is crucial for understanding how humans\ninteract with the world. Despite remarkable progress, existing methods often\nstruggle to generate plausible hand poses when the hand is heavily occluded or\nblurred. In videos, the movements of the hand allow us to observe various parts\nof the hand that may be occluded or blurred in a single frame. To adaptively\nleverage the visual clue before and after the occlusion or blurring for robust\nhand pose estimation, we propose the Deformer: a framework that implicitly\nreasons about the relationship between hand parts within the same image\n(spatial dimension) and different timesteps (temporal dimension). We show that\na naive application of the transformer self-attention mechanism is not\nsufficient because motion blur or occlusions in certain frames can lead to\nheavily distorted hand features and generate imprecise keys and queries. To\naddress this challenge, we incorporate a Dynamic Fusion Module into Deformer,\nwhich predicts the deformation of the hand and warps the hand mesh predictions\nfrom nearby frames to explicitly support the current frame estimation.\nFurthermore, we have observed that errors are unevenly distributed across\ndifferent hand parts, with vertices around fingertips having disproportionately\nhigher errors than those around the palm. We mitigate this issue by introducing\na new loss function called maxMSE that automatically adjusts the weight of\nevery vertex to focus the model on critical hand parts. Extensive experiments\nshow that our method significantly outperforms state-of-the-art methods by 10%,\nand is more robust to occlusions (over 14%).\n","authors":["Qichen Fu","Xingyu Liu","Ran Xu","Juan Carlos Niebles","Kris M. Kitani"],"pdf_url":"https://arxiv.org/pdf/2303.04991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04989v1","updated":"2023-03-09T02:20:56Z","published":"2023-03-09T02:20:56Z","title":"ARS-DETR: Aspect Ratio Sensitive Oriented Object Detection with\n  Transformer","summary":"  Existing oriented object detection methods commonly use metric AP$_{50}$ to\nmeasure the performance of the model. We argue that AP$_{50}$ is inherently\nunsuitable for oriented object detection due to its large tolerance in angle\ndeviation. Therefore, we advocate using high-precision metric, e.g. AP$_{75}$,\nto measure the performance of models. In this paper, we propose an Aspect Ratio\nSensitive Oriented Object Detector with Transformer, termed ARS-DETR, which\nexhibits a competitive performance in high-precision oriented object detection.\nSpecifically, a new angle classification method, calling Aspect Ratio aware\nCircle Smooth Label (AR-CSL), is proposed to smooth the angle label in a more\nreasonable way and discard the hyperparameter that introduced by previous work\n(e.g. CSL). Then, a rotated deformable attention module is designed to rotate\nthe sampling points with the corresponding angles and eliminate the\nmisalignment between region features and sampling points. Moreover, a dynamic\nweight coefficient according to the aspect ratio is adopted to calculate the\nangle loss. Comprehensive experiments on several challenging datasets show that\nour method achieves competitive performance on the high-precision oriented\nobject detection task.\n","authors":["Ying Zeng","Xue Yang","Qingyun Li","Yushi Chen","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2303.04989v1.pdf","comment":"10 pages, 8 figures, 8 tables, the source code is available at\n  https://github.com/httle/ARS-DETR"},{"id":"http://arxiv.org/abs/2211.08229v3","updated":"2023-03-09T02:16:37Z","published":"2022-11-15T15:48:28Z","title":"CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive\n  Learning","summary":"  Contrastive learning (CL) pre-trains general-purpose encoders using an\nunlabeled pre-training dataset, which consists of images or image-text pairs.\nCL is vulnerable to data poisoning based backdoor attacks (DPBAs), in which an\nattacker injects poisoned inputs into the pre-training dataset so the encoder\nis backdoored. However, existing DPBAs achieve limited effectiveness. In this\nwork, we propose new DPBAs called CorruptEncoder to CL. CorruptEncoder uses a\ntheory-guided method to create optimal poisoned inputs to maximize attack\neffectiveness. Our experiments show that CorruptEncoder substantially\noutperforms existing DPBAs. In particular, CorruptEncoder is the first DPBA\nthat achieves more than 90% attack success rates with only a few (3) reference\nimages and a small poisoning ratio (0.5%). Moreover, we also propose a defense,\ncalled localized cropping, to defend against DPBAs. Our results show that our\ndefense can reduce the effectiveness of DPBAs, though it slightly sacrifices\nthe utility of the encoder.\n","authors":["Jinghuai Zhang","Hongbin Liu","Jinyuan Jia","Neil Zhenqiang Gong"],"pdf_url":"https://arxiv.org/pdf/2211.08229v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.06411v2","updated":"2023-03-09T02:16:14Z","published":"2022-08-12T01:20:51Z","title":"SFF-DA: Sptialtemporal Feature Fusion for Detecting Anxiety\n  Nonintrusively","summary":"  Early detection of anxiety is crucial for reducing the suffering of\nindividuals with mental disorders and improving treatment outcomes. Utilizing\nan mHealth platform for anxiety screening can be particularly practical in\nimproving screening efficiency and reducing costs. However, the effectiveness\nof existing methods has been hindered by differences in mobile devices used to\ncapture subjects' physical and mental evaluations, as well as by the\nvariability in data quality and small sample size problems encountered in\nreal-world settings. To address these issues, we propose a framework with\nspatiotemporal feature fusion for detecting anxiety nonintrusively. We use a\nfeature extraction network based on a 3D convolutional network and long\nshort-term memory (\"3DCNN+LSTM\") to fuse the spatiotemporal features of facial\nbehavior and noncontact physiology, which reduces the impact of uneven data\nquality. Additionally, we design a similarity assessment strategy to address\nthe issue of deteriorating model accuracy due to small sample sizes. Our\nframework is validated with a crew dataset from the real world and two public\ndatasets: the University of Burgundy Franche-Comt\\'e Psychophysiological\n(UBFC-Phys) dataset and the Smart Reasoning for Well-being at Home and at Work\nfor Knowledge Work (SWELL-KW) dataset. The experimental results indicate that\nour framework outperforms the comparison methods.\n","authors":["Haimiao Mo","Yuchen Li","Shanlin Yang","Wei Zhang","Shuai Ding"],"pdf_url":"https://arxiv.org/pdf/2208.06411v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09117v2","updated":"2023-03-09T02:07:01Z","published":"2022-09-15T15:41:47Z","title":"Part-Based Models Improve Adversarial Robustness","summary":"  We show that combining human prior knowledge with end-to-end learning can\nimprove the robustness of deep neural networks by introducing a part-based\nmodel for object classification. We believe that the richer form of annotation\nhelps guide neural networks to learn more robust features without requiring\nmore samples or larger models. Our model combines a part segmentation model\nwith a tiny classifier and is trained end-to-end to simultaneously segment\nobjects into parts and then classify the segmented object. Empirically, our\npart-based models achieve both higher accuracy and higher adversarial\nrobustness than a ResNet-50 baseline on all three datasets. For instance, the\nclean accuracy of our part models is up to 15 percentage points higher than the\nbaseline's, given the same level of robustness. Our experiments indicate that\nthese models also reduce texture bias and yield better robustness against\ncommon corruptions and spurious correlations. The code is publicly available at\nhttps://github.com/chawins/adv-part-model.\n","authors":["Chawin Sitawarin","Kornrapat Pongmala","Yizheng Chen","Nicholas Carlini","David Wagner"],"pdf_url":"https://arxiv.org/pdf/2209.09117v2.pdf","comment":"Published in ICLR 2023 (poster). Code can be found at\n  https://github.com/chawins/adv-part-model"},{"id":"http://arxiv.org/abs/2303.04980v1","updated":"2023-03-09T01:42:43Z","published":"2023-03-09T01:42:43Z","title":"Decision-BADGE: Decision-based Adversarial Batch Attack with Directional\n  Gradient Estimation","summary":"  The vulnerability of deep neural networks to adversarial examples has led to\nthe rise in the use of adversarial attacks. While various decision-based and\nuniversal attack methods have been proposed, none have attempted to create a\ndecision-based universal adversarial attack. This research proposes\nDecision-BADGE, which uses random gradient-free optimization and batch attack\nto generate universal adversarial perturbations for decision-based attacks.\nMultiple adversarial examples are combined to optimize a single universal\nperturbation, and the accuracy metric is reformulated into a continuous Hamming\ndistance form. The effectiveness of accuracy metric as a loss function is\ndemonstrated and mathematically proven. The combination of Decision-BADGE and\nthe accuracy loss function performs better than both score-based\nimage-dependent attack and white-box universal attack methods in terms of\nattack time efficiency. The research also shows that Decision-BADGE can\nsuccessfully deceive unseen victims and accurately target specific classes.\n","authors":["Geunhyeok Yu","Minwoo Jeon","Hyoseok Hwang"],"pdf_url":"https://arxiv.org/pdf/2303.04980v1.pdf","comment":"10 pages (8 pages except for references), 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2303.04803v2","updated":"2023-03-09T01:37:25Z","published":"2023-03-08T18:58:26Z","title":"Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion\n  Models","summary":"  We present ODISE: Open-vocabulary DIffusion-based panoptic SEgmentation,\nwhich unifies pre-trained text-image diffusion and discriminative models to\nperform open-vocabulary panoptic segmentation. Text-to-image diffusion models\nhave shown the remarkable capability of generating high-quality images with\ndiverse open-vocabulary language descriptions. This demonstrates that their\ninternal representation space is highly correlated with open concepts in the\nreal world. Text-image discriminative models like CLIP, on the other hand, are\ngood at classifying images into open-vocabulary labels. We propose to leverage\nthe frozen representation of both these models to perform panoptic segmentation\nof any category in the wild. Our approach outperforms the previous state of the\nart by significant margins on both open-vocabulary panoptic and semantic\nsegmentation tasks. In particular, with COCO training only, our method achieves\n23.4 PQ and 30.0 mIoU on the ADE20K dataset, with 8.3 PQ and 7.9 mIoU absolute\nimprovement over the previous state-of-the-art. Project page is available at\nhttps://jerryxu.net/ODISE .\n","authors":["Jiarui Xu","Sifei Liu","Arash Vahdat","Wonmin Byeon","Xiaolong Wang","Shalini De Mello"],"pdf_url":"https://arxiv.org/pdf/2303.04803v2.pdf","comment":"CVPR 2023. Project page: https://jerryxu.net/ODISE"},{"id":"http://arxiv.org/abs/2303.04976v1","updated":"2023-03-09T01:29:58Z","published":"2023-03-09T01:29:58Z","title":"Curvature-Sensitive Predictive Coding with Approximate Laplace Monte\n  Carlo","summary":"  Predictive coding (PC) accounts of perception now form one of the dominant\ncomputational theories of the brain, where they prescribe a general algorithm\nfor inference and learning over hierarchical latent probabilistic models.\nDespite this, they have enjoyed little export to the broader field of machine\nlearning, where comparative generative modelling techniques have flourished. In\npart, this has been due to the poor performance of models trained with PC when\nevaluated by both sample quality and marginal likelihood. By adopting the\nperspective of PC as a variational Bayes algorithm under the Laplace\napproximation, we identify the source of these deficits to lie in the exclusion\nof an associated Hessian term in the PC objective function, which would\notherwise regularise the sharpness of the probability landscape and prevent\nover-certainty in the approximate posterior. To remedy this, we make three\nprimary contributions: we begin by suggesting a simple Monte Carlo estimated\nevidence lower bound which relies on sampling from the Hessian-parameterised\nvariational posterior. We then derive a novel block diagonal approximation to\nthe full Hessian matrix that has lower memory requirements and favourable\nmathematical properties. Lastly, we present an algorithm that combines our\nmethod with standard PC to reduce memory complexity further. We evaluate models\ntrained with our approach against the standard PC framework on image benchmark\ndatasets. Our approach produces higher log-likelihoods and qualitatively better\nsamples that more closely capture the diversity of the data-generating\ndistribution.\n","authors":["Umais Zahid","Qinghai Guo","Karl Friston","Zafeirios Fountas"],"pdf_url":"https://arxiv.org/pdf/2303.04976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04393v2","updated":"2023-03-09T01:29:06Z","published":"2023-03-08T05:55:02Z","title":"Imbalanced Open Set Domain Adaptation via Moving-threshold Estimation\n  and Gradual Alignment","summary":"  Multimedia applications are often associated with cross-domain knowledge\ntransfer, where Unsupervised Domain Adaptation (UDA) can be used to reduce the\ndomain shifts. Open Set Domain Adaptation (OSDA) aims to transfer knowledge\nfrom a well-labeled source domain to an unlabeled target domain under the\nassumption that the target domain contains unknown classes. Existing OSDA\nmethods consistently lay stress on the covariate shift, ignoring the potential\nlabel shift problem. The performance of OSDA methods degrades drastically under\nintra-domain class imbalance and inter-domain label shift. However, little\nattention has been paid to this issue in the community. In this paper, the\nImbalanced Open Set Domain Adaptation (IOSDA) is explored where the covariate\nshift, label shift and category mismatch exist simultaneously. To alleviate the\nnegative effects raised by label shift in OSDA, we propose Open-set\nMoving-threshold Estimation and Gradual Alignment (OMEGA) - a novel\narchitecture that improves existing OSDA methods on class-imbalanced data.\nSpecifically, a novel unknown-aware target clustering scheme is proposed to\nform tight clusters in the target domain to reduce the negative effects of\nlabel shift and intra-domain class imbalance. Furthermore, moving-threshold\nestimation is designed to generate specific thresholds for each target sample\nrather than using one for all. Extensive experiments on IOSDA, OSDA and OPDA\nbenchmarks demonstrate that our method could significantly outperform existing\nstate-of-the-arts. Code and data are available at\nhttps://github.com/mendicant04/OMEGA.\n","authors":["Jinghan Ru","Jun Tian","Zhekai Du","Chengwei Xiao","Jingjing Li","Heng Tao Shen"],"pdf_url":"https://arxiv.org/pdf/2303.04393v2.pdf","comment":"11 pages, 5 figures, 7 tables"},{"id":"http://arxiv.org/abs/2108.03372v4","updated":"2023-03-09T01:23:31Z","published":"2021-08-07T05:50:47Z","title":"Neighborhood Consensus Contrastive Learning for Backward-Compatible\n  Representation","summary":"  In object re-identification (ReID), the development of deep learning\ntechniques often involves model updates and deployment. It is unbearable to\nre-embedding and re-index with the system suspended when deploying new models.\nTherefore, backward-compatible representation is proposed to enable \"new\"\nfeatures to be compared with \"old\" features directly, which means that the\ndatabase is active when there are both \"new\" and \"old\" features in it. Thus we\ncan scroll-refresh the database or even do nothing on the database to update.\n  The existing backward-compatible methods either require a strong overlap\nbetween old and new training data or simply conduct constraints at the instance\nlevel. Thus they are difficult in handling complicated cluster structures and\nare limited in eliminating the impact of outliers in old embeddings, resulting\nin a risk of damaging the discriminative capability of new features. In this\nwork, we propose a Neighborhood Consensus Contrastive Learning (NCCL) method.\nWith no assumptions about the new training data, we estimate the sub-cluster\nstructures of old embeddings. A new embedding is constrained with multiple old\nembeddings in both embedding space and discrimination space at the sub-class\nlevel. The effect of outliers diminished, as the multiple samples serve as\n\"mean teachers\". Besides, we also propose a scheme to filter the old embeddings\nwith low credibility, further improving the compatibility robustness. Our\nmethod ensures backward compatibility without impairing the accuracy of the new\nmodel. And it can even improve the new model's accuracy in most scenarios.\n","authors":["Shengsen Wu","Liang Chen","Yihang Lou","Yan Bai","Tao Bai","Minghua Deng","Lingyu Duan"],"pdf_url":"https://arxiv.org/pdf/2108.03372v4.pdf","comment":"Accepted by AAAI 2022"},{"id":"http://arxiv.org/abs/2303.04970v1","updated":"2023-03-09T01:07:06Z","published":"2023-03-09T01:07:06Z","title":"LMR: A Large-Scale Multi-Reference Dataset for Reference-based\n  Super-Resolution","summary":"  It is widely agreed that reference-based super-resolution (RefSR) achieves\nsuperior results by referring to similar high quality images, compared to\nsingle image super-resolution (SISR). Intuitively, the more references, the\nbetter performance. However, previous RefSR methods have all focused on\nsingle-reference image training, while multiple reference images are often\navailable in testing or practical applications. The root cause of such\ntraining-testing mismatch is the absence of publicly available multi-reference\nSR training datasets, which greatly hinders research efforts on multi-reference\nsuper-resolution. To this end, we construct a large-scale, multi-reference\nsuper-resolution dataset, named LMR. It contains 112,142 groups of 300x300\ntraining images, which is 10x of the existing largest RefSR dataset. The image\nsize is also much larger. More importantly, each group is equipped with 5\nreference images with different similarity levels. Furthermore, we propose a\nnew baseline method for multi-reference super-resolution: MRefSR, including a\nMulti-Reference Attention Module (MAM) for feature fusion of an arbitrary\nnumber of reference images, and a Spatial Aware Filtering Module (SAFM) for the\nfused feature selection. The proposed MRefSR achieves significant improvements\nover state-of-the-art approaches on both quantitative and qualitative\nevaluations. Our code and data would be made available soon.\n","authors":["Lin Zhang","Xin Li","Dongliang He","Errui Ding","Zhaoxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.04970v1.pdf","comment":"6 figures, 10 pages"},{"id":"http://arxiv.org/abs/2210.08057v3","updated":"2023-03-09T23:35:08Z","published":"2022-10-14T18:48:48Z","title":"Pishgu: Universal Path Prediction Network Architecture for Real-time\n  Cyber-physical Edge Systems","summary":"  Path prediction is an essential task for many real-world Cyber-Physical\nSystems (CPS) applications, from autonomous driving and traffic\nmonitoring/management to pedestrian/worker safety. These real-world CPS\napplications need a robust, lightweight path prediction that can provide a\nuniversal network architecture for multiple subjects (e.g., pedestrians and\nvehicles) from different perspectives. However, most existing algorithms are\ntailor-made for a unique subject with a specific camera perspective and\nscenario. This article presents Pishgu, a universal lightweight network\narchitecture, as a robust and holistic solution for path prediction. Pishgu's\narchitecture can adapt to multiple path prediction domains with different\nsubjects (vehicles, pedestrians), perspectives (bird's-eye, high-angle), and\nscenes (sidewalk, highway). Our proposed architecture captures the\ninter-dependencies within the subjects in each frame by taking advantage of\nGraph Isomorphism Networks and the attention module. We separately train and\nevaluate the efficacy of our architecture on three different CPS domains across\nmultiple perspectives (vehicle bird's-eye view, pedestrian bird's-eye view, and\nhuman high-angle view). Pishgu outperforms state-of-the-art solutions in the\nvehicle bird's-eye view domain by 42% and 61% and pedestrian high-angle view\ndomain by 23% and 22% in terms of ADE and FDE, respectively. Additionally, we\nanalyze the domain-specific details for various datasets to understand their\neffect on path prediction and model interpretation. Finally, we report the\nlatency and throughput for all three domains on multiple embedded platforms\nshowcasing the robustness and adaptability of Pishgu for real-world integration\ninto CPS applications.\n","authors":["Ghazal Alinezhad Noghre","Vinit Katariya","Armin Danesh Pazho","Christopher Neff","Hamed Tabkhi"],"pdf_url":"https://arxiv.org/pdf/2210.08057v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05620v1","updated":"2023-03-09T23:20:35Z","published":"2023-03-09T23:20:35Z","title":"CFR-ICL: Cascade-Forward Refinement with Iterative Click Loss for\n  Interactive Image Segmentation","summary":"  The click-based interactive segmentation aims to extract the object of\ninterest from an image with the guidance of user clicks. Recent work has\nachieved great overall performance by employing the segmentation from the\nprevious output. However, in most state-of-the-art approaches, 1) the inference\nstage involves inflexible heuristic rules and a separate refinement model; and\n2) the training cannot balance the number of user clicks and model performance.\nTo address the challenges, we propose a click-based and mask-guided interactive\nimage segmentation framework containing three novel components: Cascade-Forward\nRefinement (CFR), Iterative Click Loss (ICL), and SUEM image augmentation. The\nproposed ICL allows model training to improve segmentation and reduce user\ninteractions simultaneously. The CFR offers a unified inference framework to\ngenerate segmentation results in a coarse-to-fine manner. The proposed SUEM\naugmentation is a comprehensive way to create large and diverse training sets\nfor interactive image segmentation. Extensive experiments demonstrate the\nstate-of-the-art performance of the proposed approach on five public datasets.\nRemarkably, our model achieves an average of 2.9 and 7.5 clicks of NoC@95 on\nthe Berkeley and DAVIS sets, respectively, improving by 33.2% and 15.5% over\nthe previous state-of-the-art results. The code and trained model are available\nat https://github.com/TitorX/CFR-ICL-Interactive-Segmentation.\n","authors":["Shoukun Sun","Min Xian","Fei Xu","Tiankai Yao","Luca Capriotti"],"pdf_url":"https://arxiv.org/pdf/2303.05620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05617v1","updated":"2023-03-09T23:11:52Z","published":"2023-03-09T23:11:52Z","title":"KGNv2: Separating Scale and Pose Prediction for Keypoint-based 6-DoF\n  Grasp Pose Synthesis on RGB-D input","summary":"  We propose a new 6-DoF grasp pose synthesis approach from 2D/2.5D input based\non keypoints. Keypoint-based grasp detector from image input has demonstrated\npromising results in the previous study, where the additional visual\ninformation provided by color images compensates for the noisy depth\nperception. However, it relies heavily on accurately predicting the location of\nkeypoints in the image space. In this paper, we devise a new grasp generation\nnetwork that reduces the dependency on precise keypoint estimation. Given an\nRGB-D input, our network estimates both the grasp pose from keypoint detection\nas well as scale towards the camera. We further re-design the keypoint output\nspace in order to mitigate the negative impact of keypoint prediction noise to\nPerspective-n-Point (PnP) algorithm. Experiments show that the proposed method\noutperforms the baseline by a large margin, validating the efficacy of our\napproach. Finally, despite trained on simple synthetic objects, our method\ndemonstrate sim-to-real capacity by showing competitive results in real-world\nrobot experiments.\n","authors":["Yiye Chen","Ruinian Xu","Yunzhi Lin","Patricio A. Vela"],"pdf_url":"https://arxiv.org/pdf/2303.05617v1.pdf","comment":"Submitted to IROS2023"},{"id":"http://arxiv.org/abs/2211.15736v2","updated":"2023-03-09T21:02:41Z","published":"2022-11-28T19:33:39Z","title":"Post-training Quantization on Diffusion Models","summary":"  Denoising diffusion (score-based) generative models have recently achieved\nsignificant accomplishments in generating realistic and diverse data. These\napproaches define a forward diffusion process for transforming data into noise\nand a backward denoising process for sampling data from noise. Unfortunately,\nthe generation process of current denoising diffusion models is notoriously\nslow due to the lengthy iterative noise estimations, which rely on cumbersome\nneural networks. It prevents the diffusion models from being widely deployed,\nespecially on edge devices. Previous works accelerate the generation process of\ndiffusion model (DM) via finding shorter yet effective sampling trajectories.\nHowever, they overlook the cost of noise estimation with a heavy network in\nevery iteration. In this work, we accelerate generation from the perspective of\ncompressing the noise estimation network. Due to the difficulty of retraining\nDMs, we exclude mainstream training-aware compression paradigms and introduce\npost-training quantization (PTQ) into DM acceleration. However, the output\ndistributions of noise estimation networks change with time-step, making\nprevious PTQ methods fail in DMs since they are designed for single-time step\nscenarios. To devise a DM-specific PTQ method, we explore PTQ on DM in three\naspects: quantized operations, calibration dataset, and calibration metric. We\nsummarize and use several observations derived from all-inclusive\ninvestigations to formulate our method, which especially targets the unique\nmulti-time-step structure of DMs. Experimentally, our method can directly\nquantize full-precision DMs into 8-bit models while maintaining or even\nimproving their performance in a training-free manner. Importantly, our method\ncan serve as a plug-and-play module on other fast-sampling methods, e.g., DDIM.\n","authors":["Yuzhang Shang","Zhihang Yuan","Bin Xie","Bingzhe Wu","Yan Yan"],"pdf_url":"https://arxiv.org/pdf/2211.15736v2.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2201.10520v3","updated":"2023-03-09T20:01:31Z","published":"2022-01-21T22:21:31Z","title":"Adaptive Activation-based Structured Pruning","summary":"  Pruning is a promising approach to compress complex deep learning models in\norder to deploy them on resource-constrained edge devices. However, many\nexisting pruning solutions are based on unstructured pruning, which yields\nmodels that cannot efficiently run on commodity hardware and require users to\nmanually explore and tune the pruning process, which is time-consuming and\noften leads to sub-optimal results. To address these limitations, this paper\npresents an adaptive, activation-based, structured pruning approach to\nautomatically and efficiently generate small, accurate, and hardware-efficient\nmodels that meet user requirements. First, it proposes iterative structured\npruning using activation-based attention feature maps to effectively identify\nand prune unimportant filters. Then, it proposes adaptive pruning policies for\nautomatically meeting the pruning objectives of accuracy-critical,\nmemory-constrained, and latency-sensitive tasks. A comprehensive evaluation\nshows that the proposed method can substantially outperform the\nstate-of-the-art structured pruning works on CIFAR-10 and ImageNet datasets.\nFor example, on ResNet-56 with CIFAR-10, without any accuracy drop, our method\nachieves the largest parameter reduction (79.11%), outperforming the related\nworks by 22.81% to 66.07%, and the largest FLOPs reduction (70.13%),\noutperforming the related works by 14.13% to 26.53%.\n","authors":["Kaiqi Zhao","Animesh Jain","Ming Zhao"],"pdf_url":"https://arxiv.org/pdf/2201.10520v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05556v1","updated":"2023-03-09T19:31:14Z","published":"2023-03-09T19:31:14Z","title":"An Evaluation of Non-Contrastive Self-Supervised Learning for Federated\n  Medical Image Analysis","summary":"  Privacy and annotation bottlenecks are two major issues that profoundly\naffect the practicality of machine learning-based medical image analysis.\nAlthough significant progress has been made in these areas, these issues are\nnot yet fully resolved. In this paper, we seek to tackle these concerns head-on\nand systematically explore the applicability of non-contrastive self-supervised\nlearning (SSL) algorithms under federated learning (FL) simulations for medical\nimage analysis. We conduct thorough experimentation of recently proposed\nstate-of-the-art non-contrastive frameworks under standard FL setups. With the\nSoTA Contrastive Learning algorithm, SimCLR as our comparative baseline, we\nbenchmark the performances of our 4 chosen non-contrastive algorithms under\nnon-i.i.d. data conditions and with a varying number of clients. We present a\nholistic evaluation of these techniques on 6 standardized medical imaging\ndatasets. We further analyse different trends inferred from the findings of our\nresearch, with the aim to find directions for further research based on ours.\nTo the best of our knowledge, ours is the first to perform such a thorough\nanalysis of federated self-supervised learning for medical imaging. All of our\nsource code will be made public upon acceptance of the paper.\n","authors":["Soumitri Chattopadhyay","Soham Ganguly","Sreejit Chaudhury","Sayan Nag","Samiran Chattopadhyay"],"pdf_url":"https://arxiv.org/pdf/2303.05556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.03004v2","updated":"2023-03-09T19:27:59Z","published":"2022-11-06T01:41:02Z","title":"Bringing Online Egocentric Action Recognition into the wild","summary":"  To enable a safe and effective human-robot cooperation, it is crucial to\ndevelop models for the identification of human activities. Egocentric vision\nseems to be a viable solution to solve this problem, and therefore many works\nprovide deep learning solutions to infer human actions from first person\nvideos. However, although very promising, most of these do not consider the\nmajor challenges that comes with a realistic deployment, such as the\nportability of the model, the need for real-time inference, and the robustness\nwith respect to the novel domains (i.e., new spaces, users, tasks). With this\npaper, we set the boundaries that egocentric vision models should consider for\nrealistic applications, defining a novel setting of egocentric action\nrecognition in the wild, which encourages researchers to develop novel,\napplications-aware solutions. We also present a new model-agnostic technique\nthat enables the rapid repurposing of existing architectures in this new\ncontext, demonstrating the feasibility to deploy a model on a tiny device\n(Jetson Nano) and to perform the task directly on the edge with very low energy\nconsumption (2.4W on average at 50 fps). The code is publicly available at:\nhttps://github.com/EgocentricVision/EgoWild.\n","authors":["Gabriele Goletto","Mirco Planamente","Barbara Caputo","Giuseppe Averta"],"pdf_url":"https://arxiv.org/pdf/2211.03004v2.pdf","comment":"Accepted to RA-L, for associated video, see\n  https://www.youtube.com/watch?v=7rtynmoYnuw&t=9s"},{"id":"http://arxiv.org/abs/2303.05552v1","updated":"2023-03-09T19:19:56Z","published":"2023-03-09T19:19:56Z","title":"EfficientTempNet: Temporal Super-Resolution of Radar Rainfall","summary":"  Rainfall data collected by various remote sensing instruments such as radars\nor satellites has different space-time resolutions. This study aims to improve\nthe temporal resolution of radar rainfall products to help with more accurate\nclimate change modeling and studies. In this direction, we introduce a solution\nbased on EfficientNetV2, namely EfficientTempNet, to increase the temporal\nresolution of radar-based rainfall products from 10 minutes to 5 minutes. We\ntested EfficientRainNet over a dataset for the state of Iowa, US, and compared\nits performance to three different baselines to show that EfficientTempNet\npresents a viable option for better climate change monitoring.\n","authors":["Bekir Z Demiray","Muhammed Sit","Ibrahim Demir"],"pdf_url":"https://arxiv.org/pdf/2303.05552v1.pdf","comment":"Published as a workshop paper at Tackling Climate Change with Machine\n  Learning, ICLR 2023"},{"id":"http://arxiv.org/abs/2303.05546v1","updated":"2023-03-09T19:08:02Z","published":"2023-03-09T19:08:02Z","title":"Weakly-Supervised HOI Detection from Interaction Labels Only and\n  Language/Vision-Language Priors","summary":"  Human-object interaction (HOI) detection aims to extract interacting\nhuman-object pairs and their interaction categories from a given natural image.\nEven though the labeling effort required for building HOI detection datasets is\ninherently more extensive than for many other computer vision tasks,\nweakly-supervised directions in this area have not been sufficiently explored\ndue to the difficulty of learning human-object interactions with weak\nsupervision, rooted in the combinatorial nature of interactions over the object\nand predicate space. In this paper, we tackle HOI detection with the weakest\nsupervision setting in the literature, using only image-level interaction\nlabels, with the help of a pretrained vision-language model (VLM) and a large\nlanguage model (LLM). We first propose an approach to prune non-interacting\nhuman and object proposals to increase the quality of positive pairs within the\nbag, exploiting the grounding capability of the vision-language model. Second,\nwe use a large language model to query which interactions are possible between\na human and a given object category, in order to force the model not to put\nemphasis on unlikely interactions. Lastly, we use an auxiliary\nweakly-supervised preposition prediction task to make our model explicitly\nreason about space. Extensive experiments and ablations show that all of our\ncontributions increase HOI detection performance.\n","authors":["Mesut Erhan Unal","Adriana Kovashka"],"pdf_url":"https://arxiv.org/pdf/2303.05546v1.pdf","comment":"8 pages, 3 figures and 5 tables"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.09051v3","updated":"2023-03-09T17:25:10Z","published":"2023-02-17T18:31:31Z","title":"Complex QA and language models hybrid architectures, Survey","summary":"  This paper reviews the state-of-the-art of hybrid language models\narchitectures and strategies for \"complex\" question-answering (QA, CQA, CPS).\nLarge Language Models (LLM) are good at leveraging public data on standard\nproblems but once you want to tackle more specific complex questions or\nproblems you may need specific architecture, knowledge, skills, methods,\nsensitive data protection, explainability, human approval and versatile\nfeedback... We identify key elements augmenting LLM to solve complex questions\nor problems. We extend findings from the robust community edited research\npapers BIG, BLOOM and HELM which open source, benchmark and analyze limits and\nchallenges of LLM in terms of tasks complexity and strict evaluation on\naccuracy (e.g. fairness, robustness, toxicity, ...). Recent projects like\nChatGPT and GALACTICA have allowed non-specialists to grasp the great potential\nas well as the equally strong limitations of language models in complex QA.\nHybridizing these models with different components could allow to overcome\nthese different limits and go much further. We discuss some challenges\nassociated with complex QA, including domain adaptation, decomposition and\nefficient multi-step QA, long form and non-factoid QA, safety and\nmulti-sensitivity data protection, multimodal search, hallucinations,\nexplainability and truthfulness, temproal reasoning. Therefore, we analyze\ncurrent solutions and promising research trends, using elements such as: hybrid\nLLM architectures, active human reinforcement learning supervised with AI,\nprompting adaptation, neuro-symbolic and structured knowledge grounding,\nprogram synthesis, iterated decomposition and others.\n","authors":["Xavier Daull","Patrice Bellot","Emmanuel Bruno","Vincent Martin","Elisabeth Murisasco"],"pdf_url":"https://arxiv.org/pdf/2302.09051v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.14233v2","updated":"2023-03-09T10:56:28Z","published":"2021-09-29T07:14:22Z","title":"A Next Basket Recommendation Reality Check","summary":"  The goal of a next basket recommendation (NBR) system is to recommend items\nfor the next basket for a user, based on the sequence of their prior baskets.\nRecently, a number of methods with complex modules have been proposed that\nclaim state-of-the-art performance. They rarely look into the predicted basket\nand just provide intuitive reasons for the observed improvements, e.g., better\nrepresentation, capturing intentions or relations, etc. We provide a novel\nangle on the evaluation of next basket recommendation methods, centered on the\ndistinction between repetition and exploration: the next basket is typically\ncomposed of previously consumed items (i.e., repeat items) and new items (i.e,\nexplore items). We propose a set of metrics that measure the repeat/explore\nratio and performance of NBR models. Using these new metrics, we analyze\nstate-of-the-art NBR models. The results of our analysis help to clarify the\nextent of the actual progress achieved by existing NBR methods as well as the\nunderlying reasons for the improvements. Overall, our work sheds light on the\nevaluation problem of NBR and provides useful insights into the model design\nfor this task.\n","authors":["Ming Li","Sami Jullien","Mozhdeh Ariannezhad","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2109.14233v2.pdf","comment":"This paper has been accepted to ACM TOIS"},{"id":"http://arxiv.org/abs/2303.05103v1","updated":"2023-03-09T08:23:56Z","published":"2023-03-09T08:23:56Z","title":"Algorithmic neutrality","summary":"  Bias infects the algorithms that wield increasing control over our lives.\nPredictive policing systems overestimate crime in communities of color; hiring\nalgorithms dock qualified female candidates; and facial recognition software\nstruggles to recognize dark-skinned faces. Algorithmic bias has received\nsignificant attention. Algorithmic neutrality, in contrast, has been largely\nneglected. Algorithmic neutrality is my topic. I take up three questions. What\nis algorithmic neutrality? Is algorithmic neutrality possible? When we have an\neye to algorithmic neutrality, what can we learn about algorithmic bias? To\nanswer these questions in concrete terms, I work with a case study: search\nengines. Drawing on work about neutrality in science, I say that a search\nengine is neutral only if certain values, like political ideologies or the\nfinancial interests of the search engine operator, play no role in how the\nsearch engine ranks pages. Search neutrality, I argue, is impossible. Its\nimpossibility seems to threaten the significance of search bias: if no search\nengine is neutral, then every search engine is biased. To defuse this threat, I\ndistinguish two forms of bias, failing-on-its-own-terms bias and other-values\nbias. This distinction allows us to make sense of search bias, and capture its\nnormative complexion, despite the impossibility of neutrality.\n","authors":["Milo Phillips-Brown"],"pdf_url":"https://arxiv.org/pdf/2303.05103v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2303.05039v1","updated":"2023-03-09T05:20:17Z","published":"2023-03-09T05:20:17Z","title":"Improving Recommendation Systems with User Personality Inferred from\n  Product Reviews","summary":"  Personality is a psychological factor that reflects people's preferences,\nwhich in turn influences their decision-making. We hypothesize that accurate\nmodeling of users' personalities improves recommendation systems' performance.\nHowever, acquiring such personality profiles is both sensitive and expensive.\nWe address this problem by introducing a novel method to automatically extract\npersonality profiles from public product review text. We then design and assess\nthree context-aware recommendation architectures that leverage the profiles to\ntest our hypothesis.\n  Experiments on our two newly contributed personality datasets --\nAmazon-beauty and Amazon-music -- validate our hypothesis, showing performance\nboosts of 3--28%.Our analysis uncovers that varying personality types\ncontribute differently to recommendation performance: open and extroverted\npersonalities are most helpful in music recommendation, while a conscientious\npersonality is most helpful in beauty product recommendation. The dataset is\navailable at https://github.com/XinyuanLu00/IRS-WSDM2023-personality-dataset.\n","authors":["Xinyuan Lu","Min-Yen Kan"],"pdf_url":"https://arxiv.org/pdf/2303.05039v1.pdf","comment":"Accepted by IRS@WSDM'23"},{"id":"http://arxiv.org/abs/2301.00767v2","updated":"2023-03-09T04:40:23Z","published":"2022-12-27T08:09:45Z","title":"A Survey on Federated Recommendation Systems","summary":"  Federated learning has recently been applied to recommendation systems to\nprotect user privacy. In federated learning settings, recommendation systems\ncan train recommendation models only collecting the intermediate parameters\ninstead of the real user data, which greatly enhances the user privacy. Beside,\nfederated recommendation systems enable to collaborate with other data\nplatforms to improve recommended model performance while meeting the regulation\nand privacy constraints. However, federated recommendation systems faces many\nnew challenges such as privacy, security, heterogeneity and communication\ncosts. While significant research has been conducted in these areas, gaps in\nthe surveying literature still exist. In this survey, we-(1) summarize some\ncommon privacy mechanisms used in federated recommendation systems and discuss\nthe advantages and limitations of each mechanism; (2) review some robust\naggregation strategies and several novel attacks against security; (3)\nsummarize some approaches to address heterogeneity and communication costs\nproblems; (4)introduce some open source platforms that can be used to build\nfederated recommendation systems; (5) present some prospective research\ndirections in the future. This survey can guide researchers and practitioners\nunderstand the research progress in these areas.\n","authors":["Zehua Sun","Yonghui Xu","Yong Liu","Wei He","Lanju Kong","Fangzhao Wu","Yali Jiang","Lizhen Cui"],"pdf_url":"https://arxiv.org/pdf/2301.00767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05582v1","updated":"2023-03-09T21:13:32Z","published":"2023-03-09T21:13:32Z","title":"Generalization analysis of an unfolding network for analysis-based\n  Compressed Sensing","summary":"  Unfolding networks have shown promising results in the Compressed Sensing\n(CS) field. Yet, the investigation of their generalization ability is still in\nits infancy. In this paper, we perform generalization analysis of a\nstate-of-the-art ADMM-based unfolding network, which jointly learns a decoder\nfor CS and a sparsifying redundant analysis operator. To this end, we first\nimpose a structural constraint on the learnable sparsifier, which parametrizes\nthe network's hypothesis class. For the latter, we estimate its Rademacher\ncomplexity. With this estimate in hand, we deliver generalization error bounds\nfor the examined network. Finally, the validity of our theory is assessed and\nnumerical comparisons to a state-of-the-art unfolding network are made, on\nsynthetic and real-world datasets. Our experimental results demonstrate that\nour proposed framework complies with our theoretical findings and outperforms\nthe baseline, consistently for all datasets.\n","authors":["Vicky Kouni","Yannis Panagakis"],"pdf_url":"https://arxiv.org/pdf/2303.05582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05575v1","updated":"2023-03-09T20:51:18Z","published":"2023-03-09T20:51:18Z","title":"Evaluating the Robustness of Conversational Recommender Systems by\n  Adversarial Examples","summary":"  Conversational recommender systems (CRSs) are improving rapidly, according to\nthe standard recommendation accuracy metrics. However, it is essential to make\nsure that these systems are robust in interacting with users including regular\nand malicious users who want to attack the system by feeding the system\nmodified input data. In this paper, we propose an adversarial evaluation scheme\nincluding four scenarios in two categories and automatically generate\nadversarial examples to evaluate the robustness of these systems in the face of\ndifferent input data. By executing these adversarial examples we can compare\nthe ability of different conversational recommender systems to satisfy the\nuser's preferences. We evaluate three CRSs by the proposed adversarial examples\non two datasets. Our results show that none of these systems are robust and\nreliable to the adversarial examples.\n","authors":["Ali Montazeralghaem","James Allan"],"pdf_url":"https://arxiv.org/pdf/2303.05575v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2303.06016v1","updated":"2023-03-09T12:13:46Z","published":"2023-03-09T12:13:46Z","title":"Modelling Projection Bias in Intertemporal Choices: A Prospect Theory\n  Based Approach","summary":"  Users often face bundle promotions when purchasing, where they have to select\nbetween two options: buy the single item at full price, or buy the bundle at a\ndiscount. In this scenario, users' preferences are usually influenced by the\nprojection bias, that is, users often believe that their future preferences are\nsimilar to their current preferences, causing them to make irrational and\nshort-sighted decisions. It is of great significance to analyze the effect of\nthe projection bias on users' preferences, and this study may help understand\nusers' decision-making process and provide bundling and pricing strategies for\nsellers. Prior works typically use a linear bias model for qualitative\nanalysis, and they cannot quantitatively calculate users' nonlinear and\npersonalized bias. In this work, we propose Pobe, a projection bias-embedded\npreference model to accurately predict users' choices. The proposed Pobe\nintroduces the prospect theory to analyze users' irrational decisions, and\nutilizes the weight function to handle users' nonlinear and personalized bias.\nBased on the proposed Pobe, we also study the impact of items' correlations or\ndiscount prices on users' choices, and provide four bundling strategies.\nExperimental results show that the proposed method can achieve better\nperformance than prior works, especially when only small data is available.\n","authors":["Qingming Li","H. Vicky Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.06016v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2303.05512v1","updated":"2023-03-09T18:59:50Z","published":"2023-03-09T18:59:50Z","title":"PAC-NeRF: Physics Augmented Continuum Neural Radiance Fields for\n  Geometry-Agnostic System Identification","summary":"  Existing approaches to system identification (estimating the physical\nparameters of an object) from videos assume known object geometries. This\nprecludes their applicability in a vast majority of scenes where object\ngeometries are complex or unknown. In this work, we aim to identify parameters\ncharacterizing a physical system from a set of multi-view videos without any\nassumption on object geometry or topology. To this end, we propose \"Physics\nAugmented Continuum Neural Radiance Fields\" (PAC-NeRF), to estimate both the\nunknown geometry and physical parameters of highly dynamic objects from\nmulti-view videos. We design PAC-NeRF to only ever produce physically plausible\nstates by enforcing the neural radiance field to follow the conservation laws\nof continuum mechanics. For this, we design a hybrid Eulerian-Lagrangian\nrepresentation of the neural radiance field, i.e., we use the Eulerian grid\nrepresentation for NeRF density and color fields, while advecting the neural\nradiance fields via Lagrangian particles. This hybrid Eulerian-Lagrangian\nrepresentation seamlessly blends efficient neural rendering with the material\npoint method (MPM) for robust differentiable physics simulation. We validate\nthe effectiveness of our proposed framework on geometry and physical parameter\nestimation over a vast range of materials, including elastic bodies,\nplasticine, sand, Newtonian and non-Newtonian fluids, and demonstrate\nsignificant performance gain on most tasks.\n","authors":["Xuan Li","Yi-Ling Qiao","Peter Yichen Chen","Krishna Murthy Jatavallabhula","Ming Lin","Chenfanfu Jiang","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2303.05512v1.pdf","comment":"ICLR 2023 Spotlight. Project page:\n  https://sites.google.com/view/PAC-NeRF"},{"id":"http://arxiv.org/abs/2303.05510v1","updated":"2023-03-09T18:59:47Z","published":"2023-03-09T18:59:47Z","title":"Planning with Large Language Models for Code Generation","summary":"  Existing large language model-based code generation pipelines typically use\nbeam search or sampling algorithms during the decoding process. Although the\nprograms they generate achieve high token-matching-based scores, they often\nfail to compile or generate incorrect outputs. The main reason is that\nconventional Transformer decoding algorithms may not be the best choice for\ncode generation. In this work, we propose a novel Transformer decoding\nalgorithm, Planning-Guided Transformer Decoding (PG-TD), that uses a planning\nalgorithm to do lookahead search and guide the Transformer to generate better\nprograms. Specifically, instead of simply optimizing the likelihood of the\ngenerated sequences, the Transformer makes use of a planner to generate\ncandidate programs and test them on public test cases. The Transformer can\ntherefore make more informed decisions and generate tokens that will eventually\nlead to higher-quality programs. We also design a mechanism that shares\ninformation between the Transformer and the planner to make our algorithm\ncomputationally efficient. We empirically evaluate our framework with several\nlarge language models as backbones on public coding challenge benchmarks,\nshowing that 1) it can generate programs that consistently achieve higher\nperformance compared with competing baseline methods; 2) it enables\ncontrollable code generation, such as concise codes and highly-commented codes\nby optimizing modified objective.\n","authors":["Shun Zhang","Zhenfang Chen","Yikang Shen","Mingyu Ding","Joshua B. Tenenbaum","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2303.05510v1.pdf","comment":"ICLR 2023. Project page:https://codeaimcts.github.io"},{"id":"http://arxiv.org/abs/2303.05511v1","updated":"2023-03-09T18:59:47Z","published":"2023-03-09T18:59:47Z","title":"Scaling up GANs for Text-to-Image Synthesis","summary":"  The recent success of text-to-image synthesis has taken the world by storm\nand captured the general public's imagination. From a technical standpoint, it\nalso marked a drastic change in the favored architecture to design generative\nimage models. GANs used to be the de facto choice, with techniques like\nStyleGAN. With DALL-E 2, auto-regressive and diffusion models became the new\nstandard for large-scale generative models overnight. This rapid shift raises a\nfundamental question: can we scale up GANs to benefit from large datasets like\nLAION? We find that na\\\"Ively increasing the capacity of the StyleGAN\narchitecture quickly becomes unstable. We introduce GigaGAN, a new GAN\narchitecture that far exceeds this limit, demonstrating GANs as a viable option\nfor text-to-image synthesis. GigaGAN offers three major advantages. First, it\nis orders of magnitude faster at inference time, taking only 0.13 seconds to\nsynthesize a 512px image. Second, it can synthesize high-resolution images, for\nexample, 16-megapixel pixels in 3.66 seconds. Finally, GigaGAN supports various\nlatent space editing applications such as latent interpolation, style mixing,\nand vector arithmetic operations.\n","authors":["Minguk Kang","Jun-Yan Zhu","Richard Zhang","Jaesik Park","Eli Shechtman","Sylvain Paris","Taesung Park"],"pdf_url":"https://arxiv.org/pdf/2303.05511v1.pdf","comment":"CVPR 2023. Project webpage at https://mingukkang.github.io/GigaGAN/"},{"id":"http://arxiv.org/abs/2302.02948v3","updated":"2023-03-09T18:59:27Z","published":"2023-02-06T17:30:22Z","title":"Efficient Online Reinforcement Learning with Offline Data","summary":"  Sample efficiency and exploration remain major challenges in online\nreinforcement learning (RL). A powerful approach that can be applied to address\nthese issues is the inclusion of offline data, such as prior trajectories from\na human expert or a sub-optimal exploration policy. Previous methods have\nrelied on extensive modifications and additional complexity to ensure the\neffective use of this data. Instead, we ask: can we simply apply existing\noff-policy methods to leverage offline data when learning online? In this work,\nwe demonstrate that the answer is yes; however, a set of minimal but important\nchanges to existing off-policy RL algorithms are required to achieve reliable\nperformance. We extensively ablate these design choices, demonstrating the key\nfactors that most affect performance, and arrive at a set of recommendations\nthat practitioners can readily apply, whether their data comprise a small\nnumber of expert demonstrations or large volumes of sub-optimal trajectories.\nWe see that correct application of these simple recommendations can provide a\n$\\mathbf{2.5\\times}$ improvement over existing approaches across a diverse set\nof competitive benchmarks, with no additional computational overhead.\n","authors":["Philip J. Ball","Laura Smith","Ilya Kostrikov","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2302.02948v3.pdf","comment":"To reproduce our results and use our codebase, see\n  https://github.com/ikostrikov/rlpd"},{"id":"http://arxiv.org/abs/2303.05506v1","updated":"2023-03-09T18:57:13Z","published":"2023-03-09T18:57:13Z","title":"TANGOS: Regularizing Tabular Neural Networks through Gradient\n  Orthogonalization and Specialization","summary":"  Despite their success with unstructured data, deep neural networks are not\nyet a panacea for structured tabular data. In the tabular domain, their\nefficiency crucially relies on various forms of regularization to prevent\noverfitting and provide strong generalization performance. Existing\nregularization techniques include broad modelling decisions such as choice of\narchitecture, loss functions, and optimization methods. In this work, we\nintroduce Tabular Neural Gradient Orthogonalization and Specialization\n(TANGOS), a novel framework for regularization in the tabular setting built on\nlatent unit attributions. The gradient attribution of an activation with\nrespect to a given input feature suggests how the neuron attends to that\nfeature, and is often employed to interpret the predictions of deep networks.\nIn TANGOS, we take a different approach and incorporate neuron attributions\ndirectly into training to encourage orthogonalization and specialization of\nlatent attributions in a fully-connected network. Our regularizer encourages\nneurons to focus on sparse, non-overlapping input features and results in a set\nof diverse and specialized latent units. In the tabular domain, we demonstrate\nthat our approach can lead to improved out-of-sample generalization\nperformance, outperforming other popular regularization methods. We provide\ninsight into why our regularizer is effective and demonstrate that TANGOS can\nbe applied jointly with existing methods to achieve even greater generalization\nperformance.\n","authors":["Alan Jeffares","Tennison Liu","Jonathan Crabbé","Fergus Imrie","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2303.05506v1.pdf","comment":"Published at International Conference on Learning Representations\n  (ICLR) 2023"},{"id":"http://arxiv.org/abs/2303.05504v1","updated":"2023-03-09T18:55:19Z","published":"2023-03-09T18:55:19Z","title":"Computable Phenotypes to Characterize Changing Patient Brain Dysfunction\n  in the Intensive Care Unit","summary":"  In the United States, more than 5 million patients are admitted annually to\nICUs, with ICU mortality of 10%-29% and costs over $82 billion. Acute brain\ndysfunction status, delirium, is often underdiagnosed or undervalued. This\nstudy's objective was to develop automated computable phenotypes for acute\nbrain dysfunction states and describe transitions among brain dysfunction\nstates to illustrate the clinical trajectories of ICU patients. We created two\nsingle-center, longitudinal EHR datasets for 48,817 adult patients admitted to\nan ICU at UFH Gainesville (GNV) and Jacksonville (JAX). We developed algorithms\nto quantify acute brain dysfunction status including coma, delirium, normal, or\ndeath at 12-hour intervals of each ICU admission and to identify acute brain\ndysfunction phenotypes using continuous acute brain dysfunction status and\nk-means clustering approach. There were 49,770 admissions for 37,835 patients\nin UFH GNV dataset and 18,472 admissions for 10,982 patients in UFH JAX\ndataset. In total, 18% of patients had coma as the worst brain dysfunction\nstatus; every 12 hours, around 4%-7% would transit to delirium, 22%-25% would\nrecover, 3%-4% would expire, and 67%-68% would remain in a coma in the ICU.\nAdditionally, 7% of patients had delirium as the worst brain dysfunction\nstatus; around 6%-7% would transit to coma, 40%-42% would be no delirium, 1%\nwould expire, and 51%-52% would remain delirium in the ICU. There were three\nphenotypes: persistent coma/delirium, persistently normal, and transition from\ncoma/delirium to normal almost exclusively in first 48 hours after ICU\nadmission. We developed phenotyping scoring algorithms that determined acute\nbrain dysfunction status every 12 hours while admitted to the ICU. This\napproach may be useful in developing prognostic and decision-support tools to\naid patients and clinicians in decision-making on resource use and escalation\nof care.\n","authors":["Yuanfang Ren","Tyler J. Loftus","Ziyuan Guan","Rayon Uddin","Benjamin Shickel","Carolina B. Maciel","Katharina Busl","Parisa Rashidi","Azra Bihorac","Tezcan Ozrazgat-Baslanti"],"pdf_url":"https://arxiv.org/pdf/2303.05504v1.pdf","comment":"21 pages, 5 figures, 3 tables, 1 eTable"},{"id":"http://arxiv.org/abs/2303.05503v1","updated":"2023-03-09T18:55:03Z","published":"2023-03-09T18:55:03Z","title":"Open-world Instance Segmentation: Top-down Learning with Bottom-up\n  Supervision","summary":"  Many top-down architectures for instance segmentation achieve significant\nsuccess when trained and tested on pre-defined closed-world taxonomy. However,\nwhen deployed in the open world, they exhibit notable bias towards seen classes\nand suffer from significant performance drop. In this work, we propose a novel\napproach for open world instance segmentation called bottom-Up and top-Down\nOpen-world Segmentation (UDOS) that combines classical bottom-up segmentation\nalgorithms within a top-down learning framework. UDOS first predicts parts of\nobjects using a top-down network trained with weak supervision from bottom-up\nsegmentations. The bottom-up segmentations are class-agnostic and do not\noverfit to specific taxonomies. The part-masks are then fed into affinity-based\ngrouping and refinement modules to predict robust instance-level segmentations.\nUDOS enjoys both the speed and efficiency from the top-down architectures and\nthe generalization ability to unseen categories from bottom-up supervision. We\nvalidate the strengths of UDOS on multiple cross-category as well as\ncross-dataset transfer tasks from 5 challenging datasets including MS-COCO,\nLVIS, ADE20k, UVO and OpenImages, achieving significant improvements over\nstate-of-the-art across the board. Our code and models are available on our\nproject page.\n","authors":["Tarun Kalluri","Weiyao Wang","Heng Wang","Manmohan Chandraker","Lorenzo Torresani","Du Tran"],"pdf_url":"https://arxiv.org/pdf/2303.05503v1.pdf","comment":"Project page: https://tarun005.github.io/UDOS"},{"id":"http://arxiv.org/abs/2301.01850v4","updated":"2023-03-09T18:54:31Z","published":"2023-01-04T23:28:58Z","title":"Bayesian Weapon System Reliability Modeling with Cox-Weibull Neural\n  Network","summary":"  We propose to integrate weapon system features (such as weapon system\nmanufacturer, deployment time and location, storage time and location, etc.)\ninto a parameterized Cox-Weibull [1] reliability model via a neural network,\nlike DeepSurv [2], to improve predictive maintenance. In parallel, we develop\nan alternative Bayesian model by parameterizing the Weibull parameters with a\nneural network and employing dropout methods such as Monte-Carlo (MC)-dropout\nfor comparative purposes. Due to data collection procedures in weapon system\ntesting we employ a novel interval-censored log-likelihood which incorporates\nMonte-Carlo Markov Chain (MCMC) [3] sampling of the Weibull parameters during\ngradient descent optimization. We compare classification metrics such as\nreceiver operator curve (ROC) area under the curve (AUC), precision-recall (PR)\nAUC, and F scores to show our model generally outperforms traditional powerful\nmodels such as XGBoost and the current standard conditional Weibull probability\ndensity estimation model.\n","authors":["Michael Potter","Benny Cheng"],"pdf_url":"https://arxiv.org/pdf/2301.01850v4.pdf","comment":"Pre-print with minor revisions, published at The 69th Annual\n  Reliability and Maintainability Symposium, January 23-26, 2023, FL, USA"},{"id":"http://arxiv.org/abs/2303.05501v1","updated":"2023-03-09T18:54:12Z","published":"2023-03-09T18:54:12Z","title":"PDSketch: Integrated Planning Domain Programming and Learning","summary":"  This paper studies a model learning and online planning approach towards\nbuilding flexible and general robots. Specifically, we investigate how to\nexploit the locality and sparsity structures in the underlying environmental\ntransition model to improve model generalization, data-efficiency, and\nruntime-efficiency. We present a new domain definition language, named\nPDSketch. It allows users to flexibly define high-level structures in the\ntransition models, such as object and feature dependencies, in a way similar to\nhow programmers use TensorFlow or PyTorch to specify kernel sizes and hidden\ndimensions of a convolutional neural network. The details of the transition\nmodel will be filled in by trainable neural networks. Based on the defined\nstructures and learned parameters, PDSketch automatically generates\ndomain-independent planning heuristics without additional training. The derived\nheuristics accelerate the performance-time planning for novel goals.\n","authors":["Jiayuan Mao","Tomás Lozano-Pérez","Joshua B. Tenenbaum","Leslie Pack Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2303.05501v1.pdf","comment":"NeurIPS 2022. Project page: https://pdsketch.csail.mit.edu"},{"id":"http://arxiv.org/abs/2303.05498v1","updated":"2023-03-09T18:51:31Z","published":"2023-03-09T18:51:31Z","title":"Mark My Words: Dangers of Watermarked Images in ImageNet","summary":"  The utilization of pre-trained networks, especially those trained on\nImageNet, has become a common practice in Computer Vision. However, prior\nresearch has indicated that a significant number of images in the ImageNet\ndataset contain watermarks, making pre-trained networks susceptible to learning\nartifacts such as watermark patterns within their latent spaces. In this paper,\nwe aim to assess the extent to which popular pre-trained architectures display\nsuch behavior and to determine which classes are most affected. Additionally,\nwe examine the impact of watermarks on the extracted features. Contrary to the\npopular belief that the Chinese logographic watermarks impact the \"carton\"\nclass only, our analysis reveals that a variety of ImageNet classes, such as\n\"monitor\", \"broom\", \"apron\" and \"safe\" rely on spurious correlations. Finally,\nwe propose a simple approach to mitigate this issue in fine-tuned networks by\nignoring the encodings from the feature-extractor layer of ImageNet pre-trained\nnetworks that are most susceptible to watermark imprints.\n","authors":["Kirill Bykov","Klaus-Robert Müller","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2303.05498v1.pdf","comment":"5 pages, 4 figures, Accepted to the ICLR 2023 TrustML-(un)Limited\n  workshop"},{"id":"http://arxiv.org/abs/2303.05497v1","updated":"2023-03-09T18:50:15Z","published":"2023-03-09T18:50:15Z","title":"Learning Stationary Markov Processes with Contrastive Adjustment","summary":"  We introduce a new optimization algorithm, termed \\emph{contrastive\nadjustment}, for learning Markov transition kernels whose stationary\ndistribution matches the data distribution. Contrastive adjustment is not\nrestricted to a particular family of transition distributions and can be used\nto model data in both continuous and discrete state spaces. Inspired by recent\nwork on noise-annealed sampling, we propose a particular transition operator,\nthe \\emph{noise kernel}, that can trade mixing speed for sample fidelity. We\nshow that contrastive adjustment is highly valuable in human-computer design\nprocesses, as the stationarity of the learned Markov chain enables local\nexploration of the data manifold and makes it possible to iteratively refine\noutputs by human feedback. We compare the performance of noise kernels trained\nwith contrastive adjustment to current state-of-the-art generative models and\ndemonstrate promising results on a variety of image synthesis tasks.\n","authors":["Ludvig Bergenstråhle","Jens Lagergren","Joakim Lundeberg"],"pdf_url":"https://arxiv.org/pdf/2303.05497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05496v1","updated":"2023-03-09T18:50:14Z","published":"2023-03-09T18:50:14Z","title":"Sparse and Local Networks for Hypergraph Reasoning","summary":"  Reasoning about the relationships between entities from input facts (e.g.,\nwhether Ari is a grandparent of Charlie) generally requires explicit\nconsideration of other entities that are not mentioned in the query (e.g., the\nparents of Charlie). In this paper, we present an approach for learning to\nsolve problems of this kind in large, real-world domains, using sparse and\nlocal hypergraph neural networks (SpaLoc). SpaLoc is motivated by two\nobservations from traditional logic-based reasoning: relational inferences\nusually apply locally (i.e., involve only a small number of individuals), and\nrelations are usually sparse (i.e., only hold for a small percentage of tuples\nin a domain). We exploit these properties to make learning and inference\nefficient in very large domains by (1) using a sparse tensor representation for\nhypergraph neural networks, (2) applying a sparsification loss during training\nto encourage sparse representations, and (3) subsampling based on a novel\ninformation sufficiency-based sampling process during training. SpaLoc achieves\nstate-of-the-art performance on several real-world, large-scale knowledge graph\nreasoning benchmarks, and is the first framework for applying hypergraph neural\nnetworks on real-world knowledge graphs with more than 10k nodes.\n","authors":["Guangxuan Xiao","Leslie Pack Kaelbling","Jiajun Wu","Jiayuan Mao"],"pdf_url":"https://arxiv.org/pdf/2303.05496v1.pdf","comment":"Learning on Graphs Conference (LoG) 2022. Project page:\n  https://spaloc.csail.mit.edu"},{"id":"http://arxiv.org/abs/2201.13094v3","updated":"2023-03-09T18:44:56Z","published":"2022-01-31T10:03:46Z","title":"Designing Universal Causal Deep Learning Models: The Geometric\n  (Hyper)Transformer","summary":"  Several problems in stochastic analysis are defined through their geometry,\nand preserving that geometric structure is essential to generating meaningful\npredictions. Nevertheless, how to design principled deep learning (DL) models\ncapable of encoding these geometric structures remains largely unknown. We\naddress this open problem by introducing a universal causal geometric DL\nframework in which the user specifies a suitable pair of metric spaces\n$\\mathscr{X}$ and $\\mathscr{Y}$ and our framework returns a DL model capable of\ncausally approximating any ``regular'' map sending time series in\n$\\mathscr{X}^{\\mathbb{Z}}$ to time series in $\\mathscr{Y}^{\\mathbb{Z}}$ while\nrespecting their forward flow of information throughout time. Suitable\ngeometries on $\\mathscr{Y}$ include various (adapted) Wasserstein spaces\narising in optimal stopping problems, a variety of statistical manifolds\ndescribing the conditional distribution of continuous-time finite state Markov\nchains, and all Fr\\'{e}chet spaces admitting a Schauder basis, e.g. as in\nclassical finance. Suitable spaces $\\mathscr{X}$ are compact subsets of any\nEuclidean space. Our results all quantitatively express the number of\nparameters needed for our DL model to achieve a given approximation error as a\nfunction of the target map's regularity and the geometric structure both of\n$\\mathscr{X}$ and of $\\mathscr{Y}$. Even when omitting any temporal structure,\nour universal approximation theorems are the first guarantees that H\\\"{o}lder\nfunctions, defined between such $\\mathscr{X}$ and $\\mathscr{Y}$ can be\napproximated by DL models.\n","authors":["Beatrice Acciaio","Anastasis Kratsios","Gudmund Pammer"],"pdf_url":"https://arxiv.org/pdf/2201.13094v3.pdf","comment":"Main Body: 31 Pages, Proofs: 16 Pages, Figures: 13, Tables: 3"},{"id":"http://arxiv.org/abs/2303.05490v1","updated":"2023-03-09T18:42:18Z","published":"2023-03-09T18:42:18Z","title":"On the Expressiveness and Generalization of Hypergraph Neural Networks","summary":"  This extended abstract describes a framework for analyzing the\nexpressiveness, learning, and (structural) generalization of hypergraph neural\nnetworks (HyperGNNs). Specifically, we focus on how HyperGNNs can learn from\nfinite datasets and generalize structurally to graph reasoning problems of\narbitrary input sizes. Our first contribution is a fine-grained analysis of the\nexpressiveness of HyperGNNs, that is, the set of functions that they can\nrealize. Our result is a hierarchy of problems they can solve, defined in terms\nof various hyperparameters such as depths and edge arities. Next, we analyze\nthe learning properties of these neural networks, especially focusing on how\nthey can be trained on a finite set of small graphs and generalize to larger\ngraphs, which we term structural generalization. Our theoretical results are\nfurther supported by the empirical results.\n","authors":["Zhezheng Luo","Jiayuan Mao","Joshua B. Tenenbaum","Leslie Pack Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2303.05490v1.pdf","comment":"Learning on Graphs Conference (LoG) 2022"},{"id":"http://arxiv.org/abs/2303.05487v1","updated":"2023-03-09T18:39:22Z","published":"2023-03-09T18:39:22Z","title":"Learning Rational Subgoals from Demonstrations and Instructions","summary":"  We present a framework for learning useful subgoals that support efficient\nlong-term planning to achieve novel goals. At the core of our framework is a\ncollection of rational subgoals (RSGs), which are essentially binary\nclassifiers over the environmental states. RSGs can be learned from\nweakly-annotated data, in the form of unsegmented demonstration trajectories,\npaired with abstract task descriptions, which are composed of terms initially\nunknown to the agent (e.g., collect-wood then craft-boat then go-across-river).\nOur framework also discovers dependencies between RSGs, e.g., the task\ncollect-wood is a helpful subgoal for the task craft-boat. Given a goal\ndescription, the learned subgoals and the derived dependencies facilitate\noff-the-shelf planning algorithms, such as A* and RRT, by setting helpful\nsubgoals as waypoints to the planner, which significantly improves\nperformance-time efficiency.\n","authors":["Zhezheng Luo","Jiayuan Mao","Jiajun Wu","Tomás Lozano-Pérez","Joshua B. Tenenbaum","Leslie Pack Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2303.05487v1.pdf","comment":"AAAI 2023. First two authors contributed equally. Project page:\n  https://rsg.csail.mit.edu"},{"id":"http://arxiv.org/abs/2303.05485v1","updated":"2023-03-09T18:38:46Z","published":"2023-03-09T18:38:46Z","title":"Efficient Testable Learning of Halfspaces with Adversarial Label Noise","summary":"  We give the first polynomial-time algorithm for the testable learning of\nhalfspaces in the presence of adversarial label noise under the Gaussian\ndistribution. In the recently introduced testable learning model, one is\nrequired to produce a tester-learner such that if the data passes the tester,\nthen one can trust the output of the robust learner on the data. Our\ntester-learner runs in time $\\poly(d/\\eps)$ and outputs a halfspace with\nmisclassification error $O(\\opt)+\\eps$, where $\\opt$ is the 0-1 error of the\nbest fitting halfspace. At a technical level, our algorithm employs an\niterative soft localization technique enhanced with appropriate testers to\nensure that the data distribution is sufficiently similar to a Gaussian.\n","authors":["Ilias Diakonikolas","Daniel M. Kane","Vasilis Kontonis","Sihan Liu","Nikos Zarifis"],"pdf_url":"https://arxiv.org/pdf/2303.05485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06064v2","updated":"2023-03-09T18:35:19Z","published":"2023-02-13T02:56:04Z","title":"Provably Safe Reinforcement Learning with Step-wise Violation\n  Constraints","summary":"  In this paper, we investigate a novel safe reinforcement learning problem\nwith step-wise violation constraints. Our problem differs from existing works\nin that we consider stricter step-wise violation constraints and do not assume\nthe existence of safe actions, making our formulation more suitable for\nsafety-critical applications which need to ensure safety in all decision steps\nand may not always possess safe actions, e.g., robot control and autonomous\ndriving. We propose a novel algorithm SUCBVI, which guarantees\n$\\widetilde{O}(\\sqrt{ST})$ step-wise violation and\n$\\widetilde{O}(\\sqrt{H^3SAT})$ regret. Lower bounds are provided to validate\nthe optimality in both violation and regret performance with respect to $S$ and\n$T$. Moreover, we further study a novel safe reward-free exploration problem\nwith step-wise violation constraints. For this problem, we design an\n$(\\varepsilon,\\delta)$-PAC algorithm SRF-UCRL, which achieves nearly\nstate-of-the-art sample complexity\n$\\widetilde{O}((\\frac{S^2AH^2}{\\varepsilon}+\\frac{H^4SA}{\\varepsilon^2})(\\log(\\frac{1}{\\delta})+S))$,\nand guarantees $\\widetilde{O}(\\sqrt{ST})$ violation during the exploration. The\nexperimental results demonstrate the superiority of our algorithms in safety\nperformance, and corroborate our theoretical results.\n","authors":["Nuoya Xiong","Yihan Du","Longbo Huang"],"pdf_url":"https://arxiv.org/pdf/2302.06064v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13354v2","updated":"2023-03-09T18:34:55Z","published":"2022-10-24T15:59:10Z","title":"Matching Map Recovery with an Unknown Number of Outliers","summary":"  We consider the problem of finding the matching map between two sets of\n$d$-dimensional noisy feature-vectors. The distinctive feature of our setting\nis that we do not assume that all the vectors of the first set have their\ncorresponding vector in the second set. If $n$ and $m$ are the sizes of these\ntwo sets, we assume that the matching map that should be recovered is defined\non a subset of unknown cardinality $k^*\\le \\min(n,m)$. We show that, in the\nhigh-dimensional setting, if the signal-to-noise ratio is larger than\n$5(d\\log(4nm/\\alpha))^{1/4}$, then the true matching map can be recovered with\nprobability $1-\\alpha$. Interestingly, this threshold does not depend on $k^*$\nand is the same as the one obtained in prior work in the case of $k =\n\\min(n,m)$. The procedure for which the aforementioned property is proved is\nobtained by a data-driven selection among candidate mappings\n$\\{\\hat\\pi_k:k\\in[\\min(n,m)]\\}$. Each $\\hat\\pi_k$ minimizes the sum of squares\nof distances between two sets of size $k$. The resulting optimization problem\ncan be formulated as a minimum-cost flow problem, and thus solved efficiently.\nFinally, we report the results of numerical experiments on both synthetic and\nreal-world data that illustrate our theoretical results and provide further\ninsight into the properties of the algorithms studied in this work.\n","authors":["Arshak Minasyan","Tigran Galstyan","Sona Hunanyan","Arnak Dalalyan"],"pdf_url":"https://arxiv.org/pdf/2210.13354v2.pdf","comment":"16 pages, 8 figures, 1 table; AISTATS 2023"},{"id":"http://arxiv.org/abs/2303.05479v1","updated":"2023-03-09T18:31:13Z","published":"2023-03-09T18:31:13Z","title":"Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online\n  Fine-Tuning","summary":"  A compelling use case of offline reinforcement learning (RL) is to obtain a\npolicy initialization from existing datasets, which allows efficient\nfine-tuning with limited amounts of active online interaction. However, several\nexisting offline RL methods tend to exhibit poor online fine-tuning\nperformance. On the other hand, online RL methods can learn effectively through\nonline interaction, but struggle to incorporate offline data, which can make\nthem very slow in settings where exploration is challenging or pre-training is\nnecessary. In this paper, we devise an approach for learning an effective\ninitialization from offline data that also enables fast online fine-tuning\ncapabilities. Our approach, calibrated Q-learning (Cal-QL) accomplishes this by\nlearning a conservative value function initialization that underestimates the\nvalue of the learned policy from offline data, while also being calibrated, in\nthe sense that the learned Q-values are at a reasonable scale. We refer to this\nproperty as calibration, and define it formally as providing a lower bound on\nthe true value function of the learned policy and an upper bound on the value\nof some other (suboptimal) reference policy, which may simply be the behavior\npolicy. We show that offline RL algorithms that learn such calibrated value\nfunctions lead to effective online fine-tuning, enabling us to take the\nbenefits of offline initializations in online fine-tuning. In practice, Cal-QL\ncan be implemented on top of existing conservative methods for offline RL\nwithin a one-line code change. Empirically, Cal-QL outperforms state-of-the-art\nmethods on 10/11 fine-tuning benchmark tasks that we study in this paper.\n","authors":["Mitsuhiko Nakamoto","Yuexiang Zhai","Anikait Singh","Max Sobol Mark","Yi Ma","Chelsea Finn","Aviral Kumar","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2303.05479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05470v1","updated":"2023-03-09T18:22:12Z","published":"2023-03-09T18:22:12Z","title":"Spawrious: A Benchmark for Fine Control of Spurious Correlation Biases","summary":"  The problem of spurious correlations (SCs) arises when a classifier relies on\nnon-predictive features that happen to be correlated with the labels in the\ntraining data. For example, a classifier may misclassify dog breeds based on\nthe background of dog images. This happens when the backgrounds are correlated\nwith other breeds in the training data, leading to misclassifications during\ntest time. Previous SC benchmark datasets suffer from varying issues, e.g.,\nover-saturation or only containing one-to-one (O2O) SCs, but no many-to-many\n(M2M) SCs arising between groups of spurious attributes and classes. In this\npaper, we present Spawrious-{O2O, M2M}-{Easy, Medium, Hard}, an image\nclassification benchmark suite containing spurious correlations among different\ndog breeds and background locations. To create this dataset, we employ a\ntext-to-image model to generate photo-realistic images, and an image captioning\nmodel to filter out unsuitable ones. The resulting dataset is of high quality,\ncontaining approximately 152,000 images. Our experimental results demonstrate\nthat state-of-the-art group robustness methods struggle with Spawrious, most\nnotably on the Hard-splits with $<60\\%$ accuracy. By examining model\nmisclassifications, we detect reliances on spurious backgrounds, demonstrating\nthat our dataset provides a significant challenge to drive future research.\n","authors":["Aengus Lynch","Gbètondji J-S Dovonon","Jean Kaddour","Ricardo Silva"],"pdf_url":"https://arxiv.org/pdf/2303.05470v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05464v1","updated":"2023-03-09T18:10:45Z","published":"2023-03-09T18:10:45Z","title":"Resolving quantitative MRI model degeneracy with machine learning via\n  training data distribution design","summary":"  Quantitative MRI (qMRI) aims to map tissue properties non-invasively via\nmodels that relate these unknown quantities to measured MRI signals. Estimating\nthese unknowns, which has traditionally required model fitting - an often\niterative procedure, can now be done with one-shot machine learning (ML)\napproaches. Such parameter estimation may be complicated by intrinsic qMRI\nsignal model degeneracy: different combinations of tissue properties produce\nthe same signal. Despite their many advantages, it remains unclear whether ML\napproaches can resolve this issue. Growing empirical evidence appears to\nsuggest ML approaches remain susceptible to model degeneracy. Here we\ndemonstrate under the right circumstances ML can address this issue. Inspired\nby recent works on the impact of training data distributions on ML-based\nparameter estimation, we propose to resolve model degeneracy by designing\ntraining data distributions. We put forward a classification of model\ndegeneracies and identify one particular kind of degeneracies amenable to the\nproposed attack. The strategy is demonstrated successfully using the Revised\nNODDI model with standard multi-shell diffusion MRI data as an exemplar. Our\nresults illustrate the importance of training set design which has the\npotential to allow accurate estimation of tissue properties with ML.\n","authors":["Michele Guerreri","Sean Epstein","Hojjat Azadbakht","Hui Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05464v1.pdf","comment":"13 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.05458v1","updated":"2023-03-09T17:57:36Z","published":"2023-03-09T17:57:36Z","title":"Beware of Instantaneous Dependence in Reinforcement Learning","summary":"  Playing an important role in Model-Based Reinforcement Learning (MBRL),\nenvironment models aim to predict future states based on the past. Existing\nworks usually ignore instantaneous dependence in the state, that is, assuming\nthat the future state variables are conditionally independent given the past\nstates. However, instantaneous dependence is prevalent in many RL environments.\nFor instance, in the stock market, instantaneous dependence can exist between\ntwo stocks because the fluctuation of one stock can quickly affect the other\nand the resolution of price change is lower than that of the effect. In this\npaper, we prove that with few exceptions, ignoring instantaneous dependence can\nresult in suboptimal policy learning in MBRL. To address the suboptimality\nproblem, we propose a simple plug-and-play method to enable existing MBRL\nalgorithms to take instantaneous dependence into account. Through experiments\non two benchmarks, we (1) confirm the existence of instantaneous dependence\nwith visualization; (2) validate our theoretical findings that ignoring\ninstantaneous dependence leads to suboptimal policy; (3) verify that our method\neffectively enables reinforcement learning with instantaneous dependence and\nimproves policy performance.\n","authors":["Zhengmao Zhu","Yuren Liu","Honglong Tian","Yang Yu","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05458v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05448v1","updated":"2023-03-09T17:46:13Z","published":"2023-03-09T17:46:13Z","title":"Power and Interference Control for VLC-Based UDN: A Reinforcement\n  Learning Approach","summary":"  Visible light communication (VLC) has been widely applied as a promising\nsolution for modern short range communication. When it comes to the deployment\nof LED arrays in VLC networks, the emerging ultra-dense network (UDN)\ntechnology can be adopted to expand the VLC network's capacity. However, the\nproblem of inter-cell interference (ICI) mitigation and efficient power control\nin the VLC-based UDN is still a critical challenge. To this end, a\nreinforcement learning (RL) based VLC UDN architecture is devised in this\npaper. The deployment of the cells is optimized via spatial reuse to mitigate\nICI. An RL-based algorithm is proposed to dynamically optimize the policy of\npower and interference control, maximizing the system utility in the\ncomplicated and dynamic environment. Simulation results demonstrate the\nsuperiority of the proposed scheme, it increase the system utility and\nachievable data rate while reducing the energy consumption and ICI, which\noutperforms the benchmark scheme.\n","authors":["Xiao Tang","Sicong Liu"],"pdf_url":"https://arxiv.org/pdf/2303.05448v1.pdf","comment":"This paper has been accepted by and to appear in Proc. ACM\n  UbiComp/ISWC'2022"},{"id":"http://arxiv.org/abs/2303.05445v1","updated":"2023-03-09T17:44:58Z","published":"2023-03-09T17:44:58Z","title":"Communication-Efficient Collaborative Heterogeneous Bandits in Networks","summary":"  The multi-agent multi-armed bandit problem has been studied extensively due\nto its ubiquity in many real-life applications, such as online recommendation\nsystems and wireless networking. We consider the setting where agents should\nminimize their group regret while collaborating over a given graph via some\ncommunication protocol and where each agent is given a different set of arms.\nPrevious literature on this problem only considered one of the two desired\nfeatures separately: agents with the same arm set communicate over a general\ngraph, or agents with different arm sets communicate over a fully connected\ngraph. In this work, we introduce a more general problem setting that\nencompasses all the desired features. For this novel setting, we first provide\na rigorous regret analysis for the standard flooding protocol combined with the\nUCB policy. Then, to mitigate the issue of high communication costs incurred by\nflooding, we propose a new protocol called Flooding with Absorption (FWA). We\nprovide a theoretical analysis of the regret bound and intuitions on the\nadvantages of using FWA over flooding. Lastly, we verify empirically that using\nFWA leads to significantly lower communication costs despite minimal regret\nperformance loss compared to flooding.\n","authors":["Junghyun Lee","Laura Schmid","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2303.05445v1.pdf","comment":"17 pages, 7 figures; submitted to MobiHoc 2023"},{"id":"http://arxiv.org/abs/2302.09051v3","updated":"2023-03-09T17:25:10Z","published":"2023-02-17T18:31:31Z","title":"Complex QA and language models hybrid architectures, Survey","summary":"  This paper reviews the state-of-the-art of hybrid language models\narchitectures and strategies for \"complex\" question-answering (QA, CQA, CPS).\nLarge Language Models (LLM) are good at leveraging public data on standard\nproblems but once you want to tackle more specific complex questions or\nproblems you may need specific architecture, knowledge, skills, methods,\nsensitive data protection, explainability, human approval and versatile\nfeedback... We identify key elements augmenting LLM to solve complex questions\nor problems. We extend findings from the robust community edited research\npapers BIG, BLOOM and HELM which open source, benchmark and analyze limits and\nchallenges of LLM in terms of tasks complexity and strict evaluation on\naccuracy (e.g. fairness, robustness, toxicity, ...). Recent projects like\nChatGPT and GALACTICA have allowed non-specialists to grasp the great potential\nas well as the equally strong limitations of language models in complex QA.\nHybridizing these models with different components could allow to overcome\nthese different limits and go much further. We discuss some challenges\nassociated with complex QA, including domain adaptation, decomposition and\nefficient multi-step QA, long form and non-factoid QA, safety and\nmulti-sensitivity data protection, multimodal search, hallucinations,\nexplainability and truthfulness, temproal reasoning. Therefore, we analyze\ncurrent solutions and promising research trends, using elements such as: hybrid\nLLM architectures, active human reinforcement learning supervised with AI,\nprompting adaptation, neuro-symbolic and structured knowledge grounding,\nprogram synthesis, iterated decomposition and others.\n","authors":["Xavier Daull","Patrice Bellot","Emmanuel Bruno","Vincent Martin","Elisabeth Murisasco"],"pdf_url":"https://arxiv.org/pdf/2302.09051v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05428v1","updated":"2023-03-09T17:21:11Z","published":"2023-03-09T17:21:11Z","title":"Quantum Splines for Non-Linear Approximations","summary":"  Quantum Computing offers a new paradigm for efficient computing and many AI\napplications could benefit from its potential boost in performance. However,\nthe main limitation is the constraint to linear operations that hampers the\nrepresentation of complex relationships in data. In this work, we propose an\nefficient implementation of quantum splines for non-linear approximation. In\nparticular, we first discuss possible parametrisations, and select the most\nconvenient for exploiting the HHL algorithm to obtain the estimates of spline\ncoefficients. Then, we investigate QSpline performance as an evaluation routine\nfor some of the most popular activation functions adopted in ML. Finally, a\ndetailed comparison with classical alternatives to the HHL is also presented.\n","authors":["Antonio Macaluso","Luca Clissa","Stefano Lodi","Claudio Sartori"],"pdf_url":"https://arxiv.org/pdf/2303.05428v1.pdf","comment":"6 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2303.05420v1","updated":"2023-03-09T17:11:31Z","published":"2023-03-09T17:11:31Z","title":"Kernel Regression with Infinite-Width Neural Networks on Millions of\n  Examples","summary":"  Neural kernels have drastically increased performance on diverse and\nnonstandard data modalities but require significantly more compute, which\npreviously limited their application to smaller datasets. In this work, we\naddress this by massively parallelizing their computation across many GPUs. We\ncombine this with a distributed, preconditioned conjugate gradients algorithm\nto enable kernel regression at a large scale (i.e. up to five million\nexamples). Using this approach, we study scaling laws of several neural kernels\nacross many orders of magnitude for the CIFAR-5m dataset. Using data\naugmentation to expand the original CIFAR-10 training dataset by a factor of\n20, we obtain a test accuracy of 91.2\\% (SotA for a pure kernel method).\nMoreover, we explore neural kernels on other data modalities, obtaining results\non protein and small molecule prediction tasks that are competitive with SotA\nmethods.\n","authors":["Ben Adlam","Jaehoon Lee","Shreyas Padhy","Zachary Nado","Jasper Snoek"],"pdf_url":"https://arxiv.org/pdf/2303.05420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04001v2","updated":"2023-03-09T17:10:27Z","published":"2023-03-07T16:00:26Z","title":"ELODIN: Naming Concepts in Embedding Spaces","summary":"  Despite recent advancements, the field of text-to-image synthesis still\nsuffers from lack of fine-grained control. Using only text, it remains\nchallenging to deal with issues such as concept coherence and concept\ncontamination. We propose a method to enhance control by generating specific\nconcepts that can be reused throughout multiple images, effectively expanding\nnatural language with new words that can be combined much like a painter's\npalette. Unlike previous contributions, our method does not copy visuals from\ninput data and can generate concepts through text alone. We perform a set of\ncomparisons that finds our method to be a significant improvement over\ntext-only prompts.\n","authors":["Rodrigo Mello","Filipe Calegario","Geber Ramalho"],"pdf_url":"https://arxiv.org/pdf/2303.04001v2.pdf","comment":"Added quantitative data, fixed formatting issues"},{"id":"http://arxiv.org/abs/2303.05413v1","updated":"2023-03-09T16:59:35Z","published":"2023-03-09T16:59:35Z","title":"Fast kernel methods for Data Quality Monitoring as a goodness-of-fit\n  test","summary":"  We here propose a machine learning approach for monitoring particle detectors\nin real-time. The goal is to assess the compatibility of incoming experimental\ndata with a reference dataset, characterising the data behaviour under normal\ncircumstances, via a likelihood-ratio hypothesis test. The model is based on a\nmodern implementation of kernel methods, nonparametric algorithms that can\nlearn any continuous function given enough data. The resulting approach is\nefficient and agnostic to the type of anomaly that may be present in the data.\nOur study demonstrates the effectiveness of this strategy on multivariate data\nfrom drift tube chamber muon detectors.\n","authors":["Gaia Grosso","Nicolò Lai","Marco Letizia","Jacopo Pazzini","Marco Rando","Lorenzo Rosasco","Andrea Wulzer","Marco Zanetti"],"pdf_url":"https://arxiv.org/pdf/2303.05413v1.pdf","comment":"16 pages, 7 figures"},{"id":"http://arxiv.org/abs/2208.07360v3","updated":"2023-03-09T16:42:28Z","published":"2022-08-15T17:55:26Z","title":"Three New Validators and a Large-Scale Benchmark Ranking for\n  Unsupervised Domain Adaptation","summary":"  Changes to hyperparameters can have a dramatic effect on model accuracy.\nThus, the tuning of hyperparameters plays an important role in optimizing\nmachine-learning models. An integral part of the hyperparameter-tuning process\nis the evaluation of model checkpoints, which is done through the use of\n\"validators\". In a supervised setting, these validators evaluate checkpoints by\ncomputing accuracy on a validation set that has labels. In contrast, in an\nunsupervised setting, the validation set has no such labels. Without any\nlabels, it is impossible to compute accuracy, so validators must estimate\naccuracy instead. But what is the best approach to estimating accuracy? In this\npaper, we consider this question in the context of unsupervised domain\nadaptation (UDA). Specifically, we propose three new validators, and we compare\nand rank them against five other existing validators, on a large dataset of\n1,000,000 checkpoints. Extensive experimental results show that two of our\nproposed validators achieve state-of-the-art performance in various settings.\nFinally, we find that in many cases, the state-of-the-art is obtained by a\nsimple baseline method. To the best of our knowledge, this is the largest\nempirical study of UDA validators to date. Code is available at\nhttps://www.github.com/KevinMusgrave/powerful-benchmarker.\n","authors":["Kevin Musgrave","Serge Belongie","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2208.07360v3.pdf","comment":"This paper was previously titled Benchmarking Validation Methods for\n  Unsupervised Domain Adaptation. This version contains new experiments,\n  analysis, and figures"},{"id":"http://arxiv.org/abs/2303.05378v1","updated":"2023-03-09T16:25:51Z","published":"2023-03-09T16:25:51Z","title":"Greener yet Powerful: Taming Large Code Generation Models with\n  Quantization","summary":"  ML-powered code generation aims to assist developers to write code in a more\nproductive manner, by intelligently generating code blocks based on natural\nlanguage prompts. Recently, large pretrained deep learning models have\nsubstantially pushed the boundary of code generation and achieved impressive\nperformance. Despite their great power, the huge number of model parameters\nposes a significant threat to adapting them in a regular software development\nenvironment, where a developer might use a standard laptop or mid-size server\nto develop her code. Such large models incur significant resource usage (in\nterms of memory, latency, and dollars) as well as carbon footprint.\n  Model compression is a promising approach to address these challenges.\nSeveral techniques are proposed to compress large pretrained models typically\nused for vision or textual data. Out of many available compression techniques,\nwe identified that quantization is mostly applicable for code generation task\nas it does not require significant retraining cost. As quantization represents\nmodel parameters with lower-bit integer (e.g., int8), the model size and\nruntime latency would both benefit from such int representation. We extensively\nstudy the impact of quantized model on code generation tasks across different\ndimension: (i) resource usage and carbon footprint, (ii) accuracy, and (iii)\nrobustness. To this end, through systematic experiments we find a recipe of\nquantization technique that could run even a $6$B model in a regular laptop\nwithout significant accuracy or robustness degradation. We further found the\nrecipe is readily applicable to code summarization task as well.\n","authors":["Xiaokai Wei","Sujan Gonugondla","Wasi Ahmad","Shiqi Wang","Baishakhi Ray","Haifeng Qian","Xiaopeng Li","Varun Kumar","Zijian Wang","Yuchen Tian","Qing Sun","Ben Athiwaratkun","Mingyue Shang","Murali Krishna Ramanathan","Parminder Bhatia","Bing Xiang"],"pdf_url":"https://arxiv.org/pdf/2303.05378v1.pdf","comment":"10 pages, 7 figures, 10 tables"},{"id":"http://arxiv.org/abs/2303.05376v1","updated":"2023-03-09T16:23:49Z","published":"2023-03-09T16:23:49Z","title":"PC-JeDi: Diffusion for Particle Cloud Generation in High Energy Physics","summary":"  In this paper, we present a new method to efficiently generate jets in High\nEnergy Physics called PC-JeDi. This method utilises score-based diffusion\nmodels in conjunction with transformers which are well suited to the task of\ngenerating jets as particle clouds due to their permutation equivariance.\nPC-JeDi achieves competitive performance with current state-of-the-art methods\nacross several metrics that evaluate the quality of the generated jets.\nAlthough slower than other models, due to the large number of forward passes\nrequired by diffusion models, it is still substantially faster than traditional\ndetailed simulation. Furthermore, PC-JeDi uses conditional generation to\nproduce jets with a desired mass and transverse momentum for two different\nparticles, top quarks and gluons.\n","authors":["Matthew Leigh","Debajyoti Sengupta","Guillaume Quétant","John Andrew Raine","Knut Zoch","Tobias Golling"],"pdf_url":"https://arxiv.org/pdf/2303.05376v1.pdf","comment":"29 pages, 25 figures, 5 tables"},{"id":"http://arxiv.org/abs/2303.05369v1","updated":"2023-03-09T16:17:45Z","published":"2023-03-09T16:17:45Z","title":"Data-dependent Generalization Bounds via Variable-Size Compressibility","summary":"  In this paper, we establish novel data-dependent upper bounds on the\ngeneralization error through the lens of a \"variable-size compressibility\"\nframework that we introduce newly here. In this framework, the generalization\nerror of an algorithm is linked to a variable-size 'compression rate' of its\ninput data. This is shown to yield bounds that depend on the empirical measure\nof the given input data at hand, rather than its unknown distribution. Our new\ngeneralization bounds that we establish are tail bounds, tail bounds on the\nexpectation, and in-expectations bounds. Moreover, it is shown that our\nframework also allows to derive general bounds on any function of the input\ndata and output hypothesis random variables. In particular, these general\nbounds are shown to subsume and possibly improve over several existing\nPAC-Bayes and data-dependent intrinsic dimension-based bounds that are\nrecovered as special cases, thus unveiling a unifying character of our\napproach. For instance, a new data-dependent intrinsic dimension based bounds\nis established, which connects the generalization error to the optimization\ntrajectories and reveals various interesting connections with rate-distortion\ndimension of process, R\\'enyi information dimension of process, and metric mean\ndimension.\n","authors":["Milad Sefidgaran","Abdellatif Zaidi"],"pdf_url":"https://arxiv.org/pdf/2303.05369v1.pdf","comment":"35 pages"},{"id":"http://arxiv.org/abs/2210.16984v2","updated":"2023-03-09T16:12:17Z","published":"2022-10-27T15:20:18Z","title":"Synthesizer Preset Interpolation using Transformer Auto-Encoders","summary":"  Sound synthesizers are widespread in modern music production but they\nincreasingly require expert skills to be mastered. This work focuses on\ninterpolation between presets, i.e., sets of values of all sound synthesis\nparameters, to enable the intuitive creation of new sounds from existing ones.\n  We introduce a bimodal auto-encoder neural network, which simultaneously\nprocesses presets using multi-head attention blocks, and audio using\nconvolutions. This model has been tested on a popular frequency modulation\nsynthesizer with more than one hundred parameters. Experiments have compared\nthe model to related architectures and methods, and have demonstrated that it\nperforms smoother interpolations. After training, the proposed model can be\nintegrated into commercial synthesizers for live interpolation or sound design\ntasks.\n","authors":["Gwendal Le Vaillant","Thierry Dutoit"],"pdf_url":"https://arxiv.org/pdf/2210.16984v2.pdf","comment":"Accepted to IEEE ICASSP 2023"},{"id":"http://arxiv.org/abs/2210.16060v2","updated":"2023-03-09T16:08:03Z","published":"2022-10-28T11:13:41Z","title":"Deep network series for large-scale high-dynamic range imaging","summary":"  We propose a new approach for large-scale high-dynamic range computational\nimaging. Deep Neural Networks (DNNs) trained end-to-end can solve linear\ninverse imaging problems almost instantaneously. While unfolded architectures\nprovide robustness to measurement setting variations, embedding large-scale\nmeasurement operators in DNN architectures is impractical. Alternative\nPlug-and-Play (PnP) approaches, where the denoising DNNs are blind to the\nmeasurement setting, have proven effective to address scalability and\nhigh-dynamic range challenges, but rely on highly iterative algorithms. We\npropose a residual DNN series approach, also interpretable as a learned version\nof matching pursuit, where the reconstructed image is a sum of residual images\nprogressively increasing the dynamic range, and estimated iteratively by DNNs\ntaking the back-projected data residual of the previous iteration as input. We\ndemonstrate on radio-astronomical imaging simulations that a series of only few\nterms provides a reconstruction quality competitive with PnP, at a fraction of\nthe cost.\n","authors":["Amir Aghabiglou","Matthieu Terris","Adrian Jackson","Yves Wiaux"],"pdf_url":"https://arxiv.org/pdf/2210.16060v2.pdf","comment":"5 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2212.06858v2","updated":"2023-03-09T16:00:00Z","published":"2022-12-13T19:02:35Z","title":"LidarCLIP or: How I Learned to Talk to Point Clouds","summary":"  Research connecting text and images has recently seen several breakthroughs,\nwith models like CLIP, DALL-E 2, and Stable Diffusion. However, the connection\nbetween text and other visual modalities, such as lidar data, has received less\nattention, prohibited by the lack of text-lidar datasets. In this work, we\npropose LidarCLIP, a mapping from automotive point clouds to a pre-existing\nCLIP embedding space. Using image-lidar pairs, we supervise a point cloud\nencoder with the image CLIP embeddings, effectively relating text and lidar\ndata with the image domain as an intermediary. We show the effectiveness of\nLidarCLIP by demonstrating that lidar-based retrieval is generally on par with\nimage-based retrieval, but with complementary strengths and weaknesses. By\ncombining image and lidar features, we improve upon both single-modality\nmethods and enable a targeted search for challenging detection scenarios under\nadverse sensor conditions. We also explore zero-shot classification and show\nthat LidarCLIP outperforms existing attempts to use CLIP for point clouds by a\nlarge margin. Finally, we leverage our compatibility with CLIP to explore a\nrange of applications, such as point cloud captioning and lidar-to-image\ngeneration, without any additional training. Code and pre-trained models are\navailable at https://github.com/atonderski/lidarclip.\n","authors":["Georg Hess","Adam Tonderski","Christoffer Petersson","Kalle Åström","Lennart Svensson"],"pdf_url":"https://arxiv.org/pdf/2212.06858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.10687v2","updated":"2023-03-09T15:43:15Z","published":"2022-08-23T02:19:10Z","title":"The Effect of Modeling Human Rationality Level on Learning Rewards from\n  Multiple Feedback Types","summary":"  When inferring reward functions from human behavior (be it demonstrations,\ncomparisons, physical corrections, or e-stops), it has proven useful to model\nthe human as making noisy-rational choices, with a \"rationality coefficient\"\ncapturing how much noise or entropy we expect to see in the human behavior.\nPrior work typically sets the rationality level to a constant value, regardless\nof the type, or quality, of human feedback. However, in many settings, giving\none type of feedback (e.g. a demonstration) may be much more difficult than a\ndifferent type of feedback (e.g. answering a comparison query). Thus, we expect\nto see more or less noise depending on the type of human feedback. In this\nwork, we advocate that grounding the rationality coefficient in real data for\neach feedback type, rather than assuming a default value, has a significant\npositive effect on reward learning. We test this in both simulated experiments\nand in a user study with real human feedback. We find that overestimating human\nrationality can have dire effects on reward learning accuracy and regret. We\nalso find that fitting the rationality coefficient to human data enables better\nreward learning, even when the human deviates significantly from the\nnoisy-rational choice model due to systematic biases. Further, we find that the\nrationality level affects the informativeness of each feedback type:\nsurprisingly, demonstrations are not always the most informative -- when the\nhuman acts very suboptimally, comparisons actually become more informative,\neven when the rationality level is the same for both. Ultimately, our results\nemphasize the importance and advantage of paying attention to the assumed\nhuman-rationality level, especially when agents actively learn from multiple\ntypes of human feedback.\n","authors":["Gaurav R. Ghosal","Matthew Zurek","Daniel S. Brown","Anca D. Dragan"],"pdf_url":"https://arxiv.org/pdf/2208.10687v2.pdf","comment":"Published at AAAI 2023; 10 pages, 5 figures plus appendices"},{"id":"http://arxiv.org/abs/2303.05341v1","updated":"2023-03-09T15:38:16Z","published":"2023-03-09T15:38:16Z","title":"Penalized Deep Partially Linear Cox Models with Application to CT Scans\n  of Lung Cancer Patients","summary":"  Lung cancer is a leading cause of cancer mortality globally, highlighting the\nimportance of understanding its mortality risks to design effective\npatient-centered therapies. The National Lung Screening Trial (NLST) was a\nnationwide study aimed at investigating risk factors for lung cancer. The study\nemployed computed tomography texture analysis (CTTA), which provides objective\nmeasurements of texture patterns on CT scans, to quantify the mortality risks\nof lung cancer patients. Partially linear Cox models are becoming a popular\ntool for modeling survival outcomes, as they effectively handle both\nestablished risk factors (such as age and other clinical factors) and new risk\nfactors (such as image features) in a single framework. The challenge in\nidentifying the texture features that impact cancer survival is due to their\nsensitivity to factors such as scanner type, segmentation, and organ motion. To\novercome this challenge, we propose a novel Penalized Deep Partially Linear Cox\nModel (Penalized DPLC), which incorporates the SCAD penalty to select\nsignificant texture features and employs a deep neural network to estimate the\nnonparametric component of the model accurately. We prove the convergence and\nasymptotic properties of the estimator and compare it to other methods through\nextensive simulation studies, evaluating its performance in risk prediction and\nfeature selection. The proposed method is applied to the NLST study dataset to\nuncover the effects of key clinical and imaging risk factors on patients'\nsurvival. Our findings provide valuable insights into the relationship between\nthese factors and survival outcomes.\n","authors":["Yuming Sun","Jian Kang","Chinmay Haridas","Nicholas R. Mayne","Alexandra L. Potter","Chi-Fu Jeffrey Yang","David C. Christiani","Yi Li"],"pdf_url":"https://arxiv.org/pdf/2303.05341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05331v1","updated":"2023-03-09T15:22:02Z","published":"2023-03-09T15:22:02Z","title":"Adaptive Calibrator Ensemble for Model Calibration under Distribution\n  Shift","summary":"  Model calibration usually requires optimizing some parameters (e.g.,\ntemperature) w.r.t an objective function (e.g., negative log-likelihood). In\nthis paper, we report a plain, important but often neglected fact that the\nobjective function is influenced by calibration set difficulty, i.e., the ratio\nof the number of incorrectly classified samples to that of correctly classified\nsamples. If a test set has a drastically different difficulty level from the\ncalibration set, the optimal calibration parameters of the two datasets would\nbe different. In other words, a calibrator optimal on the calibration set would\nbe suboptimal on the OOD test set and thus has degraded performance. With this\nknowledge, we propose a simple and effective method named adaptive calibrator\nensemble (ACE) to calibrate OOD datasets whose difficulty is usually higher\nthan the calibration set. Specifically, two calibration functions are trained,\none for in-distribution data (low difficulty), and the other for severely OOD\ndata (high difficulty). To achieve desirable calibration on a new OOD dataset,\nACE uses an adaptive weighting method that strikes a balance between the two\nextreme functions. When plugged in, ACE generally improves the performance of a\nfew state-of-the-art calibration schemes on a series of OOD benchmarks.\nImportantly, such improvement does not come at the cost of the in-distribution\ncalibration accuracy.\n","authors":["Yuli Zou","Weijian Deng","Liang Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.05331v1.pdf","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2209.15571v3","updated":"2023-03-09T15:18:40Z","published":"2022-09-30T16:30:31Z","title":"Building Normalizing Flows with Stochastic Interpolants","summary":"  A generative model based on a continuous-time normalizing flow between any\npair of base and target probability densities is proposed. The velocity field\nof this flow is inferred from the probability current of a time-dependent\ndensity that interpolates between the base and the target in finite time.\nUnlike conventional normalizing flow inference methods based the maximum\nlikelihood principle, which require costly backpropagation through ODE solvers,\nour interpolant approach leads to a simple quadratic loss for the velocity\nitself which is expressed in terms of expectations that are readily amenable to\nempirical estimation. The flow can be used to generate samples from either the\nbase or target, and to estimate the likelihood at any time along the\ninterpolant. In addition, the flow can be optimized to minimize the path length\nof the interpolant density, thereby paving the way for building optimal\ntransport maps. In situations where the base is a Gaussian density, we also\nshow that the velocity of our normalizing flow can also be used to construct a\ndiffusion model to sample the target as well as estimate its score. However,\nour approach shows that we can bypass this diffusion completely and work at the\nlevel of the probability flow with greater simplicity, opening an avenue for\nmethods based solely on ordinary differential equations as an alternative to\nthose based on stochastic differential equations. Benchmarking on density\nestimation tasks illustrates that the learned flow can match and surpass\nconventional continuous flows at a fraction of the cost, and compares well with\ndiffusions on image generation on CIFAR-10 and ImageNet $32\\times32$. The\nmethod scales ab-initio ODE flows to previously unreachable image resolutions,\ndemonstrated up to $128\\times128$.\n","authors":["Michael S. Albergo","Eric Vanden-Eijnden"],"pdf_url":"https://arxiv.org/pdf/2209.15571v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03982v2","updated":"2023-03-09T15:17:36Z","published":"2023-03-07T15:32:18Z","title":"Structured State Space Models for In-Context Reinforcement Learning","summary":"  Structured state space sequence (S4) models have recently achieved\nstate-of-the-art performance on long-range sequence modeling tasks. These\nmodels also have fast inference speeds and parallelisable training, making them\npotentially useful in many reinforcement learning settings. We propose a\nmodification to a variant of S4 that enables us to initialise and reset the\nhidden state in parallel, allowing us to tackle reinforcement learning tasks.\nWe show that our modified architecture runs asymptotically faster than\nTransformers and performs better than LSTM models on a simple memory-based\ntask. Then, by leveraging the model's ability to handle long-range sequences,\nwe achieve strong performance on a challenging meta-learning task in which the\nagent is given a randomly-sampled continuous control environment, combined with\na randomly-sampled linear projection of the environment's observations and\nactions. Furthermore, we show the resulting model can adapt to\nout-of-distribution held-out tasks. Overall, the results presented in this\npaper suggest that the S4 models are a strong contender for the default\narchitecture used for in-context reinforcement learning\n","authors":["Chris Lu","Yannick Schroecker","Albert Gu","Emilio Parisotto","Jakob Foerster","Satinder Singh","Feryal Behbahani"],"pdf_url":"https://arxiv.org/pdf/2303.03982v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.00531v3","updated":"2023-03-09T15:16:24Z","published":"2022-07-01T16:31:45Z","title":"Masked Autoencoder for Self-Supervised Pre-training on Lidar Point\n  Clouds","summary":"  Masked autoencoding has become a successful pretraining paradigm for\nTransformer models for text, images, and, recently, point clouds. Raw\nautomotive datasets are suitable candidates for self-supervised pre-training as\nthey generally are cheap to collect compared to annotations for tasks like 3D\nobject detection (OD). However, the development of masked autoencoders for\npoint clouds has focused solely on synthetic and indoor data. Consequently,\nexisting methods have tailored their representations and models toward small\nand dense point clouds with homogeneous point densities. In this work, we study\nmasked autoencoding for point clouds in an automotive setting, which are sparse\nand for which the point density can vary drastically among objects in the same\nscene. To this end, we propose Voxel-MAE, a simple masked autoencoding\npre-training scheme designed for voxel representations. We pre-train the\nbackbone of a Transformer-based 3D object detector to reconstruct masked voxels\nand to distinguish between empty and non-empty voxels. Our method improves the\n3D OD performance by 1.75 mAP points and 1.05 NDS on the challenging nuScenes\ndataset. Further, we show that by pre-training with Voxel-MAE, we require only\n40% of the annotated data to outperform a randomly initialized equivalent. Code\navailable at https://github.com/georghess/voxel-mae\n","authors":["Georg Hess","Johan Jaxing","Elias Svensson","David Hagerman","Christoffer Petersson","Lennart Svensson"],"pdf_url":"https://arxiv.org/pdf/2207.00531v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02234v2","updated":"2023-03-09T15:14:33Z","published":"2023-03-03T21:55:04Z","title":"Hindsight States: Blending Sim and Real Task Elements for Efficient\n  Reinforcement Learning","summary":"  Reinforcement learning has shown great potential in solving complex tasks\nwhen large amounts of data can be generated with little effort. In robotics,\none approach to generate training data builds on simulations based on dynamics\nmodels derived from first principles. However, for tasks that, for instance,\ninvolve complex soft robots, devising such models is substantially more\nchallenging. Being able to train effectively in increasingly complicated\nscenarios with reinforcement learning enables to take advantage of complex\nsystems such as soft robots. Here, we leverage the imbalance in complexity of\nthe dynamics to learn more sample-efficiently. We (i) abstract the task into\ndistinct components, (ii) off-load the simple dynamics parts into the\nsimulation, and (iii) multiply these virtual parts to generate more data in\nhindsight. Our new method, Hindsight States (HiS), uses this data and selects\nthe most useful transitions for training. It can be used with an arbitrary\noff-policy algorithm. We validate our method on several challenging simulated\ntasks and demonstrate that it improves learning both alone and when combined\nwith an existing hindsight algorithm, Hindsight Experience Replay (HER).\nFinally, we evaluate HiS on a physical system and show that it boosts\nperformance on a complex table tennis task with a muscular robot. Videos and\ncode of the experiments can be found on webdav.tuebingen.mpg.de/his/.\n","authors":["Simon Guist","Jan Schneider","Alexander Dittrich","Vincent Berenz","Bernhard Schölkopf","Dieter Büchler"],"pdf_url":"https://arxiv.org/pdf/2303.02234v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15162v3","updated":"2023-03-09T15:02:07Z","published":"2022-09-30T01:17:18Z","title":"Linearly Mapping from Image to Text Space","summary":"  The extent to which text-only language models (LMs) learn to represent\nfeatures of the non-linguistic world is an open question. Prior work has shown\nthat pretrained LMs can be taught to caption images when a vision model's\nparameters are optimized to encode images in the language space. We test a\nstronger hypothesis: that the conceptual representations learned by frozen\ntext-only models and vision-only models are similar enough that this can be\nachieved with a linear map. We show that the image representations from vision\nmodels can be transferred as continuous prompts to frozen LMs by training only\na single linear projection. Using these to prompt the LM achieves competitive\nperformance on captioning and visual question answering tasks compared to\nmodels that tune both the image encoder and text decoder (such as the MAGMA\nmodel). We compare three image encoders with increasing amounts of linguistic\nsupervision seen during pretraining: BEIT (no linguistic information),\nNF-ResNET (lexical category information), and CLIP (full natural language\ndescriptions). We find that all three encoders perform equally well at\ntransferring visual property information to the language model (e.g., whether\nan animal is large or small), but that image encoders pretrained with\nlinguistic supervision more saliently encode category information (e.g.,\ndistinguishing hippo vs. elephant) and thus perform significantly better on\nbenchmark language-and-vision tasks. Our results indicate that LMs encode\nconceptual information structurally similarly to vision-based models, even\nthose that are solely trained on images. Code is available here:\nhttps://github.com/jmerullo/limber\n","authors":["Jack Merullo","Louis Castricato","Carsten Eickhoff","Ellie Pavlick"],"pdf_url":"https://arxiv.org/pdf/2209.15162v3.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.05300v1","updated":"2023-03-09T14:51:10Z","published":"2023-03-09T14:51:10Z","title":"CoolPINNs: A Physics-informed Neural Network Modeling of Active Cooling\n  in Vascular Systems","summary":"  Emerging technologies like hypersonic aircraft, space exploration vehicles,\nand batteries avail fluid circulation in embedded microvasculatures for\nefficient thermal regulation. Modeling is vital during these engineered\nsystems' design and operational phases. However, many challenges exist in\ndeveloping a modeling framework. What is lacking is an accurate framework that\n(i) captures sharp jumps in the thermal flux across complex vasculature\nlayouts, (ii) deals with oblique derivatives (involving tangential and normal\ncomponents), (iii) handles nonlinearity because of radiative heat transfer,\n(iv) provides a high-speed forecast for real-time monitoring, and (v)\nfacilitates robust inverse modeling. This paper addresses these challenges by\navailing the power of physics-informed neural networks (PINNs). We develop a\nfast, reliable, and accurate Scientific Machine Learning (SciML) framework for\nvascular-based thermal regulation -- called CoolPINNs: a PINNs-based modeling\nframework for active cooling. The proposed mesh-less framework elegantly\novercomes all the mentioned challenges. The significance of the reported\nresearch is multi-fold. First, the framework is valuable for real-time\nmonitoring of thermal regulatory systems because of rapid forecasting. Second,\nresearchers can address complex thermoregulation designs inasmuch as the\napproach is mesh-less. Finally, the framework facilitates systematic parameter\nidentification and inverse modeling studies, perhaps the current framework's\nmost significant utility.\n","authors":["N. V. Jagtap","M. K. Mudunuru","K. B. Nakshatrala"],"pdf_url":"https://arxiv.org/pdf/2303.05300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05295v1","updated":"2023-03-09T14:44:31Z","published":"2023-03-09T14:44:31Z","title":"Dynamic Stashing Quantization for Efficient Transformer Training","summary":"  Large Language Models (LLMs) have demonstrated impressive performance on a\nrange of Natural Language Processing (NLP) tasks. Unfortunately, the immense\namount of computations and memory accesses required for LLM training makes them\nprohibitively expensive in terms of hardware cost, and thus challenging to\ndeploy in use cases such as on-device learning. In this paper, motivated by the\nobservation that LLM training is memory-bound, we propose a novel dynamic\nquantization strategy, termed Dynamic Stashing Quantization (DSQ), that puts a\nspecial focus on reducing the memory operations, but also enjoys the other\nbenefits of low precision training, such as the reduced arithmetic cost. We\nconduct a thorough study on two translation tasks (trained-from-scratch) and\nthree classification tasks (fine-tuning). DSQ reduces the amount of arithmetic\noperations by $20.95\\times$ and the number of DRAM operations by $2.55\\times$\non IWSLT17 compared to the standard 16-bit fixed-point, which is widely used in\non-device learning.\n","authors":["Guo Yang","Daniel Lo","Robert Mullins","Yiren Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.05295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.08147v3","updated":"2023-03-09T14:16:03Z","published":"2022-03-14T17:18:10Z","title":"Energy-Latency Attacks via Sponge Poisoning","summary":"  Sponge examples are test-time inputs carefully optimized to increase energy\nconsumption and latency of neural networks when deployed on hardware\naccelerators. In this work, we are the first to demonstrate that sponge\nexamples can also be injected at training time, via an attack that we call\nsponge poisoning. This attack allows one to increase the energy consumption and\nlatency of machine-learning models indiscriminately on each test-time input. We\npresent a novel formalization for sponge poisoning, overcoming the limitations\nrelated to the optimization of test-time sponge examples, and show that this\nattack is possible even if the attacker only controls a few model updates; for\ninstance, if model training is outsourced to an untrusted third-party or\ndistributed via federated learning. Our extensive experimental analysis shows\nthat sponge poisoning can almost completely vanish the effect of hardware\naccelerators. We also analyze the activations of poisoned models, identifying\nwhich components are more vulnerable to this attack. Finally, we examine the\nfeasibility of countermeasures against sponge poisoning to decrease energy\nconsumption, showing that sanitization methods may be overly expensive for most\nof the users.\n","authors":["Antonio Emanuele Cinà","Ambra Demontis","Battista Biggio","Fabio Roli","Marcello Pelillo"],"pdf_url":"https://arxiv.org/pdf/2203.08147v3.pdf","comment":"Preprint;16 pages"},{"id":"http://arxiv.org/abs/2302.07868v5","updated":"2023-03-09T14:12:12Z","published":"2023-02-15T18:59:27Z","title":"Target Specific De Novo Design of Drug Candidate Molecules with Graph\n  Transformer-based Generative Adversarial Networks","summary":"  Discovering novel drug candidate molecules is one of the most fundamental and\ncritical steps in drug development. Generative deep learning models, which\ncreate synthetic data given a probability distribution, have been developed\nwith the purpose of picking completely new samples from a partially known\nspace. Generative models offer high potential for designing de novo molecules;\nhowever, in order for them to be useful in real-life drug development\npipelines, these models should be able to design target-specific molecules,\nwhich is the next step in this field. In this study, we propose DrugGEN, for\nthe de novo design of drug candidate molecules that interact with selected\ntarget proteins. The proposed system represents compounds and protein\nstructures as graphs and processes them via serially connected two generative\nadversarial networks comprising graph transformers. DrugGEN is trained using a\nlarge dataset of compounds from ChEMBL and target-specific bioactive molecules,\nto design effective and specific inhibitory molecules against the AKT1 protein,\nwhich has critical importance for developing treatments against various types\nof cancer. On fundamental benchmarks, DrugGEN models have either competitive or\nbetter performance against other methods. To assess the target-specific\ngeneration performance, we conducted further in silico analysis with molecular\ndocking and deep learning-based bioactivity prediction. Results indicate that\nde novo molecules have high potential for interacting with the AKT1 protein\nstructure in the level of its native ligand. DrugGEN can be used to design\ncompletely novel and effective target-specific drug candidate molecules for any\ndruggable protein, given target features and a dataset of experimental\nbioactivities. Code base, datasets, results and trained models of DrugGEN are\navailable at https://github.com/HUBioDataLab/DrugGEN\n","authors":["Atabey Ünlü","Elif Çevrim","Ahmet Sarıgün","Hayriye Çelikbilek","Heval Ataş Güvenilir","Altay Koyaş","Deniz Cansen Kahraman","Abdurrahman Olğaç","Ahmet Rifaioğlu","Tunca Doğan"],"pdf_url":"https://arxiv.org/pdf/2302.07868v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2005.08044v6","updated":"2023-03-09T14:01:24Z","published":"2020-05-16T17:04:24Z","title":"Generalization Bounds via Information Density and Conditional\n  Information Density","summary":"  We present a general approach, based on exponential inequalities, to derive\nbounds on the generalization error of randomized learning algorithms. Using\nthis approach, we provide bounds on the average generalization error as well as\nbounds on its tail probability, for both the PAC-Bayesian and single-draw\nscenarios. Specifically, for the case of sub-Gaussian loss functions, we obtain\nnovel bounds that depend on the information density between the training data\nand the output hypothesis. When suitably weakened, these bounds recover many of\nthe information-theoretic bounds available in the literature. We also extend\nthe proposed exponential-inequality approach to the setting recently introduced\nby Steinke and Zakynthinou (2020), where the learning algorithm depends on a\nrandomly selected subset of the available training data. For this setup, we\npresent bounds for bounded loss functions in terms of the conditional\ninformation density between the output hypothesis and the random variable\ndetermining the subset choice, given all training data. Through our approach,\nwe recover the average generalization bound presented by Steinke and\nZakynthinou (2020) and extend it to the PAC-Bayesian and single-draw scenarios.\nFor the single-draw scenario, we also obtain novel bounds in terms of the\nconditional $\\alpha$-mutual information and the conditional maximal leakage.\n","authors":["Fredrik Hellström","Giuseppe Durisi"],"pdf_url":"https://arxiv.org/pdf/2005.08044v6.pdf","comment":"Published in Journal on Selected Areas in Information Theory (JSAIT).\n  This version incorporates a correction to the JSAIT version. The correction\n  is detailed at https://gdurisi.github.io/files/2021/jsait-correction.pdf"},{"id":"http://arxiv.org/abs/2303.05263v1","updated":"2023-03-09T13:58:35Z","published":"2023-03-09T13:58:35Z","title":"Fast post-process Bayesian inference with Sparse Variational Bayesian\n  Monte Carlo","summary":"  We introduce Sparse Variational Bayesian Monte Carlo (SVBMC), a method for\nfast \"post-process\" Bayesian inference for models with black-box and\npotentially noisy likelihoods. SVBMC reuses all existing target density\nevaluations -- for example, from previous optimizations or partial Markov Chain\nMonte Carlo runs -- to build a sparse Gaussian process (GP) surrogate model of\nthe log posterior density. Uncertain regions of the surrogate are then refined\nvia active learning as needed. Our work builds on the Variational Bayesian\nMonte Carlo (VBMC) framework for sample-efficient inference, with several novel\ncontributions. First, we make VBMC scalable to a large number of pre-existing\nevaluations via sparse GP regression, deriving novel Bayesian quadrature\nformulae and acquisition functions for active learning with sparse GPs. Second,\nwe introduce noise shaping, a general technique to induce the sparse GP\napproximation to focus on high posterior density regions. Third, we prove\ntheoretical results in support of the SVBMC refinement procedure. We validate\nour method on a variety of challenging synthetic scenarios and real-world\napplications. We find that SVBMC consistently builds good posterior\napproximations by post-processing of existing model evaluations from different\nsources, often requiring only a small number of additional density evaluations.\n","authors":["Chengkun Li","Grégoire Clarté","Luigi Acerbi"],"pdf_url":"https://arxiv.org/pdf/2303.05263v1.pdf","comment":"41 pages, 17 figures"},{"id":"http://arxiv.org/abs/2303.00286v2","updated":"2023-03-09T13:48:12Z","published":"2023-03-01T07:25:28Z","title":"Enhancing Knowledge Graph Embedding Models with Semantic-driven Loss\n  Functions","summary":"  Knowledge graph embedding models (KGEMs) are used for various tasks related\nto knowledge graphs (KGs), including link prediction. They are trained with\nloss functions that are computed considering a batch of scored triples and\ntheir corresponding labels. Traditional approaches consider the label of a\ntriple to be either true or false. However, recent works suggest that all\nnegative triples should not be valued equally. In line with this recent\nassumption, we posit that semantically valid negative triples might be\nhigh-quality negative triples. As such, loss functions should treat them\ndifferently from semantically invalid negative ones. To this aim, we propose\nsemantic-driven versions for the three main loss functions for link prediction.\nIn particular, we treat the scores of negative triples differently by injecting\nbackground knowledge about relation domains and ranges into the loss functions.\nIn an extensive and controlled experimental setting, we show that the proposed\nloss functions systematically provide satisfying results on three public\nbenchmark KGs underpinned with different schemas, which demonstrates both the\ngenerality and superiority of our proposed approach. In fact, the proposed loss\nfunctions do (1) lead to better MRR and Hits@$10$ values, (2) drive KGEMs\ntowards better semantic awareness. This highlights that semantic information\nglobally improves KGEMs, and thus should be incorporated into loss functions.\nDomains and ranges of relations being largely available in schema-defined KGs,\nthis makes our approach both beneficial and widely usable in practice.\n","authors":["Nicolas Hubert","Pierre Monnin","Armelle Brun","Davy Monticolo"],"pdf_url":"https://arxiv.org/pdf/2303.00286v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07533v4","updated":"2023-03-09T13:39:49Z","published":"2022-11-14T17:03:56Z","title":"Generalized Balancing Weights via Deep Neural Networks","summary":"  We present generalized balancing weights, Neural Balancing Weights (NBW), to\nestimate the causal effects for an arbitrary mixture of discrete and continuous\ninterventions. The weights were obtained by directly estimating the density\nratio between the source and balanced distributions by optimizing the\nvariational representation of $f$-divergence. For this, we selected\n$\\alpha$-divergence since it has good properties for optimization: It has an\nestimator whose sample complexity is independent of it's ground truth value and\nunbiased mini-batch gradients and is advantageous for the vanishing gradient\nproblem. In addition, we provide a method for checking the balance of the\ndistribution changed by the weights. If the balancing is imperfect, the weights\ncan be improved by adding new balancing weights. Our method can be conveniently\nimplemented with any present deep-learning libraries, and weights can be used\nin most state-of-the-art supervised algorithms. The code for our method is\navailable online.\n","authors":["Yoshiaki Kitazawa"],"pdf_url":"https://arxiv.org/pdf/2211.07533v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05246v1","updated":"2023-03-09T13:33:36Z","published":"2023-03-09T13:33:36Z","title":"Efficient Certified Training and Robustness Verification of Neural ODEs","summary":"  Neural Ordinary Differential Equations (NODEs) are a novel neural\narchitecture, built around initial value problems with learned dynamics which\nare solved during inference. Thought to be inherently more robust against\nadversarial perturbations, they were recently shown to be vulnerable to strong\nadversarial attacks, highlighting the need for formal guarantees. However,\ndespite significant progress in robustness verification for standard\nfeed-forward architectures, the verification of high dimensional NODEs remains\nan open problem. In this work, we address this challenge and propose GAINS, an\nanalysis framework for NODEs combining three key ideas: (i) a novel class of\nODE solvers, based on variable but discrete time steps, (ii) an efficient graph\nrepresentation of solver trajectories, and (iii) a novel abstraction algorithm\noperating on this graph representation. Together, these advances enable the\nefficient analysis and certified training of high-dimensional NODEs, by\nreducing the runtime from an intractable $O(\\exp(d)+\\exp(T))$ to ${O}(d+T^2\n\\log^2T)$ in the dimensionality $d$ and integration time $T$. In an extensive\nevaluation on computer vision (MNIST and FMNIST) and time-series forecasting\n(PHYSIO-NET) problems, we demonstrate the effectiveness of both our certified\ntraining and verification methods.\n","authors":["Mustafa Zeqiri","Mark Niklas Müller","Marc Fischer","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2303.05246v1.pdf","comment":"Accepted at ICLR23"},{"id":"http://arxiv.org/abs/2205.01992v3","updated":"2023-03-09T13:26:35Z","published":"2022-05-04T11:00:26Z","title":"Wild Patterns Reloaded: A Survey of Machine Learning Security against\n  Training Data Poisoning","summary":"  The success of machine learning is fueled by the increasing availability of\ncomputing power and large training datasets. The training data is used to learn\nnew models or update existing ones, assuming that it is sufficiently\nrepresentative of the data that will be encountered at test time. This\nassumption is challenged by the threat of poisoning, an attack that manipulates\nthe training data to compromise the model's performance at test time. Although\npoisoning has been acknowledged as a relevant threat in industry applications,\nand a variety of different attacks and defenses have been proposed so far, a\ncomplete systematization and critical review of the field is still missing. In\nthis survey, we provide a comprehensive systematization of poisoning attacks\nand defenses in machine learning, reviewing more than 100 papers published in\nthe field in the last 15 years. We start by categorizing the current threat\nmodels and attacks, and then organize existing defenses accordingly. While we\nfocus mostly on computer-vision applications, we argue that our systematization\nalso encompasses state-of-the-art attacks and defenses for other data\nmodalities. Finally, we discuss existing resources for research in poisoning,\nand shed light on the current limitations and open research questions in this\nresearch field.\n","authors":["Antonio Emanuele Cinà","Kathrin Grosse","Ambra Demontis","Sebastiano Vascon","Werner Zellinger","Bernhard A. Moser","Alina Oprea","Battista Biggio","Marcello Pelillo","Fabio Roli"],"pdf_url":"https://arxiv.org/pdf/2205.01992v3.pdf","comment":"35 pages, Accepted at ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2210.01620v2","updated":"2023-03-09T13:24:17Z","published":"2022-10-04T14:02:51Z","title":"SAM as an Optimal Relaxation of Bayes","summary":"  Sharpness-aware minimization (SAM) and related adversarial deep-learning\nmethods can drastically improve generalization, but their underlying mechanisms\nare not yet fully understood. Here, we establish SAM as a relaxation of the\nBayes objective where the expected negative-loss is replaced by the optimal\nconvex lower bound, obtained by using the so-called Fenchel biconjugate. The\nconnection enables a new Adam-like extension of SAM to automatically obtain\nreasonable uncertainty estimates, while sometimes also improving its accuracy.\nBy connecting adversarial and Bayesian methods, our work opens a new path to\nrobustness.\n","authors":["Thomas Möllenhoff","Mohammad Emtiyaz Khan"],"pdf_url":"https://arxiv.org/pdf/2210.01620v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.05231v1","updated":"2023-03-09T13:13:43Z","published":"2023-03-09T13:13:43Z","title":"Structure-Aware Group Discrimination with Adaptive-View Graph Encoder: A\n  Fast Graph Contrastive Learning Framework","summary":"  Albeit having gained significant progress lately, large-scale graph\nrepresentation learning remains expensive to train and deploy for two main\nreasons: (i) the repetitive computation of multi-hop message passing and\nnon-linearity in graph neural networks (GNNs); (ii) the computational cost of\ncomplex pairwise contrastive learning loss. Two main contributions are made in\nthis paper targeting this twofold challenge: we first propose an adaptive-view\ngraph neural encoder (AVGE) with a limited number of message passing to\naccelerate the forward pass computation, and then we propose a structure-aware\ngroup discrimination (SAGD) loss in our framework which avoids inefficient\npairwise loss computing in most common GCL and improves the performance of the\nsimple group discrimination. By the framework proposed, we manage to bring down\nthe training and inference cost on various large-scale datasets by a\nsignificant margin (250x faster inference time) without loss of the\ndownstream-task performance.\n","authors":["Zhenshuo Zhang","Yun Zhu","Haizhou Shi","Siliang Tang"],"pdf_url":"https://arxiv.org/pdf/2303.05231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01932v2","updated":"2023-03-09T13:08:22Z","published":"2023-03-03T14:02:50Z","title":"MobileBrick: Building LEGO for 3D Reconstruction on Mobile Devices","summary":"  High-quality 3D ground-truth shapes are critical for 3D object reconstruction\nevaluation. However, it is difficult to create a replica of an object in\nreality, and even 3D reconstructions generated by 3D scanners have artefacts\nthat cause biases in evaluation. To address this issue, we introduce a novel\nmulti-view RGBD dataset captured using a mobile device, which includes highly\nprecise 3D ground-truth annotations for 153 object models featuring a diverse\nset of 3D structures. We obtain precise 3D ground-truth shape without relying\non high-end 3D scanners by utilising LEGO models with known geometry as the 3D\nstructures for image capture. The distinct data modality offered by\nhigh-resolution RGB images and low-resolution depth maps captured on a mobile\ndevice, when combined with precise 3D geometry annotations, presents a unique\nopportunity for future research on high-fidelity 3D reconstruction.\nFurthermore, we evaluate a range of 3D reconstruction algorithms on the\nproposed dataset. Project page: http://code.active.vision/MobileBrick/\n","authors":["Kejie Li","Jia-Wang Bian","Robert Castle","Philip H. S. Torr","Victor Adrian Prisacariu"],"pdf_url":"https://arxiv.org/pdf/2303.01932v2.pdf","comment":"To be appeared at CVPR 2023"},{"id":"http://arxiv.org/abs/2210.04871v2","updated":"2023-03-09T13:02:17Z","published":"2022-10-10T17:44:11Z","title":"Certified Training: Small Boxes are All You Need","summary":"  To obtain, deterministic guarantees of adversarial robustness, specialized\ntraining methods are used. We propose, SABR, a novel such certified training\nmethod, based on the key insight that propagating interval bounds for a small\nbut carefully selected subset of the adversarial input region is sufficient to\napproximate the worst-case loss over the whole region while significantly\nreducing approximation errors. We show in an extensive empirical evaluation\nthat SABR outperforms existing certified defenses in terms of both standard and\ncertifiable accuracies across perturbation magnitudes and datasets, pointing to\na new class of certified training methods promising to alleviate the\nrobustness-accuracy trade-off.\n","authors":["Mark Niklas Müller","Franziska Eckert","Marc Fischer","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2210.04871v2.pdf","comment":"Accepted at ICLR23 as Spotlight"},{"id":"http://arxiv.org/abs/2206.11124v2","updated":"2023-03-09T12:58:51Z","published":"2022-06-22T14:15:35Z","title":"A view of mini-batch SGD via generating functions: conditions of\n  convergence, phase transitions, benefit from negative momenta","summary":"  Mini-batch SGD with momentum is a fundamental algorithm for learning large\npredictive models. In this paper we develop a new analytic framework to analyze\nnoise-averaged properties of mini-batch SGD for linear models at constant\nlearning rates, momenta and sizes of batches. Our key idea is to consider the\ndynamics of the second moments of model parameters for a special family of\n\"Spectrally Expressible\" approximations. This allows to obtain an explicit\nexpression for the generating function of the sequence of loss values. By\nanalyzing this generating function, we find, in particular, that 1) the SGD\ndynamics exhibits several convergent and divergent regimes depending on the\nspectral distributions of the problem; 2) the convergent regimes admit explicit\nstability conditions, and explicit loss asymptotics in the case of power-law\nspectral distributions; 3) the optimal convergence rate can be achieved at\nnegative momenta. We verify our theoretical predictions by extensive\nexperiments with MNIST, CIFAR10 and synthetic problems, and find a good\nquantitative agreement.\n","authors":["Maksim Velikanov","Denis Kuznedelev","Dmitry Yarotsky"],"pdf_url":"https://arxiv.org/pdf/2206.11124v2.pdf","comment":"The revised version accepted at ICLR2023"},{"id":"http://arxiv.org/abs/2303.05214v1","updated":"2023-03-09T12:37:33Z","published":"2023-03-09T12:37:33Z","title":"Taming Contrast Maximization for Learning Sequential, Low-latency,\n  Event-based Optical Flow","summary":"  Event cameras have recently gained significant traction since they open up\nnew avenues for low-latency and low-power solutions to complex computer vision\nproblems. To unlock these solutions, it is necessary to develop algorithms that\ncan leverage the unique nature of event data. However, the current\nstate-of-the-art is still highly influenced by the frame-based literature, and\nusually fails to deliver on these promises. In this work, we take this into\nconsideration and propose a novel self-supervised learning pipeline for the\nsequential estimation of event-based optical flow that allows for the scaling\nof the models to high inference frequencies. At its core, we have a\ncontinuously-running stateful neural model that is trained using a novel\nformulation of contrast maximization that makes it robust to nonlinearities and\nvarying statistics in the input events. Results across multiple datasets\nconfirm the effectiveness of our method, which establishes a new state of the\nart in terms of accuracy for approaches trained or optimized without ground\ntruth.\n","authors":["Federico Paredes-Vallés","Kirk Y. W. Scheper","Christophe De Wagter","Guido C. H. E. de Croon"],"pdf_url":"https://arxiv.org/pdf/2303.05214v1.pdf","comment":"15 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2303.05206v1","updated":"2023-03-09T12:19:45Z","published":"2023-03-09T12:19:45Z","title":"FedREP: A Byzantine-Robust, Communication-Efficient and\n  Privacy-Preserving Framework for Federated Learning","summary":"  Federated learning (FL) has recently become a hot research topic, in which\nByzantine robustness, communication efficiency and privacy preservation are\nthree important aspects. However, the tension among these three aspects makes\nit hard to simultaneously take all of them into account. In view of this\nchallenge, we theoretically analyze the conditions that a communication\ncompression method should satisfy to be compatible with existing\nByzantine-robust methods and privacy-preserving methods. Motivated by the\nanalysis results, we propose a novel communication compression method called\nconsensus sparsification (ConSpar). To the best of our knowledge, ConSpar is\nthe first communication compression method that is designed to be compatible\nwith both Byzantine-robust methods and privacy-preserving methods. Based on\nConSpar, we further propose a novel FL framework called FedREP, which is\nByzantine-robust, communication-efficient and privacy-preserving. We\ntheoretically prove the Byzantine robustness and the convergence of FedREP.\nEmpirical results show that FedREP can significantly outperform\ncommunication-efficient privacy-preserving baselines. Furthermore, compared\nwith Byzantine-robust communication-efficient baselines, FedREP can achieve\ncomparable accuracy with the extra advantage of privacy preservation.\n","authors":["Yi-Rui Yang","Kun Wang","Wu-Jun Li"],"pdf_url":"https://arxiv.org/pdf/2303.05206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05205v1","updated":"2023-03-09T12:19:20Z","published":"2023-03-09T12:19:20Z","title":"Real-time scheduling of renewable power systems through planning-based\n  reinforcement learning","summary":"  The growing renewable energy sources have posed significant challenges to\ntraditional power scheduling. It is difficult for operators to obtain accurate\nday-ahead forecasts of renewable generation, thereby requiring the future\nscheduling system to make real-time scheduling decisions aligning with\nultra-short-term forecasts. Restricted by the computation speed, traditional\noptimization-based methods can not solve this problem. Recent developments in\nreinforcement learning (RL) have demonstrated the potential to solve this\nchallenge. However, the existing RL methods are inadequate in terms of\nconstraint complexity, algorithm performance, and environment fidelity. We are\nthe first to propose a systematic solution based on the state-of-the-art\nreinforcement learning algorithm and the real power grid environment. The\nproposed approach enables planning and finer time resolution adjustments of\npower generators, including unit commitment and economic dispatch, thus\nincreasing the grid's ability to admit more renewable energy. The well-trained\nscheduling agent significantly reduces renewable curtailment and load shedding,\nwhich are issues arising from traditional scheduling's reliance on inaccurate\nday-ahead forecasts. High-frequency control decisions exploit the existing\nunits' flexibility, reducing the power grid's dependence on hardware\ntransformations and saving investment and operating costs, as demonstrated in\nexperimental results. This research exhibits the potential of reinforcement\nlearning in promoting low-carbon and intelligent power systems and represents a\nsolid step toward sustainable electricity generation.\n","authors":["Shaohuai Liu","Jinbo Liu","Weirui Ye","Nan Yang","Guanglun Zhang","Haiwang Zhong","Chongqing Kang","Qirong Jiang","Xuri Song","Fangchun Di","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2303.05205v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2112.11027v4","updated":"2023-03-09T12:01:56Z","published":"2021-12-21T07:55:55Z","title":"More is Less: Inducing Sparsity via Overparameterization","summary":"  In deep learning it is common to overparameterize neural networks, that is,\nto use more parameters than training samples. Quite surprisingly training the\nneural network via (stochastic) gradient descent leads to models that\ngeneralize very well, while classical statistics would suggest overfitting. In\norder to gain understanding of this implicit bias phenomenon we study the\nspecial case of sparse recovery (compressed sensing) which is of interest on\nits own. More precisely, in order to reconstruct a vector from underdetermined\nlinear measurements, we introduce a corresponding overparameterized square loss\nfunctional, where the vector to be reconstructed is deeply factorized into\nseveral vectors. We show that, if there exists an exact solution, vanilla\ngradient flow for the overparameterized loss functional converges to a good\napproximation of the solution of minimal $\\ell_1$-norm. The latter is\nwell-known to promote sparse solutions. As a by-product, our results\nsignificantly improve the sample complexity for compressed sensing via gradient\nflow/descent on overparameterized models derived in previous works. The theory\naccurately predicts the recovery rate in numerical experiments. Our proof\nrelies on analyzing a certain Bregman divergence of the flow. This bypasses the\nobstacles caused by non-convexity and should be of independent interest.\n","authors":["Hung-Hsu Chou","Johannes Maly","Holger Rauhut"],"pdf_url":"https://arxiv.org/pdf/2112.11027v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.09495v2","updated":"2023-03-09T12:01:51Z","published":"2022-06-19T22:10:38Z","title":"The Power of Regularization in Solving Extensive-Form Games","summary":"  In this paper, we investigate the power of {\\it regularization}, a common\ntechnique in reinforcement learning and optimization, in solving extensive-form\ngames (EFGs). We propose a series of new algorithms based on regularizing the\npayoff functions of the game, and establish a set of convergence results that\nstrictly improve over the existing ones, with either weaker assumptions or\nstronger convergence guarantees. In particular, we first show that dilated\noptimistic mirror descent (DOMD), an efficient variant of OMD for solving EFGs,\nwith adaptive regularization can achieve a fast $\\tilde O(1/T)$ last-iterate\nconvergence in terms of duality gap and distance to the set of Nash equilibrium\n(NE) without uniqueness assumption of the NE. Second, we show that regularized\ncounterfactual regret minimization (\\texttt{Reg-CFR}), with a variant of\noptimistic mirror descent algorithm as regret-minimizer, can achieve\n$O(1/T^{1/4})$ best-iterate, and $O(1/T^{3/4})$ average-iterate convergence\nrate for finding NE in EFGs. Finally, we show that \\texttt{Reg-CFR} can achieve\nasymptotic last-iterate convergence, and optimal $O(1/T)$ average-iterate\nconvergence rate, for finding the NE of perturbed EFGs, which is useful for\nfinding approximate extensive-form perfect equilibria (EFPE). To the best of\nour knowledge, they constitute the first last-iterate convergence results for\nCFR-type algorithms, while matching the state-of-the-art average-iterate\nconvergence rate in finding NE for non-perturbed EFGs. We also provide\nnumerical results to corroborate the advantages of our algorithms.\n","authors":["Mingyang Liu","Asuman Ozdaglar","Tiancheng Yu","Kaiqing Zhang"],"pdf_url":"https://arxiv.org/pdf/2206.09495v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05197v1","updated":"2023-03-09T11:52:52Z","published":"2023-03-09T11:52:52Z","title":"Mastering Strategy Card Game (Hearthstone) with Improved Techniques","summary":"  Strategy card game is a well-known genre that is demanding on the intelligent\ngame-play and can be an ideal test-bench for AI. Previous work combines an\nend-to-end policy function and an optimistic smooth fictitious play, which\nshows promising performances on the strategy card game Legend of Code and\nMagic. In this work, we apply such algorithms to Hearthstone, a famous\ncommercial game that is more complicated in game rules and mechanisms. We\nfurther propose several improved techniques and consequently achieve\nsignificant progress. For a machine-vs-human test we invite a Hearthstone\nstreamer whose best rank was top 10 of the official league in China region that\nis estimated to be of millions of players. Our models defeat the human player\nin all Best-of-5 tournaments of full games (including both deck building and\nbattle), showing a strong capability of decision making.\n","authors":["Changnan Xiao","Yongxin Zhang","Xuefeng Huang","Qinhan Huang","Jie Chen","Peng Sun"],"pdf_url":"https://arxiv.org/pdf/2303.05197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05193v1","updated":"2023-03-09T11:45:48Z","published":"2023-03-09T11:45:48Z","title":"GOATS: Goal Sampling Adaptation for Scooping with Curriculum\n  Reinforcement Learning","summary":"  In this work, we first formulate the problem of goal-conditioned robotic\nwater scooping with reinforcement learning. This task is challenging due to the\ncomplex dynamics of fluid and multi-modal goal-reaching. The policy is required\nto achieve both position goals and water amount goals, which leads to a large\nconvoluted goal state space. To address these challenges, we introduce Goal\nSampling Adaptation for Scooping (GOATS), a curriculum reinforcement learning\nmethod that can learn an effective and generalizable policy for robot scooping\ntasks. Specifically, we use a goal-factorized reward formulation and\ninterpolate position goal distributions and amount goal distributions to create\ncurriculum through the learning process. As a result, our proposed method can\noutperform the baselines in simulation and achieves 5.46% and 8.71% amount\nerrors on bowl scooping and bucket scooping tasks, respectively, under 1000\nvariations of initial water states in the tank and a large goal state space.\nBesides being effective in simulation environments, our method can efficiently\ngeneralize to noisy real-robot water-scooping scenarios with different physical\nconfigurations and unseen settings, demonstrating superior efficacy and\ngeneralizability. The videos of this work are available on our project page:\nhttps://sites.google.com/view/goatscooping.\n","authors":["Yaru Niu","Shiyu Jin","Zeqing Zhang","Jiacheng Zhu","Ding Zhao","Liangjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.09427v4","updated":"2023-03-09T11:34:24Z","published":"2021-12-17T10:47:17Z","title":"Continual Learning for Monolingual End-to-End Automatic Speech\n  Recognition","summary":"  Adapting Automatic Speech Recognition (ASR) models to new domains results in\na deterioration of performance on the original domain(s), a phenomenon called\nCatastrophic Forgetting (CF). Even monolingual ASR models cannot be extended to\nnew accents, dialects, topics, etc. without suffering from CF, making them\nunable to be continually enhanced without storing all past data. Fortunately,\nContinual Learning (CL) methods, which aim to enable continual adaptation while\novercoming CF, can be used. In this paper, we implement an extensive number of\nCL methods for End-to-End ASR and test and compare their ability to extend a\nmonolingual Hybrid CTC-Transformer model across four new tasks. We find that\nthe best performing CL method closes the gap between the fine-tuned model\n(lower bound) and the model trained jointly on all tasks (upper bound) by more\nthan 40%, while requiring access to only 0.6% of the original data.\n","authors":["Steven Vander Eeckt","Hugo Van hamme"],"pdf_url":"https://arxiv.org/pdf/2112.09427v4.pdf","comment":"Published at EUSIPCO 2022. 5 pages, 1 figure"},{"id":"http://arxiv.org/abs/2303.05186v1","updated":"2023-03-09T11:30:40Z","published":"2023-03-09T11:30:40Z","title":"A Framework for History-Aware Hyperparameter Optimisation in\n  Reinforcement Learning","summary":"  A Reinforcement Learning (RL) system depends on a set of initial conditions\n(hyperparameters) that affect the system's performance. However, defining a\ngood choice of hyperparameters is a challenging problem.\n  Hyperparameter tuning often requires manual or automated searches to find\noptimal values. Nonetheless, a noticeable limitation is the high cost of\nalgorithm evaluation for complex models, making the tuning process\ncomputationally expensive and time-consuming.\n  In this paper, we propose a framework based on integrating complex event\nprocessing and temporal models, to alleviate these trade-offs. Through this\ncombination, it is possible to gain insights about a running RL system\nefficiently and unobtrusively based on data stream monitoring and to create\nabstract representations that allow reasoning about the historical behaviour of\nthe RL system. The obtained knowledge is exploited to provide feedback to the\nRL system for optimising its hyperparameters while making effective use of\nparallel resources.\n  We introduce a novel history-aware epsilon-greedy logic for hyperparameter\noptimisation that instead of using static hyperparameters that are kept fixed\nfor the whole training, adjusts the hyperparameters at runtime based on the\nanalysis of the agent's performance over time windows in a single agent's\nlifetime. We tested the proposed approach in a 5G mobile communications case\nstudy that uses DQN, a variant of RL, for its decision-making. Our experiments\ndemonstrated the effects of hyperparameter tuning using history on training\nstability and reward values. The encouraging results show that the proposed\nhistory-aware framework significantly improved performance compared to\ntraditional hyperparameter tuning approaches.\n","authors":["Juan Marcelo Parra-Ullauri","Chen Zhen","Antonio García-Domínguez","Nelly Bencomo","Changgang Zheng","Juan Boubeta-Puig","Guadalupe Ortiz","Shufan Yang"],"pdf_url":"https://arxiv.org/pdf/2303.05186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05161v1","updated":"2023-03-09T10:35:40Z","published":"2023-03-09T10:35:40Z","title":"Inversion dynamics of class manifolds in deep learning reveals tradeoffs\n  underlying generalisation","summary":"  To achieve near-zero training error in a classification problem, the layers\nof a deep network have to disentangle the manifolds of data points with\ndifferent labels, to facilitate the discrimination. However, excessive class\nseparation can bring to overfitting since good generalisation requires learning\ninvariant features, which involve some level of entanglement. We report on\nnumerical experiments showing how the optimisation dynamics finds\nrepresentations that balance these opposing tendencies with a non-monotonic\ntrend. After a fast segregation phase, a slower rearrangement (conserved across\ndata sets and architectures) increases the class entanglement. The training\nerror at the inversion is remarkably stable under subsampling, and across\nnetwork initialisations and optimisers, which characterises it as a property\nsolely of the data structure and (very weakly) of the architecture. The\ninversion is the manifestation of tradeoffs elicited by well-defined and\nmaximally stable elements of the training set, coined \"stragglers\",\nparticularly influential for generalisation.\n","authors":["Simone Ciceri","Lorenzo Cassani","Pierre Pizzochero","Matteo Osella","Pietro Rotondo","Marco Gherardi"],"pdf_url":"https://arxiv.org/pdf/2303.05161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.05818v4","updated":"2023-03-09T10:24:02Z","published":"2022-01-15T10:04:05Z","title":"Measuring Non-Probabilistic Uncertainty","summary":"  There are two reasons why uncertainty about the future yield of investments\nmay not be adequately described by Probability Theory. The first one is due to\nunique or nearly-unique events, that either never realized or occurred too\nseldom for probabilities to be reliable. The second one arises when when one\nfears that something may happen, that one is not even able to figure out, e.g.,\nif one asks: \"Climate change, financial crises, pandemic, war, what next?\"\n  In both cases, simple one-to-one causal mappings between available\nalternatives and possible consequences eventually melt down. However, such\ndestructions reflect into the changing narratives of business executives,\nemployees and other stakeholders in specific, identifiable and differential\nways. In particular, texts such as consultants' reports or letters to\nshareholders can be analysed in order to detect the impact of both sorts of\nuncertainty onto the causal relations that normally guide decision-making.\n  We propose structural measures of causal mappings as a means to measure\nnon-probabilistic uncertainty, eventually suggesting that automated text\nanalysis can greatly augment the possibilities offered by these techniques.\nProspective applications may concern statistical institutes, stock market\ntraders, as well as businesses wishing to compare their own vision to those\nprevailing in their industry.\n","authors":["Florian Ellsaesser","Guido Fioretti","Gail E. James"],"pdf_url":"https://arxiv.org/pdf/2201.05818v4.pdf","comment":"22 pages, 15 figures"},{"id":"http://arxiv.org/abs/2303.05155v1","updated":"2023-03-09T10:15:03Z","published":"2023-03-09T10:15:03Z","title":"Aux-Drop: Handling Haphazard Inputs in Online Learning Using Auxiliary\n  Dropouts","summary":"  Many real-world applications based on online learning produce streaming data\nthat is haphazard in nature, i.e., contains missing features, features becoming\nobsolete in time, the appearance of new features at later points in time and a\nlack of clarity on the total number of input features. These challenges make it\nhard to build a learnable system for such applications, and almost no work\nexists in deep learning that addresses this issue. In this paper, we present\nAux-Drop, an auxiliary dropout regularization strategy for online learning that\nhandles the haphazard input features in an effective manner. Aux-Drop adapts\nthe conventional dropout regularization scheme for the haphazard input feature\nspace ensuring that the final output is minimally impacted by the chaotic\nappearance of such features. It helps to prevent the co-adaptation of\nespecially the auxiliary and base features, as well as reduces the strong\ndependence of the output on any of the auxiliary inputs of the model. This\nhelps in better learning for scenarios where certain features disappear in time\nor when new features are to be modeled. The efficacy of Aux-Drop has been\ndemonstrated through extensive numerical experiments on SOTA benchmarking\ndatasets that include Italy Power Demand, HIGGS, SUSY and multiple UCI\ndatasets.\n","authors":["Rohit Agarwal","Deepak Gupta","Alexander Horsch","Dilip K. Prasad"],"pdf_url":"https://arxiv.org/pdf/2303.05155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05151v1","updated":"2023-03-09T10:08:34Z","published":"2023-03-09T10:08:34Z","title":"Provable Data Subset Selection For Efficient Neural Network Training","summary":"  Radial basis function neural networks (\\emph{RBFNN}) are {well-known} for\ntheir capability to approximate any continuous function on a closed bounded set\nwith arbitrary precision given enough hidden neurons. In this paper, we\nintroduce the first algorithm to construct coresets for \\emph{RBFNNs}, i.e.,\nsmall weighted subsets that approximate the loss of the input data on any\nradial basis function network and thus approximate any function defined by an\n\\emph{RBFNN} on the larger input data. In particular, we construct coresets for\nradial basis and Laplacian loss functions. We then use our coresets to obtain a\nprovable data subset selection algorithm for training deep neural networks.\nSince our coresets approximate every function, they also approximate the\ngradient of each weight in a neural network, which is a particular function on\nthe input. We then perform empirical evaluations on function approximation and\ndataset subset selection on popular network architectures and data sets,\ndemonstrating the efficacy and accuracy of our coreset construction.\n","authors":["Murad Tukan","Samson Zhou","Alaa Maalouf","Daniela Rus","Vladimir Braverman","Dan Feldman"],"pdf_url":"https://arxiv.org/pdf/2303.05151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05143v1","updated":"2023-03-09T09:52:28Z","published":"2023-03-09T09:52:28Z","title":"ESCL: Equivariant Self-Contrastive Learning for Sentence Representations","summary":"  Previous contrastive learning methods for sentence representations often\nfocus on insensitive transformations to produce positive pairs, but neglect the\nrole of sensitive transformations that are harmful to semantic representations.\nTherefore, we propose an Equivariant Self-Contrastive Learning (ESCL) method to\nmake full use of sensitive transformations, which encourages the learned\nrepresentations to be sensitive to certain types of transformations with an\nadditional equivariant learning task. Meanwhile, in order to improve\npracticability and generality, ESCL simplifies the implementations of\ntraditional equivariant contrastive methods to share model parameters from the\nperspective of multi-task learning. We evaluate our ESCL on semantic textual\nsimilarity tasks. The proposed method achieves better results while using fewer\nlearning parameters compared to previous methods.\n","authors":["Jie Liu","Yixuan Liu","Xue Han","Chao Deng","Junlan Feng"],"pdf_url":"https://arxiv.org/pdf/2303.05143v1.pdf","comment":"accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2209.03694v3","updated":"2023-03-09T09:51:34Z","published":"2022-09-08T10:27:53Z","title":"Aerial View Localization with Reinforcement Learning: Towards Emulating\n  Search-and-Rescue","summary":"  Climate-induced disasters are and will continue to be on the rise, and thus\nsearch-and-rescue (SAR) operations, where the task is to localize and assist\none or several people who are missing, become increasingly relevant. In many\ncases the rough location may be known and a UAV can be deployed to explore a\ngiven, confined area to precisely localize the missing people. Due to time and\nbattery constraints it is often critical that localization is performed as\nefficiently as possible. In this work we approach this type of problem by\nabstracting it as an aerial view goal localization task in a framework that\nemulates a SAR-like setup without requiring access to actual UAVs. In this\nframework, an agent operates on top of an aerial image (proxy for a search\narea) and is tasked with localizing a goal that is described in terms of visual\ncues. To further mimic the situation on an actual UAV, the agent is not able to\nobserve the search area in its entirety, not even at low resolution, and thus\nit has to operate solely based on partial glimpses when navigating towards the\ngoal. To tackle this task, we propose AiRLoc, a reinforcement learning\n(RL)-based model that decouples exploration (searching for distant goals) and\nexploitation (localizing nearby goals). Extensive evaluations show that AiRLoc\noutperforms heuristic search methods as well as alternative learnable\napproaches, and that it generalizes across datasets, e.g. to disaster-hit areas\nwithout seeing a single disaster scenario during training. We also conduct a\nproof-of-concept study which indicates that the learnable methods outperform\nhumans on average. Code and models have been made publicly available at\nhttps://github.com/aleksispi/airloc.\n","authors":["Aleksis Pirinen","Anton Samuelsson","John Backsund","Kalle Åström"],"pdf_url":"https://arxiv.org/pdf/2209.03694v3.pdf","comment":"Accepted to ICLR 2023 Workshop on Machine Learning for Remote Sensing"},{"id":"http://arxiv.org/abs/2303.05138v1","updated":"2023-03-09T09:46:48Z","published":"2023-03-09T09:46:48Z","title":"The joint node degree distribution in the Erdős-Rényi network","summary":"  The Erd\\H{o}s-R\\'enyi random graph is the simplest model for node degree\ndistribution, and it is one of the most widely studied. In this model, pairs of\n$n$ vertices are selected and connected uniformly at random with probability\n$p$, consequently, the degrees for a given vertex follow the binomial\ndistribution. If the number of vertices is large, the binomial can be\napproximated by Normal using the Central Limit Theorem, which is often allowed\nwhen $\\min (np, n(1-p)) > 5$. This is true for every node independently.\nHowever, due to the fact that the degrees of nodes in a graph are not\nindependent, we aim in this paper to test whether the degrees of per node\ncollectively in the Erd\\H{o}s-R\\'enyi graph have a multivariate normal\ndistribution MVN. A chi square goodness of fit test for the hypothesis that\nbinomial is a distribution for the whole set of nodes is rejected because of\nthe dependence between degrees. Before testing MVN we show that the covariance\nand correlation between the degrees of any pair of nodes in the graph are\n$p(1-p)$ and $1/(n-1)$, respectively. We test MVN considering two assumptions:\nindependent and dependent degrees, and we obtain our results based on the\npercentages of rejected statistics of chi square, the $p$-values of Anderson\nDarling test, and a CDF comparison. We always achieve a good fit of\nmultivariate normal distribution with large values of $n$ and $p$, and very\npoor fit when $n$ or $p$ are very small. The approximation seems valid when $np\n\\geq 10$. We also compare the maximum likelihood estimate of $p$ in MVN\ndistribution where we assume independence and dependence. The estimators are\nassessed using bias, variance and mean square error.\n","authors":["Boshra Alarfaj","Charles Taylor","Leonid Bogachev"],"pdf_url":"https://arxiv.org/pdf/2303.05138v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2301.07040v2","updated":"2023-03-09T09:46:21Z","published":"2023-01-17T17:49:04Z","title":"Optimal Algorithms for Latent Bandits with Cluster Structure","summary":"  We consider the problem of latent bandits with cluster structure where there\nare multiple users, each with an associated multi-armed bandit problem. These\nusers are grouped into \\emph{latent} clusters such that the mean reward vectors\nof users within the same cluster are identical. At each round, a user, selected\nuniformly at random, pulls an arm and observes a corresponding noisy reward.\nThe goal of the users is to maximize their cumulative rewards. This problem is\ncentral to practical recommendation systems and has received wide attention of\nlate \\cite{gentile2014online, maillard2014latent}. Now, if each user acts\nindependently, then they would have to explore each arm independently and a\nregret of $\\Omega(\\sqrt{\\mathsf{MNT}})$ is unavoidable, where $\\mathsf{M},\n\\mathsf{N}$ are the number of arms and users, respectively. Instead, we propose\nLATTICE (Latent bAndiTs via maTrIx ComplEtion) which allows exploitation of the\nlatent cluster structure to provide the minimax optimal regret of\n$\\widetilde{O}(\\sqrt{(\\mathsf{M}+\\mathsf{N})\\mathsf{T}})$, when the number of\nclusters is $\\widetilde{O}(1)$. This is the first algorithm to guarantee such\nstrong regret bound. LATTICE is based on a careful exploitation of arm\ninformation within a cluster while simultaneously clustering users.\nFurthermore, it is computationally efficient and requires only\n$O(\\log{\\mathsf{T}})$ calls to an offline matrix completion oracle across all\n$\\mathsf{T}$ rounds.\n","authors":["Soumyabrata Pal","Arun Sai Suggala","Karthikeyan Shanmugam","Prateek Jain"],"pdf_url":"https://arxiv.org/pdf/2301.07040v2.pdf","comment":"44 pages. Accepted to AISTATS 2023. Added Experiments"},{"id":"http://arxiv.org/abs/2211.09565v2","updated":"2023-03-09T09:31:24Z","published":"2022-11-17T14:40:31Z","title":"Towards Good Practices in Evaluating Transfer Adversarial Attacks","summary":"  Transfer adversarial attacks raise critical security concerns in real-world,\nblack-box scenarios. However, the actual progress of this field is difficult to\nassess due to two common limitations in existing evaluations. First, different\nmethods are often not systematically and fairly evaluated in a one-to-one\ncomparison. Second, only transferability is evaluated but another key attack\nproperty, stealthiness, is largely overlooked. In this work, we design good\npractices to address these limitations, and we present the first comprehensive\nevaluation of transfer attacks, covering 23 representative attacks against 9\ndefenses on ImageNet. In particular, we propose to categorize existing attacks\ninto five categories, which enables our systematic category-wise analyses.\nThese analyses lead to new findings that even challenge existing knowledge and\nalso help determine the optimal attack hyperparameters for our attack-wise\ncomprehensive evaluation. We also pay particular attention to stealthiness, by\nadopting diverse imperceptibility metrics and looking into new, finer-grained\ncharacteristics. Overall, our new insights into transferability and\nstealthiness lead to actionable good practices for future evaluations.\n","authors":["Zhengyu Zhao","Hanwei Zhang","Renjue Li","Ronan Sicre","Laurent Amsaleg","Michael Backes"],"pdf_url":"https://arxiv.org/pdf/2211.09565v2.pdf","comment":"Our code and a list of categorized attacks are publicly available at\n  https://github.com/ZhengyuZhao/TransferAttackEval"},{"id":"http://arxiv.org/abs/2301.00122v2","updated":"2023-03-09T09:17:51Z","published":"2022-12-31T04:45:45Z","title":"Hair and Scalp Disease Detection using Machine Learning and Image\n  Processing","summary":"  Almost 80 million Americans suffer from hair loss due to aging, stress,\nmedication, or genetic makeup. Hair and scalp-related diseases often go\nunnoticed in the beginning. Sometimes, a patient cannot differentiate between\nhair loss and regular hair fall. Diagnosing hair-related diseases is\ntime-consuming as it requires professional dermatologists to perform visual and\nmedical tests. Because of that, the overall diagnosis gets delayed, which\nworsens the severity of the illness. Due to the image-processing ability,\nneural network-based applications are used in various sectors, especially\nhealthcare and health informatics, to predict deadly diseases like cancers and\ntumors. These applications assist clinicians and patients and provide an\ninitial insight into early-stage symptoms. In this study, we used a deep\nlearning approach that successfully predicts three main types of hair loss and\nscalp-related diseases: alopecia, psoriasis, and folliculitis. However, limited\nstudy in this area, unavailability of a proper dataset, and degree of variety\namong the images scattered over the internet made the task challenging. 150\nimages were obtained from various sources and then preprocessed by denoising,\nimage equalization, enhancement, and data balancing, thereby minimizing the\nerror rate. After feeding the processed data into the 2D convolutional neural\nnetwork (CNN) model, we obtained overall training accuracy of 96.2%, with a\nvalidation accuracy of 91.1%. The precision and recall score of alopecia,\npsoriasis, and folliculitis are 0.895, 0.846, and 1.0, respectively. We also\ncreated a dataset of the scalp images for future prospective researchers.\n","authors":["Mrinmoy Roy","Anica Tasnim Protity"],"pdf_url":"https://arxiv.org/pdf/2301.00122v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.03855v3","updated":"2023-03-09T09:01:46Z","published":"2022-09-08T14:50:23Z","title":"SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp\n  and motion optimization through diffusion","summary":"  Multi-objective optimization problems are ubiquitous in robotics, e.g., the\noptimization of a robot manipulation task requires a joint consideration of\ngrasp pose configurations, collisions and joint limits. While some demands can\nbe easily hand-designed, e.g., the smoothness of a trajectory, several\ntask-specific objectives need to be learned from data. This work introduces a\nmethod for learning data-driven SE(3) cost functions as diffusion models.\nDiffusion models can represent highly-expressive multimodal distributions and\nexhibit proper gradients over the entire space due to their score-matching\ntraining objective. Learning costs as diffusion models allows their seamless\nintegration with other costs into a single differentiable objective function,\nenabling joint gradient-based motion optimization. In this work, we focus on\nlearning SE(3) diffusion models for 6DoF grasping, giving rise to a novel\nframework for joint grasp and motion optimization without needing to decouple\ngrasp selection from trajectory generation. We evaluate the representation\npower of our SE(3) diffusion models w.r.t. classical generative models, and we\nshowcase the superior performance of our proposed optimization framework in a\nseries of simulated and real-world robotic manipulation tasks against\nrepresentative baselines.\n","authors":["Julen Urain","Niklas Funk","Jan Peters","Georgia Chalvatzaki"],"pdf_url":"https://arxiv.org/pdf/2209.03855v3.pdf","comment":"diffusion models, SE(3), grasping,"},{"id":"http://arxiv.org/abs/2303.05119v1","updated":"2023-03-09T08:59:33Z","published":"2023-03-09T08:59:33Z","title":"Entropic Wasserstein Component Analysis","summary":"  Dimension reduction (DR) methods provide systematic approaches for analyzing\nhigh-dimensional data. A key requirement for DR is to incorporate global\ndependencies among original and embedded samples while preserving clusters in\nthe embedding space. To achieve this, we combine the principles of optimal\ntransport (OT) and principal component analysis (PCA). Our method seeks the\nbest linear subspace that minimizes reconstruction error using entropic OT,\nwhich naturally encodes the neighborhood information of the samples. From an\nalgorithmic standpoint, we propose an efficient block-majorization-minimization\nsolver over the Stiefel manifold. Our experimental results demonstrate that our\napproach can effectively preserve high-dimensional clusters, leading to more\ninterpretable and effective embeddings. Python code of the algorithms and\nexperiments is available online.\n","authors":["Antoine Collas","Titouan Vayer","Rémi Flamary","Arnaud Breloy"],"pdf_url":"https://arxiv.org/pdf/2303.05119v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05118v1","updated":"2023-03-09T08:57:01Z","published":"2023-03-09T08:57:01Z","title":"SLCA: Slow Learner with Classifier Alignment for Continual Learning on a\n  Pre-trained Model","summary":"  The goal of continual learning is to improve the performance of recognition\nmodels in learning sequentially arrived data. Although most existing works are\nestablished on the premise of learning from scratch, growing efforts have been\ndevoted to incorporating the benefits of pre-training. However, how to\nadaptively exploit the pre-trained knowledge for each incremental task while\nmaintaining its generalizability remains an open question. In this work, we\npresent an extensive analysis for continual learning on a pre-trained model\n(CLPM), and attribute the key challenge to a progressive overfitting problem.\nObserving that selectively reducing the learning rate can almost resolve this\nissue in the representation layer, we propose a simple but extremely effective\napproach named Slow Learner with Classifier Alignment (SLCA), which further\nimproves the classification layer by modeling the class-wise distributions and\naligning the classification layers in a post-hoc fashion. Across a variety of\nscenarios, our proposal provides substantial improvements for CLPM (e.g., up to\n49.76%, 50.05%, 44.69% and 40.16% on Split CIFAR-100, Split ImageNet-R, Split\nCUB-200 and Split Cars-196, respectively), and thus outperforms\nstate-of-the-art approaches by a large margin. Based on such a strong baseline,\ncritical factors and promising directions are analyzed in-depth to facilitate\nsubsequent research.\n","authors":["Gengwei Zhang","Liyuan Wang","Guoliang Kang","Ling Chen","Yunchao Wei"],"pdf_url":"https://arxiv.org/pdf/2303.05118v1.pdf","comment":"Tech report. 11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2210.13631v2","updated":"2023-03-09T08:38:55Z","published":"2022-10-24T22:17:55Z","title":"On the Robustness of Dataset Inference","summary":"  Machine learning (ML) models are costly to train as they can require a\nsignificant amount of data, computational resources and technical expertise.\nThus, they constitute valuable intellectual property that needs protection from\nadversaries wanting to steal them. Ownership verification techniques allow the\nvictims of model stealing attacks to demonstrate that a suspect model was in\nfact stolen from theirs. Although a number of ownership verification techniques\nbased on watermarking or fingerprinting have been proposed, most of them fall\nshort either in terms of security guarantees (well-equipped adversaries can\nevade verification) or computational cost. A fingerprinting technique\nintroduced at ICLR '21, Dataset Inference (DI), has been shown to offer better\nrobustness and efficiency than prior methods. The authors of DI provided a\ncorrectness proof for linear (suspect) models. However, in the same setting, we\nprove that DI suffers from high false positives (FPs) -- it can incorrectly\nidentify an independent model trained with non-overlapping data from the same\ndistribution as stolen. We further prove that DI also triggers FPs in\nrealistic, non-linear suspect models. We then confirm empirically that DI leads\nto FPs, with high confidence. Second, we show that DI also suffers from false\nnegatives (FNs) -- an adversary can fool DI by regularising a stolen model's\ndecision boundaries using adversarial training, thereby leading to an FN. To\nthis end, we demonstrate that DI fails to identify a model adversarially\ntrained from a stolen dataset -- the setting where DI is the hardest to evade.\nFinally, we discuss the implications of our findings, the viability of\nfingerprinting-based ownership verification in general, and suggest directions\nfor future work.\n","authors":["Sebastian Szyller","Rui Zhang","Jian Liu","N. Asokan"],"pdf_url":"https://arxiv.org/pdf/2210.13631v2.pdf","comment":"17 pages, 5 tables, 4 figures"},{"id":"http://arxiv.org/abs/2303.05113v1","updated":"2023-03-09T08:34:21Z","published":"2023-03-09T08:34:21Z","title":"Segmentation method for cerebral blood vessels from MRA using hysteresis","summary":"  Segmentation of cerebral blood vessels from Magnetic Resonance Imaging (MRI)\nis an open problem that could be solved with deep learning (DL). However,\nannotated data for training is often scarce. Due to the absence of open-source\ntools, we aim to develop a classical segmentation method that generates vessel\nground truth from Magnetic Resonance Angiography for DL training of\nsegmentation across a variety of modalities. The method combines size-specific\nHessian filters, hysteresis thresholding and connected component correction.\nThe optimal choice of processing steps was evaluated with a blinded scoring by\na clinician using 24 3D images. The results show that all method steps are\nnecessary to produce the highest (14.2/15) vessel segmentation quality score.\nOmitting the connected component correction caused the largest quality loss.\nThe method, which is available on GitHub, can be used to train DL models for\nvessel segmentation.\n","authors":["Georgia Kenyon","Stephan Lau","Michael A. Chappell","Mark Jenkinson"],"pdf_url":"https://arxiv.org/pdf/2303.05113v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05102v1","updated":"2023-03-09T08:21:50Z","published":"2023-03-09T08:21:50Z","title":"StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent\n  Disentangled Space","summary":"  One major challenge in machine learning applications is coping with\nmismatches between the datasets used in the development and those obtained in\nreal-world applications. These mismatches may lead to inaccurate predictions\nand errors, resulting in poor product quality and unreliable systems. In this\nstudy, we propose StyleDiff to inform developers of the differences between the\ntwo datasets for the steady development of machine learning systems. Using\ndisentangled image spaces obtained from recently proposed generative models,\nStyleDiff compares the two datasets by focusing on attributes in the images and\nprovides an easy-to-understand analysis of the differences between the\ndatasets. The proposed StyleDiff performs in $O (d N\\log N)$, where $N$ is the\nsize of the datasets and $d$ is the number of attributes, enabling the\napplication to large datasets. We demonstrate that StyleDiff accurately detects\ndifferences between datasets and presents them in an understandable format\nusing, for example, driving scenes datasets.\n","authors":["Keisuke Kawano","Takuro Kutsuna","Ryoko Tokuhisa","Akihiro Nakamura","Yasushi Esaki"],"pdf_url":"https://arxiv.org/pdf/2303.05102v1.pdf","comment":"23 pages, 16 figures, under review"},{"id":"http://arxiv.org/abs/2303.05101v1","updated":"2023-03-09T08:20:28Z","published":"2023-03-09T08:20:28Z","title":"Scalable Stochastic Gradient Riemannian Langevin Dynamics in\n  Non-Diagonal Metrics","summary":"  Bayesian neural network inference is often carried out using stochastic\ngradient sampling methods. For best performance the methods should use a\nRiemannian metric that improves posterior exploration by accounting for the\nlocal curvature, but the existing methods resort to simple diagonal metrics to\nremain computationally efficient. This loses some of the gains. We propose two\nnon-diagonal metrics that can be used in stochastic samplers to improve\nconvergence and exploration but that have only a minor computational overhead\nover diagonal metrics. We show that for neural networks with complex\nposteriors, caused e.g. by use of sparsity-inducing priors, using these metrics\nprovides clear improvements. For some other choices the posterior is\nsufficiently easy also for the simpler metrics.\n","authors":["Hanlin Yu","Marcelo Hartmann","Bernardo Williams","Arto Klami"],"pdf_url":"https://arxiv.org/pdf/2303.05101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05098v1","updated":"2023-03-09T08:17:26Z","published":"2023-03-09T08:17:26Z","title":"Optimizing Sparse Linear Algebra Through Automatic Format Selection and\n  Machine Learning","summary":"  Sparse matrices are an integral part of scientific simulations. As hardware\nevolves new sparse matrix storage formats are proposed aiming to exploit\noptimizations specific to the new hardware. In the era of heterogeneous\ncomputing, users often are required to use multiple formats for their\napplications to remain optimal across the different available hardware,\nresulting in larger development times and maintenance overhead. A potential\nsolution to this problem is the use of a lightweight auto-tuner driven by\nMachine Learning (ML) that would select for the user an optimal format from a\npool of available formats that will match the characteristics of the sparsity\npattern, target hardware and operation to execute.\n  In this paper, we introduce Morpheus-Oracle, a library that provides a\nlightweight ML auto-tuner capable of accurately predicting the optimal format\nacross multiple backends, targeting the major HPC architectures aiming to\neliminate any format selection input by the end-user. From more than 2000\nreal-life matrices, we achieve an average classification accuracy and balanced\naccuracy of 92.63% and 80.22% respectively across the available systems. The\nadoption of the auto-tuner results in average speedup of 1.1x on CPUs and 1.5x\nto 8x on NVIDIA and AMD GPUs, with maximum speedups reaching up to 7x and 1000x\nrespectively.\n","authors":["Christodoulos Stylianou","Michele Weiland"],"pdf_url":"https://arxiv.org/pdf/2303.05098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05092v1","updated":"2023-03-09T08:04:16Z","published":"2023-03-09T08:04:16Z","title":"Reward Informed Dreamer for Task Generalization in Reinforcement\n  Learning","summary":"  A long-standing goal of reinforcement learning is that algorithms can learn\non training tasks and generalize well on unseen tasks like humans, where\ndifferent tasks share similar dynamic with different reward functions. A\ngeneral challenge is that it is nontrivial to quantitatively measure the\nsimilarities between these different tasks, which is vital for analyzing the\ntask distribution and further designing algorithms with stronger\ngeneralization. To address this, we present a novel metric named Task\nDistribution Relevance (TDR) via optimal Q functions to capture the relevance\nof the task distribution quantitatively. In the case of tasks with a high TDR,\ni.e., the tasks differ significantly, we demonstrate that the Markovian\npolicies cannot distinguish them, yielding poor performance accordingly. Based\non this observation, we propose a framework of Reward Informed Dreamer (RID)\nwith reward-informed world models, which captures invariant latent features\nover tasks and encodes reward signals into policies for distinguishing\ndifferent tasks. In RID, we calculate the corresponding variational lower bound\nof the log-likelihood on the data, which includes a novel term to distinguish\ndifferent tasks via states, based on reward-informed world models. Finally,\nextensive experiments in DeepMind control suite demonstrate that RID can\nsignificantly improve the performance of handling different tasks at the same\ntime, especially for those with high TDR, and further generalize to unseen\ntasks effectively.\n","authors":["Chengyang Ying","Zhongkai Hao","Xinning Zhou","Hang Su","Songming Liu","Jialian Li","Dong Yan","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.05092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13605v2","updated":"2023-03-09T07:41:44Z","published":"2022-09-27T18:00:55Z","title":"Efficient Recovery Learning using Model Predictive Meta-Reasoning","summary":"  Operating under real world conditions is challenging due to the possibility\nof a wide range of failures induced by execution errors and state uncertainty.\nIn relatively benign settings, such failures can be overcome by retrying or\nexecuting one of a small number of hand-engineered recovery strategies. By\ncontrast, contact-rich sequential manipulation tasks, like opening doors and\nassembling furniture, are not amenable to exhaustive hand-engineering. To\naddress this issue, we present a general approach for robustifying manipulation\nstrategies in a sample-efficient manner. Our approach incrementally improves\nrobustness by first discovering the failure modes of the current strategy via\nexploration in simulation and then learning additional recovery skills to\nhandle these failures. To ensure efficient learning, we propose an online\nalgorithm called Meta-Reasoning for Skill Learning (MetaReSkill) that monitors\nthe progress of all recovery policies during training and allocates training\nresources to recoveries that are likely to improve the task performance the\nmost. We use our approach to learn recovery skills for door-opening and\nevaluate them both in simulation and on a real robot with little fine-tuning.\nCompared to open-loop execution, our experiments show that even a limited\namount of recovery learning improves task success substantially from 71% to\n92.4% in simulation and from 75% to 90% on a real robot.\n","authors":["Shivam Vats","Maxim Likhachev","Oliver Kroemer"],"pdf_url":"https://arxiv.org/pdf/2209.13605v2.pdf","comment":"To appear in the International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2301.09474v2","updated":"2023-03-09T07:21:50Z","published":"2023-01-23T15:18:54Z","title":"DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained\n  Diffusion","summary":"  Real-world data generation often involves complex inter-dependencies among\ninstances, violating the IID-data hypothesis of standard learning paradigms and\nposing a challenge for uncovering the geometric structures for learning desired\ninstance representations. To this end, we introduce an energy constrained\ndiffusion model which encodes a batch of instances from a dataset into\nevolutionary states that progressively incorporate other instances' information\nby their interactions. The diffusion process is constrained by descent criteria\nw.r.t.~a principled energy function that characterizes the global consistency\nof instance representations over latent structures. We provide rigorous theory\nthat implies closed-form optimal estimates for the pairwise diffusion strength\namong arbitrary instance pairs, which gives rise to a new class of neural\nencoders, dubbed as DIFFormer (diffusion-based Transformers), with two\ninstantiations: a simple version with linear complexity for prohibitive\ninstance numbers, and an advanced version for learning complex structures.\nExperiments highlight the wide applicability of our model as a general-purpose\nencoder backbone with superior performance in various tasks, such as node\nclassification on large graphs, semi-supervised image/text classification, and\nspatial-temporal dynamics prediction.\n","authors":["Qitian Wu","Chenxiao Yang","Wentao Zhao","Yixuan He","David Wipf","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2301.09474v2.pdf","comment":"Published at ICLR 2023 as a spotlight presentation, the\n  implementation code is available at https://github.com/qitianwu/DIFFormer"},{"id":"http://arxiv.org/abs/2303.04016v2","updated":"2023-03-09T07:14:20Z","published":"2023-03-07T16:31:13Z","title":"Decoupling Skill Learning from Robotic Control for Generalizable Object\n  Manipulation","summary":"  Recent works in robotic manipulation through reinforcement learning (RL) or\nimitation learning (IL) have shown potential for tackling a range of tasks\ne.g., opening a drawer or a cupboard. However, these techniques generalize\npoorly to unseen objects. We conjecture that this is due to the\nhigh-dimensional action space for joint control. In this paper, we take an\nalternative approach and separate the task of learning 'what to do' from 'how\nto do it' i.e., whole-body control. We pose the RL problem as one of\ndetermining the skill dynamics for a disembodied virtual manipulator\ninteracting with articulated objects. The whole-body robotic kinematic control\nis optimized to execute the high-dimensional joint motion to reach the goals in\nthe workspace. It does so by solving a quadratic programming (QP) model with\nrobotic singularity and kinematic constraints. Our experiments on manipulating\ncomplex articulated objects show that the proposed approach is more\ngeneralizable to unseen objects with large intra-class variations,\noutperforming previous approaches. The evaluation results indicate that our\napproach generates more compliant robotic motion and outperforms the pure RL\nand IL baselines in task success rates. Additional information and videos are\navailable at https://kl-research.github.io/decoupskill\n","authors":["Kai Lu","Bo Yang","Bing Wang","Andrew Markham"],"pdf_url":"https://arxiv.org/pdf/2303.04016v2.pdf","comment":"Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2303.05072v1","updated":"2023-03-09T07:08:25Z","published":"2023-03-09T07:08:25Z","title":"Identification of Systematic Errors of Image Classifiers on Rare\n  Subgroups","summary":"  Despite excellent average-case performance of many image classifiers, their\nperformance can substantially deteriorate on semantically coherent subgroups of\nthe data that were under-represented in the training data. These systematic\nerrors can impact both fairness for demographic minority groups as well as\nrobustness and safety under domain shift. A major challenge is to identify such\nsubgroups with subpar performance when the subgroups are not annotated and\ntheir occurrence is very rare. We leverage recent advances in text-to-image\nmodels and search in the space of textual descriptions of subgroups (\"prompts\")\nfor subgroups where the target model has low performance on the\nprompt-conditioned synthesized data. To tackle the exponentially growing number\nof subgroups, we employ combinatorial testing. We denote this procedure as\nPromptAttack as it can be interpreted as an adversarial attack in a prompt\nspace. We study subgroup coverage and identifiability with PromptAttack in a\ncontrolled setting and find that it identifies systematic errors with high\naccuracy. Thereupon, we apply PromptAttack to ImageNet classifiers and identify\nnovel systematic errors on rare subgroups.\n","authors":["Jan Hendrik Metzen","Robin Hutmacher","N. Grace Hua","Valentyn Boreiko","Dan Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05069v1","updated":"2023-03-09T07:01:06Z","published":"2023-03-09T07:01:06Z","title":"Conceptual Reinforcement Learning for Language-Conditioned Tasks","summary":"  Despite the broad application of deep reinforcement learning (RL),\ntransferring and adapting the policy to unseen but similar environments is\nstill a significant challenge. Recently, the language-conditioned policy is\nproposed to facilitate policy transfer through learning the joint\nrepresentation of observation and text that catches the compact and invariant\ninformation across environments. Existing studies of language-conditioned RL\nmethods often learn the joint representation as a simple latent layer for the\ngiven instances (episode-specific observation and text), which inevitably\nincludes noisy or irrelevant information and cause spurious correlations that\nare dependent on instances, thus hurting generalization performance and\ntraining efficiency. To address this issue, we propose a conceptual\nreinforcement learning (CRL) framework to learn the concept-like joint\nrepresentation for language-conditioned policy. The key insight is that\nconcepts are compact and invariant representations in human cognition through\nextracting similarities from numerous instances in real-world. In CRL, we\npropose a multi-level attention encoder and two mutual information constraints\nfor learning compact and invariant concepts. Verified in two challenging\nenvironments, RTFM and Messenger, CRL significantly improves the training\nefficiency (up to 70%) and generalization ability (up to 30%) to the new\nenvironment dynamics.\n","authors":["Shaohui Peng","Xing Hu","Rui Zhang","Jiaming Guo","Qi Yi","Ruizhi Chen","Zidong Du","Ling Li","Qi Guo","Yunji Chen"],"pdf_url":"https://arxiv.org/pdf/2303.05069v1.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2302.02914v2","updated":"2023-03-09T06:24:02Z","published":"2023-02-06T16:38:43Z","title":"Energy-based Out-of-Distribution Detection for Graph Neural Networks","summary":"  Learning on graphs, where instance nodes are inter-connected, has become one\nof the central problems for deep learning, as relational structures are\npervasive and induce data inter-dependence which hinders trivial adaptation of\nexisting approaches that assume inputs to be i.i.d.~sampled. However, current\nmodels mostly focus on improving testing performance of in-distribution data\nand largely ignore the potential risk w.r.t. out-of-distribution (OOD) testing\nsamples that may cause negative outcome if the prediction is overconfident on\nthem. In this paper, we investigate the under-explored problem, OOD detection\non graph-structured data, and identify a provably effective OOD discriminator\nbased on an energy function directly extracted from graph neural networks\ntrained with standard classification loss. This paves a way for a simple,\npowerful and efficient OOD detection model for GNN-based learning on graphs,\nwhich we call GNNSafe. It also has nice theoretical properties that guarantee\nan overall distinguishable margin between the detection scores for\nin-distribution and OOD samples, which, more critically, can be further\nstrengthened by a learning-free energy belief propagation scheme. For\ncomprehensive evaluation, we introduce new benchmark settings that evaluate the\nmodel for detecting OOD data from both synthetic and real distribution shifts\n(cross-domain graph shifts and temporal graph shifts). The results show that\nGNNSafe achieves up to $17.0\\%$ AUROC improvement over state-of-the-arts and it\ncould serve as simple yet strong baselines in such an under-developed area.\n","authors":["Qitian Wu","Yiting Chen","Chenxiao Yang","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2302.02914v2.pdf","comment":"Published at ICLR 2023, the implementation code is available at\n  https://github.com/qitianwu/GraphOOD-GNNSafe"},{"id":"http://arxiv.org/abs/2302.14829v2","updated":"2023-03-09T06:17:13Z","published":"2023-02-22T07:56:45Z","title":"Dish-TS: A General Paradigm for Alleviating Distribution Shift in Time\n  Series Forecasting","summary":"  The distribution shift in Time Series Forecasting (TSF), indicating series\ndistribution changes over time, largely hinders the performance of TSF models.\nExisting works towards distribution shift in time series are mostly limited in\nthe quantification of distribution and, more importantly, overlook the\npotential shift between lookback and horizon windows. To address above\nchallenges, we systematically summarize the distribution shift in TSF into two\ncategories. Regarding lookback windows as input-space and horizon windows as\noutput-space, there exist (i) intra-space shift, that the distribution within\nthe input-space keeps shifted over time, and (ii) inter-space shift, that the\ndistribution is shifted between input-space and output-space. Then we\nintroduce, Dish-TS, a general neural paradigm for alleviating distribution\nshift in TSF. Specifically, for better distribution estimation, we propose the\ncoefficient net (CONET), which can be any neural architectures, to map input\nsequences into learnable distribution coefficients. To relieve intra-space and\ninter-space shift, we organize Dish-TS as a Dual-CONET framework to separately\nlearn the distribution of input- and output-space, which naturally captures the\ndistribution difference of two spaces. In addition, we introduce a more\neffective training strategy for intractable CONET learning. Finally, we conduct\nextensive experiments on several datasets coupled with different\nstate-of-the-art forecasting models. Experimental results show Dish-TS\nconsistently boosts them with a more than 20% average improvement. Code is\navailable.\n","authors":["Wei Fan","Pengyang Wang","Dongkun Wang","Dongjie Wang","Yuanchun Zhou","Yanjie Fu"],"pdf_url":"https://arxiv.org/pdf/2302.14829v2.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2302.10899v2","updated":"2023-03-09T05:54:14Z","published":"2023-02-10T01:00:49Z","title":"Feature Affinity Assisted Knowledge Distillation and Quantization of\n  Deep Neural Networks on Label-Free Data","summary":"  In this paper, we propose a feature affinity (FA) assisted knowledge\ndistillation (KD) method to improve quantization-aware training of deep neural\nnetworks (DNN). The FA loss on intermediate feature maps of DNNs plays the role\nof teaching middle steps of a solution to a student instead of only giving\nfinal answers in the conventional KD where the loss acts on the network logits\nat the output level. Combining logit loss and FA loss, we found that the\nquantized student network receives stronger supervision than from the labeled\nground-truth data. The resulting FAQD is capable of compressing model on\nlabel-free data, which brings immediate practical benefits as pre-trained\nteacher models are readily available and unlabeled data are abundant. In\ncontrast, data labeling is often laborious and expensive. Finally, we propose a\nfast feature affinity (FFA) loss that accurately approximates FA loss with a\nlower order of computational complexity, which helps speed up training for high\nresolution image input.\n","authors":["Zhijian Li","Biao Yang","Penghang Yin","Yingyong Qi","Jack Xin"],"pdf_url":"https://arxiv.org/pdf/2302.10899v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05048v1","updated":"2023-03-09T05:53:28Z","published":"2023-03-09T05:53:28Z","title":"Semi-Federated Learning for Collaborative Intelligence in Massive IoT\n  Networks","summary":"  Implementing existing federated learning in massive Internet of Things (IoT)\nnetworks faces critical challenges such as imbalanced and statistically\nheterogeneous data and device diversity. To this end, we propose a\nsemi-federated learning (SemiFL) framework to provide a potential solution for\nthe realization of intelligent IoT. By seamlessly integrating the centralized\nand federated paradigms, our SemiFL framework shows high scalability in terms\nof the number of IoT devices even in the presence of computing-limited sensors.\nFurthermore, compared to traditional learning approaches, the proposed SemiFL\ncan make better use of distributed data and computing resources, due to the\ncollaborative model training between the edge server and local devices.\nSimulation results show the effectiveness of our SemiFL framework for massive\nIoT networks. The code can be found at https://github.com/niwanli/SemiFL_IoT.\n","authors":["Wanli Ni","Jingheng Zheng","Hui Tian"],"pdf_url":"https://arxiv.org/pdf/2303.05048v1.pdf","comment":"The paper has been accepted for publication in the IEEE Internet of\n  Things Journal"},{"id":"http://arxiv.org/abs/2108.05681v2","updated":"2023-03-09T05:49:56Z","published":"2021-08-12T12:04:27Z","title":"Semantics-Native Communication with Contextual Reasoning","summary":"  Spurred by a huge interest in the post-Shannon communication, it has recently\nbeen shown that leveraging semantics can significantly improve the\ncommunication effectiveness across many tasks. In this article, inspired by\nhuman communication, we propose a novel stochastic model of System 1\nsemantics-native communication (SNC) for generic tasks, where a speaker has an\nintention of referring to an entity, extracts the semantics, and communicates\nits symbolic representation to a target listener. To further reach its full\npotential, we additionally infuse contextual reasoning into SNC such that the\nspeaker locally and iteratively self-communicates with a virtual agent built on\nthe physical listener's unique way of coding its semantics, i.e., communication\ncontext. The resultant System 2 SNC allows the speaker to extract the most\neffective semantics for its listener. Leveraging the proposed stochastic model,\nwe show that the reliability of System 2 SNC increases with the number of\nmeaningful concepts, and derive the expected semantic representation (SR) bit\nlength which quantifies the extracted effective semantics. It is also shown\nthat System 2 SNC significantly reduces the SR length without compromising\ncommunication reliability.\n","authors":["Hyowoon Seo","Jihong Park","Mehdi Bennis","Mérouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2108.05681v2.pdf","comment":"18 pages, 16 figures, in IEEE Transactions on Cognitive\n  Communications and Networking"},{"id":"http://arxiv.org/abs/2303.05043v1","updated":"2023-03-09T05:42:10Z","published":"2023-03-09T05:42:10Z","title":"Invertible Kernel PCA with Random Fourier Features","summary":"  Kernel principal component analysis (kPCA) is a widely studied method to\nconstruct a low-dimensional data representation after a nonlinear\ntransformation. The prevailing method to reconstruct the original input signal\nfrom kPCA -- an important task for denoising -- requires us to solve a\nsupervised learning problem. In this paper, we present an alternative method\nwhere the reconstruction follows naturally from the compression step. We first\napproximate the kernel with random Fourier features. Then, we exploit the fact\nthat the nonlinear transformation is invertible in a certain subdomain. Hence,\nthe name \\emph{invertible kernel PCA (ikPCA)}. We experiment with different\ndata modalities and show that ikPCA performs similarly to kPCA with supervised\nreconstruction on denoising tasks, making it a strong alternative.\n","authors":["Daniel Gedon","Antôni H. Ribeiro","Niklas Wahlström","Thomas B. Schön"],"pdf_url":"https://arxiv.org/pdf/2303.05043v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2202.11202v3","updated":"2023-03-09T05:16:49Z","published":"2022-02-22T22:31:57Z","title":"Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning","summary":"  Indiscriminate data poisoning attacks are quite effective against supervised\nlearning. However, not much is known about their impact on unsupervised\ncontrastive learning (CL). This paper is the first to consider indiscriminate\npoisoning attacks of contrastive learning. We propose Contrastive Poisoning\n(CP), the first effective such attack on CL. We empirically show that\nContrastive Poisoning, not only drastically reduces the performance of CL\nalgorithms, but also attacks supervised learning models, making it the most\ngeneralizable indiscriminate poisoning attack. We also show that CL algorithms\nwith a momentum encoder are more robust to indiscriminate poisoning, and\npropose a new countermeasure based on matrix completion. Code is available at:\nhttps://github.com/kaiwenzha/contrastive-poisoning.\n","authors":["Hao He","Kaiwen Zha","Dina Katabi"],"pdf_url":"https://arxiv.org/pdf/2202.11202v3.pdf","comment":"ICLR 2023 Spotlight (notable top 25%). The first two authors\n  contributed equally to this paper"},{"id":"http://arxiv.org/abs/2303.05038v1","updated":"2023-03-09T05:11:30Z","published":"2023-03-09T05:11:30Z","title":"Exploiting Contextual Structure to Generate Useful Auxiliary Tasks","summary":"  Reinforcement learning requires interaction with an environment, which is\nexpensive for robots. This constraint necessitates approaches that work with\nlimited environmental interaction by maximizing the reuse of previous\nexperiences. We propose an approach that maximizes experience reuse while\nlearning to solve a given task by generating and simultaneously learning useful\nauxiliary tasks. To generate these tasks, we construct an abstract temporal\nlogic representation of the given task and leverage large language models to\ngenerate context-aware object embeddings that facilitate object replacements.\nCounterfactual reasoning and off-policy methods allow us to simultaneously\nlearn these auxiliary tasks while solving the given target task. We combine\nthese insights into a novel framework for multitask reinforcement learning and\nexperimentally show that our generated auxiliary tasks share similar underlying\nexploration requirements as the given task, thereby maximizing the utility of\ndirected exploration. Our approach allows agents to automatically learn\nadditional useful policies without extra environment interaction.\n","authors":["Benedict Quartey","Ankit Shah","George Konidaris"],"pdf_url":"https://arxiv.org/pdf/2303.05038v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.03596v4","updated":"2023-03-09T05:07:58Z","published":"2021-09-08T12:47:24Z","title":"Learn2Agree: Fitting with Multiple Annotators without Objective Ground\n  Truth","summary":"  The annotation of domain experts is important for some medical applications\nwhere the objective ground truth is ambiguous to define, e.g., the\nrehabilitation for some chronic diseases, and the prescreening of some\nmusculoskeletal abnormalities without further medical examinations. However,\nimproper uses of the annotations may hinder developing reliable models. On one\nhand, forcing the use of a single ground truth generated from multiple\nannotations is less informative for the modeling. On the other hand, feeding\nthe model with all the annotations without proper regularization is noisy given\nexisting disagreements. For such issues, we propose a novel Learning to\nAgreement (Learn2Agree) framework to tackle the challenge of learning from\nmultiple annotators without objective ground truth. The framework has two\nstreams, with one stream fitting with the multiple annotators and the other\nstream learning agreement information between annotators. In particular, the\nagreement learning stream produces regularization information to the classifier\nstream, tuning its decision to be better in line with the agreement between\nannotators. The proposed method can be easily added to existing backbones, with\nexperiments on two medical datasets showed better agreement levels with\nannotators.\n","authors":["Chongyang Wang","Yuan Gao","Chenyou Fan","Junjie Hu","Tin Lun Lam","Nicholas D. Lane","Nadia Bianchi-Berthouze"],"pdf_url":"https://arxiv.org/pdf/2109.03596v4.pdf","comment":"Accepted by the TML4H workshop at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.05037v1","updated":"2023-03-09T05:05:54Z","published":"2023-03-09T05:05:54Z","title":"Gauges and Accelerated Optimization over Smooth and/or Strongly Convex\n  Sets","summary":"  We consider feasibility and constrained optimization problems defined over\nsmooth and/or strongly convex sets. These notions mirror their popular function\ncounterparts but are much less explored in the first-order optimization\nliterature. We propose new scalable, projection-free, accelerated first-order\nmethods in these settings. Our methods avoid linear optimization or projection\noracles, only using cheap one-dimensional linesearches and normal vector\ncomputations. Despite this, we derive optimal accelerated convergence\nguarantees of $O(1/T)$ for strongly convex problems, $O(1/T^2)$ for smooth\nproblems, and accelerated linear convergence given both. Our algorithms and\nanalysis are based on novel characterizations of the Minkowski gauge of smooth\nand/or strongly convex sets, which may be of independent interest: although the\ngauge is neither smooth nor strongly convex, we show the gauge squared inherits\nany structure present in the set.\n","authors":["Ning Liu","Benjamin Grimmer"],"pdf_url":"https://arxiv.org/pdf/2303.05037v1.pdf","comment":"22pages (32pages with references and appendix)"},{"id":"http://arxiv.org/abs/2303.01215v2","updated":"2023-03-09T04:56:10Z","published":"2023-03-02T12:56:52Z","title":"Why (and When) does Local SGD Generalize Better than SGD?","summary":"  Local SGD is a communication-efficient variant of SGD for large-scale\ntraining, where multiple GPUs perform SGD independently and average the model\nparameters periodically. It has been recently observed that Local SGD can not\nonly achieve the design goal of reducing the communication overhead but also\nlead to higher test accuracy than the corresponding SGD baseline (Lin et al.,\n2020b), though the training regimes for this to happen are still in debate\n(Ortiz et al., 2021). This paper aims to understand why (and when) Local SGD\ngeneralizes better based on Stochastic Differential Equation (SDE)\napproximation. The main contributions of this paper include (i) the derivation\nof an SDE that captures the long-term behavior of Local SGD in the small\nlearning rate regime, showing how noise drives the iterate to drift and diffuse\nafter it has reached close to the manifold of local minima, (ii) a comparison\nbetween the SDEs of Local SGD and SGD, showing that Local SGD induces a\nstronger drift term that can result in a stronger effect of regularization,\ne.g., a faster reduction of sharpness, and (iii) empirical evidence validating\nthat having a small learning rate and long enough training time enables the\ngeneralization improvement over SGD but removing either of the two conditions\nleads to no improvement.\n","authors":["Xinran Gu","Kaifeng Lyu","Longbo Huang","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2303.01215v2.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2301.00767v2","updated":"2023-03-09T04:40:23Z","published":"2022-12-27T08:09:45Z","title":"A Survey on Federated Recommendation Systems","summary":"  Federated learning has recently been applied to recommendation systems to\nprotect user privacy. In federated learning settings, recommendation systems\ncan train recommendation models only collecting the intermediate parameters\ninstead of the real user data, which greatly enhances the user privacy. Beside,\nfederated recommendation systems enable to collaborate with other data\nplatforms to improve recommended model performance while meeting the regulation\nand privacy constraints. However, federated recommendation systems faces many\nnew challenges such as privacy, security, heterogeneity and communication\ncosts. While significant research has been conducted in these areas, gaps in\nthe surveying literature still exist. In this survey, we-(1) summarize some\ncommon privacy mechanisms used in federated recommendation systems and discuss\nthe advantages and limitations of each mechanism; (2) review some robust\naggregation strategies and several novel attacks against security; (3)\nsummarize some approaches to address heterogeneity and communication costs\nproblems; (4)introduce some open source platforms that can be used to build\nfederated recommendation systems; (5) present some prospective research\ndirections in the future. This survey can guide researchers and practitioners\nunderstand the research progress in these areas.\n","authors":["Zehua Sun","Yonghui Xu","Yong Liu","Wei He","Lanju Kong","Fangzhao Wu","Yali Jiang","Lizhen Cui"],"pdf_url":"https://arxiv.org/pdf/2301.00767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05033v1","updated":"2023-03-09T04:36:38Z","published":"2023-03-09T04:36:38Z","title":"Out-of-distribution Detection with Implicit Outlier Transformation","summary":"  Outlier exposure (OE) is powerful in out-of-distribution (OOD) detection,\nenhancing detection capability via model fine-tuning with surrogate OOD data.\nHowever, surrogate data typically deviate from test OOD data. Thus, the\nperformance of OE, when facing unseen OOD data, can be weakened. To address\nthis issue, we propose a novel OE-based approach that makes the model perform\nwell for unseen OOD situations, even for unseen OOD cases. It leads to a\nmin-max learning scheme -- searching to synthesize OOD data that leads to worst\njudgments and learning from such OOD data for uniform performance in OOD\ndetection. In our realization, these worst OOD data are synthesized by\ntransforming original surrogate ones. Specifically, the associated transform\nfunctions are learned implicitly based on our novel insight that model\nperturbation leads to data transformation. Our methodology offers an efficient\nway of synthesizing OOD data, which can further benefit the detection model,\nbesides the surrogate OOD data. We conduct extensive experiments under various\nOOD detection setups, demonstrating the effectiveness of our method against its\nadvanced counterparts.\n","authors":["Qizhou Wang","Junjie Ye","Feng Liu","Quanyu Dai","Marcus Kalander","Tongliang Liu","Jianye Hao","Bo Han"],"pdf_url":"https://arxiv.org/pdf/2303.05033v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05026v1","updated":"2023-03-09T04:20:16Z","published":"2023-03-09T04:20:16Z","title":"SSL^2: Self-Supervised Learning meets Semi-Supervised Learning: Multiple\n  Sclerosis Segmentation in 7T-MRI from large-scale 3T-MRI","summary":"  Automated segmentation of multiple sclerosis (MS) lesions from MRI scans is\nimportant to quantify disease progression. In recent years, convolutional\nneural networks (CNNs) have shown top performance for this task when a large\namount of labeled data is available. However, the accuracy of CNNs suffers when\ndealing with few and/or sparsely labeled datasets. A potential solution is to\nleverage the information available in large public datasets in conjunction with\na target dataset which only has limited labeled data. In this paper, we propose\na training framework, SSL2 (self-supervised-semi-supervised), for\nmulti-modality MS lesion segmentation with limited supervision. We adopt\nself-supervised learning to leverage the knowledge from large public 3T\ndatasets to tackle the limitations of a small 7T target dataset. To leverage\nthe information from unlabeled 7T data, we also evaluate state-of-the-art\nsemi-supervised methods for other limited annotation settings, such as small\nlabeled training size and sparse annotations. We use the shifted-window (Swin)\ntransformer1 as our backbone network. The effectiveness of self-supervised and\nsemi-supervised training strategies is evaluated in our in-house 7T MRI\ndataset. The results indicate that each strategy improves lesion segmentation\nfor both limited training data size and for sparse labeling scenarios. The\ncombined overall framework further improves the performance substantially\ncompared to either of its components alone. Our proposed framework thus\nprovides a promising solution for future data/label-hungry 7T MS studies.\n","authors":["Jiacheng Wang","Hao Li","Han Liu","Dewei Hu","Daiwei Lu","Keejin Yoon","Kelsey Barter","Francesca Bagnato","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2303.05026v1.pdf","comment":"Accepted at the International Society for Optics and Photonics -\n  Medical Imaging (SPIE-MI) 2023"},{"id":"http://arxiv.org/abs/2303.05024v1","updated":"2023-03-09T04:09:50Z","published":"2023-03-09T04:09:50Z","title":"Phase transition for detecting a small community in a large network","summary":"  How to detect a small community in a large network is an interesting problem,\nincluding clique detection as a special case, where a naive degree-based\n$\\chi^2$-test was shown to be powerful in the presence of an Erd\\H{o}s-Renyi\nbackground. Using Sinkhorn's theorem, we show that the signal captured by the\n$\\chi^2$-test may be a modeling artifact, and it may disappear once we replace\nthe Erd\\H{o}s-Renyi model by a broader network model. We show that the recent\nSgnQ test is more appropriate for such a setting. The test is optimal in\ndetecting communities with sizes comparable to the whole network, but has never\nbeen studied for our setting, which is substantially different and more\nchallenging. Using a degree-corrected block model (DCBM), we establish phase\ntransitions of this testing problem concerning the size of the small community\nand the edge densities in small and large communities. When the size of the\nsmall community is larger than $\\sqrt{n}$, the SgnQ test is optimal for it\nattains the computational lower bound (CLB), the information lower bound for\nmethods allowing polynomial computation time. When the size of the small\ncommunity is smaller than $\\sqrt{n}$, we establish the parameter regime where\nthe SgnQ test has full power and make some conjectures of the CLB. We also\nstudy the classical information lower bound (LB) and show that there is always\na gap between the CLB and LB in our range of interest.\n","authors":["Jiashun Jin","Zheng Tracy Ke","Paxton Turner","Anru R. Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05018v1","updated":"2023-03-09T03:40:34Z","published":"2023-03-09T03:40:34Z","title":"Improved Regret Bounds for Online Kernel Selection under Bandit Feedback","summary":"  In this paper, we improve the regret bound for online kernel selection under\nbandit feedback. Previous algorithm enjoys a $O((\\Vert\nf\\Vert^2_{\\mathcal{H}_i}+1)K^{\\frac{1}{3}}T^{\\frac{2}{3}})$ expected bound for\nLipschitz loss functions. We prove two types of regret bounds improving the\nprevious bound. For smooth loss functions, we propose an algorithm with a\n$O(U^{\\frac{2}{3}}K^{-\\frac{1}{3}}(\\sum^K_{i=1}L_T(f^\\ast_i))^{\\frac{2}{3}})$\nexpected bound where $L_T(f^\\ast_i)$ is the cumulative losses of optimal\nhypothesis in $\\mathbb{H}_{i}=\\{f\\in\\mathcal{H}_i:\\Vert\nf\\Vert_{\\mathcal{H}_i}\\leq U\\}$. The data-dependent bound keeps the previous\nworst-case bound and is smaller if most of candidate kernels match well with\nthe data. For Lipschitz loss functions, we propose an algorithm with a\n$O(U\\sqrt{KT}\\ln^{\\frac{2}{3}}{T})$ expected bound asymptotically improving the\nprevious bound. We apply the two algorithms to online kernel selection with\ntime constraint and prove new regret bounds matching or improving the previous\n$O(\\sqrt{T\\ln{K}} +\\Vert\nf\\Vert^2_{\\mathcal{H}_i}\\max\\{\\sqrt{T},\\frac{T}{\\sqrt{\\mathcal{R}}}\\})$\nexpected bound where $\\mathcal{R}$ is the time budget. Finally, we empirically\nverify our algorithms on online regression and classification tasks.\n","authors":["Junfan Li","Shizhong Liao"],"pdf_url":"https://arxiv.org/pdf/2303.05018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05881v2","updated":"2023-03-09T03:18:25Z","published":"2023-02-12T09:50:32Z","title":"Low-Rank Tensor Completion With Generalized CP Decomposition and\n  Nonnegative Integer Tensor Completion","summary":"  Tensor completion is important to many areas such as computer vision, data\nanalysis, and signal processing. Previously, a category of methods known as\nlow-rank tensor completion has been proposed and developed, involving the\nenforcement of low-rank structures on completed tensors. While such methods\nhave been constantly improved, none considered exploiting the numerical\nproperties of tensor elements. This work attempts to construct a new\nmethodological framework called GCDTC (Generalized CP Decomposition Tensor\nCompletion) based on numerical properties to achieve higher accuracy in tensor\ncompletion. In this newly introduced framework, a generalized form of the CP\nDecomposition is applied to low-rank tensor completion. This paper also\nproposes an algorithm known as SPTC (Smooth Poisson Tensor Completion) for\nnonnegative integer tensor completion as an application of the GCDTC framework.\nThrough experimentation with real-life data, it is verified that this method\ncould produce results superior in completion accuracy to current\nstate-of-the-art methodologies.\n","authors":["Shiran Yuan"],"pdf_url":"https://arxiv.org/pdf/2302.05881v2.pdf","comment":"10 pages, 4 figures, and 1 table"},{"id":"http://arxiv.org/abs/2303.05000v1","updated":"2023-03-09T02:48:59Z","published":"2023-03-09T02:48:59Z","title":"Learning Representation for Anomaly Detection of Vehicle Trajectories","summary":"  Predicting the future trajectories of surrounding vehicles based on their\nhistory trajectories is a critical task in autonomous driving. However, when\nsmall crafted perturbations are introduced to those history trajectories, the\nresulting anomalous (or adversarial) trajectories can significantly mislead the\nfuture trajectory prediction module of the ego vehicle, which may result in\nunsafe planning and even fatal accidents. Therefore, it is of great importance\nto detect such anomalous trajectories of the surrounding vehicles for system\nsafety, but few works have addressed this issue. In this work, we propose two\nnovel methods for learning effective and efficient representations for online\nanomaly detection of vehicle trajectories. Different from general time-series\nanomaly detection, anomalous vehicle trajectory detection deals with much\nricher contexts on the road and fewer observable patterns on the anomalous\ntrajectories themselves. To address these challenges, our methods exploit\ncontrastive learning techniques and trajectory semantics to capture the\npatterns underlying the driving scenarios for effective anomaly detection under\nsupervised and unsupervised settings, respectively. We conduct extensive\nexperiments to demonstrate that our supervised method based on contrastive\nlearning and unsupervised method based on reconstruction with semantic latent\nspace can significantly improve the performance of anomalous trajectory\ndetection in their corresponding settings over various baseline methods. We\nalso demonstrate our methods' generalization ability to detect unseen patterns\nof anomalies.\n","authors":["Ruochen Jiao","Juyang Bai","Xiangguo Liu","Takami Sato","Xiaowei Yuan","Qi Alfred Chen","Qi Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.05000v1.pdf","comment":"8 pages paper, in anomaly detection of vehicle trajectory"},{"id":"http://arxiv.org/abs/2204.06601v3","updated":"2023-03-09T02:45:48Z","published":"2022-04-13T18:41:41Z","title":"Causal Confusion and Reward Misidentification in Preference-Based Reward\n  Learning","summary":"  Learning policies via preference-based reward learning is an increasingly\npopular method for customizing agent behavior, but has been shown anecdotally\nto be prone to spurious correlations and reward hacking behaviors. While much\nprior work focuses on causal confusion in reinforcement learning and behavioral\ncloning, we focus on a systematic study of causal confusion and reward\nmisidentification when learning from preferences. In particular, we perform a\nseries of sensitivity and ablation analyses on several benchmark domains where\nrewards learned from preferences achieve minimal test error but fail to\ngeneralize to out-of-distribution states -- resulting in poor policy\nperformance when optimized. We find that the presence of non-causal distractor\nfeatures, noise in the stated preferences, and partial state observability can\nall exacerbate reward misidentification. We also identify a set of methods with\nwhich to interpret misidentified learned rewards. In general, we observe that\noptimizing misidentified rewards drives the policy off the reward's training\ndistribution, resulting in high predicted (learned) rewards but low true\nrewards. These findings illuminate the susceptibility of preference learning to\nreward misidentification and causal confusion -- failure to consider even one\nof many factors can result in unexpected, undesirable behavior.\n","authors":["Jeremy Tien","Jerry Zhi-Yang He","Zackory Erickson","Anca D. Dragan","Daniel S. Brown"],"pdf_url":"https://arxiv.org/pdf/2204.06601v3.pdf","comment":"In the proceedings of the Eleventh International Conference on\n  Learning Representations (ICLR 2023).\n  $\\href{https://iclr.cc/virtual/2023/poster/10822}{\\text{URL}}$"},{"id":"http://arxiv.org/abs/2302.01546v2","updated":"2023-03-09T02:44:15Z","published":"2023-02-03T04:51:54Z","title":"Group Fairness in Non-monotone Submodular Maximization","summary":"  Maximizing a submodular function has a wide range of applications in machine\nlearning and data mining. One such application is data summarization whose goal\nis to select a small set of representative and diverse data items from a large\ndataset. However, data items might have sensitive attributes such as race or\ngender, in this setting, it is important to design \\emph{fairness-aware}\nalgorithms to mitigate potential algorithmic bias that may cause over- or\nunder- representation of particular groups. Motivated by that, we propose and\nstudy the classic non-monotone submodular maximization problem subject to novel\ngroup fairness constraints. Our goal is to select a set of items that maximizes\na non-monotone submodular function, while ensuring that the number of selected\nitems from each group is proportionate to its size, to the extent specified by\nthe decision maker. We develop the first constant-factor approximation\nalgorithms for this problem. We also extend the basic model to incorporate an\nadditional global size constraint on the total number of selected items.\n","authors":["Jing Yuan","Shaojie Tang"],"pdf_url":"https://arxiv.org/pdf/2302.01546v2.pdf","comment":"This article has been accepted for publication in the Journal on\n  Combinatorial Optimization"},{"id":"http://arxiv.org/abs/2303.04729v2","updated":"2023-03-09T02:40:44Z","published":"2023-03-08T17:15:58Z","title":"On the Risks of Stealing the Decoding Algorithms of Language Models","summary":"  A key component of generating text from modern language models (LM) is the\nselection and tuning of decoding algorithms. These algorithms determine how to\ngenerate text from the internal probability distribution generated by the LM.\nThe process of choosing a decoding algorithm and tuning its hyperparameters\ntakes significant time, manual effort, and computation, and it also requires\nextensive human evaluation. Therefore, the identity and hyperparameters of such\ndecoding algorithms are considered to be extremely valuable to their owners. In\nthis work, we show, for the first time, that an adversary with typical API\naccess to an LM can steal the type and hyperparameters of its decoding\nalgorithms at very low monetary costs. Our attack is effective against popular\nLMs used in text generation APIs, including GPT-2 and GPT-3. We demonstrate the\nfeasibility of stealing such information with only a few dollars, e.g.,\n$\\$0.8$, $\\$1$, $\\$4$, and $\\$40$ for the four versions of GPT-3.\n","authors":["Ali Naseh","Kalpesh Krishna","Mohit Iyyer","Amir Houmansadr"],"pdf_url":"https://arxiv.org/pdf/2303.04729v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01673v2","updated":"2023-03-09T02:20:26Z","published":"2023-03-03T02:24:06Z","title":"Near Optimal Memory-Regret Tradeoff for Online Learning","summary":"  In the experts problem, on each of $T$ days, an agent needs to follow the\nadvice of one of $n$ ``experts''. After each day, the loss associated with each\nexpert's advice is revealed. A fundamental result in learning theory says that\nthe agent can achieve vanishing regret, i.e. their cumulative loss is within\n$o(T)$ of the cumulative loss of the best-in-hindsight expert.\n  Can the agent perform well without sufficient space to remember all the\nexperts? We extend a nascent line of research on this question in two\ndirections:\n  $\\bullet$ We give a new algorithm against the oblivious adversary, improving\nover the memory-regret tradeoff obtained by [PZ23], and nearly matching the\nlower bound of [SWXZ22].\n  $\\bullet$ We also consider an adaptive adversary who can observe past experts\nchosen by the agent. In this setting we give both a new algorithm and a novel\nlower bound, proving that roughly $\\sqrt{n}$ memory is both necessary and\nsufficient for obtaining $o(T)$ regret.\n","authors":["Binghui Peng","Aviad Rubinstein"],"pdf_url":"https://arxiv.org/pdf/2303.01673v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14749v2","updated":"2023-03-09T02:19:56Z","published":"2022-12-30T14:40:00Z","title":"Asynchronous Hybrid Reinforcement Learning for Latency and Reliability\n  Optimization in the Metaverse over Wireless Communications","summary":"  Technology advancements in wireless communications and high-performance\nExtended Reality (XR) have empowered the developments of the Metaverse. The\ndemand for the Metaverse applications and hence, real-time digital twinning of\nreal-world scenes is increasing. Nevertheless, the replication of 2D physical\nworld images into 3D virtual objects is computationally intensive and requires\ncomputation offloading. The disparity in transmitted object dimension (2D as\nopposed to 3D) leads to asymmetric data sizes in uplink (UL) and downlink (DL).\nTo ensure the reliability and low latency of the system, we consider an\nasynchronous joint UL-DL scenario where in the UL stage, the smaller data size\nof the physical world images captured by multiple extended reality users (XUs)\nwill be uploaded to the Metaverse Console (MC) to be construed and rendered. In\nthe DL stage, the larger-size 3D virtual objects need to be transmitted back to\nthe XUs. We design a novel multi-agent reinforcement learning algorithm\nstructure, namely Asynchronous Actors Hybrid Critic (AAHC), to optimize the\ndecisions pertaining to computation offloading and channel assignment in the UL\nstage and optimize the DL transmission power in the DL stage. Extensive\nexperiments demonstrate that compared to proposed baselines, AAHC obtains\nbetter solutions with satisfactory training time.\n","authors":["Wenhan Yu","Terence Jie Chua","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2212.14749v2.pdf","comment":"This paper appears in IEEE Journal on Selected Areas in\n  Communications (JSAC), 2023"},{"id":"http://arxiv.org/abs/2211.08229v3","updated":"2023-03-09T02:16:37Z","published":"2022-11-15T15:48:28Z","title":"CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive\n  Learning","summary":"  Contrastive learning (CL) pre-trains general-purpose encoders using an\nunlabeled pre-training dataset, which consists of images or image-text pairs.\nCL is vulnerable to data poisoning based backdoor attacks (DPBAs), in which an\nattacker injects poisoned inputs into the pre-training dataset so the encoder\nis backdoored. However, existing DPBAs achieve limited effectiveness. In this\nwork, we propose new DPBAs called CorruptEncoder to CL. CorruptEncoder uses a\ntheory-guided method to create optimal poisoned inputs to maximize attack\neffectiveness. Our experiments show that CorruptEncoder substantially\noutperforms existing DPBAs. In particular, CorruptEncoder is the first DPBA\nthat achieves more than 90% attack success rates with only a few (3) reference\nimages and a small poisoning ratio (0.5%). Moreover, we also propose a defense,\ncalled localized cropping, to defend against DPBAs. Our results show that our\ndefense can reduce the effectiveness of DPBAs, though it slightly sacrifices\nthe utility of the encoder.\n","authors":["Jinghuai Zhang","Hongbin Liu","Jinyuan Jia","Neil Zhenqiang Gong"],"pdf_url":"https://arxiv.org/pdf/2211.08229v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02704v3","updated":"2023-03-09T02:15:21Z","published":"2022-12-06T01:53:50Z","title":"Benchmarking AutoML algorithms on a collection of synthetic\n  classification problems","summary":"  Automated machine learning (AutoML) algorithms have grown in popularity due\nto their high performance and flexibility to adapt to different problems and\ndata sets. With the increasing number of AutoML algorithms, deciding which\nwould best suit a given problem becomes increasingly more work. Therefore, it\nis essential to use complex and challenging benchmarks which would be able to\ndifferentiate the AutoML algorithms from each other. This paper compares the\nperformance of four different AutoML algorithms: Tree-based Pipeline\nOptimization Tool (TPOT), Auto-Sklearn, Auto-Sklearn 2, and H2O AutoML. We use\nthe Diverse and Generative ML benchmark (DIGEN), a diverse set of synthetic\ndatasets derived from generative functions designed to highlight the strengths\nand weaknesses of the performance of common machine learning algorithms. We\nconfirm that AutoML can identify pipelines that perform well on all included\ndatasets. Most AutoML algorithms performed similarly; however, there were some\ndifferences depending on the specific dataset and metric used.\n","authors":["Pedro Henrique Ribeiro","Patryk Orzechowski","Joost Wagenaar","Jason H. Moore"],"pdf_url":"https://arxiv.org/pdf/2212.02704v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09117v2","updated":"2023-03-09T02:07:01Z","published":"2022-09-15T15:41:47Z","title":"Part-Based Models Improve Adversarial Robustness","summary":"  We show that combining human prior knowledge with end-to-end learning can\nimprove the robustness of deep neural networks by introducing a part-based\nmodel for object classification. We believe that the richer form of annotation\nhelps guide neural networks to learn more robust features without requiring\nmore samples or larger models. Our model combines a part segmentation model\nwith a tiny classifier and is trained end-to-end to simultaneously segment\nobjects into parts and then classify the segmented object. Empirically, our\npart-based models achieve both higher accuracy and higher adversarial\nrobustness than a ResNet-50 baseline on all three datasets. For instance, the\nclean accuracy of our part models is up to 15 percentage points higher than the\nbaseline's, given the same level of robustness. Our experiments indicate that\nthese models also reduce texture bias and yield better robustness against\ncommon corruptions and spurious correlations. The code is publicly available at\nhttps://github.com/chawins/adv-part-model.\n","authors":["Chawin Sitawarin","Kornrapat Pongmala","Yizheng Chen","Nicholas Carlini","David Wagner"],"pdf_url":"https://arxiv.org/pdf/2209.09117v2.pdf","comment":"Published in ICLR 2023 (poster). Code can be found at\n  https://github.com/chawins/adv-part-model"},{"id":"http://arxiv.org/abs/2210.00173v2","updated":"2023-03-09T01:49:54Z","published":"2022-10-01T02:57:37Z","title":"Predictive Inference with Feature Conformal Prediction","summary":"  Conformal prediction is a distribution-free technique for establishing valid\nprediction intervals. Although conventionally people conduct conformal\nprediction in the output space, this is not the only possibility. In this\npaper, we propose feature conformal prediction, which extends the scope of\nconformal prediction to semantic feature spaces by leveraging the inductive\nbias of deep representation learning. From a theoretical perspective, we\ndemonstrate that feature conformal prediction provably outperforms regular\nconformal prediction under mild assumptions. Our approach could be combined\nwith not only vanilla conformal prediction, but also other adaptive conformal\nprediction methods. Apart from experiments on existing predictive inference\nbenchmarks, we also demonstrate the state-of-the-art performance of the\nproposed methods on large-scale tasks such as ImageNet classification and\nCityscapes image segmentation.\n","authors":["Jiaye Teng","Chuan Wen","Dinghuai Zhang","Yoshua Bengio","Yang Gao","Yang Yuan"],"pdf_url":"https://arxiv.org/pdf/2210.00173v2.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2301.06625v2","updated":"2023-03-09T01:35:55Z","published":"2023-01-16T22:22:04Z","title":"TDSTF: Transformer-based Diffusion probabilistic model for Sparse Time\n  series Forecasting","summary":"  \\noindent \\textbf{Background and objective:} In the intensive care unit\n(ICU), vital sign monitoring is critical, and an accurate predictive system is\nrequired. This study will create a novel model to forecast Heart Rate (HR),\nSystolic Blood Pressure (SBP), and Diastolic Blood Pressure (DBP) in ICU. These\nvital signs are crucial for prompt interventions for patients. We extracted\n$24,886$ ICU stays from the MIMIC-III database, which contains data from over\n$46$ thousand patients, to train and test the model.\n  \\noindent \\textbf{Methods:} The model proposed in this study, areansformerin\nintensive careabilistic Model for Sparse Time Series Forecasting (TDSTF), uses\na deep learning technique called the Transformer. The TDSTF model showed\nstate-of-the-art performance in predicting vital signs in the ICU,\noutperforming other models' ability to predict distributions of vital signs and\nbeing more computationally efficient. The code is available at\nhttps://github.com/PingChang818/TDSTF.\n  \\noindent \\textbf{Results:} The results of the study showed that TDSTF\nachieved a Normalized Average Continuous Ranked Probability Score (NACRPS) of\n$0.4438$ and a Mean Squared Error (MSE) of $0.4168$, an improvement of $18.9\\%$\nand $34.3\\%$ over the best baseline model, respectively.\n  \\noindent \\textbf{Conclusion:} In conclusion, TDSTF is an effective and\nefficient solution for forecasting vital signs in the ICU, and it shows a\nsignificant improvement compared to other models in the field.\n  \\noindent \\textbf{Keywords: deep learning, time series forecasting, sparse\ndata, vital signs, ICU}\n","authors":["Ping Chang","Huayu Li","Stuart F. Quan","Janet Roveda","Ao Li"],"pdf_url":"https://arxiv.org/pdf/2301.06625v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.00974v3","updated":"2023-03-09T01:34:01Z","published":"2022-12-02T05:07:50Z","title":"Faster Adaptive Federated Learning","summary":"  Federated learning has attracted increasing attention with the emergence of\ndistributed data. While extensive federated learning algorithms have been\nproposed for the non-convex distributed problem, federated learning in practice\nstill faces numerous challenges, such as the large training iterations to\nconverge since the sizes of models and datasets keep increasing, and the lack\nof adaptivity by SGD-based model updates. Meanwhile, the study of adaptive\nmethods in federated learning is scarce and existing works either lack a\ncomplete theoretical convergence guarantee or have slow sample complexity. In\nthis paper, we propose an efficient adaptive algorithm (i.e., FAFED) based on\nthe momentum-based variance-reduced technique in cross-silo FL. We first\nexplore how to design the adaptive algorithm in the FL setting. By providing a\ncounter-example, we prove that a simple combination of FL and adaptive methods\ncould lead to divergence. More importantly, we provide a convergence analysis\nfor our method and prove that our algorithm is the first adaptive FL algorithm\nto reach the best-known samples $O(\\epsilon^{-3})$ and $O(\\epsilon^{-2})$\ncommunication rounds to find an $\\epsilon$-stationary point without large\nbatches. The experimental results on the language modeling task and image\nclassification task with heterogeneous data demonstrate the efficiency of our\nalgorithms.\n","authors":["Xidong Wu","Feihu Huang","Zhengmian Hu","Heng Huang"],"pdf_url":"https://arxiv.org/pdf/2212.00974v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04976v1","updated":"2023-03-09T01:29:58Z","published":"2023-03-09T01:29:58Z","title":"Curvature-Sensitive Predictive Coding with Approximate Laplace Monte\n  Carlo","summary":"  Predictive coding (PC) accounts of perception now form one of the dominant\ncomputational theories of the brain, where they prescribe a general algorithm\nfor inference and learning over hierarchical latent probabilistic models.\nDespite this, they have enjoyed little export to the broader field of machine\nlearning, where comparative generative modelling techniques have flourished. In\npart, this has been due to the poor performance of models trained with PC when\nevaluated by both sample quality and marginal likelihood. By adopting the\nperspective of PC as a variational Bayes algorithm under the Laplace\napproximation, we identify the source of these deficits to lie in the exclusion\nof an associated Hessian term in the PC objective function, which would\notherwise regularise the sharpness of the probability landscape and prevent\nover-certainty in the approximate posterior. To remedy this, we make three\nprimary contributions: we begin by suggesting a simple Monte Carlo estimated\nevidence lower bound which relies on sampling from the Hessian-parameterised\nvariational posterior. We then derive a novel block diagonal approximation to\nthe full Hessian matrix that has lower memory requirements and favourable\nmathematical properties. Lastly, we present an algorithm that combines our\nmethod with standard PC to reduce memory complexity further. We evaluate models\ntrained with our approach against the standard PC framework on image benchmark\ndatasets. Our approach produces higher log-likelihoods and qualitatively better\nsamples that more closely capture the diversity of the data-generating\ndistribution.\n","authors":["Umais Zahid","Qinghai Guo","Karl Friston","Zafeirios Fountas"],"pdf_url":"https://arxiv.org/pdf/2303.04976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04117v2","updated":"2023-03-09T01:07:09Z","published":"2023-03-07T18:28:45Z","title":"Validation of a Hospital Digital Twin with Machine Learning","summary":"  Recently there has been a surge of interest in developing Digital Twins of\nprocess flows in healthcare to better understand bottlenecks and areas of\nimprovement. A key challenge is in the validation process. We describe a work\nin progress for a digital twin using an agent based simulation model for\ndetermining bed turnaround time for patients in hospitals. We employ a strategy\nusing machine learning for validating the model and implementing sensitivity\nanalysis.\n","authors":["Muhammad Aurangzeb Ahmad","Vijay Chickarmane","Farinaz Sabz Ali Pour","Nima Shariari","Taposh Dutta Roy"],"pdf_url":"https://arxiv.org/pdf/2303.04117v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.02920v3","updated":"2023-03-09T00:53:54Z","published":"2020-12-05T01:27:10Z","title":"Dataset of Random Relaxations for Crystal Structure Search of Li-Si\n  System","summary":"  Crystal structure search is a long-standing challenge in materials design. We\npresent a dataset of more than 100,000 structural relaxations of potential\nbattery anode materials from randomized structures using density functional\ntheory calculations. We illustrate the usage of the dataset by training graph\nneural networks to predict structural relaxations from randomly generated\nstructures. Our models directly predict stresses in addition to forces, which\nallows them to accurately simulate relaxations of both ionic positions and\nlattice vectors. We show that models trained on the molecular dynamics\nsimulations fail to simulate relaxations from random structures, while training\non our data leads to up to two orders of magnitude decrease in error for the\nsame task. Our model is able to find an experimentally verified structure of a\nstoichiometry held out from training. We find that randomly perturbing atomic\npositions during training improves both the accuracy and out of domain\ngeneralization of the models.\n","authors":["Gowoon Cheon","Lusann Yang","Kevin McCloskey","Evan J. Reed","Ekin D. Cubuk"],"pdf_url":"https://arxiv.org/pdf/2012.02920v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16997v4","updated":"2023-03-09T00:30:56Z","published":"2022-10-31T00:53:17Z","title":"Convergence Rates of Stochastic Zeroth-order Gradient Descent for Ł\n  ojasiewicz Functions","summary":"  We prove convergence rates of Stochastic Zeroth-order Gradient Descent (SZGD)\nalgorithms for Lojasiewicz functions. The SZGD algorithm iterates as\n\\begin{align*}\n  \\mathbf{x}_{t+1} = \\mathbf{x}_t - \\eta_t \\widehat{\\nabla} f (\\mathbf{x}_t),\n\\qquad t = 0,1,2,3,\\cdots , \\end{align*} where $f$ is the objective function\nthat satisfies the \\L ojasiewicz inequality with \\L ojasiewicz exponent\n$\\theta$, $\\eta_t$ is the step size (learning rate), and $ \\widehat{\\nabla} f\n(\\mathbf{x}_t) $ is the approximate gradient estimated using zeroth-order\ninformation only.\n  Our results show that $ \\{ f (\\mathbf{x}_t) - f (\\mathbf{x}_\\infty) \\}_{t \\in\n\\mathbb{N} } $ can converge faster than $ \\{ \\| \\mathbf{x}_t -\n\\mathbf{x}_\\infty \\| \\}_{t \\in \\mathbb{N} }$, regardless of whether the\nobjective $f$ is smooth or nonsmooth.\n","authors":["Tianyu Wang","Yasong Feng"],"pdf_url":"https://arxiv.org/pdf/2210.16997v4.pdf","comment":"V3: more than major revision. Y. Feng is added to the author list.\n  V4: length cut and some typo corrections"},{"id":"http://arxiv.org/abs/2202.03609v4","updated":"2023-03-09T00:21:41Z","published":"2022-02-08T02:49:09Z","title":"Backdoor Detection and Mitigation in Competitive Reinforcement Learning","summary":"  While real-world applications of reinforcement learning are becoming popular,\nthe security and robustness of RL systems are worthy of more attention and\nexploration. In particular, recent works have revealed that, in a multi-agent\nRL environment, backdoor trigger actions can be injected into a victim agent\n(a.k.a. Trojan agent), which can result in a catastrophic failure as soon as it\nsees the backdoor trigger action. To ensure the security of RL agents against\nmalicious backdoors, in this work, we propose the problem of Backdoor Detection\nin a multi-agent competitive reinforcement learning system, with the objective\nof detecting Trojan agents as well as the corresponding potential trigger\nactions, and further trying to mitigate their Trojan behavior. In order to\nsolve this problem, we propose PolicyCleanse that is based on the property that\nthe activated Trojan agents accumulated rewards degrade noticeably after\nseveral timesteps. Along with PolicyCleanse, we also design a machine\nunlearning-based approach that can effectively mitigate the detected backdoor.\nExtensive experiments demonstrate that the proposed methods can accurately\ndetect Trojan agents, and outperform existing backdoor mitigation baseline\napproaches by at least 3% in winning rate across various types of agents and\nenvironments.\n","authors":["Junfeng Guo","Ang Li","Cong Liu"],"pdf_url":"https://arxiv.org/pdf/2202.03609v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04956v1","updated":"2023-03-09T00:14:46Z","published":"2023-03-09T00:14:46Z","title":"Blackwell's Approachability with Time-Dependent Outcome Functions and\n  Dot Products. Application to the Big Match","summary":"  Blackwell's approachability is a very general sequential decision framework\nwhere a Decision Maker obtains vector-valued outcomes, and aims at the\nconvergence of the average outcome to a given \"target\" set. Blackwell gave a\nsufficient condition for the decision maker having a strategy guaranteeing such\na convergence against an adversarial environment, as well as what we now call\nthe Blackwell's algorithm, which then ensures convergence. Blackwell's\napproachability has since been applied to numerous problems, in online learning\nand game theory, in particular. We extend this framework by allowing the\noutcome function and the dot product to be time-dependent. We establish a\ngeneral guarantee for the natural extension to this framework of Blackwell's\nalgorithm. In the case where the target set is an orthant, we present a family\nof time-dependent dot products which yields different convergence speeds for\neach coordinate of the average outcome. We apply this framework to the Big\nMatch (one of the most important toy examples of stochastic games) where an\n$\\epsilon$-uniformly optimal strategy for Player I is given by Blackwell's\nalgorithm in a well-chosen auxiliary approachability problem.\n","authors":["Joon Kwon","Bruno Ziliotto"],"pdf_url":"https://arxiv.org/pdf/2303.04956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.08057v3","updated":"2023-03-09T23:35:08Z","published":"2022-10-14T18:48:48Z","title":"Pishgu: Universal Path Prediction Network Architecture for Real-time\n  Cyber-physical Edge Systems","summary":"  Path prediction is an essential task for many real-world Cyber-Physical\nSystems (CPS) applications, from autonomous driving and traffic\nmonitoring/management to pedestrian/worker safety. These real-world CPS\napplications need a robust, lightweight path prediction that can provide a\nuniversal network architecture for multiple subjects (e.g., pedestrians and\nvehicles) from different perspectives. However, most existing algorithms are\ntailor-made for a unique subject with a specific camera perspective and\nscenario. This article presents Pishgu, a universal lightweight network\narchitecture, as a robust and holistic solution for path prediction. Pishgu's\narchitecture can adapt to multiple path prediction domains with different\nsubjects (vehicles, pedestrians), perspectives (bird's-eye, high-angle), and\nscenes (sidewalk, highway). Our proposed architecture captures the\ninter-dependencies within the subjects in each frame by taking advantage of\nGraph Isomorphism Networks and the attention module. We separately train and\nevaluate the efficacy of our architecture on three different CPS domains across\nmultiple perspectives (vehicle bird's-eye view, pedestrian bird's-eye view, and\nhuman high-angle view). Pishgu outperforms state-of-the-art solutions in the\nvehicle bird's-eye view domain by 42% and 61% and pedestrian high-angle view\ndomain by 23% and 22% in terms of ADE and FDE, respectively. Additionally, we\nanalyze the domain-specific details for various datasets to understand their\neffect on path prediction and model interpretation. Finally, we report the\nlatency and throughput for all three domains on multiple embedded platforms\nshowcasing the robustness and adaptability of Pishgu for real-world integration\ninto CPS applications.\n","authors":["Ghazal Alinezhad Noghre","Vinit Katariya","Armin Danesh Pazho","Christopher Neff","Hamed Tabkhi"],"pdf_url":"https://arxiv.org/pdf/2210.08057v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.06178v3","updated":"2023-03-09T23:18:57Z","published":"2022-06-13T14:07:56Z","title":"Efficient recurrent architectures through activity sparsity and sparse\n  back-propagation through time","summary":"  Recurrent neural networks (RNNs) are well suited for solving sequence tasks\nin resource-constrained systems due to their expressivity and low computational\nrequirements. However, there is still a need to bridge the gap between what\nRNNs are capable of in terms of efficiency and performance and real-world\napplication requirements. The memory and computational requirements arising\nfrom propagating the activations of all the neurons at every time step to every\nconnected neuron, together with the sequential dependence of activations,\ncontribute to the inefficiency of training and using RNNs. We propose a\nsolution inspired by biological neuron dynamics that makes the communication\nbetween RNN units sparse and discrete. This makes the backward pass with\nbackpropagation through time (BPTT) computationally sparse and efficient as\nwell. We base our model on the gated recurrent unit (GRU), extending it with\nunits that emit discrete events for communication triggered by a threshold so\nthat no information is communicated to other units in the absence of events. We\nshow theoretically that the communication between units, and hence the\ncomputation required for both the forward and backward passes, scales with the\nnumber of events in the network. Our model achieves efficiency without\ncompromising task performance, demonstrating competitive performance compared\nto state-of-the-art recurrent network models in real-world tasks, including\nlanguage modeling. The dynamic activity sparsity mechanism also makes our model\nwell suited for novel energy-efficient neuromorphic hardware. Code is available\nat https://github.com/KhaleelKhan/EvNN/.\n","authors":["Anand Subramoney","Khaleelulla Khan Nazeer","Mark Schöne","Christian Mayr","David Kappel"],"pdf_url":"https://arxiv.org/pdf/2206.06178v3.pdf","comment":"Published as notable-top-25% paper in ICLR 2023"},{"id":"http://arxiv.org/abs/2212.01346v6","updated":"2023-03-09T23:17:08Z","published":"2022-12-02T18:03:37Z","title":"Guaranteed Conformance of Neurosymbolic Models to Natural Constraints","summary":"  Deep neural networks have emerged as the workhorse for a large section of\nrobotics and control applications, especially as models for dynamical systems.\nSuch data-driven models are in turn used for designing and verifying autonomous\nsystems. This is particularly useful in modeling medical systems where data can\nbe leveraged to individualize treatment. In safety-critical applications, it is\nimportant that the data-driven model is conformant to established knowledge\nfrom the natural sciences. Such knowledge is often available or can often be\ndistilled into a (possibly black-box) model $M$. For instance, the unicycle\nmodel (which encodes Newton's laws) for an F1 racing car. In this light, we\nconsider the following problem - given a model $M$ and state transition\ndataset, we wish to best approximate the system model while being bounded\ndistance away from $M$. We propose a method to guarantee this conformance. Our\nfirst step is to distill the dataset into few representative samples called\nmemories, using the idea of a growing neural gas. Next, using these memories we\npartition the state space into disjoint subsets and compute bounds that should\nbe respected by the neural network, when the input is drawn from a particular\nsubset. This serves as a symbolic wrapper for guaranteed conformance. We argue\ntheoretically that this only leads to bounded increase in approximation error;\nwhich can be controlled by increasing the number of memories. We experimentally\nshow that on three case studies (Car Model, Drones, and Artificial Pancreas),\nour constrained neurosymbolic models conform to specified $M$ models (each\nencoding various constraints) with order-of-magnitude improvements compared to\nthe augmented Lagrangian and vanilla training methods. Our code can be found at\nhttps://github.com/kaustubhsridhar/Constrained_Models\n","authors":["Kaustubh Sridhar","Souradeep Dutta","James Weimer","Insup Lee"],"pdf_url":"https://arxiv.org/pdf/2212.01346v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05617v1","updated":"2023-03-09T23:11:52Z","published":"2023-03-09T23:11:52Z","title":"KGNv2: Separating Scale and Pose Prediction for Keypoint-based 6-DoF\n  Grasp Pose Synthesis on RGB-D input","summary":"  We propose a new 6-DoF grasp pose synthesis approach from 2D/2.5D input based\non keypoints. Keypoint-based grasp detector from image input has demonstrated\npromising results in the previous study, where the additional visual\ninformation provided by color images compensates for the noisy depth\nperception. However, it relies heavily on accurately predicting the location of\nkeypoints in the image space. In this paper, we devise a new grasp generation\nnetwork that reduces the dependency on precise keypoint estimation. Given an\nRGB-D input, our network estimates both the grasp pose from keypoint detection\nas well as scale towards the camera. We further re-design the keypoint output\nspace in order to mitigate the negative impact of keypoint prediction noise to\nPerspective-n-Point (PnP) algorithm. Experiments show that the proposed method\noutperforms the baseline by a large margin, validating the efficacy of our\napproach. Finally, despite trained on simple synthetic objects, our method\ndemonstrate sim-to-real capacity by showing competitive results in real-world\nrobot experiments.\n","authors":["Yiye Chen","Ruinian Xu","Yunzhi Lin","Patricio A. Vela"],"pdf_url":"https://arxiv.org/pdf/2303.05617v1.pdf","comment":"Submitted to IROS2023"},{"id":"http://arxiv.org/abs/2303.05607v1","updated":"2023-03-09T22:16:47Z","published":"2023-03-09T22:16:47Z","title":"An Improved Data Augmentation Scheme for Model Predictive Control Policy\n  Approximation","summary":"  This paper considers the problem of data generation for MPC policy\napproximation. Learning an approximate MPC policy from expert demonstrations\nrequires a large data set consisting of optimal state-action pairs, sampled\nacross the feasible state space. Yet, the key challenge of efficiently\ngenerating the training samples has not been studied widely. Recently, a\nsensitivity-based data augmentation framework for MPC policy approximation was\nproposed, where the parametric sensitivities are exploited to cheaply generate\nseveral additional samples from a single offline MPC computation. The error due\nto augmenting the training data set with inexact samples was shown to increase\nwith the size of the neighborhood around each sample used for data\naugmentation. Building upon this work, this letter paper presents an improved\ndata augmentation scheme based on predictor-corrector steps that enforces a\nuser-defined level of accuracy, and shows that the error bound of the augmented\nsamples are independent of the size of the neighborhood used for data\naugmentation.\n","authors":["Dinesh Krishnamoorthy"],"pdf_url":"https://arxiv.org/pdf/2303.05607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05606v1","updated":"2023-03-09T22:16:28Z","published":"2023-03-09T22:16:28Z","title":"Variance-aware robust reinforcement learning with linear function\n  approximation with heavy-tailed rewards","summary":"  This paper presents two algorithms, AdaOFUL and VARA, for online sequential\ndecision-making in the presence of heavy-tailed rewards with only finite\nvariances. For linear stochastic bandits, we address the issue of heavy-tailed\nrewards by modifying the adaptive Huber regression and proposing AdaOFUL.\nAdaOFUL achieves a state-of-the-art regret bound of\n$\\widetilde{\\mathcal{O}}\\big(d\\big(\\sum_{t=1}^T \\nu_{t}^2\\big)^{1/2}+d\\big)$ as\nif the rewards were uniformly bounded, where $\\nu_{t}^2$ is the observed\nconditional variance of the reward at round $t$, $d$ is the feature dimension,\nand $\\widetilde{\\mathcal{O}}(\\cdot)$ hides logarithmic dependence. Building\nupon AdaOFUL, we propose VARA for linear MDPs, which achieves a tighter\nvariance-aware regret bound of\n$\\widetilde{\\mathcal{O}}(d\\sqrt{H\\mathcal{G}^*K})$. Here, $H$ is the length of\nepisodes, $K$ is the number of episodes, and $\\mathcal{G}^*$ is a smaller\ninstance-dependent quantity that can be bounded by other instance-dependent\nquantities when additional structural conditions on the MDP are satisfied. Our\nregret bound is superior to the current state-of-the-art bounds in three ways:\n(1) it depends on a tighter instance-dependent quantity and has optimal\ndependence on $d$ and $H$, (2) we can obtain further instance-dependent bounds\nof $\\mathcal{G}^*$ under additional structural conditions on the MDP, and (3)\nour regret bound is valid even when rewards have only finite variances,\nachieving a level of generality unmatched by previous works. Overall, our\nmodified adaptive Huber regression algorithm may serve as a useful building\nblock in the design of algorithms for online problems with heavy-tailed\nrewards.\n","authors":["Xiang Li","Qiang Sun"],"pdf_url":"https://arxiv.org/pdf/2303.05606v1.pdf","comment":"23 page main text, 42 page appendix"},{"id":"http://arxiv.org/abs/2205.02956v2","updated":"2023-03-09T21:41:38Z","published":"2022-05-05T22:56:19Z","title":"Low Dimensional Invariant Embeddings for Universal Geometric Learning","summary":"  This paper studies separating invariants: mappings on $D$ dimensional domains\nwhich are invariant to an appropriate group action, and which separate orbits.\nThe motivation for this study comes from the usefulness of separating\ninvariants in proving universality of equivariant neural network architectures.\n  We observe that in several cases the cardinality of separating invariants\nproposed in the machine learning literature is much larger than the dimension\n$D$. As a result, the theoretical universal constructions based on these\nseparating invariants is unrealistically large. Our goal in this paper is to\nresolve this issue.\n  We show that when a continuous family of semi-algebraic separating invariants\nis available, separation can be obtained by randomly selecting 2D+1 of these\ninvariants. We apply this methodology to obtain an efficient scheme for\ncomputing separating invariants for several classical group actions which have\nbeen studied in the invariant learning literature. Examples include matrix\nmultiplication actions on point clouds by permutations, rotations, and various\nother linear groups.\n  Often the requirement of invariant separation is relaxed and only generic\nseparation is required. In this case, we show that only D+1 invariants are\nrequired. More importantly, generic invariants are often significantly easier\nto compute, as we illustrate by discussing generic and full separation for\nweighted graphs. Finally we outline an approach for proving that separating\ninvariants can be constructed also when the random parameters have finite\nprecision.\n","authors":["Nadav Dym","Steven J. Gortler"],"pdf_url":"https://arxiv.org/pdf/2205.02956v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05593v1","updated":"2023-03-09T21:37:50Z","published":"2023-03-09T21:37:50Z","title":"Learning the Wrong Lessons: Inserting Trojans During Knowledge\n  Distillation","summary":"  In recent years, knowledge distillation has become a cornerstone of\nefficiently deployed machine learning, with labs and industries using knowledge\ndistillation to train models that are inexpensive and resource-optimized.\nTrojan attacks have contemporaneously gained significant prominence, revealing\nfundamental vulnerabilities in deep learning models. Given the widespread use\nof knowledge distillation, in this work we seek to exploit the unlabelled data\nknowledge distillation process to embed Trojans in a student model without\nintroducing conspicuous behavior in the teacher. We ultimately devise a Trojan\nattack that effectively reduces student accuracy, does not alter teacher\nperformance, and is efficiently constructible in practice.\n","authors":["Leonard Tang","Tom Shlomi","Alexander Cai"],"pdf_url":"https://arxiv.org/pdf/2303.05593v1.pdf","comment":"ICLR 2023 Workshop on Backdoor Attacks and Defenses in Machine\n  Learning"},{"id":"http://arxiv.org/abs/2303.05582v1","updated":"2023-03-09T21:13:32Z","published":"2023-03-09T21:13:32Z","title":"Generalization analysis of an unfolding network for analysis-based\n  Compressed Sensing","summary":"  Unfolding networks have shown promising results in the Compressed Sensing\n(CS) field. Yet, the investigation of their generalization ability is still in\nits infancy. In this paper, we perform generalization analysis of a\nstate-of-the-art ADMM-based unfolding network, which jointly learns a decoder\nfor CS and a sparsifying redundant analysis operator. To this end, we first\nimpose a structural constraint on the learnable sparsifier, which parametrizes\nthe network's hypothesis class. For the latter, we estimate its Rademacher\ncomplexity. With this estimate in hand, we deliver generalization error bounds\nfor the examined network. Finally, the validity of our theory is assessed and\nnumerical comparisons to a state-of-the-art unfolding network are made, on\nsynthetic and real-world datasets. Our experimental results demonstrate that\nour proposed framework complies with our theoretical findings and outperforms\nthe baseline, consistently for all datasets.\n","authors":["Vicky Kouni","Yannis Panagakis"],"pdf_url":"https://arxiv.org/pdf/2303.05582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.03668v5","updated":"2023-03-09T20:19:23Z","published":"2022-03-04T14:16:50Z","title":"A Typology for Exploring the Mitigation of Shortcut Behavior","summary":"  As machine learning models become increasingly larger, trained weakly\nsupervised on large, possibly uncurated data sets, it becomes increasingly\nimportant to establish mechanisms for inspecting, interacting, and revising\nmodels to mitigate learning shortcuts and guarantee their learned knowledge is\naligned with human knowledge. The recently proposed XIL framework was developed\nfor this purpose, and several such methods have been introduced, each with\nindividual motivations and methodological details. In this work, we provide a\nunification of various XIL methods into a single typology by establishing a\ncommon set of basic modules. In doing so, we pave the way for a principled\ncomparison of existing, but, importantly, also future XIL approaches. In\naddition, we discuss existing and introduce novel measures and benchmarks for\nevaluating the overall abilities of a XIL method. Given this extensive toolbox,\nincluding our typology, measures, and benchmarks, we finally compare several\nrecent XIL methods methodologically and quantitatively. In our evaluations, all\nmethods prove to revise a model successfully. However, we found remarkable\ndifferences in individual benchmark tasks, revealing valuable\napplication-relevant aspects for integrating these benchmarks in developing\nfuture methods.\n","authors":["Felix Friedrich","Wolfgang Stammer","Patrick Schramowski","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2203.03668v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.12373v2","updated":"2023-03-09T20:10:17Z","published":"2022-02-24T22:00:25Z","title":"Learning POD of Complex Dynamics Using Heavy-ball Neural ODEs","summary":"  Proper orthogonal decomposition (POD) allows reduced-order modeling of\ncomplex dynamical systems at a substantial level, while maintaining a high\ndegree of accuracy in modeling the underlying dynamical systems. Advances in\nmachine learning algorithms enable learning POD-based dynamics from data and\nmaking accurate and fast predictions of dynamical systems. In this paper, we\nleverage the recently proposed heavy-ball neural ODEs (HBNODEs) [Xia et al.\nNeurIPS, 2021] for learning data-driven reduced-order models (ROMs) in the POD\ncontext, in particular, for learning dynamics of time-varying coefficients\ngenerated by the POD analysis on training snapshots generated from solving full\norder models. HBNODE enjoys several practical advantages for learning POD-based\nROMs with theoretical guarantees, including 1) HBNODE can learn long-term\ndependencies effectively from sequential observations and 2) HBNODE is\ncomputationally efficient in both training and testing. We compare HBNODE with\nother popular ROMs on several complex dynamical systems, including the von\nK\\'{a}rm\\'{a}n Street flow, the Kurganov-Petrova-Popov equation, and the\none-dimensional Euler equations for fluids modeling.\n","authors":["Justin Baker","Elena Cherkaev","Akil Narayan","Bao Wang"],"pdf_url":"https://arxiv.org/pdf/2202.12373v2.pdf","comment":"31 pages, 20 figures"},{"id":"http://arxiv.org/abs/2303.02204v2","updated":"2023-03-09T20:04:05Z","published":"2023-03-03T20:31:04Z","title":"Linked Data Science Powered by Knowledge Graphs","summary":"  In recent years, we have witnessed a growing interest in data science not\nonly from academia but particularly from companies investing in data science\nplatforms to analyze large amounts of data. In this process, a myriad of data\nscience artifacts, such as datasets and pipeline scripts, are created. Yet,\nthere has so far been no systematic attempt to holistically exploit the\ncollected knowledge and experiences that are implicitly contained in the\nspecification of these pipelines, e.g., compatible datasets, cleansing steps,\nML algorithms, parameters, etc. Instead, data scientists still spend a\nconsiderable amount of their time trying to recover relevant information and\nexperiences from colleagues, trial and error, lengthy exploration, etc. In this\npaper, we, therefore, propose a scalable system (KGLiDS) that employs machine\nlearning to extract the semantics of data science pipelines and captures them\nin a knowledge graph, which can then be exploited to assist data scientists in\nvarious ways. This abstraction is the key to enabling Linked Data Science since\nit allows us to share the essence of pipelines between platforms, companies,\nand institutions without revealing critical internal information and instead\nfocusing on the semantics of what is being processed and how. Our comprehensive\nevaluation uses thousands of datasets and more than thirteen thousand pipeline\nscripts extracted from data discovery benchmarks and the Kaggle portal and\nshows that KGLiDS significantly outperforms state-of-the-art systems on related\ntasks, such as dataset recommendation and pipeline classification.\n","authors":["Mossad Helali","Shubham Vashisth","Philippe Carrier","Katja Hose","Essam Mansour"],"pdf_url":"https://arxiv.org/pdf/2303.02204v2.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2201.10520v3","updated":"2023-03-09T20:01:31Z","published":"2022-01-21T22:21:31Z","title":"Adaptive Activation-based Structured Pruning","summary":"  Pruning is a promising approach to compress complex deep learning models in\norder to deploy them on resource-constrained edge devices. However, many\nexisting pruning solutions are based on unstructured pruning, which yields\nmodels that cannot efficiently run on commodity hardware and require users to\nmanually explore and tune the pruning process, which is time-consuming and\noften leads to sub-optimal results. To address these limitations, this paper\npresents an adaptive, activation-based, structured pruning approach to\nautomatically and efficiently generate small, accurate, and hardware-efficient\nmodels that meet user requirements. First, it proposes iterative structured\npruning using activation-based attention feature maps to effectively identify\nand prune unimportant filters. Then, it proposes adaptive pruning policies for\nautomatically meeting the pruning objectives of accuracy-critical,\nmemory-constrained, and latency-sensitive tasks. A comprehensive evaluation\nshows that the proposed method can substantially outperform the\nstate-of-the-art structured pruning works on CIFAR-10 and ImageNet datasets.\nFor example, on ResNet-56 with CIFAR-10, without any accuracy drop, our method\nachieves the largest parameter reduction (79.11%), outperforming the related\nworks by 22.81% to 66.07%, and the largest FLOPs reduction (70.13%),\noutperforming the related works by 14.13% to 26.53%.\n","authors":["Kaiqi Zhao","Animesh Jain","Ming Zhao"],"pdf_url":"https://arxiv.org/pdf/2201.10520v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05561v1","updated":"2023-03-09T19:58:13Z","published":"2023-03-09T19:58:13Z","title":"Exploration of the search space of Gaussian graphical models for paired\n  data","summary":"  We consider the problem of learning a Gaussian graphical model in the case\nwhere the observations come from two dependent groups sharing the same\nvariables. We focus on a family of coloured Gaussian graphical models\nspecifically suited for the paired data problem. Commonly, graphical models are\nordered by the submodel relationship so that the search space is a lattice,\ncalled the model inclusion lattice. We introduce a novel order between models,\nnamed the twin order. We show that, embedded with this order, the model space\nis a lattice that, unlike the model inclusion lattice, is distributive.\nFurthermore, we provide the relevant rules for the computation of the\nneighbours of a model. The latter are more efficient than the same operations\nin the model inclusion lattice, and are then exploited to achieve a more\nefficient exploration of the search space. These results can be applied to\nimprove the efficiency of both greedy and Bayesian model search procedures.\nHere we implement a stepwise backward elimination procedure and evaluate its\nperformance by means of simulations. Finally, the procedure is applied to learn\na brain network from fMRI data where the two groups correspond to the left and\nright hemispheres, respectively.\n","authors":["Alberto Roverato","Dung Ngoc Nguyen"],"pdf_url":"https://arxiv.org/pdf/2303.05561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05558v1","updated":"2023-03-09T19:48:03Z","published":"2023-03-09T19:48:03Z","title":"Optimal active particle navigation meets machine learning","summary":"  The question of how \"smart\" active agents, like insects, microorganisms, or\nfuture colloidal robots need to steer to optimally reach or discover a target,\nsuch as an odor source, food, or a cancer cell in a complex environment has\nrecently attracted great interest. Here, we provide an overview of recent\ndevelopments, regarding such optimal navigation problems, from the micro- to\nthe macroscale, and give a perspective by discussing some of the challenges\nwhich are ahead of us. Besides exemplifying an elementary approach to optimal\nnavigation problems, the article focuses on works utilizing machine\nlearning-based methods. Such learning-based approaches can uncover highly\nefficient navigation strategies even for problems that involve e.g. chaotic,\nhigh-dimensional, or unknown environments and are hardly solvable based on\nconventional analytical or simulation methods.\n","authors":["Mahdi Nasiri","Hartmut Löwen","Benno Liebchen"],"pdf_url":"https://arxiv.org/pdf/2303.05558v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2301.03761v2","updated":"2023-03-09T19:46:57Z","published":"2023-01-10T02:46:09Z","title":"Tensor Denoising via Amplification and Stable Rank Methods","summary":"  Tensors in the form of multilinear arrays are ubiquitous in data science\napplications. Captured real-world data, including video, hyperspectral images,\nand discretized physical systems, naturally occur as tensors and often come\nwith attendant noise. Under the additive noise model and with the assumption\nthat the underlying clean tensor has low rank, many denoising methods have been\ncreated that utilize tensor decomposition to effect denoising through low rank\ntensor approximation. However, all such decomposition methods require\nestimating the tensor rank, or related measures such as the tensor spectral and\nnuclear norms, all of which are NP-hard problems.\n  In this work we leverage our previously developed framework of\n$\\textit{tensor amplification}$, which provides good approximations of the\nspectral and nuclear tensor norms, to denoising synthetic tensors of various\nsizes, ranks, and noise levels, along with real-world tensors derived from\nphysiological signals. We also introduce two new notions of tensor rank --\n$\\textit{stable slice rank}$ and $\\textit{stable }$$X$$\\textit{-rank}$ -- and\nnew denoising methods based on their estimation. The experimental results show\nthat in the low rank context, tensor-based amplification provides comparable\ndenoising performance in high signal-to-noise ratio (SNR) settings and superior\nperformance in noisy (i.e., low SNR) settings, while the stable $X$-rank method\nachieves superior denoising performance on the physiological signal data.\n","authors":["Jonathan Gryak","Kayvan Najarian","Harm Derksen"],"pdf_url":"https://arxiv.org/pdf/2301.03761v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05552v1","updated":"2023-03-09T19:19:56Z","published":"2023-03-09T19:19:56Z","title":"EfficientTempNet: Temporal Super-Resolution of Radar Rainfall","summary":"  Rainfall data collected by various remote sensing instruments such as radars\nor satellites has different space-time resolutions. This study aims to improve\nthe temporal resolution of radar rainfall products to help with more accurate\nclimate change modeling and studies. In this direction, we introduce a solution\nbased on EfficientNetV2, namely EfficientTempNet, to increase the temporal\nresolution of radar-based rainfall products from 10 minutes to 5 minutes. We\ntested EfficientRainNet over a dataset for the state of Iowa, US, and compared\nits performance to three different baselines to show that EfficientTempNet\npresents a viable option for better climate change monitoring.\n","authors":["Bekir Z Demiray","Muhammed Sit","Ibrahim Demir"],"pdf_url":"https://arxiv.org/pdf/2303.05552v1.pdf","comment":"Published as a workshop paper at Tackling Climate Change with Machine\n  Learning, ICLR 2023"},{"id":"http://arxiv.org/abs/2303.05545v1","updated":"2023-03-09T19:07:40Z","published":"2023-03-09T19:07:40Z","title":"Position Paper on Dataset Engineering to Accelerate Science","summary":"  Data is a critical element in any discovery process. In the last decades, we\nobserved exponential growth in the volume of available data and the technology\nto manipulate it. However, data is only practical when one can structure it for\na well-defined task. For instance, we need a corpus of text broken into\nsentences to train a natural language machine-learning model. In this work, we\nwill use the token \\textit{dataset} to designate a structured set of data built\nto perform a well-defined task. Moreover, the dataset will be used in most\ncases as a blueprint of an entity that at any moment can be stored as a table.\nSpecifically, in science, each area has unique forms to organize, gather and\nhandle its datasets. We believe that datasets must be a first-class entity in\nany knowledge-intensive process, and all workflows should have exceptional\nattention to datasets' lifecycle, from their gathering to uses and evolution.\nWe advocate that science and engineering discovery processes are extreme\ninstances of the need for such organization on datasets, claiming for new\napproaches and tooling. Furthermore, these requirements are more evident when\nthe discovery workflow uses artificial intelligence methods to empower the\nsubject-matter expert. In this work, we discuss an approach to bringing\ndatasets as a critical entity in the discovery process in science. We\nillustrate some concepts using material discovery as a use case. We chose this\ndomain because it leverages many significant problems that can be generalized\nto other science fields.\n","authors":["Emilio Vital Brazil","Eduardo Soares","Lucas Villa Real","Leonardo Azevedo","Vinicius Segura","Luiz Zerkowski","Renato Cerqueira"],"pdf_url":"https://arxiv.org/pdf/2303.05545v1.pdf","comment":"Published at 2nd Annual AAAI Workshop on AI to Accelerate Science and\n  Engineering (AI2ASE)\n  https://ai-2-ase.github.io/papers/16%5cSubmission%5cAAAI_Dataset_Engineering-8.pdf"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2303.05512v1","updated":"2023-03-09T18:59:50Z","published":"2023-03-09T18:59:50Z","title":"PAC-NeRF: Physics Augmented Continuum Neural Radiance Fields for\n  Geometry-Agnostic System Identification","summary":"  Existing approaches to system identification (estimating the physical\nparameters of an object) from videos assume known object geometries. This\nprecludes their applicability in a vast majority of scenes where object\ngeometries are complex or unknown. In this work, we aim to identify parameters\ncharacterizing a physical system from a set of multi-view videos without any\nassumption on object geometry or topology. To this end, we propose \"Physics\nAugmented Continuum Neural Radiance Fields\" (PAC-NeRF), to estimate both the\nunknown geometry and physical parameters of highly dynamic objects from\nmulti-view videos. We design PAC-NeRF to only ever produce physically plausible\nstates by enforcing the neural radiance field to follow the conservation laws\nof continuum mechanics. For this, we design a hybrid Eulerian-Lagrangian\nrepresentation of the neural radiance field, i.e., we use the Eulerian grid\nrepresentation for NeRF density and color fields, while advecting the neural\nradiance fields via Lagrangian particles. This hybrid Eulerian-Lagrangian\nrepresentation seamlessly blends efficient neural rendering with the material\npoint method (MPM) for robust differentiable physics simulation. We validate\nthe effectiveness of our proposed framework on geometry and physical parameter\nestimation over a vast range of materials, including elastic bodies,\nplasticine, sand, Newtonian and non-Newtonian fluids, and demonstrate\nsignificant performance gain on most tasks.\n","authors":["Xuan Li","Yi-Ling Qiao","Peter Yichen Chen","Krishna Murthy Jatavallabhula","Ming Lin","Chenfanfu Jiang","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2303.05512v1.pdf","comment":"ICLR 2023 Spotlight. Project page:\n  https://sites.google.com/view/PAC-NeRF"},{"id":"http://arxiv.org/abs/2303.05510v1","updated":"2023-03-09T18:59:47Z","published":"2023-03-09T18:59:47Z","title":"Planning with Large Language Models for Code Generation","summary":"  Existing large language model-based code generation pipelines typically use\nbeam search or sampling algorithms during the decoding process. Although the\nprograms they generate achieve high token-matching-based scores, they often\nfail to compile or generate incorrect outputs. The main reason is that\nconventional Transformer decoding algorithms may not be the best choice for\ncode generation. In this work, we propose a novel Transformer decoding\nalgorithm, Planning-Guided Transformer Decoding (PG-TD), that uses a planning\nalgorithm to do lookahead search and guide the Transformer to generate better\nprograms. Specifically, instead of simply optimizing the likelihood of the\ngenerated sequences, the Transformer makes use of a planner to generate\ncandidate programs and test them on public test cases. The Transformer can\ntherefore make more informed decisions and generate tokens that will eventually\nlead to higher-quality programs. We also design a mechanism that shares\ninformation between the Transformer and the planner to make our algorithm\ncomputationally efficient. We empirically evaluate our framework with several\nlarge language models as backbones on public coding challenge benchmarks,\nshowing that 1) it can generate programs that consistently achieve higher\nperformance compared with competing baseline methods; 2) it enables\ncontrollable code generation, such as concise codes and highly-commented codes\nby optimizing modified objective.\n","authors":["Shun Zhang","Zhenfang Chen","Yikang Shen","Mingyu Ding","Joshua B. Tenenbaum","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2303.05510v1.pdf","comment":"ICLR 2023. Project page:https://codeaimcts.github.io"},{"id":"http://arxiv.org/abs/2302.02948v3","updated":"2023-03-09T18:59:27Z","published":"2023-02-06T17:30:22Z","title":"Efficient Online Reinforcement Learning with Offline Data","summary":"  Sample efficiency and exploration remain major challenges in online\nreinforcement learning (RL). A powerful approach that can be applied to address\nthese issues is the inclusion of offline data, such as prior trajectories from\na human expert or a sub-optimal exploration policy. Previous methods have\nrelied on extensive modifications and additional complexity to ensure the\neffective use of this data. Instead, we ask: can we simply apply existing\noff-policy methods to leverage offline data when learning online? In this work,\nwe demonstrate that the answer is yes; however, a set of minimal but important\nchanges to existing off-policy RL algorithms are required to achieve reliable\nperformance. We extensively ablate these design choices, demonstrating the key\nfactors that most affect performance, and arrive at a set of recommendations\nthat practitioners can readily apply, whether their data comprise a small\nnumber of expert demonstrations or large volumes of sub-optimal trajectories.\nWe see that correct application of these simple recommendations can provide a\n$\\mathbf{2.5\\times}$ improvement over existing approaches across a diverse set\nof competitive benchmarks, with no additional computational overhead.\n","authors":["Philip J. Ball","Laura Smith","Ilya Kostrikov","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2302.02948v3.pdf","comment":"To reproduce our results and use our codebase, see\n  https://github.com/ikostrikov/rlpd"},{"id":"http://arxiv.org/abs/2303.05506v1","updated":"2023-03-09T18:57:13Z","published":"2023-03-09T18:57:13Z","title":"TANGOS: Regularizing Tabular Neural Networks through Gradient\n  Orthogonalization and Specialization","summary":"  Despite their success with unstructured data, deep neural networks are not\nyet a panacea for structured tabular data. In the tabular domain, their\nefficiency crucially relies on various forms of regularization to prevent\noverfitting and provide strong generalization performance. Existing\nregularization techniques include broad modelling decisions such as choice of\narchitecture, loss functions, and optimization methods. In this work, we\nintroduce Tabular Neural Gradient Orthogonalization and Specialization\n(TANGOS), a novel framework for regularization in the tabular setting built on\nlatent unit attributions. The gradient attribution of an activation with\nrespect to a given input feature suggests how the neuron attends to that\nfeature, and is often employed to interpret the predictions of deep networks.\nIn TANGOS, we take a different approach and incorporate neuron attributions\ndirectly into training to encourage orthogonalization and specialization of\nlatent attributions in a fully-connected network. Our regularizer encourages\nneurons to focus on sparse, non-overlapping input features and results in a set\nof diverse and specialized latent units. In the tabular domain, we demonstrate\nthat our approach can lead to improved out-of-sample generalization\nperformance, outperforming other popular regularization methods. We provide\ninsight into why our regularizer is effective and demonstrate that TANGOS can\nbe applied jointly with existing methods to achieve even greater generalization\nperformance.\n","authors":["Alan Jeffares","Tennison Liu","Jonathan Crabbé","Fergus Imrie","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2303.05506v1.pdf","comment":"Published at International Conference on Learning Representations\n  (ICLR) 2023"},{"id":"http://arxiv.org/abs/2303.05503v1","updated":"2023-03-09T18:55:03Z","published":"2023-03-09T18:55:03Z","title":"Open-world Instance Segmentation: Top-down Learning with Bottom-up\n  Supervision","summary":"  Many top-down architectures for instance segmentation achieve significant\nsuccess when trained and tested on pre-defined closed-world taxonomy. However,\nwhen deployed in the open world, they exhibit notable bias towards seen classes\nand suffer from significant performance drop. In this work, we propose a novel\napproach for open world instance segmentation called bottom-Up and top-Down\nOpen-world Segmentation (UDOS) that combines classical bottom-up segmentation\nalgorithms within a top-down learning framework. UDOS first predicts parts of\nobjects using a top-down network trained with weak supervision from bottom-up\nsegmentations. The bottom-up segmentations are class-agnostic and do not\noverfit to specific taxonomies. The part-masks are then fed into affinity-based\ngrouping and refinement modules to predict robust instance-level segmentations.\nUDOS enjoys both the speed and efficiency from the top-down architectures and\nthe generalization ability to unseen categories from bottom-up supervision. We\nvalidate the strengths of UDOS on multiple cross-category as well as\ncross-dataset transfer tasks from 5 challenging datasets including MS-COCO,\nLVIS, ADE20k, UVO and OpenImages, achieving significant improvements over\nstate-of-the-art across the board. Our code and models are available on our\nproject page.\n","authors":["Tarun Kalluri","Weiyao Wang","Heng Wang","Manmohan Chandraker","Lorenzo Torresani","Du Tran"],"pdf_url":"https://arxiv.org/pdf/2303.05503v1.pdf","comment":"Project page: https://tarun005.github.io/UDOS"},{"id":"http://arxiv.org/abs/2301.03561v2","updated":"2023-03-09T18:55:02Z","published":"2023-01-09T18:21:22Z","title":"Ancilia: Scalable Intelligent Video Surveillance for the Artificial\n  Intelligence of Things","summary":"  With the advancement of vision-based artificial intelligence, the\nproliferation of the Internet of Things connected cameras, and the increasing\nsocietal need for rapid and equitable security, the demand for accurate\nreal-time intelligent surveillance has never been higher. This article presents\nAncilia, an end-to-end scalable, intelligent video surveillance system for the\nArtificial Intelligence of Things. Ancilia brings state-of-the-art artificial\nintelligence to real-world surveillance applications while respecting ethical\nconcerns and performing high-level cognitive tasks in real-time. Ancilia aims\nto revolutionize the surveillance landscape, to bring more effective,\nintelligent, and equitable security to the field, resulting in safer and more\nsecure communities without requiring people to compromise their right to\nprivacy.\n","authors":["Armin Danesh Pazho","Christopher Neff","Ghazal Alinezhad Noghre","Babak Rahimi Ardabili","Shanle Yao","Mohammadreza Baharani","Hamed Tabkhi"],"pdf_url":"https://arxiv.org/pdf/2301.03561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01850v4","updated":"2023-03-09T18:54:31Z","published":"2023-01-04T23:28:58Z","title":"Bayesian Weapon System Reliability Modeling with Cox-Weibull Neural\n  Network","summary":"  We propose to integrate weapon system features (such as weapon system\nmanufacturer, deployment time and location, storage time and location, etc.)\ninto a parameterized Cox-Weibull [1] reliability model via a neural network,\nlike DeepSurv [2], to improve predictive maintenance. In parallel, we develop\nan alternative Bayesian model by parameterizing the Weibull parameters with a\nneural network and employing dropout methods such as Monte-Carlo (MC)-dropout\nfor comparative purposes. Due to data collection procedures in weapon system\ntesting we employ a novel interval-censored log-likelihood which incorporates\nMonte-Carlo Markov Chain (MCMC) [3] sampling of the Weibull parameters during\ngradient descent optimization. We compare classification metrics such as\nreceiver operator curve (ROC) area under the curve (AUC), precision-recall (PR)\nAUC, and F scores to show our model generally outperforms traditional powerful\nmodels such as XGBoost and the current standard conditional Weibull probability\ndensity estimation model.\n","authors":["Michael Potter","Benny Cheng"],"pdf_url":"https://arxiv.org/pdf/2301.01850v4.pdf","comment":"Pre-print with minor revisions, published at The 69th Annual\n  Reliability and Maintainability Symposium, January 23-26, 2023, FL, USA"},{"id":"http://arxiv.org/abs/2303.05501v1","updated":"2023-03-09T18:54:12Z","published":"2023-03-09T18:54:12Z","title":"PDSketch: Integrated Planning Domain Programming and Learning","summary":"  This paper studies a model learning and online planning approach towards\nbuilding flexible and general robots. Specifically, we investigate how to\nexploit the locality and sparsity structures in the underlying environmental\ntransition model to improve model generalization, data-efficiency, and\nruntime-efficiency. We present a new domain definition language, named\nPDSketch. It allows users to flexibly define high-level structures in the\ntransition models, such as object and feature dependencies, in a way similar to\nhow programmers use TensorFlow or PyTorch to specify kernel sizes and hidden\ndimensions of a convolutional neural network. The details of the transition\nmodel will be filled in by trainable neural networks. Based on the defined\nstructures and learned parameters, PDSketch automatically generates\ndomain-independent planning heuristics without additional training. The derived\nheuristics accelerate the performance-time planning for novel goals.\n","authors":["Jiayuan Mao","Tomás Lozano-Pérez","Joshua B. Tenenbaum","Leslie Pack Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2303.05501v1.pdf","comment":"NeurIPS 2022. Project page: https://pdsketch.csail.mit.edu"},{"id":"http://arxiv.org/abs/2303.05500v1","updated":"2023-03-09T18:53:29Z","published":"2023-03-09T18:53:29Z","title":"Users are the North Star for AI Transparency","summary":"  Despite widespread calls for transparent artificial intelligence systems, the\nterm is too overburdened with disparate meanings to express precise policy aims\nor to orient concrete lines of research. Consequently, stakeholders often talk\npast each other, with policymakers expressing vague demands and practitioners\ndevising solutions that may not address the underlying concerns. Part of why\nthis happens is that a clear ideal of AI transparency goes unsaid in this body\nof work. We explicitly name such a north star -- transparency that is\nuser-centered, user-appropriate, and honest. We conduct a broad literature\nsurvey, identifying many clusters of similar conceptions of transparency, tying\neach back to our north star with analysis of how it furthers or hinders our\nideal AI transparency goals. We conclude with a discussion on common threads\nacross all the clusters, to provide clearer common language whereby\npolicymakers, stakeholders, and practitioners can communicate concrete demands\nand deliver appropriate solutions. We hope for future work on AI transparency\nthat further advances confident, user-beneficial goals and provides clarity to\nregulators and developers alike.\n","authors":["Alex Mei","Michael Saxon","Shiyu Chang","Zachary C. Lipton","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.05500v1.pdf","comment":"9 pages, 3 tables"},{"id":"http://arxiv.org/abs/2303.05498v1","updated":"2023-03-09T18:51:31Z","published":"2023-03-09T18:51:31Z","title":"Mark My Words: Dangers of Watermarked Images in ImageNet","summary":"  The utilization of pre-trained networks, especially those trained on\nImageNet, has become a common practice in Computer Vision. However, prior\nresearch has indicated that a significant number of images in the ImageNet\ndataset contain watermarks, making pre-trained networks susceptible to learning\nartifacts such as watermark patterns within their latent spaces. In this paper,\nwe aim to assess the extent to which popular pre-trained architectures display\nsuch behavior and to determine which classes are most affected. Additionally,\nwe examine the impact of watermarks on the extracted features. Contrary to the\npopular belief that the Chinese logographic watermarks impact the \"carton\"\nclass only, our analysis reveals that a variety of ImageNet classes, such as\n\"monitor\", \"broom\", \"apron\" and \"safe\" rely on spurious correlations. Finally,\nwe propose a simple approach to mitigate this issue in fine-tuned networks by\nignoring the encodings from the feature-extractor layer of ImageNet pre-trained\nnetworks that are most susceptible to watermark imprints.\n","authors":["Kirill Bykov","Klaus-Robert Müller","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2303.05498v1.pdf","comment":"5 pages, 4 figures, Accepted to the ICLR 2023 TrustML-(un)Limited\n  workshop"},{"id":"http://arxiv.org/abs/2303.05496v1","updated":"2023-03-09T18:50:14Z","published":"2023-03-09T18:50:14Z","title":"Sparse and Local Networks for Hypergraph Reasoning","summary":"  Reasoning about the relationships between entities from input facts (e.g.,\nwhether Ari is a grandparent of Charlie) generally requires explicit\nconsideration of other entities that are not mentioned in the query (e.g., the\nparents of Charlie). In this paper, we present an approach for learning to\nsolve problems of this kind in large, real-world domains, using sparse and\nlocal hypergraph neural networks (SpaLoc). SpaLoc is motivated by two\nobservations from traditional logic-based reasoning: relational inferences\nusually apply locally (i.e., involve only a small number of individuals), and\nrelations are usually sparse (i.e., only hold for a small percentage of tuples\nin a domain). We exploit these properties to make learning and inference\nefficient in very large domains by (1) using a sparse tensor representation for\nhypergraph neural networks, (2) applying a sparsification loss during training\nto encourage sparse representations, and (3) subsampling based on a novel\ninformation sufficiency-based sampling process during training. SpaLoc achieves\nstate-of-the-art performance on several real-world, large-scale knowledge graph\nreasoning benchmarks, and is the first framework for applying hypergraph neural\nnetworks on real-world knowledge graphs with more than 10k nodes.\n","authors":["Guangxuan Xiao","Leslie Pack Kaelbling","Jiajun Wu","Jiayuan Mao"],"pdf_url":"https://arxiv.org/pdf/2303.05496v1.pdf","comment":"Learning on Graphs Conference (LoG) 2022. Project page:\n  https://spaloc.csail.mit.edu"},{"id":"http://arxiv.org/abs/2303.05490v1","updated":"2023-03-09T18:42:18Z","published":"2023-03-09T18:42:18Z","title":"On the Expressiveness and Generalization of Hypergraph Neural Networks","summary":"  This extended abstract describes a framework for analyzing the\nexpressiveness, learning, and (structural) generalization of hypergraph neural\nnetworks (HyperGNNs). Specifically, we focus on how HyperGNNs can learn from\nfinite datasets and generalize structurally to graph reasoning problems of\narbitrary input sizes. Our first contribution is a fine-grained analysis of the\nexpressiveness of HyperGNNs, that is, the set of functions that they can\nrealize. Our result is a hierarchy of problems they can solve, defined in terms\nof various hyperparameters such as depths and edge arities. Next, we analyze\nthe learning properties of these neural networks, especially focusing on how\nthey can be trained on a finite set of small graphs and generalize to larger\ngraphs, which we term structural generalization. Our theoretical results are\nfurther supported by the empirical results.\n","authors":["Zhezheng Luo","Jiayuan Mao","Joshua B. Tenenbaum","Leslie Pack Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2303.05490v1.pdf","comment":"Learning on Graphs Conference (LoG) 2022"},{"id":"http://arxiv.org/abs/2303.05487v1","updated":"2023-03-09T18:39:22Z","published":"2023-03-09T18:39:22Z","title":"Learning Rational Subgoals from Demonstrations and Instructions","summary":"  We present a framework for learning useful subgoals that support efficient\nlong-term planning to achieve novel goals. At the core of our framework is a\ncollection of rational subgoals (RSGs), which are essentially binary\nclassifiers over the environmental states. RSGs can be learned from\nweakly-annotated data, in the form of unsegmented demonstration trajectories,\npaired with abstract task descriptions, which are composed of terms initially\nunknown to the agent (e.g., collect-wood then craft-boat then go-across-river).\nOur framework also discovers dependencies between RSGs, e.g., the task\ncollect-wood is a helpful subgoal for the task craft-boat. Given a goal\ndescription, the learned subgoals and the derived dependencies facilitate\noff-the-shelf planning algorithms, such as A* and RRT, by setting helpful\nsubgoals as waypoints to the planner, which significantly improves\nperformance-time efficiency.\n","authors":["Zhezheng Luo","Jiayuan Mao","Jiajun Wu","Tomás Lozano-Pérez","Joshua B. Tenenbaum","Leslie Pack Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2303.05487v1.pdf","comment":"AAAI 2023. First two authors contributed equally. Project page:\n  https://rsg.csail.mit.edu"},{"id":"http://arxiv.org/abs/2303.05479v1","updated":"2023-03-09T18:31:13Z","published":"2023-03-09T18:31:13Z","title":"Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online\n  Fine-Tuning","summary":"  A compelling use case of offline reinforcement learning (RL) is to obtain a\npolicy initialization from existing datasets, which allows efficient\nfine-tuning with limited amounts of active online interaction. However, several\nexisting offline RL methods tend to exhibit poor online fine-tuning\nperformance. On the other hand, online RL methods can learn effectively through\nonline interaction, but struggle to incorporate offline data, which can make\nthem very slow in settings where exploration is challenging or pre-training is\nnecessary. In this paper, we devise an approach for learning an effective\ninitialization from offline data that also enables fast online fine-tuning\ncapabilities. Our approach, calibrated Q-learning (Cal-QL) accomplishes this by\nlearning a conservative value function initialization that underestimates the\nvalue of the learned policy from offline data, while also being calibrated, in\nthe sense that the learned Q-values are at a reasonable scale. We refer to this\nproperty as calibration, and define it formally as providing a lower bound on\nthe true value function of the learned policy and an upper bound on the value\nof some other (suboptimal) reference policy, which may simply be the behavior\npolicy. We show that offline RL algorithms that learn such calibrated value\nfunctions lead to effective online fine-tuning, enabling us to take the\nbenefits of offline initializations in online fine-tuning. In practice, Cal-QL\ncan be implemented on top of existing conservative methods for offline RL\nwithin a one-line code change. Empirically, Cal-QL outperforms state-of-the-art\nmethods on 10/11 fine-tuning benchmark tasks that we study in this paper.\n","authors":["Mitsuhiko Nakamoto","Yuexiang Zhai","Anikait Singh","Max Sobol Mark","Yi Ma","Chelsea Finn","Aviral Kumar","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2303.05479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09258v2","updated":"2023-03-09T18:29:47Z","published":"2022-12-19T06:05:34Z","title":"CHAD: Charlotte Anomaly Dataset","summary":"  In recent years, we have seen a significant interest in data-driven deep\nlearning approaches for video anomaly detection, where an algorithm must\ndetermine if specific frames of a video contain abnormal behaviors. However,\nvideo anomaly detection is particularly context-specific, and the availability\nof representative datasets heavily limits real-world accuracy. Additionally,\nthe metrics currently reported by most state-of-the-art methods often do not\nreflect how well the model will perform in real-world scenarios. In this\narticle, we present the Charlotte Anomaly Dataset (CHAD). CHAD is a\nhigh-resolution, multi-camera anomaly dataset in a commercial parking lot\nsetting. In addition to frame-level anomaly labels, CHAD is the first anomaly\ndataset to include bounding box, identity, and pose annotations for each actor.\nThis is especially beneficial for skeleton-based anomaly detection, which is\nuseful for its lower computational demand in real-world settings. CHAD is also\nthe first anomaly dataset to contain multiple views of the same scene. With\nfour camera views and over 1.15 million frames, CHAD is the largest fully\nannotated anomaly detection dataset including person annotations, collected\nfrom continuous video streams from stationary cameras for smart video\nsurveillance applications. To demonstrate the efficacy of CHAD for training and\nevaluation, we benchmark two state-of-the-art skeleton-based anomaly detection\nalgorithms on CHAD and provide comprehensive analysis, including both\nquantitative results and qualitative examination. The dataset is available at\nhttps://github.com/TeCSAR-UNCC/CHAD.\n","authors":["Armin Danesh Pazho","Ghazal Alinezhad Noghre","Babak Rahimi Ardabili","Christopher Neff","Hamed Tabkhi"],"pdf_url":"https://arxiv.org/pdf/2212.09258v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05463v1","updated":"2023-03-09T18:09:45Z","published":"2023-03-09T18:09:45Z","title":"Understanding the Challenges and Opportunities of Pose-based Anomaly\n  Detection","summary":"  Pose-based anomaly detection is a video-analysis technique for detecting\nanomalous events or behaviors by examining human pose extracted from the video\nframes. Utilizing pose data alleviates privacy and ethical issues. Also,\ncomputation-wise, the complexity of pose-based models is lower than pixel-based\napproaches. However, it introduces more challenges, such as noisy skeleton\ndata, losing important pixel information, and not having enriched enough\nfeatures. These problems are exacerbated by a lack of anomaly detection\ndatasets that are good enough representatives of real-world scenarios. In this\nwork, we analyze and quantify the characteristics of two well-known video\nanomaly datasets to better understand the difficulties of pose-based anomaly\ndetection. We take a step forward, exploring the discriminating power of pose\nand trajectory for video anomaly detection and their effectiveness based on\ncontext. We believe these experiments are beneficial for a better comprehension\nof pose-based anomaly detection and the datasets currently available. This will\naid researchers in tackling the task of anomaly detection with a more lucid\nperspective, accelerating the development of robust models with better\nperformance.\n","authors":["Ghazal Alinezhad Noghre","Armin Danesh Pazho","Vinit Katariya","Hamed Tabkhi"],"pdf_url":"https://arxiv.org/pdf/2303.05463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09051v3","updated":"2023-03-09T17:25:10Z","published":"2023-02-17T18:31:31Z","title":"Complex QA and language models hybrid architectures, Survey","summary":"  This paper reviews the state-of-the-art of hybrid language models\narchitectures and strategies for \"complex\" question-answering (QA, CQA, CPS).\nLarge Language Models (LLM) are good at leveraging public data on standard\nproblems but once you want to tackle more specific complex questions or\nproblems you may need specific architecture, knowledge, skills, methods,\nsensitive data protection, explainability, human approval and versatile\nfeedback... We identify key elements augmenting LLM to solve complex questions\nor problems. We extend findings from the robust community edited research\npapers BIG, BLOOM and HELM which open source, benchmark and analyze limits and\nchallenges of LLM in terms of tasks complexity and strict evaluation on\naccuracy (e.g. fairness, robustness, toxicity, ...). Recent projects like\nChatGPT and GALACTICA have allowed non-specialists to grasp the great potential\nas well as the equally strong limitations of language models in complex QA.\nHybridizing these models with different components could allow to overcome\nthese different limits and go much further. We discuss some challenges\nassociated with complex QA, including domain adaptation, decomposition and\nefficient multi-step QA, long form and non-factoid QA, safety and\nmulti-sensitivity data protection, multimodal search, hallucinations,\nexplainability and truthfulness, temproal reasoning. Therefore, we analyze\ncurrent solutions and promising research trends, using elements such as: hybrid\nLLM architectures, active human reinforcement learning supervised with AI,\nprompting adaptation, neuro-symbolic and structured knowledge grounding,\nprogram synthesis, iterated decomposition and others.\n","authors":["Xavier Daull","Patrice Bellot","Emmanuel Bruno","Vincent Martin","Elisabeth Murisasco"],"pdf_url":"https://arxiv.org/pdf/2302.09051v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05416v1","updated":"2023-03-09T17:05:19Z","published":"2023-03-09T17:05:19Z","title":"FaceXHuBERT: Text-less Speech-driven E(X)pressive 3D Facial Animation\n  Synthesis Using Self-Supervised Speech Representation Learning","summary":"  This paper presents FaceXHuBERT, a text-less speech-driven 3D facial\nanimation generation method that allows to capture personalized and subtle cues\nin speech (e.g. identity, emotion and hesitation). It is also very robust to\nbackground noise and can handle audio recorded in a variety of situations (e.g.\nmultiple people speaking). Recent approaches employ end-to-end deep learning\ntaking into account both audio and text as input to generate facial animation\nfor the whole face. However, scarcity of publicly available expressive audio-3D\nfacial animation datasets poses a major bottleneck. The resulting animations\nstill have issues regarding accurate lip-synching, expressivity,\nperson-specific information and generalizability. We effectively employ\nself-supervised pretrained HuBERT model in the training process that allows us\nto incorporate both lexical and non-lexical information in the audio without\nusing a large lexicon. Additionally, guiding the training with a binary emotion\ncondition and speaker identity distinguishes the tiniest subtle facial motion.\nWe carried out extensive objective and subjective evaluation in comparison to\nground-truth and state-of-the-art work. A perceptual user study demonstrates\nthat our approach produces superior results with respect to the realism of the\nanimation 78% of the time in comparison to the state-of-the-art. In addition,\nour method is 4 times faster eliminating the use of complex sequential models\nsuch as transformers. We strongly recommend watching the supplementary video\nbefore reading the paper. We also provide the implementation and evaluation\ncodes with a GitHub repository link.\n","authors":["Kazi Injamamul Haque","Zerrin Yumak"],"pdf_url":"https://arxiv.org/pdf/2303.05416v1.pdf","comment":"13 pages, 4 figures, code included"},{"id":"http://arxiv.org/abs/2205.01647v5","updated":"2023-03-09T16:40:45Z","published":"2022-05-03T17:14:47Z","title":"Intelligent Trajectory Design for RIS-NOMA aided Multi-robot\n  Communications","summary":"  A novel reconfigurable intelligent surface-aided multi-robot network is\nproposed, where multiple mobile robots are served by an access point (AP)\nthrough non-orthogonal multiple access (NOMA). The goal is to maximize the\nsum-rate of whole trajectories for the multi-robot system by jointly optimizing\ntrajectories and NOMA decoding orders of robots, phase-shift coefficients of\nthe RIS, and the power allocation of the AP, subject to predicted initial and\nfinal positions of robots and the quality of service (QoS) of each robot. To\ntackle this problem, an integrated machine learning (ML) scheme is proposed,\nwhich combines long short-term memory (LSTM)-autoregressive integrated moving\naverage (ARIMA) model and dueling double deep Q-network (D$^{3}$QN) algorithm.\nFor initial and final position prediction for robots, the LSTM-ARIMA is able to\novercome the problem of gradient vanishment of non-stationary and non-linear\nsequences of data. For jointly determining the phase shift matrix and robots'\ntrajectories, D$^{3}$QN is invoked for solving the problem of action value\noverestimation. Based on the proposed scheme, each robot holds an optimal\ntrajectory based on the maximum sum-rate of a whole trajectory, which reveals\nthat robots pursue long-term benefits for whole trajectory design. Numerical\nresults demonstrated that: 1) LSTM-ARIMA model provides high accuracy\npredicting model; 2) The proposed D$^{3}$QN algorithm can achieve fast average\nconvergence; and 3) RIS-NOMA networks have superior network performance\ncompared to RIS-aided orthogonal counterparts.\n","authors":["Xinyu Gao","Xidong Mu","Wenqiang Yi","Yuanwei Liu"],"pdf_url":"https://arxiv.org/pdf/2205.01647v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.10120v6","updated":"2023-03-09T16:39:58Z","published":"2022-05-17T14:00:58Z","title":"Privacy Preserving Image Registration","summary":"  Image registration is a key task in medical imaging applications, allowing to\nrepresent medical images in a common spatial reference frame. Current\napproaches to image registration are generally based on the assumption that the\ncontent of the images is usually accessible in clear form, from which the\nspatial transformation is subsequently estimated. This common assumption may\nnot be met in practical applications, since the sensitive nature of medical\nimages may ultimately require their analysis under privacy constraints,\npreventing to openly share the image content.In this work, we formulate the\nproblem of image registration under a privacy preserving regime, where images\nare assumed to be confidential and cannot be disclosed in clear. We derive our\nprivacy preserving image registration framework by extending classical\nregistration paradigms to account for advanced cryptographic tools, such as\nsecure multi-party computation and homomorphic encryption, that enable the\nexecution of operations without leaking the underlying data. To overcome the\nproblem of performance and scalability of cryptographic tools in high\ndimensions, we propose several techniques to optimize the image registration\noperations by using gradient approximations, and by revisiting the use of\nhomomorphic encryption trough packing, to allow the efficient encryption and\nmultiplication of large matrices. We demonstrate our privacy preserving\nframework in linear and non-linear registration problems, evaluating its\naccuracy and scalability with respect to standard, non-private counterparts.\nOur results show that privacy preserving image registration is feasible and can\nbe adopted in sensitive medical imaging applications.\n","authors":["Riccardo Taiello","Melek Önen","Francesco Capano","Olivier Humbert","Marco Lorenzi"],"pdf_url":"https://arxiv.org/pdf/2205.10120v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05393v1","updated":"2023-03-09T16:31:35Z","published":"2023-03-09T16:31:35Z","title":"Deep Functional Predictive Control for Strawberry Cluster Manipulation\n  using Tactile Prediction","summary":"  This paper introduces a novel approach to address the problem of Physical\nRobot Interaction (PRI) during robot pushing tasks. The approach uses a\ndata-driven forward model based on tactile predictions to inform the controller\nabout potential future movements of the object being pushed, such as a\nstrawberry stem, using a robot tactile finger. The model is integrated into a\nDeep Functional Predictive Control (d-FPC) system to control the displacement\nof the stem on the tactile finger during pushes. Pushing an object with a robot\nfinger along a desired trajectory in 3D is a highly nonlinear and complex\nphysical robot interaction, especially when the object is not stably grasped.\nThe proposed approach controls the stem movements on the tactile finger in a\nprediction horizon. The effectiveness of the proposed FPC is demonstrated in a\nseries of tests involving a real robot pushing a strawberry in a cluster. The\nresults indicate that the d-FPC controller can successfully control PRI in\nrobotic manipulation tasks beyond the handling of strawberries. The proposed\napproach offers a promising direction for addressing the challenging PRI\nproblem in robotic manipulation tasks. Future work will explore the\ngeneralisation of the approach to other objects and tasks.\n","authors":["Kiyanoush Nazari","Gabriele Gandolfi","Zeynab Talebpour","Vishnu Rajendran","Paolo Rocco","Amir Ghalamzan E."],"pdf_url":"https://arxiv.org/pdf/2303.05393v1.pdf","comment":"Submitted to IEEE IROS 2023"},{"id":"http://arxiv.org/abs/2303.03709v2","updated":"2023-03-09T16:23:02Z","published":"2023-03-07T07:47:41Z","title":"Bootstrap The Original Latent: Learning a Private Model from a Black-box\n  Model","summary":"  In this paper, considering the balance of data/model privacy of model owners\nand user needs, we propose a new setting called Back-Propagated Black-Box\nAdaptation (BPBA) for users to better train their private models via the\nguidance of the back-propagated results of a Black-box foundation/source model.\nOur setting can ease the usage of foundation/source models as well as prevent\nthe leakage and misuse of foundation/source models. Moreover, we also propose a\nnew training strategy called Bootstrap The Original Latent (BTOL) to fully\nutilize the foundation/source models. Our strategy consists of a domain adapter\nand a freeze-and-thaw strategy. We apply our BTOL under BPBA and Black-box UDA\nsettings on three different datasets. Experiments show that our strategy is\nefficient and robust in various settings without manual augmentations.\n","authors":["Shuai Wang","Daoan Zhang","Jianguo Zhang","Weiwei Zhang","Rui Li"],"pdf_url":"https://arxiv.org/pdf/2303.03709v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05360v1","updated":"2023-03-09T16:10:13Z","published":"2023-03-09T16:10:13Z","title":"Proceedings 11th International Workshop on Theorem Proving Components\n  for Educational Software","summary":"  The ThEdu series pursues the smooth transition from an intuitive way of doing\nmathematics at secondary school to a more formal approach to the subject in\nSTEM education, while favouring software support for this transition by\nexploiting the power of theorem-proving technologies. What follows is a brief\ndescription of how the present volume contributes to this enterprise. The 11th\nInternational Workshop on Theorem Proving Components for Educational Software\n(ThEdu'22), was a satellite event of the 8th Federated Logic Conference (FLoC\n2022), July 31-August 12, 2022, Haifa, Israel ThEdu'22 was a vibrant workshop,\nwith two invited talk by Thierry Dana-Picard (Jerusalem College of Technology,\nJerusalem, Israel) and Yoni Zohar (Bar Ilan University, Tel Aviv, Israel) and\nfour contributions. An open call for papers was then issued, and attracted\nseven submissions. Those submissions have been accepted by our reviewers, who\njointly produced at least three careful reports on each of the contributions.\nThe resulting revised papers are collected in the present volume. The\ncontributions in this volume are a faithful representation of the wide spectrum\nof ThEdu, ranging from those more focused on the automated deduction research,\nnot losing track of the possible applications in an educational setting, to\nthose focused on the applications, in educational settings, of automated\ndeduction tools and methods. We, the volume editors, hope that this collection\nof papers will further promote the development of theorem-proving based\nsoftware, and that it will allow to improve the mutual understanding between\ncomputer scientists, mathematicians and stakeholders in education. While this\nvolume goes to press, the next edition of the ThEdu workshop is being prepared:\nThEdu'23 will be a satellite event of the 29th international Conference on\nAutomated Deduction (CADE 2023), July 1-4, 2023, Rome, Italy.\n","authors":["Pedro Quaresma","João Marcos","Walther Neuper"],"pdf_url":"https://arxiv.org/pdf/2303.05360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.10687v2","updated":"2023-03-09T15:43:15Z","published":"2022-08-23T02:19:10Z","title":"The Effect of Modeling Human Rationality Level on Learning Rewards from\n  Multiple Feedback Types","summary":"  When inferring reward functions from human behavior (be it demonstrations,\ncomparisons, physical corrections, or e-stops), it has proven useful to model\nthe human as making noisy-rational choices, with a \"rationality coefficient\"\ncapturing how much noise or entropy we expect to see in the human behavior.\nPrior work typically sets the rationality level to a constant value, regardless\nof the type, or quality, of human feedback. However, in many settings, giving\none type of feedback (e.g. a demonstration) may be much more difficult than a\ndifferent type of feedback (e.g. answering a comparison query). Thus, we expect\nto see more or less noise depending on the type of human feedback. In this\nwork, we advocate that grounding the rationality coefficient in real data for\neach feedback type, rather than assuming a default value, has a significant\npositive effect on reward learning. We test this in both simulated experiments\nand in a user study with real human feedback. We find that overestimating human\nrationality can have dire effects on reward learning accuracy and regret. We\nalso find that fitting the rationality coefficient to human data enables better\nreward learning, even when the human deviates significantly from the\nnoisy-rational choice model due to systematic biases. Further, we find that the\nrationality level affects the informativeness of each feedback type:\nsurprisingly, demonstrations are not always the most informative -- when the\nhuman acts very suboptimally, comparisons actually become more informative,\neven when the rationality level is the same for both. Ultimately, our results\nemphasize the importance and advantage of paying attention to the assumed\nhuman-rationality level, especially when agents actively learn from multiple\ntypes of human feedback.\n","authors":["Gaurav R. Ghosal","Matthew Zurek","Daniel S. Brown","Anca D. Dragan"],"pdf_url":"https://arxiv.org/pdf/2208.10687v2.pdf","comment":"Published at AAAI 2023; 10 pages, 5 figures plus appendices"},{"id":"http://arxiv.org/abs/2303.05344v1","updated":"2023-03-09T15:42:01Z","published":"2023-03-09T15:42:01Z","title":"Recent Advances of Deep Robotic Affordance Learning: A Reinforcement\n  Learning Perspective","summary":"  As a popular concept proposed in the field of psychology, affordance has been\nregarded as one of the important abilities that enable humans to understand and\ninteract with the environment. Briefly, it captures the possibilities and\neffects of the actions of an agent applied to a specific object or, more\ngenerally, a part of the environment. This paper provides a short review of the\nrecent developments of deep robotic affordance learning (DRAL), which aims to\ndevelop data-driven methods that use the concept of affordance to aid in\nrobotic tasks. We first classify these papers from a reinforcement learning\n(RL) perspective, and draw connections between RL and affordances. The\ntechnical details of each category are discussed and their limitations\nidentified. We further summarise them and identify future challenges from the\naspects of observations, actions, affordance representation, data-collection\nand real-world deployment. A final remark is given at the end to propose a\npromising future direction of the RL-based affordance definition to include the\npredictions of arbitrary action consequences.\n","authors":["Xintong Yang","Ze Ji","Jing Wu","Yu-kun Lai"],"pdf_url":"https://arxiv.org/pdf/2303.05344v1.pdf","comment":"This paper is under review"},{"id":"http://arxiv.org/abs/2303.05342v1","updated":"2023-03-09T15:38:40Z","published":"2023-03-09T15:38:40Z","title":"Knowledge-augmented Few-shot Visual Relation Detection","summary":"  Visual Relation Detection (VRD) aims to detect relationships between objects\nfor image understanding. Most existing VRD methods rely on thousands of\ntraining samples of each relationship to achieve satisfactory performance. Some\nrecent papers tackle this problem by few-shot learning with elaborately\ndesigned pipelines and pre-trained word vectors. However, the performance of\nexisting few-shot VRD models is severely hampered by the poor generalization\ncapability, as they struggle to handle the vast semantic diversity of visual\nrelationships. Nonetheless, humans have the ability to learn new relationships\nwith just few examples based on their knowledge. Inspired by this, we devise a\nknowledge-augmented, few-shot VRD framework leveraging both textual knowledge\nand visual relation knowledge to improve the generalization ability of few-shot\nVRD. The textual knowledge and visual relation knowledge are acquired from a\npre-trained language model and an automatically constructed visual relation\nknowledge graph, respectively. We extensively validate the effectiveness of our\nframework. Experiments conducted on three benchmarks from the commonly used\nVisual Genome dataset show that our performance surpasses existing\nstate-of-the-art models with a large improvement.\n","authors":["Tianyu Yu","Yangning Li","Jiaoyan Chen","Yinghui Li","Hai-Tao Zheng","Xi Chen","Qingbin Liu","Wenqiang Liu","Dongxiao Huang","Bei Wu","Yexin Wang"],"pdf_url":"https://arxiv.org/pdf/2303.05342v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2303.05334v1","updated":"2023-03-09T15:24:26Z","published":"2023-03-09T15:24:26Z","title":"Brain-Diffuser: Natural scene reconstruction from fMRI signals using\n  generative latent diffusion","summary":"  In neural decoding research, one of the most intriguing topics is the\nreconstruction of perceived natural images based on fMRI signals. Previous\nstudies have succeeded in re-creating different aspects of the visuals, such as\nlow-level properties (shape, texture, layout) or high-level features (category\nof objects, descriptive semantics of scenes) but have typically failed to\nreconstruct these properties together for complex scene images. Generative AI\nhas recently made a leap forward with latent diffusion models capable of\ngenerating high-complexity images. Here, we investigate how to take advantage\nof this innovative technology for brain decoding. We present a two-stage scene\nreconstruction framework called ``Brain-Diffuser''. In the first stage,\nstarting from fMRI signals, we reconstruct images that capture low-level\nproperties and overall layout using a VDVAE (Very Deep Variational Autoencoder)\nmodel. In the second stage, we use the image-to-image framework of a latent\ndiffusion model (Versatile Diffusion) conditioned on predicted multimodal (text\nand visual) features, to generate final reconstructed images. On the publicly\navailable Natural Scenes Dataset benchmark, our method outperforms previous\nmodels both qualitatively and quantitatively. When applied to synthetic fMRI\npatterns generated from individual ROI (region-of-interest) masks, our trained\nmodel creates compelling ``ROI-optimal'' scenes consistent with neuroscientific\nknowledge. Thus, the proposed methodology can have an impact on both applied\n(e.g. brain-computer interface) and fundamental neuroscience.\n","authors":["Furkan Ozcelik","Rufin VanRullen"],"pdf_url":"https://arxiv.org/pdf/2303.05334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02234v2","updated":"2023-03-09T15:14:33Z","published":"2023-03-03T21:55:04Z","title":"Hindsight States: Blending Sim and Real Task Elements for Efficient\n  Reinforcement Learning","summary":"  Reinforcement learning has shown great potential in solving complex tasks\nwhen large amounts of data can be generated with little effort. In robotics,\none approach to generate training data builds on simulations based on dynamics\nmodels derived from first principles. However, for tasks that, for instance,\ninvolve complex soft robots, devising such models is substantially more\nchallenging. Being able to train effectively in increasingly complicated\nscenarios with reinforcement learning enables to take advantage of complex\nsystems such as soft robots. Here, we leverage the imbalance in complexity of\nthe dynamics to learn more sample-efficiently. We (i) abstract the task into\ndistinct components, (ii) off-load the simple dynamics parts into the\nsimulation, and (iii) multiply these virtual parts to generate more data in\nhindsight. Our new method, Hindsight States (HiS), uses this data and selects\nthe most useful transitions for training. It can be used with an arbitrary\noff-policy algorithm. We validate our method on several challenging simulated\ntasks and demonstrate that it improves learning both alone and when combined\nwith an existing hindsight algorithm, Hindsight Experience Replay (HER).\nFinally, we evaluate HiS on a physical system and show that it boosts\nperformance on a complex table tennis task with a muscular robot. Videos and\ncode of the experiments can be found on webdav.tuebingen.mpg.de/his/.\n","authors":["Simon Guist","Jan Schneider","Alexander Dittrich","Vincent Berenz","Bernhard Schölkopf","Dieter Büchler"],"pdf_url":"https://arxiv.org/pdf/2303.02234v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05307v1","updated":"2023-03-09T14:57:15Z","published":"2023-03-09T14:57:15Z","title":"Learning Strategic Value and Cooperation in Multi-Player Stochastic\n  Games through Side Payments","summary":"  For general-sum, n-player, strategic games with transferable utility, the\nHarsanyi-Shapley value provides a computable method to both 1) quantify the\nstrategic value of a player; and 2) make cooperation rational through side\npayments. We give a simple formula to compute the HS value in normal-form\ngames. Next, we provide two methods to generalize the HS values to stochastic\n(or Markov) games, and show that one of them may be computed using generalized\nQ-learning algorithms. Finally, an empirical validation is performed on\nstochastic grid-games with three or more players. Source code is provided to\ncompute HS values for both the normal-form and stochastic game setting.\n","authors":["Alan Kuhnle","Jeffrey Richley","Darleen Perez-Lavin"],"pdf_url":"https://arxiv.org/pdf/2303.05307v1.pdf","comment":"8 pages in main work, 6 figures, ICML submission"},{"id":"http://arxiv.org/abs/2303.05288v1","updated":"2023-03-09T14:32:11Z","published":"2023-03-09T14:32:11Z","title":"Knowledge-augmented Risk Assessment (KaRA): a hybrid-intelligence\n  framework for supporting knowledge-intensive risk assessment of prospect\n  candidates","summary":"  Evaluating the potential of a prospective candidate is a common task in\nmultiple decision-making processes in different industries. We refer to a\nprospect as something or someone that could potentially produce positive\nresults in a given context, e.g., an area where an oil company could find oil,\na compound that, when synthesized, results in a material with required\nproperties, and so on. In many contexts, assessing the Probability of Success\n(PoS) of prospects heavily depends on experts' knowledge, often leading to\nbiased and inconsistent assessments. We have developed the framework named KARA\n(Knowledge-augmented Risk Assessment) to address these issues. It combines\nmultiple AI techniques that consider SMEs (Subject Matter Experts) feedback on\ntop of a structured domain knowledge-base to support risk assessment processes\nof prospect candidates in knowledge-intensive contexts.\n","authors":["Carlos Raoni Mendes","Emilio Vital Brazil","Vinicius Segura","Renato Cerqueira"],"pdf_url":"https://arxiv.org/pdf/2303.05288v1.pdf","comment":"Published at 2nd Annual AAAI Workshop on AI to Accelerate Science and\n  Engineering (AI2ASE)\n  https://ai-2-ase.github.io/papers/17%5cSubmission%5cKaRA_AI2ASE_Workshop-3.pdf.\n  arXiv admin note: text overlap with arXiv:2211.04257"},{"id":"http://arxiv.org/abs/2303.00286v2","updated":"2023-03-09T13:48:12Z","published":"2023-03-01T07:25:28Z","title":"Enhancing Knowledge Graph Embedding Models with Semantic-driven Loss\n  Functions","summary":"  Knowledge graph embedding models (KGEMs) are used for various tasks related\nto knowledge graphs (KGs), including link prediction. They are trained with\nloss functions that are computed considering a batch of scored triples and\ntheir corresponding labels. Traditional approaches consider the label of a\ntriple to be either true or false. However, recent works suggest that all\nnegative triples should not be valued equally. In line with this recent\nassumption, we posit that semantically valid negative triples might be\nhigh-quality negative triples. As such, loss functions should treat them\ndifferently from semantically invalid negative ones. To this aim, we propose\nsemantic-driven versions for the three main loss functions for link prediction.\nIn particular, we treat the scores of negative triples differently by injecting\nbackground knowledge about relation domains and ranges into the loss functions.\nIn an extensive and controlled experimental setting, we show that the proposed\nloss functions systematically provide satisfying results on three public\nbenchmark KGs underpinned with different schemas, which demonstrates both the\ngenerality and superiority of our proposed approach. In fact, the proposed loss\nfunctions do (1) lead to better MRR and Hits@$10$ values, (2) drive KGEMs\ntowards better semantic awareness. This highlights that semantic information\nglobally improves KGEMs, and thus should be incorporated into loss functions.\nDomains and ranges of relations being largely available in schema-defined KGs,\nthis makes our approach both beneficial and widely usable in practice.\n","authors":["Nicolas Hubert","Pierre Monnin","Armelle Brun","Davy Monticolo"],"pdf_url":"https://arxiv.org/pdf/2303.00286v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05246v1","updated":"2023-03-09T13:33:36Z","published":"2023-03-09T13:33:36Z","title":"Efficient Certified Training and Robustness Verification of Neural ODEs","summary":"  Neural Ordinary Differential Equations (NODEs) are a novel neural\narchitecture, built around initial value problems with learned dynamics which\nare solved during inference. Thought to be inherently more robust against\nadversarial perturbations, they were recently shown to be vulnerable to strong\nadversarial attacks, highlighting the need for formal guarantees. However,\ndespite significant progress in robustness verification for standard\nfeed-forward architectures, the verification of high dimensional NODEs remains\nan open problem. In this work, we address this challenge and propose GAINS, an\nanalysis framework for NODEs combining three key ideas: (i) a novel class of\nODE solvers, based on variable but discrete time steps, (ii) an efficient graph\nrepresentation of solver trajectories, and (iii) a novel abstraction algorithm\noperating on this graph representation. Together, these advances enable the\nefficient analysis and certified training of high-dimensional NODEs, by\nreducing the runtime from an intractable $O(\\exp(d)+\\exp(T))$ to ${O}(d+T^2\n\\log^2T)$ in the dimensionality $d$ and integration time $T$. In an extensive\nevaluation on computer vision (MNIST and FMNIST) and time-series forecasting\n(PHYSIO-NET) problems, we demonstrate the effectiveness of both our certified\ntraining and verification methods.\n","authors":["Mustafa Zeqiri","Mark Niklas Müller","Marc Fischer","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2303.05246v1.pdf","comment":"Accepted at ICLR23"},{"id":"http://arxiv.org/abs/2205.01992v3","updated":"2023-03-09T13:26:35Z","published":"2022-05-04T11:00:26Z","title":"Wild Patterns Reloaded: A Survey of Machine Learning Security against\n  Training Data Poisoning","summary":"  The success of machine learning is fueled by the increasing availability of\ncomputing power and large training datasets. The training data is used to learn\nnew models or update existing ones, assuming that it is sufficiently\nrepresentative of the data that will be encountered at test time. This\nassumption is challenged by the threat of poisoning, an attack that manipulates\nthe training data to compromise the model's performance at test time. Although\npoisoning has been acknowledged as a relevant threat in industry applications,\nand a variety of different attacks and defenses have been proposed so far, a\ncomplete systematization and critical review of the field is still missing. In\nthis survey, we provide a comprehensive systematization of poisoning attacks\nand defenses in machine learning, reviewing more than 100 papers published in\nthe field in the last 15 years. We start by categorizing the current threat\nmodels and attacks, and then organize existing defenses accordingly. While we\nfocus mostly on computer-vision applications, we argue that our systematization\nalso encompasses state-of-the-art attacks and defenses for other data\nmodalities. Finally, we discuss existing resources for research in poisoning,\nand shed light on the current limitations and open research questions in this\nresearch field.\n","authors":["Antonio Emanuele Cinà","Kathrin Grosse","Ambra Demontis","Sebastiano Vascon","Werner Zellinger","Bernhard A. Moser","Alina Oprea","Battista Biggio","Marcello Pelillo","Fabio Roli"],"pdf_url":"https://arxiv.org/pdf/2205.01992v3.pdf","comment":"35 pages, Accepted at ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2210.01620v2","updated":"2023-03-09T13:24:17Z","published":"2022-10-04T14:02:51Z","title":"SAM as an Optimal Relaxation of Bayes","summary":"  Sharpness-aware minimization (SAM) and related adversarial deep-learning\nmethods can drastically improve generalization, but their underlying mechanisms\nare not yet fully understood. Here, we establish SAM as a relaxation of the\nBayes objective where the expected negative-loss is replaced by the optimal\nconvex lower bound, obtained by using the so-called Fenchel biconjugate. The\nconnection enables a new Adam-like extension of SAM to automatically obtain\nreasonable uncertainty estimates, while sometimes also improving its accuracy.\nBy connecting adversarial and Bayesian methods, our work opens a new path to\nrobustness.\n","authors":["Thomas Möllenhoff","Mohammad Emtiyaz Khan"],"pdf_url":"https://arxiv.org/pdf/2210.01620v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.05231v1","updated":"2023-03-09T13:13:43Z","published":"2023-03-09T13:13:43Z","title":"Structure-Aware Group Discrimination with Adaptive-View Graph Encoder: A\n  Fast Graph Contrastive Learning Framework","summary":"  Albeit having gained significant progress lately, large-scale graph\nrepresentation learning remains expensive to train and deploy for two main\nreasons: (i) the repetitive computation of multi-hop message passing and\nnon-linearity in graph neural networks (GNNs); (ii) the computational cost of\ncomplex pairwise contrastive learning loss. Two main contributions are made in\nthis paper targeting this twofold challenge: we first propose an adaptive-view\ngraph neural encoder (AVGE) with a limited number of message passing to\naccelerate the forward pass computation, and then we propose a structure-aware\ngroup discrimination (SAGD) loss in our framework which avoids inefficient\npairwise loss computing in most common GCL and improves the performance of the\nsimple group discrimination. By the framework proposed, we manage to bring down\nthe training and inference cost on various large-scale datasets by a\nsignificant margin (250x faster inference time) without loss of the\ndownstream-task performance.\n","authors":["Zhenshuo Zhang","Yun Zhu","Haizhou Shi","Siliang Tang"],"pdf_url":"https://arxiv.org/pdf/2303.05231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05214v1","updated":"2023-03-09T12:37:33Z","published":"2023-03-09T12:37:33Z","title":"Taming Contrast Maximization for Learning Sequential, Low-latency,\n  Event-based Optical Flow","summary":"  Event cameras have recently gained significant traction since they open up\nnew avenues for low-latency and low-power solutions to complex computer vision\nproblems. To unlock these solutions, it is necessary to develop algorithms that\ncan leverage the unique nature of event data. However, the current\nstate-of-the-art is still highly influenced by the frame-based literature, and\nusually fails to deliver on these promises. In this work, we take this into\nconsideration and propose a novel self-supervised learning pipeline for the\nsequential estimation of event-based optical flow that allows for the scaling\nof the models to high inference frequencies. At its core, we have a\ncontinuously-running stateful neural model that is trained using a novel\nformulation of contrast maximization that makes it robust to nonlinearities and\nvarying statistics in the input events. Results across multiple datasets\nconfirm the effectiveness of our method, which establishes a new state of the\nart in terms of accuracy for approaches trained or optimized without ground\ntruth.\n","authors":["Federico Paredes-Vallés","Kirk Y. W. Scheper","Christophe De Wagter","Guido C. H. E. de Croon"],"pdf_url":"https://arxiv.org/pdf/2303.05214v1.pdf","comment":"15 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2303.05205v1","updated":"2023-03-09T12:19:20Z","published":"2023-03-09T12:19:20Z","title":"Real-time scheduling of renewable power systems through planning-based\n  reinforcement learning","summary":"  The growing renewable energy sources have posed significant challenges to\ntraditional power scheduling. It is difficult for operators to obtain accurate\nday-ahead forecasts of renewable generation, thereby requiring the future\nscheduling system to make real-time scheduling decisions aligning with\nultra-short-term forecasts. Restricted by the computation speed, traditional\noptimization-based methods can not solve this problem. Recent developments in\nreinforcement learning (RL) have demonstrated the potential to solve this\nchallenge. However, the existing RL methods are inadequate in terms of\nconstraint complexity, algorithm performance, and environment fidelity. We are\nthe first to propose a systematic solution based on the state-of-the-art\nreinforcement learning algorithm and the real power grid environment. The\nproposed approach enables planning and finer time resolution adjustments of\npower generators, including unit commitment and economic dispatch, thus\nincreasing the grid's ability to admit more renewable energy. The well-trained\nscheduling agent significantly reduces renewable curtailment and load shedding,\nwhich are issues arising from traditional scheduling's reliance on inaccurate\nday-ahead forecasts. High-frequency control decisions exploit the existing\nunits' flexibility, reducing the power grid's dependence on hardware\ntransformations and saving investment and operating costs, as demonstrated in\nexperimental results. This research exhibits the potential of reinforcement\nlearning in promoting low-carbon and intelligent power systems and represents a\nsolid step toward sustainable electricity generation.\n","authors":["Shaohuai Liu","Jinbo Liu","Weirui Ye","Nan Yang","Guanglun Zhang","Haiwang Zhong","Chongqing Kang","Qirong Jiang","Xuri Song","Fangchun Di","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2303.05205v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.05203v1","updated":"2023-03-09T12:13:39Z","published":"2023-03-09T12:13:39Z","title":"RMMDet: Road-Side Multitype and Multigroup Sensor Detection System for\n  Autonomous Driving","summary":"  Autonomous driving has now made great strides thanks to artificial\nintelligence, and numerous advanced methods have been proposed for vehicle end\ntarget detection, including single sensor or multi sensor detection methods.\nHowever, the complexity and diversity of real traffic situations necessitate an\nexamination of how to use these methods in real road conditions. In this paper,\nwe propose RMMDet, a road-side multitype and multigroup sensor detection system\nfor autonomous driving. We use a ROS-based virtual environment to simulate\nreal-world conditions, in particular the physical and functional construction\nof the sensors. Then we implement muti-type sensor detection and multi-group\nsensors fusion in this environment, including camera-radar and camera-lidar\ndetection based on result-level fusion. We produce local datasets and real sand\ntable field, and conduct various experiments. Furthermore, we link a\nmulti-agent collaborative scheduling system to the fusion detection system.\nHence, the whole roadside detection system is formed by roadside perception,\nfusion detection, and scheduling planning. Through the experiments, it can be\nseen that RMMDet system we built plays an important role in vehicle-road\ncollaboration and its optimization. The code and supplementary materials can be\nfound at: https://github.com/OrangeSodahub/RMMDet\n","authors":["Xiuyu Yang","Zhuangyan Zhang","Haikuo Du","Sui Yang","Fengping Sun","Yanbo Liu","Ling Pei","Wenchao Xu","Weiqi Sun","Zhengyu Li"],"pdf_url":"https://arxiv.org/pdf/2303.05203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05197v1","updated":"2023-03-09T11:52:52Z","published":"2023-03-09T11:52:52Z","title":"Mastering Strategy Card Game (Hearthstone) with Improved Techniques","summary":"  Strategy card game is a well-known genre that is demanding on the intelligent\ngame-play and can be an ideal test-bench for AI. Previous work combines an\nend-to-end policy function and an optimistic smooth fictitious play, which\nshows promising performances on the strategy card game Legend of Code and\nMagic. In this work, we apply such algorithms to Hearthstone, a famous\ncommercial game that is more complicated in game rules and mechanisms. We\nfurther propose several improved techniques and consequently achieve\nsignificant progress. For a machine-vs-human test we invite a Hearthstone\nstreamer whose best rank was top 10 of the official league in China region that\nis estimated to be of millions of players. Our models defeat the human player\nin all Best-of-5 tournaments of full games (including both deck building and\nbattle), showing a strong capability of decision making.\n","authors":["Changnan Xiao","Yongxin Zhang","Xuefeng Huang","Qinhan Huang","Jie Chen","Peng Sun"],"pdf_url":"https://arxiv.org/pdf/2303.05197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05193v1","updated":"2023-03-09T11:45:48Z","published":"2023-03-09T11:45:48Z","title":"GOATS: Goal Sampling Adaptation for Scooping with Curriculum\n  Reinforcement Learning","summary":"  In this work, we first formulate the problem of goal-conditioned robotic\nwater scooping with reinforcement learning. This task is challenging due to the\ncomplex dynamics of fluid and multi-modal goal-reaching. The policy is required\nto achieve both position goals and water amount goals, which leads to a large\nconvoluted goal state space. To address these challenges, we introduce Goal\nSampling Adaptation for Scooping (GOATS), a curriculum reinforcement learning\nmethod that can learn an effective and generalizable policy for robot scooping\ntasks. Specifically, we use a goal-factorized reward formulation and\ninterpolate position goal distributions and amount goal distributions to create\ncurriculum through the learning process. As a result, our proposed method can\noutperform the baselines in simulation and achieves 5.46% and 8.71% amount\nerrors on bowl scooping and bucket scooping tasks, respectively, under 1000\nvariations of initial water states in the tank and a large goal state space.\nBesides being effective in simulation environments, our method can efficiently\ngeneralize to noisy real-robot water-scooping scenarios with different physical\nconfigurations and unseen settings, demonstrating superior efficacy and\ngeneralizability. The videos of this work are available on our project page:\nhttps://sites.google.com/view/goatscooping.\n","authors":["Yaru Niu","Shiyu Jin","Zeqing Zhang","Jiacheng Zhu","Ding Zhao","Liangjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05186v1","updated":"2023-03-09T11:30:40Z","published":"2023-03-09T11:30:40Z","title":"A Framework for History-Aware Hyperparameter Optimisation in\n  Reinforcement Learning","summary":"  A Reinforcement Learning (RL) system depends on a set of initial conditions\n(hyperparameters) that affect the system's performance. However, defining a\ngood choice of hyperparameters is a challenging problem.\n  Hyperparameter tuning often requires manual or automated searches to find\noptimal values. Nonetheless, a noticeable limitation is the high cost of\nalgorithm evaluation for complex models, making the tuning process\ncomputationally expensive and time-consuming.\n  In this paper, we propose a framework based on integrating complex event\nprocessing and temporal models, to alleviate these trade-offs. Through this\ncombination, it is possible to gain insights about a running RL system\nefficiently and unobtrusively based on data stream monitoring and to create\nabstract representations that allow reasoning about the historical behaviour of\nthe RL system. The obtained knowledge is exploited to provide feedback to the\nRL system for optimising its hyperparameters while making effective use of\nparallel resources.\n  We introduce a novel history-aware epsilon-greedy logic for hyperparameter\noptimisation that instead of using static hyperparameters that are kept fixed\nfor the whole training, adjusts the hyperparameters at runtime based on the\nanalysis of the agent's performance over time windows in a single agent's\nlifetime. We tested the proposed approach in a 5G mobile communications case\nstudy that uses DQN, a variant of RL, for its decision-making. Our experiments\ndemonstrated the effects of hyperparameter tuning using history on training\nstability and reward values. The encouraging results show that the proposed\nhistory-aware framework significantly improved performance compared to\ntraditional hyperparameter tuning approaches.\n","authors":["Juan Marcelo Parra-Ullauri","Chen Zhen","Antonio García-Domínguez","Nelly Bencomo","Changgang Zheng","Juan Boubeta-Puig","Guadalupe Ortiz","Shufan Yang"],"pdf_url":"https://arxiv.org/pdf/2303.05186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05180v1","updated":"2023-03-09T11:19:42Z","published":"2023-03-09T11:19:42Z","title":"Classification in Histopathology: A unique deep embeddings extractor for\n  multiple classification tasks","summary":"  In biomedical imaging, deep learning-based methods are state-of-the-art for\nevery modality (virtual slides, MRI, etc.) In histopathology, these methods can\nbe used to detect certain biomarkers or classify lesions. However, such\ntechniques require large amounts of data to train high-performing models which\ncan be intrinsically difficult to acquire, especially when it comes to scarce\nbiomarkers. To address this challenge, we use a single, pre-trained, deep\nembeddings extractor to convert images into deep features and train small,\ndedicated classification head on these embeddings for each classification task.\nThis approach offers several benefits such as the ability to reuse a single\npre-trained deep network for various tasks; reducing the amount of labeled data\nneeded as classification heads have fewer parameters; and accelerating training\ntime by up to 1000 times, which allows for much more tuning of the\nclassification head. In this work, we perform an extensive comparison of\nvarious open-source backbones and assess their fit to the target histological\nimage domain. This is achieved using a novel method based on a proxy\nclassification task. We demonstrate that thanks to this selection method, an\noptimal feature extractor can be selected for different tasks on the target\ndomain. We also introduce a feature space augmentation strategy which proves to\nsubstantially improve the final metrics computed for the different tasks\nconsidered. To demonstrate the benefit of such backbone selection and\nfeature-space augmentation, our experiments are carried out on three separate\nclassification tasks and show a clear improvement on each of them:\nmicrocalcifications (29.1% F1-score increase), lymph nodes metastasis (12.5%\nF1-score increase), mitosis (15.0% F1-score increase).\n","authors":["Adrien Nivaggioli","Nicolas Pozin","Rémy Peyret","Stéphane Sockeel","Marie Sockeel","Nicolas Nerrienet","Marceau Clavel","Clara Simmat","Catherine Miquel"],"pdf_url":"https://arxiv.org/pdf/2303.05180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04238v2","updated":"2023-03-09T11:14:06Z","published":"2023-03-07T21:03:48Z","title":"Patch of Invisibility: Naturalistic Black-Box Adversarial Attacks on\n  Object Detectors","summary":"  Adversarial attacks on deep-learning models have been receiving increased\nattention in recent years. Work in this area has mostly focused on\ngradient-based techniques, so-called white-box attacks, wherein the attacker\nhas access to the targeted model's internal parameters; such an assumption is\nusually unrealistic in the real world. Some attacks additionally use the entire\npixel space to fool a given model, which is neither practical nor physical\n(i.e., real-world). On the contrary, we propose herein a gradient-free method\nthat uses the learned image manifold of a pretrained generative adversarial\nnetwork (GAN) to generate naturalistic physical adversarial patches for object\ndetectors. We show that our proposed method works both digitally and\nphysically.\n","authors":["Raz Lapid","Moshe Sipper"],"pdf_url":"https://arxiv.org/pdf/2303.04238v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.14233v2","updated":"2023-03-09T10:56:28Z","published":"2021-09-29T07:14:22Z","title":"A Next Basket Recommendation Reality Check","summary":"  The goal of a next basket recommendation (NBR) system is to recommend items\nfor the next basket for a user, based on the sequence of their prior baskets.\nRecently, a number of methods with complex modules have been proposed that\nclaim state-of-the-art performance. They rarely look into the predicted basket\nand just provide intuitive reasons for the observed improvements, e.g., better\nrepresentation, capturing intentions or relations, etc. We provide a novel\nangle on the evaluation of next basket recommendation methods, centered on the\ndistinction between repetition and exploration: the next basket is typically\ncomposed of previously consumed items (i.e., repeat items) and new items (i.e,\nexplore items). We propose a set of metrics that measure the repeat/explore\nratio and performance of NBR models. Using these new metrics, we analyze\nstate-of-the-art NBR models. The results of our analysis help to clarify the\nextent of the actual progress achieved by existing NBR methods as well as the\nunderlying reasons for the improvements. Overall, our work sheds light on the\nevaluation problem of NBR and provides useful insights into the model design\nfor this task.\n","authors":["Ming Li","Sami Jullien","Mozhdeh Ariannezhad","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2109.14233v2.pdf","comment":"This paper has been accepted to ACM TOIS"},{"id":"http://arxiv.org/abs/2201.05818v4","updated":"2023-03-09T10:24:02Z","published":"2022-01-15T10:04:05Z","title":"Measuring Non-Probabilistic Uncertainty","summary":"  There are two reasons why uncertainty about the future yield of investments\nmay not be adequately described by Probability Theory. The first one is due to\nunique or nearly-unique events, that either never realized or occurred too\nseldom for probabilities to be reliable. The second one arises when when one\nfears that something may happen, that one is not even able to figure out, e.g.,\nif one asks: \"Climate change, financial crises, pandemic, war, what next?\"\n  In both cases, simple one-to-one causal mappings between available\nalternatives and possible consequences eventually melt down. However, such\ndestructions reflect into the changing narratives of business executives,\nemployees and other stakeholders in specific, identifiable and differential\nways. In particular, texts such as consultants' reports or letters to\nshareholders can be analysed in order to detect the impact of both sorts of\nuncertainty onto the causal relations that normally guide decision-making.\n  We propose structural measures of causal mappings as a means to measure\nnon-probabilistic uncertainty, eventually suggesting that automated text\nanalysis can greatly augment the possibilities offered by these techniques.\nProspective applications may concern statistical institutes, stock market\ntraders, as well as businesses wishing to compare their own vision to those\nprevailing in their industry.\n","authors":["Florian Ellsaesser","Guido Fioretti","Gail E. James"],"pdf_url":"https://arxiv.org/pdf/2201.05818v4.pdf","comment":"22 pages, 15 figures"},{"id":"http://arxiv.org/abs/2303.05155v1","updated":"2023-03-09T10:15:03Z","published":"2023-03-09T10:15:03Z","title":"Aux-Drop: Handling Haphazard Inputs in Online Learning Using Auxiliary\n  Dropouts","summary":"  Many real-world applications based on online learning produce streaming data\nthat is haphazard in nature, i.e., contains missing features, features becoming\nobsolete in time, the appearance of new features at later points in time and a\nlack of clarity on the total number of input features. These challenges make it\nhard to build a learnable system for such applications, and almost no work\nexists in deep learning that addresses this issue. In this paper, we present\nAux-Drop, an auxiliary dropout regularization strategy for online learning that\nhandles the haphazard input features in an effective manner. Aux-Drop adapts\nthe conventional dropout regularization scheme for the haphazard input feature\nspace ensuring that the final output is minimally impacted by the chaotic\nappearance of such features. It helps to prevent the co-adaptation of\nespecially the auxiliary and base features, as well as reduces the strong\ndependence of the output on any of the auxiliary inputs of the model. This\nhelps in better learning for scenarios where certain features disappear in time\nor when new features are to be modeled. The efficacy of Aux-Drop has been\ndemonstrated through extensive numerical experiments on SOTA benchmarking\ndatasets that include Italy Power Demand, HIGGS, SUSY and multiple UCI\ndatasets.\n","authors":["Rohit Agarwal","Deepak Gupta","Alexander Horsch","Dilip K. Prasad"],"pdf_url":"https://arxiv.org/pdf/2303.05155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05153v1","updated":"2023-03-09T10:12:18Z","published":"2023-03-09T10:12:18Z","title":"Can a Frozen Pretrained Language Model be used for Zero-shot Neural\n  Retrieval on Entity-centric Questions?","summary":"  Neural document retrievers, including dense passage retrieval (DPR), have\noutperformed classical lexical-matching retrievers, such as BM25, when\nfine-tuned and tested on specific question-answering datasets. However, it has\nbeen shown that the existing dense retrievers do not generalize well not only\nout of domain but even in domain such as Wikipedia, especially when a named\nentity in a question is a dominant clue for retrieval. In this paper, we\npropose an approach toward in-domain generalization using the embeddings\ngenerated by the frozen language model trained with the entities in the domain.\nBy not fine-tuning, we explore the possibility that the rich knowledge\ncontained in a pretrained language model can be used for retrieval tasks. The\nproposed method outperforms conventional DPRs on entity-centric questions in\nWikipedia domain and achieves almost comparable performance to BM25 and\nstate-of-the-art SPAR model. We also show that the contextualized keys lead to\nstrong improvements compared to BM25 when the entity names consist of common\nwords. Our results demonstrate the feasibility of the zero-shot retrieval\nmethod for entity-centric questions of Wikipedia domain, where DPR has\nstruggled to perform.\n","authors":["Yasuto Hoshi","Daisuke Miyashita","Yasuhiro Morioka","Youyang Ng","Osamu Torii","Jun Deguchi"],"pdf_url":"https://arxiv.org/pdf/2303.05153v1.pdf","comment":"Accepted to Workshop on Knowledge Augmented Methods for Natural\n  Language Processing, in conjunction with AAAI 2023"},{"id":"http://arxiv.org/abs/2303.05151v1","updated":"2023-03-09T10:08:34Z","published":"2023-03-09T10:08:34Z","title":"Provable Data Subset Selection For Efficient Neural Network Training","summary":"  Radial basis function neural networks (\\emph{RBFNN}) are {well-known} for\ntheir capability to approximate any continuous function on a closed bounded set\nwith arbitrary precision given enough hidden neurons. In this paper, we\nintroduce the first algorithm to construct coresets for \\emph{RBFNNs}, i.e.,\nsmall weighted subsets that approximate the loss of the input data on any\nradial basis function network and thus approximate any function defined by an\n\\emph{RBFNN} on the larger input data. In particular, we construct coresets for\nradial basis and Laplacian loss functions. We then use our coresets to obtain a\nprovable data subset selection algorithm for training deep neural networks.\nSince our coresets approximate every function, they also approximate the\ngradient of each weight in a neural network, which is a particular function on\nthe input. We then perform empirical evaluations on function approximation and\ndataset subset selection on popular network architectures and data sets,\ndemonstrating the efficacy and accuracy of our coreset construction.\n","authors":["Murad Tukan","Samson Zhou","Alaa Maalouf","Daniela Rus","Vladimir Braverman","Dan Feldman"],"pdf_url":"https://arxiv.org/pdf/2303.05151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13510v2","updated":"2023-03-09T10:08:19Z","published":"2023-01-31T09:54:20Z","title":"3D Former: Monocular Scene Reconstruction with 3D SDF Transformers","summary":"  Monocular scene reconstruction from posed images is challenging due to the\ncomplexity of a large environment. Recent volumetric methods learn to directly\npredict the TSDF volume and have demonstrated promising results in this task.\nHowever, most methods focus on how to extract and fuse the 2D features to a 3D\nfeature volume, but none of them improve the way how the 3D volume is\naggregated. In this work, we propose an SDF transformer network, which replaces\nthe role of 3D CNN for better 3D feature aggregation. To reduce the explosive\ncomputation complexity of the 3D multi-head attention, we propose a sparse\nwindow attention module, where the attention is only calculated between the\nnon-empty voxels within a local window. Then a top-down-bottom-up 3D attention\nnetwork is built for 3D feature aggregation, where a dilate-attention structure\nis proposed to prevent geometry degeneration, and two global modules are\nemployed to equip with global receptive fields. The experiments on multiple\ndatasets show that this 3D transformer network generates a more accurate and\ncomplete reconstruction, which outperforms previous methods by a large margin.\nRemarkably, the mesh accuracy is improved by 41.8%, and the mesh completeness\nis improved by 25.3% on the ScanNet dataset. Project page:\nhttps://weihaosky.github.io/sdfformer.\n","authors":["Weihao Yuan","Xiaodong Gu","Heng Li","Zilong Dong","Siyu Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.13510v2.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2112.03073v2","updated":"2023-03-09T09:22:29Z","published":"2021-11-26T07:58:11Z","title":"Active Learning for Event Extraction with Memory-based Loss Prediction\n  Model","summary":"  Event extraction (EE) plays an important role in many industrial application\nscenarios, and high-quality EE methods require a large amount of manual\nannotation data to train supervised learning models. However, the cost of\nobtaining annotation data is very high, especially for annotation of domain\nevents, which requires the participation of experts from corresponding domain.\nSo we introduce active learning (AL) technology to reduce the cost of event\nannotation. But the existing AL methods have two main problems, which make them\nnot well used for event extraction. Firstly, the existing pool-based selection\nstrategies have limitations in terms of computational cost and sample validity.\nSecondly, the existing evaluation of sample importance lacks the use of local\nsample information. In this paper, we present a novel deep AL method for EE. We\npropose a batch-based selection strategy and a Memory-Based Loss Prediction\nmodel (MBLP) to select unlabeled samples efficiently. During the selection\nprocess, we use an internal-external sample loss ranking method to evaluate the\nsample importance by using local information. Finally, we propose a delayed\ntraining strategy to train the MBLP model. Extensive experiments are performed\non three domain datasets, and our method outperforms other state-of-the-art\nmethods.\n","authors":["Shirong Shen","Zhen Li","Guilin Qi"],"pdf_url":"https://arxiv.org/pdf/2112.03073v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07126v2","updated":"2023-03-09T09:17:25Z","published":"2022-10-13T16:06:59Z","title":"Challenges in Explanation Quality Evaluation","summary":"  While much research focused on producing explanations, it is still unclear\nhow the produced explanations' quality can be evaluated in a meaningful way.\nToday's predominant approach is to quantify explanations using proxy scores\nwhich compare explanations to (human-annotated) gold explanations. This\napproach assumes that explanations which reach higher proxy scores will also\nprovide a greater benefit to human users. In this paper, we present problems of\nthis approach. Concretely, we (i) formulate desired characteristics of\nexplanation quality, (ii) describe how current evaluation practices violate\nthem, and (iii) support our argumentation with initial evidence from a\ncrowdsourcing case study in which we investigate the explanation quality of\nstate-of-the-art explainable question answering systems. We find that proxy\nscores correlate poorly with human quality ratings and, additionally, become\nless expressive the more often they are used (i.e. following Goodhart's law).\nFinally, we propose guidelines to enable a meaningful evaluation of\nexplanations to drive the development of systems that provide tangible benefits\nto human users.\n","authors":["Hendrik Schuff","Heike Adel","Peng Qi","Ngoc Thang Vu"],"pdf_url":"https://arxiv.org/pdf/2210.07126v2.pdf","comment":"41 pages, 11 figures"},{"id":"http://arxiv.org/abs/2303.05118v1","updated":"2023-03-09T08:57:01Z","published":"2023-03-09T08:57:01Z","title":"SLCA: Slow Learner with Classifier Alignment for Continual Learning on a\n  Pre-trained Model","summary":"  The goal of continual learning is to improve the performance of recognition\nmodels in learning sequentially arrived data. Although most existing works are\nestablished on the premise of learning from scratch, growing efforts have been\ndevoted to incorporating the benefits of pre-training. However, how to\nadaptively exploit the pre-trained knowledge for each incremental task while\nmaintaining its generalizability remains an open question. In this work, we\npresent an extensive analysis for continual learning on a pre-trained model\n(CLPM), and attribute the key challenge to a progressive overfitting problem.\nObserving that selectively reducing the learning rate can almost resolve this\nissue in the representation layer, we propose a simple but extremely effective\napproach named Slow Learner with Classifier Alignment (SLCA), which further\nimproves the classification layer by modeling the class-wise distributions and\naligning the classification layers in a post-hoc fashion. Across a variety of\nscenarios, our proposal provides substantial improvements for CLPM (e.g., up to\n49.76%, 50.05%, 44.69% and 40.16% on Split CIFAR-100, Split ImageNet-R, Split\nCUB-200 and Split Cars-196, respectively), and thus outperforms\nstate-of-the-art approaches by a large margin. Based on such a strong baseline,\ncritical factors and promising directions are analyzed in-depth to facilitate\nsubsequent research.\n","authors":["Gengwei Zhang","Liyuan Wang","Guoliang Kang","Ling Chen","Yunchao Wei"],"pdf_url":"https://arxiv.org/pdf/2303.05118v1.pdf","comment":"Tech report. 11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2209.15137v3","updated":"2023-03-09T07:47:11Z","published":"2022-09-29T23:40:38Z","title":"Generalizable machine learning for stress monitoring from wearable\n  devices: A systematic literature review","summary":"  Introduction. The stress response has both subjective, psychological and\nobjectively measurable, biological components. Both of them can be expressed\ndifferently from person to person, complicating the development of a generic\nstress measurement model. This is further compounded by the lack of large,\nlabeled datasets that can be utilized to build machine learning models for\naccurately detecting periods and levels of stress. The aim of this review is to\nprovide an overview of the current state of stress detection and monitoring\nusing wearable devices, and where applicable, machine learning techniques\nutilized.\n  Methods. This study reviewed published works contributing and/or using\ndatasets designed for detecting stress and their associated machine learning\nmethods, with a systematic review and meta-analysis of those that utilized\nwearable sensor data as stress biomarkers. The electronic databases of Google\nScholar, Crossref, DOAJ and PubMed were searched for relevant articles and a\ntotal of 24 articles were identified and included in the final analysis. The\nreviewed works were synthesized into three categories of publicly available\nstress datasets, machine learning, and future research directions.\n  Results. A wide variety of study-specific test and measurement protocols were\nnoted in the literature. A number of public datasets were identified that are\nlabeled for stress detection. In addition, we discuss that previous works show\nshortcomings in areas such as their labeling protocols, lack of statistical\npower, validity of stress biomarkers, and generalization ability.\n  Conclusion. Generalization of existing machine learning models still require\nfurther study, and research in this area will continue to provide improvements\nas newer and more substantial datasets become available for study.\n","authors":["Gideon Vos","Kelly Trinh","Zoltan Sarnyai","Mostafa Rahimi Azghadi"],"pdf_url":"https://arxiv.org/pdf/2209.15137v3.pdf","comment":"https://www.sciencedirect.com/science/article/pii/S1386505623000436"},{"id":"http://arxiv.org/abs/2209.13605v2","updated":"2023-03-09T07:41:44Z","published":"2022-09-27T18:00:55Z","title":"Efficient Recovery Learning using Model Predictive Meta-Reasoning","summary":"  Operating under real world conditions is challenging due to the possibility\nof a wide range of failures induced by execution errors and state uncertainty.\nIn relatively benign settings, such failures can be overcome by retrying or\nexecuting one of a small number of hand-engineered recovery strategies. By\ncontrast, contact-rich sequential manipulation tasks, like opening doors and\nassembling furniture, are not amenable to exhaustive hand-engineering. To\naddress this issue, we present a general approach for robustifying manipulation\nstrategies in a sample-efficient manner. Our approach incrementally improves\nrobustness by first discovering the failure modes of the current strategy via\nexploration in simulation and then learning additional recovery skills to\nhandle these failures. To ensure efficient learning, we propose an online\nalgorithm called Meta-Reasoning for Skill Learning (MetaReSkill) that monitors\nthe progress of all recovery policies during training and allocates training\nresources to recoveries that are likely to improve the task performance the\nmost. We use our approach to learn recovery skills for door-opening and\nevaluate them both in simulation and on a real robot with little fine-tuning.\nCompared to open-loop execution, our experiments show that even a limited\namount of recovery learning improves task success substantially from 71% to\n92.4% in simulation and from 75% to 90% on a real robot.\n","authors":["Shivam Vats","Maxim Likhachev","Oliver Kroemer"],"pdf_url":"https://arxiv.org/pdf/2209.13605v2.pdf","comment":"To appear in the International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2301.09474v2","updated":"2023-03-09T07:21:50Z","published":"2023-01-23T15:18:54Z","title":"DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained\n  Diffusion","summary":"  Real-world data generation often involves complex inter-dependencies among\ninstances, violating the IID-data hypothesis of standard learning paradigms and\nposing a challenge for uncovering the geometric structures for learning desired\ninstance representations. To this end, we introduce an energy constrained\ndiffusion model which encodes a batch of instances from a dataset into\nevolutionary states that progressively incorporate other instances' information\nby their interactions. The diffusion process is constrained by descent criteria\nw.r.t.~a principled energy function that characterizes the global consistency\nof instance representations over latent structures. We provide rigorous theory\nthat implies closed-form optimal estimates for the pairwise diffusion strength\namong arbitrary instance pairs, which gives rise to a new class of neural\nencoders, dubbed as DIFFormer (diffusion-based Transformers), with two\ninstantiations: a simple version with linear complexity for prohibitive\ninstance numbers, and an advanced version for learning complex structures.\nExperiments highlight the wide applicability of our model as a general-purpose\nencoder backbone with superior performance in various tasks, such as node\nclassification on large graphs, semi-supervised image/text classification, and\nspatial-temporal dynamics prediction.\n","authors":["Qitian Wu","Chenxiao Yang","Wentao Zhao","Yixuan He","David Wipf","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2301.09474v2.pdf","comment":"Published at ICLR 2023 as a spotlight presentation, the\n  implementation code is available at https://github.com/qitianwu/DIFFormer"},{"id":"http://arxiv.org/abs/2303.05072v1","updated":"2023-03-09T07:08:25Z","published":"2023-03-09T07:08:25Z","title":"Identification of Systematic Errors of Image Classifiers on Rare\n  Subgroups","summary":"  Despite excellent average-case performance of many image classifiers, their\nperformance can substantially deteriorate on semantically coherent subgroups of\nthe data that were under-represented in the training data. These systematic\nerrors can impact both fairness for demographic minority groups as well as\nrobustness and safety under domain shift. A major challenge is to identify such\nsubgroups with subpar performance when the subgroups are not annotated and\ntheir occurrence is very rare. We leverage recent advances in text-to-image\nmodels and search in the space of textual descriptions of subgroups (\"prompts\")\nfor subgroups where the target model has low performance on the\nprompt-conditioned synthesized data. To tackle the exponentially growing number\nof subgroups, we employ combinatorial testing. We denote this procedure as\nPromptAttack as it can be interpreted as an adversarial attack in a prompt\nspace. We study subgroup coverage and identifiability with PromptAttack in a\ncontrolled setting and find that it identifies systematic errors with high\naccuracy. Thereupon, we apply PromptAttack to ImageNet classifiers and identify\nnovel systematic errors on rare subgroups.\n","authors":["Jan Hendrik Metzen","Robin Hutmacher","N. Grace Hua","Valentyn Boreiko","Dan Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05066v1","updated":"2023-03-09T06:33:31Z","published":"2023-03-09T06:33:31Z","title":"Distortion-Disentangled Contrastive Learning","summary":"  Self-supervised learning is well known for its remarkable performance in\nrepresentation learning and various downstream computer vision tasks. Recently,\nPositive-pair-Only Contrastive Learning (POCL) has achieved reliable\nperformance without the need to construct positive-negative training sets. It\nreduces memory requirements by lessening the dependency on the batch size. The\nPOCL method typically uses a single loss function to extract the distortion\ninvariant representation (DIR) which describes the proximity of positive-pair\nrepresentations affected by different distortions. This loss function\nimplicitly enables the model to filter out or ignore the distortion variant\nrepresentation (DVR) affected by different distortions. However, existing POCL\nmethods do not explicitly enforce the disentanglement and exploitation of the\nactually valuable DVR. In addition, these POCL methods have been observed to be\nsensitive to augmentation strategies. To address these limitations, we propose\na novel POCL framework named Distortion-Disentangled Contrastive Learning\n(DDCL) and a Distortion-Disentangled Loss (DDL). Our approach is the first to\nexplicitly disentangle and exploit the DVR inside the model and feature stream\nto improve the overall representation utilization efficiency, robustness and\nrepresentation ability. Experiments carried out demonstrate the superiority of\nour framework to Barlow Twins and Simsiam in terms of convergence,\nrepresentation quality, and robustness on several benchmark datasets.\n","authors":["Jinfeng Wang","Sifan Song","Jionglong Su","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.05066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03840v2","updated":"2023-03-09T06:28:38Z","published":"2023-03-07T12:10:47Z","title":"A Challenging Benchmark for Low-Resource Learning","summary":"  With promising yet saturated results in high-resource settings, low-resource\ndatasets have gradually become popular benchmarks for evaluating the learning\nability of advanced neural networks (e.g., BigBench, superGLUE). Some models\neven surpass humans according to benchmark test results. However, we find that\nthere exists a set of hard examples in low-resource settings that challenge\nneural networks but are not well evaluated, which causes over-estimated\nperformance. We first give a theoretical analysis on which factors bring the\ndifficulty of low-resource learning. It then motivate us to propose a\nchallenging benchmark hardBench to better evaluate the learning ability, which\ncovers 11 datasets, including 3 computer vision (CV) datasets and 8 natural\nlanguage process (NLP) datasets. Experiments on a wide range of models show\nthat neural networks, even pre-trained language models, have sharp performance\ndrops on our benchmark, demonstrating the effectiveness on evaluating the\nweaknesses of neural networks. On NLP tasks, we surprisingly find that despite\nbetter results on traditional low-resource benchmarks, pre-trained networks,\ndoes not show performance improvements on our benchmarks. These results\ndemonstrate that there are still a large robustness gap between existing models\nand human-level performance.\n","authors":["Yudong Wang","Chang Ma","Qingxiu Dong","Lingpeng Kong","Jingjing Xu"],"pdf_url":"https://arxiv.org/pdf/2303.03840v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02914v2","updated":"2023-03-09T06:24:02Z","published":"2023-02-06T16:38:43Z","title":"Energy-based Out-of-Distribution Detection for Graph Neural Networks","summary":"  Learning on graphs, where instance nodes are inter-connected, has become one\nof the central problems for deep learning, as relational structures are\npervasive and induce data inter-dependence which hinders trivial adaptation of\nexisting approaches that assume inputs to be i.i.d.~sampled. However, current\nmodels mostly focus on improving testing performance of in-distribution data\nand largely ignore the potential risk w.r.t. out-of-distribution (OOD) testing\nsamples that may cause negative outcome if the prediction is overconfident on\nthem. In this paper, we investigate the under-explored problem, OOD detection\non graph-structured data, and identify a provably effective OOD discriminator\nbased on an energy function directly extracted from graph neural networks\ntrained with standard classification loss. This paves a way for a simple,\npowerful and efficient OOD detection model for GNN-based learning on graphs,\nwhich we call GNNSafe. It also has nice theoretical properties that guarantee\nan overall distinguishable margin between the detection scores for\nin-distribution and OOD samples, which, more critically, can be further\nstrengthened by a learning-free energy belief propagation scheme. For\ncomprehensive evaluation, we introduce new benchmark settings that evaluate the\nmodel for detecting OOD data from both synthetic and real distribution shifts\n(cross-domain graph shifts and temporal graph shifts). The results show that\nGNNSafe achieves up to $17.0\\%$ AUROC improvement over state-of-the-arts and it\ncould serve as simple yet strong baselines in such an under-developed area.\n","authors":["Qitian Wu","Yiting Chen","Chenxiao Yang","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2302.02914v2.pdf","comment":"Published at ICLR 2023, the implementation code is available at\n  https://github.com/qitianwu/GraphOOD-GNNSafe"},{"id":"http://arxiv.org/abs/2302.14829v2","updated":"2023-03-09T06:17:13Z","published":"2023-02-22T07:56:45Z","title":"Dish-TS: A General Paradigm for Alleviating Distribution Shift in Time\n  Series Forecasting","summary":"  The distribution shift in Time Series Forecasting (TSF), indicating series\ndistribution changes over time, largely hinders the performance of TSF models.\nExisting works towards distribution shift in time series are mostly limited in\nthe quantification of distribution and, more importantly, overlook the\npotential shift between lookback and horizon windows. To address above\nchallenges, we systematically summarize the distribution shift in TSF into two\ncategories. Regarding lookback windows as input-space and horizon windows as\noutput-space, there exist (i) intra-space shift, that the distribution within\nthe input-space keeps shifted over time, and (ii) inter-space shift, that the\ndistribution is shifted between input-space and output-space. Then we\nintroduce, Dish-TS, a general neural paradigm for alleviating distribution\nshift in TSF. Specifically, for better distribution estimation, we propose the\ncoefficient net (CONET), which can be any neural architectures, to map input\nsequences into learnable distribution coefficients. To relieve intra-space and\ninter-space shift, we organize Dish-TS as a Dual-CONET framework to separately\nlearn the distribution of input- and output-space, which naturally captures the\ndistribution difference of two spaces. In addition, we introduce a more\neffective training strategy for intractable CONET learning. Finally, we conduct\nextensive experiments on several datasets coupled with different\nstate-of-the-art forecasting models. Experimental results show Dish-TS\nconsistently boosts them with a more than 20% average improvement. Code is\navailable.\n","authors":["Wei Fan","Pengyang Wang","Dongkun Wang","Dongjie Wang","Yuanchun Zhou","Yanjie Fu"],"pdf_url":"https://arxiv.org/pdf/2302.14829v2.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2302.10899v2","updated":"2023-03-09T05:54:14Z","published":"2023-02-10T01:00:49Z","title":"Feature Affinity Assisted Knowledge Distillation and Quantization of\n  Deep Neural Networks on Label-Free Data","summary":"  In this paper, we propose a feature affinity (FA) assisted knowledge\ndistillation (KD) method to improve quantization-aware training of deep neural\nnetworks (DNN). The FA loss on intermediate feature maps of DNNs plays the role\nof teaching middle steps of a solution to a student instead of only giving\nfinal answers in the conventional KD where the loss acts on the network logits\nat the output level. Combining logit loss and FA loss, we found that the\nquantized student network receives stronger supervision than from the labeled\nground-truth data. The resulting FAQD is capable of compressing model on\nlabel-free data, which brings immediate practical benefits as pre-trained\nteacher models are readily available and unlabeled data are abundant. In\ncontrast, data labeling is often laborious and expensive. Finally, we propose a\nfast feature affinity (FFA) loss that accurately approximates FA loss with a\nlower order of computational complexity, which helps speed up training for high\nresolution image input.\n","authors":["Zhijian Li","Biao Yang","Penghang Yin","Yingyong Qi","Jack Xin"],"pdf_url":"https://arxiv.org/pdf/2302.10899v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05047v1","updated":"2023-03-09T05:52:42Z","published":"2023-03-09T05:52:42Z","title":"Diversity-Measurable Anomaly Detection","summary":"  Reconstruction-based anomaly detection models achieve their purpose by\nsuppressing the generalization ability for anomaly. However, diverse normal\npatterns are consequently not well reconstructed as well. Although some efforts\nhave been made to alleviate this problem by modeling sample diversity, they\nsuffer from shortcut learning due to undesired transmission of abnormal\ninformation. In this paper, to better handle the tradeoff problem, we propose\nDiversity-Measurable Anomaly Detection (DMAD) framework to enhance\nreconstruction diversity while avoid the undesired generalization on anomalies.\nTo this end, we design Pyramid Deformation Module (PDM), which models diverse\nnormals and measures the severity of anomaly by estimating multi-scale\ndeformation fields from reconstructed reference to original input. Integrated\nwith an information compression module, PDM essentially decouples deformation\nfrom prototypical embedding and makes the final anomaly score more reliable.\nExperimental results on both surveillance videos and industrial images\ndemonstrate the effectiveness of our method. In addition, DMAD works equally\nwell in front of contaminated data and anomaly-like normal samples.\n","authors":["Wenrui Liu","Hong Chang","Bingpeng Ma","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.05047v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2202.11202v3","updated":"2023-03-09T05:16:49Z","published":"2022-02-22T22:31:57Z","title":"Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning","summary":"  Indiscriminate data poisoning attacks are quite effective against supervised\nlearning. However, not much is known about their impact on unsupervised\ncontrastive learning (CL). This paper is the first to consider indiscriminate\npoisoning attacks of contrastive learning. We propose Contrastive Poisoning\n(CP), the first effective such attack on CL. We empirically show that\nContrastive Poisoning, not only drastically reduces the performance of CL\nalgorithms, but also attacks supervised learning models, making it the most\ngeneralizable indiscriminate poisoning attack. We also show that CL algorithms\nwith a momentum encoder are more robust to indiscriminate poisoning, and\npropose a new countermeasure based on matrix completion. Code is available at:\nhttps://github.com/kaiwenzha/contrastive-poisoning.\n","authors":["Hao He","Kaiwen Zha","Dina Katabi"],"pdf_url":"https://arxiv.org/pdf/2202.11202v3.pdf","comment":"ICLR 2023 Spotlight (notable top 25%). The first two authors\n  contributed equally to this paper"},{"id":"http://arxiv.org/abs/2303.05038v1","updated":"2023-03-09T05:11:30Z","published":"2023-03-09T05:11:30Z","title":"Exploiting Contextual Structure to Generate Useful Auxiliary Tasks","summary":"  Reinforcement learning requires interaction with an environment, which is\nexpensive for robots. This constraint necessitates approaches that work with\nlimited environmental interaction by maximizing the reuse of previous\nexperiences. We propose an approach that maximizes experience reuse while\nlearning to solve a given task by generating and simultaneously learning useful\nauxiliary tasks. To generate these tasks, we construct an abstract temporal\nlogic representation of the given task and leverage large language models to\ngenerate context-aware object embeddings that facilitate object replacements.\nCounterfactual reasoning and off-policy methods allow us to simultaneously\nlearn these auxiliary tasks while solving the given target task. We combine\nthese insights into a novel framework for multitask reinforcement learning and\nexperimentally show that our generated auxiliary tasks share similar underlying\nexploration requirements as the given task, thereby maximizing the utility of\ndirected exploration. Our approach allows agents to automatically learn\nadditional useful policies without extra environment interaction.\n","authors":["Benedict Quartey","Ankit Shah","George Konidaris"],"pdf_url":"https://arxiv.org/pdf/2303.05038v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.07467v5","updated":"2023-03-09T05:06:46Z","published":"2021-12-14T15:28:45Z","title":"AI Ethics Principles in Practice: Perspectives of Designers and\n  Developers","summary":"  As consensus across the various published AI ethics principles is approached,\na gap remains between high-level principles and practical techniques that can\nbe readily adopted to design and develop responsible AI systems. We examine the\npractices and experiences of researchers and engineers from Australia's\nnational scientific research agency (CSIRO), who are involved in designing and\ndeveloping AI systems for many application areas. Semi-structured interviews\nwere used to examine how the practices of the participants relate to and align\nwith a set of high-level AI ethics principles proposed by the Australian\nGovernment. The principles comprise: (1) privacy protection and security, (2)\nreliability and safety, (3) transparency and explainability, (4) fairness, (5)\ncontestability, (6) accountability, (7) human-centred values, (8) human, social\nand environmental wellbeing. Discussions on the gained insights from the\ninterviews include various tensions and trade-offs between the principles, and\nprovide suggestions for implementing each high-level principle. We also present\nsuggestions aiming to enhance associated support mechanisms.\n","authors":["Conrad Sanderson","David Douglas","Qinghua Lu","Emma Schleiger","Jon Whittle","Justine Lacey","Glenn Newnham","Stefan Hajkowicz","Cathy Robinson","David Hansen"],"pdf_url":"https://arxiv.org/pdf/2112.07467v5.pdf","comment":"submitted to IEEE Transactions on Technology & Society"},{"id":"http://arxiv.org/abs/2112.11191v2","updated":"2023-03-09T04:57:03Z","published":"2021-12-07T11:58:51Z","title":"Developing a Trusted Human-AI Network for Humanitarian Benefit","summary":"  Artificial intelligences (AI) will increasingly participate digitally and\nphysically in conflicts, yet there is a lack of trused communications with\nhumans for humanitarian purposes. In this paper we consider the integration of\na communications protocol (the 'whiteflag protocol'), distributed ledger\n'blockchain' technology, and information fusion with AI, to improve conflict\ncommunications called 'protected assurance understanding situation and\nentitities' PAUSE. Such a trusted human-AI communication network could provide\naccountable information exchange regarding protected entities, critical\ninfrastructure, humanitiarian signals and status updates for humans and\nmachines in conflicts. We examine several realistic potential case studies for\nthe integration of these technologies into a trusted human-AI network for\nhumanitarian benefit including mapping a conflict zone with civilians and\ncombatants in real time, preparation to avoid incidents and using the network\nto manage misinformation. We finish with a real-world example of a PAUSE-like\nnetwork, the Human Security Information System (HSIS), being developed by\nUSAID, that uses blockchain technology to provide a secure means to better\nunderstand the civilian environment.\n","authors":["Susannah Kate Devitt","Jason Scholz","Timo Schless","Larry Lewis"],"pdf_url":"https://arxiv.org/pdf/2112.11191v2.pdf","comment":"30 pages, 7 figures, 2 boxes, submitted for peer review to the\n  Journal of Digital War, My War Special Issue"},{"id":"http://arxiv.org/abs/2301.00767v2","updated":"2023-03-09T04:40:23Z","published":"2022-12-27T08:09:45Z","title":"A Survey on Federated Recommendation Systems","summary":"  Federated learning has recently been applied to recommendation systems to\nprotect user privacy. In federated learning settings, recommendation systems\ncan train recommendation models only collecting the intermediate parameters\ninstead of the real user data, which greatly enhances the user privacy. Beside,\nfederated recommendation systems enable to collaborate with other data\nplatforms to improve recommended model performance while meeting the regulation\nand privacy constraints. However, federated recommendation systems faces many\nnew challenges such as privacy, security, heterogeneity and communication\ncosts. While significant research has been conducted in these areas, gaps in\nthe surveying literature still exist. In this survey, we-(1) summarize some\ncommon privacy mechanisms used in federated recommendation systems and discuss\nthe advantages and limitations of each mechanism; (2) review some robust\naggregation strategies and several novel attacks against security; (3)\nsummarize some approaches to address heterogeneity and communication costs\nproblems; (4)introduce some open source platforms that can be used to build\nfederated recommendation systems; (5) present some prospective research\ndirections in the future. This survey can guide researchers and practitioners\nunderstand the research progress in these areas.\n","authors":["Zehua Sun","Yonghui Xu","Yong Liu","Wei He","Lanju Kong","Fangzhao Wu","Yali Jiang","Lizhen Cui"],"pdf_url":"https://arxiv.org/pdf/2301.00767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05023v1","updated":"2023-03-09T04:00:29Z","published":"2023-03-09T04:00:29Z","title":"X-SepFormer: End-to-end Speaker Extraction Network with Explicit\n  Optimization on Speaker Confusion","summary":"  Target speech extraction (TSE) systems are designed to extract target speech\nfrom a multi-talker mixture. The popular training objective for most prior TSE\nnetworks is to enhance reconstruction performance of extracted speech waveform.\nHowever, it has been reported that a TSE system delivers high reconstruction\nperformance may still suffer low-quality experience problems in practice. One\nsuch experience problem is wrong speaker extraction (called speaker confusion,\nSC), which leads to strong negative experience and hampers effective\nconversations. To mitigate the imperative SC issue, we reformulate the training\nobjective and propose two novel loss schemes that explore the metric of\nreconstruction improvement performance defined at small chunk-level and\nleverage the metric associated distribution information. Both loss schemes aim\nto encourage a TSE network to pay attention to those SC chunks based on the\nsaid distribution information. On this basis, we present X-SepFormer, an\nend-to-end TSE model with proposed loss schemes and a backbone of SepFormer.\nExperimental results on the benchmark WSJ0-2mix dataset validate the\neffectiveness of our proposals, showing consistent improvements on SC errors\n(by 14.8% relative). Moreover, with SI-SDRi of 19.4 dB and PESQ of 3.81, our\nbest system significantly outperforms the current SOTA systems and offers the\ntop TSE results reported till date on the WSJ0-2mix.\n","authors":["Kai Liu","Ziqing Du","Xucheng Wan","Huan Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.05023v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.05881v2","updated":"2023-03-09T03:18:25Z","published":"2023-02-12T09:50:32Z","title":"Low-Rank Tensor Completion With Generalized CP Decomposition and\n  Nonnegative Integer Tensor Completion","summary":"  Tensor completion is important to many areas such as computer vision, data\nanalysis, and signal processing. Previously, a category of methods known as\nlow-rank tensor completion has been proposed and developed, involving the\nenforcement of low-rank structures on completed tensors. While such methods\nhave been constantly improved, none considered exploiting the numerical\nproperties of tensor elements. This work attempts to construct a new\nmethodological framework called GCDTC (Generalized CP Decomposition Tensor\nCompletion) based on numerical properties to achieve higher accuracy in tensor\ncompletion. In this newly introduced framework, a generalized form of the CP\nDecomposition is applied to low-rank tensor completion. This paper also\nproposes an algorithm known as SPTC (Smooth Poisson Tensor Completion) for\nnonnegative integer tensor completion as an application of the GCDTC framework.\nThrough experimentation with real-life data, it is verified that this method\ncould produce results superior in completion accuracy to current\nstate-of-the-art methodologies.\n","authors":["Shiran Yuan"],"pdf_url":"https://arxiv.org/pdf/2302.05881v2.pdf","comment":"10 pages, 4 figures, and 1 table"},{"id":"http://arxiv.org/abs/2302.00843v2","updated":"2023-03-09T03:07:11Z","published":"2023-02-02T03:02:16Z","title":"Enactivism & Objectively Optimal Super-Intelligence","summary":"  Software's effect upon the world hinges upon the hardware that interprets it.\nThis tends not to be an issue, because we standardise hardware. AI is typically\nconceived of as a software ``mind'' running on such interchangeable hardware.\nThis formalises mind-body dualism, in that a software ``mind'' can be run on\nany number of standardised bodies. While this works well for simple\napplications, we argue that this approach is less than ideal for the purposes\nof formalising artificial general intelligence (AGI) or artificial\nsuper-intelligence (ASI). The general reinforcement learning agent AIXI is\npareto optimal. However, this claim regarding AIXI's performance is highly\nsubjective, because that performance depends upon the choice of interpreter. We\nexamine this problem and formulate an approach based upon enactive cognition\nand pancomputationalism to address the issue. Weakness is a measure of\nplausibility, a ``proxy for intelligence'' unrelated to compression or\nsimplicity. If hypotheses are evaluated in terms of weakness rather than\nlength, then we are able to make objective claims regarding performance (how\neffectively one adapts, or ``generalises'' from limited information).\nSubsequently, we propose a definition of AGI which is objectively optimal given\na ``vocabulary'' (body etc) in which cognition is enacted, and of ASI as that\nwhich finds the optimal vocabulary for a purpose and then constructs an AGI.\n","authors":["Michael Timothy Bennett"],"pdf_url":"https://arxiv.org/pdf/2302.00843v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04995v1","updated":"2023-03-09T02:38:32Z","published":"2023-03-09T02:38:32Z","title":"Text-Visual Prompting for Efficient 2D Temporal Video Grounding","summary":"  In this paper, we study the problem of temporal video grounding (TVG), which\naims to predict the starting/ending time points of moments described by a text\nsentence within a long untrimmed video. Benefiting from fine-grained 3D visual\nfeatures, the TVG techniques have achieved remarkable progress in recent years.\nHowever, the high complexity of 3D convolutional neural networks (CNNs) makes\nextracting dense 3D visual features time-consuming, which calls for intensive\nmemory and computing resources. Towards efficient TVG, we propose a novel\ntext-visual prompting (TVP) framework, which incorporates optimized\nperturbation patterns (that we call 'prompts') into both visual inputs and\ntextual features of a TVG model. In sharp contrast to 3D CNNs, we show that TVP\nallows us to effectively co-train vision encoder and language encoder in a 2D\nTVG model and improves the performance of crossmodal feature fusion using only\nlow-complexity sparse 2D visual features. The proposed prompts also compensate\nfor the lack of spatiotemporal information in 2D CNNs for visual feature\nextraction. Further, we propose a TemporalDistance IoU (TDIoU) loss for\nefficient learning of TVG. Last but not least, extensive experiments on two\nbenchmark datasets, Charades-STA and ActivityNet Captions datasets, empirically\nshow that the proposed TVP significantly boosts the performance of 2D TVG\n(e.g., 9.79% improvement in Charades-STA and 30.77% improvement in ActivityNet\nCaptions) and achieves 5x inference acceleration over TVG of using 3D visual\nfeatures. Code and model will be released.\n","authors":["Yimeng Zhang","Xin Chen","Jinghan Jia","Sijia Liu","Ke Ding"],"pdf_url":"https://arxiv.org/pdf/2303.04995v1.pdf","comment":"Accepted into the CVPR 2023"},{"id":"http://arxiv.org/abs/2303.04989v1","updated":"2023-03-09T02:20:56Z","published":"2023-03-09T02:20:56Z","title":"ARS-DETR: Aspect Ratio Sensitive Oriented Object Detection with\n  Transformer","summary":"  Existing oriented object detection methods commonly use metric AP$_{50}$ to\nmeasure the performance of the model. We argue that AP$_{50}$ is inherently\nunsuitable for oriented object detection due to its large tolerance in angle\ndeviation. Therefore, we advocate using high-precision metric, e.g. AP$_{75}$,\nto measure the performance of models. In this paper, we propose an Aspect Ratio\nSensitive Oriented Object Detector with Transformer, termed ARS-DETR, which\nexhibits a competitive performance in high-precision oriented object detection.\nSpecifically, a new angle classification method, calling Aspect Ratio aware\nCircle Smooth Label (AR-CSL), is proposed to smooth the angle label in a more\nreasonable way and discard the hyperparameter that introduced by previous work\n(e.g. CSL). Then, a rotated deformable attention module is designed to rotate\nthe sampling points with the corresponding angles and eliminate the\nmisalignment between region features and sampling points. Moreover, a dynamic\nweight coefficient according to the aspect ratio is adopted to calculate the\nangle loss. Comprehensive experiments on several challenging datasets show that\nour method achieves competitive performance on the high-precision oriented\nobject detection task.\n","authors":["Ying Zeng","Xue Yang","Qingyun Li","Yushi Chen","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2303.04989v1.pdf","comment":"10 pages, 8 figures, 8 tables, the source code is available at\n  https://github.com/httle/ARS-DETR"},{"id":"http://arxiv.org/abs/2303.01673v2","updated":"2023-03-09T02:20:26Z","published":"2023-03-03T02:24:06Z","title":"Near Optimal Memory-Regret Tradeoff for Online Learning","summary":"  In the experts problem, on each of $T$ days, an agent needs to follow the\nadvice of one of $n$ ``experts''. After each day, the loss associated with each\nexpert's advice is revealed. A fundamental result in learning theory says that\nthe agent can achieve vanishing regret, i.e. their cumulative loss is within\n$o(T)$ of the cumulative loss of the best-in-hindsight expert.\n  Can the agent perform well without sufficient space to remember all the\nexperts? We extend a nascent line of research on this question in two\ndirections:\n  $\\bullet$ We give a new algorithm against the oblivious adversary, improving\nover the memory-regret tradeoff obtained by [PZ23], and nearly matching the\nlower bound of [SWXZ22].\n  $\\bullet$ We also consider an adaptive adversary who can observe past experts\nchosen by the agent. In this setting we give both a new algorithm and a novel\nlower bound, proving that roughly $\\sqrt{n}$ memory is both necessary and\nsufficient for obtaining $o(T)$ regret.\n","authors":["Binghui Peng","Aviad Rubinstein"],"pdf_url":"https://arxiv.org/pdf/2303.01673v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00173v2","updated":"2023-03-09T01:49:54Z","published":"2022-10-01T02:57:37Z","title":"Predictive Inference with Feature Conformal Prediction","summary":"  Conformal prediction is a distribution-free technique for establishing valid\nprediction intervals. Although conventionally people conduct conformal\nprediction in the output space, this is not the only possibility. In this\npaper, we propose feature conformal prediction, which extends the scope of\nconformal prediction to semantic feature spaces by leveraging the inductive\nbias of deep representation learning. From a theoretical perspective, we\ndemonstrate that feature conformal prediction provably outperforms regular\nconformal prediction under mild assumptions. Our approach could be combined\nwith not only vanilla conformal prediction, but also other adaptive conformal\nprediction methods. Apart from experiments on existing predictive inference\nbenchmarks, we also demonstrate the state-of-the-art performance of the\nproposed methods on large-scale tasks such as ImageNet classification and\nCityscapes image segmentation.\n","authors":["Jiaye Teng","Chuan Wen","Dinghuai Zhang","Yoshua Bengio","Yang Gao","Yang Yuan"],"pdf_url":"https://arxiv.org/pdf/2210.00173v2.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.04982v1","updated":"2023-03-09T01:46:33Z","published":"2023-03-09T01:46:33Z","title":"The Robustness Verification of Linear Sound Quantum Classifiers","summary":"  I present a quick and sound method for the robustness verification of a sort\nof quantum classifiers who are Linear Sound. Since quantum machine learning has\nbeen put into practice in relevant fields and Linear Sound Property, LSP is a\npervasive property, the method could be universally applied. I implemented my\nmethod with a Quantum Convolutional Neural Network, QCNN using MindQuantum,\nHuawei and successfully verified its robustness when classifying MNIST dataset.\n","authors":["Su Bonan"],"pdf_url":"https://arxiv.org/pdf/2303.04982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10447v3","updated":"2023-03-09T01:38:38Z","published":"2023-02-21T05:24:00Z","title":"Mask-guided BERT for Few Shot Text Classification","summary":"  Transformer-based language models have achieved significant success in\nvarious domains. However, the data-intensive nature of the transformer\narchitecture requires much labeled data, which is challenging in low-resource\nscenarios (i.e., few-shot learning (FSL)). The main challenge of FSL is the\ndifficulty of training robust models on small amounts of samples, which\nfrequently leads to overfitting. Here we present Mask-BERT, a simple and\nmodular framework to help BERT-based architectures tackle FSL. The proposed\napproach fundamentally differs from existing FSL strategies such as prompt\ntuning and meta-learning. The core idea is to selectively apply masks on text\ninputs and filter out irrelevant information, which guides the model to focus\non discriminative tokens that influence prediction results. In addition, to\nmake the text representations from different categories more separable and the\ntext representations from the same category more compact, we introduce a\ncontrastive learning loss function. Experimental results on public-domain\nbenchmark datasets demonstrate the effectiveness of Mask-BERT.\n","authors":["Wenxiong Liao","Zhengliang Liu","Haixing Dai","Zihao Wu","Yiyang Zhang","Xiaoke Huang","Yuzhong Chen","Xi Jiang","Wei Liu","Dajiang Zhu","Tianming Liu","Sheng Li","Xiang Li","Hongmin Cai"],"pdf_url":"https://arxiv.org/pdf/2302.10447v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04976v1","updated":"2023-03-09T01:29:58Z","published":"2023-03-09T01:29:58Z","title":"Curvature-Sensitive Predictive Coding with Approximate Laplace Monte\n  Carlo","summary":"  Predictive coding (PC) accounts of perception now form one of the dominant\ncomputational theories of the brain, where they prescribe a general algorithm\nfor inference and learning over hierarchical latent probabilistic models.\nDespite this, they have enjoyed little export to the broader field of machine\nlearning, where comparative generative modelling techniques have flourished. In\npart, this has been due to the poor performance of models trained with PC when\nevaluated by both sample quality and marginal likelihood. By adopting the\nperspective of PC as a variational Bayes algorithm under the Laplace\napproximation, we identify the source of these deficits to lie in the exclusion\nof an associated Hessian term in the PC objective function, which would\notherwise regularise the sharpness of the probability landscape and prevent\nover-certainty in the approximate posterior. To remedy this, we make three\nprimary contributions: we begin by suggesting a simple Monte Carlo estimated\nevidence lower bound which relies on sampling from the Hessian-parameterised\nvariational posterior. We then derive a novel block diagonal approximation to\nthe full Hessian matrix that has lower memory requirements and favourable\nmathematical properties. Lastly, we present an algorithm that combines our\nmethod with standard PC to reduce memory complexity further. We evaluate models\ntrained with our approach against the standard PC framework on image benchmark\ndatasets. Our approach produces higher log-likelihoods and qualitatively better\nsamples that more closely capture the diversity of the data-generating\ndistribution.\n","authors":["Umais Zahid","Qinghai Guo","Karl Friston","Zafeirios Fountas"],"pdf_url":"https://arxiv.org/pdf/2303.04976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02849v2","updated":"2023-03-09T01:29:46Z","published":"2022-11-05T08:16:38Z","title":"Coarse-to-fine Knowledge Graph Domain Adaptation based on\n  Distantly-supervised Iterative Training","summary":"  Modern supervised learning neural network models require a large amount of\nmanually labeled data, which makes the construction of domain-specific\nknowledge graphs time-consuming and labor-intensive. In parallel, although\nthere has been much research on named entity recognition and relation\nextraction based on distantly supervised learning, constructing a\ndomain-specific knowledge graph from large collections of textual data without\nmanual annotations is still an urgent problem to be solved. In response, we\npropose an integrated framework for adapting and re-learning knowledge graphs\nfrom one coarse domain (biomedical) to a finer-define domain (oncology). In\nthis framework, we apply distant-supervision on cross-domain knowledge graph\nadaptation. Consequently, no manual data annotation is required to train the\nmodel. We introduce a novel iterative training strategy to facilitate the\ndiscovery of domain-specific named entities and triples. Experimental results\nindicate that the proposed framework can perform domain adaptation and\nconstruction of knowledge graph efficiently.\n","authors":["Hongmin Cai","Wenxiong Liao","Zhengliang Liu","Yiyang Zhang","Xiaoke Huang","Siqi Ding","Hui Ren","Zihao Wu","Haixing Dai","Sheng Li","Lingfei Wu","Ninghao Liu","Quanzheng Li","Tianming Liu","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2211.02849v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04117v2","updated":"2023-03-09T01:07:09Z","published":"2023-03-07T18:28:45Z","title":"Validation of a Hospital Digital Twin with Machine Learning","summary":"  Recently there has been a surge of interest in developing Digital Twins of\nprocess flows in healthcare to better understand bottlenecks and areas of\nimprovement. A key challenge is in the validation process. We describe a work\nin progress for a digital twin using an agent based simulation model for\ndetermining bed turnaround time for patients in hospitals. We employ a strategy\nusing machine learning for validating the model and implementing sensitivity\nanalysis.\n","authors":["Muhammad Aurangzeb Ahmad","Vijay Chickarmane","Farinaz Sabz Ali Pour","Nima Shariari","Taposh Dutta Roy"],"pdf_url":"https://arxiv.org/pdf/2303.04117v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04958v1","updated":"2023-03-09T00:26:59Z","published":"2023-03-09T00:26:59Z","title":"NIFF: Alleviating Forgetting in Generalized Few-Shot Object Detection\n  via Neural Instance Feature Forging","summary":"  Privacy and memory are two recurring themes in a broad conversation about the\nsocietal impact of AI. These concerns arise from the need for huge amounts of\ndata to train deep neural networks. A promise of Generalized Few-shot Object\nDetection (G-FSOD), a learning paradigm in AI, is to alleviate the need for\ncollecting abundant training samples of novel classes we wish to detect by\nleveraging prior knowledge from old classes (i.e., base classes). G-FSOD\nstrives to learn these novel classes while alleviating catastrophic forgetting\nof the base classes. However, existing approaches assume that the base images\nare accessible, an assumption that does not hold when sharing and storing data\nis problematic. In this work, we propose the first data-free knowledge\ndistillation (DFKD) approach for G-FSOD that leverages the statistics of the\nregion of interest (RoI) features from the base model to forge instance-level\nfeatures without accessing the base images. Our contribution is three-fold: (1)\nwe design a standalone lightweight generator with (2) class-wise heads (3) to\ngenerate and replay diverse instance-level base features to the RoI head while\nfinetuning on the novel data. This stands in contrast to standard DFKD\napproaches in image classification, which invert the entire network to generate\nbase images. Moreover, we make careful design choices in the novel finetuning\npipeline to regularize the model. We show that our approach can dramatically\nreduce the base memory requirements, all while setting a new standard for\nG-FSOD on the challenging MS-COCO and PASCAL-VOC benchmarks.\n","authors":["Karim Guirguis","Johannes Meier","George Eskandar","Matthias Kayser","Bin Yang","Juergen Beyerer"],"pdf_url":"https://arxiv.org/pdf/2303.04958v1.pdf","comment":"Accepted at CVPR 2023"},{"id":"http://arxiv.org/abs/2202.03609v4","updated":"2023-03-09T00:21:41Z","published":"2022-02-08T02:49:09Z","title":"Backdoor Detection and Mitigation in Competitive Reinforcement Learning","summary":"  While real-world applications of reinforcement learning are becoming popular,\nthe security and robustness of RL systems are worthy of more attention and\nexploration. In particular, recent works have revealed that, in a multi-agent\nRL environment, backdoor trigger actions can be injected into a victim agent\n(a.k.a. Trojan agent), which can result in a catastrophic failure as soon as it\nsees the backdoor trigger action. To ensure the security of RL agents against\nmalicious backdoors, in this work, we propose the problem of Backdoor Detection\nin a multi-agent competitive reinforcement learning system, with the objective\nof detecting Trojan agents as well as the corresponding potential trigger\nactions, and further trying to mitigate their Trojan behavior. In order to\nsolve this problem, we propose PolicyCleanse that is based on the property that\nthe activated Trojan agents accumulated rewards degrade noticeably after\nseveral timesteps. Along with PolicyCleanse, we also design a machine\nunlearning-based approach that can effectively mitigate the detected backdoor.\nExtensive experiments demonstrate that the proposed methods can accurately\ndetect Trojan agents, and outperform existing backdoor mitigation baseline\napproaches by at least 3% in winning rate across various types of agents and\nenvironments.\n","authors":["Junfeng Guo","Ang Li","Cong Liu"],"pdf_url":"https://arxiv.org/pdf/2202.03609v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05622v1","updated":"2023-03-09T23:27:08Z","published":"2023-03-09T23:27:08Z","title":"Explainable Goal Recognition: A Framework Based on Weight of Evidence","summary":"  We introduce and evaluate an eXplainable Goal Recognition (XGR) model that\nuses the Weight of Evidence (WoE) framework to explain goal recognition\nproblems. Our model provides human-centered explanations that answer why? and\nwhy not? questions. We computationally evaluate the performance of our system\nover eight different domains. Using a human behavioral study to obtain the\nground truth from human annotators, we further show that the XGR model can\nsuccessfully generate human-like explanations. We then report on a study with\n60 participants who observe agents playing Sokoban game and then receive\nexplanations of the goal recognition output. We investigate participants'\nunderstanding obtained by explanations through task prediction, explanation\nsatisfaction, and trust.\n","authors":["Abeer Alshehri","Tim Miller","Mor Vered"],"pdf_url":"https://arxiv.org/pdf/2303.05622v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2206.06178v3","updated":"2023-03-09T23:18:57Z","published":"2022-06-13T14:07:56Z","title":"Efficient recurrent architectures through activity sparsity and sparse\n  back-propagation through time","summary":"  Recurrent neural networks (RNNs) are well suited for solving sequence tasks\nin resource-constrained systems due to their expressivity and low computational\nrequirements. However, there is still a need to bridge the gap between what\nRNNs are capable of in terms of efficiency and performance and real-world\napplication requirements. The memory and computational requirements arising\nfrom propagating the activations of all the neurons at every time step to every\nconnected neuron, together with the sequential dependence of activations,\ncontribute to the inefficiency of training and using RNNs. We propose a\nsolution inspired by biological neuron dynamics that makes the communication\nbetween RNN units sparse and discrete. This makes the backward pass with\nbackpropagation through time (BPTT) computationally sparse and efficient as\nwell. We base our model on the gated recurrent unit (GRU), extending it with\nunits that emit discrete events for communication triggered by a threshold so\nthat no information is communicated to other units in the absence of events. We\nshow theoretically that the communication between units, and hence the\ncomputation required for both the forward and backward passes, scales with the\nnumber of events in the network. Our model achieves efficiency without\ncompromising task performance, demonstrating competitive performance compared\nto state-of-the-art recurrent network models in real-world tasks, including\nlanguage modeling. The dynamic activity sparsity mechanism also makes our model\nwell suited for novel energy-efficient neuromorphic hardware. Code is available\nat https://github.com/KhaleelKhan/EvNN/.\n","authors":["Anand Subramoney","Khaleelulla Khan Nazeer","Mark Schöne","Christian Mayr","David Kappel"],"pdf_url":"https://arxiv.org/pdf/2206.06178v3.pdf","comment":"Published as notable-top-25% paper in ICLR 2023"},{"id":"http://arxiv.org/abs/2212.01346v6","updated":"2023-03-09T23:17:08Z","published":"2022-12-02T18:03:37Z","title":"Guaranteed Conformance of Neurosymbolic Models to Natural Constraints","summary":"  Deep neural networks have emerged as the workhorse for a large section of\nrobotics and control applications, especially as models for dynamical systems.\nSuch data-driven models are in turn used for designing and verifying autonomous\nsystems. This is particularly useful in modeling medical systems where data can\nbe leveraged to individualize treatment. In safety-critical applications, it is\nimportant that the data-driven model is conformant to established knowledge\nfrom the natural sciences. Such knowledge is often available or can often be\ndistilled into a (possibly black-box) model $M$. For instance, the unicycle\nmodel (which encodes Newton's laws) for an F1 racing car. In this light, we\nconsider the following problem - given a model $M$ and state transition\ndataset, we wish to best approximate the system model while being bounded\ndistance away from $M$. We propose a method to guarantee this conformance. Our\nfirst step is to distill the dataset into few representative samples called\nmemories, using the idea of a growing neural gas. Next, using these memories we\npartition the state space into disjoint subsets and compute bounds that should\nbe respected by the neural network, when the input is drawn from a particular\nsubset. This serves as a symbolic wrapper for guaranteed conformance. We argue\ntheoretically that this only leads to bounded increase in approximation error;\nwhich can be controlled by increasing the number of memories. We experimentally\nshow that on three case studies (Car Model, Drones, and Artificial Pancreas),\nour constrained neurosymbolic models conform to specified $M$ models (each\nencoding various constraints) with order-of-magnitude improvements compared to\nthe augmented Lagrangian and vanilla training methods. Our code can be found at\nhttps://github.com/kaustubhsridhar/Constrained_Models\n","authors":["Kaustubh Sridhar","Souradeep Dutta","James Weimer","Insup Lee"],"pdf_url":"https://arxiv.org/pdf/2212.01346v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05617v1","updated":"2023-03-09T23:11:52Z","published":"2023-03-09T23:11:52Z","title":"KGNv2: Separating Scale and Pose Prediction for Keypoint-based 6-DoF\n  Grasp Pose Synthesis on RGB-D input","summary":"  We propose a new 6-DoF grasp pose synthesis approach from 2D/2.5D input based\non keypoints. Keypoint-based grasp detector from image input has demonstrated\npromising results in the previous study, where the additional visual\ninformation provided by color images compensates for the noisy depth\nperception. However, it relies heavily on accurately predicting the location of\nkeypoints in the image space. In this paper, we devise a new grasp generation\nnetwork that reduces the dependency on precise keypoint estimation. Given an\nRGB-D input, our network estimates both the grasp pose from keypoint detection\nas well as scale towards the camera. We further re-design the keypoint output\nspace in order to mitigate the negative impact of keypoint prediction noise to\nPerspective-n-Point (PnP) algorithm. Experiments show that the proposed method\noutperforms the baseline by a large margin, validating the efficacy of our\napproach. Finally, despite trained on simple synthetic objects, our method\ndemonstrate sim-to-real capacity by showing competitive results in real-world\nrobot experiments.\n","authors":["Yiye Chen","Ruinian Xu","Yunzhi Lin","Patricio A. Vela"],"pdf_url":"https://arxiv.org/pdf/2303.05617v1.pdf","comment":"Submitted to IROS2023"},{"id":"http://arxiv.org/abs/2303.05606v1","updated":"2023-03-09T22:16:28Z","published":"2023-03-09T22:16:28Z","title":"Variance-aware robust reinforcement learning with linear function\n  approximation with heavy-tailed rewards","summary":"  This paper presents two algorithms, AdaOFUL and VARA, for online sequential\ndecision-making in the presence of heavy-tailed rewards with only finite\nvariances. For linear stochastic bandits, we address the issue of heavy-tailed\nrewards by modifying the adaptive Huber regression and proposing AdaOFUL.\nAdaOFUL achieves a state-of-the-art regret bound of\n$\\widetilde{\\mathcal{O}}\\big(d\\big(\\sum_{t=1}^T \\nu_{t}^2\\big)^{1/2}+d\\big)$ as\nif the rewards were uniformly bounded, where $\\nu_{t}^2$ is the observed\nconditional variance of the reward at round $t$, $d$ is the feature dimension,\nand $\\widetilde{\\mathcal{O}}(\\cdot)$ hides logarithmic dependence. Building\nupon AdaOFUL, we propose VARA for linear MDPs, which achieves a tighter\nvariance-aware regret bound of\n$\\widetilde{\\mathcal{O}}(d\\sqrt{H\\mathcal{G}^*K})$. Here, $H$ is the length of\nepisodes, $K$ is the number of episodes, and $\\mathcal{G}^*$ is a smaller\ninstance-dependent quantity that can be bounded by other instance-dependent\nquantities when additional structural conditions on the MDP are satisfied. Our\nregret bound is superior to the current state-of-the-art bounds in three ways:\n(1) it depends on a tighter instance-dependent quantity and has optimal\ndependence on $d$ and $H$, (2) we can obtain further instance-dependent bounds\nof $\\mathcal{G}^*$ under additional structural conditions on the MDP, and (3)\nour regret bound is valid even when rewards have only finite variances,\nachieving a level of generality unmatched by previous works. Overall, our\nmodified adaptive Huber regression algorithm may serve as a useful building\nblock in the design of algorithms for online problems with heavy-tailed\nrewards.\n","authors":["Xiang Li","Qiang Sun"],"pdf_url":"https://arxiv.org/pdf/2303.05606v1.pdf","comment":"23 page main text, 42 page appendix"},{"id":"http://arxiv.org/abs/2211.01241v3","updated":"2023-03-09T21:48:54Z","published":"2022-11-02T16:22:41Z","title":"WiserVR: Semantic Communication Enabled Wireless Virtual Reality\n  Delivery","summary":"  Virtual reality (VR) over wireless is expected to be one of the killer\napplications in next-generation communication networks. Nevertheless, the huge\ndata volume along with stringent requirements on latency and reliability under\nlimited bandwidth resources makes untethered wireless VR delivery increasingly\nchallenging. Such bottlenecks, therefore, motivate this work to seek the\npotential of using semantic communication, a new paradigm that promises to\nsignificantly ease the resource pressure, for efficient VR delivery. To this\nend, we propose a novel framework, namely WIreless SEmantic deliveRy for VR\n(WiserVR), for delivering consecutive 360{\\deg} video frames to VR users.\nSpecifically, deep learning-based multiple modules are well-devised for the\ntransceiver in WiserVR to realize high-performance feature extraction and\nsemantic recovery. Among them, we dedicatedly develop a concept of semantic\nlocation graph and leverage the joint-semantic-channel-coding method with\nknowledge sharing to not only substantially reduce communication latency, but\nalso to guarantee adequate transmission reliability and resilience under\nvarious channel states. Moreover, implementation of WiserVR is presented,\nfollowed by corresponding initial simulations for performance evaluation\ncompared with benchmarks. Finally, we discuss several open issues and offer\nfeasible solutions to unlock the full potential of WiserVR.\n","authors":["Le Xia","Yao Sun","Chengsi Liang","Daquan Feng","Runze Cheng","Yang Yang","Muhammad Ali Imran"],"pdf_url":"https://arxiv.org/pdf/2211.01241v3.pdf","comment":"This magazine article has been accepted for publication by IEEE\n  Wireless Communications. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2303.05593v1","updated":"2023-03-09T21:37:50Z","published":"2023-03-09T21:37:50Z","title":"Learning the Wrong Lessons: Inserting Trojans During Knowledge\n  Distillation","summary":"  In recent years, knowledge distillation has become a cornerstone of\nefficiently deployed machine learning, with labs and industries using knowledge\ndistillation to train models that are inexpensive and resource-optimized.\nTrojan attacks have contemporaneously gained significant prominence, revealing\nfundamental vulnerabilities in deep learning models. Given the widespread use\nof knowledge distillation, in this work we seek to exploit the unlabelled data\nknowledge distillation process to embed Trojans in a student model without\nintroducing conspicuous behavior in the teacher. We ultimately devise a Trojan\nattack that effectively reduces student accuracy, does not alter teacher\nperformance, and is efficiently constructible in practice.\n","authors":["Leonard Tang","Tom Shlomi","Alexander Cai"],"pdf_url":"https://arxiv.org/pdf/2303.05593v1.pdf","comment":"ICLR 2023 Workshop on Backdoor Attacks and Defenses in Machine\n  Learning"},{"id":"http://arxiv.org/abs/2303.05584v1","updated":"2023-03-09T21:21:05Z","published":"2023-03-09T21:21:05Z","title":"SOCIALGYM 2.0: Simulator for Multi-Agent Social Robot Navigation in\n  Shared Human Spaces","summary":"  We present SocialGym 2, a multi-agent navigation simulator for social robot\nresearch. Our simulator models multiple autonomous agents, replicating\nreal-world dynamics in complex environments, including doorways, hallways,\nintersections, and roundabouts. Unlike traditional simulators that concentrate\non single robots with basic kinematic constraints in open spaces, SocialGym 2\nemploys multi-agent reinforcement learning (MARL) to develop optimal navigation\npolicies for multiple robots with diverse, dynamic constraints in complex\nenvironments. Built on the PettingZoo MARL library and Stable Baselines3 API,\nSocialGym 2 offers an accessible python interface that integrates with a\nnavigation stack through ROS messaging. SocialGym 2 can be easily installed and\nis packaged in a docker container, and it provides the capability to swap and\nevaluate different MARL algorithms, as well as customize observation and reward\nfunctions. We also provide scripts to allow users to create their own\nenvironments and have conducted benchmarks using various social navigation\nalgorithms, reporting a broad range of social navigation metrics. Projected\nhosted at: https://amrl.cs.utexas.edu/social_gym/index.html\n","authors":["Zayne Sprague","Rohan Chandra","Jarrett Holtz","Joydeep Biswas"],"pdf_url":"https://arxiv.org/pdf/2303.05584v1.pdf","comment":"Submitted to RSS 2023"},{"id":"http://arxiv.org/abs/2303.05581v1","updated":"2023-03-09T21:12:46Z","published":"2023-03-09T21:12:46Z","title":"Open World Classification with Adaptive Negative Samples","summary":"  Open world classification is a task in natural language processing with key\npractical relevance and impact. Since the open or {\\em unknown} category data\nonly manifests in the inference phase, finding a model with a suitable decision\nboundary accommodating for the identification of known classes and\ndiscrimination of the open category is challenging. The performance of existing\nmodels is limited by the lack of effective open category data during the\ntraining stage or the lack of a good mechanism to learn appropriate decision\nboundaries. We propose an approach based on \\underline{a}daptive\n\\underline{n}egative \\underline{s}amples (ANS) designed to generate effective\nsynthetic open category samples in the training stage and without requiring any\nprior knowledge or external datasets. Empirically, we find a significant\nadvantage in using auxiliary one-versus-rest binary classifiers, which\neffectively utilize the generated negative samples and avoid the complex\nthreshold-seeking stage in previous works. Extensive experiments on three\nbenchmark datasets show that ANS achieves significant improvements over\nstate-of-the-art methods.\n","authors":["Ke Bai","Guoyin Wang","Jiwei Li","Sunghyun Park","Sungjin Lee","Puyang Xu","Ricardo Henao","Lawrence Carin"],"pdf_url":"https://arxiv.org/pdf/2303.05581v1.pdf","comment":"Accepted by EMNLP 2021 (Main Track, Long Paper)"},{"id":"http://arxiv.org/abs/2303.05575v1","updated":"2023-03-09T20:51:18Z","published":"2023-03-09T20:51:18Z","title":"Evaluating the Robustness of Conversational Recommender Systems by\n  Adversarial Examples","summary":"  Conversational recommender systems (CRSs) are improving rapidly, according to\nthe standard recommendation accuracy metrics. However, it is essential to make\nsure that these systems are robust in interacting with users including regular\nand malicious users who want to attack the system by feeding the system\nmodified input data. In this paper, we propose an adversarial evaluation scheme\nincluding four scenarios in two categories and automatically generate\nadversarial examples to evaluate the robustness of these systems in the face of\ndifferent input data. By executing these adversarial examples we can compare\nthe ability of different conversational recommender systems to satisfy the\nuser's preferences. We evaluate three CRSs by the proposed adversarial examples\non two datasets. Our results show that none of these systems are robust and\nreliable to the adversarial examples.\n","authors":["Ali Montazeralghaem","James Allan"],"pdf_url":"https://arxiv.org/pdf/2303.05575v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2203.03668v5","updated":"2023-03-09T20:19:23Z","published":"2022-03-04T14:16:50Z","title":"A Typology for Exploring the Mitigation of Shortcut Behavior","summary":"  As machine learning models become increasingly larger, trained weakly\nsupervised on large, possibly uncurated data sets, it becomes increasingly\nimportant to establish mechanisms for inspecting, interacting, and revising\nmodels to mitigate learning shortcuts and guarantee their learned knowledge is\naligned with human knowledge. The recently proposed XIL framework was developed\nfor this purpose, and several such methods have been introduced, each with\nindividual motivations and methodological details. In this work, we provide a\nunification of various XIL methods into a single typology by establishing a\ncommon set of basic modules. In doing so, we pave the way for a principled\ncomparison of existing, but, importantly, also future XIL approaches. In\naddition, we discuss existing and introduce novel measures and benchmarks for\nevaluating the overall abilities of a XIL method. Given this extensive toolbox,\nincluding our typology, measures, and benchmarks, we finally compare several\nrecent XIL methods methodologically and quantitatively. In our evaluations, all\nmethods prove to revise a model successfully. However, we found remarkable\ndifferences in individual benchmark tasks, revealing valuable\napplication-relevant aspects for integrating these benchmarks in developing\nfuture methods.\n","authors":["Felix Friedrich","Wolfgang Stammer","Patrick Schramowski","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2203.03668v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.10520v3","updated":"2023-03-09T20:01:31Z","published":"2022-01-21T22:21:31Z","title":"Adaptive Activation-based Structured Pruning","summary":"  Pruning is a promising approach to compress complex deep learning models in\norder to deploy them on resource-constrained edge devices. However, many\nexisting pruning solutions are based on unstructured pruning, which yields\nmodels that cannot efficiently run on commodity hardware and require users to\nmanually explore and tune the pruning process, which is time-consuming and\noften leads to sub-optimal results. To address these limitations, this paper\npresents an adaptive, activation-based, structured pruning approach to\nautomatically and efficiently generate small, accurate, and hardware-efficient\nmodels that meet user requirements. First, it proposes iterative structured\npruning using activation-based attention feature maps to effectively identify\nand prune unimportant filters. Then, it proposes adaptive pruning policies for\nautomatically meeting the pruning objectives of accuracy-critical,\nmemory-constrained, and latency-sensitive tasks. A comprehensive evaluation\nshows that the proposed method can substantially outperform the\nstate-of-the-art structured pruning works on CIFAR-10 and ImageNet datasets.\nFor example, on ResNet-56 with CIFAR-10, without any accuracy drop, our method\nachieves the largest parameter reduction (79.11%), outperforming the related\nworks by 22.81% to 66.07%, and the largest FLOPs reduction (70.13%),\noutperforming the related works by 14.13% to 26.53%.\n","authors":["Kaiqi Zhao","Animesh Jain","Ming Zhao"],"pdf_url":"https://arxiv.org/pdf/2201.10520v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12250v2","updated":"2023-03-09T19:19:44Z","published":"2022-10-21T21:09:37Z","title":"STAP: Sequencing Task-Agnostic Policies","summary":"  Advances in robotic skill acquisition have made it possible to build\ngeneral-purpose libraries of learned skills for downstream manipulation tasks.\nHowever, naively executing these skills one after the other is unlikely to\nsucceed without accounting for dependencies between actions prevalent in\nlong-horizon plans. We present Sequencing Task-Agnostic Policies (STAP), a\nscalable framework for training manipulation skills and coordinating their\ngeometric dependencies at planning time to solve long-horizon tasks never seen\nby any skill during training. Given that Q-functions encode a measure of skill\nfeasibility, we formulate an optimization problem to maximize the joint success\nof all skills sequenced in a plan, which we estimate by the product of their\nQ-values. Our experiments indicate that this objective function approximates\nground truth plan feasibility and, when used as a planning objective, reduces\nmyopic behavior and thereby promotes long-horizon task success. We further\ndemonstrate how STAP can be used for task and motion planning by estimating the\ngeometric feasibility of skill sequences provided by a task planner. We\nevaluate our approach in simulation and on a real robot. Qualitative results\nand code are made available at https://sites.google.com/stanford.edu/stap/home.\n","authors":["Christopher Agia","Toki Migimatsu","Jiajun Wu","Jeannette Bohg"],"pdf_url":"https://arxiv.org/pdf/2210.12250v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05546v1","updated":"2023-03-09T19:08:02Z","published":"2023-03-09T19:08:02Z","title":"Weakly-Supervised HOI Detection from Interaction Labels Only and\n  Language/Vision-Language Priors","summary":"  Human-object interaction (HOI) detection aims to extract interacting\nhuman-object pairs and their interaction categories from a given natural image.\nEven though the labeling effort required for building HOI detection datasets is\ninherently more extensive than for many other computer vision tasks,\nweakly-supervised directions in this area have not been sufficiently explored\ndue to the difficulty of learning human-object interactions with weak\nsupervision, rooted in the combinatorial nature of interactions over the object\nand predicate space. In this paper, we tackle HOI detection with the weakest\nsupervision setting in the literature, using only image-level interaction\nlabels, with the help of a pretrained vision-language model (VLM) and a large\nlanguage model (LLM). We first propose an approach to prune non-interacting\nhuman and object proposals to increase the quality of positive pairs within the\nbag, exploiting the grounding capability of the vision-language model. Second,\nwe use a large language model to query which interactions are possible between\na human and a given object category, in order to force the model not to put\nemphasis on unlikely interactions. Lastly, we use an auxiliary\nweakly-supervised preposition prediction task to make our model explicitly\nreason about space. Extensive experiments and ablations show that all of our\ncontributions increase HOI detection performance.\n","authors":["Mesut Erhan Unal","Adriana Kovashka"],"pdf_url":"https://arxiv.org/pdf/2303.05546v1.pdf","comment":"8 pages, 3 figures and 5 tables"},{"id":"http://arxiv.org/abs/2303.06018v1","updated":"2023-03-09T18:20:07Z","published":"2023-03-09T18:20:07Z","title":"Hierarchical Neural Program Synthesis","summary":"  Program synthesis aims to automatically construct human-readable programs\nthat satisfy given task specifications, such as input/output pairs or\ndemonstrations. Recent works have demonstrated encouraging results in a variety\nof domains, such as string transformation, tensor manipulation, and describing\nbehaviors of embodied agents. Most existing program synthesis methods are\ndesigned to synthesize programs from scratch, generating a program token by\ntoken, line by line. This fundamentally prevents these methods from scaling up\nto synthesize programs that are longer or more complex. In this work, we\npresent a scalable program synthesis framework that instead synthesizes a\nprogram by hierarchically composing programs. Specifically, we first learn a\ntask embedding space and a program decoder that can decode a task embedding\ninto a program. Then, we train a high-level module to comprehend the task\nspecification (e.g., input/output pairs or demonstrations) from long programs\nand produce a sequence of task embeddings, which are then decoded by the\nprogram decoder and composed to yield the synthesized program. We extensively\nevaluate our proposed framework in a string transformation domain with\ninput/output pairs. The experimental results demonstrate that the proposed\nframework can synthesize programs that are significantly longer and more\ncomplex than the programs considered in prior program synthesis works. Website\nat https://thoughtp0lice.github.io/hnps_web/\n","authors":["Linghan Zhong","Ryan Lindeborg","Jesse Zhang","Joseph J. Lim","Shao-Hua Sun"],"pdf_url":"https://arxiv.org/pdf/2303.06018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05518v1","updated":"2023-03-09T16:05:10Z","published":"2023-03-09T16:05:10Z","title":"Computably Continuous Reinforcement-Learning Objectives are\n  PAC-learnable","summary":"  In reinforcement learning, the classic objectives of maximizing discounted\nand finite-horizon cumulative rewards are PAC-learnable: There are algorithms\nthat learn a near-optimal policy with high probability using a finite amount of\nsamples and computation. In recent years, researchers have introduced\nobjectives and corresponding reinforcement-learning algorithms beyond the\nclassic cumulative rewards, such as objectives specified as linear temporal\nlogic formulas. However, questions about the PAC-learnability of these new\nobjectives have remained open.\n  This work demonstrates the PAC-learnability of general reinforcement-learning\nobjectives through sufficient conditions for PAC-learnability in two analysis\nsettings. In particular, for the analysis that considers only sample\ncomplexity, we prove that if an objective given as an oracle is uniformly\ncontinuous, then it is PAC-learnable. Further, for the analysis that considers\ncomputational complexity, we prove that if an objective is computable, then it\nis PAC-learnable. In other words, if a procedure computes successive\napproximations of the objective's value, then the objective is PAC-learnable.\n  We give three applications of our condition on objectives from the literature\nwith previously unknown PAC-learnability and prove that these objectives are\nPAC-learnable. Overall, our result helps verify existing objectives'\nPAC-learnability. Also, as some studied objectives that are not uniformly\ncontinuous have been shown to be not PAC-learnable, our results could guide the\ndesign of new PAC-learnable objectives.\n","authors":["Cambridge Yang","Michael Littman","Michael Carbin"],"pdf_url":"https://arxiv.org/pdf/2303.05518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05517v1","updated":"2023-03-09T13:27:54Z","published":"2023-03-09T13:27:54Z","title":"On the Soundness of XAI in Prognostics and Health Management (PHM)","summary":"  The aim of Predictive Maintenance, within the field of Prognostics and Health\nManagement (PHM), is to identify and anticipate potential issues in the\nequipment before these become critical. The main challenge to be addressed is\nto assess the amount of time a piece of equipment will function effectively\nbefore it fails, which is known as Remaining Useful Life (RUL). Deep Learning\n(DL) models, such as Deep Convolutional Neural Networks (DCNN) and Long\nShort-Term Memory (LSTM) networks, have been widely adopted to address the\ntask, with great success. However, it is well known that this kind of black box\nmodels are opaque decision systems, and it may be hard to explain its outputs\nto stakeholders (experts in the industrial equipment). Due to the large number\nof parameters that determine the behavior of these complex models,\nunderstanding the reasoning behind the predictions is challenging. This work\npresents a critical and comparative revision on a number of XAI methods applied\non time series regression model for PM. The aim is to explore XAI methods\nwithin time series regression, which have been less studied than those for time\nseries classification. The model used during the experimentation is a DCNN\ntrained to predict the RUL of an aircraft engine. The methods are reviewed and\ncompared using a set of metrics that quantifies a number of desirable\nproperties that any XAI method should fulfill. The results show that GRAD-CAM\nis the most robust method, and that the best layer is not the bottom one, as is\ncommonly seen within the context of Image Processing.\n","authors":["David Solís-Martín","Juan Galán-Páez","Joaquín Borrego-Díaz"],"pdf_url":"https://arxiv.org/pdf/2303.05517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06016v1","updated":"2023-03-09T12:13:46Z","published":"2023-03-09T12:13:46Z","title":"Modelling Projection Bias in Intertemporal Choices: A Prospect Theory\n  Based Approach","summary":"  Users often face bundle promotions when purchasing, where they have to select\nbetween two options: buy the single item at full price, or buy the bundle at a\ndiscount. In this scenario, users' preferences are usually influenced by the\nprojection bias, that is, users often believe that their future preferences are\nsimilar to their current preferences, causing them to make irrational and\nshort-sighted decisions. It is of great significance to analyze the effect of\nthe projection bias on users' preferences, and this study may help understand\nusers' decision-making process and provide bundling and pricing strategies for\nsellers. Prior works typically use a linear bias model for qualitative\nanalysis, and they cannot quantitatively calculate users' nonlinear and\npersonalized bias. In this work, we propose Pobe, a projection bias-embedded\npreference model to accurately predict users' choices. The proposed Pobe\nintroduces the prospect theory to analyze users' irrational decisions, and\nutilizes the weight function to handle users' nonlinear and personalized bias.\nBased on the proposed Pobe, we also study the impact of items' correlations or\ndiscount prices on users' choices, and provide four bundling strategies.\nExperimental results show that the proposed method can achieve better\nperformance than prior works, especially when only small data is available.\n","authors":["Qingming Li","H. Vicky Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.06016v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06052v1","updated":"2023-03-09T05:11:46Z","published":"2023-03-09T05:11:46Z","title":"Analysis and Evaluation of Explainable Artificial Intelligence on\n  Suicide Risk Assessment","summary":"  This study investigates the effectiveness of Explainable Artificial\nIntelligence (XAI) techniques in predicting suicide risks and identifying the\ndominant causes for such behaviours. Data augmentation techniques and ML models\nare utilized to predict the associated risk. Furthermore, SHapley Additive\nexPlanations (SHAP) and correlation analysis are used to rank the importance of\nvariables in predictions. Experimental results indicate that Decision Tree\n(DT), Random Forest (RF) and eXtreme Gradient Boosting (XGBoost) models achieve\nthe best results while DT has the best performance with an accuracy of 95:23%\nand an Area Under Curve (AUC) of 0.95. As per SHAP results, anger problems,\ndepression, and social isolation are the leading variables in predicting the\nrisk of suicide, and patients with good incomes, respected occupations, and\nuniversity education have the least risk. Results demonstrate the effectiveness\nof machine learning and XAI framework for suicide risk prediction, and they can\nassist psychiatrists in understanding complex human behaviours and can also\nassist in reliable clinical decision-making.\n","authors":["Hao Tang","Aref Miri Rekavandi","Dharjinder Rooprai","Girish Dwivedi","Frank Sanfilippo","Farid Boussaid","Mohammed Bennamoun"],"pdf_url":"https://arxiv.org/pdf/2303.06052v1.pdf","comment":null}]},"2023-03-10T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2107.13290v4","updated":"2023-03-10T18:59:02Z","published":"2021-07-28T11:34:00Z","title":"Arabic aspect sentiment polarity classification using BERT","summary":"  Aspect-based sentiment analysis(ABSA) is a textual analysis methodology that\ndefines the polarity of opinions on certain aspects related to specific\ntargets. The majority of research on ABSA is in English, with a small amount of\nwork available in Arabic. Most previous Arabic research has relied on deep\nlearning models that depend primarily on context-independent word embeddings\n(e.g.word2vec), where each word has a fixed representation independent of its\ncontext. This article explores the modeling capabilities of contextual\nembeddings from pre-trained language models, such as BERT, and making use of\nsentence pair input on Arabic aspect sentiment polarity classification task. In\nparticular, we develop a simple but effective BERT-based neural baseline to\nhandle this task. Our BERT architecture with a simple linear classification\nlayer surpassed the state-of-the-art works, according to the experimental\nresults on three different Arabic datasets. Achieving an accuracy of 89.51% on\nthe Arabic hotel reviews dataset, 73% on the Human annotated book reviews\ndataset, and 85.73% on the Arabic news dataset.\n","authors":["Mohammed M. Abdelgwad","Taysir Hassan A Soliman","Ahmed I. Taloba"],"pdf_url":"https://arxiv.org/pdf/2107.13290v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06135v1","updated":"2023-03-10T18:53:52Z","published":"2023-03-10T18:53:52Z","title":"Rewarding Chatbots for Real-World Engagement with Millions of Users","summary":"  The emergence of pretrained large language models has led to the deployment\nof a range of social chatbots for chitchat. Although these chatbots demonstrate\nlanguage ability and fluency, they are not guaranteed to be engaging and can\nstruggle to retain users. This work investigates the development of social\nchatbots that prioritize user engagement to enhance retention, specifically\nexamining the use of human feedback to efficiently develop highly engaging\nchatbots. The proposed approach uses automatic pseudo-labels collected from\nuser interactions to train a reward model that can be used to reject\nlow-scoring sample responses generated by the chatbot model at inference time.\nIntuitive evaluation metrics, such as mean conversation length (MCL), are\nintroduced as proxies to measure the level of engagement of deployed chatbots.\nA/B testing on groups of 10,000 new daily chatbot users on the Chai Research\nplatform shows that this approach increases the MCL by up to 70%, which\ntranslates to a more than 30% increase in user retention for a GPT-J 6B model.\nFuture work aims to use the reward model to realise a data fly-wheel, where the\nlatest user conversations can be used to alternately fine-tune the language\nmodel and the reward model.\n","authors":["Robert Irvine","Douglas Boubert","Vyas Raina","Adian Liusie","Vineet Mudupalli","Aliaksei Korshuk","Zongyi Liu","Fritz Cremer","Valentin Assassi","Christie-Carol Beauchamp","Xiaoding Lu","Thomas Rialan","William Beauchamp"],"pdf_url":"https://arxiv.org/pdf/2303.06135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14228v4","updated":"2023-03-10T17:24:26Z","published":"2022-11-25T16:41:59Z","title":"GPT-3-driven pedagogical agents for training children's curious\n  question-asking skills","summary":"  In order to train children's ability to ask curiosity-driven questions,\nprevious research has explored designing specific exercises relying on\nproviding semantic and linguistic cues to help formulate such questions. But\ndespite showing pedagogical efficiency, this method is still limited as it\nrelies on generating the said cues by hand, which can be a very costly process.\nIn this context, we propose to leverage advances in the natural language\nprocessing field (NLP) and investigate the efficiency of using a large language\nmodel (LLM) for automating the production of the pedagogical content of a\ncurious question-asking (QA) training. We study generating the said content\nusing the \"prompt-based\" method that consists of explaining the task to the LLM\nin natural text. We evaluate the output using human experts annotations and\ncomparisons with hand-generated content. Results suggested indeed the relevance\nand usefulness of this content. We also conduct a field study in primary school\n(75 children aged 9-10), where we evaluate children's QA performance when\nhaving this training. We compare 3 types of content : 1) hand-generated content\nthat proposes \"closed\" cues leading to predefined questions; 2) GPT-3-generated\ncontent that proposes the same type of cues; 3) GPT-3-generated content that\nproposes \"open\" cues leading to several possible questions. We see a similar QA\nperformance between the two \"closed\" trainings (showing the scalability of the\napproach using GPT-3), and a better one for participants with the \"open\"\ntraining. These results suggest the efficiency of using LLMs to support\nchildren in generating more curious questions, using a natural language\nprompting approach that affords usability by teachers and other users not\nspecialists of AI techniques. Furthermore, results also show that open-ended\ncontent may be more suitable for training curious question-asking skills.\n","authors":["Rania Abdelghani","Yen-Hsiang Wang","Xingdi Yuan","Tong Wang","Pauline Lucas","Hélène Sauzéon","Pierre-Yves Oudeyer"],"pdf_url":"https://arxiv.org/pdf/2211.14228v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01910v2","updated":"2023-03-10T17:20:17Z","published":"2022-11-03T15:43:03Z","title":"Large Language Models Are Human-Level Prompt Engineers","summary":"  By conditioning on natural language instructions, large language models\n(LLMs) have displayed impressive capabilities as general-purpose computers.\nHowever, task performance depends significantly on the quality of the prompt\nused to steer the model, and most effective prompts have been handcrafted by\nhumans. Inspired by classical program synthesis and the human approach to\nprompt engineering, we propose Automatic Prompt Engineer (APE) for automatic\ninstruction generation and selection. In our method, we treat the instruction\nas the \"program,\" optimized by searching over a pool of instruction candidates\nproposed by an LLM in order to maximize a chosen score function. To evaluate\nthe quality of the selected instruction, we evaluate the zero-shot performance\nof another LLM following the selected instruction. Experiments on 24 NLP tasks\nshow that our automatically generated instructions outperform the prior LLM\nbaseline by a large margin and achieve better or comparable performance to the\ninstructions generated by human annotators on 19/24 tasks. We conduct extensive\nqualitative and quantitative analyses to explore the performance of APE. We\nshow that APE-engineered prompts can be applied to steer models toward\ntruthfulness and/or informativeness, as well as to improve few-shot learning\nperformance by simply prepending them to standard in-context learning prompts.\nPlease check out our webpage at\nhttps://sites.google.com/view/automatic-prompt-engineer.\n","authors":["Yongchao Zhou","Andrei Ioan Muresanu","Ziwen Han","Keiran Paster","Silviu Pitis","Harris Chan","Jimmy Ba"],"pdf_url":"https://arxiv.org/pdf/2211.01910v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06074v1","updated":"2023-03-10T16:53:30Z","published":"2023-03-10T16:53:30Z","title":"Susceptibility to Influence of Large Language Models","summary":"  Two studies tested the hypothesis that a Large Language Model (LLM) can be\nused to model psychological change following exposure to influential input. The\nfirst study tested a generic mode of influence - the Illusory Truth Effect\n(ITE) - where earlier exposure to a statement (through, for example, rating its\ninterest) boosts a later truthfulness test rating. Data was collected from 1000\nhuman participants using an online experiment, and 1000 simulated participants\nusing engineered prompts and LLM completion. 64 ratings per participant were\ncollected, using all exposure-test combinations of the attributes: truth,\ninterest, sentiment and importance. The results for human participants\nreconfirmed the ITE, and demonstrated an absence of effect for attributes other\nthan truth, and when the same attribute is used for exposure and test. The same\npattern of effects was found for LLM-simulated participants. The second study\nconcerns a specific mode of influence - populist framing of news to increase\nits persuasion and political mobilization. Data from LLM-simulated participants\nwas collected and compared to previously published data from a 15-country\nexperiment on 7286 human participants. Several effects previously demonstrated\nfrom the human study were replicated by the simulated study, including effects\nthat surprised the authors of the human study by contradicting their\ntheoretical expectations (anti-immigrant framing of news decreases its\npersuasion and mobilization); but some significant relationships found in human\ndata (modulation of the effectiveness of populist framing according to relative\ndeprivation of the participant) were not present in the LLM data. Together the\ntwo studies support the view that LLMs have potential to act as models of the\neffect of influence.\n","authors":["Lewis D Griffin","Bennett Kleinberg","Maximilian Mozes","Kimberly T Mai","Maria Vau","Matthew Caldwell","Augustine Marvor-Parker"],"pdf_url":"https://arxiv.org/pdf/2303.06074v1.pdf","comment":"24 pages, 6 figures, 7 tables, 53 references"},{"id":"http://arxiv.org/abs/2303.06002v1","updated":"2023-03-10T16:03:19Z","published":"2023-03-10T16:03:19Z","title":"Is In-hospital Meta-information Useful for Abstractive Discharge Summary\n  Generation?","summary":"  During the patient's hospitalization, the physician must record daily\nobservations of the patient and summarize them into a brief document called\n\"discharge summary\" when the patient is discharged. Automated generation of\ndischarge summary can greatly relieve the physicians' burden, and has been\naddressed recently in the research community. Most previous studies of\ndischarge summary generation using the sequence-to-sequence architecture focus\non only inpatient notes for input. However, electric health records (EHR) also\nhave rich structured metadata (e.g., hospital, physician, disease, length of\nstay, etc.) that might be useful. This paper investigates the effectiveness of\nmedical meta-information for summarization tasks. We obtain four types of\nmeta-information from the EHR systems and encode each meta-information into a\nsequence-to-sequence model. Using Japanese EHRs, meta-information encoded\nmodels increased ROUGE-1 by up to 4.45 points and BERTScore by 3.77 points over\nthe vanilla Longformer. Also, we found that the encoded meta-information\nimproves the precisions of its related terms in the outputs. Our results showed\nthe benefit of the use of medical meta-information.\n","authors":["Kenichiro Ando","Mamoru Komachi","Takashi Okumura","Hiromasa Horiguchi","Yuji Matsumoto"],"pdf_url":"https://arxiv.org/pdf/2303.06002v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05958v1","updated":"2023-03-10T14:46:23Z","published":"2023-03-10T14:46:23Z","title":"Robust Knowledge Distillation from RNN-T Models With Noisy Training\n  Labels Using Full-Sum Loss","summary":"  This work studies knowledge distillation (KD) and addresses its constraints\nfor recurrent neural network transducer (RNN-T) models. In hard distillation, a\nteacher model transcribes large amounts of unlabelled speech to train a student\nmodel. Soft distillation is another popular KD method that distills the output\nlogits of the teacher model. Due to the nature of RNN-T alignments, applying\nsoft distillation between RNN-T architectures having different posterior\ndistributions is challenging. In addition, bad teachers having high\nword-error-rate (WER) reduce the efficacy of KD. We investigate how to\neffectively distill knowledge from variable quality ASR teachers, which has not\nbeen studied before to the best of our knowledge. We show that a sequence-level\nKD, full-sum distillation, outperforms other distillation methods for RNN-T\nmodels, especially for bad teachers. We also propose a variant of full-sum\ndistillation that distills the sequence discriminative knowledge of the teacher\nleading to further improvement in WER. We conduct experiments on public\ndatasets namely SpeechStew and LibriSpeech, and on in-house production data.\n","authors":["Mohammad Zeineldeen","Kartik Audhkhasi","Murali Karthick Baskar","Bhuvana Ramabhadran"],"pdf_url":"https://arxiv.org/pdf/2303.05958v1.pdf","comment":"Accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.05891v1","updated":"2023-03-10T12:58:34Z","published":"2023-03-10T12:58:34Z","title":"Creation and evaluation of timelines for longitudinal user posts","summary":"  There is increasing interest to work with user generated content in social\nmedia, especially textual posts over time. Currently there is no consistent way\nof segmenting user posts into timelines in a meaningful way that improves the\nquality and cost of manual annotation. Here we propose a set of methods for\nsegmenting longitudinal user posts into timelines likely to contain interesting\nmoments of change in a user's behaviour, based on their online posting\nactivity. We also propose a novel framework for evaluating timelines and show\nits applicability in the context of two different social media datasets.\nFinally, we present a discussion of the linguistic content of highly ranked\ntimelines.\n","authors":["Anthony Hills","Adam Tsakalidis","Federico Nanni","Ioannis Zachos","Maria Liakata"],"pdf_url":"https://arxiv.org/pdf/2303.05891v1.pdf","comment":"Accepted at EACL 2023 (main, long); camera-ready version"},{"id":"http://arxiv.org/abs/2208.09012v2","updated":"2023-03-10T12:32:27Z","published":"2022-08-18T18:22:42Z","title":"A Kind Introduction to Lexical and Grammatical Aspect, with a Survey of\n  Computational Approaches","summary":"  Aspectual meaning refers to how the internal temporal structure of situations\nis presented. This includes whether a situation is described as a state or as\nan event, whether the situation is finished or ongoing, and whether it is\nviewed as a whole or with a focus on a particular phase. This survey gives an\noverview of computational approaches to modeling lexical and grammatical aspect\nalong with intuitive explanations of the necessary linguistic concepts and\nterminology. In particular, we describe the concepts of stativity, telicity,\nhabituality, perfective and imperfective, as well as influential inventories of\neventuality and situation types. We argue that because aspect is a crucial\ncomponent of semantics, especially when it comes to reporting the temporal\nstructure of situations in a precise way, future NLP approaches need to be able\nto handle and evaluate it systematically in order to achieve human-level\nlanguage understanding.\n","authors":["Annemarie Friedrich","Nianwen Xue","Alexis Palmer"],"pdf_url":"https://arxiv.org/pdf/2208.09012v2.pdf","comment":"Accepted at EACL 2023, camera ready version"},{"id":"http://arxiv.org/abs/2210.07523v2","updated":"2023-03-10T12:32:16Z","published":"2022-10-14T05:10:53Z","title":"Self-Adaptive Named Entity Recognition by Retrieving Unstructured\n  Knowledge","summary":"  Although named entity recognition (NER) helps us to extract domain-specific\nentities from text (e.g., artists in the music domain), it is costly to create\na large amount of training data or a structured knowledge base to perform\naccurate NER in the target domain. Here, we propose self-adaptive NER, which\nretrieves external knowledge from unstructured text to learn the usages of\nentities that have not been learned well. To retrieve useful knowledge for NER,\nwe design an effective two-stage model that retrieves unstructured knowledge\nusing uncertain entities as queries. Our model predicts the entities in the\ninput and then finds those of which the prediction is not confident. Then, it\nretrieves knowledge by using these uncertain entities as queries and\nconcatenates the retrieved text to the original input to revise the prediction.\nExperiments on CrossNER datasets demonstrated that our model outperforms strong\nbaselines by 2.35 points in F1 metric.\n","authors":["Kosuke Nishida","Naoki Yoshinaga","Kyosuke Nishida"],"pdf_url":"https://arxiv.org/pdf/2210.07523v2.pdf","comment":"EACL2023 (long)"},{"id":"http://arxiv.org/abs/2301.03029v5","updated":"2023-03-10T11:38:05Z","published":"2023-01-08T12:33:58Z","title":"Topic Modelling of Swedish Newspaper Articles about Coronavirus: a Case\n  Study using Latent Dirichlet Allocation Method","summary":"  Topic Modelling (TM) is from the research branches of natural language\nunderstanding (NLU) and natural language processing (NLP) that is to facilitate\ninsightful analysis from large documents and datasets, such as a summarisation\nof main topics and the topic changes. This kind of discovery is getting more\npopular in real-life applications due to its impact on big data analytics. In\nthis study, from the social-media and healthcare domain, we apply popular\nLatent Dirichlet Allocation (LDA) methods to model the topic changes in Swedish\nnewspaper articles about Coronavirus. We describe the corpus we created\nincluding 6515 articles, methods applied, and statistics on topic changes over\napproximately 1 year and two months period of time from 17th January 2020 to\n13th March 2021. We hope this work can be an asset for grounding applications\nof topic modelling and can be inspiring for similar case studies in an era with\npandemics, to support socio-economic impact research as well as clinical and\nhealthcare analytics. Our data and source code are openly available at\nhttps://github. com/poethan/Swed_Covid_TM Keywords: Latent Dirichlet Allocation\n(LDA); Topic Modelling; Coronavirus; Pandemics; Natural Language Understanding;\nBERT-topic\n","authors":["Bernadeta Griciūtė","Lifeng Han","Hao Li","Goran Nenadic"],"pdf_url":"https://arxiv.org/pdf/2301.03029v5.pdf","comment":"14 pages, 14 figures"},{"id":"http://arxiv.org/abs/2301.10761v3","updated":"2023-03-10T11:04:26Z","published":"2023-01-25T18:55:05Z","title":"Fillers in Spoken Language Understanding: Computational and\n  Psycholinguistic Perspectives","summary":"  Disfluencies (i.e. interruptions in the regular flow of speech), are\nubiquitous to spoken discourse. Fillers (\"uh\", \"um\") are disfluencies that\noccur the most frequently compared to other kinds of disfluencies. Yet, to the\nbest of our knowledge, there isn't a resource that brings together the research\nperspectives influencing Spoken Language Understanding (SLU) on these speech\nevents. This aim of this article is to survey a breadth of perspectives in a\nholistic way; i.e. from considering underlying (psycho)linguistic theory, to\ntheir annotation and consideration in Automatic Speech Recognition (ASR) and\nSLU systems, to lastly, their study from a generation standpoint. This article\naims to present the perspectives in an approachable way to the SLU and\nConversational AI community, and discuss moving forward, what we believe are\nthe trends and challenges in each area.\n","authors":["Tanvi Dinkar","Chloé Clavel","Ioana Vasilescu"],"pdf_url":"https://arxiv.org/pdf/2301.10761v3.pdf","comment":"To appear in TAL Journal"},{"id":"http://arxiv.org/abs/2301.04312v3","updated":"2023-03-10T11:03:10Z","published":"2023-01-11T05:21:00Z","title":"Word-Graph2vec: An efficient word embedding approach on word\n  co-occurrence graph using random walk sampling","summary":"  Word embedding has become ubiquitous and is widely used in various text\nmining and natural language processing (NLP) tasks, such as information\nretrieval, semantic analysis, and machine translation, among many others.\nUnfortunately, it is prohibitively expensive to train the word embedding in a\nrelatively large corpus. We propose a graph-based word embedding algorithm,\ncalled Word-Graph2vec, which converts the large corpus into a word\nco-occurrence graph, then takes the word sequence samples from this graph by\nrandomly traveling and trains the word embedding on this sampling corpus in the\nend. We posit that because of the stable vocabulary, relative idioms, and fixed\nexpressions in English, the size and density of the word co-occurrence graph\nchange slightly with the increase in the training corpus. So that\nWord-Graph2vec has stable runtime on the large scale data set, and its\nperformance advantage becomes more and more obvious with the growth of the\ntraining corpus. Extensive experiments conducted on real-world datasets show\nthat the proposed algorithm outperforms traditional Skip-Gram by four-five\ntimes in terms of efficiency, while the error generated by the random walk\nsampling is small.\n","authors":["Wenting Li","Yuanzhe Cai","Jiahong Xue","Xi Zhang","Huacan Chen","Zeyu Chen"],"pdf_url":"https://arxiv.org/pdf/2301.04312v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05834v1","updated":"2023-03-10T10:21:20Z","published":"2023-03-10T10:21:20Z","title":"An algebraic approach to translating Japanese","summary":"  We use Lambek's pregroups and the framework of compositional distributional\nmodels of language (\"DisCoCat\") to study translations from Japanese to English\nas pairs of functors. Adding decorations to pregroups we show how to handle\nword order changes between languages.\n","authors":["Valentin Boboc"],"pdf_url":"https://arxiv.org/pdf/2303.05834v1.pdf","comment":"20 pages, multiple diagrams and glosses"},{"id":"http://arxiv.org/abs/2211.09733v2","updated":"2023-03-10T08:06:57Z","published":"2022-11-04T14:35:56Z","title":"BERT-Deep CNN: State-of-the-Art for Sentiment Analysis of COVID-19\n  Tweets","summary":"  The free flow of information has been accelerated by the rapid development of\nsocial media technology. There has been a significant social and psychological\nimpact on the population due to the outbreak of Coronavirus disease (COVID-19).\nThe COVID-19 pandemic is one of the current events being discussed on social\nmedia platforms. In order to safeguard societies from this pandemic, studying\npeople's emotions on social media is crucial. As a result of their particular\ncharacteristics, sentiment analysis of texts like tweets remains challenging.\nSentiment analysis is a powerful text analysis tool. It automatically detects\nand analyzes opinions and emotions from unstructured data. Texts from a wide\nrange of sources are examined by a sentiment analysis tool, which extracts\nmeaning from them, including emails, surveys, reviews, social media posts, and\nweb articles. To evaluate sentiments, natural language processing (NLP) and\nmachine learning techniques are used, which assign weights to entities, topics,\nthemes, and categories in sentences or phrases. Machine learning tools learn\nhow to detect sentiment without human intervention by examining examples of\nemotions in text. In a pandemic situation, analyzing social media texts to\nuncover sentimental trends can be very helpful in gaining a better\nunderstanding of society's needs and predicting future trends. We intend to\nstudy society's perception of the COVID-19 pandemic through social media using\nstate-of-the-art BERT and Deep CNN models. The superiority of BERT models over\nother deep models in sentiment analysis is evident and can be concluded from\nthe comparison of the various research studies mentioned in this article.\n","authors":["Javad Hassannataj Joloudari","Sadiq Hussain","Mohammad Ali Nematollahi","Rouhollah Bagheri","Fatemeh Fazl","Roohallah Alizadehsani","Reza Lashgari","Ashis Talukder"],"pdf_url":"https://arxiv.org/pdf/2211.09733v2.pdf","comment":"20 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.05759v1","updated":"2023-03-10T07:55:00Z","published":"2023-03-10T07:55:00Z","title":"An Overview on Language Models: Recent Developments and Outlook","summary":"  Language modeling studies the probability distributions over strings of\ntexts. It is one of the most fundamental tasks in natural language processing\n(NLP). It has been widely used in text generation, speech recognition, machine\ntranslation, etc. Conventional language models (CLMs) aim to predict the\nprobability of linguistic sequences in a causal manner. In contrast,\npre-trained language models (PLMs) cover broader concepts and can be used in\nboth causal sequential modeling and fine-tuning for downstream applications.\nPLMs have their own training paradigms (usually self-supervised) and serve as\nfoundation models in modern NLP systems. This overview paper provides an\nintroduction to both CLMs and PLMs from five aspects, i.e., linguistic units,\nstructures, training methods, evaluation methods, and applications.\nFurthermore, we discuss the relationship between CLMs and PLMs and shed light\non the future directions of language modeling in the pre-trained era.\n","authors":["Chengwei Wei","Yun-Cheng Wang","Bin Wang","C. -C. Jay Kuo"],"pdf_url":"https://arxiv.org/pdf/2303.05759v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05758v1","updated":"2023-03-10T07:52:28Z","published":"2023-03-10T07:52:28Z","title":"MIXPGD: Hybrid Adversarial Training for Speech Recognition Systems","summary":"  Automatic speech recognition (ASR) systems based on deep neural networks are\nweak against adversarial perturbations. We propose mixPGD adversarial training\nmethod to improve the robustness of the model for ASR systems. In standard\nadversarial training, adversarial samples are generated by leveraging\nsupervised or unsupervised methods. We merge the capabilities of both\nsupervised and unsupervised approaches in our method to generate new\nadversarial samples which aid in improving model robustness. Extensive\nexperiments and comparison across various state-of-the-art defense methods and\nadversarial attacks have been performed to show that mixPGD gains 4.1% WER of\nbetter performance than previous best performing models under white-box\nadversarial attack setting. We tested our proposed defense method against both\nwhite-box and transfer based black-box attack settings to ensure that our\ndefense strategy is robust against various types of attacks. Empirical results\non several adversarial attacks validate the effectiveness of our proposed\napproach.\n","authors":["Aminul Huq","Weiyi Zhang","Xiaolin Hu"],"pdf_url":"https://arxiv.org/pdf/2303.05758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05737v1","updated":"2023-03-10T06:46:23Z","published":"2023-03-10T06:46:23Z","title":"Clinical BERTScore: An Improved Measure of Automatic Speech Recognition\n  Performance in Clinical Settings","summary":"  Automatic Speech Recognition (ASR) in medical contexts has the potential to\nsave time, cut costs, increase report accuracy, and reduce physician burnout.\nHowever, the healthcare industry has been slower to adopt this technology, in\npart due to the importance of avoiding medically-relevant transcription\nmistakes. In this work, we present the Clinical BERTScore (CBERTScore), an ASR\nmetric that penalizes clinically-relevant mistakes more than others. We\ndemonstrate that this metric more closely aligns with clinician preferences on\nmedical sentences as compared to other metrics (WER, BLUE, METEOR, etc),\nsometimes by wide margins. We collect a benchmark of 13 clinician preferences\non 149 realistic medical sentences called the Clinician Transcript Preference\nbenchmark (CTP), demonstrate that CBERTScore more closely matches what\nclinicians prefer, and release the benchmark for the community to further\ndevelop clinically-aware ASR metrics.\n","authors":["Joel Shor","Ruyue Agnes Bi","Subhashini Venugopalan","Steven Ibara","Roman Goldenberg","Ehud Rivlen"],"pdf_url":"https://arxiv.org/pdf/2303.05737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05707v1","updated":"2023-03-10T05:22:39Z","published":"2023-03-10T05:22:39Z","title":"MuLTI: Efficient Video-and-Language Understanding with MultiWay-Sampler\n  and Multiple Choice Modeling","summary":"  Video-and-language understanding has a variety of applications in the\nindustry, such as video question answering, text-video retrieval and\nmulti-label classification. Existing video-and-language understanding methods\ngenerally adopt heavy multi-modal encoders and feature fusion modules, which\nconsume large amounts of GPU memory. Especially, they have difficulty dealing\nwith dense video frames or long text that are prevalent in industrial\napplications. In this paper, we propose MuLTI, a highly accurate and\nmemory-efficient video-and-language understanding model that achieves efficient\nand effective feature fusion through feature sampling and attention modules.\nTherefore, MuLTI can handle longer sequences with limited GPU memory. Then, we\nintroduce an attention-based adapter to the encoders, which finetunes the\nshallow features to improve the model's performance with low GPU memory\nconsumption. Finally, to further improve the model's performance, we introduce\na new pretraining task named Multiple Choice Modeling to bridge the task gap\nbetween pretraining and downstream tasks and enhance the model's ability to\nalign the video and the text. Benefiting from the efficient feature fusion\nmodule, the attention-based adapter and the new pretraining task, MuLTI\nachieves state-of-the-art performance on multiple datasets. Implementation and\npretrained models will be released.\n","authors":["Jiaqi Xu","Bo Liu","Yunkuo Chen","Mengli Cheng","Xing Shi"],"pdf_url":"https://arxiv.org/pdf/2303.05707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08233v2","updated":"2023-03-10T04:11:56Z","published":"2022-11-14T13:35:01Z","title":"Temporal Modeling Matters: A Novel Temporal Emotional Modeling Approach\n  for Speech Emotion Recognition","summary":"  Speech emotion recognition (SER) plays a vital role in improving the\ninteractions between humans and machines by inferring human emotion and\naffective states from speech signals. Whereas recent works primarily focus on\nmining spatiotemporal information from hand-crafted features, we explore how to\nmodel the temporal patterns of speech emotions from dynamic temporal scales.\nTowards that goal, we introduce a novel temporal emotional modeling approach\nfor SER, termed Temporal-aware bI-direction Multi-scale Network (TIM-Net),\nwhich learns multi-scale contextual affective representations from various time\nscales. Specifically, TIM-Net first employs temporal-aware blocks to learn\ntemporal affective representation, then integrates complementary information\nfrom the past and the future to enrich contextual representations, and finally,\nfuses multiple time scale features for better adaptation to the emotional\nvariation. Extensive experimental results on six benchmark SER datasets\ndemonstrate the superior performance of TIM-Net, gaining 2.34% and 2.61%\nimprovements of the average UAR and WAR over the second-best on each corpus.\nThe source code is available at https://github.com/Jiaxin-Ye/TIM-Net_SER.\n","authors":["Jiaxin Ye","Xin-cheng Wen","Yujie Wei","Yong Xu","Kunhong Liu","Hongming Shan"],"pdf_url":"https://arxiv.org/pdf/2211.08233v2.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.05670v1","updated":"2023-03-10T02:52:13Z","published":"2023-03-10T02:52:13Z","title":"Logic Against Bias: Textual Entailment Mitigates Stereotypical Sentence\n  Reasoning","summary":"  Due to their similarity-based learning objectives, pretrained sentence\nencoders often internalize stereotypical assumptions that reflect the social\nbiases that exist within their training corpora. In this paper, we describe\nseveral kinds of stereotypes concerning different communities that are present\nin popular sentence representation models, including pretrained next sentence\nprediction and contrastive sentence representation models. We compare such\nmodels to textual entailment models that learn language logic for a variety of\ndownstream language understanding tasks. By comparing strong pretrained models\nbased on text similarity with textual entailment learning, we conclude that the\nexplicit logic learning with textual entailment can significantly reduce bias\nand improve the recognition of social communities, without an explicit\nde-biasing process\n","authors":["Hongyin Luo","James Glass"],"pdf_url":"https://arxiv.org/pdf/2303.05670v1.pdf","comment":"Accepted by EACL 2023"},{"id":"http://arxiv.org/abs/2303.03387v2","updated":"2023-03-10T02:09:29Z","published":"2023-03-02T17:30:43Z","title":"CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a\n  Context Synergized Hyperbolic Network","summary":"  The tremendous growth of social media users interacting in online\nconversations has also led to significant growth in hate speech. Most of the\nprior works focus on detecting explicit hate speech, which is overt and\nleverages hateful phrases, with very little work focusing on detecting hate\nspeech that is implicit or denotes hatred through indirect or coded language.\nIn this paper, we present CoSyn, a user- and conversational-context synergized\nnetwork for detecting implicit hate speech in online conversation trees. CoSyn\nfirst models the user's personal historical and social context using a novel\nhyperbolic Fourier attention mechanism and hyperbolic graph convolution\nnetwork. Next, we jointly model the user's personal context and the\nconversational context using a novel context interaction mechanism in the\nhyperbolic space that clearly captures the interplay between the two and makes\nindependent assessments on the amounts of information to be retrieved from both\ncontexts. CoSyn performs all operations in the hyperbolic space to account for\nthe scale-free dynamics of social media. We demonstrate the effectiveness of\nCoSyn both qualitatively and quantitatively on an open-source hate speech\ndataset with Twitter conversations and show that CoSyn outperforms all our\nbaselines in detecting implicit hate speech with absolute improvements in the\nrange of 8.15% - 19.50%.\n","authors":["Sreyan Ghosh","Manan Suri","Purva Chiniya","Utkarsh Tyagi","Sonal Kumar","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2303.03387v2.pdf","comment":"Under review at IJCAI 2023"},{"id":"http://arxiv.org/abs/2105.11115v2","updated":"2023-03-10T01:23:57Z","published":"2021-05-24T06:42:58Z","title":"Self-Attention Networks Can Process Bounded Hierarchical Languages","summary":"  Despite their impressive performance in NLP, self-attention networks were\nrecently proved to be limited for processing formal languages with hierarchical\nstructure, such as $\\mathsf{Dyck}_k$, the language consisting of well-nested\nparentheses of $k$ types. This suggested that natural language can be\napproximated well with models that are too weak for formal languages, or that\nthe role of hierarchy and recursion in natural language might be limited. We\nqualify this implication by proving that self-attention networks can process\n$\\mathsf{Dyck}_{k, D}$, the subset of $\\mathsf{Dyck}_{k}$ with depth bounded by\n$D$, which arguably better captures the bounded hierarchical structure of\nnatural language. Specifically, we construct a hard-attention network with\n$D+1$ layers and $O(\\log k)$ memory size (per token per layer) that recognizes\n$\\mathsf{Dyck}_{k, D}$, and a soft-attention network with two layers and\n$O(\\log k)$ memory size that generates $\\mathsf{Dyck}_{k, D}$. Experiments show\nthat self-attention networks trained on $\\mathsf{Dyck}_{k, D}$ generalize to\nlonger inputs with near-perfect accuracy, and also verify the theoretical\nmemory advantage of self-attention networks over recurrent networks.\n","authors":["Shunyu Yao","Binghui Peng","Christos Papadimitriou","Karthik Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2105.11115v2.pdf","comment":"ACL 2021. 19 pages with extended appendix. v2 fixed a small typo in\n  the formula at the end of page 5 (thank to Gabriel Faria). Code:\n  https://github.com/princeton-nlp/dyck-transformer"},{"id":"http://arxiv.org/abs/2210.03629v3","updated":"2023-03-10T01:00:17Z","published":"2022-10-06T01:00:32Z","title":"ReAct: Synergizing Reasoning and Acting in Language Models","summary":"  While large language models (LLMs) have demonstrated impressive capabilities\nacross tasks in language understanding and interactive decision making, their\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\naction plan generation) have primarily been studied as separate topics. In this\npaper, we explore the use of LLMs to generate both reasoning traces and\ntask-specific actions in an interleaved manner, allowing for greater synergy\nbetween the two: reasoning traces help the model induce, track, and update\naction plans as well as handle exceptions, while actions allow it to interface\nwith external sources, such as knowledge bases or environments, to gather\nadditional information. We apply our approach, named ReAct, to a diverse set of\nlanguage and decision making tasks and demonstrate its effectiveness over\nstate-of-the-art baselines, as well as improved human interpretability and\ntrustworthiness over methods without reasoning or acting components.\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\nReAct overcomes issues of hallucination and error propagation prevalent in\nchain-of-thought reasoning by interacting with a simple Wikipedia API, and\ngenerates human-like task-solving trajectories that are more interpretable than\nbaselines without reasoning traces. On two interactive decision making\nbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\nreinforcement learning methods by an absolute success rate of 34% and 10%\nrespectively, while being prompted with only one or two in-context examples.\nProject site with code: https://react-lm.github.io\n","authors":["Shunyu Yao","Jeffrey Zhao","Dian Yu","Nan Du","Izhak Shafran","Karthik Narasimhan","Yuan Cao"],"pdf_url":"https://arxiv.org/pdf/2210.03629v3.pdf","comment":"v3 is the ICLR camera ready version with some typos fixed. Project\n  site with code: https://react-lm.github.io"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.06146v1","updated":"2023-03-10T18:59:33Z","published":"2023-03-10T18:59:33Z","title":"StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces","summary":"  Recent advances in face manipulation using StyleGAN have produced impressive\nresults. However, StyleGAN is inherently limited to cropped aligned faces at a\nfixed image resolution it is pre-trained on. In this paper, we propose a simple\nand effective solution to this limitation by using dilated convolutions to\nrescale the receptive fields of shallow layers in StyleGAN, without altering\nany model parameters. This allows fixed-size small features at shallow layers\nto be extended into larger ones that can accommodate variable resolutions,\nmaking them more robust in characterizing unaligned faces. To enable real face\ninversion and manipulation, we introduce a corresponding encoder that provides\nthe first-layer feature of the extended StyleGAN in addition to the latent\nstyle code. We validate the effectiveness of our method using unaligned face\ninputs of various resolutions in a diverse set of face manipulation tasks,\nincluding facial attribute editing, super-resolution, sketch/mask-to-face\ntranslation, and face toonification.\n","authors":["Shuai Yang","Liming Jiang","Ziwei Liu","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2303.06146v1.pdf","comment":"Code: https://github.com/williamyang1991/StyleGANEX Project page:\n  https://www.mmlab-ntu.com/project/styleganex/"},{"id":"http://arxiv.org/abs/2303.06145v1","updated":"2023-03-10T18:59:10Z","published":"2023-03-10T18:59:10Z","title":"Learning to Select Camera Views: Efficient Multiview Understanding at\n  Few Glances","summary":"  Multiview camera setups have proven useful in many computer vision\napplications for reducing ambiguities, mitigating occlusions, and increasing\nfield-of-view coverage. However, the high computational cost associated with\nmultiple views poses a significant challenge for end devices with limited\ncomputational resources. To address this issue, we propose a view selection\napproach that analyzes the target object or scenario from given views and\nselects the next best view for processing. Our approach features a\nreinforcement learning based camera selection module, MVSelect, that not only\nselects views but also facilitates joint training with the task network.\nExperimental results on multiview classification and detection tasks show that\nour approach achieves promising performance while using only 2 or 3 out of N\navailable views, significantly reducing computational costs. Furthermore,\nanalysis on the selected views reveals that certain cameras can be shut off\nwith minimal performance impact, shedding light on future camera layout\noptimization for multiview systems. Code is available at\nhttps://github.com/hou-yz/MVSelect.\n","authors":["Yunzhong Hou","Stephen Gould","Liang Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.06145v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06138v1","updated":"2023-03-10T18:55:46Z","published":"2023-03-10T18:55:46Z","title":"Learning Object-Centric Neural Scattering Functions for Free-viewpoint\n  Relighting and Scene Composition","summary":"  Photorealistic object appearance modeling from 2D images is a constant topic\nin vision and graphics. While neural implicit methods (such as Neural Radiance\nFields) have shown high-fidelity view synthesis results, they cannot relight\nthe captured objects. More recent neural inverse rendering approaches have\nenabled object relighting, but they represent surface properties as simple\nBRDFs, and therefore cannot handle translucent objects. We propose\nObject-Centric Neural Scattering Functions (OSFs) for learning to reconstruct\nobject appearance from only images. OSFs not only support free-viewpoint object\nrelighting, but also can model both opaque and translucent objects. While\naccurately modeling subsurface light transport for translucent objects can be\nhighly complex and even intractable for neural methods, OSFs learn to\napproximate the radiance transfer from a distant light to an outgoing direction\nat any spatial location. This approximation avoids explicitly modeling complex\nsubsurface scattering, making learning a neural implicit model tractable.\nExperiments on real and synthetic data show that OSFs accurately reconstruct\nappearances for both opaque and translucent objects, allowing faithful\nfree-viewpoint relighting as well as scene composition.\n","authors":["Hong-Xing Yu","Michelle Guo","Alireza Fathi","Yen-Yu Chang","Eric Ryan Chan","Ruohan Gao","Thomas Funkhouser","Jiajun Wu"],"pdf_url":"https://arxiv.org/pdf/2303.06138v1.pdf","comment":"Journal extension of arXiv:2012.08503. The first two authors\n  contributed equally to this work"},{"id":"http://arxiv.org/abs/2303.06129v1","updated":"2023-03-10T18:48:40Z","published":"2023-03-10T18:48:40Z","title":"Single-branch Network for Multimodal Training","summary":"  With the rapid growth of social media platforms, users are sharing billions\nof multimedia posts containing audio, images, and text. Researchers have\nfocused on building autonomous systems capable of processing such multimedia\ndata to solve challenging multimodal tasks including cross-modal retrieval,\nmatching, and verification. Existing works use separate networks to extract\nembeddings of each modality to bridge the gap between them. The modular\nstructure of their branched networks is fundamental in creating numerous\nmultimodal applications and has become a defacto standard to handle multiple\nmodalities. In contrast, we propose a novel single-branch network capable of\nlearning discriminative representation of unimodal as well as multimodal tasks\nwithout changing the network. An important feature of our single-branch network\nis that it can be trained either using single or multiple modalities without\nsacrificing performance. We evaluated our proposed single-branch network on the\nchallenging multimodal problem (face-voice association) for cross-modal\nverification and matching tasks with various loss formulations. Experimental\nresults demonstrate the superiority of our proposed single-branch network over\nthe existing methods in a wide range of experiments. Code:\nhttps://github.com/msaadsaeed/SBNet\n","authors":["Muhammad Saad Saeed","Shah Nawaz","Muhammad Haris Khan","Muhammad Zaigham Zaheer","Karthik Nandakumar","Muhammad Haroon Yousaf","Arif Mahmood"],"pdf_url":"https://arxiv.org/pdf/2303.06129v1.pdf","comment":"Accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.06124v1","updated":"2023-03-10T18:37:43Z","published":"2023-03-10T18:37:43Z","title":"Self-supervised Training Sample Difficulty Balancing for Local\n  Descriptor Learning","summary":"  In the case of an imbalance between positive and negative samples, hard\nnegative mining strategies have been shown to help models learn more subtle\ndifferences between positive and negative samples, thus improving recognition\nperformance. However, if too strict mining strategies are promoted in the\ndataset, there may be a risk of introducing false negative samples. Meanwhile,\nthe implementation of the mining strategy disrupts the difficulty distribution\nof samples in the real dataset, which may cause the model to over-fit these\ndifficult samples. Therefore, in this paper, we investigate how to trade off\nthe difficulty of the mined samples in order to obtain and exploit high-quality\nnegative samples, and try to solve the problem in terms of both the loss\nfunction and the training strategy. The proposed balance loss provides an\neffective discriminant for the quality of negative samples by combining a\nself-supervised approach to the loss function, and uses a dynamic gradient\nmodulation strategy to achieve finer gradient adjustment for samples of\ndifferent difficulties. The proposed annealing training strategy then\nconstrains the difficulty of the samples drawn from negative sample mining to\nprovide data sources with different difficulty distributions for the loss\nfunction, and uses samples of decreasing difficulty to train the model.\nExtensive experiments show that our new descriptors outperform previous\nstate-of-the-art descriptors for patch validation, matching, and retrieval\ntasks.\n","authors":["Jiahan Zhang","Dayong Tian"],"pdf_url":"https://arxiv.org/pdf/2303.06124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1905.13543v3","updated":"2023-03-10T18:30:42Z","published":"2019-05-28T06:35:52Z","title":"DDPNAS: Efficient Neural Architecture Search via Dynamic Distribution\n  Pruning","summary":"  Neural Architecture Search (NAS) has demonstrated state-of-the-art\nperformance on various computer vision tasks. Despite the superior performance\nachieved, the efficiency and generality of existing methods are highly valued\ndue to their high computational complexity and low generality. In this paper,\nwe propose an efficient and unified NAS framework termed DDPNAS via dynamic\ndistribution pruning, facilitating a theoretical bound on accuracy and\nefficiency. In particular, we first sample architectures from a joint\ncategorical distribution. Then the search space is dynamically pruned and its\ndistribution is updated every few epochs. With the proposed efficient network\ngeneration method, we directly obtain the optimal neural architectures on given\nconstraints, which is practical for on-device models across diverse search\nspaces and constraints. The architectures searched by our method achieve\nremarkable top-1 accuracies, 97.56 and 77.2 on CIFAR-10 and ImageNet (mobile\nsettings), respectively, with the fastest search process, i.e., only 1.8 GPU\nhours on a Tesla V100. Codes for searching and network generation are available\nat: https://openi.pcl.ac.cn/PCL AutoML/XNAS.\n","authors":["Xiawu Zheng","Chenyi Yang","Shaokun Zhang","Yan Wang","Baochang Zhang","Yongjian Wu","Yunsheng Wu","Ling Shao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/1905.13543v3.pdf","comment":"A update version of this work. 19 pages"},{"id":"http://arxiv.org/abs/2301.10418v2","updated":"2023-03-10T18:17:34Z","published":"2023-01-25T05:56:53Z","title":"DEJA VU: Continual Model Generalization For Unseen Domains","summary":"  In real-world applications, deep learning models often run in non-stationary\nenvironments where the target data distribution continually shifts over time.\nThere have been numerous domain adaptation (DA) methods in both online and\noffline modes to improve cross-domain adaptation ability. However, these DA\nmethods typically only provide good performance after a long period of\nadaptation, and perform poorly on new domains before and during adaptation - in\nwhat we call the \"Unfamiliar Period\", especially when domain shifts happen\nsuddenly and significantly. On the other hand, domain generalization (DG)\nmethods have been proposed to improve the model generalization ability on\nunadapted domains. However, existing DG works are ineffective for continually\nchanging domains due to severe catastrophic forgetting of learned knowledge. To\novercome these limitations of DA and DG in handling the Unfamiliar Period\nduring continual domain shift, we propose RaTP, a framework that focuses on\nimproving models' target domain generalization (TDG) capability, while also\nachieving effective target domain adaptation (TDA) capability right after\ntraining on certain domains and forgetting alleviation (FA) capability on past\ndomains. RaTP includes a training-free data augmentation module to prepare data\nfor TDG, a novel pseudo-labeling mechanism to provide reliable supervision for\nTDA, and a prototype contrastive alignment algorithm to align different domains\nfor achieving TDG, TDA and FA. Extensive experiments on Digits, PACS, and\nDomainNet demonstrate that RaTP significantly outperforms state-of-the-art\nworks from Continual DA, Source-Free DA, Test-Time/Online DA, Single DG,\nMultiple DG and Unified DA&DG in TDG, and achieves comparable TDA and FA\ncapabilities.\n","authors":["Chenxi Liu","Lixu Wang","Lingjuan Lyu","Chen Sun","Xiao Wang","Qi Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.10418v2.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03361v2","updated":"2023-03-10T17:47:57Z","published":"2023-03-06T18:48:18Z","title":"Nerflets: Local Radiance Fields for Efficient Structure-Aware 3D Scene\n  Representation from 2D Supervision","summary":"  We address efficient and structure-aware 3D scene representation from images.\nNerflets are our key contribution -- a set of local neural radiance fields that\ntogether represent a scene. Each nerflet maintains its own spatial position,\norientation, and extent, within which it contributes to panoptic, density, and\nradiance reconstructions. By leveraging only photometric and inferred panoptic\nimage supervision, we can directly and jointly optimize the parameters of a set\nof nerflets so as to form a decomposed representation of the scene, where each\nobject instance is represented by a group of nerflets. During experiments with\nindoor and outdoor environments, we find that nerflets: (1) fit and approximate\nthe scene more efficiently than traditional global NeRFs, (2) allow the\nextraction of panoptic and photometric renderings from arbitrary views, and (3)\nenable tasks rare for NeRFs, such as 3D panoptic segmentation and interactive\nediting.\n","authors":["Xiaoshuai Zhang","Abhijit Kundu","Thomas Funkhouser","Leonidas Guibas","Hao Su","Kyle Genova"],"pdf_url":"https://arxiv.org/pdf/2303.03361v2.pdf","comment":"accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2209.06119v4","updated":"2023-03-10T17:31:32Z","published":"2022-09-10T14:26:04Z","title":"APTx: better activation function than MISH, SWISH, and ReLU's variants\n  used in deep learning","summary":"  Activation Functions introduce non-linearity in the deep neural networks.\nThis nonlinearity helps the neural networks learn faster and efficiently from\nthe dataset. In deep learning, many activation functions are developed and used\nbased on the type of problem statement. ReLU's variants, SWISH, and MISH are\ngoto activation functions. MISH function is considered having similar or even\nbetter performance than SWISH, and much better than ReLU. In this paper, we\npropose an activation function named APTx which behaves similar to MISH, but\nrequires lesser mathematical operations to compute. The lesser computational\nrequirements of APTx does speed up the model training, and thus also reduces\nthe hardware requirement for the deep learning model.\n","authors":["Ravin Kumar"],"pdf_url":"https://arxiv.org/pdf/2209.06119v4.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.06088v1","updated":"2023-03-10T17:09:04Z","published":"2023-03-10T17:09:04Z","title":"Improving Domain-Invariance in Self-Supervised Learning via Batch Styles\n  Standardization","summary":"  The recent rise of Self-Supervised Learning (SSL) as one of the preferred\nstrategies for learning with limited labeled data, and abundant unlabeled data\nhas led to the widespread use of these models. They are usually pretrained,\nfinetuned, and evaluated on the same data distribution, i.e., within an\nin-distribution setting. However, they tend to perform poorly in\nout-of-distribution evaluation scenarios, a challenge that Unsupervised Domain\nGeneralization (UDG) seeks to address.\n  This paper introduces a novel method to standardize the styles of images in a\nbatch. Batch styles standardization, relying on Fourier-based augmentations,\npromotes domain invariance in SSL by preventing spurious correlations from\nleaking into the features. The combination of batch styles standardization with\nthe well-known contrastive-based method SimCLR leads to a novel UDG method\nnamed CLaSSy ($\\textbf{C}$ontrastive $\\textbf{L}$e$\\textbf{a}$rning with\n$\\textbf{S}$tandardized $\\textbf{S}$t$\\textbf{y}$les). CLaSSy offers serious\nadvantages over prior methods, as it does not rely on domain labels and is\nscalable to handle a large number of domains. Experimental results on various\nUDG datasets demonstrate the superior performance of CLaSSy compared to\nexisting UDG methods. Finally, the versatility of the proposed batch styles\nstandardization is demonstrated by extending respectively the contrastive-based\nand non-contrastive-based SSL methods, SWaV and MSN, while considering\ndifferent backbone architectures (convolutional-based, transformers-based).\n","authors":["Marin Scalbert","Maria Vakalopoulou","Florent Couzinié-Devy"],"pdf_url":"https://arxiv.org/pdf/2303.06088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06080v1","updated":"2023-03-10T16:59:24Z","published":"2023-03-10T16:59:24Z","title":"Communication-Critical Planning via Multi-Agent Trajectory Exchange","summary":"  This paper addresses the task of joint multi-agent perception and planning,\nespecially as it relates to the real-world challenge of collision-free\nnavigation for connected self-driving vehicles. For this task, several\ncommunication-enabled vehicles must navigate through a busy intersection while\navoiding collisions with each other and with obstacles. To this end, this paper\nproposes a learnable costmap-based planning mechanism, given raw perceptual\ndata, that is (1) distributed, (2) uncertainty-aware, and (3)\nbandwidth-efficient. Our method produces a costmap and uncertainty-aware\nentropy map to sort and fuse candidate trajectories as evaluated across\nmultiple-agents. The proposed method demonstrates several favorable performance\ntrends on a suite of open-source overhead datasets as well as within a novel\ncommunication-critical simulator. It produces accurate semantic occupancy\nforecasts as an intermediate perception output, attaining a 72.5% average\npixel-wise classification accuracy. By selecting the top trajectory, the\nmulti-agent method scales well with the number of agents, reducing the hard\ncollision rate by up to 57% with eight agents compared to the single-agent\nversion.\n","authors":["Nathaniel Moore Glaser","Zsolt Kira"],"pdf_url":"https://arxiv.org/pdf/2303.06080v1.pdf","comment":"Accepted to ICRA 2023"},{"id":"http://arxiv.org/abs/2303.06075v1","updated":"2023-03-10T16:53:51Z","published":"2023-03-10T16:53:51Z","title":"Long-tailed Classification from a Bayesian-decision-theory Perspective","summary":"  Long-tailed classification poses a challenge due to its heavy imbalance in\nclass probabilities and tail-sensitivity risks with asymmetric misprediction\ncosts. Recent attempts have used re-balancing loss and ensemble methods, but\nthey are largely heuristic and depend heavily on empirical results, lacking\ntheoretical explanation. Furthermore, existing methods overlook the decision\nloss, which characterizes different costs associated with tailed classes. This\npaper presents a general and principled framework from a\nBayesian-decision-theory perspective, which unifies existing techniques\nincluding re-balancing and ensemble methods, and provides theoretical\njustifications for their effectiveness. From this perspective, we derive a\nnovel objective based on the integrated risk and a Bayesian deep-ensemble\napproach to improve the accuracy of all classes, especially the ``tail\".\nBesides, our framework allows for task-adaptive decision loss which provides\nprovably optimal decisions in varying task scenarios, along with the capability\nto quantify uncertainty. Finally, We conduct comprehensive experiments,\nincluding standard classification, tail-sensitive classification with a new\nFalse Head Rate metric, calibration, and ablation studies. Our framework\nsignificantly improves the current SOTA even on large-scale real-world datasets\nlike ImageNet.\n","authors":["Bolian Li","Ruqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.06075v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06042v1","updated":"2023-03-10T16:31:31Z","published":"2023-03-10T16:31:31Z","title":"MVImgNet: A Large-scale Dataset of Multi-view Images","summary":"  Being data-driven is one of the most iconic properties of deep learning\nalgorithms. The birth of ImageNet drives a remarkable trend of \"learning from\nlarge-scale data\" in computer vision. Pretraining on ImageNet to obtain rich\nuniversal representations has been manifested to benefit various 2D visual\ntasks, and becomes a standard in 2D vision. However, due to the laborious\ncollection of real-world 3D data, there is yet no generic dataset serving as a\ncounterpart of ImageNet in 3D vision, thus how such a dataset can impact the 3D\ncommunity is unraveled. To remedy this defect, we introduce MVImgNet, a\nlarge-scale dataset of multi-view images, which is highly convenient to gain by\nshooting videos of real-world objects in human daily life. It contains 6.5\nmillion frames from 219,188 videos crossing objects from 238 classes, with rich\nannotations of object masks, camera parameters, and point clouds. The\nmulti-view attribute endows our dataset with 3D-aware signals, making it a soft\nbridge between 2D and 3D vision.\n  We conduct pilot studies for probing the potential of MVImgNet on a variety\nof 3D and 2D visual tasks, including radiance field reconstruction, multi-view\nstereo, and view-consistent image understanding, where MVImgNet demonstrates\npromising performance, remaining lots of possibilities for future explorations.\n  Besides, via dense reconstruction on MVImgNet, a 3D object point cloud\ndataset is derived, called MVPNet, covering 87,200 samples from 150 categories,\nwith the class label on each point cloud. Experiments show that MVPNet can\nbenefit the real-world 3D object classification while posing new challenges to\npoint cloud understanding.\n  MVImgNet and MVPNet will be publicly available, hoping to inspire the broader\nvision community.\n","authors":["Xianggang Yu","Mutian Xu","Yidan Zhang","Haolin Liu","Chongjie Ye","Yushuang Wu","Zizheng Yan","Chenming Zhu","Zhangyang Xiong","Tianyou Liang","Guanying Chen","Shuguang Cui","Xiaoguang Han"],"pdf_url":"https://arxiv.org/pdf/2303.06042v1.pdf","comment":"To be appear in CVPR2023. Project page:\n  https://gaplab.cuhk.edu.cn/projects/MVImgNet/"},{"id":"http://arxiv.org/abs/2303.06040v1","updated":"2023-03-10T16:30:09Z","published":"2023-03-10T16:30:09Z","title":"Importance of Aligning Training Strategy with Evaluation for Diffusion\n  Models in 3D Multiclass Segmentation","summary":"  Recently, denoising diffusion probabilistic models (DDPM) have been applied\nto image segmentation by generating segmentation masks conditioned on images,\nwhile the applications were mainly limited to 2D networks without exploiting\npotential benefits from the 3D formulation. In this work, for the first time,\nDDPMs are used for 3D multiclass image segmentation. We make three key\ncontributions that all focus on aligning the training strategy with the\nevaluation methodology, and improving efficiency. Firstly, the model predicts\nsegmentation masks instead of sampled noise and is optimised directly via Dice\nloss. Secondly, the predicted mask in the previous time step is recycled to\ngenerate noise-corrupted masks to reduce information leakage. Finally, the\ndiffusion process during training was reduced to five steps, the same as the\nevaluation. Through studies on two large multiclass data sets (prostate MR and\nabdominal CT), we demonstrated significantly improved performance compared to\nexisting DDPMs, and reached competitive performance with non-diffusion\nsegmentation models, based on U-net, within the same compute budget. The\nJAX-based diffusion framework has been released on\nhttps://github.com/mathpluscode/ImgX-DiffSeg.\n","authors":["Yunguan Fu","Yiwen Li","Shaheer U. Saeed","Matthew J. Clarkson","Yipeng Hu"],"pdf_url":"https://arxiv.org/pdf/2303.06040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01340v3","updated":"2023-03-10T16:23:19Z","published":"2022-11-02T17:48:52Z","title":"POLICE: Provably Optimal Linear Constraint Enforcement for Deep Neural\n  Networks","summary":"  Deep Neural Networks (DNNs) outshine alternative function approximators in\nmany settings thanks to their modularity in composing any desired\ndifferentiable operator. The formed parametrized functional is then tuned to\nsolve a task at hand from simple gradient descent. This modularity comes at the\ncost of making strict enforcement of constraints on DNNs, e.g. from a priori\nknowledge of the task, or from desired physical properties, an open challenge.\nIn this paper we propose the first provable affine constraint enforcement\nmethod for DNNs that only requires minimal changes into a given DNN's\nforward-pass, that is computationally friendly, and that leaves the\noptimization of the DNN's parameter to be unconstrained, i.e. standard\ngradient-based method can be employed. Our method does not require any sampling\nand provably ensures that the DNN fulfills the affine constraint on a given\ninput space's region at any point during training, and testing. We coin this\nmethod POLICE, standing for Provably Optimal LInear Constraint Enforcement.\nGithub: https://github.com/RandallBalestriero/POLICE\n","authors":["Randall Balestriero","Yann LeCun"],"pdf_url":"https://arxiv.org/pdf/2211.01340v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06015v1","updated":"2023-03-10T16:19:34Z","published":"2023-03-10T16:19:34Z","title":"Dynamic Y-KD: A Hybrid Approach to Continual Instance Segmentation","summary":"  Despite the success of deep learning methods on instance segmentation, these\nmodels still suffer from catastrophic forgetting in continual learning\nscenarios. In this paper, our contributions for continual instance segmentation\nare threefold. First, we propose the Y-knowledge distillation (Y-KD), a\nknowledge distillation strategy that shares a common feature extractor between\nthe teacher and student networks. As the teacher is also updated with new data\nin Y-KD, the increased plasticity results in new modules that are specialized\non new classes. Second, our Y-KD approach is supported by a dynamic\narchitecture method that grows new modules for each task and uses all of them\nfor inference with a unique instance segmentation head, which significantly\nreduces forgetting. Third, we complete our approach by leveraging checkpoint\naveraging as a simple method to manually balance the trade-off between the\nperformance on the various sets of classes, thus increasing the control over\nthe model's behavior without any additional cost. These contributions are\nunited in our model that we name the Dynamic Y-KD network.\n  We perform extensive experiments on several single-step and multi-steps\nscenarios on Pascal-VOC, and we show that our approach outperforms previous\nmethods both on past and new classes. For instance, compared to recent work,\nour method obtains +2.1% mAP on old classes in 15-1, +7.6% mAP on new classes\nin 19-1 and reaches 91.5% of the mAP obtained by joint-training on all classes\nin 15-5.\n","authors":["Mathieu Pagé-Fortin","Brahim Chaib-draa"],"pdf_url":"https://arxiv.org/pdf/2303.06015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14491v2","updated":"2023-03-10T16:07:51Z","published":"2022-11-26T06:17:21Z","title":"Human-machine Interactive Tissue Prototype Learning for Label-efficient\n  Histopathology Image Segmentation","summary":"  Recently, deep neural networks have greatly advanced histopathology image\nsegmentation but usually require abundant annotated data. However, due to the\ngigapixel scale of whole slide images and pathologists' heavy daily workload,\nobtaining pixel-level labels for supervised learning in clinical practice is\noften infeasible. Alternatively, weakly-supervised segmentation methods have\nbeen explored with less laborious image-level labels, but their performance is\nunsatisfactory due to the lack of dense supervision. Inspired by the recent\nsuccess of self-supervised learning methods, we present a label-efficient\ntissue prototype dictionary building pipeline and propose to use the obtained\nprototypes to guide histopathology image segmentation. Particularly, taking\nadvantage of self-supervised contrastive learning, an encoder is trained to\nproject the unlabeled histopathology image patches into a discriminative\nembedding space where these patches are clustered to identify the tissue\nprototypes by efficient pathologists' visual examination. Then, the encoder is\nused to map the images into the embedding space and generate pixel-level pseudo\ntissue masks by querying the tissue prototype dictionary. Finally, the pseudo\nmasks are used to train a segmentation network with dense supervision for\nbetter performance. Experiments on two public datasets demonstrate that our\nhuman-machine interactive tissue prototype learning method can achieve\ncomparable segmentation performance as the fully-supervised baselines with less\nannotation burden and outperform other weakly-supervised methods. Codes will be\navailable upon publication.\n","authors":["Wentao Pan","Jiangpeng Yan","Hanbo Chen","Jiawei Yang","Zhe Xu","Xiu Li","Jianhua Yao"],"pdf_url":"https://arxiv.org/pdf/2211.14491v2.pdf","comment":"IPMI2023 camera ready"},{"id":"http://arxiv.org/abs/2303.05998v1","updated":"2023-03-10T16:01:30Z","published":"2023-03-10T16:01:30Z","title":"Combining visibility analysis and deep learning for refinement of\n  semantic 3D building models by conflict classification","summary":"  Semantic 3D building models are widely available and used in numerous\napplications. Such 3D building models display rich semantics but no fa\\c{c}ade\nopenings, chiefly owing to their aerial acquisition techniques. Hence, refining\nmodels' fa\\c{c}ades using dense, street-level, terrestrial point clouds seems a\npromising strategy. In this paper, we propose a method of combining visibility\nanalysis and neural networks for enriching 3D models with window and door\nfeatures. In the method, occupancy voxels are fused with classified point\nclouds, which provides semantics to voxels. Voxels are also used to identify\nconflicts between laser observations and 3D models. The semantic voxels and\nconflicts are combined in a Bayesian network to classify and delineate\nfa\\c{c}ade openings, which are reconstructed using a 3D model library.\nUnaffected building semantics is preserved while the updated one is added,\nthereby upgrading the building model to LoD3. Moreover, Bayesian network\nresults are back-projected onto point clouds to improve points' classification\naccuracy. We tested our method on a municipal CityGML LoD2 repository and the\nopen point cloud datasets: TUM-MLS-2016 and TUM-FA\\c{C}ADE. Validation results\nrevealed that the method improves the accuracy of point cloud semantic\nsegmentation and upgrades buildings with fa\\c{c}ade elements. The method can be\napplied to enhance the accuracy of urban simulations and facilitate the\ndevelopment of semantic segmentation algorithms.\n","authors":["Olaf Wysocki","Eleonora Grilli","Ludwig Hoegner","Uwe Stilla"],"pdf_url":"https://arxiv.org/pdf/2303.05998v1.pdf","comment":"ISPRS Annals, 3DGeoInfo 2022, Australia, Sydney"},{"id":"http://arxiv.org/abs/2303.05983v1","updated":"2023-03-10T15:35:11Z","published":"2023-03-10T15:35:11Z","title":"New Benchmarks for Accountable Text-based Visual Re-creation","summary":"  Given a command, humans can directly execute the action after thinking or\nchoose to reject it, with reasonable feedback at the same time. However, the\nbehavior of existing text-to-image generation methods are uncontrollable and\nirresponsible. In this paper, we construct extensive experiments to verify\nwhether they can be accountable (say no and explain why) for those prohibited\ninstructions. To this end, we define a novel text-based visual re-creation task\nand construct new synthetic CLEVR-NOT dataset (620K) and manually pictured\nFruit-NOT dataset (50K). In our method, one text-image pair as the query is fed\ninto the machine, and the model gives a yes or no answer after visual and\ntextual reasoning. If the answer is yes, the image auto-encoder and\nauto-regressive transformer must complete the visual re-creation under the\npremise of ensuring image quality, otherwise the system needs to explain why\nthe commands cannot be completed or prohibited. We provide a detailed analysis\nof experimental results in image quality, answer accuracy, and model behavior\nin the face of uncertainty and imperfect user queries. Our results demonstrate\nthe difficulty of a single model for both textual and visual reasoning. We also\nhope our explorations and findings can bring valuable insights about the\naccountability of text-based image generation models. Code and datasets can be\nfound at https://matrix-alpha.github.io.\n","authors":["Zhiwei Zhang","Yuliang Liu"],"pdf_url":"https://arxiv.org/pdf/2303.05983v1.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.05977v1","updated":"2023-03-10T15:17:22Z","published":"2023-03-10T15:17:22Z","title":"Open-Ended Medical Visual Question Answering Through Prefix Tuning of\n  Language Models","summary":"  Medical Visual Question Answering (VQA) is an important challenge, as it\nwould lead to faster and more accurate diagnoses and treatment decisions. Most\nexisting methods approach it as a multi-class classification problem, which\nrestricts the outcome to a predefined closed-set of curated answers. We focus\non open-ended VQA and motivated by the recent advances in language models\nconsider it as a generative task. Leveraging pre-trained language models, we\nintroduce a novel method particularly suited for small, domain-specific,\nmedical datasets. To properly communicate the medical images to the language\nmodel, we develop a network that maps the extracted visual features to a set of\nlearnable tokens. Then, alongside the question, these learnable tokens directly\nprompt the language model. We explore recent parameter-efficient fine-tuning\nstrategies for language models, which allow for resource- and data-efficient\nfine-tuning. We evaluate our approach on the prime medical VQA benchmarks,\nnamely, Slake, OVQA and PathVQA. The results demonstrate that our approach\noutperforms existing methods across various training settings while also being\ncomputationally efficient.\n","authors":["Tom van Sonsbeek","Mohammad Mahdi Derakhshani","Ivona Najdenkoska","Cees G. M. Snoek","Marcel Worring"],"pdf_url":"https://arxiv.org/pdf/2303.05977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05970v1","updated":"2023-03-10T15:01:51Z","published":"2023-03-10T15:01:51Z","title":"Exploring Recurrent Long-term Temporal Fusion for Multi-view 3D\n  Perception","summary":"  Long-term temporal fusion is a crucial but often overlooked technique in\ncamera-based Bird's-Eye-View (BEV) 3D perception. Existing methods are mostly\nin a parallel manner. While parallel fusion can benefit from long-term\ninformation, it suffers from increasing computational and memory overheads as\nthe fusion window size grows. Alternatively, BEVFormer adopts a recurrent\nfusion pipeline so that history information can be efficiently integrated, yet\nit fails to benefit from longer temporal frames. In this paper, we explore an\nembarrassingly simple long-term recurrent fusion strategy built upon the\nLSS-based methods and find it already able to enjoy the merits from both sides,\ni.e., rich long-term information and efficient fusion pipeline. A temporal\nembedding module is further proposed to improve the model's robustness against\noccasionally missed frames in practical scenarios. We name this simple but\neffective fusing pipeline VideoBEV. Experimental results on the nuScenes\nbenchmark show that VideoBEV obtains leading performance on various\ncamera-based 3D perception tasks, including object detection (55.4% mAP and\n62.9% NDS), segmentation (48.6% vehicle mIoU), tracking (54.8% AMOTA), and\nmotion prediction (0.80m minADE and 0.463 EPA). Code will be available.\n","authors":["Chunrui Han","Jianjian Sun","Zheng Ge","Jinrong Yang","Runpei Dong","Hongyu Zhou","Weixin Mao","Yuang Peng","Xiangyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05970v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05966v1","updated":"2023-03-10T14:55:35Z","published":"2023-03-10T14:55:35Z","title":"Score-Based Generative Models for Medical Image Segmentation using\n  Signed Distance Functions","summary":"  Medical image segmentation is a crucial task that relies on the ability to\naccurately identify and isolate regions of interest in images. Thereby,\ngenerative approaches allow to capture the statistical properties of\nsegmentation masks that are dependent on the respective medical images. In this\nwork we propose a conditional score-based generative modeling framework that\nleverages the signed distance function to represent an implicit and smoother\ndistribution of segmentation masks. The score function of the conditional\ndistribution of segmentation masks is learned in a conditional denoising\nprocess, which can be effectively used to generate accurate segmentation masks.\nMoreover, uncertainty maps can be generated, which can aid in further analysis\nand thus enhance the predictive robustness. We qualitatively and quantitatively\nillustrate competitive performance of the proposed method on a public nuclei\nand gland segmentation data set, highlighting its potential utility in medical\nimage segmentation applications.\n","authors":["Lea Bogensperger","Dominik Narnhofer","Filip Ilic","Thomas Pock"],"pdf_url":"https://arxiv.org/pdf/2303.05966v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05957v1","updated":"2023-03-10T14:45:37Z","published":"2023-03-10T14:45:37Z","title":"Automated crack propagation measurement on asphalt concrete specimens\n  using an optical flow-based deep neural network","summary":"  This article proposes a deep neural network, namely CrackPropNet, to measure\ncrack propagation on asphalt concrete (AC) specimens. It offers an accurate,\nflexible, efficient, and low-cost solution for crack propagation measurement\nusing images collected during cracking tests. CrackPropNet significantly\ndiffers from traditional deep learning networks, as it involves learning to\nlocate displacement field discontinuities by matching features at various\nlocations in the reference and deformed images. An image library representing\nthe diversified cracking behavior of AC was developed for supervised training.\nCrackPropNet achieved an optimal dataset scale F-1 of 0.755 and optimal image\nscale F-1 of 0.781 on the testing dataset at a running speed of 26\nframe-per-second. Experiments demonstrated that low to medium-level Gaussian\nnoises had a limited impact on the measurement accuracy of CrackPropNet.\nMoreover, the model showed promising generalization on fundamentally different\nimages. As a crack measurement technique, the CrackPropNet can detect complex\ncrack patterns accurately and efficiently in AC cracking tests. It can be\napplied to characterize the cracking phenomenon, evaluate AC cracking\npotential, validate test protocols, and verify theoretical models.\n","authors":["Zehui Zhu","Imad L. Al-Qadi"],"pdf_url":"https://arxiv.org/pdf/2303.05957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05955v1","updated":"2023-03-10T14:44:11Z","published":"2023-03-10T14:44:11Z","title":"Neuron Structure Modeling for Generalizable Remote Physiological\n  Measurement","summary":"  Remote photoplethysmography (rPPG) technology has drawn increasing attention\nin recent years. It can extract Blood Volume Pulse (BVP) from facial videos,\nmaking many applications like health monitoring and emotional analysis more\naccessible. However, as the BVP signal is easily affected by environmental\nchanges, existing methods struggle to generalize well for unseen domains. In\nthis paper, we systematically address the domain shift problem in the rPPG\nmeasurement task. We show that most domain generalization methods do not work\nwell in this problem, as domain labels are ambiguous in complicated\nenvironmental changes. In light of this, we propose a domain-label-free\napproach called NEuron STructure modeling (NEST). NEST improves the\ngeneralization capacity by maximizing the coverage of feature space during\ntraining, which reduces the chance for under-optimized feature activation\nduring inference. Besides, NEST can also enrich and enhance domain invariant\nfeatures across multi-domain. We create and benchmark a large-scale domain\ngeneralization protocol for the rPPG measurement task. Extensive experiments\nshow that our approach outperforms the state-of-the-art methods on both\ncross-dataset and intra-dataset settings.\n","authors":["Hao Lu","Zitong Yu","Xuesong Niu","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2303.05955v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2206.04530v2","updated":"2023-03-10T14:41:21Z","published":"2022-06-09T14:25:14Z","title":"DORA: Exploring outlier representations in Deep Neural Networks","summary":"  Deep Neural Networks (DNNs) draw their power from the representations they\nlearn. However, while being incredibly effective in learning complex\nabstractions, they are susceptible to learning malicious concepts, due to the\nspurious correlations inherent in the training data. So far, existing methods\nfor uncovering such artifactual behavior in trained models focus on finding\nartifacts in the input data, which requires both availability of a data set and\nhuman supervision. In this paper, we introduce DORA (Data-agnOstic\nRepresentation Analysis): the first data-agnostic framework for the analysis of\nthe representation space of DNNs. We propose a novel distance measure between\nrepresentations that utilizes self-explaining capabilities within the network\nitself without access to any data and quantitatively validate its alignment\nwith human-defined semantic distances. We further demonstrate that this metric\ncould be utilized for the detection of anomalous representations, which may\nbear a risk of learning unintended spurious concepts deviating from the desired\ndecision-making policy. Finally, we demonstrate the practical utility of DORA\nby analyzing and identifying artifactual representations in widely popular\nComputer Vision models.\n","authors":["Kirill Bykov","Mayukh Deb","Dennis Grinwald","Klaus-Robert Müller","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2206.04530v2.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2303.05952v1","updated":"2023-03-10T14:38:49Z","published":"2023-03-10T14:38:49Z","title":"Understanding and Constructing Latent Modality Structures in Multi-modal\n  Representation Learning","summary":"  Contrastive loss has been increasingly used in learning representations from\nmultiple modalities. In the limit, the nature of the contrastive loss\nencourages modalities to exactly match each other in the latent space. Yet it\nremains an open question how the modality alignment affects the downstream task\nperformance. In this paper, based on an information-theoretic argument, we\nfirst prove that exact modality alignment is sub-optimal in general for\ndownstream prediction tasks. Hence we advocate that the key of better\nperformance lies in meaningful latent modality structures instead of perfect\nmodality alignment. To this end, we propose three general approaches to\nconstruct latent modality structures. Specifically, we design 1) a deep feature\nseparation loss for intra-modality regularization; 2) a Brownian-bridge loss\nfor inter-modality regularization; and 3) a geometric consistency loss for both\nintra- and inter-modality regularization. Extensive experiments are conducted\non two popular multi-modal representation learning frameworks: the CLIP-based\ntwo-tower model and the ALBEF-based fusion model. We test our model on a\nvariety of tasks including zero/few-shot image classification, image-text\nretrieval, visual question answering, visual reasoning, and visual entailment.\nOur method achieves consistent improvements over existing methods,\ndemonstrating the effectiveness and generalizability of our proposed approach\non latent modality structure regularization.\n","authors":["Qian Jiang","Changyou Chen","Han Zhao","Liqun Chen","Qing Ping","Son Dinh Tran","Yi Xu","Belinda Zeng","Trishul Chilimbi"],"pdf_url":"https://arxiv.org/pdf/2303.05952v1.pdf","comment":"14 pages, 8 figure, CVPR 2023 accepted"},{"id":"http://arxiv.org/abs/2303.05938v1","updated":"2023-03-10T14:19:02Z","published":"2023-03-10T14:19:02Z","title":"ACR: Attention Collaboration-based Regressor for Arbitrary Two-Hand\n  Reconstruction","summary":"  Reconstructing two hands from monocular RGB images is challenging due to\nfrequent occlusion and mutual confusion. Existing methods mainly learn an\nentangled representation to encode two interacting hands, which are incredibly\nfragile to impaired interaction, such as truncated hands, separate hands, or\nexternal occlusion. This paper presents ACR (Attention Collaboration-based\nRegressor), which makes the first attempt to reconstruct hands in arbitrary\nscenarios. To achieve this, ACR explicitly mitigates interdependencies between\nhands and between parts by leveraging center and part-based attention for\nfeature extraction. However, reducing interdependence helps release the input\nconstraint while weakening the mutual reasoning about reconstructing the\ninteracting hands. Thus, based on center attention, ACR also learns cross-hand\nprior that handle the interacting hands better. We evaluate our method on\nvarious types of hand reconstruction datasets. Our method significantly\noutperforms the best interacting-hand approaches on the InterHand2.6M dataset\nwhile yielding comparable performance with the state-of-the-art single-hand\nmethods on the FreiHand dataset. More qualitative results on in-the-wild and\nhand-object interaction datasets and web images/videos further demonstrate the\neffectiveness of our approach for arbitrary hand reconstruction. Our code is\navailable at https://github.com/ZhengdiYu/Arbitrary-Hands-3D-Reconstruction.\n","authors":["Zhengdi Yu","Shaoli Huang","Chen Fang","Toby P. Breckon","Jue Wang"],"pdf_url":"https://arxiv.org/pdf/2303.05938v1.pdf","comment":"Accepted by CVPR 2023; Code at\n  https://github.com/ZhengdiYu/Arbitrary-Hands-3D-Reconstruction"},{"id":"http://arxiv.org/abs/2303.05937v1","updated":"2023-03-10T14:18:40Z","published":"2023-03-10T14:18:40Z","title":"Structural Multiplane Image: Bridging Neural View Synthesis and 3D\n  Reconstruction","summary":"  The Multiplane Image (MPI), containing a set of fronto-parallel RGBA layers,\nis an effective and efficient representation for view synthesis from sparse\ninputs. Yet, its fixed structure limits the performance, especially for\nsurfaces imaged at oblique angles. We introduce the Structural MPI (S-MPI),\nwhere the plane structure approximates 3D scenes concisely. Conveying RGBA\ncontexts with geometrically-faithful structures, the S-MPI directly bridges\nview synthesis and 3D reconstruction. It can not only overcome the critical\nlimitations of MPI, i.e., discretization artifacts from sloped surfaces and\nabuse of redundant layers, and can also acquire planar 3D reconstruction.\nDespite the intuition and demand of applying S-MPI, great challenges are\nintroduced, e.g., high-fidelity approximation for both RGBA layers and plane\nposes, multi-view consistency, non-planar regions modeling, and efficient\nrendering with intersected planes. Accordingly, we propose a transformer-based\nnetwork based on a segmentation model. It predicts compact and expressive S-MPI\nlayers with their corresponding masks, poses, and RGBA contexts. Non-planar\nregions are inclusively handled as a special case in our unified framework.\nMulti-view consistency is ensured by sharing global proxy embeddings, which\nencode plane-level features covering the complete 3D scenes with aligned\ncoordinates. Intensive experiments show that our method outperforms both\nprevious state-of-the-art MPI-based view synthesis methods and planar\nreconstruction methods.\n","authors":["Mingfang Zhang","Jinglu Wang","Xiao Li","Yifei Huang","Yoichi Sato","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2303.05937v1.pdf","comment":"Accepted to CVPR2023"},{"id":"http://arxiv.org/abs/2303.05933v1","updated":"2023-03-10T14:11:09Z","published":"2023-03-10T14:11:09Z","title":"Boosting Open-Set Domain Adaptation with Threshold Self-Tuning and\n  Cross-Domain Mixup","summary":"  Open-set domain adaptation (OSDA) aims to not only recognize target samples\nbelonging to common classes shared by source and target domains but also\nperceive unknown class samples. Existing OSDA methods suffer from two\nobstacles. First, a tedious process of manually tuning a hyperparameter\n$threshold$ is required for most OSDA approaches to separate common and unknown\nclasses. It is difficult to determine a proper threshold when the target domain\ndata is unlabeled. Second, most OSDA methods only rely on confidence values\npredicted by models to distinguish common/unknown classes. The performance is\nnot satisfied, especially when the majority of the target domain consists of\nunknown classes. Our experiments demonstrate that combining entropy,\nconsistency, and confidence is a more reliable way of distinguishing common and\nunknown samples. In this paper, we design a novel threshold self-tuning and\ncross-domain mixup (TSCM) method to overcome the two drawbacks. TSCM can\nautomatically tune a proper threshold utilizing unlabeled target samples rather\nthan manually setting an empirical hyperparameter. Our method considers\nmultiple criteria instead of only the confidence and uses the threshold\ngenerated by itself to separate common and unknown classes in the target\ndomain. Furthermore, we introduce a cross-domain mixup method designed for OSDA\nscenarios to learn domain-invariant features in a more continuous latent space.\nComprehensive experiments illustrate that our method consistently achieves\nsuperior performance on different benchmarks compared with various\nstate-of-the-arts.\n","authors":["Xinghong Liu","Yi Zhou","Tao Zhou","Jie Qin","Shengcai Liao"],"pdf_url":"https://arxiv.org/pdf/2303.05933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05929v1","updated":"2023-03-10T14:00:53Z","published":"2023-03-10T14:00:53Z","title":"Marginalia and machine learning: Handwritten text recognition for\n  Marginalia Collections","summary":"  The pressing need for digitization of historical document collections has led\nto a strong interest in designing computerised image processing methods for\nautomatic handwritten text recognition (HTR). Handwritten text possesses high\nvariability due to different writing styles, languages and scripts. Training an\naccurate and robust HTR system calls for data-efficient approaches due to the\nunavailability of sufficient amounts of annotated multi-writer text. A case\nstudy on an ongoing project ``Marginalia and Machine Learning\" is presented\nhere that focuses on automatic detection and recognition of handwritten\nmarginalia texts i.e., text written in margins or handwritten notes. Faster\nR-CNN network is used for detection of marginalia and AttentionHTR is used for\nword recognition. The data comes from early book collections (printed) found in\nthe Uppsala University Library, with handwritten marginalia texts. Source code\nand pretrained models are available at\nhttps://github.com/ektavats/Project-Marginalia.\n","authors":["Adam Axelsson","Liang Cheng","Jonas Frankemölle","Ekta Vats"],"pdf_url":"https://arxiv.org/pdf/2303.05929v1.pdf","comment":"Work under progress"},{"id":"http://arxiv.org/abs/2303.05927v1","updated":"2023-03-10T13:58:28Z","published":"2023-03-10T13:58:28Z","title":"Estimating friction coefficient using generative modelling","summary":"  It is common to utilise dynamic models to measure the tyre-road friction in\nreal-time. Alternatively, predictive approaches estimate the tyre-road friction\nby identifying the environmental factors affecting it. This work aims to\nformulate the problem of friction estimation as a visual perceptual learning\ntask. The problem is broken down into detecting surface characteristics by\napplying semantic segmentation and using the extracted features to predict the\nfrictional force. This work for the first time formulates the friction\nestimation problem as a regression from the latent space of a semantic\nsegmentation model. The preliminary results indicate that this approach can\nestimate frictional force.\n","authors":["Mohammad Otoofi","William J. B. Midgley","Leo Laine","Henderson Leon","Laura Justham","James Fleming"],"pdf_url":"https://arxiv.org/pdf/2303.05927v1.pdf","comment":"To be published in ICM2023"},{"id":"http://arxiv.org/abs/2212.00937v3","updated":"2023-03-10T13:49:14Z","published":"2022-12-02T02:52:01Z","title":"StructVPR: Distill Structural Knowledge with Weighting Samples for\n  Visual Place Recognition","summary":"  Visual place recognition (VPR) is usually considered as a specific image\nretrieval problem. Limited by existing training frameworks, most deep\nlearning-based works cannot extract sufficiently stable global features from\nRGB images and rely on a time-consuming re-ranking step to exploit spatial\nstructural information for better performance. In this paper, we propose\nStructVPR, a novel training architecture for VPR, to enhance structural\nknowledge in RGB global features and thus improve feature stability in a\nconstantly changing environment. Specifically, StructVPR uses segmentation\nimages as a more definitive source of structural knowledge input into a CNN\nnetwork and applies knowledge distillation to avoid online segmentation and\ninference of seg-branch in testing. Considering that not all samples contain\nhigh-quality and helpful knowledge, and some even hurt the performance of\ndistillation, we partition samples and weigh each sample's distillation loss to\nenhance the expected knowledge precisely. Finally, StructVPR achieves\nimpressive performance on several benchmarks using only global retrieval and\neven outperforms many two-stage approaches by a large margin. After adding\nadditional re-ranking, ours achieves state-of-the-art performance while\nmaintaining a low computational cost.\n","authors":["Yanqing Shen","Sanping Zhou","Jingwen Fu","Ruotong Wang","Shitao Chen","Nanning Zheng"],"pdf_url":"https://arxiv.org/pdf/2212.00937v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05916v1","updated":"2023-03-10T13:45:44Z","published":"2023-03-10T13:45:44Z","title":"GECCO: Geometrically-Conditioned Point Diffusion Models","summary":"  Diffusion models generating images conditionally on text, such as Dall-E 2\nand Stable Diffusion, have recently made a splash far beyond the computer\nvision community. Here, we tackle the related problem of generating point\nclouds, both unconditionally, and conditionally with images. For the latter, we\nintroduce a novel geometrically-motivated conditioning scheme based on\nprojecting sparse image features into the point cloud and attaching them to\neach individual point, at every step in the denoising process. This approach\nimproves geometric consistency and yields greater fidelity than current methods\nrelying on unstructured, global latent codes. Additionally, we show how to\napply recent continuous-time diffusion schemes. Our method performs on par or\nabove the state of art on conditional and unconditional experiments on\nsynthetic data, while being faster, lighter, and delivering tractable\nlikelihoods. We show it can also scale to diverse indoors scenes.\n","authors":["Michał J. Tyszkiewicz","Pascal Fua","Eduard Trulls"],"pdf_url":"https://arxiv.org/pdf/2303.05916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05912v1","updated":"2023-03-10T13:41:20Z","published":"2023-03-10T13:41:20Z","title":"DACov: A Deeper Analysis of Data Augmentation on the Computed Tomography\n  Segmentation Problem","summary":"  Due to the COVID-19 global pandemic, computer-assisted diagnoses of medical\nimages have gained much attention, and robust methods of semantic segmentation\nof Computed Tomography (CT) images have become highly desirable. In this work,\nwe present a deeper analysis of how data augmentation techniques improve\nsegmentation performance on this problem. We evaluate 20 traditional\naugmentation techniques on five public datasets. Six different probabilities of\napplying each augmentation technique on an image were evaluated. We also assess\na different training methodology where the training subsets are combined into a\nsingle larger set. All networks were evaluated through a 5-fold\ncross-validation strategy, resulting in over 4,600 experiments. We also propose\na novel data augmentation technique based on Generative Adversarial Networks\n(GANs) to create new healthy and unhealthy lung CT images, evaluating four\nvariations of our approach with the same six probabilities of the traditional\nmethods. Our findings show that GAN-based techniques and spatial-level\ntransformations are the most promising for improving the learning of deep\nmodels on this problem, with the StarGANv2 + F with a probability of 0.3\nachieving the highest F-score value on the Ricord1a dataset in the unified\ntraining strategy. Our code is publicly available at\nhttps://github.com/VRI-UFPR/DACov2022\n","authors":["Bruno A. Krinski","Daniel V. Ruiz","Rayson Laroca","Eduardo Todt"],"pdf_url":"https://arxiv.org/pdf/2303.05912v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14307v2","updated":"2023-03-10T13:28:52Z","published":"2023-02-28T04:45:31Z","title":"GradMA: A Gradient-Memory-based Accelerated Federated Learning with\n  Alleviated Catastrophic Forgetting","summary":"  Federated Learning (FL) has emerged as a de facto machine learning area and\nreceived rapid increasing research interests from the community. However,\ncatastrophic forgetting caused by data heterogeneity and partial participation\nposes distinctive challenges for FL, which are detrimental to the performance.\nTo tackle the problems, we propose a new FL approach (namely GradMA), which\ntakes inspiration from continual learning to simultaneously correct the\nserver-side and worker-side update directions as well as take full advantage of\nserver's rich computing and memory resources. Furthermore, we elaborate a\nmemory reduction strategy to enable GradMA to accommodate FL with a large scale\nof workers. We then analyze convergence of GradMA theoretically under the\nsmooth non-convex setting and show that its convergence rate achieves a linear\nspeed up w.r.t the increasing number of sampled active workers. At last, our\nextensive experiments on various image classification tasks show that GradMA\nachieves significant performance gains in accuracy and communication efficiency\ncompared to SOTA baselines.\n","authors":["Kangyang Luo","Xiang Li","Yunshi Lan","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2302.14307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05892v1","updated":"2023-03-10T12:58:34Z","published":"2023-03-10T12:58:34Z","title":"Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection","summary":"  Open-vocabulary object detection aims to provide object detectors trained on\na fixed set of object categories with the generalizability to detect objects\ndescribed by arbitrary text queries. Previous methods adopt knowledge\ndistillation to extract knowledge from Pretrained Vision-and-Language Models\n(PVLMs) and transfer it to detectors. However, due to the non-adaptive proposal\ncropping and single-level feature mimicking processes, they suffer from\ninformation destruction during knowledge extraction and inefficient knowledge\ntransfer. To remedy these limitations, we propose an Object-Aware Distillation\nPyramid (OADP) framework, including an Object-Aware Knowledge Extraction (OAKE)\nmodule and a Distillation Pyramid (DP) mechanism. When extracting object\nknowledge from PVLMs, the former adaptively transforms object proposals and\nadopts object-aware mask attention to obtain precise and complete knowledge of\nobjects. The latter introduces global and block distillation for more\ncomprehensive knowledge transfer to compensate for the missing relation\ninformation in object distillation. Extensive experiments show that our method\nachieves significant improvement compared to current methods. Especially on the\nMS-COCO dataset, our OADP framework reaches $35.6$ mAP$^{\\text{N}}_{50}$,\nsurpassing the current state-of-the-art method by $3.3$ mAP$^{\\text{N}}_{50}$.\nCode is released at https://github.com/LutingWang/OADP.\n","authors":["Luting Wang","Yi Liu","Penghui Du","Zihan Ding","Yue Liao","Qiaosong Qi","Biaolong Chen","Si Liu"],"pdf_url":"https://arxiv.org/pdf/2303.05892v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.05886v1","updated":"2023-03-10T12:38:37Z","published":"2023-03-10T12:38:37Z","title":"Bi3D: Bi-domain Active Learning for Cross-domain 3D Object Detection","summary":"  Unsupervised Domain Adaptation (UDA) technique has been explored in 3D\ncross-domain tasks recently. Though preliminary progress has been made, the\nperformance gap between the UDA-based 3D model and the supervised one trained\nwith fully annotated target domain is still large. This motivates us to\nconsider selecting partial-yet-important target data and labeling them at a\nminimum cost, to achieve a good trade-off between high performance and low\nannotation cost. To this end, we propose a Bi-domain active learning approach,\nnamely Bi3D, to solve the cross-domain 3D object detection task. The Bi3D first\ndevelops a domainness-aware source sampling strategy, which identifies\ntarget-domain-like samples from the source domain to avoid the model being\ninterfered by irrelevant source data. Then a diversity-based target sampling\nstrategy is developed, which selects the most informative subset of target\ndomain to improve the model adaptability to the target domain using as little\nannotation budget as possible. Experiments are conducted on typical\ncross-domain adaptation scenarios including cross-LiDAR-beam, cross-country,\nand cross-sensor, where Bi3D achieves a promising target-domain detection\naccuracy (89.63% on KITTI) compared with UDAbased work (84.29%), even\nsurpassing the detector trained on the full set of the labeled target domain\n(88.98%). Our code is available at: https://github.com/PJLabADG/3DTrans.\n","authors":["Jiakang Yuan","Bo Zhang","Xiangchao Yan","Tao Chen","Botian Shi","Yikang Li","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2303.05886v1.pdf","comment":"Accepted by CVPR2023; Code is available at\n  https://github.com/PJLabADG/3DTrans"},{"id":"http://arxiv.org/abs/2208.04438v2","updated":"2023-03-10T12:24:50Z","published":"2022-08-08T21:39:26Z","title":"Occlusion-Aware Instance Segmentation via BiLayer Network Architectures","summary":"  Segmenting highly-overlapping image objects is challenging, because there is\ntypically no distinction between real object contours and occlusion boundaries\non images. Unlike previous instance segmentation methods, we model image\nformation as a composition of two overlapping layers, and propose Bilayer\nConvolutional Network (BCNet), where the top layer detects occluding objects\n(occluders) and the bottom layer infers partially occluded instances\n(occludees). The explicit modeling of occlusion relationship with bilayer\nstructure naturally decouples the boundaries of both the occluding and occluded\ninstances, and considers the interaction between them during mask regression.\nWe investigate the efficacy of bilayer structure using two popular\nconvolutional network designs, namely, Fully Convolutional Network (FCN) and\nGraph Convolutional Network (GCN). Further, we formulate bilayer decoupling\nusing the vision transformer (ViT), by representing instances in the image as\nseparate learnable occluder and occludee queries. Large and consistent\nimprovements using one/two-stage and query-based object detectors with various\nbackbones and network layer choices validate the generalization ability of\nbilayer decoupling, as shown by extensive experiments on image instance\nsegmentation benchmarks (COCO, KINS, COCOA) and video instance segmentation\nbenchmarks (YTVIS, OVIS, BDD100K MOTS), especially for heavy occlusion cases.\nCode and data are available at https://github.com/lkeab/BCNet.\n","authors":["Lei Ke","Yu-Wing Tai","Chi-Keung Tang"],"pdf_url":"https://arxiv.org/pdf/2208.04438v2.pdf","comment":"Extended version of \"Deep Occlusion-Aware Instance Segmentation with\n  Overlapping BiLayers\", CVPR 2021 (arXiv:2103.12340)"},{"id":"http://arxiv.org/abs/2303.01917v2","updated":"2023-03-10T12:14:01Z","published":"2023-03-03T13:36:55Z","title":"PPCR: Learning Pyramid Pixel Context Recalibration Module for Medical\n  Image Classification","summary":"  Spatial attention mechanism has been widely incorporated into deep\nconvolutional neural networks (CNNs) via long-range dependency capturing,\nsignificantly lifting the performance in computer vision, but it may perform\npoorly in medical imaging. Unfortunately, existing efforts are often unaware\nthat long-range dependency capturing has limitations in highlighting subtle\nlesion regions, neglecting to exploit the potential of multi-scale pixel\ncontext information to improve the representational capability of CNNs. In this\npaper, we propose a practical yet lightweight architectural unit, Pyramid Pixel\nContext Recalibration (PPCR) module, which exploits multi-scale pixel context\ninformation to recalibrate pixel position in a pixel-independent manner\nadaptively. PPCR first designs a cross-channel pyramid pooling to aggregate\nmulti-scale pixel context information, then eliminates the inconsistency among\nthem by the well-designed pixel normalization, and finally estimates per pixel\nattention weight via a pixel context integration. PPCR can be flexibly plugged\ninto modern CNNs with negligible overhead. Extensive experiments on five\nmedical image datasets and CIFAR benchmarks empirically demonstrate the\nsuperiority and generalization of PPCR over state-of-the-art attention methods.\nThe in-depth analyses explain the inherent behavior of PPCR in the\ndecision-making process, improving the interpretability of CNNs.\n","authors":["Xiaoqing Zhang","Zunjie Xiao","Xiao Wu","Jiansheng Fang","Junyong Shen","Yan Hu","Risa Higashita","Jiang Liu"],"pdf_url":"https://arxiv.org/pdf/2303.01917v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2303.05879v1","updated":"2023-03-10T12:13:31Z","published":"2023-03-10T12:13:31Z","title":"Handheld Burst Super-Resolution Meets Multi-Exposure Satellite Imagery","summary":"  Image resolution is an important criterion for many applications based on\nsatellite imagery. In this work, we adapt a state-of-the-art kernel regression\ntechnique for smartphone camera burst super-resolution to satellites. This\ntechnique leverages the local structure of the image to optimally steer the\nfusion kernels, limiting blur in the final high-resolution prediction,\ndenoising the image, and recovering details up to a zoom factor of 2. We extend\nthis approach to the multi-exposure case to predict from a sequence of\nmulti-exposure low-resolution frames a high-resolution and noise-free one.\nExperiments on both single and multi-exposure scenarios show the merits of the\napproach. Since the fusion is learning-free, the proposed method is ensured to\nnot hallucinate details, which is crucial for many remote sensing applications.\n","authors":["Jamy Lafenetre","Ngoc Long Nguyen","Gabriele Facciolo","Thomas Eboli"],"pdf_url":"https://arxiv.org/pdf/2303.05879v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2303.05871v1","updated":"2023-03-10T11:51:22Z","published":"2023-03-10T11:51:22Z","title":"Accurate Real-time Polyp Detection in Videos from Concatenation of\n  Latent Features Extracted from Consecutive Frames","summary":"  An efficient deep learning model that can be implemented in real-time for\npolyp detection is crucial to reducing polyp miss-rate during screening\nprocedures. Convolutional neural networks (CNNs) are vulnerable to small\nchanges in the input image. A CNN-based model may miss the same polyp appearing\nin a series of consecutive frames and produce unsubtle detection output due to\nchanges in camera pose, lighting condition, light reflection, etc. In this\nstudy, we attempt to tackle this problem by integrating temporal information\namong neighboring frames. We propose an efficient feature concatenation method\nfor a CNN-based encoder-decoder model without adding complexity to the model.\nThe proposed method incorporates extracted feature maps of previous frames to\ndetect polyps in the current frame. The experimental results demonstrate that\nthe proposed method of feature concatenation improves the overall performance\nof automatic polyp detection in videos. The following results are obtained on a\npublic video dataset: sensitivity 90.94\\%, precision 90.53\\%, and specificity\n92.46%\n","authors":["Hemin Ali Qadir","Younghak Shin","Jacob Bergsland","Ilangko Balasingham"],"pdf_url":"https://arxiv.org/pdf/2303.05871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.00767v2","updated":"2023-03-10T10:57:23Z","published":"2022-12-01T18:52:46Z","title":"Exploiting Proximity-Aware Tasks for Embodied Social Navigation","summary":"  Learning how to navigate among humans in an occluded and spatially\nconstrained indoor environment, is a key ability required to embodied agent to\nbe integrated into our society. In this paper, we propose an end-to-end\narchitecture that exploits Proximity-Aware Tasks (referred as to Risk and\nProximity Compass) to inject into a reinforcement learning navigation policy\nthe ability to infer common-sense social behaviors. To this end, our tasks\nexploit the notion of immediate and future dangers of collision. Furthermore,\nwe propose an evaluation protocol specifically designed for the Social\nNavigation Task in simulated environments. This is done to capture fine-grained\nfeatures and characteristics of the policy by analyzing the minimal unit of\nhuman-robot spatial interaction, called Encounter. We validate our approach on\nGibson4+ and Habitat-Matterport3D datasets.\n","authors":["Enrico Cancelli","Tommaso Campari","Luciano Serafini","Angel X. Chang","Lamberto Ballan"],"pdf_url":"https://arxiv.org/pdf/2212.00767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.03491v6","updated":"2023-03-10T10:34:33Z","published":"2022-06-07T07:45:45Z","title":"EiX-GNN : Concept-level eigencentrality explainer for graph neural\n  networks","summary":"  Nowadays, deep prediction models, especially graph neural networks, have a\nmajorplace in critical applications. In such context, those models need to be\nhighlyinterpretable or being explainable by humans, and at the societal scope,\nthis understandingmay also be feasible for humans that do not have a strong\nprior knowledgein models and contexts that need to be explained. In the\nliterature, explainingis a human knowledge transfer process regarding a\nphenomenon between an explainerand an explainee. We propose EiX-GNN\n(Eigencentrality eXplainer forGraph Neural Networks) a new powerful method for\nexplaining graph neural networksthat encodes computationally this social\nexplainer-to-explainee dependenceunderlying in the explanation process. To\nhandle this dependency, we introducethe notion of explainee concept\nassimibility which allows explainer to adapt itsexplanation to explainee\nbackground or expectation. We lead a qualitative studyto illustrate our\nexplainee concept assimibility notion on real-world data as wellas a\nqualitative study that compares, according to objective metrics established\ninthe literature, fairness and compactness of our method with respect to\nperformingstate-of-the-art methods. It turns out that our method achieves\nstrong results inboth aspects.\n","authors":["Adrien Raison","Pascal Bourdon","David Helbert"],"pdf_url":"https://arxiv.org/pdf/2206.03491v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05835v1","updated":"2023-03-10T10:23:17Z","published":"2023-03-10T10:23:17Z","title":"You Only Train Once: Multi-Identity Free-Viewpoint Neural Human\n  Rendering from Monocular Videos","summary":"  We introduce You Only Train Once (YOTO), a dynamic human generation\nframework, which performs free-viewpoint rendering of different human\nidentities with distinct motions, via only one-time training from monocular\nvideos. Most prior works for the task require individualized optimization for\neach input video that contains a distinct human identity, leading to a\nsignificant amount of time and resources for the deployment, thereby impeding\nthe scalability and the overall application potential of the system. In this\npaper, we tackle this problem by proposing a set of learnable identity codes to\nexpand the capability of the framework for multi-identity free-viewpoint\nrendering, and an effective pose-conditioned code query mechanism to finely\nmodel the pose-dependent non-rigid motions. YOTO optimizes neural radiance\nfields (NeRF) by utilizing designed identity codes to condition the model for\nlearning various canonical T-pose appearances in a single shared volumetric\nrepresentation. Besides, our joint learning of multiple identities within a\nunified model incidentally enables flexible motion transfer in high-quality\nphoto-realistic renderings for all learned appearances. This capability expands\nits potential use in important applications, including Virtual Reality. We\npresent extensive experimental results on ZJU-MoCap and PeopleSnapshot to\nclearly demonstrate the effectiveness of our proposed model. YOTO shows\nstate-of-the-art performance on all evaluation metrics while showing\nsignificant benefits in training and inference efficiency as well as rendering\nquality. The code and model will be made publicly available soon.\n","authors":["Jaehyeok Kim","Dongyoon Wee","Dan Xu"],"pdf_url":"https://arxiv.org/pdf/2303.05835v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16290v2","updated":"2023-03-10T10:22:29Z","published":"2022-11-29T15:21:34Z","title":"LocPoseNet: Robust Location Prior for Unseen Object Pose Estimation","summary":"  Object location priors have been shown to be critical for the standard 6D\nobject pose estimation setting, where the training and testing objects are the\nsame. Specifically, they can be used to initialize the 3D object translation\nand facilitate 3D object rotation estimation. Unfortunately, the object\ndetectors that are used for this purpose do not generalize to unseen objects,\ni.e., objects from new categories at test time. Therefore, existing 6D pose\nestimation methods for previously-unseen objects either assume the ground-truth\nobject location to be known, or yield inaccurate results when it is\nunavailable. In this paper, we address this problem by developing a method,\nLocPoseNet, able to robustly learn location prior for unseen objects. Our\nmethod builds upon a template matching strategy, where we propose to distribute\nthe reference kernels and convolve them with a query to efficiently compute\nmulti-scale correlations. We then introduce a novel translation estimator,\nwhich decouples scale-aware and scale-robust features to predict different\nobject location parameters. Our method outperforms existing works by a large\nmargin on LINEMOD and GenMOP. We further construct a challenging synthetic\ndataset, which allows us to highlight the better robustness of our method to\nvarious noise sources.\n","authors":["Chen Zhao","Yinlin Hu","Mathieu Salzmann"],"pdf_url":"https://arxiv.org/pdf/2211.16290v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.15369v2","updated":"2023-03-10T10:22:17Z","published":"2022-06-30T15:43:51Z","title":"No Reason for No Supervision: Improved Generalization in Supervised\n  Models","summary":"  We consider the problem of training a deep neural network on a given\nclassification task, e.g., ImageNet-1K (IN1K), so that it excels at both the\ntraining task as well as at other (future) transfer tasks. These two seemingly\ncontradictory properties impose a trade-off between improving the model's\ngeneralization and maintaining its performance on the original task. Models\ntrained with self-supervised learning tend to generalize better than their\nsupervised counterparts for transfer learning; yet, they still lag behind\nsupervised models on IN1K. In this paper, we propose a supervised learning\nsetup that leverages the best of both worlds. We extensively analyze supervised\ntraining using multi-scale crops for data augmentation and an expendable\nprojector head, and reveal that the design of the projector allows us to\ncontrol the trade-off between performance on the training task and\ntransferability. We further replace the last layer of class weights with class\nprototypes computed on the fly using a memory bank and derive two models: t-ReX\nthat achieves a new state of the art for transfer learning and outperforms top\nmethods such as DINO and PAWS on IN1K, and t-ReX* that matches the highly\noptimized RSB-A1 model on IN1K while performing better on transfer tasks. Code\nand pretrained models: https://europe.naverlabs.com/t-rex\n","authors":["Mert Bulent Sariyildiz","Yannis Kalantidis","Karteek Alahari","Diane Larlus"],"pdf_url":"https://arxiv.org/pdf/2206.15369v2.pdf","comment":"Accepted to ICLR 2023 (spotlight)"},{"id":"http://arxiv.org/abs/2303.05828v1","updated":"2023-03-10T10:02:18Z","published":"2023-03-10T10:02:18Z","title":"Contrastive Language-Image Pretrained (CLIP) Models are Powerful\n  Out-of-Distribution Detectors","summary":"  We present a comprehensive experimental study on pretrained feature\nextractors for visual out-of-distribution (OOD) detection. We examine several\nsetups, based on the availability of labels or image captions and using\ndifferent combinations of in- and out-distributions. Intriguingly, we find that\n(i) contrastive language-image pretrained models achieve state-of-the-art\nunsupervised out-of-distribution performance using nearest neighbors feature\nsimilarity as the OOD detection score, (ii) supervised state-of-the-art OOD\ndetection performance can be obtained without in-distribution fine-tuning,\n(iii) even top-performing billion-scale vision transformers trained with\nnatural language supervision fail at detecting adversarially manipulated OOD\nimages. Finally, we argue whether new benchmarks for visual anomaly detection\nare needed based on our experiments. Using the largest publicly available\nvision transformer, we achieve state-of-the-art performance across all $18$\nreported OOD benchmarks, including an AUROC of 87.6\\% (9.2\\% gain,\nunsupervised) and 97.4\\% (1.2\\% gain, supervised) for the challenging task of\nCIFAR100 $\\rightarrow$ CIFAR10 OOD detection. The code will be open-sourced.\n","authors":["Felix Michels","Nikolas Adaloglou","Tim Kaiser","Markus Kollmann"],"pdf_url":"https://arxiv.org/pdf/2303.05828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.10447v2","updated":"2023-03-10T09:53:56Z","published":"2022-07-21T12:37:15Z","title":"Weakly Supervised Object Localization via Transformer with Implicit\n  Spatial Calibration","summary":"  Weakly Supervised Object Localization (WSOL), which aims to localize objects\nby only using image-level labels, has attracted much attention because of its\nlow annotation cost in real applications. Recent studies leverage the advantage\nof self-attention in visual Transformer for long-range dependency to re-active\nsemantic regions, aiming to avoid partial activation in traditional class\nactivation mapping (CAM). However, the long-range modeling in Transformer\nneglects the inherent spatial coherence of the object, and it usually diffuses\nthe semantic-aware regions far from the object boundary, making localization\nresults significantly larger or far smaller. To address such an issue, we\nintroduce a simple yet effective Spatial Calibration Module (SCM) for accurate\nWSOL, incorporating semantic similarities of patch tokens and their spatial\nrelationships into a unified diffusion model. Specifically, we introduce a\nlearnable parameter to dynamically adjust the semantic correlations and spatial\ncontext intensities for effective information propagation. In practice, SCM is\ndesigned as an external module of Transformer, and can be removed during\ninference to reduce the computation cost. The object-sensitive localization\nability is implicitly embedded into the Transformer encoder through\noptimization in the training phase. It enables the generated attention maps to\ncapture the sharper object boundaries and filter the object-irrelevant\nbackground area. Extensive experimental results demonstrate the effectiveness\nof the proposed method, which significantly outperforms its counterpart TS-CAM\non both CUB-200 and ImageNet-1K benchmarks. The code is available at\nhttps://github.com/164140757/SCM.\n","authors":["Haotian Bai","Ruimao Zhang","Jiong Wang","Xiang Wan"],"pdf_url":"https://arxiv.org/pdf/2207.10447v2.pdf","comment":"Accepted by ECCV2022"},{"id":"http://arxiv.org/abs/2303.05807v1","updated":"2023-03-10T09:28:09Z","published":"2023-03-10T09:28:09Z","title":"Aleth-NeRF: Low-light Condition View Synthesis with Concealing Fields","summary":"  Common capture low-light scenes are challenging for most computer vision\ntechniques, including Neural Radiance Fields (NeRF). Vanilla NeRF is\nviewer-centred that simplifies the rendering process only as light emission\nfrom 3D locations in the viewing direction, thus failing to model the\nlow-illumination induced darkness. Inspired by emission theory of ancient Greek\nthat visual perception is accomplished by rays casting from eyes, we make\nslight modifications on vanilla NeRF to train on multiple views of low-light\nscene, we can thus render out the well-lit scene in an unsupervised manner. We\nintroduce a surrogate concept, Concealing Fields, that reduce the transport of\nlight during the volume rendering stage. Specifically, our proposed method,\nAleth-NeRF, directly learns from the dark image to understand volumetric object\nrepresentation and concealing field under priors. By simply eliminating\nConcealing Fields, we can render a single or multi-view well-lit image(s) and\ngain superior performance over other 2D low light enhancement methods.\nAdditionally, we collect the first paired LOw-light and normal-light Multi-view\n(LOM) datasets for future research.\n","authors":["Ziteng Cui","Lin Gu","Xiao Sun","Yu Qiao","Tatsuya Harada"],"pdf_url":"https://arxiv.org/pdf/2303.05807v1.pdf","comment":"website page: https://cuiziteng.github.io/Aleth_NeRF_web/"},{"id":"http://arxiv.org/abs/2303.05800v1","updated":"2023-03-10T09:09:37Z","published":"2023-03-10T09:09:37Z","title":"Enhancing the success rates by performing pooling decisions adjacent to\n  the output layer","summary":"  Learning classification tasks of (2^nx2^n) inputs typically consist of \\le n\n(2x2) max-pooling (MP) operators along the entire feedforward deep\narchitecture. Here we show, using the CIFAR-10 database, that pooling decisions\nadjacent to the last convolutional layer significantly enhance accuracy success\nrates (SRs). In particular, average SRs of the advanced VGG with m layers\n(A-VGGm) architectures are 0.936, 0.940, 0.954, 0.955, and 0.955 for m=6, 8,\n14, 13, and 16, respectively. The results indicate A-VGG8s' SR is superior to\nVGG16s', and that the SRs of A-VGG13 and A-VGG16 are equal, and comparable to\nthat of Wide-ResNet16. In addition, replacing the three fully connected (FC)\nlayers with one FC layer, A-VGG6 and A-VGG14, or with several linear activation\nFC layers, yielded similar SRs. These significantly enhanced SRs stem from\ntraining the most influential input-output routes, in comparison to the\ninferior routes selected following multiple MP decisions along the deep\narchitecture. In addition, SRs are sensitive to the order of the\nnon-commutative MP and average pooling operators adjacent to the output layer,\nvarying the number and location of training routes. The results call for the\nreexamination of previously proposed deep architectures and their SRs by\nutilizing the proposed pooling strategy adjacent to the output layer.\n","authors":["Yuval Meir","Yarden Tzach","Ronit D. Gross","Ofek Tevet","Roni Vardi","Ido Kanter"],"pdf_url":"https://arxiv.org/pdf/2303.05800v1.pdf","comment":"27 pages, 3 figures, 1 table and Supplementary Information"},{"id":"http://arxiv.org/abs/2303.05789v1","updated":"2023-03-10T08:49:31Z","published":"2023-03-10T08:49:31Z","title":"AnoMalNet: Outlier Detection based Malaria Cell Image Classification\n  Method Leveraging Deep Autoencoder","summary":"  Class imbalance is a pervasive issue in the field of disease classification\nfrom medical images. It is necessary to balance out the class distribution\nwhile training a model for decent results. However, in the case of rare medical\ndiseases, images from affected patients are much harder to come by compared to\nimages from non-affected patients, resulting in unwanted class imbalance.\nVarious processes of tackling class imbalance issues have been explored so far,\neach having its fair share of drawbacks. In this research, we propose an\noutlier detection based binary medical image classification technique which can\nhandle even the most extreme case of class imbalance. We have utilized a\ndataset of malaria parasitized and uninfected cells. An autoencoder model\ntitled AnoMalNet is trained with only the uninfected cell images at the\nbeginning and then used to classify both the affected and non-affected cell\nimages by thresholding a loss value. We have achieved an accuracy, precision,\nrecall, and F1 score of 98.49%, 97.07%, 100%, and 98.52% respectively,\nperforming better than large deep learning models and other published works. As\nour proposed approach can provide competitive results without needing the\ndisease-positive samples during training, it should prove to be useful in\nbinary disease classification on imbalanced datasets.\n","authors":["Aminul Huq","Md Tanzim Reza","Shahriar Hossain","Shakib Mahmud Dipto"],"pdf_url":"https://arxiv.org/pdf/2303.05789v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.07692v2","updated":"2023-03-10T08:48:44Z","published":"2022-01-19T16:22:02Z","title":"GroupGazer: A Tool to Compute the Gaze per Participant in Groups with\n  integrated Calibration to Map the Gaze Online to a Screen or Beamer\n  Projection","summary":"  In this paper we present GroupGaze. It is a tool that can be used to\ncalculate the gaze direction and the gaze position of whole groups. GroupGazer\ncalculates the gaze direction of every single person in the image and allows to\nmap these gaze vectors to a projection like a projector. In addition to the\nperson-specific gaze direction, the person affiliation of each gaze vector is\nstored based on the position in the image. Also, it is possible to save the\ngroup attention after a calibration. The software is free to use and requires a\nsimple webcam as well as an NVIDIA GPU and the operating system Windows or\nLinux.\n  Link:\nhttps://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FGroupGazer&mode=list\n","authors":["Wolfgang Fuhl","Daniel Weber","Shahram Eivazi"],"pdf_url":"https://arxiv.org/pdf/2201.07692v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04909v2","updated":"2023-03-10T08:46:02Z","published":"2023-03-08T21:55:15Z","title":"Robotic Fabric Flattening with Wrinkle Direction Detection","summary":"  Deformable Object Manipulation (DOM) is an important field of research as it\ncontributes to practical tasks such as automatic cloth handling, cable routing,\nsurgical operation, etc. Perception is considered one of the major challenges\nin DOM due to the complex dynamics and high degree of freedom of deformable\nobjects. In this paper, we develop a novel image-processing algorithm based on\nGabor filters to extract useful features from cloth, and based on this, devise\na strategy for cloth flattening tasks. We evaluate the overall framework\nexperimentally, and compare it with three human operators. The results show\nthat our algorithm can determine the direction of wrinkles on the cloth\naccurately in the simulation as well as the real robot experiments. Besides,\nthe robot executing the flattening tasks using the dewrinkling strategy given\nby our algorithm achieves satisfying performance compared to other baseline\nmethods. The experiment video is available on\nhttps://sites.google.com/view/robotic-fabric-flattening/home\n","authors":["Yulei Qiu","Jihong Zhu","Cosimo Della Santina","Michael Gienger","Jens Kober"],"pdf_url":"https://arxiv.org/pdf/2303.04909v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.06799v2","updated":"2023-03-10T08:45:40Z","published":"2022-01-18T07:54:55Z","title":"Pistol: Pupil Invisible Supportive Tool to extract Pupil, Iris, Eye\n  Opening, Eye Movements, Pupil and Iris Gaze Vector, and 2D as well as 3D Gaze","summary":"  This paper describes a feature extraction and gaze estimation software, named\n\\textit{Pistol} that can be used with Pupil Invisible projects and other eye\ntrackers in the future. In offline mode, our software extracts multiple\nfeatures from the eye including, the pupil and iris ellipse, eye aperture,\npupil vector, iris vector, eye movement types from pupil and iris velocities,\nmarker detection, marker distance, 2D gaze estimation for the pupil center,\niris center, pupil vector, and iris vector using Levenberg Marquart fitting and\nneural networks. The gaze signal is computed in 2D for each eye and each\nfeature separately and for both eyes in 3D also for each feature separately. We\nhope this software helps other researchers to extract state-of-the-art features\nfor their research out of their recordings.\n  Link:\nhttps://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FPISTOL&mode=list\n","authors":["Wolfgang Fuhl","Daniel Weber","Shahram Eivazi"],"pdf_url":"https://arxiv.org/pdf/2201.06799v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05785v1","updated":"2023-03-10T08:38:34Z","published":"2023-03-10T08:38:34Z","title":"Scaling Up 3D Kernels with Bayesian Frequency Re-parameterization for\n  Medical Image Segmentation","summary":"  With the inspiration of vision transformers, the concept of depth-wise\nconvolution revisits to provide a large Effective Receptive Field (ERF) using\nLarge Kernel (LK) sizes for medical image segmentation. However, the\nsegmentation performance might be saturated and even degraded as the kernel\nsizes scaled up (e.g., $21\\times 21\\times 21$) in a Convolutional Neural\nNetwork (CNN). We hypothesize that convolution with LK sizes is limited to\nmaintain an optimal convergence for locality learning. While Structural\nRe-parameterization (SR) enhances the local convergence with small kernels in\nparallel, optimal small kernel branches may hinder the computational efficiency\nfor training. In this work, we propose RepUX-Net, a pure CNN architecture with\na simple large kernel block design, which competes favorably with current\nnetwork state-of-the-art (SOTA) (e.g., 3D UX-Net, SwinUNETR) using 6\nchallenging public datasets. We derive an equivalency between kernel\nre-parameterization and the branch-wise variation in kernel convergence.\nInspired by the spatial frequency in the human visual system, we extend to vary\nthe kernel convergence into element-wise setting and model the spatial\nfrequency as a Bayesian prior to re-parameterize convolutional weights during\ntraining. Specifically, a reciprocal function is leveraged to estimate a\nfrequency-weighted value, which rescales the corresponding kernel element for\nstochastic gradient descent. From the experimental results, RepUX-Net\nconsistently outperforms 3D SOTA benchmarks with internal validation (FLARE:\n0.929 to 0.944), external validation (MSD: 0.901 to 0.932, KiTS: 0.815 to\n0.847, LiTS: 0.933 to 0.949, TCIA: 0.736 to 0.779) and transfer learning (AMOS:\n0.880 to 0.911) scenarios in Dice Score.\n","authors":["Ho Hin Lee","Quan Liu","Shunxing Bao","Qi Yang","Xin Yu","Leon Y. Cai","Thomas Li","Yuankai Huo","Xenofon Koutsoukos","Bennett A. Landman"],"pdf_url":"https://arxiv.org/pdf/2303.05785v1.pdf","comment":"Both codes and pretrained models are available at:\n  https://github.com/MASILab/RepUX-Net"},{"id":"http://arxiv.org/abs/2101.03793v3","updated":"2023-03-10T08:34:49Z","published":"2021-01-11T10:04:52Z","title":"The Gaze and Mouse Signal as additional Source for User Fingerprints in\n  Browser Applications","summary":"  In this work, we inspect different data sources for browser fingerprints. We\nshow which disadvantages and limitations browser statistics have and how this\ncan be avoided with other data sources. Since human visual behavior is a rich\nsource of information and also contains person specific information, it is a\nvaluable source for browser fingerprints. However, human gaze acquisition in\nthe browser also has disadvantages, such as inaccuracies via webcam and the\nrestriction that the user must first allow access to the camera. However, it is\nalso known that the mouse movements and the human gaze correlate and therefore,\nthe mouse movements can be used instead of the gaze signal. In our evaluation,\nwe show the influence of all possible combinations of the three information\nsources for user recognition and describe our simple approach in detail.\n  Link:\nhttps://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FThe%20Gaze%20and%20Mouse%20Signal%20as%20additional%20Source%20...&mode=list\n","authors":["Wolfgang Fuhl","Daniel Weber","Shahram Eivazi"],"pdf_url":"https://arxiv.org/pdf/2101.03793v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05780v1","updated":"2023-03-10T08:29:35Z","published":"2023-03-10T08:29:35Z","title":"Knowledge Transfer via Multi-Head Feature Adaptation for Whole Slide\n  Image Classification","summary":"  Transferring prior knowledge from a source domain to the same or similar\ntarget domain can greatly enhance the performance of models on the target\ndomain. However, it is challenging to directly leverage the knowledge from the\nsource domain due to task discrepancy and domain shift. To bridge the gaps\nbetween different tasks and domains, we propose a Multi-Head Feature Adaptation\nmodule, which projects features in the source feature space to a new space that\nis more similar to the target space. Knowledge transfer is particularly\nimportant in Whole Slide Image (WSI) classification since the number of WSIs in\none dataset might be too small to achieve satisfactory performance. Therefore,\nWSI classification is an ideal testbed for our method, and we adapt multiple\nknowledge transfer methods for WSI classification. The experimental results\nshow that models with knowledge transfer outperform models that are trained\nfrom scratch by a large margin regardless of the number of WSIs in the\ndatasets, and our method achieves state-of-the-art performances among other\nknowledge transfer methods on multiple datasets, including TCGA-RCC,\nTCGA-NSCLC, and Camelyon16 datasets.\n","authors":["Conghao Xiong","Yi Lin","Hao Chen","Joseph Sung","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2303.05780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05777v1","updated":"2023-03-10T08:27:14Z","published":"2023-03-10T08:27:14Z","title":"Self-Supervised CSF Inpainting with Synthetic Atrophy for Improved\n  Accuracy Validation of Cortical Surface Analyses","summary":"  Accuracy validation of cortical thickness measurement is a difficult problem\ndue to the lack of ground truth data. To address this need, many methods have\nbeen developed to synthetically induce gray matter (GM) atrophy in an MRI via\ndeformable registration, creating a set of images with known changes in\ncortical thickness. However, these methods often cause blurring in atrophied\nregions, and cannot simulate realistic atrophy within deep sulci where\ncerebrospinal fluid (CSF) is obscured or absent. In this paper, we present a\nsolution using a self-supervised inpainting model to generate CSF in these\nregions and create images with more plausible GM/CSF boundaries. Specifically,\nwe introduce a novel, 3D GAN model that incorporates patch-based dropout\ntraining, edge map priors, and sinusoidal positional encoding, all of which are\nestablished methods previously limited to 2D domains. We show that our\nframework significantly improves the quality of the resulting synthetic images\nand is adaptable to unseen data with fine-tuning. We also demonstrate that our\nresulting dataset can be employed for accuracy validation of cortical\nsegmentation and thickness measurement.\n","authors":["Jiacheng Wang","Kathleen E. Larson","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2303.05777v1.pdf","comment":"Accepted at Medical Imaging with Deep Learning (MIDL) 2023"},{"id":"http://arxiv.org/abs/2112.05958v4","updated":"2023-03-10T08:24:55Z","published":"2021-12-11T11:44:09Z","title":"You Only Need End-to-End Training for Long-Tailed Recognition","summary":"  The generalization gap on the long-tailed data sets is largely owing to most\ncategories only occupying a few training samples. Decoupled training achieves\nbetter performance by training backbone and classifier separately. What causes\nthe poorer performance of end-to-end model training (e.g., logits margin-based\nmethods)? In this work, we identify a key factor that affects the learning of\nthe classifier: the channel-correlated features with low entropy before\ninputting into the classifier. From the perspective of information theory, we\nanalyze why cross-entropy loss tends to produce highly correlated features on\nthe imbalanced data. In addition, we theoretically analyze and prove its\nimpacts on the gradients of classifier weights, the condition number of\nHessian, and logits margin-based approach. Therefore, we firstly propose to use\nChannel Whitening to decorrelate (\"scatter\") the classifier's inputs for\ndecoupling the weight update and reshaping the skewed decision boundary, which\nachieves satisfactory results combined with logits margin-based method.\nHowever, when the number of minor classes are large, batch imbalance and more\nparticipation in training cause over-fitting of the major classes. We also\npropose two novel modules, Block-based Relatively Balanced Batch Sampler (B3RS)\nand Batch Embedded Training (BET) to solve the above problems, which makes the\nend-to-end training achieve even better performance than decoupled training.\nExperimental results on the long-tailed classification benchmarks, CIFAR-LT and\nImageNet-LT, demonstrate the effectiveness of our method.\n","authors":["Zhiwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2112.05958v4.pdf","comment":"This is a draft"},{"id":"http://arxiv.org/abs/2303.05775v1","updated":"2023-03-10T08:22:36Z","published":"2023-03-10T08:22:36Z","title":"Self-NeRF: A Self-Training Pipeline for Few-Shot Neural Radiance Fields","summary":"  Recently, Neural Radiance Fields (NeRF) have emerged as a potent method for\nsynthesizing novel views from a dense set of images. Despite its impressive\nperformance, NeRF is plagued by its necessity for numerous calibrated views and\nits accuracy diminishes significantly in a few-shot setting. To address this\nchallenge, we propose Self-NeRF, a self-evolved NeRF that iteratively refines\nthe radiance fields with very few number of input views, without incorporating\nadditional priors. Basically, we train our model under the supervision of\nreference and unseen views simultaneously in an iterative procedure. In each\niteration, we label unseen views with the predicted colors or warped pixels\ngenerated by the model from the preceding iteration. However, these expanded\npseudo-views are afflicted by imprecision in color and warping artifacts, which\ndegrades the performance of NeRF. To alleviate this issue, we construct an\nuncertainty-aware NeRF with specialized embeddings. Some techniques such as\ncone entropy regularization are further utilized to leverage the pseudo-views\nin the most efficient manner. Through experiments under various settings, we\nverified that our Self-NeRF is robust to input with uncertainty and surpasses\nexisting methods when trained on limited training data.\n","authors":["Jiayang Bai","Letian Huang","Wen Gong","Jie Guo","Yanwen Guo"],"pdf_url":"https://arxiv.org/pdf/2303.05775v1.pdf","comment":"11 pages, 11 figures"},{"id":"http://arxiv.org/abs/2303.05768v1","updated":"2023-03-10T08:09:40Z","published":"2023-03-10T08:09:40Z","title":"Learning Global-Local Correspondence with Semantic Bottleneck for\n  Logical Anomaly Detection","summary":"  This paper presents a novel framework, named Global-Local Correspondence\nFramework (GLCF), for visual anomaly detection with logical constraints. Visual\nanomaly detection has become an active research area in various real-world\napplications, such as industrial anomaly detection and medical disease\ndiagnosis. However, most existing methods focus on identifying local structural\ndegeneration anomalies and often fail to detect high-level functional anomalies\nthat involve logical constraints. To address this issue, we propose a\ntwo-branch approach that consists of a local branch for detecting structural\nanomalies and a global branch for detecting logical anomalies. To facilitate\nlocal-global feature correspondence, we introduce a novel semantic bottleneck\nenabled by the visual Transformer. Moreover, we develop feature estimation\nnetworks for each branch separately to detect anomalies. Our proposed framework\nis validated using various benchmarks, including industrial datasets, Mvtec AD,\nMvtec Loco AD, and the Retinal-OCT medical dataset. Experimental results show\nthat our method outperforms existing methods, particularly in detecting logical\nanomalies.\n","authors":["Haiming Yao","Wenyong Yu","Wei Luo","Zhenfeng Qiang","Donghao Luo","Xiaotian Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05768v1.pdf","comment":"Submission to IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO\n  TECHNOLOGY"},{"id":"http://arxiv.org/abs/2303.05763v1","updated":"2023-03-10T08:04:16Z","published":"2023-03-10T08:04:16Z","title":"Automatic Detection and Rectification of Paper Receipts on Smartphones","summary":"  We describe the development of a real-time smartphone app that allows the\nuser to digitize paper receipts in a novel way by \"waving\" their phone over the\nreceipts and letting the app automatically detect and rectify the receipts for\nsubsequent text recognition.\n  We show that traditional computer vision algorithms for edge and corner\ndetection do not robustly detect the non-linear and discontinuous edges and\ncorners of a typical paper receipt in real-world settings. This is particularly\nthe case when the colors of the receipt and background are similar, or where\nother interfering rectangular objects are present. Inaccurate detection of a\nreceipt's corner positions then results in distorted images when using an\naffine projective transformation to rectify the perspective.\n  We propose an innovative solution to receipt corner detection by treating\neach of the four corners as a unique \"object\", and training a Single Shot\nDetection MobileNet object detection model. We use a small amount of real data\nand a large amount of automatically generated synthetic data that is designed\nto be similar to real-world imaging scenarios.\n  We show that our proposed method robustly detects the four corners of a\nreceipt, giving a receipt detection accuracy of 85.3% on real-world data,\ncompared to only 36.9% with a traditional edge detection-based approach. Our\nmethod works even when the color of the receipt is virtually indistinguishable\nfrom the background.\n  Moreover, our method is trained to detect only the corners of the central\ntarget receipt and implicitly learns to ignore other receipts, and other\nrectangular objects. Including synthetic data allows us to train an even better\nmodel. These factors are a major advantage over traditional edge\ndetection-based approaches, allowing us to deliver a much better experience to\nthe user.\n","authors":["Edward Whittaker","Masashi Tanaka","Ikuo Kitagishi"],"pdf_url":"https://arxiv.org/pdf/2303.05763v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02095v2","updated":"2023-03-10T08:04:01Z","published":"2023-03-03T17:24:39Z","title":"Data-Efficient Training of CNNs and Transformers with Coresets: A\n  Stability Perspective","summary":"  Coreset selection is among the most effective ways to reduce the training\ntime of CNNs, however, only limited is known on how the resultant models will\nbehave under variations of the coreset size, and choice of datasets and models.\nMoreover, given the recent paradigm shift towards transformer-based models, it\nis still an open question how coreset selection would impact their performance.\nThere are several similar intriguing questions that need to be answered for a\nwide acceptance of coreset selection methods, and this paper attempts to answer\nsome of these. We present a systematic benchmarking setup and perform a\nrigorous comparison of different coreset selection methods on CNNs and\ntransformers. Our investigation reveals that under certain circumstances,\nrandom selection of subsets is more robust and stable when compared with the\nSOTA selection methods. We demonstrate that the conventional concept of uniform\nsubset sampling across the various classes of the data is not the appropriate\nchoice. Rather samples should be adaptively chosen based on the complexity of\nthe data distribution for each class. Transformers are generally pretrained on\nlarge datasets, and we show that for certain target datasets, it helps to keep\ntheir performance stable at even very small coreset sizes. We further show that\nwhen no pretraining is done or when the pretrained transformer models are used\nwith non-natural images (e.g. medical data), CNNs tend to generalize better\nthan transformers at even very small coreset sizes. Lastly, we demonstrate that\nin the absence of the right pretraining, CNNs are better at learning the\nsemantic coherence between spatially distant objects within an image, and these\ntend to outperform transformers at almost all choices of the coreset size.\n","authors":["Animesh Gupta","Irtiza Hasan","Dilip K. Prasad","Deepak K. Gupta"],"pdf_url":"https://arxiv.org/pdf/2303.02095v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05762v1","updated":"2023-03-10T08:01:23Z","published":"2023-03-10T08:01:23Z","title":"TrojDiff: Trojan Attacks on Diffusion Models with Diverse Targets","summary":"  Diffusion models have achieved great success in a range of tasks, such as\nimage synthesis and molecule design. As such successes hinge on large-scale\ntraining data collected from diverse sources, the trustworthiness of these\ncollected data is hard to control or audit. In this work, we aim to explore the\nvulnerabilities of diffusion models under potential training data manipulations\nand try to answer: How hard is it to perform Trojan attacks on well-trained\ndiffusion models? What are the adversarial targets that such Trojan attacks can\nachieve? To answer these questions, we propose an effective Trojan attack\nagainst diffusion models, TrojDiff, which optimizes the Trojan diffusion and\ngenerative processes during training. In particular, we design novel\ntransitions during the Trojan diffusion process to diffuse adversarial targets\ninto a biased Gaussian distribution and propose a new parameterization of the\nTrojan generative process that leads to an effective training objective for the\nattack. In addition, we consider three types of adversarial targets: the\nTrojaned diffusion models will always output instances belonging to a certain\nclass from the in-domain distribution (In-D2D attack), out-of-domain\ndistribution (Out-D2D-attack), and one specific instance (D2I attack). We\nevaluate TrojDiff on CIFAR-10 and CelebA datasets against both DDPM and DDIM\ndiffusion models. We show that TrojDiff always achieves high attack performance\nunder different adversarial targets using different types of triggers, while\nthe performance in benign environments is preserved. The code is available at\nhttps://github.com/chenweixin107/TrojDiff.\n","authors":["Weixin Chen","Dawn Song","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2303.05762v1.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2302.14402v2","updated":"2023-03-10T07:56:58Z","published":"2023-02-28T08:35:50Z","title":"Neural Video Compression with Diverse Contexts","summary":"  For any video codecs, the coding efficiency highly relies on whether the\ncurrent signal to be encoded can find the relevant contexts from the previous\nreconstructed signals. Traditional codec has verified more contexts bring\nsubstantial coding gain, but in a time-consuming manner. However, for the\nemerging neural video codec (NVC), its contexts are still limited, leading to\nlow compression ratio. To boost NVC, this paper proposes increasing the context\ndiversity in both temporal and spatial dimensions. First, we guide the model to\nlearn hierarchical quality patterns across frames, which enriches long-term and\nyet high-quality temporal contexts. Furthermore, to tap the potential of\noptical flow-based coding framework, we introduce a group-based offset\ndiversity where the cross-group interaction is proposed for better context\nmining. In addition, this paper also adopts a quadtree-based partition to\nincrease spatial context diversity when encoding the latent representation in\nparallel. Experiments show that our codec obtains 23.5% bitrate saving over\nprevious SOTA NVC. Better yet, our codec has surpassed the under-developing\nnext generation traditional codec/ECM in both RGB and YUV420 colorspaces, in\nterms of PSNR. The codes are at https://github.com/microsoft/DCVC.\n","authors":["Jiahao Li","Bin Li","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2302.14402v2.pdf","comment":"Accepted by CVPR 2023. Codes are at https://github.com/microsoft/DCVC"},{"id":"http://arxiv.org/abs/2303.05754v1","updated":"2023-03-10T07:42:49Z","published":"2023-03-10T07:42:49Z","title":"Fast Diffusion Sampler for Inverse Problems by Geometric Decomposition","summary":"  Diffusion models have shown exceptional performance in solving inverse\nproblems. However, one major limitation is the slow inference time. While\nfaster diffusion samplers have been developed for unconditional sampling, there\nhas been limited research on conditional sampling in the context of inverse\nproblems. In this study, we propose a novel and efficient diffusion sampling\nstrategy that employs the geometric decomposition of diffusion sampling.\nSpecifically, we discover that the samples generated from diffusion models can\nbe decomposed into two orthogonal components: a ``denoised\" component obtained\nby projecting the sample onto the clean data manifold, and a ``noise\" component\nthat induces a transition to the next lower-level noisy manifold with the\naddition of stochastic noise. Furthermore, we prove that, under some conditions\non the clean data manifold, the conjugate gradient update for imposing\nconditioning from the denoised signal belongs to the clean manifold, resulting\nin a much faster and more accurate diffusion sampling. Our method is applicable\nregardless of the parameterization and setting (i.e., VE, VP). Notably, we\nachieve state-of-the-art reconstruction quality on challenging real-world\nmedical inverse imaging problems, including multi-coil MRI reconstruction and\n3D CT reconstruction. Moreover, our proposed method achieves more than 80 times\nfaster inference time than the previous state-of-the-art method.\n","authors":["Hyungjin Chung","Suhyeon Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2303.05754v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2303.05752v1","updated":"2023-03-10T07:40:09Z","published":"2023-03-10T07:40:09Z","title":"Deep Learning for Predicting Metastasis on Melanoma WSIs","summary":"  Northern Europe has the second highest mortality rate of melanoma globally.\nIn 2020, the mortality rate of melanoma rose to 1.9 per 100 000 habitants.\nMelanoma prognosis is based on a pathologist's subjective visual analysis of\nthe patient's tumor. This methodology is heavily time-consuming, and the\nprognosis variability among experts is notable, drastically jeopardizing its\nreproducibility. Thus, the need for faster and more reproducible methods\narises. Machine learning has paved its way into digital pathology, but so far,\nmost contributions are on localization, segmentation, and diagnostics, with\nlittle emphasis on prognostics. This paper presents a convolutional neural\nnetwork (CNN) method based on VGG16 to predict melanoma prognosis as the\npresence of metastasis within five years. Patches are extracted from regions of\ninterest from Whole Slide Images (WSIs) at different magnification levels used\nin model training and validation. Results infer that utilizing WSI patches at\n20x magnification level has the best performance, with an F1 score of 0.7667\nand an AUC of 0.81.\n","authors":["Christopher Andreassen","Saul Fuster","Helga Hardardottir","Emiel A. M. Janssen","Kjersti Engan"],"pdf_url":"https://arxiv.org/pdf/2303.05752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05325v2","updated":"2023-03-10T07:39:42Z","published":"2023-03-09T15:15:55Z","title":"BaDLAD: A Large Multi-Domain Bengali Document Layout Analysis Dataset","summary":"  While strides have been made in deep learning based Bengali Optical Character\nRecognition (OCR) in the past decade, the absence of large Document Layout\nAnalysis (DLA) datasets has hindered the application of OCR in document\ntranscription, e.g., transcribing historical documents and newspapers.\nMoreover, rule-based DLA systems that are currently being employed in practice\nare not robust to domain variations and out-of-distribution layouts. To this\nend, we present the first multidomain large Bengali Document Layout Analysis\nDataset: BaDLAD. This dataset contains 33,695 human annotated document samples\nfrom six domains - i) books and magazines, ii) public domain govt. documents,\niii) liberation war documents, iv) newspapers, v) historical newspapers, and\nvi) property deeds, with 710K polygon annotations for four unit types:\ntext-box, paragraph, image, and table. Through preliminary experiments\nbenchmarking the performance of existing state-of-the-art deep learning\narchitectures for English DLA, we demonstrate the efficacy of our dataset in\ntraining deep learning based Bengali document digitization models.\n","authors":["Md. Istiak Hossain Shihab","Md. Rakibul Hasan","Mahfuzur Rahman Emon","Syed Mobassir Hossen","Md. Nazmuddoha Ansary","Intesur Ahmed","Fazle Rabbi Rakib","Shahriar Elahi Dhruvo","Souhardya Saha Dip","Akib Hasan Pavel","Marsia Haque Meghla","Md. Rezwanul Haque","Sayma Sultana Chowdhury","Farig Sadeque","Tahsin Reasat","Ahmed Imtiaz Humayun","Asif Shahriyar Sushmit"],"pdf_url":"https://arxiv.org/pdf/2303.05325v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07839v3","updated":"2023-03-10T07:37:34Z","published":"2022-10-02T07:29:57Z","title":"Contrastive Audio-Visual Masked Autoencoder","summary":"  In this paper, we first extend the recent Masked Auto-Encoder (MAE) model\nfrom a single modality to audio-visual multi-modalities. Subsequently, we\npropose the Contrastive Audio-Visual Masked Auto-Encoder (CAV-MAE) by combining\ncontrastive learning and masked data modeling, two major self-supervised\nlearning frameworks, to learn a joint and coordinated audio-visual\nrepresentation. Our experiments show that the contrastive audio-visual\ncorrespondence learning objective not only enables the model to perform\naudio-visual retrieval tasks, but also helps the model learn a better joint\nrepresentation. As a result, our fully self-supervised pretrained CAV-MAE\nachieves a new SOTA accuracy of 65.9% on VGGSound, and is comparable with the\nprevious best supervised pretrained model on AudioSet in the audio-visual event\nclassification task. Code and pretrained models are at\nhttps://github.com/yuangongnd/cav-mae.\n","authors":["Yuan Gong","Andrew Rouditchenko","Alexander H. Liu","David Harwath","Leonid Karlinsky","Hilde Kuehne","James Glass"],"pdf_url":"https://arxiv.org/pdf/2210.07839v3.pdf","comment":"Accepted at ICLR 2023 as a notable top 25% paper. Code and pretrained\n  models are at https://github.com/yuangongnd/cav-mae"},{"id":"http://arxiv.org/abs/2303.03916v3","updated":"2023-03-10T07:28:09Z","published":"2023-03-07T14:26:08Z","title":"A survey on automated detection and classification of acute leukemia and\n  WBCs in microscopic blood cells","summary":"  Leukemia (blood cancer) is an unusual spread of White Blood Cells or\nLeukocytes (WBCs) in the bone marrow and blood. Pathologists can diagnose\nleukemia by looking at a person's blood sample under a microscope. They\nidentify and categorize leukemia by counting various blood cells and\nmorphological features. This technique is time-consuming for the prediction of\nleukemia. The pathologist's professional skills and experiences may be\naffecting this procedure, too. In computer vision, traditional machine learning\nand deep learning techniques are practical roadmaps that increase the accuracy\nand speed in diagnosing and classifying medical images such as microscopic\nblood cells. This paper provides a comprehensive analysis of the detection and\nclassification of acute leukemia and WBCs in the microscopic blood cells.\nFirst, we have divided the previous works into six categories based on the\noutput of the models. Then, we describe various steps of detection and\nclassification of acute leukemia and WBCs, including Data Augmentation,\nPreprocessing, Segmentation, Feature Extraction, Feature Selection (Reduction),\nClassification, and focus on classification step in the methods. Finally, we\ndivide automated detection and classification of acute leukemia and WBCs into\nthree categories, including traditional, Deep Neural Network (DNN), and mixture\n(traditional and DNN) methods based on the type of classifier in the\nclassification step and analyze them. The results of this study show that in\nthe diagnosis and classification of acute leukemia and WBCs, the Support Vector\nMachine (SVM) classifier in traditional machine learning models and\nConvolutional Neural Network (CNN) classifier in deep learning models have\nwidely employed. The performance metrics of the models that use these\nclassifiers compared to the others model are higher.\n","authors":["Mohammad Zolfaghari","Hedieh Sajedi"],"pdf_url":"https://arxiv.org/pdf/2303.03916v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.07227v2","updated":"2023-03-10T07:12:32Z","published":"2022-08-15T14:32:10Z","title":"DM-NeRF: 3D Scene Geometry Decomposition and Manipulation from 2D Images","summary":"  In this paper, we study the problem of 3D scene geometry decomposition and\nmanipulation from 2D views. By leveraging the recent implicit neural\nrepresentation techniques, particularly the appealing neural radiance fields,\nwe introduce an object field component to learn unique codes for all individual\nobjects in 3D space only from 2D supervision. The key to this component is a\nseries of carefully designed loss functions to enable every 3D point,\nespecially in non-occupied space, to be effectively optimized even without 3D\nlabels. In addition, we introduce an inverse query algorithm to freely\nmanipulate any specified 3D object shape in the learned scene representation.\nNotably, our manipulation algorithm can explicitly tackle key issues such as\nobject collisions and visual occlusions. Our method, called DM-NeRF, is among\nthe first to simultaneously reconstruct, decompose, manipulate and render\ncomplex 3D scenes in a single pipeline. Extensive experiments on three datasets\nclearly show that our method can accurately decompose all 3D objects from 2D\nviews, allowing any interested object to be freely manipulated in 3D space such\nas translation, rotation, size adjustment, and deformation.\n","authors":["Bing Wang","Lu Chen","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2208.07227v2.pdf","comment":"ICLR 2023. Our data and code are available at:\n  https://github.com/vLAR-group/DM-NeRF"},{"id":"http://arxiv.org/abs/2303.05745v1","updated":"2023-03-10T07:08:25Z","published":"2023-03-10T07:08:25Z","title":"Multi-site, Multi-domain Airway Tree Modeling (ATM'22): A Public\n  Benchmark for Pulmonary Airway Segmentation","summary":"  Open international challenges are becoming the de facto standard for\nassessing computer vision and image analysis algorithms. In recent years, new\nmethods have extended the reach of pulmonary airway segmentation that is closer\nto the limit of image resolution. Since EXACT'09 pulmonary airway segmentation,\nlimited effort has been directed to quantitative comparison of newly emerged\nalgorithms driven by the maturity of deep learning based approaches and\nclinical drive for resolving finer details of distal airways for early\nintervention of pulmonary diseases. Thus far, public annotated datasets are\nextremely limited, hindering the development of data-driven methods and\ndetailed performance evaluation of new algorithms. To provide a benchmark for\nthe medical imaging community, we organized the Multi-site, Multi-domain Airway\nTree Modeling (ATM'22), which was held as an official challenge event during\nthe MICCAI 2022 conference. ATM'22 provides large-scale CT scans with detailed\npulmonary airway annotation, including 500 CT scans (300 for training, 50 for\nvalidation, and 150 for testing). The dataset was collected from different\nsites and it further included a portion of noisy COVID-19 CTs with ground-glass\nopacity and consolidation. Twenty-three teams participated in the entire phase\nof the challenge and the algorithms for the top ten teams are reviewed in this\npaper. Quantitative and qualitative results revealed that deep learning models\nembedded with the topological continuity enhancement achieved superior\nperformance in general. ATM'22 challenge holds as an open-call design, the\ntraining data and the gold standard evaluation are available upon successful\nregistration via its homepage.\n","authors":["Minghui Zhang","Yangqian Wu","Hanxiao Zhang","Yulei Qin","Hao Zheng","Wen Tang","Corey Arnold","Chenhao Pei","Pengxin Yu","Yang Nan","Guang Yang","Simon Walsh","Dominic C. Marshall","Matthieu Komorowski","Puyang Wang","Dazhou Guo","Dakai Jin","Ya'nan Wu","Shuiqing Zhao","Runsheng Chang","Boyu Zhang","Xing Lv","Abdul Qayyum","Moona Mazher","Qi Su","Yonghuang Wu","Ying'ao Liu","Yufei Zhu","Jiancheng Yang","Ashkan Pakzad","Bojidar Rangelov","Raul San Jose Estepar","Carlos Cano Espinosa","Jiayuan Sun","Guang-Zhong Yang","Yun Gu"],"pdf_url":"https://arxiv.org/pdf/2303.05745v1.pdf","comment":"32 pages, 16 figures. Homepage: https://atm22.grand-challenge.org/.\n  Submitted"},{"id":"http://arxiv.org/abs/2303.05739v1","updated":"2023-03-10T06:49:31Z","published":"2023-03-10T06:49:31Z","title":"Boosting Semi-Supervised Few-Shot Object Detection with SoftER Teacher","summary":"  Few-shot object detection is an emerging problem aimed at detecting novel\nconcepts from few exemplars. Existing approaches to few-shot detection assume\nabundant base labels to adapt to novel objects. This paper explores the task of\nsemi-supervised few-shot detection by considering a realistic scenario which\nlacks abundant labels for both base and novel objects. Motivated by this unique\nproblem, we introduce SoftER Teacher, a robust detector combining the\nadvantages of pseudo-labeling with representation learning on region proposals.\nSoftER Teacher harnesses unlabeled data to jointly optimize for semi-supervised\nfew-shot detection without explicitly relying on abundant base labels.\nExtensive experiments show that SoftER Teacher matches the novel class\nperformance of a strong supervised detector using only 10% of base labels. Our\nwork also sheds insight into a previously unknown relationship between\nsemi-supervised and few-shot detection to suggest that a stronger\nsemi-supervised detector leads to a more label-efficient few-shot detector.\nCode and models are available at\nhttps://github.com/lexisnexis-risk-open-source/ledetection\n","authors":["Phi Vu Tran"],"pdf_url":"https://arxiv.org/pdf/2303.05739v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2303.05734v1","updated":"2023-03-10T06:43:55Z","published":"2023-03-10T06:43:55Z","title":"Generative Model Based Noise Robust Training for Unsupervised Domain\n  Adaptation","summary":"  Target domain pseudo-labelling has shown effectiveness in unsupervised domain\nadaptation (UDA). However, pseudo-labels of unlabeled target domain data are\ninevitably noisy due to the distribution shift between source and target\ndomains. This paper proposes a Generative model-based Noise-Robust Training\nmethod (GeNRT), which eliminates domain shift while mitigating label noise.\nGeNRT incorporates a Distribution-based Class-wise Feature Augmentation (D-CFA)\nand a Generative-Discriminative classifier Consistency (GDC), both based on the\nclass-wise target distributions modelled by generative models. D-CFA minimizes\nthe domain gap by augmenting the source data with distribution-sampled target\nfeatures, and trains a noise-robust discriminative classifier by using target\ndomain knowledge from the generative models. GDC regards all the class-wise\ngenerative models as generative classifiers and enforces a consistency\nregularization between the generative and discriminative classifiers. It\nexploits an ensemble of target knowledge from all the generative models to\ntrain a noise-robust discriminative classifier and eventually gets\ntheoretically linked to the Ben-David domain adaptation theorem for reducing\nthe domain gap. Extensive experiments on Office-Home, PACS, and Digit-Five show\nthat our GeNRT achieves comparable performance to state-of-the-art methods\nunder single-source and multi-source UDA settings.\n","authors":["Zhongying Deng","Da Li","Junjun He","Yi-Zhe Song","Tao Xiang"],"pdf_url":"https://arxiv.org/pdf/2303.05734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00914v2","updated":"2023-03-10T06:43:31Z","published":"2023-03-02T02:18:56Z","title":"Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation","summary":"  Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. We take\ninspiration from the biological plausibility learning where the neuron\nresponses are tuned based on a local synapse-change procedure and activated by\ncompetitive lateral inhibition rules. Based on these feed-forward learning\nrules, we design a soft Hebbian learning process which provides an unsupervised\nand effective mechanism for online adaptation. We observe that the performance\nof this feed-forward Hebbian learning for fully test-time adaptation can be\nsignificantly improved by incorporating a feedback neuro-modulation layer. It\nis able to fine-tune the neuron responses based on the external feedback\ngenerated by the error back-propagation from the top inference layers. This\nleads to our proposed neuro-modulated Hebbian learning (NHL) method for fully\ntest-time adaptation. With the unsupervised feed-forward soft Hebbian learning\nbeing combined with a learned neuro-modulator to capture feedback from external\nresponses, the source model can be effectively adapted during the testing\nprocess. Experimental results on benchmark datasets demonstrate that our\nproposed method can significantly improve the adaptation performance of network\nmodels and outperforms existing state-of-the-art methods.\n","authors":["Yushun Tang","Ce Zhang","Heng Xu","Shuoshuo Chen","Jie Cheng","Luziwei Leng","Qinghai Guo","Zhihai He"],"pdf_url":"https://arxiv.org/pdf/2303.00914v2.pdf","comment":"CVPR2023 accepted"},{"id":"http://arxiv.org/abs/2303.05499v2","updated":"2023-03-10T06:37:04Z","published":"2023-03-09T18:52:16Z","title":"Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set\n  Object Detection","summary":"  In this paper, we present an open-set object detector, called Grounding DINO,\nby marrying Transformer-based detector DINO with grounded pre-training, which\ncan detect arbitrary objects with human inputs such as category names or\nreferring expressions. The key solution of open-set object detection is\nintroducing language to a closed-set detector for open-set concept\ngeneralization. To effectively fuse language and vision modalities, we\nconceptually divide a closed-set detector into three phases and propose a tight\nfusion solution, which includes a feature enhancer, a language-guided query\nselection, and a cross-modality decoder for cross-modality fusion. While\nprevious works mainly evaluate open-set object detection on novel categories,\nwe propose to also perform evaluations on referring expression comprehension\nfor objects specified with attributes. Grounding DINO performs remarkably well\non all three settings, including benchmarks on COCO, LVIS, ODinW, and\nRefCOCO/+/g. Grounding DINO achieves a $52.5$ AP on the COCO detection\nzero-shot transfer benchmark, i.e., without any training data from COCO. It\nsets a new record on the ODinW zero-shot benchmark with a mean $26.1$ AP. Code\nwill be available at \\url{https://github.com/IDEA-Research/GroundingDINO}.\n","authors":["Shilong Liu","Zhaoyang Zeng","Tianhe Ren","Feng Li","Hao Zhang","Jie Yang","Chunyuan Li","Jianwei Yang","Hang Su","Jun Zhu","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05499v2.pdf","comment":"Code will be available at\n  https://github.com/IDEA-Research/GroundingDINO"},{"id":"http://arxiv.org/abs/2210.10108v2","updated":"2023-03-10T06:27:33Z","published":"2022-10-18T19:09:58Z","title":"Parallel Inversion of Neural Radiance Fields for Robust Pose Estimation","summary":"  We present a parallelized optimization method based on fast Neural Radiance\nFields (NeRF) for estimating 6-DoF pose of a camera with respect to an object\nor scene. Given a single observed RGB image of the target, we can predict the\ntranslation and rotation of the camera by minimizing the residual between\npixels rendered from a fast NeRF model and pixels in the observed image. We\nintegrate a momentum-based camera extrinsic optimization procedure into Instant\nNeural Graphics Primitives, a recent exceptionally fast NeRF implementation. By\nintroducing parallel Monte Carlo sampling into the pose estimation task, our\nmethod overcomes local minima and improves efficiency in a more extensive\nsearch space. We also show the importance of adopting a more robust pixel-based\nloss function to reduce error. Experiments demonstrate that our method can\nachieve improved generalization and robustness on both synthetic and real-world\nbenchmarks.\n","authors":["Yunzhi Lin","Thomas Müller","Jonathan Tremblay","Bowen Wen","Stephen Tyree","Alex Evans","Patricio A. Vela","Stan Birchfield"],"pdf_url":"https://arxiv.org/pdf/2210.10108v2.pdf","comment":"ICRA 2023. Project page at https://pnerfp.github.io/"},{"id":"http://arxiv.org/abs/2202.07291v4","updated":"2023-03-10T06:26:10Z","published":"2022-02-15T10:17:02Z","title":"Exploring Discontinuity for Video Frame Interpolation","summary":"  Video frame interpolation (VFI) is the task that synthesizes the intermediate\nframe given two consecutive frames. Most of the previous studies have focused\non appropriate frame warping operations and refinement modules for the warped\nframes. These studies have been conducted on natural videos containing only\ncontinuous motions. However, many practical videos contain various unnatural\nobjects with discontinuous motions such as logos, user interfaces and\nsubtitles. We propose three techniques to make the existing deep learning-based\nVFI architectures robust to these elements. First is a novel data augmentation\nstrategy called figure-text mixing (FTM) which can make the models learn\ndiscontinuous motions during training stage without any extra dataset. Second,\nwe propose a simple but effective module that predicts a map called\ndiscontinuity map (D-map), which densely distinguishes between areas of\ncontinuous and discontinuous motions. Lastly, we propose loss functions to give\nsupervisions of the discontinuous motion areas which can be applied along with\nFTM and D-map. We additionally collect a special test benchmark called\nGraphical Discontinuous Motion (GDM) dataset consisting of some mobile games\nand chatting videos. Applied to the various state-of-the-art VFI networks, our\nmethod significantly improves the interpolation qualities on the videos from\nnot only GDM dataset, but also the existing benchmarks containing only\ncontinuous motions such as Vimeo90K, UCF101, and DAVIS.\n","authors":["Sangjin Lee","Hyeongmin Lee","Chajin Shin","Hanbin Son","Sangyoun Lee"],"pdf_url":"https://arxiv.org/pdf/2202.07291v4.pdf","comment":"CVPR2023 Accepted (The IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition 2023)"},{"id":"http://arxiv.org/abs/2303.05730v1","updated":"2023-03-10T06:23:16Z","published":"2023-03-10T06:23:16Z","title":"IC classifier: a classifier for 3D industrial components based on\n  geometric prior using GNN","summary":"  In this paper, we propose an approach to address the problem of classifying\n3D industrial components by introducing a novel framework named IC-classifier\n(Industrial Component classifier). Our framework is designed to focus on the\nobject's local and global structures, emphasizing the former by incorporating\nspecific local features for embedding the model. By utilizing graphical neural\nnetworks and embedding derived from geometric properties, IC-classifier\nfacilitates the exploration of the local structures of the object while using\ngeometric attention for the analysis of global structures. Furthermore, the\nframework uses point clouds to circumvent the heavy computation workload. The\nproposed framework's performance is benchmarked against state-of-the-art\nmodels, demonstrating its potential to compete in the field.\n","authors":["Zipeng Lin","Zhenguo Nie"],"pdf_url":"https://arxiv.org/pdf/2303.05730v1.pdf","comment":"15 pages including citations, 3 pages of figures"},{"id":"http://arxiv.org/abs/2210.11668v2","updated":"2023-03-10T06:13:13Z","published":"2022-10-21T01:45:08Z","title":"RGB-Only Reconstruction of Tabletop Scenes for Collision-Free\n  Manipulator Control","summary":"  We present a system for collision-free control of a robot manipulator that\nuses only RGB views of the world. Perceptual input of a tabletop scene is\nprovided by multiple images of an RGB camera (without depth) that is either\nhandheld or mounted on the robot end effector. A NeRF-like process is used to\nreconstruct the 3D geometry of the scene, from which the Euclidean full signed\ndistance function (ESDF) is computed. A model predictive control algorithm is\nthen used to control the manipulator to reach a desired pose while avoiding\nobstacles in the ESDF. We show results on a real dataset collected and\nannotated in our lab.\n","authors":["Zhenggang Tang","Balakumar Sundaralingam","Jonathan Tremblay","Bowen Wen","Ye Yuan","Stephen Tyree","Charles Loop","Alexander Schwing","Stan Birchfield"],"pdf_url":"https://arxiv.org/pdf/2210.11668v2.pdf","comment":"ICRA 2023. Project page at https://ngp-mpc.github.io/"},{"id":"http://arxiv.org/abs/2303.05725v1","updated":"2023-03-10T06:12:36Z","published":"2023-03-10T06:12:36Z","title":"CVT-SLR: Contrastive Visual-Textual Transformation for Sign Language\n  Recognition with Variational Alignment","summary":"  Sign language recognition (SLR) is a weakly supervised task that annotates\nsign videos as textual glosses. Recent studies show that insufficient training\ncaused by the lack of large-scale available sign language datasets becomes the\nmain bottleneck for SLR. The majority of SLR works thereby adopt pretrained\nvisual modules and develop two mainstream solutions. The multi-stream\narchitectures extend multi-cue visual features, yielding the current SOTA\nperformances but requiring complex designs and might introduce potential noise.\nAlternatively, the advanced single-cue SLR frameworks using explicit\ncross-modal alignment between visual and textual modalities are simple and\neffective, potentially competitive with the multi-cue framework. In this work,\nwe propose a novel contrastive visual-textual transformation for SLR, CVT-SLR,\nto fully explore the pretrained knowledge of both the visual and language\nmodalities. Based on the single-cue cross-modal alignment framework, we propose\na variational autoencoder (VAE) for pretrained contextual knowledge while\nintroducing the complete pretrained language module. The VAE implicitly aligns\nvisual and textual modalities while benefiting from pretrained contextual\nknowledge as the traditional contextual module. Meanwhile, a contrastive\ncross-modal alignment algorithm is proposed to further enhance the explicit\nconsistency constraints. Extensive experiments conducted on the two most\npopular public datasets, PHOENIX-2014 and PHOENIX-2014T, demonstrate that our\nproposed SLR framework not only consistently outperforms existing single-cue\nmethods but even outperforms SOTA multi-cue methods.\n","authors":["Jiangbin Zheng","Yile Wang","Cheng Tan","Siyuan Li","Ge Wang","Jun Xia","Yidong Chen","Stan Z. Li"],"pdf_url":"https://arxiv.org/pdf/2303.05725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05724v1","updated":"2023-03-10T06:08:23Z","published":"2023-03-10T06:08:23Z","title":"3D Cinemagraphy from a Single Image","summary":"  We present 3D Cinemagraphy, a new technique that marries 2D image animation\nwith 3D photography. Given a single still image as input, our goal is to\ngenerate a video that contains both visual content animation and camera motion.\nWe empirically find that naively combining existing 2D image animation and 3D\nphotography methods leads to obvious artifacts or inconsistent animation. Our\nkey insight is that representing and animating the scene in 3D space offers a\nnatural solution to this task. To this end, we first convert the input image\ninto feature-based layered depth images using predicted depth values, followed\nby unprojecting them to a feature point cloud. To animate the scene, we perform\nmotion estimation and lift the 2D motion into the 3D scene flow. Finally, to\nresolve the problem of hole emergence as points move forward, we propose to\nbidirectionally displace the point cloud as per the scene flow and synthesize\nnovel views by separately projecting them into target image planes and blending\nthe results. Extensive experiments demonstrate the effectiveness of our method.\nA user study is also conducted to validate the compelling rendering results of\nour method.\n","authors":["Xingyi Li","Zhiguo Cao","Huiqiang Sun","Jianming Zhang","Ke Xian","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2303.05724v1.pdf","comment":"Accepted by CVPR 2023. Project page:\n  https://xingyi-li.github.io/3d-cinemagraphy/"},{"id":"http://arxiv.org/abs/2303.05719v1","updated":"2023-03-10T05:54:11Z","published":"2023-03-10T05:54:11Z","title":"Boosting Adversarial Attacks by Leveraging Decision Boundary Information","summary":"  Due to the gap between a substitute model and a victim model, the\ngradient-based noise generated from a substitute model may have low\ntransferability for a victim model since their gradients are different.\nInspired by the fact that the decision boundaries of different models do not\ndiffer much, we conduct experiments and discover that the gradients of\ndifferent models are more similar on the decision boundary than in the original\nposition. Moreover, since the decision boundary in the vicinity of an input\nimage is flat along most directions, we conjecture that the boundary gradients\ncan help find an effective direction to cross the decision boundary of the\nvictim models. Based on it, we propose a Boundary Fitting Attack to improve\ntransferability. Specifically, we introduce a method to obtain a set of\nboundary points and leverage the gradient information of these points to update\nthe adversarial examples. Notably, our method can be combined with existing\ngradient-based methods. Extensive experiments prove the effectiveness of our\nmethod, i.e., improving the success rate by 5.6% against normally trained CNNs\nand 14.9% against defense CNNs on average compared to state-of-the-art\ntransfer-based attacks. Further we compare transformers with CNNs, the results\nindicate that transformers are more robust than CNNs. However, our method still\noutperforms existing methods when attacking transformers. Specifically, when\nusing CNNs as substitute models, our method obtains an average attack success\nrate of 58.2%, which is 10.8% higher than other state-of-the-art transfer-based\nattacks.\n","authors":["Boheng Zeng","LianLi Gao","QiLong Zhang","ChaoQun Li","JingKuan Song","ShuaiQi Jing"],"pdf_url":"https://arxiv.org/pdf/2303.05719v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05715v1","updated":"2023-03-10T05:46:25Z","published":"2023-03-10T05:46:25Z","title":"Context-Based Trit-Plane Coding for Progressive Image Compression","summary":"  Trit-plane coding enables deep progressive image compression, but it cannot\nuse autoregressive context models. In this paper, we propose the context-based\ntrit-plane coding (CTC) algorithm to achieve progressive compression more\ncompactly. First, we develop the context-based rate reduction module to\nestimate trit probabilities of latent elements accurately and thus encode the\ntrit-planes compactly. Second, we develop the context-based distortion\nreduction module to refine partial latent tensors from the trit-planes and\nimprove the reconstructed image quality. Third, we propose a retraining scheme\nfor the decoder to attain better rate-distortion tradeoffs. Extensive\nexperiments show that CTC outperforms the baseline trit-plane codec\nsignificantly in BD-rate on the Kodak lossless dataset, while increasing the\ntime complexity only marginally. Our codes are available at\nhttps://github.com/seungminjeon-github/CTC.\n","authors":["Seungmin Jeon","Kwang Pyo Choi","Youngo Park","Chang-Su Kim"],"pdf_url":"https://arxiv.org/pdf/2303.05715v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2302.08175v4","updated":"2023-03-10T05:33:18Z","published":"2023-02-16T09:44:55Z","title":"A numerical approximation method for the Fisher-Rao distance between\n  multivariate normal distributions","summary":"  We present a simple method to approximate Rao's distance between multivariate\nnormal distributions based on discretizing curves joining normal distributions\nand approximating Rao distances between successive nearby normal distributions\non the curves by the square root of Jeffreys divergence. We consider\nexperimentally the linear interpolation curves in the ordinary, natural and\nexpectation parameterizations of the normal distributions, and compare these\ncurves with a curve derived from the Calvo and Oller's isometric embedding of\nthe Fisher-Rao $d$-variate normal manifold into the cone of $(d+1)\\times (d+1)$\nsymmetric positive-definite matrices [Journal of multivariate analysis 35.2\n(1990): 223-242]. We report on our experiments and assess the quality of our\napproximation technique by comparing the numerical approximations with lower\nand upper bounds. Finally, we present some information-geometric properties of\nthe Calvo and Oller's isometric embedding.\n","authors":["Frank Nielsen"],"pdf_url":"https://arxiv.org/pdf/2302.08175v4.pdf","comment":"30 pages, 16 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.05708v1","updated":"2023-03-10T05:22:45Z","published":"2023-03-10T05:22:45Z","title":"Self-supervised Facial Action Unit Detection with Region and Relation\n  Learning","summary":"  Facial action unit (AU) detection is a challenging task due to the scarcity\nof manual annotations. Recent works on AU detection with self-supervised\nlearning have emerged to address this problem, aiming to learn meaningful AU\nrepresentations from numerous unlabeled data. However, most existing AU\ndetection works with self-supervised learning utilize global facial features\nonly, while AU-related properties such as locality and relevance are not fully\nexplored. In this paper, we propose a novel self-supervised framework for AU\ndetection with the region and relation learning. In particular, AU related\nattention map is utilized to guide the model to focus more on AU-specific\nregions to enhance the integrity of AU local features. Meanwhile, an improved\nOptimal Transport (OT) algorithm is introduced to exploit the correlation\ncharacteristics among AUs. In addition, Swin Transformer is exploited to model\nthe long-distance dependencies within each AU region during feature learning.\nThe evaluation results on BP4D and DISFA demonstrate that our proposed method\nis comparable or even superior to the state-of-the-art self-supervised learning\nmethods and supervised AU detection methods.\n","authors":["Juan Song","Zhilei Liu"],"pdf_url":"https://arxiv.org/pdf/2303.05708v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.05707v1","updated":"2023-03-10T05:22:39Z","published":"2023-03-10T05:22:39Z","title":"MuLTI: Efficient Video-and-Language Understanding with MultiWay-Sampler\n  and Multiple Choice Modeling","summary":"  Video-and-language understanding has a variety of applications in the\nindustry, such as video question answering, text-video retrieval and\nmulti-label classification. Existing video-and-language understanding methods\ngenerally adopt heavy multi-modal encoders and feature fusion modules, which\nconsume large amounts of GPU memory. Especially, they have difficulty dealing\nwith dense video frames or long text that are prevalent in industrial\napplications. In this paper, we propose MuLTI, a highly accurate and\nmemory-efficient video-and-language understanding model that achieves efficient\nand effective feature fusion through feature sampling and attention modules.\nTherefore, MuLTI can handle longer sequences with limited GPU memory. Then, we\nintroduce an attention-based adapter to the encoders, which finetunes the\nshallow features to improve the model's performance with low GPU memory\nconsumption. Finally, to further improve the model's performance, we introduce\na new pretraining task named Multiple Choice Modeling to bridge the task gap\nbetween pretraining and downstream tasks and enhance the model's ability to\nalign the video and the text. Benefiting from the efficient feature fusion\nmodule, the attention-based adapter and the new pretraining task, MuLTI\nachieves state-of-the-art performance on multiple datasets. Implementation and\npretrained models will be released.\n","authors":["Jiaqi Xu","Bo Liu","Yunkuo Chen","Mengli Cheng","Xing Shi"],"pdf_url":"https://arxiv.org/pdf/2303.05707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05703v1","updated":"2023-03-10T05:06:30Z","published":"2023-03-10T05:06:30Z","title":"MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field","summary":"  We present MovingParts, a NeRF-based method for dynamic scene reconstruction\nand part discovery. We consider motion as an important cue for identifying\nparts, that all particles on the same part share the common motion pattern.\nFrom the perspective of fluid simulation, existing deformation-based methods\nfor dynamic NeRF can be seen as parameterizing the scene motion under the\nEulerian view, i.e., focusing on specific locations in space through which the\nfluid flows as time passes. However, it is intractable to extract the motion of\nconstituting objects or parts using the Eulerian view representation. In this\nwork, we introduce the dual Lagrangian view and enforce representations under\nthe Eulerian/Lagrangian views to be cycle-consistent. Under the Lagrangian\nview, we parameterize the scene motion by tracking the trajectory of particles\non objects. The Lagrangian view makes it convenient to discover parts by\nfactorizing the scene motion as a composition of part-level rigid motions.\nExperimentally, our method can achieve fast and high-quality dynamic scene\nreconstruction from even a single moving camera, and the induced part-based\nrepresentation allows direct applications of part tracking, animation, 3D scene\nediting, etc.\n","authors":["Kaizhi Yang","Xiaoshuai Zhang","Zhiao Huang","Xuejin Chen","Zexiang Xu","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2303.05703v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2211.06368v2","updated":"2023-03-10T04:55:37Z","published":"2022-11-11T17:31:25Z","title":"Phase-Shifting Coder: Predicting Accurate Orientation in Oriented Object\n  Detection","summary":"  With the vigorous development of computer vision, oriented object detection\nhas gradually been featured. In this paper, a novel differentiable angle coder\nnamed phase-shifting coder (PSC) is proposed to accurately predict the\norientation of objects, along with a dual-frequency version (PSCD). By mapping\nthe rotational periodicity of different cycles into the phase of different\nfrequencies, we provide a unified framework for various periodic fuzzy problems\ncaused by rotational symmetry in oriented object detection. Upon such a\nframework, common problems in oriented object detection such as boundary\ndiscontinuity and square-like problems are elegantly solved in a unified form.\nVisual analysis and experiments on three datasets prove the effectiveness and\nthe potentiality of our approach. When facing scenarios requiring high-quality\nbounding boxes, the proposed methods are expected to give a competitive\nperformance. The codes are publicly available at\nhttps://github.com/open-mmlab/mmrotate.\n","authors":["Yi Yu","Feipeng Da"],"pdf_url":"https://arxiv.org/pdf/2211.06368v2.pdf","comment":"Accepted to CVPR 2023, 10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.01498v2","updated":"2023-03-10T04:49:02Z","published":"2023-03-02T18:58:15Z","title":"ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit\n  Detection & Emotional Reaction Intensity Estimation Challenges","summary":"  The fifth Affective Behavior Analysis in-the-wild (ABAW) Competition is part\nof the respective ABAW Workshop which will be held in conjunction with IEEE\nComputer Vision and Pattern Recognition Conference (CVPR), 2023. The 5th ABAW\nCompetition is a continuation of the Competitions held at ECCV 2022, IEEE CVPR\n2022, ICCV 2021, IEEE FG 2020 and CVPR 2017 Conferences, and is dedicated at\nautomatically analyzing affect. For this year's Competition, we feature two\ncorpora: i) an extended version of the Aff-Wild2 database and ii) the\nHume-Reaction dataset. The former database is an audiovisual one of around 600\nvideos of around 3M frames and is annotated with respect to:a) two continuous\naffect dimensions -valence (how positive/negative a person is) and arousal (how\nactive/passive a person is)-; b) basic expressions (e.g. happiness, sadness,\nneutral state); and c) atomic facial muscle actions (i.e., action units). The\nlatter dataset is an audiovisual one in which reactions of individuals to\nemotional stimuli have been annotated with respect to seven emotional\nexpression intensities. Thus the 5th ABAW Competition encompasses four\nChallenges: i) uni-task Valence-Arousal Estimation, ii) uni-task Expression\nClassification, iii) uni-task Action Unit Detection, and iv) Emotional Reaction\nIntensity Estimation. In this paper, we present these Challenges, along with\ntheir corpora, we outline the evaluation metrics, we present the baseline\nsystems and illustrate their obtained performance.\n","authors":["Dimitrios Kollias","Panagiotis Tzirakis","Alice Baird","Alan Cowen","Stefanos Zafeiriou"],"pdf_url":"https://arxiv.org/pdf/2303.01498v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.10659"},{"id":"http://arxiv.org/abs/2303.05699v1","updated":"2023-03-10T04:49:01Z","published":"2023-03-10T04:49:01Z","title":"Feature Unlearning for Generative Models via Implicit Feedback","summary":"  We tackle the problem of feature unlearning from a pretrained image\ngenerative model. Unlike a common unlearning task where an unlearning target is\na subset of the training set, we aim to unlearn a specific feature, such as\nhairstyle from facial images, from the pretrained generative models. As the\ntarget feature is only presented in a local region of an image, unlearning the\nentire image from the pretrained model may result in losing other details in\nthe remaining region of the image. To specify which features to unlearn, we\ndevelop an implicit feedback mechanism where a user can select images\ncontaining the target feature. From the implicit feedback, we identify a latent\nrepresentation corresponding to the target feature and then use the\nrepresentation to unlearn the generative model. Our framework is generalizable\nfor the two well-known families of generative models: GANs and VAEs. Through\nexperiments on MNIST and CelebA datasets, we show that target features are\nsuccessfully removed while keeping the fidelity of the original models.\n","authors":["Saemi Moon","Seunghyuk Cho","Dongwoo Kim"],"pdf_url":"https://arxiv.org/pdf/2303.05699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04661v2","updated":"2023-03-10T04:40:25Z","published":"2023-03-08T15:29:17Z","title":"DULDA: Dual-domain Unsupervised Learned Descent Algorithm for PET image\n  reconstruction","summary":"  Deep learning based PET image reconstruction methods have achieved promising\nresults recently. However, most of these methods follow a supervised learning\nparadigm, which rely heavily on the availability of high-quality training\nlabels. In particular, the long scanning time required and high radiation\nexposure associated with PET scans make obtaining this labels impractical. In\nthis paper, we propose a dual-domain unsupervised PET image reconstruction\nmethod based on learned decent algorithm, which reconstructs high-quality PET\nimages from sinograms without the need for image labels. Specifically, we\nunroll the proximal gradient method with a learnable l2,1 norm for PET image\nreconstruction problem. The training is unsupervised, using measurement domain\nloss based on deep image prior as well as image domain loss based on rotation\nequivariance property. The experimental results domonstrate the superior\nperformance of proposed method compared with maximum likelihood expectation\nmaximazation (MLEM), total-variation regularized EM (EM-TV) and deep image\nprior based method (DIP).\n","authors":["Rui Hu","Yunmei Chen","Kyungsang Kim","Marcio Aloisio Bezerra Cavalcanti Rockenbach","Quanzheng Li","Huafeng Liu"],"pdf_url":"https://arxiv.org/pdf/2303.04661v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05696v1","updated":"2023-03-10T04:34:51Z","published":"2023-03-10T04:34:51Z","title":"Explainable Semantic Medical Image Segmentation with Style","summary":"  Semantic medical image segmentation using deep learning has recently achieved\nhigh accuracy, making it appealing to clinical problems such as radiation\ntherapy. However, the lack of high-quality semantically labelled data remains a\nchallenge leading to model brittleness to small shifts to input data. Most\nworks require extra data for semi-supervised learning and lack the\ninterpretability of the boundaries of the training data distribution during\ntraining, which is essential for model deployment in clinical practice. We\npropose a fully supervised generative framework that can achieve generalisable\nsegmentation with only limited labelled data by simultaneously constructing an\nexplorable manifold during training. The proposed approach creates medical\nimage style paired with a segmentation task driven discriminator incorporating\nend-to-end adversarial training. The discriminator is generalised to small\ndomain shifts as much as permissible by the training data, and the generator\nautomatically diversifies the training samples using a manifold of input\nfeatures learnt during segmentation. All the while, the discriminator guides\nthe manifold learning by supervising the semantic content and fine-grained\nfeatures separately during the image diversification. After training,\nvisualisation of the learnt manifold from the generator is available to\ninterpret the model limits. Experiments on a fully semantic, publicly available\npelvis dataset demonstrated that our method is more generalisable to shifts\nthan other state-of-the-art methods while being more explainable using an\nexplorable manifold.\n","authors":["Wei Dai","Siyu Liu","Craig B. Engstrom","Shekhar S. Chandra"],"pdf_url":"https://arxiv.org/pdf/2303.05696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05695v1","updated":"2023-03-10T04:23:01Z","published":"2023-03-10T04:23:01Z","title":"Mode-locking Theory for Long-Range Interaction in Artificial Neural\n  Networks","summary":"  Visual long-range interaction refers to modeling dependencies between distant\nfeature points or blocks within an image, which can significantly enhance the\nmodel's robustness. Both CNN and Transformer can establish long-range\ninteractions through layering and patch calculations. However, the underlying\nmechanism of long-range interaction in visual space remains unclear. We propose\nthe mode-locking theory as the underlying mechanism, which constrains the phase\nand wavelength relationship between waves to achieve mode-locked interference\nwaveform. We verify this theory through simulation experiments and demonstrate\nthe mode-locking pattern in real-world scene models. Our proposed theory of\nlong-range interaction provides a comprehensive understanding of the mechanism\nbehind this phenomenon in artificial neural networks. This theory can inspire\nthe integration of the mode-locking pattern into models to enhance their\nrobustness.\n","authors":["Xiuxiu Bai","Shuaishuai Zhao","Yao Gao","Zhe Liu"],"pdf_url":"https://arxiv.org/pdf/2303.05695v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2111.12664v2","updated":"2023-03-10T04:12:36Z","published":"2021-11-24T17:51:29Z","title":"MIO : Mutual Information Optimization using Self-Supervised Binary\n  Contrastive Learning","summary":"  Self-supervised contrastive learning frameworks have progressed rapidly over\nthe last few years. In this paper, we propose a novel mutual information\noptimization-based loss function for contrastive learning. We model our\npre-training task as a binary classification problem to induce an implicit\ncontrastive effect and predict whether a pair is positive or negative. We\nfurther improve the n\\\"aive loss function using the Majorize-Minimizer\nprinciple and such improvement helps us to track the problem mathematically.\nUnlike the existing methods, the proposed loss function optimizes the mutual\ninformation in both positive and negative pairs. We also present a closed-form\nexpression for the parameter gradient flow and compare the behavior of the\nproposed loss function using its Hessian eigen-spectrum to analytically study\nthe convergence of SSL frameworks. The proposed method outperforms the SOTA\ncontrastive self-supervised frameworks on benchmark datasets like CIFAR-10,\nCIFAR-100, STL-10, and Tiny-ImageNet. After 200 epochs of pre-training with\nResNet-18 as the backbone, the proposed model achieves an accuracy of 86.2\\%,\n58.18\\%, 77.49\\%, and 30.87\\% on CIFAR-10, CIFAR-100, STL-10, and Tiny-ImageNet\ndatasets, respectively, and surpasses the SOTA contrastive baseline by 1.23\\%,\n3.57\\%, 2.00\\%, and 0.33\\%, respectively.\n","authors":["Siladittya Manna","Umapada Pal","Saumik Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2111.12664v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05692v1","updated":"2023-03-10T03:50:44Z","published":"2023-03-10T03:50:44Z","title":"Semantic-Preserving Augmentation for Robust Image-Text Retrieval","summary":"  Image text retrieval is a task to search for the proper textual descriptions\nof the visual world and vice versa. One challenge of this task is the\nvulnerability to input image and text corruptions. Such corruptions are often\nunobserved during the training, and degrade the retrieval model decision\nquality substantially. In this paper, we propose a novel image text retrieval\ntechnique, referred to as robust visual semantic embedding (RVSE), which\nconsists of novel image-based and text-based augmentation techniques called\nsemantic preserving augmentation for image (SPAugI) and text (SPAugT). Since\nSPAugI and SPAugT change the original data in a way that its semantic\ninformation is preserved, we enforce the feature extractors to generate\nsemantic aware embedding vectors regardless of the corruption, improving the\nmodel robustness significantly. From extensive experiments using benchmark\ndatasets, we show that RVSE outperforms conventional retrieval schemes in terms\nof image-text retrieval performance.\n","authors":["Sunwoo Kim","Kyuhong Shim","Luong Trung Nguyen","Byonghyo Shim"],"pdf_url":"https://arxiv.org/pdf/2303.05692v1.pdf","comment":"Accepted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2205.01142v3","updated":"2023-03-10T03:50:24Z","published":"2022-05-02T18:16:17Z","title":"Cost-Aware Evaluation and Model Scaling for LiDAR-Based 3D Object\n  Detection","summary":"  Considerable research effort has been devoted to LiDAR-based 3D object\ndetection and empirical performance has been significantly improved. While\nprogress has been encouraging, we observe an overlooked issue: it is not yet\ncommon practice to compare different 3D detectors under the same cost, e.g.,\ninference latency. This makes it difficult to quantify the true performance\ngain brought by recently proposed architecture designs. The goal of this work\nis to conduct a cost-aware evaluation of LiDAR-based 3D object detectors.\nSpecifically, we focus on SECOND, a simple grid-based one-stage detector, and\nanalyze its performance under different costs by scaling its original\narchitecture. Then we compare the family of scaled SECOND with recent 3D\ndetection methods, such as Voxel R-CNN and PV-RCNN++. The results are\nsurprising. We find that, if allowed to use the same latency, SECOND can match\nthe performance of PV-RCNN++, the current state-of-the-art method on the Waymo\nOpen Dataset. Scaled SECOND also easily outperforms many recent 3D detection\nmethods published during the past year. We recommend future research control\nthe inference cost in their empirical comparison and include the family of\nscaled SECOND as a strong baseline when presenting novel 3D detection methods.\n","authors":["Xiaofang Wang","Kris M. Kitani"],"pdf_url":"https://arxiv.org/pdf/2205.01142v3.pdf","comment":"ICRA 2023"},{"id":"http://arxiv.org/abs/2303.05691v1","updated":"2023-03-10T03:49:50Z","published":"2023-03-10T03:49:50Z","title":"Human Pose Estimation from Ambiguous Pressure Recordings with\n  Spatio-temporal Masked Transformers","summary":"  Despite the impressive performance of vision-based pose estimators, they\ngenerally fail to perform well under adverse vision conditions and often don't\nsatisfy the privacy demands of customers. As a result, researchers have begun\nto study tactile sensing systems as an alternative. However, these systems\nsuffer from noisy and ambiguous recordings. To tackle this problem, we propose\na novel solution for pose estimation from ambiguous pressure data. Our method\ncomprises a spatio-temporal vision transformer with an encoder-decoder\narchitecture. Detailed experiments on two popular public datasets reveal that\nour model outperforms existing solutions in the area. Moreover, we observe that\nincreasing the number of temporal crops in the early stages of the network\npositively impacts the performance while pre-training the network in a\nself-supervised setting using a masked auto-encoder approach also further\nimproves the results.\n","authors":["Vandad Davoodnia","Ali Etemad"],"pdf_url":"https://arxiv.org/pdf/2303.05691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05689v1","updated":"2023-03-10T03:44:01Z","published":"2023-03-10T03:44:01Z","title":"Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing\n  Mistake Severity","summary":"  There is a recently discovered and intriguing phenomenon called Neural\nCollapse: at the terminal phase of training a deep neural network for\nclassification, the within-class penultimate feature means and the associated\nclassifier vectors of all flat classes collapse to the vertices of a simplex\nEquiangular Tight Frame (ETF). Recent work has tried to exploit this phenomenon\nby fixing the related classifier weights to a pre-computed ETF to induce neural\ncollapse and maximize the separation of the learned features when training with\nimbalanced data. In this work, we propose to fix the linear classifier of a\ndeep neural network to a Hierarchy-Aware Frame (HAFrame), instead of an ETF,\nand use a cosine similarity-based auxiliary loss to learn hierarchy-aware\npenultimate features that collapse to the HAFrame. We demonstrate that our\napproach reduces the mistake severity of the model's predictions while\nmaintaining its top-1 accuracy on several datasets of varying scales with\nhierarchies of heights ranging from 3 to 12. We will release our code on GitHub\nin the near future.\n","authors":["Tong Liang","Jim Davis"],"pdf_url":"https://arxiv.org/pdf/2303.05689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05686v1","updated":"2023-03-10T03:39:23Z","published":"2023-03-10T03:39:23Z","title":"Generalized Diffusion MRI Denoising and Super-Resolution using Swin\n  Transformers","summary":"  Diffusion MRI is a non-invasive, in-vivo medical imaging method able to map\ntissue microstructure and structural connectivity of the human brain, as well\nas detect changes, such as brain development and injury, not visible by other\nclinical neuroimaging techniques. However, acquiring high signal-to-noise ratio\n(SNR) datasets with high angular and spatial sampling requires prohibitively\nlong scan times, limiting usage in many important clinical settings, especially\nchildren, the elderly, and emergency patients with acute neurological disorders\nwho might not be able to cooperate with the MRI scan without conscious sedation\nor general anesthesia. Here, we propose to use a Swin UNEt TRansformers (Swin\nUNETR) model, trained on augmented Human Connectome Project (HCP) data and\nconditioned on registered T1 scans, to perform generalized denoising and\nsuper-resolution of diffusion MRI invariant to acquisition parameters, patient\npopulations, scanners, and sites. We qualitatively demonstrate super-resolution\nwith artificially downsampled HCP data in normal adult volunteers. Our\nexperiments on two other unrelated datasets, one of children with\nneurodevelopmental disorders and one of traumatic brain injury patients, show\nthat our method demonstrates superior denoising despite wide data distribution\nshifts. Further improvement can be achieved via finetuning with just one\nadditional subject. We apply our model to diffusion tensor (2nd order spherical\nharmonic) and higher-order spherical harmonic coefficient estimation and show\nresults superior to current state-of-the-art methods. Our method can be used\nout-of-the-box or minimally finetuned to denoise and super-resolve a wide\nvariety of diffusion MRI datasets. The code and model are publicly available at\nhttps://github.com/ucsfncl/dmri-swin.\n","authors":["Amir Sadikov","Jamie Wren-Jarvis","Xinlei Pan","Lanya T. Cai","Pratik Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2303.05686v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05685v1","updated":"2023-03-10T03:37:05Z","published":"2023-03-10T03:37:05Z","title":"An Adaptive GViT for Gas Mixture Identification and Concentration\n  Estimation","summary":"  Estimating the composition and concentration of ambient gases is crucial for\nindustrial gas safety. Even though other researchers have proposed some gas\nidentification and con-centration estimation algorithms, these algorithms still\nsuffer from severe flaws, particularly in fulfilling industry demands. One\nexample is that the lengths of data collected in an industrial setting tend to\nvary. The conventional algorithm, yet, cannot be used to analyze the\nvariant-length data effectively. Trimming the data will preserve only\nsteady-state values, inevitably leading to the loss of vital information. The\ngas identification and concentration estimation model called GCN-ViT(GViT) is\nproposed in this paper; we view the sensor data to be a one-way chain that has\nonly been downscaled to retain the majority of the original in-formation. The\nGViT model can directly utilize sensor ar-rays' variable-length real-time\nsignal data as input. We validated the above model on a dataset of 12-hour\nuninterrupted monitoring of two randomly varying gas mixtures, CO-ethylene and\nmethane-ethylene. The accuracy of gas identification can reach 97.61%, R2 of\nthe pure gas concentration estimation is above 99.5% on average, and R2 of the\nmixed gas concentration estimation is above 95% on average.\n","authors":["Ding Wang","Wenwen Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05079v2","updated":"2023-03-10T03:09:41Z","published":"2023-03-09T07:30:53Z","title":"DDS3D: Dense Pseudo-Labels with Dynamic Threshold for Semi-Supervised 3D\n  Object Detection","summary":"  In this paper, we present a simple yet effective semi-supervised 3D object\ndetector named DDS3D. Our main contributions have two-fold. On the one hand,\ndifferent from previous works using Non-Maximal Suppression (NMS) or its\nvariants for obtaining the sparse pseudo labels, we propose a dense\npseudo-label generation strategy to get dense pseudo-labels, which can retain\nmore potential supervision information for the student network. On the other\nhand, instead of traditional fixed thresholds, we propose a dynamic threshold\nmanner to generate pseudo-labels, which can guarantee the quality and quantity\nof pseudo-labels during the whole training process. Benefiting from these two\ncomponents, our DDS3D outperforms the state-of-the-art semi-supervised 3d\nobject detection with mAP of 3.1% on the pedestrian and 2.1% on the cyclist\nunder the same configuration of 1% samples. Extensive ablation studies on the\nKITTI dataset demonstrate the effectiveness of our DDS3D. The code and models\nwill be made publicly available at https://github.com/hust-jy/DDS3D\n","authors":["Jingyu Li","Zhe Liu","Jinghua Hou","Dingkang Liang"],"pdf_url":"https://arxiv.org/pdf/2303.05079v2.pdf","comment":"Accepted for publication in 2023 IEEE International Conference on\n  Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2303.05675v1","updated":"2023-03-10T02:57:07Z","published":"2023-03-10T02:57:07Z","title":"HumanBench: Towards General Human-centric Perception with Projector\n  Assisted Pretraining","summary":"  Human-centric perceptions include a variety of vision tasks, which have\nwidespread industrial applications, including surveillance, autonomous driving,\nand the metaverse. It is desirable to have a general pretrain model for\nversatile human-centric downstream tasks. This paper forges ahead along this\npath from the aspects of both benchmark and pretraining methods. Specifically,\nwe propose a \\textbf{HumanBench} based on existing datasets to comprehensively\nevaluate on the common ground the generalization abilities of different\npretraining methods on 19 datasets from 6 diverse downstream tasks, including\nperson ReID, pose estimation, human parsing, pedestrian attribute recognition,\npedestrian detection, and crowd counting. To learn both coarse-grained and\nfine-grained knowledge in human bodies, we further propose a \\textbf{P}rojector\n\\textbf{A}ssis\\textbf{T}ed \\textbf{H}ierarchical pretraining method\n(\\textbf{PATH}) to learn diverse knowledge at different granularity levels.\nComprehensive evaluations on HumanBench show that our PATH achieves new\nstate-of-the-art results on 17 downstream datasets and on-par results on the\nother 2 datasets. The code will be publicly at\n\\href{https://github.com/OpenGVLab/HumanBench}{https://github.com/OpenGVLab/HumanBench}.\n","authors":["Shixiang Tang","Cheng Chen","Qingsong Xie","Meilin Chen","Yizhou Wang","Yuanzheng Ci","Lei Bai","Feng Zhu","Haiyang Yang","Li Yi","Rui Zhao","Wanli Ouyang"],"pdf_url":"https://arxiv.org/pdf/2303.05675v1.pdf","comment":"Accepted to CVPR2023"},{"id":"http://arxiv.org/abs/2303.00941v2","updated":"2023-03-10T02:52:47Z","published":"2023-03-02T03:29:16Z","title":"ParaFormer: Parallel Attention Transformer for Efficient Feature\n  Matching","summary":"  Heavy computation is a bottleneck limiting deep-learningbased feature\nmatching algorithms to be applied in many realtime applications. However,\nexisting lightweight networks optimized for Euclidean data cannot address\nclassical feature matching tasks, since sparse keypoint based descriptors are\nexpected to be matched. This paper tackles this problem and proposes two\nconcepts: 1) a novel parallel attention model entitled ParaFormer and 2) a\ngraph based U-Net architecture with attentional pooling. First, ParaFormer\nfuses features and keypoint positions through the concept of amplitude and\nphase, and integrates self- and cross-attention in a parallel manner which\nachieves a win-win performance in terms of accuracy and efficiency. Second,\nwith U-Net architecture and proposed attentional pooling, the ParaFormer-U\nvariant significantly reduces computational complexity, and minimize\nperformance loss caused by downsampling. Sufficient experiments on various\napplications, including homography estimation, pose estimation, and image\nmatching, demonstrate that ParaFormer achieves state-of-the-art performance\nwhile maintaining high efficiency. The efficient ParaFormer-U variant achieves\ncomparable performance with less than 50% FLOPs of the existing attention-based\nmodels.\n","authors":["Xiaoyong Lu","Yaping Yan","Bin Kang","Songlin Du"],"pdf_url":"https://arxiv.org/pdf/2303.00941v2.pdf","comment":"Have been accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2210.14457v2","updated":"2023-03-10T02:45:34Z","published":"2022-10-26T04:02:29Z","title":"Implicit Identity Leakage: The Stumbling Block to Improving Deepfake\n  Detection Generalization","summary":"  In this paper, we analyse the generalization ability of binary classifiers\nfor the task of deepfake detection. We find that the stumbling block to their\ngeneralization is caused by the unexpected learned identity representation on\nimages. Termed as the Implicit Identity Leakage, this phenomenon has been\nqualitatively and quantitatively verified among various DNNs. Furthermore,\nbased on such understanding, we propose a simple yet effective method named the\nID-unaware Deepfake Detection Model to reduce the influence of this phenomenon.\nExtensive experimental results demonstrate that our method outperforms the\nstate-of-the-art in both in-dataset and cross-dataset evaluation. The code is\navailable at https://github.com/megvii-research/CADDM.\n","authors":["Shichao Dong","Jin Wang","Renhe Ji","Jiajun Liang","Haoqiang Fan","Zheng Ge"],"pdf_url":"https://arxiv.org/pdf/2210.14457v2.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2301.03213v3","updated":"2023-03-10T02:28:01Z","published":"2023-01-09T09:10:35Z","title":"EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset","summary":"  Visual object tracking is a key component to many egocentric vision problems.\nHowever, the full spectrum of challenges of egocentric tracking faced by an\nembodied AI is underrepresented in many existing datasets; these tend to focus\non relatively short, third-person videos. Egocentric video has several\ndistinguishing characteristics from those commonly found in past datasets:\nfrequent large camera motions and hand interactions with objects commonly lead\nto occlusions or objects exiting the frame, and object appearance can change\nrapidly due to widely different points of view, scale, or object states.\nEmbodied tracking is also naturally long-term, and being able to consistently\n(re-)associate objects to their appearances and disappearances over as long as\na lifetime is critical. Previous datasets under-emphasize this re-detection\nproblem, and their \"framed\" nature has led to adoption of various\nspatiotemporal priors that we find do not necessarily generalize to egocentric\nvideo. We thus introduce EgoTracks, a new dataset for long-term egocentric\nvisual object tracking. Sourced from the Ego4D dataset, this new dataset\npresents a significant challenge to recent state-of-the-art single-object\ntracking models, which we find score poorly on traditional tracking metrics for\nour new dataset, compared to popular benchmarks. We further show improvements\nthat can be made to a STARK tracker to significantly increase its performance\non egocentric data, resulting in a baseline model we call EgoSTARK. We publicly\nrelease our annotations and benchmark, hoping our dataset leads to further\nadvancements in tracking.\n","authors":["Hao Tang","Kevin Liang","Matt Feiszli","Weiyao Wang"],"pdf_url":"https://arxiv.org/pdf/2301.03213v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05657v1","updated":"2023-03-10T02:16:35Z","published":"2023-03-10T02:16:35Z","title":"Tag2Text: Guiding Vision-Language Model via Image Tagging","summary":"  This paper presents Tag2Text, a vision language pre-training (VLP) framework,\nwhich introduces image tagging into vision-language models to guide the\nlearning of visual-linguistic features. In contrast to prior works which\nutilize object tags either manually labeled or automatically detected with a\nlimited detector, our approach utilizes tags parsed from its paired text to\nlearn an image tagger and meanwhile provides guidance to vision-language\nmodels. Given that, Tag2Text can utilize large-scale annotation-free image tags\nin accordance with image-text pairs, and provides more diverse tag categories\nbeyond objects. As a result, Tag2Text achieves a superior image tag recognition\nability by exploiting fine-grained text information. Moreover, by leveraging\ntagging guidance, Tag2Text effectively enhances the performance of\nvision-language models on both generation-based and alignment-based tasks.\nAcross a wide range of downstream benchmarks, Tag2Text achieves\nstate-of-the-art or competitive results with similar model sizes and data\nscales, demonstrating the efficacy of the proposed tagging guidance.\n","authors":["Xinyu Huang","Youcai Zhang","Jinyu Ma","Weiwei Tian","Rui Feng","Yuejie Zhang","Yaqian Li","Yandong Guo","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.05657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05656v1","updated":"2023-03-10T02:15:58Z","published":"2023-03-10T02:15:58Z","title":"EHRDiff: Exploring Realistic EHR Synthesis with Diffusion Models","summary":"  Electronic health records (EHR) contain vast biomedical knowledge and are\nrich resources for developing precise medicine systems. However, due to privacy\nconcerns, there are limited high-quality EHR data accessible to researchers\nhence hindering the advancement of methodologies. Recent research has explored\nusing generative modelling methods to synthesize realistic EHR data, and most\nproposed methods are based on the generative adversarial network (GAN) and its\nvariants for EHR synthesis. Although GAN-style methods achieved\nstate-of-the-art performance in generating high-quality EHR data, such methods\nare hard to train and prone to mode collapse. Diffusion models are recently\nproposed generative modelling methods and set cutting-edge performance in image\ngeneration. The performance of diffusion models in realistic EHR synthesis is\nrarely explored. In this work, we explore whether the superior performance of\ndiffusion models can translate to the domain of EHR synthesis and propose a\nnovel EHR synthesis method named EHRDiff. Through comprehensive experiments,\nEHRDiff achieves new state-of-the-art performance for the quality of synthetic\nEHR data and can better protect private information in real training EHRs in\nthe meanwhile.\n","authors":["Hongyi Yuan","Songchi Zhou","Sheng Yu"],"pdf_url":"https://arxiv.org/pdf/2303.05656v1.pdf","comment":"Working in progress"},{"id":"http://arxiv.org/abs/2303.05653v1","updated":"2023-03-10T02:08:56Z","published":"2023-03-10T02:08:56Z","title":"Direct Robot Configuration Space Construction using Convolutional\n  Encoder-Decoders","summary":"  Intelligent robots must be able to perform safe and efficient motion planning\nin their environments. Central to modern motion planning is the configuration\nspace. Configuration spaces define the set of configurations of a robot that\nresult in collisions with obstacles in the workspace, C-clsn, and the set of\nconfigurations that do not, C-free. Modern approaches to motion planning first\ncompute the configuration space and then perform motion planning using the\ncalculated configuration space. Real-time motion planning requires accurate and\nefficient construction of configuration spaces.\n  We are the first to apply a convolutional encoder-decoder framework for\ncalculating highly accurate approximations to configuration spaces. Our model\nachieves an average 97.5% F1-score for predicting C-free and C-clsn for 2-D\nrobotic workspaces with a dual-arm robot. Our method limits undetected\ncollisions to less than 2.5% on robotic workspaces that involve translation,\nrotation, and removal of obstacles. Our model learns highly transferable\nfeatures between robotic workspaces, requiring little to no fine-tuning to\nadapt to new transformations of obstacles in the workspace.\n","authors":["Christopher Benka","Carl Gross","Riya Gupta","Hod Lipson"],"pdf_url":"https://arxiv.org/pdf/2303.05653v1.pdf","comment":"6 pages, 7 figures, 4 tables"},{"id":"http://arxiv.org/abs/2303.05652v1","updated":"2023-03-10T02:08:01Z","published":"2023-03-10T02:08:01Z","title":"GATOR: Graph-Aware Transformer with Motion-Disentangled Regression for\n  Human Mesh Recovery from a 2D Pose","summary":"  3D human mesh recovery from a 2D pose plays an important role in various\napplications. However, it is hard for existing methods to simultaneously\ncapture the multiple relations during the evolution from skeleton to mesh,\nincluding joint-joint, joint-vertex and vertex-vertex relations, which often\nleads to implausible results. To address this issue, we propose a novel\nsolution, called GATOR, that contains an encoder of Graph-Aware Transformer\n(GAT) and a decoder with Motion-Disentangled Regression (MDR) to explore these\nmultiple relations. Specifically, GAT combines a GCN and a graph-aware\nself-attention in parallel to capture physical and hidden joint-joint\nrelations. Furthermore, MDR models joint-vertex and vertex-vertex interactions\nto explore joint and vertex relations. Based on the clustering characteristics\nof vertex offset fields, MDR regresses the vertices by composing the predicted\nbase motions. Extensive experiments show that GATOR achieves state-of-the-art\nperformance on two challenging benchmarks.\n","authors":["Yingxuan You","Hong Liu","Xia Li","Wenhao Li","Ti Wang","Runwei Ding"],"pdf_url":"https://arxiv.org/pdf/2303.05652v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.05646v1","updated":"2023-03-10T01:48:14Z","published":"2023-03-10T01:48:14Z","title":"Iterative Few-shot Semantic Segmentation from Image Label Text","summary":"  Few-shot semantic segmentation aims to learn to segment unseen class objects\nwith the guidance of only a few support images. Most previous methods rely on\nthe pixel-level label of support images. In this paper, we focus on a more\nchallenging setting, in which only the image-level labels are available. We\npropose a general framework to firstly generate coarse masks with the help of\nthe powerful vision-language model CLIP, and then iteratively and mutually\nrefine the mask predictions of support and query images. Extensive experiments\non PASCAL-5i and COCO-20i datasets demonstrate that our method not only\noutperforms the state-of-the-art weakly supervised approaches by a significant\nmargin, but also achieves comparable or better results to recent supervised\nmethods. Moreover, our method owns an excellent generalization ability for the\nimages in the wild and uncommon classes. Code will be available at\nhttps://github.com/Whileherham/IMR-HSNet.\n","authors":["Haohan Wang","Liang Liu","Wuhao Zhang","Jiangning Zhang","Zhenye Gan","Yabiao Wang","Chengjie Wang","Haoqian Wang"],"pdf_url":"https://arxiv.org/pdf/2303.05646v1.pdf","comment":"ijcai 2022"},{"id":"http://arxiv.org/abs/2206.02967v2","updated":"2023-03-10T01:15:56Z","published":"2022-06-07T02:03:06Z","title":"Masked Unsupervised Self-training for Label-free Image Classification","summary":"  State-of-the-art computer vision models are mostly trained with supervised\nlearning using human-labeled images, which limits their scalability due to the\nexpensive annotation cost. While self-supervised representation learning has\nachieved impressive progress, it still requires a second stage of finetuning on\nlabeled data. On the other hand, models pre-trained with large-scale text-image\nsupervision (e.g., CLIP) have enabled zero-shot transfer to downstream image\nclassification tasks. However, the zero-shot performance of CLIP-like models\nare often insufficient for real-world adoption. In this paper, we aim to\nleverage the abundant unlabeled data from a target domain to improve the\nperformance of a pre-trained zero-shot classifier, by unsupervised finetuning\nof the pre-trained model. We propose Masked Unsupervised Self-Training (MUST),\na new unsupervised adaptation method which leverages two different and\ncomplementary sources of training signals: pseudo-labels and raw images. MUST\njointly optimizes three objectives to learn both class-level global feature and\npixel-level local feature and enforces a regularization between the two. We\ndemonstrate the efficacy of MUST on a variety of downstream tasks, where it\nimproves upon CLIP by a large margin. MUST also outperforms supervised few-shot\nadaptation methods. It achieves a top-1 accuracy of 77.7% on ImageNet using\nViT-B, +9.4% higher than CLIP, and +6.2% higher than 16-shot CLIP adaptation.\nOur code is available at https://github.com/salesforce/MUST.\n","authors":["Junnan Li","Silvio Savarese","Steven C. H. Hoi"],"pdf_url":"https://arxiv.org/pdf/2206.02967v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05639v1","updated":"2023-03-10T01:04:27Z","published":"2023-03-10T01:04:27Z","title":"Self-Supervised One-Shot Learning for Automatic Segmentation of StyleGAN\n  Images","summary":"  We propose in this paper a framework for automatic one-shot segmentation of\nsynthetic images generated using StyleGANs. As to the need for `one-shot\nsegmentation', we want the network to carry out a semantic segmentation of the\nimages on the fly, that is, as they are being produced at inference time. The\nimplementation of our framework is based on the observation that the\nmulti-scale hidden features produced by a GAN during image synthesis hold\nuseful semantic information that can be utilized for automatic segmentation.\nUsing these features, our proposed framework learns to segment synthetic images\nusing a novel self-supervised, contrastive clustering algorithm that projects\nthe hidden features in the generator onto a compact feature space for per-pixel\nclassification. This contrastive learner uses a swapped prediction loss for\nimage segmentation that is computed using pixel-wise cluster assignments for\nthe image and its transformed variants. Using the hidden features from an\nalready pre-trained GAN for clustering, this leads to a much faster learning of\nthe pixel-wise feature vectors for one-shot segmentation. We have tested our\nimplementation on a number of standard benchmarks (CelebA, LSUN, PASCAL-Part)\nfor object and part segmentation. The results of our experiments yield a\nsegmentation performance that not only outperforms the semi-supervised baseline\nmethods with an average wIoU margin of 1.02 % but also improves the inference\nspeeds by a peak factor of 4.5. Finally, we also show the results of using the\nproposed framework in the implementation of BagGAN, a GAN-based framework for\nthe production of annotated synthetic baggage X-ray scans for threat detection.\nThis one-shot learning framework was trained and tested on the PIDRay baggage\nscreening benchmark for 5 different threat categories to yield a segmentation\nperformance which stands close to its baseline segmenter.\n","authors":["Ankit Manerikar","Avinash C. Kak"],"pdf_url":"https://arxiv.org/pdf/2303.05639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05634v1","updated":"2023-03-10T00:46:32Z","published":"2023-03-10T00:46:32Z","title":"Fusarium head blight detection, spikelet estimation, and severity\n  assessment in wheat using 3D convolutional neural networks","summary":"  Fusarium head blight (FHB) is one of the most significant diseases affecting\nwheat and other small grain cereals worldwide. The development of resistant\nvarieties requires the laborious task of field and greenhouse phenotyping. The\napplications considered in this work are the automated detection of FHB disease\nsymptoms expressed on a wheat plant, the automated estimation of the total\nnumber of spikelets and the total number of infected spikelets on a wheat head,\nand the automated assessment of the FHB severity in infected wheat. The data\nused to generate the results are 3-dimensional (3D) multispectral point clouds\n(PC), which are 3D collections of points - each associated with a red, green,\nblue (RGB), and near-infrared (NIR) measurement. Over 300 wheat plant images\nwere collected using a multispectral 3D scanner, and the labelled UW-MRDC 3D\nwheat dataset was created. The data was used to develop novel and efficient 3D\nconvolutional neural network (CNN) models for FHB detection, which achieved\n100% accuracy. The influence of the multispectral information on performance\nwas evaluated, and our results showed the dominance of the RGB channels over\nboth the NIR and the NIR plus RGB channels combined. Furthermore, novel and\nefficient 3D CNNs were created to estimate the total number of spikelets and\nthe total number of infected spikelets on a wheat head, and our best models\nachieved mean absolute errors (MAE) of 1.13 and 1.56, respectively. Moreover,\n3D CNN models for FHB severity estimation were created, and our best model\nachieved 8.6 MAE. A linear regression analysis between the visual FHB severity\nassessment and the FHB severity predicted by our 3D CNN was performed, and the\nresults showed a significant correlation between the two variables with a\n0.0001 P-value and 0.94 R-squared.\n","authors":["Oumaima Hamila","Christopher J. Henry","Oscar I. Molina","Christopher P. Bidinosti","Maria Antonia Henriquez"],"pdf_url":"https://arxiv.org/pdf/2303.05634v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2303.06095v1","updated":"2023-03-10T17:24:41Z","published":"2023-03-10T17:24:41Z","title":"HiNet: A Novel Multi-Scenario & Multi-Task Learning Approach with\n  Hierarchical Information Extraction","summary":"  Multi-scenario & multi-task learning has been widely applied to many\nrecommendation systems in industrial applications, wherein an effective and\npractical approach is to carry out multi-scenario transfer learning on the\nbasis of the Mixture-of-Expert (MoE) architecture. However, the MoE-based\nmethod, which aims to project all information in the same feature space, cannot\neffectively deal with the complex relationships inherent among various\nscenarios and tasks, resulting in unsatisfactory performance. To tackle the\nproblem, we propose a Hierarchical information extraction Network (HiNet) for\nmulti-scenario and multi-task recommendation, which achieves hierarchical\nextraction based on coarse-to-fine knowledge transfer scheme. The multiple\nextraction layers of the hierarchical network enable the model to enhance the\ncapability of transferring valuable information across scenarios while\npreserving specific features of scenarios and tasks. Furthermore, a novel\nscenario-aware attentive network module is proposed to model correlations\nbetween scenarios explicitly. Comprehensive experiments conducted on real-world\nindustrial datasets from Meituan Meishi platform demonstrate that HiNet\nachieves a new state-of-the-art performance and significantly outperforms\nexisting solutions. HiNet is currently fully deployed in two scenarios and has\nachieved 2.87% and 1.75% order quantity gain respectively.\n","authors":["Jie Zhou","Xianshuai Cao","Wenhao Li","Kun Zhang","Chuan Luo","Qian Yu"],"pdf_url":"https://arxiv.org/pdf/2303.06095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05847v1","updated":"2023-03-10T10:42:21Z","published":"2023-03-10T10:42:21Z","title":"Gradient Coordination for Quantifying and Maximizing Knowledge\n  Transference in Multi-Task Learning","summary":"  Multi-task learning (MTL) has been widely applied in online advertising and\nrecommender systems. To address the negative transfer issue, recent studies\nhave proposed optimization methods that thoroughly focus on the gradient\nalignment of directions or magnitudes. However, since prior study has proven\nthat both general and specific knowledge exist in the limited shared capacity,\noveremphasizing on gradient alignment may crowd out task-specific knowledge,\nand vice versa. In this paper, we propose a transference-driven approach CoGrad\nthat adaptively maximizes knowledge transference via Coordinated Gradient\nmodification. We explicitly quantify the transference as loss reduction from\none task to another, and then derive an auxiliary gradient from optimizing it.\nWe perform the optimization by incorporating this gradient into original task\ngradients, making the model automatically maximize inter-task transfer and\nminimize individual losses. Thus, CoGrad can harmonize between general and\nspecific knowledge to boost overall performance. Besides, we introduce an\nefficient approximation of the Hessian matrix, making CoGrad computationally\nefficient and simple to implement. Both offline and online experiments verify\nthat CoGrad significantly outperforms previous methods.\n","authors":["Xuanhua Yang","Jianxin Zhao","Shaoguo Liu","Liang Wang","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.05847v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.05812v1","updated":"2023-03-10T09:39:18Z","published":"2023-03-10T09:39:18Z","title":"Semi-supervised Adversarial Learning for Complementary Item\n  Recommendation","summary":"  Complementary item recommendations are a ubiquitous feature of modern\ne-commerce sites. Such recommendations are highly effective when they are based\non collaborative signals like co-purchase statistics. In certain online\nmarketplaces, however, e.g., on online auction sites, constantly new items are\nadded to the catalog. In such cases, complementary item recommendations are\noften based on item side-information due to a lack of interaction data. In this\nwork, we propose a novel approach that can leverage both item side-information\nand labeled complementary item pairs to generate effective complementary\nrecommendations for cold items, i.e., for items for which no co-purchase\nstatistics yet exist. Given that complementary items typically have to be of a\ndifferent category than the seed item, we technically maintain a latent space\nfor each item category. Simultaneously, we learn to project distributed item\nrepresentations into these category spaces to determine suitable\nrecommendations. The main learning process in our architecture utilizes labeled\npairs of complementary items. In addition, we adopt ideas from Cycle Generative\nAdversarial Networks (CycleGAN) to leverage available item information even in\ncase no labeled data exists for a given item and category. Experiments on three\ne-commerce datasets show that our method is highly effective.\n","authors":["Koby Bibas","Oren Sar Shalom","Dietmar Jannach"],"pdf_url":"https://arxiv.org/pdf/2303.05812v1.pdf","comment":"ACM Web Conference 2023"},{"id":"http://arxiv.org/abs/2302.03328v2","updated":"2023-03-10T03:36:18Z","published":"2023-02-07T09:11:17Z","title":"Multi-Task Recommendations with Reinforcement Learning","summary":"  In recent years, Multi-task Learning (MTL) has yielded immense success in\nRecommender System (RS) applications. However, current MTL-based recommendation\nmodels tend to disregard the session-wise patterns of user-item interactions\nbecause they are predominantly constructed based on item-wise datasets.\nMoreover, balancing multiple objectives has always been a challenge in this\nfield, which is typically avoided via linear estimations in existing works. To\naddress these issues, in this paper, we propose a Reinforcement Learning (RL)\nenhanced MTL framework, namely RMTL, to combine the losses of different\nrecommendation tasks using dynamic weights. To be specific, the RMTL structure\ncan address the two aforementioned issues by (i) constructing an MTL\nenvironment from session-wise interactions and (ii) training multi-task\nactor-critic network structure, which is compatible with most existing\nMTL-based recommendation models, and (iii) optimizing and fine-tuning the MTL\nloss function using the weights generated by critic networks. Experiments on\ntwo real-world public datasets demonstrate the effectiveness of RMTL with a\nhigher AUC against state-of-the-art MTL-based recommendation models.\nAdditionally, we evaluate and validate RMTL's compatibility and transferability\nacross various MTL models.\n","authors":["Ziru Liu","Jiejie Tian","Qingpeng Cai","Xiangyu Zhao","Jingtong Gao","Shuchang Liu","Dayou Chen","Tonghao He","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.03328v2.pdf","comment":"TheWebConf2023"},{"id":"http://arxiv.org/abs/2303.05648v1","updated":"2023-03-10T01:49:56Z","published":"2023-03-10T01:49:56Z","title":"Pacos: Modeling Users' Interpretable and Context-Dependent Choices in\n  Preference Reversals","summary":"  Choice problems refer to selecting the best choices from several items, and\nlearning users' preferences in choice problems is of great significance in\nunderstanding the decision making mechanisms and providing personalized\nservices. Existing works typically assume that people evaluate items\nindependently. In practice, however, users' preferences depend on the market in\nwhich items are placed, which is known as context effects; and the order of\nusers' preferences for two items may even be reversed, which is referred to\npreference reversals. In this work, we identify three factors contributing to\ncontext effects: users' adaptive weights, the inter-item comparison, and\ndisplay positions. We propose a context-dependent preference model named Pacos\nas a unified framework for addressing three factors simultaneously, and\nconsider two design methods including an additive method with high\ninterpretability and an ANN-based method with high accuracy. We study the\nconditions for preference reversals to occur and provide an theoretical proof\nof the effectiveness of Pacos in addressing preference reversals. Experimental\nresults show that the proposed method has better performance than prior works\nin predicting users' choices, and has great interpretability to help understand\nthe cause of preference reversals.\n","authors":["Qingming Li","H. Vicky Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.05648v1.pdf","comment":"29 pages, 12 figures"},{"id":"http://arxiv.org/abs/2303.04392v2","updated":"2023-03-10T01:31:11Z","published":"2023-03-08T05:53:33Z","title":"Achievable Rates and Low-Complexity Encoding of Posterior Matching for\n  the BSC","summary":"  Horstein, Burnashev, Shayevitz and Feder, Naghshvar et al. and others have\nstudied sequential transmission of a K-bit message over the binary symmetric\nchannel (BSC) with full, noiseless feedback using posterior matching. Yang et\nal. provide an improved lower bound on the achievable rate using martingale\nanalysis that relies on the small-enough difference (SED) partitioning\nintroduced by Naghshvar et al. SED requires a relatively complex encoder and\ndecoder. To reduce complexity, this paper replaces SED with relaxed constraints\nthat admit the small enough absolute difference (SEAD) partitioning rule. The\nmain analytical results show that achievable-rate bounds higher than those\nfound by Yang et al. are possible even under the new constraints, which are\nless restrictive than SED. The new analysis does not use martingale theory for\nthe confirmation phase and applies a surrogate channel technique to tighten the\nresults. An initial systematic transmission further increases the achievable\nrate bound. The simplified encoder associated with SEAD has a complexity below\norder O(K^2) and allows simulations for message sizes of at least 1000 bits.\nFor example, simulations achieve 99% of of the channel's 0.50-bit capacity with\nan average block size of 200 bits for a target codeword error rate of 10^(-3).\n","authors":["Amaael Antonini","Rita Gimelshein","Richard Wesel"],"pdf_url":"https://arxiv.org/pdf/2303.04392v2.pdf","comment":"This paper consists of 26 pages and contains 6 figures. An earlier\n  version of the algorithm included in this paper was published at the 2020\n  IEEE International Symposium on Information Theory (ISIT), (DOI:\n  10.1109/ISIT44484.2020.9174232)"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2303.06147v1","updated":"2023-03-10T18:59:57Z","published":"2023-03-10T18:59:57Z","title":"Exphormer: Sparse Transformers for Graphs","summary":"  Graph transformers have emerged as a promising architecture for a variety of\ngraph learning and representation tasks. Despite their successes, though, it\nremains challenging to scale graph transformers to large graphs while\nmaintaining accuracy competitive with message-passing networks. In this paper,\nwe introduce Exphormer, a framework for building powerful and scalable graph\ntransformers. Exphormer consists of a sparse attention mechanism based on two\nmechanisms: virtual global nodes and expander graphs, whose mathematical\ncharacteristics, such as spectral expansion, pseduorandomness, and sparsity,\nyield graph transformers with complexity only linear in the size of the graph,\nwhile allowing us to prove desirable theoretical properties of the resulting\ntransformer models. We show that incorporating \\textsc{Exphormer} into the\nrecently-proposed GraphGPS framework produces models with competitive empirical\nresults on a wide variety of graph datasets, including state-of-the-art results\non three datasets. We also show that \\textsc{Exphormer} can scale to datasets\non larger graphs than shown in previous graph transformer architectures. Code\ncan be found at https://github.com/hamed1375/Exphormer.\n","authors":["Hamed Shirzad","Ameya Velingker","Balaji Venkatachalam","Danica J. Sutherland","Ali Kemal Sinop"],"pdf_url":"https://arxiv.org/pdf/2303.06147v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06146v1","updated":"2023-03-10T18:59:33Z","published":"2023-03-10T18:59:33Z","title":"StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces","summary":"  Recent advances in face manipulation using StyleGAN have produced impressive\nresults. However, StyleGAN is inherently limited to cropped aligned faces at a\nfixed image resolution it is pre-trained on. In this paper, we propose a simple\nand effective solution to this limitation by using dilated convolutions to\nrescale the receptive fields of shallow layers in StyleGAN, without altering\nany model parameters. This allows fixed-size small features at shallow layers\nto be extended into larger ones that can accommodate variable resolutions,\nmaking them more robust in characterizing unaligned faces. To enable real face\ninversion and manipulation, we introduce a corresponding encoder that provides\nthe first-layer feature of the extended StyleGAN in addition to the latent\nstyle code. We validate the effectiveness of our method using unaligned face\ninputs of various resolutions in a diverse set of face manipulation tasks,\nincluding facial attribute editing, super-resolution, sketch/mask-to-face\ntranslation, and face toonification.\n","authors":["Shuai Yang","Liming Jiang","Ziwei Liu","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2303.06146v1.pdf","comment":"Code: https://github.com/williamyang1991/StyleGANEX Project page:\n  https://www.mmlab-ntu.com/project/styleganex/"},{"id":"http://arxiv.org/abs/2303.06137v1","updated":"2023-03-10T18:55:02Z","published":"2023-03-10T18:55:02Z","title":"Multiple Hands Make Light Work: Enhancing Quality and Diversity using\n  MAP-Elites with Multiple Parallel Evolution Strategies","summary":"  With the development of hardware accelerators and their corresponding tools,\nevaluations have become more affordable through fast and massively parallel\nevaluations in some applications. This advancement has drastically sped up the\nruntime of evolution-inspired algorithms such as Quality-Diversity\noptimization, creating tremendous potential for algorithmic innovation through\nscale. In this work, we propose MAP-Elites-Multi-ES (MEMES), a novel QD\nalgorithm based on Evolution Strategies (ES) designed for fast parallel\nevaluations. ME-Multi-ES builds on top of the existing MAP-Elites-ES algorithm,\nscaling it by maintaining multiple independent ES threads with massive\nparallelization. We also introduce a new dynamic reset procedure for the\nlifespan of the independent ES to autonomously maximize the improvement of the\nQD population. We show experimentally that MEMES outperforms existing\ngradient-based and objective-agnostic QD algorithms when compared in terms of\ngenerations. We perform this comparison on both black-box optimization and\nQD-Reinforcement Learning tasks, demonstrating the benefit of our approach\nacross different problems and domains. Finally, we also find that our approach\nintrinsically enables optimization of fitness locally around a niche, a\nphenomenon not observed in other QD algorithms.\n","authors":["Manon Flageat","Bryan Lim","Antoine Cully"],"pdf_url":"https://arxiv.org/pdf/2303.06137v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06135v1","updated":"2023-03-10T18:53:52Z","published":"2023-03-10T18:53:52Z","title":"Rewarding Chatbots for Real-World Engagement with Millions of Users","summary":"  The emergence of pretrained large language models has led to the deployment\nof a range of social chatbots for chitchat. Although these chatbots demonstrate\nlanguage ability and fluency, they are not guaranteed to be engaging and can\nstruggle to retain users. This work investigates the development of social\nchatbots that prioritize user engagement to enhance retention, specifically\nexamining the use of human feedback to efficiently develop highly engaging\nchatbots. The proposed approach uses automatic pseudo-labels collected from\nuser interactions to train a reward model that can be used to reject\nlow-scoring sample responses generated by the chatbot model at inference time.\nIntuitive evaluation metrics, such as mean conversation length (MCL), are\nintroduced as proxies to measure the level of engagement of deployed chatbots.\nA/B testing on groups of 10,000 new daily chatbot users on the Chai Research\nplatform shows that this approach increases the MCL by up to 70%, which\ntranslates to a more than 30% increase in user retention for a GPT-J 6B model.\nFuture work aims to use the reward model to realise a data fly-wheel, where the\nlatest user conversations can be used to alternately fine-tune the language\nmodel and the reward model.\n","authors":["Robert Irvine","Douglas Boubert","Vyas Raina","Adian Liusie","Vineet Mudupalli","Aliaksei Korshuk","Zongyi Liu","Fritz Cremer","Valentin Assassi","Christie-Carol Beauchamp","Xiaoding Lu","Thomas Rialan","William Beauchamp"],"pdf_url":"https://arxiv.org/pdf/2303.06135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.16711v2","updated":"2023-03-10T18:47:11Z","published":"2022-03-30T23:24:06Z","title":"An analytic theory for the dynamics of wide quantum neural networks","summary":"  Parameterized quantum circuits can be used as quantum neural networks and\nhave the potential to outperform their classical counterparts when trained for\naddressing learning problems. To date, much of the results on their performance\non practical problems are heuristic in nature. In particular, the convergence\nrate for the training of quantum neural networks is not fully understood. Here,\nwe analyze the dynamics of gradient descent for the training error of a class\nof variational quantum machine learning models. We define wide quantum neural\nnetworks as parameterized quantum circuits in the limit of a large number of\nqubits and variational parameters. We then find a simple analytic formula that\ncaptures the average behavior of their loss function and discuss the\nconsequences of our findings. For example, for random quantum circuits, we\npredict and characterize an exponential decay of the residual training error as\na function of the parameters of the system. We finally validate our analytic\nresults with numerical experiments.\n","authors":["Junyu Liu","Khadijeh Najafi","Kunal Sharma","Francesco Tacchino","Liang Jiang","Antonio Mezzacapo"],"pdf_url":"https://arxiv.org/pdf/2203.16711v2.pdf","comment":"37 pages, many figures. v2: adding learning supervised perspectives\n  and new results, close to published version"},{"id":"http://arxiv.org/abs/2303.06121v1","updated":"2023-03-10T18:31:50Z","published":"2023-03-10T18:31:50Z","title":"Ignorance is Bliss: Robust Control via Information Gating","summary":"  Informational parsimony -- i.e., using the minimal information required for a\ntask, -- provides a useful inductive bias for learning representations that\nachieve better generalization by being robust to noise and spurious\ncorrelations. We propose information gating in the pixel space as a way to\nlearn more parsimonious representations. Information gating works by learning\nmasks that capture only the minimal information required to solve a given task.\nIntuitively, our models learn to identify which visual cues actually matter for\na given task. We gate information using a differentiable parameterization of\nthe signal-to-noise ratio, which can be applied to arbitrary values in a\nnetwork, e.g.~masking out pixels at the input layer. We apply our approach,\nwhich we call InfoGating, to various objectives such as: multi-step forward and\ninverse dynamics, Q-learning, behavior cloning, and standard self-supervised\ntasks. Our experiments show that learning to identify and use minimal\ninformation can improve generalization in downstream tasks -- e.g., policies\nbased on info-gated images are considerably more robust to\ndistracting/irrelevant visual features.\n","authors":["Manan Tomar","Riashat Islam","Sergey Levine","Philip Bachman"],"pdf_url":"https://arxiv.org/pdf/2303.06121v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1905.13543v3","updated":"2023-03-10T18:30:42Z","published":"2019-05-28T06:35:52Z","title":"DDPNAS: Efficient Neural Architecture Search via Dynamic Distribution\n  Pruning","summary":"  Neural Architecture Search (NAS) has demonstrated state-of-the-art\nperformance on various computer vision tasks. Despite the superior performance\nachieved, the efficiency and generality of existing methods are highly valued\ndue to their high computational complexity and low generality. In this paper,\nwe propose an efficient and unified NAS framework termed DDPNAS via dynamic\ndistribution pruning, facilitating a theoretical bound on accuracy and\nefficiency. In particular, we first sample architectures from a joint\ncategorical distribution. Then the search space is dynamically pruned and its\ndistribution is updated every few epochs. With the proposed efficient network\ngeneration method, we directly obtain the optimal neural architectures on given\nconstraints, which is practical for on-device models across diverse search\nspaces and constraints. The architectures searched by our method achieve\nremarkable top-1 accuracies, 97.56 and 77.2 on CIFAR-10 and ImageNet (mobile\nsettings), respectively, with the fastest search process, i.e., only 1.8 GPU\nhours on a Tesla V100. Codes for searching and network generation are available\nat: https://openi.pcl.ac.cn/PCL AutoML/XNAS.\n","authors":["Xiawu Zheng","Chenyi Yang","Shaokun Zhang","Yan Wang","Baochang Zhang","Yongjian Wu","Yunsheng Wu","Ling Shao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/1905.13543v3.pdf","comment":"A update version of this work. 19 pages"},{"id":"http://arxiv.org/abs/2301.10418v2","updated":"2023-03-10T18:17:34Z","published":"2023-01-25T05:56:53Z","title":"DEJA VU: Continual Model Generalization For Unseen Domains","summary":"  In real-world applications, deep learning models often run in non-stationary\nenvironments where the target data distribution continually shifts over time.\nThere have been numerous domain adaptation (DA) methods in both online and\noffline modes to improve cross-domain adaptation ability. However, these DA\nmethods typically only provide good performance after a long period of\nadaptation, and perform poorly on new domains before and during adaptation - in\nwhat we call the \"Unfamiliar Period\", especially when domain shifts happen\nsuddenly and significantly. On the other hand, domain generalization (DG)\nmethods have been proposed to improve the model generalization ability on\nunadapted domains. However, existing DG works are ineffective for continually\nchanging domains due to severe catastrophic forgetting of learned knowledge. To\novercome these limitations of DA and DG in handling the Unfamiliar Period\nduring continual domain shift, we propose RaTP, a framework that focuses on\nimproving models' target domain generalization (TDG) capability, while also\nachieving effective target domain adaptation (TDA) capability right after\ntraining on certain domains and forgetting alleviation (FA) capability on past\ndomains. RaTP includes a training-free data augmentation module to prepare data\nfor TDG, a novel pseudo-labeling mechanism to provide reliable supervision for\nTDA, and a prototype contrastive alignment algorithm to align different domains\nfor achieving TDG, TDA and FA. Extensive experiments on Digits, PACS, and\nDomainNet demonstrate that RaTP significantly outperforms state-of-the-art\nworks from Continual DA, Source-Free DA, Test-Time/Online DA, Single DG,\nMultiple DG and Unified DA&DG in TDG, and achieves comparable TDA and FA\ncapabilities.\n","authors":["Chenxi Liu","Lixu Wang","Lingjuan Lyu","Chen Sun","Xiao Wang","Qi Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.10418v2.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2209.11691v2","updated":"2023-03-10T18:14:25Z","published":"2022-09-23T16:11:09Z","title":"Multidimensional Interactive Fixed-Effects","summary":"  This paper studies a linear and additively separable model for\nmultidimensional panel data of three or more dimensions with unobserved\ninteractive fixed effects. Two approaches are considered to account for these\nunobserved interactive fixed-effects when estimating coefficients on the\nobserved covariates. First, the model is embedded within the standard\ntwo-dimensional panel framework and restrictions are derived under which the\nfactor structure methods in Bai (2009) lead to consistent estimation of model\nparameters, but at potentially slow rates of convergence. The second approach\nutilises popular machine learning techniques to develop group fixed-effects and\nkernel weighted fixed-effects that are more robust to the multidimensional\nnature of the problem and can achieve the parametric rate of consistency under\ncertain conditions. Theoretical results and simulations show the benefit of\nstandard two-dimensional panel methods when the structure of the interactive\nfixed-effect term is known, but also highlight how the group fixed-effects and\nkernel methods perform well without knowledge of this structure. The methods\nare implemented to estimate the demand elasticity for beer under a handful of\nmodels for demand.\n","authors":["Hugo Freeman"],"pdf_url":"https://arxiv.org/pdf/2209.11691v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11826v3","updated":"2023-03-10T18:13:57Z","published":"2023-01-27T16:27:18Z","title":"Deep Clustering Survival Machines with Interpretable Expert\n  Distributions","summary":"  Conventional survival analysis methods are typically ineffective to\ncharacterize heterogeneity in the population while such information can be used\nto assist predictive modeling. In this study, we propose a hybrid survival\nanalysis method, referred to as deep clustering survival machines, that\ncombines the discriminative and generative mechanisms. Similar to the mixture\nmodels, we assume that the timing information of survival data is generatively\ndescribed by a mixture of certain numbers of parametric distributions, i.e.,\nexpert distributions. We learn weights of the expert distributions for\nindividual instances according to their features discriminatively such that\neach instance's survival information can be characterized by a weighted\ncombination of the learned constant expert distributions. This method also\nfacilitates interpretable subgrouping/clustering of all instances according to\ntheir associated expert distributions. Extensive experiments on both real and\nsynthetic datasets have demonstrated that the method is capable of obtaining\npromising clustering results and competitive time-to-event predicting\nperformance.\n","authors":["Bojian Hou","Hongming Li","Zhicheng Jiao","Zhen Zhou","Hao Zheng","Yong Fan"],"pdf_url":"https://arxiv.org/pdf/2301.11826v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.15465v5","updated":"2023-03-10T18:05:56Z","published":"2020-12-31T06:39:22Z","title":"Accelerating ODE-Based Neural Networks on Low-Cost FPGAs","summary":"  ODENet is a deep neural network architecture in which a stacking structure of\nResNet is implemented with an ordinary differential equation (ODE) solver. It\ncan reduce the number of parameters and strike a balance between accuracy and\nperformance by selecting a proper solver. It is also possible to improve the\naccuracy while keeping the same number of parameters on resource-limited edge\ndevices. In this paper, using Euler method as an ODE solver, a part of ODENet\nis implemented as a dedicated logic on a low-cost FPGA (Field-Programmable Gate\nArray) board, such as PYNQ-Z2 board. As ODENet variants, reduced ODENets\n(rODENets) each of which heavily uses a part of ODENet layers and\nreduces/eliminates some layers differently are proposed and analyzed for\nlow-cost FPGA implementation. They are evaluated in terms of parameter size,\naccuracy, execution time, and resource utilization on the FPGA. The results\nshow that an overall execution time of an rODENet variant is improved by up to\n2.66 times compared to a pure software execution while keeping a comparable\naccuracy to the original ODENet.\n","authors":["Hirohisa Watanabe","Hiroki Matsutani"],"pdf_url":"https://arxiv.org/pdf/2012.15465v5.pdf","comment":"RAW'21"},{"id":"http://arxiv.org/abs/2303.06109v1","updated":"2023-03-10T17:57:40Z","published":"2023-03-10T17:57:40Z","title":"On the Fusion Strategies for Federated Decision Making","summary":"  We consider the problem of information aggregation in federated decision\nmaking, where a group of agents collaborate to infer the underlying state of\nnature without sharing their private data with the central processor or each\nother. We analyze the non-Bayesian social learning strategy in which agents\nincorporate their individual observations into their opinions (i.e.,\nsoft-decisions) with Bayes rule, and the central processor aggregates these\nopinions by arithmetic or geometric averaging. Building on our previous work,\nwe establish that both pooling strategies result in asymptotic normality\ncharacterization of the system, which, for instance, can be utilized in order\nto give approximate expressions for the error probability. We verify the\ntheoretical findings with simulations and compare both strategies.\n","authors":["Mert Kayaalp","Yunus Inan","Visa Koivunen","Emre Telatar","Ali H. Sayed"],"pdf_url":"https://arxiv.org/pdf/2303.06109v1.pdf","comment":"Submitted for publication"},{"id":"http://arxiv.org/abs/2110.13506v3","updated":"2023-03-10T17:44:00Z","published":"2021-10-26T09:01:41Z","title":"Accelerating Distributed Deep Reinforcement Learning by In-Network\n  Experience Sampling","summary":"  A computing cluster that interconnects multiple compute nodes is used to\naccelerate distributed reinforcement learning based on DQN (Deep Q-Network). In\ndistributed reinforcement learning, Actor nodes acquire experiences by\ninteracting with a given environment and a Learner node optimizes their DQN\nmodel. Since data transfer between Actor and Learner nodes increases depending\non the number of Actor nodes and their experience size, communication overhead\nbetween them is one of major performance bottlenecks. In this paper, their\ncommunication is accelerated by DPDK-based network optimizations, and\nDPDK-based low-latency experience replay memory server is deployed between\nActor and Learner nodes interconnected with a 40GbE (40Gbit Ethernet) network.\nEvaluation results show that, as a network optimization technique, kernel\nbypassing by DPDK reduces network access latencies to a shared memory server by\n32.7% to 58.9%. As another network optimization technique, an in-network\nexperience replay memory server between Actor and Learner nodes reduces access\nlatencies to the experience replay memory by 11.7% to 28.1% and communication\nlatencies for prioritized experience sampling by 21.9% to 29.1%.\n","authors":["Masaki Furukawa","Hiroki Matsutani"],"pdf_url":"https://arxiv.org/pdf/2110.13506v3.pdf","comment":"PDP'22"},{"id":"http://arxiv.org/abs/2209.06119v4","updated":"2023-03-10T17:31:32Z","published":"2022-09-10T14:26:04Z","title":"APTx: better activation function than MISH, SWISH, and ReLU's variants\n  used in deep learning","summary":"  Activation Functions introduce non-linearity in the deep neural networks.\nThis nonlinearity helps the neural networks learn faster and efficiently from\nthe dataset. In deep learning, many activation functions are developed and used\nbased on the type of problem statement. ReLU's variants, SWISH, and MISH are\ngoto activation functions. MISH function is considered having similar or even\nbetter performance than SWISH, and much better than ReLU. In this paper, we\npropose an activation function named APTx which behaves similar to MISH, but\nrequires lesser mathematical operations to compute. The lesser computational\nrequirements of APTx does speed up the model training, and thus also reduces\nthe hardware requirement for the deep learning model.\n","authors":["Ravin Kumar"],"pdf_url":"https://arxiv.org/pdf/2209.06119v4.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2208.09478v3","updated":"2023-03-10T17:25:49Z","published":"2022-08-19T17:57:32Z","title":"Communication Size Reduction of Federated Learning using Neural ODE\n  Models","summary":"  Federated learning is a machine learning approach in which data is not\naggregated on a server, but is trained at clients locally, in consideration of\nsecurity and privacy. ResNet is a classic but representative neural network\nthat succeeds in deepening the neural network by learning a residual function\nthat adds the inputs and outputs together. In federated learning, communication\nis performed between the server and clients to exchange weight parameters.\nSince ResNet has deep layers and a large number of parameters, the\ncommunication size becomes large. In this paper, we use Neural ODE as a\nlightweight model of ResNet to reduce communication size in federated learning.\nIn addition, we newly introduce a flexible federated learning using Neural ODE\nmodels with different number of iterations, which correspond to ResNet models\nwith different depths. Evaluation results using CIFAR-10 dataset show that the\nuse of Neural ODE reduces communication size by up to 92.4% compared to ResNet.\nWe also show that the proposed flexible federated learning can merge models\nwith different iteration counts or depths.\n","authors":["Yuto Hoshino","Hiroki Kawakami","Hiroki Matsutani"],"pdf_url":"https://arxiv.org/pdf/2208.09478v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13898v3","updated":"2023-03-10T17:23:00Z","published":"2022-08-29T21:40:01Z","title":"Conjugate Natural Selection: Fisher-Rao Natural Gradient Descent\n  Optimally Approximates Evolutionary Dynamics and Continuous Bayesian\n  Inference","summary":"  Rather than refining individual candidate solutions for a general non-convex\noptimization problem, by analogy to evolution, we consider minimizing the\naverage loss for a parametric distribution over hypotheses. In this setting, we\nprove that Fisher-Rao natural gradient descent (FR-NGD) optimally approximates\nthe continuous-time replicator equation (an essential model of evolutionary\ndynamics) by minimizing the mean-squared error for the relative fitness of\ncompeting hypotheses. We term this finding \"conjugate natural selection\" and\ndemonstrate its utility by numerically solving an example non-convex\noptimization problem over a continuous strategy space. Next, by developing\nknown connections between discrete-time replicator dynamics and Bayes's rule,\nwe show that when absolute fitness corresponds to the negative KL-divergence of\na hypothesis's predictions from actual observations, FR-NGD provides the\noptimal approximation of continuous Bayesian inference. We use this result to\ndemonstrate a novel method for estimating the parameters of stochastic\nprocesses.\n","authors":["Reilly Raab","Luca de Alfaro","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2208.13898v3.pdf","comment":"13 pages, 3 figures"},{"id":"http://arxiv.org/abs/2211.01910v2","updated":"2023-03-10T17:20:17Z","published":"2022-11-03T15:43:03Z","title":"Large Language Models Are Human-Level Prompt Engineers","summary":"  By conditioning on natural language instructions, large language models\n(LLMs) have displayed impressive capabilities as general-purpose computers.\nHowever, task performance depends significantly on the quality of the prompt\nused to steer the model, and most effective prompts have been handcrafted by\nhumans. Inspired by classical program synthesis and the human approach to\nprompt engineering, we propose Automatic Prompt Engineer (APE) for automatic\ninstruction generation and selection. In our method, we treat the instruction\nas the \"program,\" optimized by searching over a pool of instruction candidates\nproposed by an LLM in order to maximize a chosen score function. To evaluate\nthe quality of the selected instruction, we evaluate the zero-shot performance\nof another LLM following the selected instruction. Experiments on 24 NLP tasks\nshow that our automatically generated instructions outperform the prior LLM\nbaseline by a large margin and achieve better or comparable performance to the\ninstructions generated by human annotators on 19/24 tasks. We conduct extensive\nqualitative and quantitative analyses to explore the performance of APE. We\nshow that APE-engineered prompts can be applied to steer models toward\ntruthfulness and/or informativeness, as well as to improve few-shot learning\nperformance by simply prepending them to standard in-context learning prompts.\nPlease check out our webpage at\nhttps://sites.google.com/view/automatic-prompt-engineer.\n","authors":["Yongchao Zhou","Andrei Ioan Muresanu","Ziwen Han","Keiran Paster","Silviu Pitis","Harris Chan","Jimmy Ba"],"pdf_url":"https://arxiv.org/pdf/2211.01910v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.11943v3","updated":"2023-03-10T16:54:53Z","published":"2021-06-22T17:29:24Z","title":"Reusing Combinatorial Structure: Faster Iterative Projections over\n  Submodular Base Polytopes","summary":"  Optimization algorithms such as projected Newton's method, FISTA, mirror\ndescent, and its variants enjoy near-optimal regret bounds and convergence\nrates, but suffer from a computational bottleneck of computing ``projections''\nin potentially each iteration (e.g., $O(T^{1/2})$ regret of online mirror\ndescent). On the other hand, conditional gradient variants solve a linear\noptimization in each iteration, but result in suboptimal rates (e.g.,\n$O(T^{3/4})$ regret of online Frank-Wolfe). Motivated by this trade-off in\nruntime v/s convergence rates, we consider iterative projections of close-by\npoints over widely-prevalent submodular base polytopes $B(f)$. We first give\nnecessary and sufficient conditions for when two close points project to the\nsame face of a polytope, and then show that points far away from the polytope\nproject onto its vertices with high probability. We next use this theory and\ndevelop a toolkit to speed up the computation of iterative projections over\nsubmodular polytopes using both discrete and continuous perspectives. We\nsubsequently adapt the away-step Frank-Wolfe algorithm to use this information\nand enable early termination. For the special case of cardinality-based\nsubmodular polytopes, we improve the runtime of computing certain Bregman\nprojections by a factor of $\\Omega(n/\\log(n))$. Our theoretical results show\norders of magnitude reduction in runtime in preliminary computational\nexperiments.\n","authors":["Jai Moondra","Hassan Mortagy","Swati Gupta"],"pdf_url":"https://arxiv.org/pdf/2106.11943v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06075v1","updated":"2023-03-10T16:53:51Z","published":"2023-03-10T16:53:51Z","title":"Long-tailed Classification from a Bayesian-decision-theory Perspective","summary":"  Long-tailed classification poses a challenge due to its heavy imbalance in\nclass probabilities and tail-sensitivity risks with asymmetric misprediction\ncosts. Recent attempts have used re-balancing loss and ensemble methods, but\nthey are largely heuristic and depend heavily on empirical results, lacking\ntheoretical explanation. Furthermore, existing methods overlook the decision\nloss, which characterizes different costs associated with tailed classes. This\npaper presents a general and principled framework from a\nBayesian-decision-theory perspective, which unifies existing techniques\nincluding re-balancing and ensemble methods, and provides theoretical\njustifications for their effectiveness. From this perspective, we derive a\nnovel objective based on the integrated risk and a Bayesian deep-ensemble\napproach to improve the accuracy of all classes, especially the ``tail\".\nBesides, our framework allows for task-adaptive decision loss which provides\nprovably optimal decisions in varying task scenarios, along with the capability\nto quantify uncertainty. Finally, We conduct comprehensive experiments,\nincluding standard classification, tail-sensitive classification with a new\nFalse Head Rate metric, calibration, and ablation studies. Our framework\nsignificantly improves the current SOTA even on large-scale real-world datasets\nlike ImageNet.\n","authors":["Bolian Li","Ruqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.06075v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02262v2","updated":"2023-03-10T16:51:19Z","published":"2023-03-03T23:31:15Z","title":"Locally Regularized Neural Differential Equations: Some Black Boxes Were\n  Meant to Remain Closed!","summary":"  Implicit layer deep learning techniques, like Neural Differential Equations,\nhave become an important modeling framework due to their ability to adapt to\nnew problems automatically. Training a neural differential equation is\neffectively a search over a space of plausible dynamical systems. However,\ncontrolling the computational cost for these models is difficult since it\nrelies on the number of steps the adaptive solver takes. Most prior works have\nused higher-order methods to reduce prediction timings while greatly increasing\ntraining time or reducing both training and prediction timings by relying on\nspecific training algorithms, which are harder to use as a drop-in replacement\ndue to strict requirements on automatic differentiation. In this manuscript, we\nuse internal cost heuristics of adaptive differential equation solvers at\nstochastic time points to guide the training toward learning a dynamical system\nthat is easier to integrate. We \"close the black-box\" and allow the use of our\nmethod with any adjoint technique for gradient calculations of the differential\nequation solution. We perform experimental studies to compare our method to\nglobal regularization to show that we attain similar performance numbers\nwithout compromising the flexibility of implementation on ordinary differential\nequations (ODEs) and stochastic differential equations (SDEs). We develop two\nsampling strategies to trade off between performance and training time. Our\nmethod reduces the number of function evaluations to 0.556-0.733x and\naccelerates predictions by 1.3-2x.\n","authors":["Avik Pal","Alan Edelman","Chris Rackauckas"],"pdf_url":"https://arxiv.org/pdf/2303.02262v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06067v1","updated":"2023-03-10T16:48:54Z","published":"2023-03-10T16:48:54Z","title":"Modeling Events and Interactions through Temporal Processes -- A Survey","summary":"  In real-world scenario, many phenomena produce a collection of events that\noccur in continuous time. Point Processes provide a natural mathematical\nframework for modeling these sequences of events. In this survey, we\ninvestigate probabilistic models for modeling event sequences through temporal\nprocesses. We revise the notion of event modeling and provide the mathematical\nfoundations that characterize the literature on the topic. We define an\nontology to categorize the existing approaches in terms of three families:\nsimple, marked, and spatio-temporal point processes. For each family, we\nsystematically review the existing approaches based based on deep learning.\nFinally, we analyze the scenarios where the proposed techniques can be used for\naddressing prediction and modeling aspects.\n","authors":["Angelica Liguori","Luciano Caroprese","Marco Minici","Bruno Veloso","Francesco Spinnato","Mirco Nanni","Giuseppe Manco","Joao Gama"],"pdf_url":"https://arxiv.org/pdf/2303.06067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06058v1","updated":"2023-03-10T16:43:48Z","published":"2023-03-10T16:43:48Z","title":"A General Recipe for the Analysis of Randomized Multi-Armed Bandit\n  Algorithms","summary":"  In this paper we propose a general methodology to derive regret bounds for\nrandomized multi-armed bandit algorithms. It consists in checking a set of\nsufficient conditions on the sampling probability of each arm and on the family\nof distributions to prove a logarithmic regret. As a direct application we\nrevisit two famous bandit algorithms, Minimum Empirical Divergence (MED) and\nThompson Sampling (TS), under various models for the distributions including\nsingle parameter exponential families, Gaussian distributions, bounded\ndistributions, or distributions satisfying some conditions on their moments. In\nparticular, we prove that MED is asymptotically optimal for all these models,\nbut also provide a simple regret analysis of some TS algorithms for which the\noptimality is already known. We then further illustrate the interest of our\napproach, by analyzing a new Non-Parametric TS algorithm (h-NPTS), adapted to\nsome families of unbounded reward distributions with a bounded h-moment. This\nmodel can for instance capture some non-parametric families of distributions\nwhose variance is upper bounded by a known constant.\n","authors":["Dorian Baudry","Kazuya Suzuki","Junya Honda"],"pdf_url":"https://arxiv.org/pdf/2303.06058v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06053v1","updated":"2023-03-10T16:41:24Z","published":"2023-03-10T16:41:24Z","title":"TSMixer: An all-MLP Architecture for Time Series Forecasting","summary":"  Real-world time-series datasets are often multivariate with complex dynamics.\nCommonly-used high capacity architectures like recurrent- or attention-based\nsequential models have become popular. However, recent work demonstrates that\nsimple univariate linear models can outperform those deep alternatives. In this\npaper, we investigate the capabilities of linear models for time-series\nforecasting and present Time-Series Mixer (TSMixer), an architecture designed\nby stacking multi-layer perceptrons (MLPs). TSMixer is based on mixing\noperations along time and feature dimensions to extract information\nefficiently. On popular academic benchmarks, the simple-to-implement TSMixer is\ncomparable to specialized state-of-the-art models that leverage the inductive\nbiases of specific benchmarks. On the challenging and large scale M5 benchmark,\na real-world retail dataset, TSMixer demonstrates superior performance compared\nto the state-of-the-art alternatives. Our results underline the importance of\nefficiently utilizing cross-variate and auxiliary information for improving the\nperformance of time series forecasting. The design paradigms utilized in\nTSMixer are expected to open new horizons for deep learning-based time series\nforecasting.\n","authors":["Si-An Chen","Chun-Liang Li","Nate Yoder","Sercan O. Arik","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2303.06053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15049v3","updated":"2023-03-10T16:31:08Z","published":"2022-05-30T12:28:10Z","title":"Metrizing Fairness","summary":"  We study supervised learning problems for predicting properties of\nindividuals who belong to one of two demographic groups, and we seek predictors\nthat are fair according to statistical parity. This means that the\ndistributions of the predictions within the two groups should be close with\nrespect to the Kolmogorov distance, and fairness is achieved by penalizing the\ndissimilarity of these two distributions in the objective function of the\nlearning problem. In this paper, we showcase conceptual and computational\nbenefits of measuring unfairness with integral probability metrics (IPMs) other\nthan the Kolmogorov distance. Conceptually, we show that the generator of any\nIPM can be interpreted as a family of utility functions and that unfairness\nwith respect to this IPM arises if individuals in the two demographic groups\nhave diverging expected utilities. We also prove that the\nunfairness-regularized prediction loss admits unbiased gradient estimators if\nunfairness is measured by the squared $\\mathcal L^2$-distance or by a squared\nmaximum mean discrepancy. In this case, the fair learning problem is\nsusceptible to efficient stochastic gradient descent (SGD) algorithms.\nNumerical experiments on real data show that these SGD algorithms outperform\nstate-of-the-art methods for fair learning in that they achieve superior\naccuracy-unfairness trade-offs -- sometimes orders of magnitude faster.\nFinally, we identify conditions under which statistical parity can improve\nprediction accuracy.\n","authors":["Yves Rychener","Bahar Taskesen","Daniel Kuhn"],"pdf_url":"https://arxiv.org/pdf/2205.15049v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06034v1","updated":"2023-03-10T16:27:37Z","published":"2023-03-10T16:27:37Z","title":"Tactile-Filter: Interactive Tactile Perception for Part Mating","summary":"  Humans rely on touch and tactile sensing for a lot of dexterous manipulation\ntasks. Our tactile sensing provides us with a lot of information regarding\ncontact formations as well as geometric information about objects during any\ninteraction. With this motivation, vision-based tactile sensors are being\nwidely used for various robotic perception and control tasks. In this paper, we\npresent a method for interactive perception using vision-based tactile sensors\nfor multi-object assembly. In particular, we are interested in tactile\nperception during part mating, where a robot can use tactile sensors and a\nfeedback mechanism using particle filter to incrementally improve its estimate\nof objects that fit together for assembly. To do this, we first train a deep\nneural network that makes use of tactile images to predict the probabilistic\ncorrespondence between arbitrarily shaped objects that fit together. The\ntrained model is used to design a particle filter which is used twofold. First,\ngiven one partial (or non-unique) observation of the hole, it incrementally\nimproves the estimate of the correct peg by sampling more tactile observations.\nSecond, it selects the next action for the robot to sample the next touch (and\nthus image) which results in maximum uncertainty reduction to minimize the\nnumber of interactions during the perception task. We evaluate our method on\nseveral part-mating tasks for assembly using a robot equipped with a\nvision-based tactile sensor. We also show the efficiency of the proposed action\nselection method against a naive method. See supplementary video at\nhttps://www.youtube.com/watch?v=jMVBg_e3gLw .\n","authors":["Kei Ota","Devesh K. Jha","Hsiao-Yu Tung","Joshua B. Tenenbaum"],"pdf_url":"https://arxiv.org/pdf/2303.06034v1.pdf","comment":"under submission"},{"id":"http://arxiv.org/abs/2303.06024v1","updated":"2023-03-10T16:23:56Z","published":"2023-03-10T16:23:56Z","title":"A hybrid deep-learning-metaheuristic framework to approximate discrete\n  road network design problems","summary":"  This study proposes a hybrid deep-learning-metaheuristic framework with a\nbi-level architecture to solve road network design problems (NDPs). We train a\ngraph neural network (GNN) to approximate the solution of the user equilibrium\n(UE) traffic assignment problem, and use inferences made by the trained model\nto calculate fitness function evaluations of a genetic algorithm (GA) to\napproximate solutions for NDPs. Using two NDP variants and an exact solver as\nbenchmark, we show that our proposed framework can provide solutions within 5%\ngap of the global optimum results given less than 1% of the time required for\nfinding the optimal results. Moreover, we observe many interesting future\ndirections, thus we propose a brief research agenda for this topic. The key\nobservation inspiring influential future research was that fitness function\nevaluation time using the inferences made by the GNN model for the genetic\nalgorithm was in the order of milliseconds, which points to an opportunity and\na need for novel heuristics that 1) can cope well with noisy fitness function\nvalues provided by neural networks, and 2) can use the significantly higher\ncomputation time provided to them to explore the search space effectively\n(rather than efficiently). This opens a new avenue for a modern class of\nmetaheuristics that are crafted for use with AI-powered predictors.\n","authors":["Bahman Madadi","Goncalo Homem de Almeida Correia"],"pdf_url":"https://arxiv.org/pdf/2303.06024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01340v3","updated":"2023-03-10T16:23:19Z","published":"2022-11-02T17:48:52Z","title":"POLICE: Provably Optimal Linear Constraint Enforcement for Deep Neural\n  Networks","summary":"  Deep Neural Networks (DNNs) outshine alternative function approximators in\nmany settings thanks to their modularity in composing any desired\ndifferentiable operator. The formed parametrized functional is then tuned to\nsolve a task at hand from simple gradient descent. This modularity comes at the\ncost of making strict enforcement of constraints on DNNs, e.g. from a priori\nknowledge of the task, or from desired physical properties, an open challenge.\nIn this paper we propose the first provable affine constraint enforcement\nmethod for DNNs that only requires minimal changes into a given DNN's\nforward-pass, that is computationally friendly, and that leaves the\noptimization of the DNN's parameter to be unconstrained, i.e. standard\ngradient-based method can be employed. Our method does not require any sampling\nand provably ensures that the DNN fulfills the affine constraint on a given\ninput space's region at any point during training, and testing. We coin this\nmethod POLICE, standing for Provably Optimal LInear Constraint Enforcement.\nGithub: https://github.com/RandallBalestriero/POLICE\n","authors":["Randall Balestriero","Yann LeCun"],"pdf_url":"https://arxiv.org/pdf/2211.01340v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06021v1","updated":"2023-03-10T16:22:38Z","published":"2023-03-10T16:22:38Z","title":"Machine learning for sports betting: should forecasting models be\n  optimised for accuracy or calibration?","summary":"  Sports betting's recent federal legalisation in the USA coincides with the\ngolden age of machine learning. If bettors can leverage data to accurately\npredict the probability of an outcome, they can recognise when the bookmaker's\nodds are in their favour. As sports betting is a multi-billion dollar industry\nin the USA alone, identifying such opportunities could be extremely lucrative.\nMany researchers have applied machine learning to the sports outcome prediction\nproblem, generally using accuracy to evaluate the performance of forecasting\nmodels. We hypothesise that for the sports betting problem, model calibration\nis more important than accuracy. To test this hypothesis, we train models on\nNBA data over several seasons and run betting experiments on a single season,\nusing published odds. Evaluating various betting systems, we show that\noptimising the forecasting model for calibration leads to greater returns than\noptimising for accuracy, on average (return on investment of $110.42\\%$ versus\n$2.98\\%$) and in the best case ($902.01\\%$ versus $222.84\\%$). These findings\nsuggest that for sports betting (or any forecasting problem where decisions are\nmade based on the predicted probability of each outcome), calibration is a more\nimportant metric than accuracy. Sports bettors who wish to increase profits\nshould therefore optimise their forecasting model for calibration.\n","authors":["Conor Walsh","Alok Joshi"],"pdf_url":"https://arxiv.org/pdf/2303.06021v1.pdf","comment":"27 pages (including bibliography). 8 Figures"},{"id":"http://arxiv.org/abs/2303.06010v1","updated":"2023-03-10T16:13:35Z","published":"2023-03-10T16:13:35Z","title":"Forecasting Solar Irradiance without Direct Observation: An Empirical\n  Analysis","summary":"  As the use of solar power increases, having accurate and timely forecasters\nwill be essential for smooth grid operators. There are many proposed methods\nfor forecasting solar irradiance / solar power production. However, many of\nthese methods formulate the problem as a time-series, relying on near real-time\naccess to observations at the location of interest to generate forecasts. This\nrequires both access to a real-time stream of data and enough historical\nobservations for these methods to be deployed. In this paper, we conduct a\nthorough analysis of effective ways to formulate the forecasting problem\ncomparing classical machine learning approaches to state-of-the-art deep\nlearning. Using data from 20 locations distributed throughout the UK and\ncommercially available weather data, we show that it is possible to build\nsystems that do not require access to this data. Leveraging weather\nobservations and measurements from other locations we show it is possible to\ncreate models capable of accurately forecasting solar irradiance at new\nlocations. We utilise compare both satellite and ground observations (e.g.\ntemperature, pressure) of weather data. This could facilitate use planning and\noptimisation for both newly deployed solar farms and domestic installations\nfrom the moment they come online. Additionally, we show that training a single\nglobal model for multiple locations can produce a more robust model with more\nconsistent and accurate results across locations.\n","authors":["Timothy Cargan","Dario Landa-Silva","Isaac Triguero"],"pdf_url":"https://arxiv.org/pdf/2303.06010v1.pdf","comment":"39 pages, 11 figures"},{"id":"http://arxiv.org/abs/2210.12256v2","updated":"2023-03-10T16:05:53Z","published":"2022-10-21T21:24:37Z","title":"Uncertainty Estimates of Predictions via a General Bias-Variance\n  Decomposition","summary":"  Reliably estimating the uncertainty of a prediction throughout the model\nlifecycle is crucial in many safety-critical applications. The most common way\nto measure this uncertainty is via the predicted confidence. While this tends\nto work well for in-domain samples, these estimates are unreliable under domain\ndrift and restricted to classification. Alternatively, proper scores can be\nused for most predictive tasks but a bias-variance decomposition for model\nuncertainty does not exist in the current literature. In this work we introduce\na general bias-variance decomposition for proper scores, giving rise to the\nBregman Information as the variance term. We discover how exponential families\nand the classification log-likelihood are special cases and provide novel\nformulations. Surprisingly, we can express the classification case purely in\nthe logit space. We showcase the practical relevance of this decomposition on\nseveral downstream tasks, including model ensembles and confidence regions.\nFurther, we demonstrate how different approximations of the instance-level\nBregman Information allow reliable out-of-distribution detection for all\ndegrees of domain drift.\n","authors":["Sebastian G. Gruber","Florian Buettner"],"pdf_url":"https://arxiv.org/pdf/2210.12256v2.pdf","comment":"Accepted at AISTATS 2023"},{"id":"http://arxiv.org/abs/2211.10257v2","updated":"2023-03-10T15:43:54Z","published":"2022-11-18T14:28:21Z","title":"Model-based Causal Bayesian Optimization","summary":"  How should we intervene on an unknown structural equation model to maximize a\ndownstream variable of interest? This setting, also known as causal Bayesian\noptimization (CBO), has important applications in medicine, ecology, and\nmanufacturing. Standard Bayesian optimization algorithms fail to effectively\nleverage the underlying causal structure. Existing CBO approaches assume\nnoiseless measurements and do not come with guarantees. We propose the\nmodel-based causal Bayesian optimization algorithm (MCBO) that learns a full\nsystem model instead of only modeling intervention-reward pairs. MCBO\npropagates epistemic uncertainty about the causal mechanisms through the graph\nand trades off exploration and exploitation via the optimism principle. We\nbound its cumulative regret, and obtain the first non-asymptotic bounds for\nCBO. Unlike in standard Bayesian optimization, our acquisition function cannot\nbe evaluated in closed form, so we show how the reparameterization trick can be\nused to apply gradient-based optimizers. The resulting practical implementation\nof MCBO compares favorably with state-of-the-art approaches empirically.\n","authors":["Scott Sussex","Anastasiia Makarova","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2211.10257v2.pdf","comment":"24 pages, 8 figures, accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2006.06853v6","updated":"2023-03-10T15:42:52Z","published":"2020-06-11T21:59:13Z","title":"Maximal Objectives in the Multi-armed Bandit with Applications","summary":"  In several applications of the stochastic multi-armed bandit problem, the\ntraditional objective of maximizing the expected total reward can be\ninappropriate. In this paper, motivated by certain operational concerns in\nonline platforms, we consider a new objective in the classical setup. Given $K$\narms, instead of maximizing the expected total reward from $T$ pulls (the\ntraditional \"sum\" objective), we consider the vector of total rewards earned\nfrom each of the $K$ arms at the end of $T$ pulls and aim to maximize the\nexpected highest total reward across arms (the \"max\" objective). For this\nobjective, we show that any policy must incur an instance-dependent asymptotic\nregret of $\\Omega(\\log T)$ (with a higher instance-dependent constant compared\nto the traditional objective) and a worst-case regret of\n$\\Omega(K^{1/3}T^{2/3})$. We then design an adaptive explore-then-commit policy\nfeaturing exploration based on appropriately tuned confidence bounds on the\nmean reward and an adaptive stopping criterion, which adapts to the problem\ndifficulty and achieves these bounds (up to logarithmic factors). We then\ngeneralize our algorithmic insights to the problem of maximizing the expected\nvalue of the average total reward of the top $m$ arms with the highest total\nrewards. Our numerical experiments demonstrate the efficacy of our policies\ncompared to several natural alternatives in practical parameter regimes. We\ndiscuss applications of these new objectives to the problem of grooming an\nadequate supply of value-providing market participants (workers/sellers/service\nproviders) in online platforms.\n","authors":["Eren Ozbay","Vijay Kamble"],"pdf_url":"https://arxiv.org/pdf/2006.06853v6.pdf","comment":"92 pages, 10 figures, 6 tables"},{"id":"http://arxiv.org/abs/2107.00055v3","updated":"2023-03-10T15:41:02Z","published":"2021-06-30T18:38:08Z","title":"Approximate Regions of Attraction in Learning with Decision-Dependent\n  Distributions","summary":"  As data-driven methods are deployed in real-world settings, the processes\nthat generate the observed data will often react to the decisions of the\nlearner. For example, a data source may have some incentive for the algorithm\nto provide a particular label (e.g. approve a bank loan), and manipulate their\nfeatures accordingly. Work in strategic classification and decision-dependent\ndistributions seeks to characterize the closed-loop behavior of deploying\nlearning algorithms by explicitly considering the effect of the classifier on\nthe underlying data distribution. More recently, works in performative\nprediction seek to classify the closed-loop behavior by considering general\nproperties of the mapping from classifier to data distribution, rather than an\nexplicit form. Building on this notion, we analyze repeated risk minimization\nas the perturbed trajectories of the gradient flows of performative risk\nminimization. We consider the case where there may be multiple local minimizers\nof performative risk, motivated by situations where the initial conditions may\nhave significant impact on the long-term behavior of the system. We provide\nsufficient conditions to characterize the region of attraction for the various\nequilibria in this settings. Additionally, we introduce the notion of\nperformative alignment, which provides a geometric condition on the convergence\nof repeated risk minimization to performative risk minimizers.\n","authors":["Roy Dong","Heling Zhang","Lillian J. Ratliff"],"pdf_url":"https://arxiv.org/pdf/2107.00055v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05978v1","updated":"2023-03-10T15:21:12Z","published":"2023-03-10T15:21:12Z","title":"Neural Gromov-Wasserstein Optimal Transport","summary":"  We present a scalable neural method to solve the Gromov-Wasserstein (GW)\nOptimal Transport (OT) problem with the inner product cost. In this problem,\ngiven two distributions supported on (possibly different) spaces, one has to\nfind the most isometric map between them. Our proposed approach uses neural\nnetworks and stochastic mini-batch optimization which allows to overcome the\nlimitations of existing GW methods such as their poor scalability with the\nnumber of samples and the lack of out-of-sample estimation. To demonstrate the\neffectiveness of our proposed method, we conduct experiments on the synthetic\ndata and explore the practical applicability of our method to the popular task\nof the unsupervised alignment of word embeddings.\n","authors":["Maksim Nekrashevich","Alexander Korotin","Evgeny Burnaev"],"pdf_url":"https://arxiv.org/pdf/2303.05978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05972v1","updated":"2023-03-10T15:05:32Z","published":"2023-03-10T15:05:32Z","title":"Classifying the evolution of COVID-19 severity on patients with combined\n  dynamic Bayesian networks and neural networks","summary":"  When we face patients arriving to a hospital suffering from the effects of\nsome illness, one of the main problems we can encounter is evaluating whether\nor not said patients are going to require intensive care in the near future.\nThis intensive care requires allotting valuable and scarce resources, and\nknowing beforehand the severity of a patients illness can improve both its\ntreatment and the organization of resources. We illustrate this issue in a\ndataset consistent of Spanish COVID-19 patients from the sixth epidemic wave\nwhere we label patients as critical when they either had to enter the intensive\ncare unit or passed away. We then combine the use of dynamic Bayesian networks,\nto forecast the vital signs and the blood analysis results of patients over the\nnext 40 hours, and neural networks, to evaluate the severity of a patients\ndisease in that interval of time. Our empirical results show that the\ntransposition of the current state of a patient to future values with the DBN\nfor its subsequent use in classification obtains better the accuracy and g-mean\nscore than a direct application with a classifier.\n","authors":["David Quesada","Pedro Larrañaga","Concha Bielza"],"pdf_url":"https://arxiv.org/pdf/2303.05972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10143v2","updated":"2023-03-10T15:05:28Z","published":"2022-06-21T07:01:36Z","title":"A Contrastive Approach to Online Change Point Detection","summary":"  We suggest a novel procedure for online change point detection. Our approach\nexpands an idea of maximizing a discrepancy measure between points from\npre-change and post-change distributions. This leads to a flexible procedure\nsuitable for both parametric and nonparametric scenarios. We prove\nnon-asymptotic bounds on the average running length of the procedure and its\nexpected detection delay. The efficiency of the algorithm is illustrated with\nnumerical experiments on synthetic and real-world data sets.\n","authors":["Nikita Puchkin","Valeriia Shcherbakova"],"pdf_url":"https://arxiv.org/pdf/2206.10143v2.pdf","comment":"Accepted for presentation at AISTATS 2023; 28 pages"},{"id":"http://arxiv.org/abs/2206.04530v2","updated":"2023-03-10T14:41:21Z","published":"2022-06-09T14:25:14Z","title":"DORA: Exploring outlier representations in Deep Neural Networks","summary":"  Deep Neural Networks (DNNs) draw their power from the representations they\nlearn. However, while being incredibly effective in learning complex\nabstractions, they are susceptible to learning malicious concepts, due to the\nspurious correlations inherent in the training data. So far, existing methods\nfor uncovering such artifactual behavior in trained models focus on finding\nartifacts in the input data, which requires both availability of a data set and\nhuman supervision. In this paper, we introduce DORA (Data-agnOstic\nRepresentation Analysis): the first data-agnostic framework for the analysis of\nthe representation space of DNNs. We propose a novel distance measure between\nrepresentations that utilizes self-explaining capabilities within the network\nitself without access to any data and quantitatively validate its alignment\nwith human-defined semantic distances. We further demonstrate that this metric\ncould be utilized for the detection of anomalous representations, which may\nbear a risk of learning unintended spurious concepts deviating from the desired\ndecision-making policy. Finally, we demonstrate the practical utility of DORA\nby analyzing and identifying artifactual representations in widely popular\nComputer Vision models.\n","authors":["Kirill Bykov","Mayukh Deb","Dennis Grinwald","Klaus-Robert Müller","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2206.04530v2.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2202.13710v2","updated":"2023-03-10T14:39:35Z","published":"2022-02-28T12:10:48Z","title":"Best of Many Worlds Guarantees for Online Learning with Knapsacks","summary":"  We study online learning problems in which a decision maker wants to maximize\ntheir expected reward without violating a finite set of $m$ resource\nconstraints. By casting the learning process over a suitably defined space of\nstrategy mixtures, we recover strong duality on a Lagrangian relaxation of the\nunderlying optimization problem, even for general settings with non-convex\nreward and resource-consumption functions. Then, we provide the first\nbest-of-many-worlds type framework for this setting, with no-regret guarantees\nunder stochastic, adversarial, and non-stationary inputs. Our framework yields\nthe same regret guarantees of prior work in the stochastic case. On the other\nhand, when budgets grow at least linearly in the time horizon, it allows us to\nprovide a constant competitive ratio in the adversarial case, which improves\nover the best known upper bound bound of $O(\\log m \\log T)$. Moreover, our\nframework allows the decision maker to handle non-convex reward and cost\nfunctions. We provide two game-theoretic applications of our framework to give\nfurther evidence of its flexibility. In doing so, we show that it can be\nemployed to implement budget-pacing mechanisms in repeated first-price\nauctions.\n","authors":["Andrea Celli","Matteo Castiglioni","Christian Kroer"],"pdf_url":"https://arxiv.org/pdf/2202.13710v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05952v1","updated":"2023-03-10T14:38:49Z","published":"2023-03-10T14:38:49Z","title":"Understanding and Constructing Latent Modality Structures in Multi-modal\n  Representation Learning","summary":"  Contrastive loss has been increasingly used in learning representations from\nmultiple modalities. In the limit, the nature of the contrastive loss\nencourages modalities to exactly match each other in the latent space. Yet it\nremains an open question how the modality alignment affects the downstream task\nperformance. In this paper, based on an information-theoretic argument, we\nfirst prove that exact modality alignment is sub-optimal in general for\ndownstream prediction tasks. Hence we advocate that the key of better\nperformance lies in meaningful latent modality structures instead of perfect\nmodality alignment. To this end, we propose three general approaches to\nconstruct latent modality structures. Specifically, we design 1) a deep feature\nseparation loss for intra-modality regularization; 2) a Brownian-bridge loss\nfor inter-modality regularization; and 3) a geometric consistency loss for both\nintra- and inter-modality regularization. Extensive experiments are conducted\non two popular multi-modal representation learning frameworks: the CLIP-based\ntwo-tower model and the ALBEF-based fusion model. We test our model on a\nvariety of tasks including zero/few-shot image classification, image-text\nretrieval, visual question answering, visual reasoning, and visual entailment.\nOur method achieves consistent improvements over existing methods,\ndemonstrating the effectiveness and generalizability of our proposed approach\non latent modality structure regularization.\n","authors":["Qian Jiang","Changyou Chen","Han Zhao","Liqun Chen","Qing Ping","Son Dinh Tran","Yi Xu","Belinda Zeng","Trishul Chilimbi"],"pdf_url":"https://arxiv.org/pdf/2303.05952v1.pdf","comment":"14 pages, 8 figure, CVPR 2023 accepted"},{"id":"http://arxiv.org/abs/2303.05947v1","updated":"2023-03-10T14:29:06Z","published":"2023-03-10T14:29:06Z","title":"Automotive Perception Software Development: An Empirical Investigation\n  into Data, Annotation, and Ecosystem Challenges","summary":"  Software that contains machine learning algorithms is an integral part of\nautomotive perception, for example, in driving automation systems. The\ndevelopment of such software, specifically the training and validation of the\nmachine learning components, require large annotated datasets. An industry of\ndata and annotation services has emerged to serve the development of such\ndata-intensive automotive software components. Wide-spread difficulties to\nspecify data and annotation needs challenge collaborations between OEMs\n(Original Equipment Manufacturers) and their suppliers of software components,\ndata, and annotations. This paper investigates the reasons for these\ndifficulties for practitioners in the Swedish automotive industry to arrive at\nclear specifications for data and annotations. The results from an interview\nstudy show that a lack of effective metrics for data quality aspects,\nambiguities in the way of working, unclear definitions of annotation quality,\nand deficits in the business ecosystems are causes for the difficulty in\nderiving the specifications. We provide a list of recommendations that can\nmitigate challenges when deriving specifications and we propose future research\nopportunities to overcome these challenges. Our work contributes towards the\non-going research on accountability of machine learning as applied to complex\nsoftware systems, especially for high-stake applications such as automated\ndriving.\n","authors":["Hans-Martin Heyn","Khan Mohammad Habibullah","Eric Knauss","Jennifer Horkoff","Markus Borg","Alessia Knauss","Polly Jing Li"],"pdf_url":"https://arxiv.org/pdf/2303.05947v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00954v2","updated":"2023-03-10T14:28:57Z","published":"2022-10-03T14:11:33Z","title":"Machine Learning-powered Course Allocation","summary":"  We introduce a machine learning-powered course allocation mechanism.\nConcretely, we extend the state-of-the-art Course Match mechanism with a\nmachine learning-based preference elicitation module. In an iterative,\nasynchronous manner, this module generates pairwise comparison queries that are\ntailored to each individual student. Regarding incentives, our machine\nlearning-powered course match (MLCM) mechanism retains the attractive\nstrategyproofness in the large property of Course Match. Regarding welfare, we\nperform computational experiments using a simulator that was fitted to\nreal-world data. Our results show that, compared to Course Match, MLCM\nincreases average student utility by 4%-9% and minimum student utility by\n10%-21%, even with only ten comparison queries. Finally, we highlight the\npracticability of MLCM and the ease of piloting it for universities currently\nusing Course Match.\n","authors":["Ermis Soumalias","Behnoosh Zamanlooy","Jakob Weissteiner","Sven Seuken"],"pdf_url":"https://arxiv.org/pdf/2210.00954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05927v1","updated":"2023-03-10T13:58:28Z","published":"2023-03-10T13:58:28Z","title":"Estimating friction coefficient using generative modelling","summary":"  It is common to utilise dynamic models to measure the tyre-road friction in\nreal-time. Alternatively, predictive approaches estimate the tyre-road friction\nby identifying the environmental factors affecting it. This work aims to\nformulate the problem of friction estimation as a visual perceptual learning\ntask. The problem is broken down into detecting surface characteristics by\napplying semantic segmentation and using the extracted features to predict the\nfrictional force. This work for the first time formulates the friction\nestimation problem as a regression from the latent space of a semantic\nsegmentation model. The preliminary results indicate that this approach can\nestimate frictional force.\n","authors":["Mohammad Otoofi","William J. B. Midgley","Leo Laine","Henderson Leon","Laura Justham","James Fleming"],"pdf_url":"https://arxiv.org/pdf/2303.05927v1.pdf","comment":"To be published in ICM2023"},{"id":"http://arxiv.org/abs/2303.05911v1","updated":"2023-03-10T13:38:36Z","published":"2023-03-10T13:38:36Z","title":"Lifelong Machine Learning Potentials","summary":"  Machine learning potentials (MLPs) trained on accurate quantum chemical data\ncan retain the high accuracy, while inflicting little computational demands. On\nthe downside, they need to be trained for each individual system. In recent\nyears, a vast number of MLPs has been trained from scratch because learning\nadditional data typically requires to train again on all data to not forget\npreviously acquired knowledge. Additionally, most common structural descriptors\nof MLPs cannot represent efficiently a large number of different chemical\nelements. In this work, we tackle these problems by introducing\nelement-embracing atom-centered symmetry functions (eeACSFs) which combine\nstructural properties and element information from the periodic table. These\neeACSFs are a key for our development of a lifelong machine learning potential\n(lMLP). Uncertainty quantification can be exploited to transgress a fixed,\npre-trained MLP to arrive at a continuously adapting lMLP, because a predefined\nlevel of accuracy can be ensured. To extend the applicability of an lMLP to new\nsystems, we apply continual learning strategies to enable autonomous and\non-the-fly training on a continuous stream of new data. For the training of\ndeep neural networks, we propose the continual resilient (CoRe) optimizer and\nincremental learning strategies relying on rehearsal of data, regularization of\nparameters, and the architecture of the model.\n","authors":["Marco Eckhoff","Markus Reiher"],"pdf_url":"https://arxiv.org/pdf/2303.05911v1.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.05910v1","updated":"2023-03-10T13:37:57Z","published":"2023-03-10T13:37:57Z","title":"Product Jacobi-Theta Boltzmann machines with score matching","summary":"  The estimation of probability density functions is a non trivial task that\nover the last years has been tackled with machine learning techniques.\nSuccessful applications can be obtained using models inspired by the Boltzmann\nmachine (BM) architecture. In this manuscript, the product Jacobi-Theta\nBoltzmann machine (pJTBM) is introduced as a restricted version of the\nRiemann-Theta Boltzmann machine (RTBM) with diagonal hidden sector connection\nmatrix. We show that score matching, based on the Fisher divergence, can be\nused to fit probability densities with the pJTBM more efficiently than with the\noriginal RTBM.\n","authors":["Andrea Pasquale","Daniel Krefl","Stefano Carrazza","Frank Nielsen"],"pdf_url":"https://arxiv.org/pdf/2303.05910v1.pdf","comment":"7 pages, 3 figures, ACAT22 proceedings"},{"id":"http://arxiv.org/abs/2302.14307v2","updated":"2023-03-10T13:28:52Z","published":"2023-02-28T04:45:31Z","title":"GradMA: A Gradient-Memory-based Accelerated Federated Learning with\n  Alleviated Catastrophic Forgetting","summary":"  Federated Learning (FL) has emerged as a de facto machine learning area and\nreceived rapid increasing research interests from the community. However,\ncatastrophic forgetting caused by data heterogeneity and partial participation\nposes distinctive challenges for FL, which are detrimental to the performance.\nTo tackle the problems, we propose a new FL approach (namely GradMA), which\ntakes inspiration from continual learning to simultaneously correct the\nserver-side and worker-side update directions as well as take full advantage of\nserver's rich computing and memory resources. Furthermore, we elaborate a\nmemory reduction strategy to enable GradMA to accommodate FL with a large scale\nof workers. We then analyze convergence of GradMA theoretically under the\nsmooth non-convex setting and show that its convergence rate achieves a linear\nspeed up w.r.t the increasing number of sampled active workers. At last, our\nextensive experiments on various image classification tasks show that GradMA\nachieves significant performance gains in accuracy and communication efficiency\ncompared to SOTA baselines.\n","authors":["Kangyang Luo","Xiang Li","Yunshi Lan","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2302.14307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05904v1","updated":"2023-03-10T13:20:52Z","published":"2023-03-10T13:20:52Z","title":"Deep Anomaly Detection on Tennessee Eastman Process Data","summary":"  This paper provides the first comprehensive evaluation and analysis of modern\n(deep-learning) unsupervised anomaly detection methods for chemical process\ndata. We focus on the Tennessee Eastman process dataset, which has been a\nstandard litmus test to benchmark anomaly detection methods for nearly three\ndecades. Our extensive study will facilitate choosing appropriate anomaly\ndetection methods in industrial applications.\n","authors":["Fabian Hartung","Billy Joe Franks","Tobias Michels","Dennis Wagner","Philipp Liznerski","Steffen Reithermann","Sophie Fellenz","Fabian Jirasek","Maja Rudolph","Daniel Neider","Heike Leitte","Chen Song","Benjamin Kloepper","Stephan Mandt","Michael Bortz","Jakob Burger","Hans Hasse","Marius Kloft"],"pdf_url":"https://arxiv.org/pdf/2303.05904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1906.07801v5","updated":"2023-03-10T13:14:45Z","published":"2019-06-18T20:39:27Z","title":"Safe Testing","summary":"  We develop the theory of hypothesis testing based on the e-value, a notion of\nevidence that, unlike the p-value, allows for effortlessly combining results\nfrom several studies in the common scenario where the decision to perform a new\nstudy may depend on previous outcomes. Tests based on e-values are safe, i.e.\nthey preserve Type-I error guarantees, under such optional continuation. We\ndefine growth-rate optimality (GRO) as an analogue of power in an optional\ncontinuation context, and we show how to construct GRO e-variables for general\ntesting problems with composite null and alternative, emphasizing models with\nnuisance parameters. GRO e-values take the form of Bayes factors with special\npriors. We illustrate the theory using several classic examples including a\none-sample safe t-test and the 2 x 2 contingency table. Sharing Fisherian,\nNeymanian and Jeffreys-Bayesian interpretations, e-values may provide a\nmethodology acceptable to adherents of all three schools.\n","authors":["Peter Grünwald","Rianne de Heide","Wouter Koolen"],"pdf_url":"https://arxiv.org/pdf/1906.07801v5.pdf","comment":"Accepted as discussion paper to the Journal of the Royal Statistical\n  Society series B"},{"id":"http://arxiv.org/abs/2209.09617v2","updated":"2023-03-10T13:09:10Z","published":"2022-09-20T11:23:19Z","title":"Seq2Seq Surrogates of Epidemic Models to Facilitate Bayesian Inference","summary":"  Epidemic models are powerful tools in understanding infectious disease.\nHowever, as they increase in size and complexity, they can quickly become\ncomputationally intractable. Recent progress in modelling methodology has shown\nthat surrogate models can be used to emulate complex epidemic models with a\nhigh-dimensional parameter space. We show that deep sequence-to-sequence\n(seq2seq) models can serve as accurate surrogates for complex epidemic models\nwith sequence based model parameters, effectively replicating seasonal and\nlong-term transmission dynamics. Once trained, our surrogate can predict\nscenarios a several thousand times faster than the original model, making them\nideal for policy exploration. We demonstrate that replacing a traditional\nepidemic model with a learned simulator facilitates robust Bayesian inference.\n","authors":["Giovanni Charles","Timothy M. Wolock","Peter Winskill","Azra Ghani","Samir Bhatt","Seth Flaxman"],"pdf_url":"https://arxiv.org/pdf/2209.09617v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05896v1","updated":"2023-03-10T13:05:30Z","published":"2023-03-10T13:05:30Z","title":"Distribution Preserving Source Separation With Time Frequency Predictive\n  Models","summary":"  We provide an example of a distribution preserving source separation method,\nwhich aims at addressing perceptual shortcomings of state-of-the-art methods.\nOur approach uses unconditioned generative models of signal sources.\nReconstruction is achieved by means of mix-consistent sampling from a\ndistribution conditioned on a realization of a mix. The separated signals\nfollow their respective source distributions, which provides an advantage when\nseparation results are evaluated in a listening test.\n","authors":["Pedro J. Villasana T.","Janusz Klejsa","Lars Villemoes","Per Hedelin"],"pdf_url":"https://arxiv.org/pdf/2303.05896v1.pdf","comment":"5 pages, 4 figures, pre-review version submitted to EUSIPCO 2023"},{"id":"http://arxiv.org/abs/2301.00351v2","updated":"2023-03-10T12:56:51Z","published":"2023-01-01T05:26:33Z","title":"Skew Class-balanced Re-weighting for Unbiased Scene Graph Generation","summary":"  An unbiased scene graph generation (SGG) algorithm referred to as Skew\nClass-balanced Re-weighting (SCR) is proposed for considering the unbiased\npredicate prediction caused by the long-tailed distribution. The prior works\nfocus mainly on alleviating the deteriorating performances of the minority\npredicate predictions, showing drastic dropping recall scores, i.e., losing the\nmajority predicate performances. It has not yet correctly analyzed the\ntrade-off between majority and minority predicate performances in the limited\nSGG datasets. In this paper, to alleviate the issue, the Skew Class-balanced\nRe-weighting (SCR) loss function is considered for the unbiased SGG models.\nLeveraged by the skewness of biased predicate predictions, the SCR estimates\nthe target predicate weight coefficient and then re-weights more to the biased\npredicates for better trading-off between the majority predicates and the\nminority ones. Extensive experiments conducted on the standard Visual Genome\ndataset and Open Image V4 \\& V6 show the performances and generality of the SCR\nwith the traditional SGG models.\n","authors":["Haeyong Kang","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2301.00351v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13060v2","updated":"2023-03-10T12:53:09Z","published":"2023-01-30T17:02:23Z","title":"Zero-One Laws of Graph Neural Networks","summary":"  Graph neural networks (GNNs) are de facto standard deep learning\narchitectures for machine learning on graphs. This has led to a large body of\nwork analyzing the capabilities and limitations of these models, particularly\npertaining to their representation and extrapolation capacity. We offer a novel\ntheoretical perspective on the representation and extrapolation capacity of\nGNNs, by answering the question: how do GNNs behave as the number of graph\nnodes become very large? Under mild assumptions, we show that when we draw\ngraphs of increasing size from the Erd\\H{o}s-R\\'enyi model, the probability\nthat such graphs are mapped to a particular output by a class of GNN\nclassifiers tends to either zero or to one. This class includes the popular\ngraph convolutional network architecture. The result establishes 'zero-one\nlaws' for these GNNs, and analogously to other convergence laws, entails\ntheoretical limitations on their capacity. We empirically verify our results,\nobserving that the theoretical asymptotic limits are evident already on\nrelatively small graphs.\n","authors":["Sam Adam-Day","Theodor Mihai Iliant","İsmail İlkan Ceylan"],"pdf_url":"https://arxiv.org/pdf/2301.13060v2.pdf","comment":"8 pages + references + 9 pages appendices, 2 figures"},{"id":"http://arxiv.org/abs/2303.05873v1","updated":"2023-03-10T11:56:56Z","published":"2023-03-10T11:56:56Z","title":"Simulation-based Bayesian inference for robotic grasping","summary":"  General robotic grippers are challenging to control because of their rich\nnonsmooth contact dynamics and the many sources of uncertainties due to the\nenvironment or sensor noise. In this work, we demonstrate how to compute 6-DoF\ngrasp poses using simulation-based Bayesian inference through the full\nstochastic forward simulation of the robot in its environment while robustly\naccounting for many of the uncertainties in the system. A Riemannian manifold\noptimization procedure preserving the nonlinearity of the rotation space is\nused to compute the maximum a posteriori grasp pose. Simulation and physical\nbenchmarks show the promising high success rate of the approach.\n","authors":["Norman Marlier","Olivier Brüls","Gilles Louppe"],"pdf_url":"https://arxiv.org/pdf/2303.05873v1.pdf","comment":"5 pages, 4 figures, IROS 2022 Probabilistic Robotics at the age of\n  Deep Learning workshop. arXiv admin note: substantial text overlap with\n  arXiv:2109.14275"},{"id":"http://arxiv.org/abs/2303.05871v1","updated":"2023-03-10T11:51:22Z","published":"2023-03-10T11:51:22Z","title":"Accurate Real-time Polyp Detection in Videos from Concatenation of\n  Latent Features Extracted from Consecutive Frames","summary":"  An efficient deep learning model that can be implemented in real-time for\npolyp detection is crucial to reducing polyp miss-rate during screening\nprocedures. Convolutional neural networks (CNNs) are vulnerable to small\nchanges in the input image. A CNN-based model may miss the same polyp appearing\nin a series of consecutive frames and produce unsubtle detection output due to\nchanges in camera pose, lighting condition, light reflection, etc. In this\nstudy, we attempt to tackle this problem by integrating temporal information\namong neighboring frames. We propose an efficient feature concatenation method\nfor a CNN-based encoder-decoder model without adding complexity to the model.\nThe proposed method incorporates extracted feature maps of previous frames to\ndetect polyps in the current frame. The experimental results demonstrate that\nthe proposed method of feature concatenation improves the overall performance\nof automatic polyp detection in videos. The following results are obtained on a\npublic video dataset: sensitivity 90.94\\%, precision 90.53\\%, and specificity\n92.46%\n","authors":["Hemin Ali Qadir","Younghak Shin","Jacob Bergsland","Ilangko Balasingham"],"pdf_url":"https://arxiv.org/pdf/2303.05871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.13380v4","updated":"2023-03-10T11:38:48Z","published":"2021-02-26T10:08:02Z","title":"A novel notion of barycenter for probability distributions based on\n  optimal weak mass transport","summary":"  We introduce weak barycenters of a family of probability distributions, based\non the recently developed notion of optimal weak transport of mass by Gozlanet\nal. (2017) and Backhoff-Veraguas et al. (2020). We provide a theoretical\nanalysis of this object and discuss its interpretation in the light of convex\nordering between probability measures. In particular, we show that, rather than\naveraging the input distributions in a geometric way (as the Wasserstein\nbarycenter based on classic optimal transport does) weak barycenters extract\ncommon geometric information shared by all the input distributions, encoded as\na latent random variable that underlies all of them. We also provide an\niterative algorithm to compute a weak barycenter for a finite family of input\ndistributions, and a stochastic algorithm that computes them for arbitrary\npopulations of laws. The latter approach is particularly well suited for the\nstreaming setting, i.e., when distributions are observed sequentially. The\nnotion of weak barycenter and our approaches to compute it are illustrated on\nsynthetic examples, validated on 2D real-world data and compared to standard\nWasserstein barycenters.\n","authors":["Elsa Cazelles","Felipe Tobar","Joaquín Fontbona"],"pdf_url":"https://arxiv.org/pdf/2102.13380v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05860v1","updated":"2023-03-10T11:24:32Z","published":"2023-03-10T11:24:32Z","title":"Variational Quantum Neural Networks (VQNNS) in Image Classification","summary":"  Quantum machine learning has established as an interdisciplinary field to\novercome limitations of classical machine learning and neural networks. This is\na field of research which can prove that quantum computers are able to solve\nproblems with complex correlations between inputs that can be hard for\nclassical computers. This suggests that learning models made on quantum\ncomputers may be more powerful for applications, potentially faster computation\nand better generalization on less data. The objective of this paper is to\ninvestigate how training of quantum neural network (QNNs) can be done using\nquantum optimization algorithms for improving the performance and time\ncomplexity of QNNs. A classical neural network can be partially quantized to\ncreate a hybrid quantum-classical neural network which is used mainly in\nclassification and image recognition. In this paper, a QNN structure is made\nwhere a variational parameterized circuit is incorporated as an input layer\nnamed as Variational Quantum Neural Network (VQNNs). We encode the cost\nfunction of QNNs onto relative phases of a superposition state in the Hilbert\nspace of the network parameters. The parameters are tuned with an iterative\nquantum approximate optimisation (QAOA) mixer and problem hamiltonians. VQNNs\nis experimented with MNIST digit recognition (less complex) and crack image\nclassification datasets (more complex) which converges the computation in\nlesser time than QNN with decent training accuracy.\n","authors":["Meghashrita Das","Tirupati Bolisetti"],"pdf_url":"https://arxiv.org/pdf/2303.05860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.00553v4","updated":"2023-03-10T11:19:37Z","published":"2021-06-01T15:07:34Z","title":"SHINE: SHaring the INverse Estimate from the forward pass for bi-level\n  optimization and implicit models","summary":"  In recent years, implicit deep learning has emerged as a method to increase\nthe effective depth of deep neural networks. While their training is\nmemory-efficient, they are still significantly slower to train than their\nexplicit counterparts. In Deep Equilibrium Models (DEQs), the training is\nperformed as a bi-level problem, and its computational complexity is partially\ndriven by the iterative inversion of a huge Jacobian matrix. In this paper, we\npropose a novel strategy to tackle this computational bottleneck from which\nmany bi-level problems suffer. The main idea is to use the quasi-Newton\nmatrices from the forward pass to efficiently approximate the inverse Jacobian\nmatrix in the direction needed for the gradient computation. We provide a\ntheorem that motivates using our method with the original forward algorithms.\nIn addition, by modifying these forward algorithms, we further provide\ntheoretical guarantees that our method asymptotically estimates the true\nimplicit gradient. We empirically study this approach and the recent\nJacobian-Free method in different settings, ranging from hyperparameter\noptimization to large Multiscale DEQs (MDEQs) applied to CIFAR and ImageNet.\nBoth methods reduce significantly the computational cost of the backward pass.\nWhile SHINE has a clear advantage on hyperparameter optimization problems, both\nmethods attain similar computational performances for larger scale problems\nsuch as MDEQs at the cost of a limited performance drop compared to the\noriginal models.\n","authors":["Zaccharie Ramzi","Florian Mannel","Shaojie Bai","Jean-Luc Starck","Philippe Ciuciu","Thomas Moreau"],"pdf_url":"https://arxiv.org/pdf/2106.00553v4.pdf","comment":"Accepted as a spotlight to ICLR 2022"},{"id":"http://arxiv.org/abs/2212.00767v2","updated":"2023-03-10T10:57:23Z","published":"2022-12-01T18:52:46Z","title":"Exploiting Proximity-Aware Tasks for Embodied Social Navigation","summary":"  Learning how to navigate among humans in an occluded and spatially\nconstrained indoor environment, is a key ability required to embodied agent to\nbe integrated into our society. In this paper, we propose an end-to-end\narchitecture that exploits Proximity-Aware Tasks (referred as to Risk and\nProximity Compass) to inject into a reinforcement learning navigation policy\nthe ability to infer common-sense social behaviors. To this end, our tasks\nexploit the notion of immediate and future dangers of collision. Furthermore,\nwe propose an evaluation protocol specifically designed for the Social\nNavigation Task in simulated environments. This is done to capture fine-grained\nfeatures and characteristics of the policy by analyzing the minimal unit of\nhuman-robot spatial interaction, called Encounter. We validate our approach on\nGibson4+ and Habitat-Matterport3D datasets.\n","authors":["Enrico Cancelli","Tommaso Campari","Luciano Serafini","Angel X. Chang","Lamberto Ballan"],"pdf_url":"https://arxiv.org/pdf/2212.00767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05848v1","updated":"2023-03-10T10:53:33Z","published":"2023-03-10T10:53:33Z","title":"Decision-Making Under Uncertainty: Beyond Probabilities","summary":"  This position paper reflects on the state-of-the-art in decision-making under\nuncertainty. A classical assumption is that probabilities can sufficiently\ncapture all uncertainty in a system. In this paper, the focus is on the\nuncertainty that goes beyond this classical interpretation, particularly by\nemploying a clear distinction between aleatoric and epistemic uncertainty. The\npaper features an overview of Markov decision processes (MDPs) and extensions\nto account for partial observability and adversarial behavior. These models\nsufficiently capture aleatoric uncertainty but fail to account for epistemic\nuncertainty robustly. Consequently, we present a thorough overview of so-called\nuncertainty models that exhibit uncertainty in a more robust interpretation. We\nshow several solution techniques for both discrete and continuous models,\nranging from formal verification, over control-based abstractions, to\nreinforcement learning. As an integral part of this paper, we list and discuss\nseveral key challenges that arise when dealing with rich types of uncertainty\nin a model-based fashion.\n","authors":["Thom Badings","Thiago D. Simão","Marnix Suilen","Nils Jansen"],"pdf_url":"https://arxiv.org/pdf/2303.05848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05847v1","updated":"2023-03-10T10:42:21Z","published":"2023-03-10T10:42:21Z","title":"Gradient Coordination for Quantifying and Maximizing Knowledge\n  Transference in Multi-Task Learning","summary":"  Multi-task learning (MTL) has been widely applied in online advertising and\nrecommender systems. To address the negative transfer issue, recent studies\nhave proposed optimization methods that thoroughly focus on the gradient\nalignment of directions or magnitudes. However, since prior study has proven\nthat both general and specific knowledge exist in the limited shared capacity,\noveremphasizing on gradient alignment may crowd out task-specific knowledge,\nand vice versa. In this paper, we propose a transference-driven approach CoGrad\nthat adaptively maximizes knowledge transference via Coordinated Gradient\nmodification. We explicitly quantify the transference as loss reduction from\none task to another, and then derive an auxiliary gradient from optimizing it.\nWe perform the optimization by incorporating this gradient into original task\ngradients, making the model automatically maximize inter-task transfer and\nminimize individual losses. Thus, CoGrad can harmonize between general and\nspecific knowledge to boost overall performance. Besides, we introduce an\nefficient approximation of the Hessian matrix, making CoGrad computationally\nefficient and simple to implement. Both offline and online experiments verify\nthat CoGrad significantly outperforms previous methods.\n","authors":["Xuanhua Yang","Jianxin Zhao","Shaoguo Liu","Liang Wang","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.05847v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2206.03491v6","updated":"2023-03-10T10:34:33Z","published":"2022-06-07T07:45:45Z","title":"EiX-GNN : Concept-level eigencentrality explainer for graph neural\n  networks","summary":"  Nowadays, deep prediction models, especially graph neural networks, have a\nmajorplace in critical applications. In such context, those models need to be\nhighlyinterpretable or being explainable by humans, and at the societal scope,\nthis understandingmay also be feasible for humans that do not have a strong\nprior knowledgein models and contexts that need to be explained. In the\nliterature, explainingis a human knowledge transfer process regarding a\nphenomenon between an explainerand an explainee. We propose EiX-GNN\n(Eigencentrality eXplainer forGraph Neural Networks) a new powerful method for\nexplaining graph neural networksthat encodes computationally this social\nexplainer-to-explainee dependenceunderlying in the explanation process. To\nhandle this dependency, we introducethe notion of explainee concept\nassimibility which allows explainer to adapt itsexplanation to explainee\nbackground or expectation. We lead a qualitative studyto illustrate our\nexplainee concept assimibility notion on real-world data as wellas a\nqualitative study that compares, according to objective metrics established\ninthe literature, fairness and compactness of our method with respect to\nperformingstate-of-the-art methods. It turns out that our method achieves\nstrong results inboth aspects.\n","authors":["Adrien Raison","Pascal Bourdon","David Helbert"],"pdf_url":"https://arxiv.org/pdf/2206.03491v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14105v2","updated":"2023-03-10T10:24:50Z","published":"2022-09-28T13:55:28Z","title":"Exploring the Relationship between Architecture and Adversarially Robust\n  Generalization","summary":"  Adversarial training has been demonstrated to be one of the most effective\nremedies for defending adversarial examples, yet it often suffers from the huge\nrobustness generalization gap on unseen testing adversaries, deemed as the\nadversarially robust generalization problem. Despite the preliminary\nunderstandings devoted to adversarially robust generalization, little is known\nfrom the architectural perspective. To bridge the gap, this paper for the first\ntime systematically investigated the relationship between adversarially robust\ngeneralization and architectural design. Inparticular, we comprehensively\nevaluated 20 most representative adversarially trained architectures on\nImageNette and CIFAR-10 datasets towards multiple `p-norm adversarial attacks.\nBased on the extensive experiments, we found that, under aligned settings,\nVision Transformers (e.g., PVT, CoAtNet) often yield better adversarially\nrobust generalization while CNNs tend to overfit on specific attacks and fail\nto generalize on multiple adversaries. To better understand the nature behind\nit, we conduct theoretical analysis via the lens of Rademacher complexity. We\nrevealed the fact that the higher weight sparsity contributes significantly\ntowards the better adversarially robust generalization of Transformers, which\ncan be often achieved by the specially-designed attention blocks. We hope our\npaper could help to better understand the mechanism for designing robust DNNs.\nOur model weights can be found at http://robust.art.\n","authors":["Aishan Liu","Shiyu Tang","Siyuan Liang","Ruihao Gong","Boxi Wu","Xianglong Liu","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2209.14105v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.15369v2","updated":"2023-03-10T10:22:17Z","published":"2022-06-30T15:43:51Z","title":"No Reason for No Supervision: Improved Generalization in Supervised\n  Models","summary":"  We consider the problem of training a deep neural network on a given\nclassification task, e.g., ImageNet-1K (IN1K), so that it excels at both the\ntraining task as well as at other (future) transfer tasks. These two seemingly\ncontradictory properties impose a trade-off between improving the model's\ngeneralization and maintaining its performance on the original task. Models\ntrained with self-supervised learning tend to generalize better than their\nsupervised counterparts for transfer learning; yet, they still lag behind\nsupervised models on IN1K. In this paper, we propose a supervised learning\nsetup that leverages the best of both worlds. We extensively analyze supervised\ntraining using multi-scale crops for data augmentation and an expendable\nprojector head, and reveal that the design of the projector allows us to\ncontrol the trade-off between performance on the training task and\ntransferability. We further replace the last layer of class weights with class\nprototypes computed on the fly using a memory bank and derive two models: t-ReX\nthat achieves a new state of the art for transfer learning and outperforms top\nmethods such as DINO and PAWS on IN1K, and t-ReX* that matches the highly\noptimized RSB-A1 model on IN1K while performing better on transfer tasks. Code\nand pretrained models: https://europe.naverlabs.com/t-rex\n","authors":["Mert Bulent Sariyildiz","Yannis Kalantidis","Karteek Alahari","Diane Larlus"],"pdf_url":"https://arxiv.org/pdf/2206.15369v2.pdf","comment":"Accepted to ICLR 2023 (spotlight)"},{"id":"http://arxiv.org/abs/2303.05828v1","updated":"2023-03-10T10:02:18Z","published":"2023-03-10T10:02:18Z","title":"Contrastive Language-Image Pretrained (CLIP) Models are Powerful\n  Out-of-Distribution Detectors","summary":"  We present a comprehensive experimental study on pretrained feature\nextractors for visual out-of-distribution (OOD) detection. We examine several\nsetups, based on the availability of labels or image captions and using\ndifferent combinations of in- and out-distributions. Intriguingly, we find that\n(i) contrastive language-image pretrained models achieve state-of-the-art\nunsupervised out-of-distribution performance using nearest neighbors feature\nsimilarity as the OOD detection score, (ii) supervised state-of-the-art OOD\ndetection performance can be obtained without in-distribution fine-tuning,\n(iii) even top-performing billion-scale vision transformers trained with\nnatural language supervision fail at detecting adversarially manipulated OOD\nimages. Finally, we argue whether new benchmarks for visual anomaly detection\nare needed based on our experiments. Using the largest publicly available\nvision transformer, we achieve state-of-the-art performance across all $18$\nreported OOD benchmarks, including an AUROC of 87.6\\% (9.2\\% gain,\nunsupervised) and 97.4\\% (1.2\\% gain, supervised) for the challenging task of\nCIFAR100 $\\rightarrow$ CIFAR10 OOD detection. The code will be open-sourced.\n","authors":["Felix Michels","Nikolas Adaloglou","Tim Kaiser","Markus Kollmann"],"pdf_url":"https://arxiv.org/pdf/2303.05828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1604.00772v2","updated":"2023-03-10T09:45:23Z","published":"2016-04-04T08:16:12Z","title":"The CMA Evolution Strategy: A Tutorial","summary":"  This tutorial introduces the CMA Evolution Strategy (ES), where CMA stands\nfor Covariance Matrix Adaptation. The CMA-ES is a stochastic, or randomized,\nmethod for real-parameter (continuous domain) optimization of non-linear,\nnon-convex functions. We try to motivate and derive the algorithm from\nintuitive concepts and from requirements of non-linear, non-convex search in\ncontinuous domain.\n","authors":["Nikolaus Hansen"],"pdf_url":"https://arxiv.org/pdf/1604.00772v2.pdf","comment":"ArXiv e-prints, arXiv:1604.00772, 2016, pp.1-39"},{"id":"http://arxiv.org/abs/2303.05812v1","updated":"2023-03-10T09:39:18Z","published":"2023-03-10T09:39:18Z","title":"Semi-supervised Adversarial Learning for Complementary Item\n  Recommendation","summary":"  Complementary item recommendations are a ubiquitous feature of modern\ne-commerce sites. Such recommendations are highly effective when they are based\non collaborative signals like co-purchase statistics. In certain online\nmarketplaces, however, e.g., on online auction sites, constantly new items are\nadded to the catalog. In such cases, complementary item recommendations are\noften based on item side-information due to a lack of interaction data. In this\nwork, we propose a novel approach that can leverage both item side-information\nand labeled complementary item pairs to generate effective complementary\nrecommendations for cold items, i.e., for items for which no co-purchase\nstatistics yet exist. Given that complementary items typically have to be of a\ndifferent category than the seed item, we technically maintain a latent space\nfor each item category. Simultaneously, we learn to project distributed item\nrepresentations into these category spaces to determine suitable\nrecommendations. The main learning process in our architecture utilizes labeled\npairs of complementary items. In addition, we adopt ideas from Cycle Generative\nAdversarial Networks (CycleGAN) to leverage available item information even in\ncase no labeled data exists for a given item and category. Experiments on three\ne-commerce datasets show that our method is highly effective.\n","authors":["Koby Bibas","Oren Sar Shalom","Dietmar Jannach"],"pdf_url":"https://arxiv.org/pdf/2303.05812v1.pdf","comment":"ACM Web Conference 2023"},{"id":"http://arxiv.org/abs/2205.13826v4","updated":"2023-03-10T09:38:22Z","published":"2022-05-27T08:38:20Z","title":"Multivariate Probabilistic Forecasting of Intraday Electricity Prices\n  using Normalizing Flows","summary":"  Electricity is traded on various markets with different time horizons and\nregulations. Short-term intraday trading becomes increasingly important due to\nthe higher penetration of renewables. In Germany, the intraday electricity\nprice typically fluctuates around the day-ahead price of the European Power\nEXchange (EPEX) spot markets in a distinct hourly pattern. This work proposes a\nprobabilistic modeling approach that models the intraday price difference to\nthe day-ahead contracts. The model captures the emerging hourly pattern by\nconsidering the four 15 min intervals in each day-ahead price interval as a\nfour-dimensional joint probability distribution. The resulting nontrivial,\nmultivariate price difference distribution is learned using a normalizing flow,\ni.e., a deep generative model that combines conditional multivariate density\nestimation and probabilistic regression. Furthermore, this work discusses the\ninfluence of different external impact factors based on literature insights and\nimpact analysis using explainable artificial intelligence (XAI). The\nnormalizing flow is compared to an informed selection of historical data and\nprobabilistic forecasts using a Gaussian copula and a Gaussian regression\nmodel. Among the different models, the normalizing flow identifies the trends\nwith the highest accuracy and has the narrowest prediction intervals. Both the\nXAI analysis and the empirical experiments highlight that the immediate history\nof the price difference realization and the increments of the day-ahead price\nhave the most substantial impact on the price difference.\n","authors":["Eike Cramer","Dirk Witthaut","Alexander Mitsos","Manuel Dahmen"],"pdf_url":"https://arxiv.org/pdf/2205.13826v4.pdf","comment":"manuscript (20 pages, 11 figures, 5 tables), supporting information\n  (8 pages, 5 figures, 4 tables)"},{"id":"http://arxiv.org/abs/2112.08954v3","updated":"2023-03-10T09:35:31Z","published":"2021-12-15T05:47:21Z","title":"Advancing Spiking Neural Networks towards Deep Residual Learning","summary":"  Despite the rapid progress of neuromorphic computing, inadequate capacity and\ninsufficient representation power of spiking neural networks (SNNs) severely\nrestrict their application scope in practice. Residual learning and shortcuts\nhave been evidenced as an important approach for training deep neural networks,\nbut rarely did previous work assess their applicability to the characteristics\nof spike-based communication and spatiotemporal dynamics. In this paper, we\nfirst identify that this negligence leads to impeded information flow and the\naccompanying degradation problem in previous residual SNNs. To address this\nissue, we propose a novel SNN-oriented residual architecture termed MS-ResNet,\nwhich establishes membrane-based shortcut pathways, and further prove that the\ngradient norm equality can be achieved in MS-ResNet by introducing block\ndynamical isometry theory, which ensures the network can be well-behaved in a\ndepth-insensitive way. Thus we are able to significantly extend the depth of\ndirectly trained SNNs, e.g., up to 482 layers on CIFAR-10 and 104 layers on\nImageNet, without observing any slight degradation problem. To validate the\neffectiveness of MS-ResNet, experiments on both frame-based and neuromorphic\ndatasets are conducted. MS-ResNet104 achieves a superior result of 76.02%\naccuracy on ImageNet, which is the highest to our best knowledge in the domain\nof directly trained SNNs. Great energy efficiency is also observed, with an\naverage of only one spike per neuron needed to classify an input sample. We\nbelieve our powerful and scalable models will provide a strong support for\nfurther exploration of SNNs.\n","authors":["Yifan Hu","Lei Deng","Yujie Wu","Man Yao","Guoqi Li"],"pdf_url":"https://arxiv.org/pdf/2112.08954v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05809v1","updated":"2023-03-10T09:31:44Z","published":"2023-03-10T09:31:44Z","title":"Distributionally Robust Optimization with Probabilistic Group","summary":"  Modern machine learning models may be susceptible to learning spurious\ncorrelations that hold on average but not for the atypical group of samples. To\naddress the problem, previous approaches minimize the empirical worst-group\nrisk. Despite the promise, they often assume that each sample belongs to one\nand only one group, which does not allow expressing the uncertainty in group\nlabeling. In this paper, we propose a novel framework PG-DRO, which explores\nthe idea of probabilistic group membership for distributionally robust\noptimization. Key to our framework, we consider soft group membership instead\nof hard group annotations. The group probabilities can be flexibly generated\nusing either supervised learning or zero-shot approaches. Our framework\naccommodates samples with group membership ambiguity, offering stronger\nflexibility and generality than the prior art. We comprehensively evaluate\nPG-DRO on both image classification and natural language processing benchmarks,\nestablishing superior performance\n","authors":["Soumya Suvra Ghosal","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2303.05809v1.pdf","comment":"Published at AAAI 2023"},{"id":"http://arxiv.org/abs/2210.07723v2","updated":"2023-03-10T09:21:52Z","published":"2022-10-14T11:41:18Z","title":"Privacy-Preserving and Lossless Distributed Estimation of\n  High-Dimensional Generalized Additive Mixed Models","summary":"  Various privacy-preserving frameworks that respect the individual's privacy\nin the analysis of data have been developed in recent years. However, available\nmodel classes such as simple statistics or generalized linear models lack the\nflexibility required for a good approximation of the underlying data-generating\nprocess in practice. In this paper, we propose an algorithm for a distributed,\nprivacy-preserving, and lossless estimation of generalized additive mixed\nmodels (GAMM) using component-wise gradient boosting (CWB). Making use of CWB\nallows us to reframe the GAMM estimation as a distributed fitting of base\nlearners using the $L_2$-loss. In order to account for the heterogeneity of\ndifferent data location sites, we propose a distributed version of a row-wise\ntensor product that allows the computation of site-specific (smooth) effects.\nOur adaption of CWB preserves all the important properties of the original\nalgorithm, such as an unbiased feature selection and the feasibility to fit\nmodels in high-dimensional feature spaces, and yields equivalent model\nestimates as CWB on pooled data. Next to a derivation of the equivalence of\nboth algorithms, we also showcase the efficacy of our algorithm on a\ndistributed heart disease data set and compare it with state-of-the-art\nmethods.\n","authors":["Daniel Schalk","Bernd Bischl","David Rügamer"],"pdf_url":"https://arxiv.org/pdf/2210.07723v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05798v1","updated":"2023-03-10T09:08:46Z","published":"2023-03-10T09:08:46Z","title":"Sliced-Wasserstein on Symmetric Positive Definite Matrices for M/EEG\n  Signals","summary":"  When dealing with electro or magnetoencephalography records, many supervised\nprediction tasks are solved by working with covariance matrices to summarize\nthe signals. Learning with these matrices requires using Riemanian geometry to\naccount for their structure. In this paper, we propose a new method to deal\nwith distributions of covariance matrices and demonstrate its computational\nefficiency on M/EEG multivariate time series. More specifically, we define a\nSliced-Wasserstein distance between measures of symmetric positive definite\nmatrices that comes with strong theoretical guarantees. Then, we take advantage\nof its properties and kernel methods to apply this distance to brain-age\nprediction from MEG data and compare it to state-of-the-art algorithms based on\nRiemannian geometry. Finally, we show that it is an efficient surrogate to the\nWasserstein distance in domain adaptation for Brain Computer Interface\napplications.\n","authors":["Clément Bonet","Benoît Malézieux","Alain Rakotomamonjy","Lucas Drumetz","Thomas Moreau","Matthieu Kowalski","Nicolas Courty"],"pdf_url":"https://arxiv.org/pdf/2303.05798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05796v1","updated":"2023-03-10T09:00:52Z","published":"2023-03-10T09:00:52Z","title":"Training, Architecture, and Prior for Deterministic Uncertainty Methods","summary":"  Accurate and efficient uncertainty estimation is crucial to build reliable\nMachine Learning (ML) models capable to provide calibrated uncertainty\nestimates, generalize and detect Out-Of-Distribution (OOD) datasets. To this\nend, Deterministic Uncertainty Methods (DUMs) is a promising model family\ncapable to perform uncertainty estimation in a single forward pass. This work\ninvestigates important design choices in DUMs: (1) we show that training\nschemes decoupling the core architecture and the uncertainty head schemes can\nsignificantly improve uncertainty performances. (2) we demonstrate that the\ncore architecture expressiveness is crucial for uncertainty performance and\nthat additional architecture constraints to avoid feature collapse can\ndeteriorate the trade-off between OOD generalization and detection. (3)\nContrary to other Bayesian models, we show that the prior defined by DUMs do\nnot have a strong effect on the final performances.\n","authors":["Bertrand Charpentier","Chenxiang Zhang","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2303.05796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09634v3","updated":"2023-03-10T08:51:10Z","published":"2022-11-17T16:27:15Z","title":"On the Sample Complexity of Two-Layer Networks: Lipschitz vs.\n  Element-Wise Lipschitz Activation","summary":"  We investigate the sample complexity of bounded two-layer neural networks\nusing different activation functions.\n  In particular, we consider the class\n  $$ \\mathcal{H} = \\left\\{\\textbf{x}\\mapsto \\langle \\textbf{v}, \\sigma \\circ\nW\\textbf{b} + \\textbf{b} \\rangle : \\textbf{b}\\in\\mathbb{R}^d, W \\in\n\\mathbb{R}^{\\mathcal{T}\\times d}, \\textbf{v} \\in\n\\mathbb{R}^{\\mathcal{T}}\\right\\} $$\n  where the spectral norm of $W$ and $\\textbf{v}$ is bounded by $O(1)$, the\nFrobenius norm of $W$ is bounded from its initialization by $R > 0$, and\n$\\sigma$ is a Lipschitz activation function.\n  We prove that if $\\sigma$ is element-wise, then the sample complexity of\n$\\mathcal{H}$ has only logarithmic dependency in width and that this complexity\nis tight, up to logarithmic factors.\n  We further show that the element-wise property of $\\sigma$ is essential for a\nlogarithmic dependency bound in width, in the sense that there exist\nnon-element-wise activation functions whose sample complexity is linear in\nwidth, for widths that can be up to exponential in the input dimension.\n  For the upper bound, we use the recent approach for norm-based bounds named\nApproximate Description Length (ADL) by arXiv:1910.05697.\n  We further develop new techniques and tools for this approach that will\nhopefully inspire future works.\n","authors":["Amit Daniely","Elad Granot"],"pdf_url":"https://arxiv.org/pdf/2211.09634v3.pdf","comment":"9 pages with additional 15 pages of supplementary"},{"id":"http://arxiv.org/abs/2303.05788v1","updated":"2023-03-10T08:47:22Z","published":"2023-03-10T08:47:22Z","title":"Deep Generative Fixed-filter Active Noise Control","summary":"  Due to the slow convergence and poor tracking ability, conventional LMS-based\nadaptive algorithms are less capable of handling dynamic noises. Selective\nfixed-filter active noise control (SFANC) can significantly reduce response\ntime by selecting appropriate pre-trained control filters for different noises.\nNonetheless, the limited number of pre-trained control filters may affect noise\nreduction performance, especially when the incoming noise differs much from the\ninitial noises during pre-training. Therefore, a generative fixed-filter active\nnoise control (GFANC) method is proposed in this paper to overcome the\nlimitation. Based on deep learning and a perfect-reconstruction filter bank,\nthe GFANC method only requires a few prior data (one pre-trained broadband\ncontrol filter) to automatically generate suitable control filters for various\nnoises. The efficacy of the GFANC method is demonstrated by numerical\nsimulations on real-recorded noises.\n","authors":["Zhengding Luo","Dongyuan Shi","Xiaoyi Shen","Junwei Ji","Woon-Seng Gan"],"pdf_url":"https://arxiv.org/pdf/2303.05788v1.pdf","comment":"Accepted by ICASSP 2023. Code will be available after publication"},{"id":"http://arxiv.org/abs/2201.06799v2","updated":"2023-03-10T08:45:40Z","published":"2022-01-18T07:54:55Z","title":"Pistol: Pupil Invisible Supportive Tool to extract Pupil, Iris, Eye\n  Opening, Eye Movements, Pupil and Iris Gaze Vector, and 2D as well as 3D Gaze","summary":"  This paper describes a feature extraction and gaze estimation software, named\n\\textit{Pistol} that can be used with Pupil Invisible projects and other eye\ntrackers in the future. In offline mode, our software extracts multiple\nfeatures from the eye including, the pupil and iris ellipse, eye aperture,\npupil vector, iris vector, eye movement types from pupil and iris velocities,\nmarker detection, marker distance, 2D gaze estimation for the pupil center,\niris center, pupil vector, and iris vector using Levenberg Marquart fitting and\nneural networks. The gaze signal is computed in 2D for each eye and each\nfeature separately and for both eyes in 3D also for each feature separately. We\nhope this software helps other researchers to extract state-of-the-art features\nfor their research out of their recordings.\n  Link:\nhttps://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FPISTOL&mode=list\n","authors":["Wolfgang Fuhl","Daniel Weber","Shahram Eivazi"],"pdf_url":"https://arxiv.org/pdf/2201.06799v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05785v1","updated":"2023-03-10T08:38:34Z","published":"2023-03-10T08:38:34Z","title":"Scaling Up 3D Kernels with Bayesian Frequency Re-parameterization for\n  Medical Image Segmentation","summary":"  With the inspiration of vision transformers, the concept of depth-wise\nconvolution revisits to provide a large Effective Receptive Field (ERF) using\nLarge Kernel (LK) sizes for medical image segmentation. However, the\nsegmentation performance might be saturated and even degraded as the kernel\nsizes scaled up (e.g., $21\\times 21\\times 21$) in a Convolutional Neural\nNetwork (CNN). We hypothesize that convolution with LK sizes is limited to\nmaintain an optimal convergence for locality learning. While Structural\nRe-parameterization (SR) enhances the local convergence with small kernels in\nparallel, optimal small kernel branches may hinder the computational efficiency\nfor training. In this work, we propose RepUX-Net, a pure CNN architecture with\na simple large kernel block design, which competes favorably with current\nnetwork state-of-the-art (SOTA) (e.g., 3D UX-Net, SwinUNETR) using 6\nchallenging public datasets. We derive an equivalency between kernel\nre-parameterization and the branch-wise variation in kernel convergence.\nInspired by the spatial frequency in the human visual system, we extend to vary\nthe kernel convergence into element-wise setting and model the spatial\nfrequency as a Bayesian prior to re-parameterize convolutional weights during\ntraining. Specifically, a reciprocal function is leveraged to estimate a\nfrequency-weighted value, which rescales the corresponding kernel element for\nstochastic gradient descent. From the experimental results, RepUX-Net\nconsistently outperforms 3D SOTA benchmarks with internal validation (FLARE:\n0.929 to 0.944), external validation (MSD: 0.901 to 0.932, KiTS: 0.815 to\n0.847, LiTS: 0.933 to 0.949, TCIA: 0.736 to 0.779) and transfer learning (AMOS:\n0.880 to 0.911) scenarios in Dice Score.\n","authors":["Ho Hin Lee","Quan Liu","Shunxing Bao","Qi Yang","Xin Yu","Leon Y. Cai","Thomas Li","Yuankai Huo","Xenofon Koutsoukos","Bennett A. Landman"],"pdf_url":"https://arxiv.org/pdf/2303.05785v1.pdf","comment":"Both codes and pretrained models are available at:\n  https://github.com/MASILab/RepUX-Net"},{"id":"http://arxiv.org/abs/2207.05164v2","updated":"2023-03-10T08:36:06Z","published":"2022-07-11T19:58:56Z","title":"Machine Learning Security in Industry: A Quantitative Survey","summary":"  Despite the large body of academic work on machine learning security, little\nis known about the occurrence of attacks on machine learning systems in the\nwild. In this paper, we report on a quantitative study with 139 industrial\npractitioners. We analyze attack occurrence and concern and evaluate\nstatistical hypotheses on factors influencing threat perception and exposure.\nOur results shed light on real-world attacks on deployed machine learning. On\nthe organizational level, while we find no predictors for threat exposure in\nour sample, the amount of implement defenses depends on exposure to threats or\nexpected likelihood to become a target. We also provide a detailed analysis of\npractitioners' replies on the relevance of individual machine learning attacks,\nunveiling complex concerns like unreliable decision making, business\ninformation leakage, and bias introduction into models. Finally, we find that\non the individual level, prior knowledge about machine learning security\ninfluences threat perception. Our work paves the way for more research about\nadversarial machine learning in practice, but yields also insights for\nregulation and auditing.\n","authors":["Kathrin Grosse","Lukas Bieringer","Tarek Richard Besold","Battista Biggio","Katharina Krombholz"],"pdf_url":"https://arxiv.org/pdf/2207.05164v2.pdf","comment":"Accepted at TIFS, version with more detailed appendix containing more\n  detailed statistical results. 17 pages, 6 tables and 4 figures"},{"id":"http://arxiv.org/abs/2303.05777v1","updated":"2023-03-10T08:27:14Z","published":"2023-03-10T08:27:14Z","title":"Self-Supervised CSF Inpainting with Synthetic Atrophy for Improved\n  Accuracy Validation of Cortical Surface Analyses","summary":"  Accuracy validation of cortical thickness measurement is a difficult problem\ndue to the lack of ground truth data. To address this need, many methods have\nbeen developed to synthetically induce gray matter (GM) atrophy in an MRI via\ndeformable registration, creating a set of images with known changes in\ncortical thickness. However, these methods often cause blurring in atrophied\nregions, and cannot simulate realistic atrophy within deep sulci where\ncerebrospinal fluid (CSF) is obscured or absent. In this paper, we present a\nsolution using a self-supervised inpainting model to generate CSF in these\nregions and create images with more plausible GM/CSF boundaries. Specifically,\nwe introduce a novel, 3D GAN model that incorporates patch-based dropout\ntraining, edge map priors, and sinusoidal positional encoding, all of which are\nestablished methods previously limited to 2D domains. We show that our\nframework significantly improves the quality of the resulting synthetic images\nand is adaptable to unseen data with fine-tuning. We also demonstrate that our\nresulting dataset can be employed for accuracy validation of cortical\nsegmentation and thickness measurement.\n","authors":["Jiacheng Wang","Kathleen E. Larson","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2303.05777v1.pdf","comment":"Accepted at Medical Imaging with Deep Learning (MIDL) 2023"},{"id":"http://arxiv.org/abs/2112.05958v4","updated":"2023-03-10T08:24:55Z","published":"2021-12-11T11:44:09Z","title":"You Only Need End-to-End Training for Long-Tailed Recognition","summary":"  The generalization gap on the long-tailed data sets is largely owing to most\ncategories only occupying a few training samples. Decoupled training achieves\nbetter performance by training backbone and classifier separately. What causes\nthe poorer performance of end-to-end model training (e.g., logits margin-based\nmethods)? In this work, we identify a key factor that affects the learning of\nthe classifier: the channel-correlated features with low entropy before\ninputting into the classifier. From the perspective of information theory, we\nanalyze why cross-entropy loss tends to produce highly correlated features on\nthe imbalanced data. In addition, we theoretically analyze and prove its\nimpacts on the gradients of classifier weights, the condition number of\nHessian, and logits margin-based approach. Therefore, we firstly propose to use\nChannel Whitening to decorrelate (\"scatter\") the classifier's inputs for\ndecoupling the weight update and reshaping the skewed decision boundary, which\nachieves satisfactory results combined with logits margin-based method.\nHowever, when the number of minor classes are large, batch imbalance and more\nparticipation in training cause over-fitting of the major classes. We also\npropose two novel modules, Block-based Relatively Balanced Batch Sampler (B3RS)\nand Batch Embedded Training (BET) to solve the above problems, which makes the\nend-to-end training achieve even better performance than decoupled training.\nExperimental results on the long-tailed classification benchmarks, CIFAR-LT and\nImageNet-LT, demonstrate the effectiveness of our method.\n","authors":["Zhiwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2112.05958v4.pdf","comment":"This is a draft"},{"id":"http://arxiv.org/abs/2303.05774v1","updated":"2023-03-10T08:19:35Z","published":"2023-03-10T08:19:35Z","title":"NFL Career Success as Predicted by NFL Scouting Combine","summary":"  The National Football League (NFL) Scouting Combine serves as a tool to\nevaluate the skills of prospective players and assess their readiness to play\nin the NFL. The development of machine learning brings new opportunities in\nassessing the utility of the Scouting Combine. Using machine and statistical\nlearning, it may be possible to predict future success of prospective athletes,\nas well as predict which Scouting Combine tests are the most important. Results\nfrom statistical learning research have been contradicting whether the Scouting\ncombine is a useful metric for player success. In this study, we investigate if\nmachine learning can be used to determine matriculation and future success in\nthe NFL. Using Scouting Combine data, we evaluate six different algorithms'\nability to predict whether a potential draft pick will play a single NFL snap\n(matriculation). If a player is drafted, we predict how many snaps they go on\nto play (success). We are able to predict matriculation with 83% accuracy;\nhowever, we are unable to predict later success. Our best performing algorithm\nreturns large error and low explained variance (RMSE=1,210 snaps;\n${R}^2$=0.17). These findings indicate that while the Scouting Combine can\npredict NFL matriculation, it may not be a reliable predictor of long-term\nplayer success.\n","authors":["Brian Szekely","Christian Sinnott","Savannah Halow","Gregory Ryan"],"pdf_url":"https://arxiv.org/pdf/2303.05774v1.pdf","comment":"16 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2303.02095v2","updated":"2023-03-10T08:04:01Z","published":"2023-03-03T17:24:39Z","title":"Data-Efficient Training of CNNs and Transformers with Coresets: A\n  Stability Perspective","summary":"  Coreset selection is among the most effective ways to reduce the training\ntime of CNNs, however, only limited is known on how the resultant models will\nbehave under variations of the coreset size, and choice of datasets and models.\nMoreover, given the recent paradigm shift towards transformer-based models, it\nis still an open question how coreset selection would impact their performance.\nThere are several similar intriguing questions that need to be answered for a\nwide acceptance of coreset selection methods, and this paper attempts to answer\nsome of these. We present a systematic benchmarking setup and perform a\nrigorous comparison of different coreset selection methods on CNNs and\ntransformers. Our investigation reveals that under certain circumstances,\nrandom selection of subsets is more robust and stable when compared with the\nSOTA selection methods. We demonstrate that the conventional concept of uniform\nsubset sampling across the various classes of the data is not the appropriate\nchoice. Rather samples should be adaptively chosen based on the complexity of\nthe data distribution for each class. Transformers are generally pretrained on\nlarge datasets, and we show that for certain target datasets, it helps to keep\ntheir performance stable at even very small coreset sizes. We further show that\nwhen no pretraining is done or when the pretrained transformer models are used\nwith non-natural images (e.g. medical data), CNNs tend to generalize better\nthan transformers at even very small coreset sizes. Lastly, we demonstrate that\nin the absence of the right pretraining, CNNs are better at learning the\nsemantic coherence between spatially distant objects within an image, and these\ntend to outperform transformers at almost all choices of the coreset size.\n","authors":["Animesh Gupta","Irtiza Hasan","Dilip K. Prasad","Deepak K. Gupta"],"pdf_url":"https://arxiv.org/pdf/2303.02095v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05762v1","updated":"2023-03-10T08:01:23Z","published":"2023-03-10T08:01:23Z","title":"TrojDiff: Trojan Attacks on Diffusion Models with Diverse Targets","summary":"  Diffusion models have achieved great success in a range of tasks, such as\nimage synthesis and molecule design. As such successes hinge on large-scale\ntraining data collected from diverse sources, the trustworthiness of these\ncollected data is hard to control or audit. In this work, we aim to explore the\nvulnerabilities of diffusion models under potential training data manipulations\nand try to answer: How hard is it to perform Trojan attacks on well-trained\ndiffusion models? What are the adversarial targets that such Trojan attacks can\nachieve? To answer these questions, we propose an effective Trojan attack\nagainst diffusion models, TrojDiff, which optimizes the Trojan diffusion and\ngenerative processes during training. In particular, we design novel\ntransitions during the Trojan diffusion process to diffuse adversarial targets\ninto a biased Gaussian distribution and propose a new parameterization of the\nTrojan generative process that leads to an effective training objective for the\nattack. In addition, we consider three types of adversarial targets: the\nTrojaned diffusion models will always output instances belonging to a certain\nclass from the in-domain distribution (In-D2D attack), out-of-domain\ndistribution (Out-D2D-attack), and one specific instance (D2I attack). We\nevaluate TrojDiff on CIFAR-10 and CelebA datasets against both DDPM and DDIM\ndiffusion models. We show that TrojDiff always achieves high attack performance\nunder different adversarial targets using different types of triggers, while\nthe performance in benign environments is preserved. The code is available at\nhttps://github.com/chenweixin107/TrojDiff.\n","authors":["Weixin Chen","Dawn Song","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2303.05762v1.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2303.05754v1","updated":"2023-03-10T07:42:49Z","published":"2023-03-10T07:42:49Z","title":"Fast Diffusion Sampler for Inverse Problems by Geometric Decomposition","summary":"  Diffusion models have shown exceptional performance in solving inverse\nproblems. However, one major limitation is the slow inference time. While\nfaster diffusion samplers have been developed for unconditional sampling, there\nhas been limited research on conditional sampling in the context of inverse\nproblems. In this study, we propose a novel and efficient diffusion sampling\nstrategy that employs the geometric decomposition of diffusion sampling.\nSpecifically, we discover that the samples generated from diffusion models can\nbe decomposed into two orthogonal components: a ``denoised\" component obtained\nby projecting the sample onto the clean data manifold, and a ``noise\" component\nthat induces a transition to the next lower-level noisy manifold with the\naddition of stochastic noise. Furthermore, we prove that, under some conditions\non the clean data manifold, the conjugate gradient update for imposing\nconditioning from the denoised signal belongs to the clean manifold, resulting\nin a much faster and more accurate diffusion sampling. Our method is applicable\nregardless of the parameterization and setting (i.e., VE, VP). Notably, we\nachieve state-of-the-art reconstruction quality on challenging real-world\nmedical inverse imaging problems, including multi-coil MRI reconstruction and\n3D CT reconstruction. Moreover, our proposed method achieves more than 80 times\nfaster inference time than the previous state-of-the-art method.\n","authors":["Hyungjin Chung","Suhyeon Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2303.05754v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2303.04150v2","updated":"2023-03-10T07:21:10Z","published":"2023-03-07T01:38:42Z","title":"Evolutionary Reinforcement Learning: A Survey","summary":"  Reinforcement learning (RL) is a machine learning approach that trains agents\nto maximize cumulative rewards through interactions with environments. The\nintegration of RL with deep learning has recently resulted in impressive\nachievements in a wide range of challenging tasks, including board games,\narcade games, and robot control. Despite these successes, there remain several\ncrucial challenges, including brittle convergence properties caused by\nsensitive hyperparameters, difficulties in temporal credit assignment with long\ntime horizons and sparse rewards, a lack of diverse exploration, especially in\ncontinuous search space scenarios, difficulties in credit assignment in\nmulti-agent reinforcement learning, and conflicting objectives for rewards.\nEvolutionary computation (EC), which maintains a population of learning agents,\nhas demonstrated promising performance in addressing these limitations. This\narticle presents a comprehensive survey of state-of-the-art methods for\nintegrating EC into RL, referred to as evolutionary reinforcement learning\n(EvoRL). We categorize EvoRL methods according to key research fields in RL,\nincluding hyperparameter optimization, policy search, exploration, reward\nshaping, meta-RL, and multi-objective RL. We then discuss future research\ndirections in terms of efficient methods, benchmarks, and scalable platforms.\nThis survey serves as a resource for researchers and practitioners interested\nin the field of EvoRL, highlighting the important challenges and opportunities\nfor future research. With the help of this survey, researchers and\npractitioners can develop more efficient methods and tailored benchmarks for\nEvoRL, further advancing this promising cross-disciplinary research field.\n","authors":["Hui Bai","Ran Cheng","Yaochu Jin"],"pdf_url":"https://arxiv.org/pdf/2303.04150v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.07227v2","updated":"2023-03-10T07:12:32Z","published":"2022-08-15T14:32:10Z","title":"DM-NeRF: 3D Scene Geometry Decomposition and Manipulation from 2D Images","summary":"  In this paper, we study the problem of 3D scene geometry decomposition and\nmanipulation from 2D views. By leveraging the recent implicit neural\nrepresentation techniques, particularly the appealing neural radiance fields,\nwe introduce an object field component to learn unique codes for all individual\nobjects in 3D space only from 2D supervision. The key to this component is a\nseries of carefully designed loss functions to enable every 3D point,\nespecially in non-occupied space, to be effectively optimized even without 3D\nlabels. In addition, we introduce an inverse query algorithm to freely\nmanipulate any specified 3D object shape in the learned scene representation.\nNotably, our manipulation algorithm can explicitly tackle key issues such as\nobject collisions and visual occlusions. Our method, called DM-NeRF, is among\nthe first to simultaneously reconstruct, decompose, manipulate and render\ncomplex 3D scenes in a single pipeline. Extensive experiments on three datasets\nclearly show that our method can accurately decompose all 3D objects from 2D\nviews, allowing any interested object to be freely manipulated in 3D space such\nas translation, rotation, size adjustment, and deformation.\n","authors":["Bing Wang","Lu Chen","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2208.07227v2.pdf","comment":"ICLR 2023. Our data and code are available at:\n  https://github.com/vLAR-group/DM-NeRF"},{"id":"http://arxiv.org/abs/2303.05747v1","updated":"2023-03-10T07:11:48Z","published":"2023-03-10T07:11:48Z","title":"Phase Aberration Correction without Reference Data: An Adaptive Mixed\n  Loss Deep Learning Approach","summary":"  Phase aberration is one of the primary sources of image quality degradation\nin ultrasound, which is induced by spatial variations in sound speed across the\nheterogeneous medium. This effect disrupts transmitted waves and prevents\ncoherent summation of echo signals, resulting in suboptimal image quality. In\nreal experiments, obtaining non-aberrated ground truths can be extremely\nchallenging, if not infeasible. It hinders the performance of deep\nlearning-based phase aberration correction techniques due to sole reliance on\nsimulated data and the presence of domain shift between simulated and\nexperimental data. Here, for the first time, we propose a deep learning-based\nmethod that does not require reference data to compensate for the phase\naberration effect. We train a network wherein both input and target output are\nrandomly aberrated radio frequency (RF) data. Moreover, we demonstrate that a\nconventional loss function such as mean square error is inadequate for training\nthe network to achieve optimal performance. Instead, we propose an adaptive\nmixed loss function that employs both B-mode and RF data, resulting in more\nefficient convergence and enhanced performance. Source code is available at\n\\url{http://code.sonography.ai}.\n","authors":["Mostafa Sharifzadeh","Habib Benali","Hassan Rivaz"],"pdf_url":"https://arxiv.org/pdf/2303.05747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.08185v2","updated":"2023-03-10T06:52:39Z","published":"2022-10-15T04:07:39Z","title":"GFlowCausal: Generative Flow Networks for Causal Discovery","summary":"  Causal discovery aims to uncover causal structure among a set of variables.\nScore-based approaches mainly focus on searching for the best Directed Acyclic\nGraph (DAG) based on a predefined score function. However, most of them are not\napplicable on a large scale due to the limited searchability. Inspired by the\nactive learning in generative flow networks, we propose a novel approach to\nlearning a DAG from observational data called GFlowCausal. It converts the\ngraph search problem to a generation problem, in which direct edges are added\ngradually. GFlowCausal aims to learn the best policy to generate high-reward\nDAGs by sequential actions with probabilities proportional to predefined\nrewards. We propose a plug-and-play module based on transitive closure to\nensure efficient sampling. Theoretical analysis shows that this module could\nguarantee acyclicity properties effectively and the consistency between final\nstates and fully-connected graphs. We conduct extensive experiments on both\nsynthetic and real datasets, and results show the proposed approach to be\nsuperior and also performs well in a large-scale setting.\n","authors":["Wenqian Li","Yinchuan Li","Shengyu Zhu","Yunfeng Shao","Jianye Hao","Yan Pang"],"pdf_url":"https://arxiv.org/pdf/2210.08185v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05739v1","updated":"2023-03-10T06:49:31Z","published":"2023-03-10T06:49:31Z","title":"Boosting Semi-Supervised Few-Shot Object Detection with SoftER Teacher","summary":"  Few-shot object detection is an emerging problem aimed at detecting novel\nconcepts from few exemplars. Existing approaches to few-shot detection assume\nabundant base labels to adapt to novel objects. This paper explores the task of\nsemi-supervised few-shot detection by considering a realistic scenario which\nlacks abundant labels for both base and novel objects. Motivated by this unique\nproblem, we introduce SoftER Teacher, a robust detector combining the\nadvantages of pseudo-labeling with representation learning on region proposals.\nSoftER Teacher harnesses unlabeled data to jointly optimize for semi-supervised\nfew-shot detection without explicitly relying on abundant base labels.\nExtensive experiments show that SoftER Teacher matches the novel class\nperformance of a strong supervised detector using only 10% of base labels. Our\nwork also sheds insight into a previously unknown relationship between\nsemi-supervised and few-shot detection to suggest that a stronger\nsemi-supervised detector leads to a more label-efficient few-shot detector.\nCode and models are available at\nhttps://github.com/lexisnexis-risk-open-source/ledetection\n","authors":["Phi Vu Tran"],"pdf_url":"https://arxiv.org/pdf/2303.05739v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2303.05737v1","updated":"2023-03-10T06:46:23Z","published":"2023-03-10T06:46:23Z","title":"Clinical BERTScore: An Improved Measure of Automatic Speech Recognition\n  Performance in Clinical Settings","summary":"  Automatic Speech Recognition (ASR) in medical contexts has the potential to\nsave time, cut costs, increase report accuracy, and reduce physician burnout.\nHowever, the healthcare industry has been slower to adopt this technology, in\npart due to the importance of avoiding medically-relevant transcription\nmistakes. In this work, we present the Clinical BERTScore (CBERTScore), an ASR\nmetric that penalizes clinically-relevant mistakes more than others. We\ndemonstrate that this metric more closely aligns with clinician preferences on\nmedical sentences as compared to other metrics (WER, BLUE, METEOR, etc),\nsometimes by wide margins. We collect a benchmark of 13 clinician preferences\non 149 realistic medical sentences called the Clinician Transcript Preference\nbenchmark (CTP), demonstrate that CBERTScore more closely matches what\nclinicians prefer, and release the benchmark for the community to further\ndevelop clinically-aware ASR metrics.\n","authors":["Joel Shor","Ruyue Agnes Bi","Subhashini Venugopalan","Steven Ibara","Roman Goldenberg","Ehud Rivlen"],"pdf_url":"https://arxiv.org/pdf/2303.05737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05735v1","updated":"2023-03-10T06:44:49Z","published":"2023-03-10T06:44:49Z","title":"Hardware Acceleration of Neural Graphics","summary":"  Rendering and inverse-rendering algorithms that drive conventional computer\ngraphics have recently been superseded by neural representations (NR). NRs have\nrecently been used to learn the geometric and the material properties of the\nscenes and use the information to synthesize photorealistic imagery, thereby\npromising a replacement for traditional rendering algorithms with scalable\nquality and predictable performance. In this work we ask the question: Does\nneural graphics (NG) need hardware support? We studied representative NG\napplications showing that, if we want to render 4k res. at 60FPS there is a gap\nof 1.5X-55X in the desired performance on current GPUs. For AR/VR applications,\nthere is an even larger gap of 2-4 OOM between the desired performance and the\nrequired system power. We identify that the input encoding and the MLP kernels\nare the performance bottlenecks, consuming 72%,60% and 59% of application time\nfor multi res. hashgrid, multi res. densegrid and low res. densegrid encodings,\nrespectively. We propose a NG processing cluster, a scalable and flexible\nhardware architecture that directly accelerates the input encoding and MLP\nkernels through dedicated engines and supports a wide range of NG applications.\nWe also accelerate the rest of the kernels by fusing them together in Vulkan,\nwhich leads to 9.94X kernel-level performance improvement compared to un-fused\nimplementation of the pre-processing and the post-processing kernels. Our\nresults show that, NGPC gives up to 58X end-to-end application-level\nperformance improvement, for multi res. hashgrid encoding on average across the\nfour NG applications, the performance benefits are 12X,20X,33X and 39X for the\nscaling factor of 8,16,32 and 64, respectively. Our results show that with\nmulti res. hashgrid encoding, NGPC enables the rendering of 4k res. at 30FPS\nfor NeRF and 8k res. at 120FPS for all our other NG applications.\n","authors":["Muhammad Husnain Mubarik","Ramakrishna Kanungo","Tobias Zirr","Rakesh Kumar"],"pdf_url":"https://arxiv.org/pdf/2303.05735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14900v2","updated":"2023-03-10T06:41:49Z","published":"2022-09-29T16:05:28Z","title":"Joint Optimization of Energy Consumption and Completion Time in\n  Federated Learning","summary":"  Federated Learning (FL) is an intriguing distributed machine learning\napproach due to its privacy-preserving characteristics. To balance the\ntrade-off between energy and execution latency, and thus accommodate different\ndemands and application scenarios, we formulate an optimization problem to\nminimize a weighted sum of total energy consumption and completion time through\ntwo weight parameters. The optimization variables include bandwidth,\ntransmission power and CPU frequency of each device in the FL system, where all\ndevices are linked to a base station and train a global model collaboratively.\nThrough decomposing the non-convex optimization problem into two subproblems,\nwe devise a resource allocation algorithm to determine the bandwidth\nallocation, transmission power, and CPU frequency for each participating\ndevice. We further present the convergence analysis and computational\ncomplexity of the proposed algorithm. Numerical results show that our proposed\nalgorithm not only has better performance at different weight parameters (i.e.,\ndifferent demands) but also outperforms the state of the art.\n","authors":["Xinyu Zhou","Jun Zhao","Huimei Han","Claude Guet"],"pdf_url":"https://arxiv.org/pdf/2209.14900v2.pdf","comment":"This paper appears in the Proceedings of IEEE International\n  Conference on Distributed Computing Systems (ICDCS) 2022. Please feel free to\n  contact us for questions or remarks"},{"id":"http://arxiv.org/abs/2303.05733v1","updated":"2023-03-10T06:33:38Z","published":"2023-03-10T06:33:38Z","title":"Provably Efficient Model-Free Algorithms for Non-stationary CMDPs","summary":"  We study model-free reinforcement learning (RL) algorithms in episodic\nnon-stationary constrained Markov Decision Processes (CMDPs), in which an agent\naims to maximize the expected cumulative reward subject to a cumulative\nconstraint on the expected utility (cost). In the non-stationary environment,\nreward, utility functions, and transition kernels can vary arbitrarily over\ntime as long as the cumulative variations do not exceed certain variation\nbudgets. We propose the first model-free, simulator-free RL algorithms with\nsublinear regret and zero constraint violation for non-stationary CMDPs in both\ntabular and linear function approximation settings with provable performance\nguarantees. Our results on regret bound and constraint violation for the\ntabular case match the corresponding best results for stationary CMDPs when the\ntotal budget is known. Additionally, we present a general framework for\naddressing the well-known challenges associated with analyzing non-stationary\nCMDPs, without requiring prior knowledge of the variation budget. We apply the\napproach for both tabular and linear approximation settings.\n","authors":["Honghao Wei","Arnob Ghosh","Ness Shroff","Lei Ying","Xingyu Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.05733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05731v1","updated":"2023-03-10T06:31:30Z","published":"2023-03-10T06:31:30Z","title":"Upper Bound of Real Log Canonical Threshold of Tensor Decomposition and\n  its Application to Bayesian Inference","summary":"  Tensor decomposition is now being used for data analysis, information\ncompression, and knowledge recovery. However, the mathematical property of\ntensor decomposition is not yet fully clarified because it is one of singular\nlearning machines. In this paper, we give the upper bound of its real log\ncanonical threshold (RLCT) of the tensor decomposition by using an algebraic\ngeometrical method and derive its Bayesian generalization error theoretically.\nWe also give considerations about its mathematical property through numerical\nexperiments.\n","authors":["Naoki Yoshida","Sumio Watanabe"],"pdf_url":"https://arxiv.org/pdf/2303.05731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05729v1","updated":"2023-03-10T06:22:13Z","published":"2023-03-10T06:22:13Z","title":"Explaining Model Confidence Using Counterfactuals","summary":"  Displaying confidence scores in human-AI interaction has been shown to help\nbuild trust between humans and AI systems. However, most existing research uses\nonly the confidence score as a form of communication. As confidence scores are\njust another model output, users may want to understand why the algorithm is\nconfident to determine whether to accept the confidence score. In this paper,\nwe show that counterfactual explanations of confidence scores help study\nparticipants to better understand and better trust a machine learning model's\nprediction. We present two methods for understanding model confidence using\ncounterfactual explanation: (1) based on counterfactual examples; and (2) based\non visualisation of the counterfactual space. Both increase understanding and\ntrust for study participants over a baseline of no explanation, but qualitative\nresults show that they are used quite differently, leading to recommendations\nof when to use each one and directions of designing better explanations.\n","authors":["Thao Le","Tim Miller","Ronal Singh","Liz Sonenberg"],"pdf_url":"https://arxiv.org/pdf/2303.05729v1.pdf","comment":"AAAI 2023 Main Track. arXiv admin note: substantial text overlap with\n  arXiv:2206.02790"},{"id":"http://arxiv.org/abs/2303.05728v1","updated":"2023-03-10T06:21:24Z","published":"2023-03-10T06:21:24Z","title":"On the effectiveness of neural priors in modeling dynamical systems","summary":"  Modelling dynamical systems is an integral component for understanding the\nnatural world. To this end, neural networks are becoming an increasingly\npopular candidate owing to their ability to learn complex functions from large\namounts of data. Despite this recent progress, there has not been an adequate\ndiscussion on the architectural regularization that neural networks offer when\nlearning such systems, hindering their efficient usage. In this paper, we\ninitiate a discussion in this direction using coordinate networks as a test\nbed. We interpret dynamical systems and coordinate networks from a signal\nprocessing lens, and show that simple coordinate networks with few layers can\nbe used to solve multiple problems in modelling dynamical systems, without any\nexplicit regularizers.\n","authors":["Sameera Ramasinghe","Hemanth Saratchandran","Violetta Shevchenko","Simon Lucey"],"pdf_url":"https://arxiv.org/pdf/2303.05728v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05719v1","updated":"2023-03-10T05:54:11Z","published":"2023-03-10T05:54:11Z","title":"Boosting Adversarial Attacks by Leveraging Decision Boundary Information","summary":"  Due to the gap between a substitute model and a victim model, the\ngradient-based noise generated from a substitute model may have low\ntransferability for a victim model since their gradients are different.\nInspired by the fact that the decision boundaries of different models do not\ndiffer much, we conduct experiments and discover that the gradients of\ndifferent models are more similar on the decision boundary than in the original\nposition. Moreover, since the decision boundary in the vicinity of an input\nimage is flat along most directions, we conjecture that the boundary gradients\ncan help find an effective direction to cross the decision boundary of the\nvictim models. Based on it, we propose a Boundary Fitting Attack to improve\ntransferability. Specifically, we introduce a method to obtain a set of\nboundary points and leverage the gradient information of these points to update\nthe adversarial examples. Notably, our method can be combined with existing\ngradient-based methods. Extensive experiments prove the effectiveness of our\nmethod, i.e., improving the success rate by 5.6% against normally trained CNNs\nand 14.9% against defense CNNs on average compared to state-of-the-art\ntransfer-based attacks. Further we compare transformers with CNNs, the results\nindicate that transformers are more robust than CNNs. However, our method still\noutperforms existing methods when attacking transformers. Specifically, when\nusing CNNs as substitute models, our method obtains an average attack success\nrate of 58.2%, which is 10.8% higher than other state-of-the-art transfer-based\nattacks.\n","authors":["Boheng Zeng","LianLi Gao","QiLong Zhang","ChaoQun Li","JingKuan Song","ShuaiQi Jing"],"pdf_url":"https://arxiv.org/pdf/2303.05719v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05718v1","updated":"2023-03-10T05:50:17Z","published":"2023-03-10T05:50:17Z","title":"Tradeoff of generalization error in unsupervised learning","summary":"  Finding the optimal model complexity that minimizes the generalization error\n(GE) is a key issue of machine learning. For the conventional supervised\nlearning, this task typically involves the bias-variance tradeoff: lowering the\nbias by making the model more complex entails an increase in the variance.\nMeanwhile, little has been studied about whether the same tradeoff exists for\nunsupervised learning. In this study, we propose that unsupervised learning\ngenerally exhibits a two-component tradeoff of the GE, namely the model error\nand the data error -- using a more complex model reduces the model error at the\ncost of the data error, with the data error playing a more significant role for\na smaller training dataset. This is corroborated by training the restricted\nBoltzmann machine to generate the configurations of the two-dimensional Ising\nmodel at a given temperature and the totally asymmetric simple exclusion\nprocess with given entry and exit rates. Our results also indicate that the\noptimal model tends to be more complex when the data to be learned are more\ncomplex.\n","authors":["Gilhan Kim","Hojun Lee","Junghyo Jo","Yongjoo Baek"],"pdf_url":"https://arxiv.org/pdf/2303.05718v1.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.08175v4","updated":"2023-03-10T05:33:18Z","published":"2023-02-16T09:44:55Z","title":"A numerical approximation method for the Fisher-Rao distance between\n  multivariate normal distributions","summary":"  We present a simple method to approximate Rao's distance between multivariate\nnormal distributions based on discretizing curves joining normal distributions\nand approximating Rao distances between successive nearby normal distributions\non the curves by the square root of Jeffreys divergence. We consider\nexperimentally the linear interpolation curves in the ordinary, natural and\nexpectation parameterizations of the normal distributions, and compare these\ncurves with a curve derived from the Calvo and Oller's isometric embedding of\nthe Fisher-Rao $d$-variate normal manifold into the cone of $(d+1)\\times (d+1)$\nsymmetric positive-definite matrices [Journal of multivariate analysis 35.2\n(1990): 223-242]. We report on our experiments and assess the quality of our\napproximation technique by comparing the numerical approximations with lower\nand upper bounds. Finally, we present some information-geometric properties of\nthe Calvo and Oller's isometric embedding.\n","authors":["Frank Nielsen"],"pdf_url":"https://arxiv.org/pdf/2302.08175v4.pdf","comment":"30 pages, 16 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.05710v1","updated":"2023-03-10T05:27:23Z","published":"2023-03-10T05:27:23Z","title":"A Unified and Efficient Coordinating Framework for Autonomous DBMS\n  Tuning","summary":"  Recently using machine learning (ML) based techniques to optimize modern\ndatabase management systems has attracted intensive interest from both industry\nand academia. With an objective to tune a specific component of a DBMS (e.g.,\nindex selection, knobs tuning), the ML-based tuning agents have shown to be\nable to find better configurations than experienced database administrators.\nHowever, one critical yet challenging question remains unexplored -- how to\nmake those ML-based tuning agents work collaboratively. Existing methods do not\nconsider the dependencies among the multiple agents, and the model used by each\nagent only studies the effect of changing the configurations in a single\ncomponent. To tune different components for DBMS, a coordinating mechanism is\nneeded to make the multiple agents cognizant of each other. Also, we need to\ndecide how to allocate the limited tuning budget among the agents to maximize\nthe performance. Such a decision is difficult to make since the distribution of\nthe reward for each agent is unknown and non-stationary. In this paper, we\nstudy the above question and present a unified coordinating framework to\nefficiently utilize existing ML-based agents. First, we propose a message\npropagation protocol that specifies the collaboration behaviors for agents and\nencapsulates the global tuning messages in each agent's model. Second, we\ncombine Thompson Sampling, a well-studied reinforcement learning algorithm with\na memory buffer so that our framework can allocate budget judiciously in a\nnon-stationary environment. Our framework defines the interfaces adapted to a\nbroad class of ML-based tuning agents, yet simple enough for integration with\nexisting implementations and future extensions. We show that it can effectively\nutilize different ML-based agents and find better configurations with 1.4~14.1X\nspeedups on the workload execution time compared with baselines.\n","authors":["Xinyi Zhang","Zhuo Chang","Hong Wu","Yang Li","Jia Chen","Jian Tan","Feifei Li","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2303.05710v1.pdf","comment":"Accepted at 2023 International Conference on Management of Data\n  (SIGMOD '23)"},{"id":"http://arxiv.org/abs/2303.01498v2","updated":"2023-03-10T04:49:02Z","published":"2023-03-02T18:58:15Z","title":"ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit\n  Detection & Emotional Reaction Intensity Estimation Challenges","summary":"  The fifth Affective Behavior Analysis in-the-wild (ABAW) Competition is part\nof the respective ABAW Workshop which will be held in conjunction with IEEE\nComputer Vision and Pattern Recognition Conference (CVPR), 2023. The 5th ABAW\nCompetition is a continuation of the Competitions held at ECCV 2022, IEEE CVPR\n2022, ICCV 2021, IEEE FG 2020 and CVPR 2017 Conferences, and is dedicated at\nautomatically analyzing affect. For this year's Competition, we feature two\ncorpora: i) an extended version of the Aff-Wild2 database and ii) the\nHume-Reaction dataset. The former database is an audiovisual one of around 600\nvideos of around 3M frames and is annotated with respect to:a) two continuous\naffect dimensions -valence (how positive/negative a person is) and arousal (how\nactive/passive a person is)-; b) basic expressions (e.g. happiness, sadness,\nneutral state); and c) atomic facial muscle actions (i.e., action units). The\nlatter dataset is an audiovisual one in which reactions of individuals to\nemotional stimuli have been annotated with respect to seven emotional\nexpression intensities. Thus the 5th ABAW Competition encompasses four\nChallenges: i) uni-task Valence-Arousal Estimation, ii) uni-task Expression\nClassification, iii) uni-task Action Unit Detection, and iv) Emotional Reaction\nIntensity Estimation. In this paper, we present these Challenges, along with\ntheir corpora, we outline the evaluation metrics, we present the baseline\nsystems and illustrate their obtained performance.\n","authors":["Dimitrios Kollias","Panagiotis Tzirakis","Alice Baird","Alan Cowen","Stefanos Zafeiriou"],"pdf_url":"https://arxiv.org/pdf/2303.01498v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.10659"},{"id":"http://arxiv.org/abs/2303.05699v1","updated":"2023-03-10T04:49:01Z","published":"2023-03-10T04:49:01Z","title":"Feature Unlearning for Generative Models via Implicit Feedback","summary":"  We tackle the problem of feature unlearning from a pretrained image\ngenerative model. Unlike a common unlearning task where an unlearning target is\na subset of the training set, we aim to unlearn a specific feature, such as\nhairstyle from facial images, from the pretrained generative models. As the\ntarget feature is only presented in a local region of an image, unlearning the\nentire image from the pretrained model may result in losing other details in\nthe remaining region of the image. To specify which features to unlearn, we\ndevelop an implicit feedback mechanism where a user can select images\ncontaining the target feature. From the implicit feedback, we identify a latent\nrepresentation corresponding to the target feature and then use the\nrepresentation to unlearn the generative model. Our framework is generalizable\nfor the two well-known families of generative models: GANs and VAEs. Through\nexperiments on MNIST and CelebA datasets, we show that target features are\nsuccessfully removed while keeping the fidelity of the original models.\n","authors":["Saemi Moon","Seunghyuk Cho","Dongwoo Kim"],"pdf_url":"https://arxiv.org/pdf/2303.05699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05698v1","updated":"2023-03-10T04:37:14Z","published":"2023-03-10T04:37:14Z","title":"Fairness-enhancing deep learning for ride-hailing demand prediction","summary":"  Short-term demand forecasting for on-demand ride-hailing services is one of\nthe fundamental issues in intelligent transportation systems. However, previous\ntravel demand forecasting research predominantly focused on improving\nprediction accuracy, ignoring fairness issues such as systematic\nunderestimations of travel demand in disadvantaged neighborhoods. This study\ninvestigates how to measure, evaluate, and enhance prediction fairness between\ndisadvantaged and privileged communities in spatial-temporal demand forecasting\nof ride-hailing services. A two-pronged approach is taken to reduce the demand\nprediction bias. First, we develop a novel deep learning model architecture,\nnamed socially aware neural network (SA-Net), to integrate the\nsocio-demographics and ridership information for fair demand prediction through\nan innovative socially-aware convolution operation. Second, we propose a\nbias-mitigation regularization method to mitigate the mean percentage\nprediction error gap between different groups. The experimental results,\nvalidated on the real-world Chicago Transportation Network Company (TNC) data,\nshow that the de-biasing SA-Net can achieve better predictive performance in\nboth prediction accuracy and fairness. Specifically, the SA-Net improves\nprediction accuracy for both the disadvantaged and privileged groups compared\nwith the state-of-the-art models. When coupled with the bias mitigation\nregularization method, the de-biasing SA-Net effectively bridges the mean\npercentage prediction error gap between the disadvantaged and privileged\ngroups, and also protects the disadvantaged regions against systematic\nunderestimation of TNC demand. Our proposed de-biasing method can be adopted in\nmany existing short-term travel demand estimation models, and can be utilized\nfor various other spatial-temporal prediction tasks such as crime incidents\npredictions.\n","authors":["Yunhan Zheng","Qingyi Wang","Dingyi Zhuang","Shenhao Wang","Jinhua Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.05698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05696v1","updated":"2023-03-10T04:34:51Z","published":"2023-03-10T04:34:51Z","title":"Explainable Semantic Medical Image Segmentation with Style","summary":"  Semantic medical image segmentation using deep learning has recently achieved\nhigh accuracy, making it appealing to clinical problems such as radiation\ntherapy. However, the lack of high-quality semantically labelled data remains a\nchallenge leading to model brittleness to small shifts to input data. Most\nworks require extra data for semi-supervised learning and lack the\ninterpretability of the boundaries of the training data distribution during\ntraining, which is essential for model deployment in clinical practice. We\npropose a fully supervised generative framework that can achieve generalisable\nsegmentation with only limited labelled data by simultaneously constructing an\nexplorable manifold during training. The proposed approach creates medical\nimage style paired with a segmentation task driven discriminator incorporating\nend-to-end adversarial training. The discriminator is generalised to small\ndomain shifts as much as permissible by the training data, and the generator\nautomatically diversifies the training samples using a manifold of input\nfeatures learnt during segmentation. All the while, the discriminator guides\nthe manifold learning by supervising the semantic content and fine-grained\nfeatures separately during the image diversification. After training,\nvisualisation of the learnt manifold from the generator is available to\ninterpret the model limits. Experiments on a fully semantic, publicly available\npelvis dataset demonstrated that our method is more generalisable to shifts\nthan other state-of-the-art methods while being more explainable using an\nexplorable manifold.\n","authors":["Wei Dai","Siyu Liu","Craig B. Engstrom","Shekhar S. Chandra"],"pdf_url":"https://arxiv.org/pdf/2303.05696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05694v1","updated":"2023-03-10T04:14:30Z","published":"2023-03-10T04:14:30Z","title":"Gaussian Max-Value Entropy Search for Multi-Agent Bayesian Optimization","summary":"  We study the multi-agent Bayesian optimization (BO) problem, where multiple\nagents maximize a black-box function via iterative queries. We focus on Entropy\nSearch (ES), a sample-efficient BO algorithm that selects queries to maximize\nthe mutual information about the maximum of the black-box function. One of the\nmain challenges of ES is that calculating the mutual information requires\ncomputationally-costly approximation techniques. For multi-agent BO problems,\nthe computational cost of ES is exponential in the number of agents. To address\nthis challenge, we propose the Gaussian Max-value Entropy Search, a multi-agent\nBO algorithm with favorable sample and computational efficiency. The key to our\nidea is to use a normal distribution to approximate the function maximum and\ncalculate its mutual information accordingly. The resulting approximation\nallows queries to be cast as the solution of a closed-form optimization problem\nwhich, in turn, can be solved via a modified gradient ascent algorithm and\nscaled to a large number of agents. We demonstrate the effectiveness of\nGaussian max-value Entropy Search through numerical experiments on standard\ntest functions and real-robot experiments on the source-seeking problem.\nResults show that the proposed algorithm outperforms the multi-agent BO\nbaselines in the numerical experiments and can stably seek the source with a\nlimited number of noisy observations on real robots.\n","authors":["Haitong Ma","Tianpeng Zhang","Yixuan Wu","Flavio P. Calmon","Na Li"],"pdf_url":"https://arxiv.org/pdf/2303.05694v1.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2109.11723v3","updated":"2023-03-10T04:13:25Z","published":"2021-09-24T03:33:45Z","title":"Combining Contention-Based Spectrum Access and Adaptive Modulation using\n  Deep Reinforcement Learning","summary":"  The use of unlicensed spectrum for cellular systems to mitigate spectrum\nscarcity has led to the development of intelligent adaptive approaches to\nspectrum access that improve upon traditional carrier sensing and\nlisten-before-talk methods. We study decentralized contention-based medium\naccess for base stations (BSs) of a single Radio Access Technology (RAT)\noperating on unlicensed shared spectrum. We devise a distributed deep\nreinforcement learning-based algorithm for both contention and adaptive\nmodulation, modelled on a two state Markov decision process, that attempts to\nmaximize a network-wide downlink throughput objective. Empirically, we find the\n(proportional fairness) reward accumulated by a policy gradient approach to be\nsignificantly higher than even a genie-aided adaptive energy detection\nthreshold. Our approaches are further validated by improved sum and peak\nthroughput. The scalability of our approach to large networks is demonstrated\nvia an improved cumulative reward earned on both indoor and outdoor layouts\nwith a large number of BSs.\n","authors":["Akash Doshi","Jeffrey G. Andrews"],"pdf_url":"https://arxiv.org/pdf/2109.11723v3.pdf","comment":"6 pages, 3 figures. Published in Asilomar 2022"},{"id":"http://arxiv.org/abs/2303.05691v1","updated":"2023-03-10T03:49:50Z","published":"2023-03-10T03:49:50Z","title":"Human Pose Estimation from Ambiguous Pressure Recordings with\n  Spatio-temporal Masked Transformers","summary":"  Despite the impressive performance of vision-based pose estimators, they\ngenerally fail to perform well under adverse vision conditions and often don't\nsatisfy the privacy demands of customers. As a result, researchers have begun\nto study tactile sensing systems as an alternative. However, these systems\nsuffer from noisy and ambiguous recordings. To tackle this problem, we propose\na novel solution for pose estimation from ambiguous pressure data. Our method\ncomprises a spatio-temporal vision transformer with an encoder-decoder\narchitecture. Detailed experiments on two popular public datasets reveal that\nour model outperforms existing solutions in the area. Moreover, we observe that\nincreasing the number of temporal crops in the early stages of the network\npositively impacts the performance while pre-training the network in a\nself-supervised setting using a masked auto-encoder approach also further\nimproves the results.\n","authors":["Vandad Davoodnia","Ali Etemad"],"pdf_url":"https://arxiv.org/pdf/2303.05691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03328v2","updated":"2023-03-10T03:36:18Z","published":"2023-02-07T09:11:17Z","title":"Multi-Task Recommendations with Reinforcement Learning","summary":"  In recent years, Multi-task Learning (MTL) has yielded immense success in\nRecommender System (RS) applications. However, current MTL-based recommendation\nmodels tend to disregard the session-wise patterns of user-item interactions\nbecause they are predominantly constructed based on item-wise datasets.\nMoreover, balancing multiple objectives has always been a challenge in this\nfield, which is typically avoided via linear estimations in existing works. To\naddress these issues, in this paper, we propose a Reinforcement Learning (RL)\nenhanced MTL framework, namely RMTL, to combine the losses of different\nrecommendation tasks using dynamic weights. To be specific, the RMTL structure\ncan address the two aforementioned issues by (i) constructing an MTL\nenvironment from session-wise interactions and (ii) training multi-task\nactor-critic network structure, which is compatible with most existing\nMTL-based recommendation models, and (iii) optimizing and fine-tuning the MTL\nloss function using the weights generated by critic networks. Experiments on\ntwo real-world public datasets demonstrate the effectiveness of RMTL with a\nhigher AUC against state-of-the-art MTL-based recommendation models.\nAdditionally, we evaluate and validate RMTL's compatibility and transferability\nacross various MTL models.\n","authors":["Ziru Liu","Jiejie Tian","Qingpeng Cai","Xiangyu Zhao","Jingtong Gao","Shuchang Liu","Dayou Chen","Tonghao He","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.03328v2.pdf","comment":"TheWebConf2023"},{"id":"http://arxiv.org/abs/1904.05351v2","updated":"2023-03-10T03:22:22Z","published":"2019-04-10T10:25:25Z","title":"RawNet: Fast End-to-End Neural Vocoder","summary":"  Neural network-based vocoders have recently demonstrated the powerful ability\nto synthesize high-quality speech. These models usually generate samples by\nconditioning on spectral features, such as Mel-spectrogram and fundamental\nfrequency, which is crucial to speech synthesis. However, the feature\nextraction procession tends to depend heavily on human knowledge resulting in a\nless expressive description of the origin audio. In this work, we proposed\nRawNet, a complete end-to-end neural vocoder following the auto-encoder\nstructure for speaker-dependent and -independent speech synthesis. It\nautomatically learns to extract features and recover audio using neural\nnetworks, which include a coder network to capture a higher representation of\nthe input audio and an autoregressive voder network to restore the audio in a\nsample-by-sample manner. The coder and voder are jointly trained directly on\nthe raw waveform without any human-designed features. The experimental results\nshow that RawNet achieves a better speech quality using a simplified model\narchitecture and obtains a faster speech generation speed at the inference\nstage.\n","authors":["Yunchao He","Yujun Wang"],"pdf_url":"https://arxiv.org/pdf/1904.05351v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05683v1","updated":"2023-03-10T03:20:40Z","published":"2023-03-10T03:20:40Z","title":"Hierarchical Clustering with OWA-based Linkages, the Lance-Williams\n  Formula, and Dendrogram Inversions","summary":"  Agglomerative hierarchical clustering based on Ordered Weighted Averaging\n(OWA) operators not only generalises the single, complete, and average\nlinkages, but also includes intercluster distances based on a few nearest or\nfarthest neighbours, trimmed and winsorised means of pairwise point\nsimilarities, amongst many others. We explore the relationships between the\nfamous Lance-Williams update formula and the extended OWA-based linkages with\nweights generated via infinite coefficient sequences. Furthermore, we provide\nsome conditions for the weight generators to guarantee the resulting\ndendrograms to be free from unaesthetic inversions.\n","authors":["Marek Gagolewski","Anna Cena","Simon James","Gleb Beliakov"],"pdf_url":"https://arxiv.org/pdf/2303.05683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05682v1","updated":"2023-03-10T03:20:03Z","published":"2023-03-10T03:20:03Z","title":"A dual basis approach to multidimensional scaling: spectral analysis and\n  graph regularity","summary":"  Classical multidimensional scaling (CMDS) is a technique that aims to embed a\nset of objects in a Euclidean space given their pairwise Euclidean distance\nmatrix. The main part of CMDS is based on double centering a squared distance\nmatrix and employing a truncated eigendecomposition to recover the point\ncoordinates. A central result in CMDS connects the squared Euclidean matrix to\na Gram matrix derived from the set of points. In this paper, we study a dual\nbasis approach to classical multidimensional scaling. We give an explicit\nformula for the dual basis and fully characterize the spectrum of an essential\nmatrix in the dual basis framework. We make connections to a related problem in\nmetric nearness.\n","authors":["Samuel Lichtenberg","Abiy Tasissa"],"pdf_url":"https://arxiv.org/pdf/2303.05682v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2303.05679v1","updated":"2023-03-10T03:18:03Z","published":"2023-03-10T03:18:03Z","title":"Clustering with minimum spanning trees: How good can it be?","summary":"  Minimum spanning trees (MSTs) provide a convenient representation of datasets\nin numerous pattern recognition activities. Moreover, they are relatively fast\nto compute. In this paper, we quantify the extent to which they can be\nmeaningful in data clustering tasks. By identifying the upper bounds for the\nagreement between the best (oracle) algorithm and the expert labels from a\nlarge battery of benchmark data, we discover that MST methods can overall be\nvery competitive. Next, instead of proposing yet another algorithm that\nperforms well on a limited set of examples, we review, study, extend, and\ngeneralise existing, the state-of-the-art MST-based partitioning schemes, which\nleads to a few new and interesting approaches. It turns out that the Genie\nmethod and the information-theoretic approaches often outperform the non-MST\nalgorithms such as k-means, Gaussian mixtures, spectral clustering, BIRCH, and\nclassical hierarchical agglomerative procedures.\n","authors":["Marek Gagolewski","Anna Cena","Maciej Bartoszuk","Łukasz Brzozowski"],"pdf_url":"https://arxiv.org/pdf/2303.05679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05678v1","updated":"2023-03-10T03:13:36Z","published":"2023-03-10T03:13:36Z","title":"Improving Weakly Supervised Sound Event Detection with Causal\n  Intervention","summary":"  Existing weakly supervised sound event detection (WSSED) work has not\nexplored both types of co-occurrences simultaneously, i.e., some sound events\noften co-occur, and their occurrences are usually accompanied by specific\nbackground sounds, so they would be inevitably entangled, causing\nmisclassification and biased localization results with only clip-level\nsupervision. To tackle this issue, we first establish a structural causal model\n(SCM) to reveal that the context is the main cause of co-occurrence confounders\nthat mislead the model to learn spurious correlations between frames and\nclip-level labels. Based on the causal analysis, we propose a causal\nintervention (CI) method for WSSED to remove the negative impact of\nco-occurrence confounders by iteratively accumulating every possible context of\neach class and then re-projecting the contexts to the frame-level features for\nmaking the event boundary clearer. Experiments show that our method effectively\nimproves the performance on multiple datasets and can generalize to various\nbaseline models.\n","authors":["Yifei Xin","Dongchao Yang","Fan Cui","Yujun Wang","Yuexian Zou"],"pdf_url":"https://arxiv.org/pdf/2303.05678v1.pdf","comment":"Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2303.02011v2","updated":"2023-03-10T02:31:28Z","published":"2023-03-03T15:27:16Z","title":"Diagnosing Model Performance Under Distribution Shift","summary":"  Prediction models can perform poorly when deployed to target distributions\ndifferent from the training distribution. To understand these operational\nfailure modes, we develop a method, called DIstribution Shift DEcomposition\n(DISDE), to attribute a drop in performance to different types of distribution\nshifts. Our approach decomposes the performance drop into terms for 1) an\nincrease in harder but frequently seen examples from training, 2) changes in\nthe relationship between features and outcomes, and 3) poor performance on\nexamples infrequent or unseen during training. These terms are defined by\nfixing a distribution on $X$ while varying the conditional distribution of $Y\n\\mid X$ between training and target, or by fixing the conditional distribution\nof $Y \\mid X$ while varying the distribution on $X$. In order to do this, we\ndefine a hypothetical distribution on $X$ consisting of values common in both\ntraining and target, over which it is easy to compare $Y \\mid X$ and thus\npredictive performance. We estimate performance on this hypothetical\ndistribution via reweighting methods. Empirically, we show how our method can\n1) inform potential modeling improvements across distribution shifts for\nemployment prediction on tabular census data, and 2) help to explain why\ncertain domain adaptation methods fail to improve model performance for\nsatellite image classification.\n","authors":["Tiffany Tianhui Cai","Hongseok Namkoong","Steve Yadlowsky"],"pdf_url":"https://arxiv.org/pdf/2303.02011v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05660v1","updated":"2023-03-10T02:22:33Z","published":"2023-03-10T02:22:33Z","title":"Towards better traffic volume estimation: Tackling both underdetermined\n  and non-equilibrium problems via a correlation adaptive graph convolution\n  network","summary":"  Traffic volume is an indispensable ingredient to provide fine-grained\ninformation for traffic management and control. However, due to limited\ndeployment of traffic sensors, obtaining full-scale volume information is far\nfrom easy. Existing works on this topic primarily focus on improving the\noverall estimation accuracy of a particular method and ignore the underlying\nchallenges of volume estimation, thereby having inferior performances on some\ncritical tasks. This paper studies two key problems with regard to traffic\nvolume estimation: (1) underdetermined traffic flows caused by undetected\nmovements, and (2) non-equilibrium traffic flows arise from congestion\npropagation. Here we demonstrate a graph-based deep learning method that can\noffer a data-driven, model-free and correlation adaptive approach to tackle the\nabove issues and perform accurate network-wide traffic volume estimation.\nParticularly, in order to quantify the dynamic and nonlinear relationships\nbetween traffic speed and volume for the estimation of underdetermined flows, a\nspeed patternadaptive adjacent matrix based on graph attention is developed and\nintegrated into the graph convolution process, to capture non-local\ncorrelations between sensors. To measure the impacts of non-equilibrium flows,\na temporal masked and clipped attention combined with a gated temporal\nconvolution layer is customized to capture time-asynchronous correlations\nbetween upstream and downstream sensors. We then evaluate our model on a\nreal-world highway traffic volume dataset and compare it with several benchmark\nmodels. It is demonstrated that the proposed model achieves high estimation\naccuracy even under 20% sensor coverage rate and outperforms other baselines\nsignificantly, especially on underdetermined and non-equilibrium flow\nlocations. Furthermore, comprehensive quantitative model analysis are also\ncarried out to justify the model designs.\n","authors":["Tong Nie","Guoyang Qin","Yunpeng Wang","Jian Sun"],"pdf_url":"https://arxiv.org/pdf/2303.05660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.09762v5","updated":"2023-03-10T02:22:13Z","published":"2021-12-17T20:52:03Z","title":"Reproducible and Portable Big Data Analytics in the Cloud","summary":"  Cloud computing has become a major approach to help reproduce computational\nexperiments. Yet there are still two main difficulties in reproducing batch\nbased big data analytics (including descriptive and predictive analytics) in\nthe cloud. The first is how to automate end-to-end scalable execution of\nanalytics including distributed environment provisioning, analytics pipeline\ndescription, parallel execution, and resource termination. The second is that\nan application developed for one cloud is difficult to be reproduced in another\ncloud, a.k.a. vendor lock-in problem. To tackle these problems, we leverage\nserverless computing and containerization techniques for automated scalable\nexecution and reproducibility, and utilize the adapter design pattern to enable\napplication portability and reproducibility across different clouds. We propose\nand develop an open-source toolkit that supports 1) fully automated end-to-end\nexecution and reproduction via a single command, 2) automated data and\nconfiguration storage for each execution, 3) flexible client modes based on\nuser preferences, 4) execution history query, and 5) simple reproduction of\nexisting executions in the same environment or a different environment. We did\nextensive experiments on both AWS and Azure using four big data analytics\napplications that run on virtual CPU/GPU clusters. The experiments show our\ntoolkit can achieve good execution performance, scalability, and efficient\nreproducibility for cloud-based big data analytics.\n","authors":["Xin Wang","Pei Guo","Xingyan Li","Aryya Gangopadhyay","Carl E. Busart","Jade Freeman","Jianwu Wang"],"pdf_url":"https://arxiv.org/pdf/2112.09762v5.pdf","comment":"accepted by journal IEEE Transactions on Cloud Computing"},{"id":"http://arxiv.org/abs/2303.05656v1","updated":"2023-03-10T02:15:58Z","published":"2023-03-10T02:15:58Z","title":"EHRDiff: Exploring Realistic EHR Synthesis with Diffusion Models","summary":"  Electronic health records (EHR) contain vast biomedical knowledge and are\nrich resources for developing precise medicine systems. However, due to privacy\nconcerns, there are limited high-quality EHR data accessible to researchers\nhence hindering the advancement of methodologies. Recent research has explored\nusing generative modelling methods to synthesize realistic EHR data, and most\nproposed methods are based on the generative adversarial network (GAN) and its\nvariants for EHR synthesis. Although GAN-style methods achieved\nstate-of-the-art performance in generating high-quality EHR data, such methods\nare hard to train and prone to mode collapse. Diffusion models are recently\nproposed generative modelling methods and set cutting-edge performance in image\ngeneration. The performance of diffusion models in realistic EHR synthesis is\nrarely explored. In this work, we explore whether the superior performance of\ndiffusion models can translate to the domain of EHR synthesis and propose a\nnovel EHR synthesis method named EHRDiff. Through comprehensive experiments,\nEHRDiff achieves new state-of-the-art performance for the quality of synthetic\nEHR data and can better protect private information in real training EHRs in\nthe meanwhile.\n","authors":["Hongyi Yuan","Songchi Zhou","Sheng Yu"],"pdf_url":"https://arxiv.org/pdf/2303.05656v1.pdf","comment":"Working in progress"},{"id":"http://arxiv.org/abs/2303.03387v2","updated":"2023-03-10T02:09:29Z","published":"2023-03-02T17:30:43Z","title":"CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a\n  Context Synergized Hyperbolic Network","summary":"  The tremendous growth of social media users interacting in online\nconversations has also led to significant growth in hate speech. Most of the\nprior works focus on detecting explicit hate speech, which is overt and\nleverages hateful phrases, with very little work focusing on detecting hate\nspeech that is implicit or denotes hatred through indirect or coded language.\nIn this paper, we present CoSyn, a user- and conversational-context synergized\nnetwork for detecting implicit hate speech in online conversation trees. CoSyn\nfirst models the user's personal historical and social context using a novel\nhyperbolic Fourier attention mechanism and hyperbolic graph convolution\nnetwork. Next, we jointly model the user's personal context and the\nconversational context using a novel context interaction mechanism in the\nhyperbolic space that clearly captures the interplay between the two and makes\nindependent assessments on the amounts of information to be retrieved from both\ncontexts. CoSyn performs all operations in the hyperbolic space to account for\nthe scale-free dynamics of social media. We demonstrate the effectiveness of\nCoSyn both qualitatively and quantitatively on an open-source hate speech\ndataset with Twitter conversations and show that CoSyn outperforms all our\nbaselines in detecting implicit hate speech with absolute improvements in the\nrange of 8.15% - 19.50%.\n","authors":["Sreyan Ghosh","Manan Suri","Purva Chiniya","Utkarsh Tyagi","Sonal Kumar","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2303.03387v2.pdf","comment":"Under review at IJCAI 2023"},{"id":"http://arxiv.org/abs/2303.05652v1","updated":"2023-03-10T02:08:01Z","published":"2023-03-10T02:08:01Z","title":"GATOR: Graph-Aware Transformer with Motion-Disentangled Regression for\n  Human Mesh Recovery from a 2D Pose","summary":"  3D human mesh recovery from a 2D pose plays an important role in various\napplications. However, it is hard for existing methods to simultaneously\ncapture the multiple relations during the evolution from skeleton to mesh,\nincluding joint-joint, joint-vertex and vertex-vertex relations, which often\nleads to implausible results. To address this issue, we propose a novel\nsolution, called GATOR, that contains an encoder of Graph-Aware Transformer\n(GAT) and a decoder with Motion-Disentangled Regression (MDR) to explore these\nmultiple relations. Specifically, GAT combines a GCN and a graph-aware\nself-attention in parallel to capture physical and hidden joint-joint\nrelations. Furthermore, MDR models joint-vertex and vertex-vertex interactions\nto explore joint and vertex relations. Based on the clustering characteristics\nof vertex offset fields, MDR regresses the vertices by composing the predicted\nbase motions. Extensive experiments show that GATOR achieves state-of-the-art\nperformance on two challenging benchmarks.\n","authors":["Yingxuan You","Hong Liu","Xia Li","Wenhao Li","Ti Wang","Runwei Ding"],"pdf_url":"https://arxiv.org/pdf/2303.05652v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.05648v1","updated":"2023-03-10T01:49:56Z","published":"2023-03-10T01:49:56Z","title":"Pacos: Modeling Users' Interpretable and Context-Dependent Choices in\n  Preference Reversals","summary":"  Choice problems refer to selecting the best choices from several items, and\nlearning users' preferences in choice problems is of great significance in\nunderstanding the decision making mechanisms and providing personalized\nservices. Existing works typically assume that people evaluate items\nindependently. In practice, however, users' preferences depend on the market in\nwhich items are placed, which is known as context effects; and the order of\nusers' preferences for two items may even be reversed, which is referred to\npreference reversals. In this work, we identify three factors contributing to\ncontext effects: users' adaptive weights, the inter-item comparison, and\ndisplay positions. We propose a context-dependent preference model named Pacos\nas a unified framework for addressing three factors simultaneously, and\nconsider two design methods including an additive method with high\ninterpretability and an ANN-based method with high accuracy. We study the\nconditions for preference reversals to occur and provide an theoretical proof\nof the effectiveness of Pacos in addressing preference reversals. Experimental\nresults show that the proposed method has better performance than prior works\nin predicting users' choices, and has great interpretability to help understand\nthe cause of preference reversals.\n","authors":["Qingming Li","H. Vicky Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.05648v1.pdf","comment":"29 pages, 12 figures"},{"id":"http://arxiv.org/abs/2303.05641v1","updated":"2023-03-10T01:09:04Z","published":"2023-03-10T01:09:04Z","title":"Efficient Real Time Recurrent Learning through combined activity and\n  parameter sparsity","summary":"  Backpropagation through time (BPTT) is the standard algorithm for training\nrecurrent neural networks (RNNs), which requires separate simulation phases for\nthe forward and backward passes for inference and learning, respectively.\nMoreover, BPTT requires storing the complete history of network states between\nphases, with memory consumption growing proportional to the input sequence\nlength. This makes BPTT unsuited for online learning and presents a challenge\nfor implementation on low-resource real-time systems. Real-Time Recurrent\nLearning (RTRL) allows online learning, and the growth of required memory is\nindependent of sequence length. However, RTRL suffers from exceptionally high\ncomputational costs that grow proportional to the fourth power of the state\nsize, making RTRL computationally intractable for all but the smallest of\nnetworks. In this work, we show that recurrent networks exhibiting high\nactivity sparsity can reduce the computational cost of RTRL. Moreover,\ncombining activity and parameter sparsity can lead to significant enough\nsavings in computational and memory costs to make RTRL practical. Unlike\nprevious work, this improvement in the efficiency of RTRL can be achieved\nwithout using any approximations for the learning process.\n","authors":["Anand Subramoney"],"pdf_url":"https://arxiv.org/pdf/2303.05641v1.pdf","comment":"Published as a workshop paper at ICLR 2023 Workshop on Sparsity in\n  Neural Networks"},{"id":"http://arxiv.org/abs/2303.05639v1","updated":"2023-03-10T01:04:27Z","published":"2023-03-10T01:04:27Z","title":"Self-Supervised One-Shot Learning for Automatic Segmentation of StyleGAN\n  Images","summary":"  We propose in this paper a framework for automatic one-shot segmentation of\nsynthetic images generated using StyleGANs. As to the need for `one-shot\nsegmentation', we want the network to carry out a semantic segmentation of the\nimages on the fly, that is, as they are being produced at inference time. The\nimplementation of our framework is based on the observation that the\nmulti-scale hidden features produced by a GAN during image synthesis hold\nuseful semantic information that can be utilized for automatic segmentation.\nUsing these features, our proposed framework learns to segment synthetic images\nusing a novel self-supervised, contrastive clustering algorithm that projects\nthe hidden features in the generator onto a compact feature space for per-pixel\nclassification. This contrastive learner uses a swapped prediction loss for\nimage segmentation that is computed using pixel-wise cluster assignments for\nthe image and its transformed variants. Using the hidden features from an\nalready pre-trained GAN for clustering, this leads to a much faster learning of\nthe pixel-wise feature vectors for one-shot segmentation. We have tested our\nimplementation on a number of standard benchmarks (CelebA, LSUN, PASCAL-Part)\nfor object and part segmentation. The results of our experiments yield a\nsegmentation performance that not only outperforms the semi-supervised baseline\nmethods with an average wIoU margin of 1.02 % but also improves the inference\nspeeds by a peak factor of 4.5. Finally, we also show the results of using the\nproposed framework in the implementation of BagGAN, a GAN-based framework for\nthe production of annotated synthetic baggage X-ray scans for threat detection.\nThis one-shot learning framework was trained and tested on the PIDRay baggage\nscreening benchmark for 5 different threat categories to yield a segmentation\nperformance which stands close to its baseline segmenter.\n","authors":["Ankit Manerikar","Avinash C. Kak"],"pdf_url":"https://arxiv.org/pdf/2303.05639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.03629v3","updated":"2023-03-10T01:00:17Z","published":"2022-10-06T01:00:32Z","title":"ReAct: Synergizing Reasoning and Acting in Language Models","summary":"  While large language models (LLMs) have demonstrated impressive capabilities\nacross tasks in language understanding and interactive decision making, their\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\naction plan generation) have primarily been studied as separate topics. In this\npaper, we explore the use of LLMs to generate both reasoning traces and\ntask-specific actions in an interleaved manner, allowing for greater synergy\nbetween the two: reasoning traces help the model induce, track, and update\naction plans as well as handle exceptions, while actions allow it to interface\nwith external sources, such as knowledge bases or environments, to gather\nadditional information. We apply our approach, named ReAct, to a diverse set of\nlanguage and decision making tasks and demonstrate its effectiveness over\nstate-of-the-art baselines, as well as improved human interpretability and\ntrustworthiness over methods without reasoning or acting components.\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\nReAct overcomes issues of hallucination and error propagation prevalent in\nchain-of-thought reasoning by interacting with a simple Wikipedia API, and\ngenerates human-like task-solving trajectories that are more interpretable than\nbaselines without reasoning traces. On two interactive decision making\nbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\nreinforcement learning methods by an absolute success rate of 34% and 10%\nrespectively, while being prompted with only one or two in-context examples.\nProject site with code: https://react-lm.github.io\n","authors":["Shunyu Yao","Jeffrey Zhao","Dian Yu","Nan Du","Izhak Shafran","Karthik Narasimhan","Yuan Cao"],"pdf_url":"https://arxiv.org/pdf/2210.03629v3.pdf","comment":"v3 is the ICLR camera ready version with some typos fixed. Project\n  site with code: https://react-lm.github.io"},{"id":"http://arxiv.org/abs/2303.05634v1","updated":"2023-03-10T00:46:32Z","published":"2023-03-10T00:46:32Z","title":"Fusarium head blight detection, spikelet estimation, and severity\n  assessment in wheat using 3D convolutional neural networks","summary":"  Fusarium head blight (FHB) is one of the most significant diseases affecting\nwheat and other small grain cereals worldwide. The development of resistant\nvarieties requires the laborious task of field and greenhouse phenotyping. The\napplications considered in this work are the automated detection of FHB disease\nsymptoms expressed on a wheat plant, the automated estimation of the total\nnumber of spikelets and the total number of infected spikelets on a wheat head,\nand the automated assessment of the FHB severity in infected wheat. The data\nused to generate the results are 3-dimensional (3D) multispectral point clouds\n(PC), which are 3D collections of points - each associated with a red, green,\nblue (RGB), and near-infrared (NIR) measurement. Over 300 wheat plant images\nwere collected using a multispectral 3D scanner, and the labelled UW-MRDC 3D\nwheat dataset was created. The data was used to develop novel and efficient 3D\nconvolutional neural network (CNN) models for FHB detection, which achieved\n100% accuracy. The influence of the multispectral information on performance\nwas evaluated, and our results showed the dominance of the RGB channels over\nboth the NIR and the NIR plus RGB channels combined. Furthermore, novel and\nefficient 3D CNNs were created to estimate the total number of spikelets and\nthe total number of infected spikelets on a wheat head, and our best models\nachieved mean absolute errors (MAE) of 1.13 and 1.56, respectively. Moreover,\n3D CNN models for FHB severity estimation were created, and our best model\nachieved 8.6 MAE. A linear regression analysis between the visual FHB severity\nassessment and the FHB severity predicted by our 3D CNN was performed, and the\nresults showed a significant correlation between the two variables with a\n0.0001 P-value and 0.94 R-squared.\n","authors":["Oumaima Hamila","Christopher J. Henry","Oscar I. Molina","Christopher P. Bidinosti","Maria Antonia Henriquez"],"pdf_url":"https://arxiv.org/pdf/2303.05634v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05629v1","updated":"2023-03-10T00:15:08Z","published":"2023-03-10T00:15:08Z","title":"Monitoring Efficiency of IoT Wireless Charging","summary":"  Crowdsourcing wireless energy is a novel and convenient solution to charge\nnearby IoT devices. Several applications have been proposed to enable\npeer-to-peer wireless energy charging. However, none of them considered the\nenergy efficiency of the wireless transfer of energy. In this paper, we propose\nan energy estimation framework that predicts the actual received energy. Our\nframework uses two machine learning algorithms, namely XGBoost and Neural\nNetwork, to estimate the received energy. The result shows that the Neural\nNetwork model is better than XGBoost at predicting the received energy. We\ntrain and evaluate our models by collecting a real wireless energy dataset.\n","authors":["Pengwei Yang","Amani Abusafia","Abdallah Lakhdari","Athman Bouguettaya"],"pdf_url":"https://arxiv.org/pdf/2303.05629v1.pdf","comment":"3 pages, 4 figures. This is an accepted demo paper and it will appear\n  in The 21st International Conference on Pervasive Computing and\n  Communications (PerCom 2023)"},{"id":"http://arxiv.org/abs/2303.05628v1","updated":"2023-03-10T00:11:18Z","published":"2023-03-10T00:11:18Z","title":"On the Unlikelihood of D-Separation","summary":"  Causal discovery aims to recover a causal graph from data generated by it;\nconstraint based methods do so by searching for a d-separating conditioning set\nof nodes in the graph via an oracle. In this paper, we provide analytic\nevidence that on large graphs, d-separation is a rare phenomenon, even when\nguaranteed to exist, unless the graph is extremely sparse. We then provide an\nanalytic average case analysis of the PC Algorithm for causal discovery, as\nwell as a variant of the SGS Algorithm we call UniformSGS. We consider a set\n$V=\\{v_1,\\ldots,v_n\\}$ of nodes, and generate a random DAG $G=(V,E)$ where\n$(v_a, v_b) \\in E$ with i.i.d. probability $p_1$ if $a<b$ and $0$ if $a > b$.\nWe provide upper bounds on the probability that a subset of $V-\\{x,y\\}$\nd-separates $x$ and $y$, conditional on $x$ and $y$ being d-separable; our\nupper bounds decay exponentially fast to $0$ as $|V| \\rightarrow \\infty$. For\nthe PC Algorithm, while it is known that its worst-case guarantees fail on\nnon-sparse graphs, we show that the same is true for the average case, and that\nthe sparsity requirement is quite demanding: for good performance, the density\nmust go to $0$ as $|V| \\rightarrow \\infty$ even in the average case. For\nUniformSGS, while it is known that the running time is exponential for existing\nedges, we show that in the average case, that is the expected running time for\nmost non-existing edges as well.\n","authors":["Itai Feigenbaum","Huan Wang","Shelby Heinecke","Juan Carlos Niebles","Weiran Yao","Caiming Xiong","Devansh Arpit"],"pdf_url":"https://arxiv.org/pdf/2303.05628v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2303.06137v1","updated":"2023-03-10T18:55:02Z","published":"2023-03-10T18:55:02Z","title":"Multiple Hands Make Light Work: Enhancing Quality and Diversity using\n  MAP-Elites with Multiple Parallel Evolution Strategies","summary":"  With the development of hardware accelerators and their corresponding tools,\nevaluations have become more affordable through fast and massively parallel\nevaluations in some applications. This advancement has drastically sped up the\nruntime of evolution-inspired algorithms such as Quality-Diversity\noptimization, creating tremendous potential for algorithmic innovation through\nscale. In this work, we propose MAP-Elites-Multi-ES (MEMES), a novel QD\nalgorithm based on Evolution Strategies (ES) designed for fast parallel\nevaluations. ME-Multi-ES builds on top of the existing MAP-Elites-ES algorithm,\nscaling it by maintaining multiple independent ES threads with massive\nparallelization. We also introduce a new dynamic reset procedure for the\nlifespan of the independent ES to autonomously maximize the improvement of the\nQD population. We show experimentally that MEMES outperforms existing\ngradient-based and objective-agnostic QD algorithms when compared in terms of\ngenerations. We perform this comparison on both black-box optimization and\nQD-Reinforcement Learning tasks, demonstrating the benefit of our approach\nacross different problems and domains. Finally, we also find that our approach\nintrinsically enables optimization of fitness locally around a niche, a\nphenomenon not observed in other QD algorithms.\n","authors":["Manon Flageat","Bryan Lim","Antoine Cully"],"pdf_url":"https://arxiv.org/pdf/2303.06137v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06135v1","updated":"2023-03-10T18:53:52Z","published":"2023-03-10T18:53:52Z","title":"Rewarding Chatbots for Real-World Engagement with Millions of Users","summary":"  The emergence of pretrained large language models has led to the deployment\nof a range of social chatbots for chitchat. Although these chatbots demonstrate\nlanguage ability and fluency, they are not guaranteed to be engaging and can\nstruggle to retain users. This work investigates the development of social\nchatbots that prioritize user engagement to enhance retention, specifically\nexamining the use of human feedback to efficiently develop highly engaging\nchatbots. The proposed approach uses automatic pseudo-labels collected from\nuser interactions to train a reward model that can be used to reject\nlow-scoring sample responses generated by the chatbot model at inference time.\nIntuitive evaluation metrics, such as mean conversation length (MCL), are\nintroduced as proxies to measure the level of engagement of deployed chatbots.\nA/B testing on groups of 10,000 new daily chatbot users on the Chai Research\nplatform shows that this approach increases the MCL by up to 70%, which\ntranslates to a more than 30% increase in user retention for a GPT-J 6B model.\nFuture work aims to use the reward model to realise a data fly-wheel, where the\nlatest user conversations can be used to alternately fine-tune the language\nmodel and the reward model.\n","authors":["Robert Irvine","Douglas Boubert","Vyas Raina","Adian Liusie","Vineet Mudupalli","Aliaksei Korshuk","Zongyi Liu","Fritz Cremer","Valentin Assassi","Christie-Carol Beauchamp","Xiaoding Lu","Thomas Rialan","William Beauchamp"],"pdf_url":"https://arxiv.org/pdf/2303.06135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.16711v2","updated":"2023-03-10T18:47:11Z","published":"2022-03-30T23:24:06Z","title":"An analytic theory for the dynamics of wide quantum neural networks","summary":"  Parameterized quantum circuits can be used as quantum neural networks and\nhave the potential to outperform their classical counterparts when trained for\naddressing learning problems. To date, much of the results on their performance\non practical problems are heuristic in nature. In particular, the convergence\nrate for the training of quantum neural networks is not fully understood. Here,\nwe analyze the dynamics of gradient descent for the training error of a class\nof variational quantum machine learning models. We define wide quantum neural\nnetworks as parameterized quantum circuits in the limit of a large number of\nqubits and variational parameters. We then find a simple analytic formula that\ncaptures the average behavior of their loss function and discuss the\nconsequences of our findings. For example, for random quantum circuits, we\npredict and characterize an exponential decay of the residual training error as\na function of the parameters of the system. We finally validate our analytic\nresults with numerical experiments.\n","authors":["Junyu Liu","Khadijeh Najafi","Kunal Sharma","Francesco Tacchino","Liang Jiang","Antonio Mezzacapo"],"pdf_url":"https://arxiv.org/pdf/2203.16711v2.pdf","comment":"37 pages, many figures. v2: adding learning supervised perspectives\n  and new results, close to published version"},{"id":"http://arxiv.org/abs/2303.06124v1","updated":"2023-03-10T18:37:43Z","published":"2023-03-10T18:37:43Z","title":"Self-supervised Training Sample Difficulty Balancing for Local\n  Descriptor Learning","summary":"  In the case of an imbalance between positive and negative samples, hard\nnegative mining strategies have been shown to help models learn more subtle\ndifferences between positive and negative samples, thus improving recognition\nperformance. However, if too strict mining strategies are promoted in the\ndataset, there may be a risk of introducing false negative samples. Meanwhile,\nthe implementation of the mining strategy disrupts the difficulty distribution\nof samples in the real dataset, which may cause the model to over-fit these\ndifficult samples. Therefore, in this paper, we investigate how to trade off\nthe difficulty of the mined samples in order to obtain and exploit high-quality\nnegative samples, and try to solve the problem in terms of both the loss\nfunction and the training strategy. The proposed balance loss provides an\neffective discriminant for the quality of negative samples by combining a\nself-supervised approach to the loss function, and uses a dynamic gradient\nmodulation strategy to achieve finer gradient adjustment for samples of\ndifferent difficulties. The proposed annealing training strategy then\nconstrains the difficulty of the samples drawn from negative sample mining to\nprovide data sources with different difficulty distributions for the loss\nfunction, and uses samples of decreasing difficulty to train the model.\nExtensive experiments show that our new descriptors outperform previous\nstate-of-the-art descriptors for patch validation, matching, and retrieval\ntasks.\n","authors":["Jiahan Zhang","Dayong Tian"],"pdf_url":"https://arxiv.org/pdf/2303.06124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06121v1","updated":"2023-03-10T18:31:50Z","published":"2023-03-10T18:31:50Z","title":"Ignorance is Bliss: Robust Control via Information Gating","summary":"  Informational parsimony -- i.e., using the minimal information required for a\ntask, -- provides a useful inductive bias for learning representations that\nachieve better generalization by being robust to noise and spurious\ncorrelations. We propose information gating in the pixel space as a way to\nlearn more parsimonious representations. Information gating works by learning\nmasks that capture only the minimal information required to solve a given task.\nIntuitively, our models learn to identify which visual cues actually matter for\na given task. We gate information using a differentiable parameterization of\nthe signal-to-noise ratio, which can be applied to arbitrary values in a\nnetwork, e.g.~masking out pixels at the input layer. We apply our approach,\nwhich we call InfoGating, to various objectives such as: multi-step forward and\ninverse dynamics, Q-learning, behavior cloning, and standard self-supervised\ntasks. Our experiments show that learning to identify and use minimal\ninformation can improve generalization in downstream tasks -- e.g., policies\nbased on info-gated images are considerably more robust to\ndistracting/irrelevant visual features.\n","authors":["Manan Tomar","Riashat Islam","Sergey Levine","Philip Bachman"],"pdf_url":"https://arxiv.org/pdf/2303.06121v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10418v2","updated":"2023-03-10T18:17:34Z","published":"2023-01-25T05:56:53Z","title":"DEJA VU: Continual Model Generalization For Unseen Domains","summary":"  In real-world applications, deep learning models often run in non-stationary\nenvironments where the target data distribution continually shifts over time.\nThere have been numerous domain adaptation (DA) methods in both online and\noffline modes to improve cross-domain adaptation ability. However, these DA\nmethods typically only provide good performance after a long period of\nadaptation, and perform poorly on new domains before and during adaptation - in\nwhat we call the \"Unfamiliar Period\", especially when domain shifts happen\nsuddenly and significantly. On the other hand, domain generalization (DG)\nmethods have been proposed to improve the model generalization ability on\nunadapted domains. However, existing DG works are ineffective for continually\nchanging domains due to severe catastrophic forgetting of learned knowledge. To\novercome these limitations of DA and DG in handling the Unfamiliar Period\nduring continual domain shift, we propose RaTP, a framework that focuses on\nimproving models' target domain generalization (TDG) capability, while also\nachieving effective target domain adaptation (TDA) capability right after\ntraining on certain domains and forgetting alleviation (FA) capability on past\ndomains. RaTP includes a training-free data augmentation module to prepare data\nfor TDG, a novel pseudo-labeling mechanism to provide reliable supervision for\nTDA, and a prototype contrastive alignment algorithm to align different domains\nfor achieving TDG, TDA and FA. Extensive experiments on Digits, PACS, and\nDomainNet demonstrate that RaTP significantly outperforms state-of-the-art\nworks from Continual DA, Source-Free DA, Test-Time/Online DA, Single DG,\nMultiple DG and Unified DA&DG in TDG, and achieves comparable TDA and FA\ncapabilities.\n","authors":["Chenxi Liu","Lixu Wang","Lingjuan Lyu","Chen Sun","Xiao Wang","Qi Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.10418v2.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.05344v2","updated":"2023-03-10T18:14:19Z","published":"2023-03-09T15:42:01Z","title":"Recent Advances of Deep Robotic Affordance Learning: A Reinforcement\n  Learning Perspective","summary":"  As a popular concept proposed in the field of psychology, affordance has been\nregarded as one of the important abilities that enable humans to understand and\ninteract with the environment. Briefly, it captures the possibilities and\neffects of the actions of an agent applied to a specific object or, more\ngenerally, a part of the environment. This paper provides a short review of the\nrecent developments of deep robotic affordance learning (DRAL), which aims to\ndevelop data-driven methods that use the concept of affordance to aid in\nrobotic tasks. We first classify these papers from a reinforcement learning\n(RL) perspective, and draw connections between RL and affordances. The\ntechnical details of each category are discussed and their limitations\nidentified. We further summarise them and identify future challenges from the\naspects of observations, actions, affordance representation, data-collection\nand real-world deployment. A final remark is given at the end to propose a\npromising future direction of the RL-based affordance definition to include the\npredictions of arbitrary action consequences.\n","authors":["Xintong Yang","Ze Ji","Jing Wu","Yu-kun Lai"],"pdf_url":"https://arxiv.org/pdf/2303.05344v2.pdf","comment":"This paper is under review"},{"id":"http://arxiv.org/abs/2301.11826v3","updated":"2023-03-10T18:13:57Z","published":"2023-01-27T16:27:18Z","title":"Deep Clustering Survival Machines with Interpretable Expert\n  Distributions","summary":"  Conventional survival analysis methods are typically ineffective to\ncharacterize heterogeneity in the population while such information can be used\nto assist predictive modeling. In this study, we propose a hybrid survival\nanalysis method, referred to as deep clustering survival machines, that\ncombines the discriminative and generative mechanisms. Similar to the mixture\nmodels, we assume that the timing information of survival data is generatively\ndescribed by a mixture of certain numbers of parametric distributions, i.e.,\nexpert distributions. We learn weights of the expert distributions for\nindividual instances according to their features discriminatively such that\neach instance's survival information can be characterized by a weighted\ncombination of the learned constant expert distributions. This method also\nfacilitates interpretable subgrouping/clustering of all instances according to\ntheir associated expert distributions. Extensive experiments on both real and\nsynthetic datasets have demonstrated that the method is capable of obtaining\npromising clustering results and competitive time-to-event predicting\nperformance.\n","authors":["Bojian Hou","Hongming Li","Zhicheng Jiao","Zhen Zhou","Hao Zheng","Yong Fan"],"pdf_url":"https://arxiv.org/pdf/2301.11826v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.15465v5","updated":"2023-03-10T18:05:56Z","published":"2020-12-31T06:39:22Z","title":"Accelerating ODE-Based Neural Networks on Low-Cost FPGAs","summary":"  ODENet is a deep neural network architecture in which a stacking structure of\nResNet is implemented with an ordinary differential equation (ODE) solver. It\ncan reduce the number of parameters and strike a balance between accuracy and\nperformance by selecting a proper solver. It is also possible to improve the\naccuracy while keeping the same number of parameters on resource-limited edge\ndevices. In this paper, using Euler method as an ODE solver, a part of ODENet\nis implemented as a dedicated logic on a low-cost FPGA (Field-Programmable Gate\nArray) board, such as PYNQ-Z2 board. As ODENet variants, reduced ODENets\n(rODENets) each of which heavily uses a part of ODENet layers and\nreduces/eliminates some layers differently are proposed and analyzed for\nlow-cost FPGA implementation. They are evaluated in terms of parameter size,\naccuracy, execution time, and resource utilization on the FPGA. The results\nshow that an overall execution time of an rODENet variant is improved by up to\n2.66 times compared to a pure software execution while keeping a comparable\naccuracy to the original ODENet.\n","authors":["Hirohisa Watanabe","Hiroki Matsutani"],"pdf_url":"https://arxiv.org/pdf/2012.15465v5.pdf","comment":"RAW'21"},{"id":"http://arxiv.org/abs/2303.06109v1","updated":"2023-03-10T17:57:40Z","published":"2023-03-10T17:57:40Z","title":"On the Fusion Strategies for Federated Decision Making","summary":"  We consider the problem of information aggregation in federated decision\nmaking, where a group of agents collaborate to infer the underlying state of\nnature without sharing their private data with the central processor or each\nother. We analyze the non-Bayesian social learning strategy in which agents\nincorporate their individual observations into their opinions (i.e.,\nsoft-decisions) with Bayes rule, and the central processor aggregates these\nopinions by arithmetic or geometric averaging. Building on our previous work,\nwe establish that both pooling strategies result in asymptotic normality\ncharacterization of the system, which, for instance, can be utilized in order\nto give approximate expressions for the error probability. We verify the\ntheoretical findings with simulations and compare both strategies.\n","authors":["Mert Kayaalp","Yunus Inan","Visa Koivunen","Emre Telatar","Ali H. Sayed"],"pdf_url":"https://arxiv.org/pdf/2303.06109v1.pdf","comment":"Submitted for publication"},{"id":"http://arxiv.org/abs/2209.06119v4","updated":"2023-03-10T17:31:32Z","published":"2022-09-10T14:26:04Z","title":"APTx: better activation function than MISH, SWISH, and ReLU's variants\n  used in deep learning","summary":"  Activation Functions introduce non-linearity in the deep neural networks.\nThis nonlinearity helps the neural networks learn faster and efficiently from\nthe dataset. In deep learning, many activation functions are developed and used\nbased on the type of problem statement. ReLU's variants, SWISH, and MISH are\ngoto activation functions. MISH function is considered having similar or even\nbetter performance than SWISH, and much better than ReLU. In this paper, we\npropose an activation function named APTx which behaves similar to MISH, but\nrequires lesser mathematical operations to compute. The lesser computational\nrequirements of APTx does speed up the model training, and thus also reduces\nthe hardware requirement for the deep learning model.\n","authors":["Ravin Kumar"],"pdf_url":"https://arxiv.org/pdf/2209.06119v4.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.06095v1","updated":"2023-03-10T17:24:41Z","published":"2023-03-10T17:24:41Z","title":"HiNet: A Novel Multi-Scenario & Multi-Task Learning Approach with\n  Hierarchical Information Extraction","summary":"  Multi-scenario & multi-task learning has been widely applied to many\nrecommendation systems in industrial applications, wherein an effective and\npractical approach is to carry out multi-scenario transfer learning on the\nbasis of the Mixture-of-Expert (MoE) architecture. However, the MoE-based\nmethod, which aims to project all information in the same feature space, cannot\neffectively deal with the complex relationships inherent among various\nscenarios and tasks, resulting in unsatisfactory performance. To tackle the\nproblem, we propose a Hierarchical information extraction Network (HiNet) for\nmulti-scenario and multi-task recommendation, which achieves hierarchical\nextraction based on coarse-to-fine knowledge transfer scheme. The multiple\nextraction layers of the hierarchical network enable the model to enhance the\ncapability of transferring valuable information across scenarios while\npreserving specific features of scenarios and tasks. Furthermore, a novel\nscenario-aware attentive network module is proposed to model correlations\nbetween scenarios explicitly. Comprehensive experiments conducted on real-world\nindustrial datasets from Meituan Meishi platform demonstrate that HiNet\nachieves a new state-of-the-art performance and significantly outperforms\nexisting solutions. HiNet is currently fully deployed in two scenarios and has\nachieved 2.87% and 1.75% order quantity gain respectively.\n","authors":["Jie Zhou","Xianshuai Cao","Wenhao Li","Kun Zhang","Chuan Luo","Qian Yu"],"pdf_url":"https://arxiv.org/pdf/2303.06095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01910v2","updated":"2023-03-10T17:20:17Z","published":"2022-11-03T15:43:03Z","title":"Large Language Models Are Human-Level Prompt Engineers","summary":"  By conditioning on natural language instructions, large language models\n(LLMs) have displayed impressive capabilities as general-purpose computers.\nHowever, task performance depends significantly on the quality of the prompt\nused to steer the model, and most effective prompts have been handcrafted by\nhumans. Inspired by classical program synthesis and the human approach to\nprompt engineering, we propose Automatic Prompt Engineer (APE) for automatic\ninstruction generation and selection. In our method, we treat the instruction\nas the \"program,\" optimized by searching over a pool of instruction candidates\nproposed by an LLM in order to maximize a chosen score function. To evaluate\nthe quality of the selected instruction, we evaluate the zero-shot performance\nof another LLM following the selected instruction. Experiments on 24 NLP tasks\nshow that our automatically generated instructions outperform the prior LLM\nbaseline by a large margin and achieve better or comparable performance to the\ninstructions generated by human annotators on 19/24 tasks. We conduct extensive\nqualitative and quantitative analyses to explore the performance of APE. We\nshow that APE-engineered prompts can be applied to steer models toward\ntruthfulness and/or informativeness, as well as to improve few-shot learning\nperformance by simply prepending them to standard in-context learning prompts.\nPlease check out our webpage at\nhttps://sites.google.com/view/automatic-prompt-engineer.\n","authors":["Yongchao Zhou","Andrei Ioan Muresanu","Ziwen Han","Keiran Paster","Silviu Pitis","Harris Chan","Jimmy Ba"],"pdf_url":"https://arxiv.org/pdf/2211.01910v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06078v1","updated":"2023-03-10T16:56:09Z","published":"2023-03-10T16:56:09Z","title":"An End-to-End Neural Network for Image-to-Audio Transformation","summary":"  This paper describes an end-to-end (E2E) neural architecture for the audio\nrendering of small portions of display content on low resource personal\ncomputing devices. It is intended to address the problem of accessibility for\nvision-impaired or vision-distracted users at the hardware level. Neural\nimage-to-text (ITT) and text-to-speech (TTS) approaches are reviewed and a new\ntechnique is introduced to efficiently integrate them in a way that is both\nefficient and back-propagate-able, leading to a non-autoregressive E2E\nimage-to-speech (ITS) neural network that is efficient and trainable.\nExperimental results are presented showing that, compared with the non-E2E\napproach, the proposed E2E system is 29% faster and uses 19% fewer parameters\nwith a 2% reduction in phone accuracy. A future direction to address accuracy\nis presented.\n","authors":["Liu Chen","Michael Deisher","Munir Georges"],"pdf_url":"https://arxiv.org/pdf/2303.06078v1.pdf","comment":"5 pages, 3 figures, 2023 IEEE Conference on Acoustics, Speech, and\n  Signal Processing"},{"id":"http://arxiv.org/abs/2303.02262v2","updated":"2023-03-10T16:51:19Z","published":"2023-03-03T23:31:15Z","title":"Locally Regularized Neural Differential Equations: Some Black Boxes Were\n  Meant to Remain Closed!","summary":"  Implicit layer deep learning techniques, like Neural Differential Equations,\nhave become an important modeling framework due to their ability to adapt to\nnew problems automatically. Training a neural differential equation is\neffectively a search over a space of plausible dynamical systems. However,\ncontrolling the computational cost for these models is difficult since it\nrelies on the number of steps the adaptive solver takes. Most prior works have\nused higher-order methods to reduce prediction timings while greatly increasing\ntraining time or reducing both training and prediction timings by relying on\nspecific training algorithms, which are harder to use as a drop-in replacement\ndue to strict requirements on automatic differentiation. In this manuscript, we\nuse internal cost heuristics of adaptive differential equation solvers at\nstochastic time points to guide the training toward learning a dynamical system\nthat is easier to integrate. We \"close the black-box\" and allow the use of our\nmethod with any adjoint technique for gradient calculations of the differential\nequation solution. We perform experimental studies to compare our method to\nglobal regularization to show that we attain similar performance numbers\nwithout compromising the flexibility of implementation on ordinary differential\nequations (ODEs) and stochastic differential equations (SDEs). We develop two\nsampling strategies to trade off between performance and training time. Our\nmethod reduces the number of function evaluations to 0.556-0.733x and\naccelerates predictions by 1.3-2x.\n","authors":["Avik Pal","Alan Edelman","Chris Rackauckas"],"pdf_url":"https://arxiv.org/pdf/2303.02262v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11770v2","updated":"2023-03-10T16:48:23Z","published":"2022-12-22T15:06:21Z","title":"S-Graphs+: Real-time Localization and Mapping leveraging Hierarchical\n  Representations","summary":"  In this paper, we present an evolved version of the Situational Graphs, which\njointly models in a single optimizable factor graph, a SLAM graph, as a set of\nrobot keyframes, containing its associated measurements and robot poses, and a\n3D scene graph, as a high-level representation of the environment that encodes\nits different geometric elements with semantic attributes and the relational\ninformation between those elements. Our proposed S-Graphs+ is a novel\nfour-layered factor graph that includes: (1) a keyframes layer with robot pose\nestimates, (2) a walls layer representing wall surfaces, (3) a rooms layer\nencompassing sets of wall planes, and (4) a floors layer gathering the rooms\nwithin a given floor level. The above graph is optimized in real-time to obtain\na robust and accurate estimate of the robot's pose and its map, simultaneously\nconstructing and leveraging the high-level information of the environment. To\nextract such high-level information, we present novel room and floor\nsegmentation algorithms utilizing the mapped wall planes and free-space\nclusters. We tested S-Graphs+ on multiple datasets including, simulations of\ndistinct indoor environments, on real datasets captured over several\nconstruction sites and office environments, and on a real public dataset of\nindoor office environments. S-Graphs+ outperforms relevant baselines in the\nmajority of the datasets while extending the robot situational awareness by a\nfour-layered scene model. Moreover, we make the algorithm available as a docker\nfile.\n","authors":["Hriday Bavle","Jose Luis Sanchez-Lopez","Muhammad Shaheer","Javier Civera","Holger Voos"],"pdf_url":"https://arxiv.org/pdf/2212.11770v2.pdf","comment":"8 Pages, 7 Figures, 3 Tables"},{"id":"http://arxiv.org/abs/2303.06053v1","updated":"2023-03-10T16:41:24Z","published":"2023-03-10T16:41:24Z","title":"TSMixer: An all-MLP Architecture for Time Series Forecasting","summary":"  Real-world time-series datasets are often multivariate with complex dynamics.\nCommonly-used high capacity architectures like recurrent- or attention-based\nsequential models have become popular. However, recent work demonstrates that\nsimple univariate linear models can outperform those deep alternatives. In this\npaper, we investigate the capabilities of linear models for time-series\nforecasting and present Time-Series Mixer (TSMixer), an architecture designed\nby stacking multi-layer perceptrons (MLPs). TSMixer is based on mixing\noperations along time and feature dimensions to extract information\nefficiently. On popular academic benchmarks, the simple-to-implement TSMixer is\ncomparable to specialized state-of-the-art models that leverage the inductive\nbiases of specific benchmarks. On the challenging and large scale M5 benchmark,\na real-world retail dataset, TSMixer demonstrates superior performance compared\nto the state-of-the-art alternatives. Our results underline the importance of\nefficiently utilizing cross-variate and auxiliary information for improving the\nperformance of time series forecasting. The design paradigms utilized in\nTSMixer are expected to open new horizons for deep learning-based time series\nforecasting.\n","authors":["Si-An Chen","Chun-Liang Li","Nate Yoder","Sercan O. Arik","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2303.06053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06050v1","updated":"2023-03-10T16:40:12Z","published":"2023-03-10T16:40:12Z","title":"Optimal foraging strategies can be learned and outperform Lévy walks","summary":"  L\\'evy walks and other theoretical models of optimal foraging have been\nsuccessfully used to describe real-world scenarios, attracting attention in\nseveral fields such as economy, physics, ecology, and evolutionary biology.\nHowever, it remains unclear in most cases which strategies maximize foraging\nefficiency and whether such strategies can be learned by living organisms. To\naddress these questions, we model foragers as reinforcement learning agents. We\nfirst prove theoretically that maximizing rewards in our reinforcement learning\nmodel is equivalent to optimizing foraging efficiency. We then show with\nnumerical experiments that our agents learn foraging strategies which\noutperform the efficiency of known strategies such as L\\'evy walks.\n","authors":["Gorka Muñoz-Gil","Andrea López-Incera","Lukas J. Fiderer","Hans J. Briegel"],"pdf_url":"https://arxiv.org/pdf/2303.06050v1.pdf","comment":"11 pages (6 main text) and 8 figures"},{"id":"http://arxiv.org/abs/2303.06034v1","updated":"2023-03-10T16:27:37Z","published":"2023-03-10T16:27:37Z","title":"Tactile-Filter: Interactive Tactile Perception for Part Mating","summary":"  Humans rely on touch and tactile sensing for a lot of dexterous manipulation\ntasks. Our tactile sensing provides us with a lot of information regarding\ncontact formations as well as geometric information about objects during any\ninteraction. With this motivation, vision-based tactile sensors are being\nwidely used for various robotic perception and control tasks. In this paper, we\npresent a method for interactive perception using vision-based tactile sensors\nfor multi-object assembly. In particular, we are interested in tactile\nperception during part mating, where a robot can use tactile sensors and a\nfeedback mechanism using particle filter to incrementally improve its estimate\nof objects that fit together for assembly. To do this, we first train a deep\nneural network that makes use of tactile images to predict the probabilistic\ncorrespondence between arbitrarily shaped objects that fit together. The\ntrained model is used to design a particle filter which is used twofold. First,\ngiven one partial (or non-unique) observation of the hole, it incrementally\nimproves the estimate of the correct peg by sampling more tactile observations.\nSecond, it selects the next action for the robot to sample the next touch (and\nthus image) which results in maximum uncertainty reduction to minimize the\nnumber of interactions during the perception task. We evaluate our method on\nseveral part-mating tasks for assembly using a robot equipped with a\nvision-based tactile sensor. We also show the efficiency of the proposed action\nselection method against a naive method. See supplementary video at\nhttps://www.youtube.com/watch?v=jMVBg_e3gLw .\n","authors":["Kei Ota","Devesh K. Jha","Hsiao-Yu Tung","Joshua B. Tenenbaum"],"pdf_url":"https://arxiv.org/pdf/2303.06034v1.pdf","comment":"under submission"},{"id":"http://arxiv.org/abs/2210.15305v3","updated":"2023-03-10T16:14:05Z","published":"2022-10-27T10:29:19Z","title":"Deformable Temporal Convolutional Networks for Monaural Noisy\n  Reverberant Speech Separation","summary":"  Speech separation models are used for isolating individual speakers in many\nspeech processing applications. Deep learning models have been shown to lead to\nstate-of-the-art (SOTA) results on a number of speech separation benchmarks.\nOne such class of models known as temporal convolutional networks (TCNs) has\nshown promising results for speech separation tasks. A limitation of these\nmodels is that they have a fixed receptive field (RF). Recent research in\nspeech dereverberation has shown that the optimal RF of a TCN varies with the\nreverberation characteristics of the speech signal. In this work deformable\nconvolution is proposed as a solution to allow TCN models to have dynamic RFs\nthat can adapt to various reverberation times for reverberant speech\nseparation. The proposed models are capable of achieving an 11.1 dB average\nscale-invariant signalto-distortion ratio (SISDR) improvement over the input\nsignal on the WHAMR benchmark. A relatively small deformable TCN model of 1.3M\nparameters is proposed which gives comparable separation performance to larger\nand more computationally complex models.\n","authors":["William Ravenscroft","Stefan Goetze","Thomas Hain"],"pdf_url":"https://arxiv.org/pdf/2210.15305v3.pdf","comment":"Accepted for ICASSP 2023"},{"id":"http://arxiv.org/abs/2301.10347v2","updated":"2023-03-10T15:55:10Z","published":"2023-01-24T23:24:47Z","title":"GePA*SE: Generalized Edge-Based Parallel A* for Slow Evaluations","summary":"  Parallel search algorithms have been shown to improve planning speed by\nharnessing the multithreading capability of modern processors. One such\nalgorithm PA*SE achieves this by parallelizing state expansions, whereas\nanother algorithm ePA*SE achieves this by effectively parallelizing edge\nevaluations. ePA*SE targets domains in which the action space comprises actions\nwith expensive but similar evaluation times. However, in a number of robotics\ndomains, the action space is heterogenous in the computational effort required\nto evaluate the cost of an action and its outcome. Motivated by this, we\nintroduce GePA*SE: Generalized Edge-based Parallel A* for Slow Evaluations,\nwhich generalizes the key ideas of PA*SE and ePA*SE i.e. parallelization of\nstate expansions and edge evaluations respectively. This extends its\napplicability to domains that have actions requiring varying computational\neffort to evaluate them. The open-source code for GePA*SE along with the\nbaselines is available here: https://github.com/shohinm/parallel_search\n","authors":["Shohin Mukherjee","Maxim Likhachev"],"pdf_url":"https://arxiv.org/pdf/2301.10347v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05983v1","updated":"2023-03-10T15:35:11Z","published":"2023-03-10T15:35:11Z","title":"New Benchmarks for Accountable Text-based Visual Re-creation","summary":"  Given a command, humans can directly execute the action after thinking or\nchoose to reject it, with reasonable feedback at the same time. However, the\nbehavior of existing text-to-image generation methods are uncontrollable and\nirresponsible. In this paper, we construct extensive experiments to verify\nwhether they can be accountable (say no and explain why) for those prohibited\ninstructions. To this end, we define a novel text-based visual re-creation task\nand construct new synthetic CLEVR-NOT dataset (620K) and manually pictured\nFruit-NOT dataset (50K). In our method, one text-image pair as the query is fed\ninto the machine, and the model gives a yes or no answer after visual and\ntextual reasoning. If the answer is yes, the image auto-encoder and\nauto-regressive transformer must complete the visual re-creation under the\npremise of ensuring image quality, otherwise the system needs to explain why\nthe commands cannot be completed or prohibited. We provide a detailed analysis\nof experimental results in image quality, answer accuracy, and model behavior\nin the face of uncertainty and imperfect user queries. Our results demonstrate\nthe difficulty of a single model for both textual and visual reasoning. We also\nhope our explorations and findings can bring valuable insights about the\naccountability of text-based image generation models. Code and datasets can be\nfound at https://matrix-alpha.github.io.\n","authors":["Zhiwei Zhang","Yuliang Liu"],"pdf_url":"https://arxiv.org/pdf/2303.05983v1.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.05972v1","updated":"2023-03-10T15:05:32Z","published":"2023-03-10T15:05:32Z","title":"Classifying the evolution of COVID-19 severity on patients with combined\n  dynamic Bayesian networks and neural networks","summary":"  When we face patients arriving to a hospital suffering from the effects of\nsome illness, one of the main problems we can encounter is evaluating whether\nor not said patients are going to require intensive care in the near future.\nThis intensive care requires allotting valuable and scarce resources, and\nknowing beforehand the severity of a patients illness can improve both its\ntreatment and the organization of resources. We illustrate this issue in a\ndataset consistent of Spanish COVID-19 patients from the sixth epidemic wave\nwhere we label patients as critical when they either had to enter the intensive\ncare unit or passed away. We then combine the use of dynamic Bayesian networks,\nto forecast the vital signs and the blood analysis results of patients over the\nnext 40 hours, and neural networks, to evaluate the severity of a patients\ndisease in that interval of time. Our empirical results show that the\ntransposition of the current state of a patient to future values with the DBN\nfor its subsequent use in classification obtains better the accuracy and g-mean\nscore than a direct application with a classifier.\n","authors":["David Quesada","Pedro Larrañaga","Concha Bielza"],"pdf_url":"https://arxiv.org/pdf/2303.05972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.04530v2","updated":"2023-03-10T14:41:21Z","published":"2022-06-09T14:25:14Z","title":"DORA: Exploring outlier representations in Deep Neural Networks","summary":"  Deep Neural Networks (DNNs) draw their power from the representations they\nlearn. However, while being incredibly effective in learning complex\nabstractions, they are susceptible to learning malicious concepts, due to the\nspurious correlations inherent in the training data. So far, existing methods\nfor uncovering such artifactual behavior in trained models focus on finding\nartifacts in the input data, which requires both availability of a data set and\nhuman supervision. In this paper, we introduce DORA (Data-agnOstic\nRepresentation Analysis): the first data-agnostic framework for the analysis of\nthe representation space of DNNs. We propose a novel distance measure between\nrepresentations that utilizes self-explaining capabilities within the network\nitself without access to any data and quantitatively validate its alignment\nwith human-defined semantic distances. We further demonstrate that this metric\ncould be utilized for the detection of anomalous representations, which may\nbear a risk of learning unintended spurious concepts deviating from the desired\ndecision-making policy. Finally, we demonstrate the practical utility of DORA\nby analyzing and identifying artifactual representations in widely popular\nComputer Vision models.\n","authors":["Kirill Bykov","Mayukh Deb","Dennis Grinwald","Klaus-Robert Müller","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2206.04530v2.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2303.05952v1","updated":"2023-03-10T14:38:49Z","published":"2023-03-10T14:38:49Z","title":"Understanding and Constructing Latent Modality Structures in Multi-modal\n  Representation Learning","summary":"  Contrastive loss has been increasingly used in learning representations from\nmultiple modalities. In the limit, the nature of the contrastive loss\nencourages modalities to exactly match each other in the latent space. Yet it\nremains an open question how the modality alignment affects the downstream task\nperformance. In this paper, based on an information-theoretic argument, we\nfirst prove that exact modality alignment is sub-optimal in general for\ndownstream prediction tasks. Hence we advocate that the key of better\nperformance lies in meaningful latent modality structures instead of perfect\nmodality alignment. To this end, we propose three general approaches to\nconstruct latent modality structures. Specifically, we design 1) a deep feature\nseparation loss for intra-modality regularization; 2) a Brownian-bridge loss\nfor inter-modality regularization; and 3) a geometric consistency loss for both\nintra- and inter-modality regularization. Extensive experiments are conducted\non two popular multi-modal representation learning frameworks: the CLIP-based\ntwo-tower model and the ALBEF-based fusion model. We test our model on a\nvariety of tasks including zero/few-shot image classification, image-text\nretrieval, visual question answering, visual reasoning, and visual entailment.\nOur method achieves consistent improvements over existing methods,\ndemonstrating the effectiveness and generalizability of our proposed approach\non latent modality structure regularization.\n","authors":["Qian Jiang","Changyou Chen","Han Zhao","Liqun Chen","Qing Ping","Son Dinh Tran","Yi Xu","Belinda Zeng","Trishul Chilimbi"],"pdf_url":"https://arxiv.org/pdf/2303.05952v1.pdf","comment":"14 pages, 8 figure, CVPR 2023 accepted"},{"id":"http://arxiv.org/abs/2210.00954v2","updated":"2023-03-10T14:28:57Z","published":"2022-10-03T14:11:33Z","title":"Machine Learning-powered Course Allocation","summary":"  We introduce a machine learning-powered course allocation mechanism.\nConcretely, we extend the state-of-the-art Course Match mechanism with a\nmachine learning-based preference elicitation module. In an iterative,\nasynchronous manner, this module generates pairwise comparison queries that are\ntailored to each individual student. Regarding incentives, our machine\nlearning-powered course match (MLCM) mechanism retains the attractive\nstrategyproofness in the large property of Course Match. Regarding welfare, we\nperform computational experiments using a simulator that was fitted to\nreal-world data. Our results show that, compared to Course Match, MLCM\nincreases average student utility by 4%-9% and minimum student utility by\n10%-21%, even with only ten comparison queries. Finally, we highlight the\npracticability of MLCM and the ease of piloting it for universities currently\nusing Course Match.\n","authors":["Ermis Soumalias","Behnoosh Zamanlooy","Jakob Weissteiner","Sven Seuken"],"pdf_url":"https://arxiv.org/pdf/2210.00954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09617v2","updated":"2023-03-10T13:09:10Z","published":"2022-09-20T11:23:19Z","title":"Seq2Seq Surrogates of Epidemic Models to Facilitate Bayesian Inference","summary":"  Epidemic models are powerful tools in understanding infectious disease.\nHowever, as they increase in size and complexity, they can quickly become\ncomputationally intractable. Recent progress in modelling methodology has shown\nthat surrogate models can be used to emulate complex epidemic models with a\nhigh-dimensional parameter space. We show that deep sequence-to-sequence\n(seq2seq) models can serve as accurate surrogates for complex epidemic models\nwith sequence based model parameters, effectively replicating seasonal and\nlong-term transmission dynamics. Once trained, our surrogate can predict\nscenarios a several thousand times faster than the original model, making them\nideal for policy exploration. We demonstrate that replacing a traditional\nepidemic model with a learned simulator facilitates robust Bayesian inference.\n","authors":["Giovanni Charles","Timothy M. Wolock","Peter Winskill","Azra Ghani","Samir Bhatt","Seth Flaxman"],"pdf_url":"https://arxiv.org/pdf/2209.09617v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.04599v2","updated":"2023-03-10T12:19:25Z","published":"2023-02-09T12:21:55Z","title":"Principled and Efficient Motif Finding for Structure Learning of Lifted\n  Graphical Models","summary":"  Structure learning is a core problem in AI central to the fields of\nneuro-symbolic AI and statistical relational learning. It consists in\nautomatically learning a logical theory from data. The basis for structure\nlearning is mining repeating patterns in the data, known as structural motifs.\nFinding these patterns reduces the exponential search space and therefore\nguides the learning of formulas. Despite the importance of motif learning, it\nis still not well understood. We present the first principled approach for\nmining structural motifs in lifted graphical models, languages that blend\nfirst-order logic with probabilistic models, which uses a stochastic process to\nmeasure the similarity of entities in the data. Our first contribution is an\nalgorithm, which depends on two intuitive hyperparameters: one controlling the\nuncertainty in the entity similarity measure, and one controlling the softness\nof the resulting rules. Our second contribution is a preprocessing step where\nwe perform hierarchical clustering on the data to reduce the search space to\nthe most relevant data. Our third contribution is to introduce an O(n ln n) (in\nthe size of the entities in the data) algorithm for clustering\nstructurally-related data. We evaluate our approach using standard benchmarks\nand show that we outperform state-of-the-art structure learning approaches by\nup to 6% in terms of accuracy and up to 80% in terms of runtime.\n","authors":["Jonathan Feldstein","Dominic Phillips","Efthymia Tsamoura"],"pdf_url":"https://arxiv.org/pdf/2302.04599v2.pdf","comment":"Submitted to AAAI23. 9 pages. Appendix included"},{"id":"http://arxiv.org/abs/2104.06714v5","updated":"2023-03-10T12:18:38Z","published":"2021-04-14T09:17:18Z","title":"Lazy Parameter Tuning and Control: Choosing All Parameters Randomly From\n  a Power-Law Distribution","summary":"  Most evolutionary algorithms have multiple parameters and their values\ndrastically affect the performance. Due to the often complicated interplay of\nthe parameters, setting these values right for a particular problem (parameter\ntuning) is a challenging task. This task becomes even more complicated when the\noptimal parameter values change significantly during the run of the algorithm\nsince then a dynamic parameter choice (parameter control) is necessary.\n  In this work, we propose a lazy but effective solution, namely choosing all\nparameter values (where this makes sense) in each iteration randomly from a\nsuitably scaled power-law distribution. To demonstrate the effectiveness of\nthis approach, we perform runtime analyses of the $(1+(\\lambda,\\lambda))$\ngenetic algorithm with all three parameters chosen in this manner. We show that\nthis algorithm on the one hand can imitate simple hill-climbers like the\n$(1+1)$ EA, giving the same asymptotic runtime on problems like OneMax,\nLeadingOnes, or Minimum Spanning Tree. On the other hand, this algorithm is\nalso very efficient on jump functions, where the best static parameters are\nvery different from those necessary to optimize simple problems. We prove a\nperformance guarantee that is comparable to the best performance known for\nstatic parameters. For the most interesting case that the jump size $k$ is\nconstant, we prove that our performance is asymptotically better than what can\nbe obtained with any static parameter choice. We complement our theoretical\nresults with a rigorous empirical study confirming what the asymptotic runtime\nresults suggest.\n","authors":["Denis Antipov","Maxim Buzdalov","Benjamin Doerr"],"pdf_url":"https://arxiv.org/pdf/2104.06714v5.pdf","comment":"Extended version of the paper that appeared at GECCO 2021. To appear\n  in Algorithmica"},{"id":"http://arxiv.org/abs/2303.05871v1","updated":"2023-03-10T11:51:22Z","published":"2023-03-10T11:51:22Z","title":"Accurate Real-time Polyp Detection in Videos from Concatenation of\n  Latent Features Extracted from Consecutive Frames","summary":"  An efficient deep learning model that can be implemented in real-time for\npolyp detection is crucial to reducing polyp miss-rate during screening\nprocedures. Convolutional neural networks (CNNs) are vulnerable to small\nchanges in the input image. A CNN-based model may miss the same polyp appearing\nin a series of consecutive frames and produce unsubtle detection output due to\nchanges in camera pose, lighting condition, light reflection, etc. In this\nstudy, we attempt to tackle this problem by integrating temporal information\namong neighboring frames. We propose an efficient feature concatenation method\nfor a CNN-based encoder-decoder model without adding complexity to the model.\nThe proposed method incorporates extracted feature maps of previous frames to\ndetect polyps in the current frame. The experimental results demonstrate that\nthe proposed method of feature concatenation improves the overall performance\nof automatic polyp detection in videos. The following results are obtained on a\npublic video dataset: sensitivity 90.94\\%, precision 90.53\\%, and specificity\n92.46%\n","authors":["Hemin Ali Qadir","Younghak Shin","Jacob Bergsland","Ilangko Balasingham"],"pdf_url":"https://arxiv.org/pdf/2303.05871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05866v1","updated":"2023-03-10T11:37:09Z","published":"2023-03-10T11:37:09Z","title":"On Exams with the Isabelle Proof Assistant","summary":"  We present an approach for testing student learning outcomes in a course on\nautomated reasoning using the Isabelle proof assistant. The approach allows us\nto test both general understanding of formal proofs in various logical proof\nsystems and understanding of proofs in the higher-order logic of Isabelle/HOL\nin particular. The use of Isabelle enables almost automatic grading of large\nparts of the exam. We explain our approach through a number of example\nproblems, and explain why we believe that each of the kinds of problems we have\nselected are adequate measures of our intended learning outcomes. Finally, we\ndiscuss our experiences using the approach for the exam of a course on\nautomated reasoning and suggest potential future work.\n","authors":["Frederik Krogsdal Jacobsen","Jørgen Villadsen"],"pdf_url":"https://arxiv.org/pdf/2303.05866v1.pdf","comment":"In Proceedings ThEdu'22, arXiv:2303.05360"},{"id":"http://arxiv.org/abs/2303.05863v1","updated":"2023-03-10T11:36:10Z","published":"2023-03-10T11:36:10Z","title":"A Rule Based Theorem Prover: an Introduction to Proofs in Secondary\n  Schools","summary":"  The introduction of automated deduction systems in secondary schools face\nseveral bottlenecks. Beyond the problems related with the curricula and the\nteachers, the dissonance between the outcomes of the geometry automated theorem\nprovers and the normal practice of conjecturing and proving in schools is a\nmajor barrier to a wider use of such tools in an educational environment. Since\nthe early implementations of geometry automated theorem provers, applications\nof artificial intelligence methods, synthetic provers based on inference rules\nand using forward chaining reasoning are considered to be more suited for\neducation proposes. Choosing an appropriate set of rules and an automated\nmethod that can use those rules is a major challenge. We discuss one such rule\nset and its implementation using the geometry deductive databases method\n(GDDM). The approach is tested using some chosen geometric conjectures that\ncould be the goal of a 7th year class (approx. 12-year-old students). A lesson\nplan is presented, its goal is the introduction of formal demonstration of\nproving geometric theorems, trying to motivate students to that goal\n","authors":["Joana Teles","Vanda Santos","Pedro Quaresma"],"pdf_url":"https://arxiv.org/pdf/2303.05863v1.pdf","comment":"In Proceedings ThEdu'22, arXiv:2303.05360"},{"id":"http://arxiv.org/abs/2303.05854v1","updated":"2023-03-10T11:06:43Z","published":"2023-03-10T11:06:43Z","title":"Lemmas: Generation, Selection, Application","summary":"  Noting that lemmas are a key feature of mathematics, we engage in an\ninvestigation of the role of lemmas in automated theorem proving. The paper\ndescribes experiments with a combined system involving learning technology that\ngenerates useful lemmas for automated theorem provers, demonstrating\nimprovement for several representative systems and solving a hard problem not\nsolved by any system for twenty years. By focusing on condensed detachment\nproblems we simplify the setting considerably, allowing us to get at the\nessence of lemmas and their role in proof search.\n","authors":["Michael Rawson","Christoph Wernhard","Zsolt Zombori","Wolfgang Bibel"],"pdf_url":"https://arxiv.org/pdf/2303.05854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.00767v2","updated":"2023-03-10T10:57:23Z","published":"2022-12-01T18:52:46Z","title":"Exploiting Proximity-Aware Tasks for Embodied Social Navigation","summary":"  Learning how to navigate among humans in an occluded and spatially\nconstrained indoor environment, is a key ability required to embodied agent to\nbe integrated into our society. In this paper, we propose an end-to-end\narchitecture that exploits Proximity-Aware Tasks (referred as to Risk and\nProximity Compass) to inject into a reinforcement learning navigation policy\nthe ability to infer common-sense social behaviors. To this end, our tasks\nexploit the notion of immediate and future dangers of collision. Furthermore,\nwe propose an evaluation protocol specifically designed for the Social\nNavigation Task in simulated environments. This is done to capture fine-grained\nfeatures and characteristics of the policy by analyzing the minimal unit of\nhuman-robot spatial interaction, called Encounter. We validate our approach on\nGibson4+ and Habitat-Matterport3D datasets.\n","authors":["Enrico Cancelli","Tommaso Campari","Luciano Serafini","Angel X. Chang","Lamberto Ballan"],"pdf_url":"https://arxiv.org/pdf/2212.00767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05848v1","updated":"2023-03-10T10:53:33Z","published":"2023-03-10T10:53:33Z","title":"Decision-Making Under Uncertainty: Beyond Probabilities","summary":"  This position paper reflects on the state-of-the-art in decision-making under\nuncertainty. A classical assumption is that probabilities can sufficiently\ncapture all uncertainty in a system. In this paper, the focus is on the\nuncertainty that goes beyond this classical interpretation, particularly by\nemploying a clear distinction between aleatoric and epistemic uncertainty. The\npaper features an overview of Markov decision processes (MDPs) and extensions\nto account for partial observability and adversarial behavior. These models\nsufficiently capture aleatoric uncertainty but fail to account for epistemic\nuncertainty robustly. Consequently, we present a thorough overview of so-called\nuncertainty models that exhibit uncertainty in a more robust interpretation. We\nshow several solution techniques for both discrete and continuous models,\nranging from formal verification, over control-based abstractions, to\nreinforcement learning. As an integral part of this paper, we list and discuss\nseveral key challenges that arise when dealing with rich types of uncertainty\nin a model-based fashion.\n","authors":["Thom Badings","Thiago D. Simão","Marnix Suilen","Nils Jansen"],"pdf_url":"https://arxiv.org/pdf/2303.05848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.03491v6","updated":"2023-03-10T10:34:33Z","published":"2022-06-07T07:45:45Z","title":"EiX-GNN : Concept-level eigencentrality explainer for graph neural\n  networks","summary":"  Nowadays, deep prediction models, especially graph neural networks, have a\nmajorplace in critical applications. In such context, those models need to be\nhighlyinterpretable or being explainable by humans, and at the societal scope,\nthis understandingmay also be feasible for humans that do not have a strong\nprior knowledgein models and contexts that need to be explained. In the\nliterature, explainingis a human knowledge transfer process regarding a\nphenomenon between an explainerand an explainee. We propose EiX-GNN\n(Eigencentrality eXplainer forGraph Neural Networks) a new powerful method for\nexplaining graph neural networksthat encodes computationally this social\nexplainer-to-explainee dependenceunderlying in the explanation process. To\nhandle this dependency, we introducethe notion of explainee concept\nassimibility which allows explainer to adapt itsexplanation to explainee\nbackground or expectation. We lead a qualitative studyto illustrate our\nexplainee concept assimibility notion on real-world data as wellas a\nqualitative study that compares, according to objective metrics established\ninthe literature, fairness and compactness of our method with respect to\nperformingstate-of-the-art methods. It turns out that our method achieves\nstrong results inboth aspects.\n","authors":["Adrien Raison","Pascal Bourdon","David Helbert"],"pdf_url":"https://arxiv.org/pdf/2206.03491v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05828v1","updated":"2023-03-10T10:02:18Z","published":"2023-03-10T10:02:18Z","title":"Contrastive Language-Image Pretrained (CLIP) Models are Powerful\n  Out-of-Distribution Detectors","summary":"  We present a comprehensive experimental study on pretrained feature\nextractors for visual out-of-distribution (OOD) detection. We examine several\nsetups, based on the availability of labels or image captions and using\ndifferent combinations of in- and out-distributions. Intriguingly, we find that\n(i) contrastive language-image pretrained models achieve state-of-the-art\nunsupervised out-of-distribution performance using nearest neighbors feature\nsimilarity as the OOD detection score, (ii) supervised state-of-the-art OOD\ndetection performance can be obtained without in-distribution fine-tuning,\n(iii) even top-performing billion-scale vision transformers trained with\nnatural language supervision fail at detecting adversarially manipulated OOD\nimages. Finally, we argue whether new benchmarks for visual anomaly detection\nare needed based on our experiments. Using the largest publicly available\nvision transformer, we achieve state-of-the-art performance across all $18$\nreported OOD benchmarks, including an AUROC of 87.6\\% (9.2\\% gain,\nunsupervised) and 97.4\\% (1.2\\% gain, supervised) for the challenging task of\nCIFAR100 $\\rightarrow$ CIFAR10 OOD detection. The code will be open-sourced.\n","authors":["Felix Michels","Nikolas Adaloglou","Tim Kaiser","Markus Kollmann"],"pdf_url":"https://arxiv.org/pdf/2303.05828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05780v1","updated":"2023-03-10T08:29:35Z","published":"2023-03-10T08:29:35Z","title":"Knowledge Transfer via Multi-Head Feature Adaptation for Whole Slide\n  Image Classification","summary":"  Transferring prior knowledge from a source domain to the same or similar\ntarget domain can greatly enhance the performance of models on the target\ndomain. However, it is challenging to directly leverage the knowledge from the\nsource domain due to task discrepancy and domain shift. To bridge the gaps\nbetween different tasks and domains, we propose a Multi-Head Feature Adaptation\nmodule, which projects features in the source feature space to a new space that\nis more similar to the target space. Knowledge transfer is particularly\nimportant in Whole Slide Image (WSI) classification since the number of WSIs in\none dataset might be too small to achieve satisfactory performance. Therefore,\nWSI classification is an ideal testbed for our method, and we adapt multiple\nknowledge transfer methods for WSI classification. The experimental results\nshow that models with knowledge transfer outperform models that are trained\nfrom scratch by a large margin regardless of the number of WSIs in the\ndatasets, and our method achieves state-of-the-art performances among other\nknowledge transfer methods on multiple datasets, including TCGA-RCC,\nTCGA-NSCLC, and Camelyon16 datasets.\n","authors":["Conghao Xiong","Yi Lin","Hao Chen","Joseph Sung","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2303.05780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05763v1","updated":"2023-03-10T08:04:16Z","published":"2023-03-10T08:04:16Z","title":"Automatic Detection and Rectification of Paper Receipts on Smartphones","summary":"  We describe the development of a real-time smartphone app that allows the\nuser to digitize paper receipts in a novel way by \"waving\" their phone over the\nreceipts and letting the app automatically detect and rectify the receipts for\nsubsequent text recognition.\n  We show that traditional computer vision algorithms for edge and corner\ndetection do not robustly detect the non-linear and discontinuous edges and\ncorners of a typical paper receipt in real-world settings. This is particularly\nthe case when the colors of the receipt and background are similar, or where\nother interfering rectangular objects are present. Inaccurate detection of a\nreceipt's corner positions then results in distorted images when using an\naffine projective transformation to rectify the perspective.\n  We propose an innovative solution to receipt corner detection by treating\neach of the four corners as a unique \"object\", and training a Single Shot\nDetection MobileNet object detection model. We use a small amount of real data\nand a large amount of automatically generated synthetic data that is designed\nto be similar to real-world imaging scenarios.\n  We show that our proposed method robustly detects the four corners of a\nreceipt, giving a receipt detection accuracy of 85.3% on real-world data,\ncompared to only 36.9% with a traditional edge detection-based approach. Our\nmethod works even when the color of the receipt is virtually indistinguishable\nfrom the background.\n  Moreover, our method is trained to detect only the corners of the central\ntarget receipt and implicitly learns to ignore other receipts, and other\nrectangular objects. Including synthetic data allows us to train an even better\nmodel. These factors are a major advantage over traditional edge\ndetection-based approaches, allowing us to deliver a much better experience to\nthe user.\n","authors":["Edward Whittaker","Masashi Tanaka","Ikuo Kitagishi"],"pdf_url":"https://arxiv.org/pdf/2303.05763v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05754v1","updated":"2023-03-10T07:42:49Z","published":"2023-03-10T07:42:49Z","title":"Fast Diffusion Sampler for Inverse Problems by Geometric Decomposition","summary":"  Diffusion models have shown exceptional performance in solving inverse\nproblems. However, one major limitation is the slow inference time. While\nfaster diffusion samplers have been developed for unconditional sampling, there\nhas been limited research on conditional sampling in the context of inverse\nproblems. In this study, we propose a novel and efficient diffusion sampling\nstrategy that employs the geometric decomposition of diffusion sampling.\nSpecifically, we discover that the samples generated from diffusion models can\nbe decomposed into two orthogonal components: a ``denoised\" component obtained\nby projecting the sample onto the clean data manifold, and a ``noise\" component\nthat induces a transition to the next lower-level noisy manifold with the\naddition of stochastic noise. Furthermore, we prove that, under some conditions\non the clean data manifold, the conjugate gradient update for imposing\nconditioning from the denoised signal belongs to the clean manifold, resulting\nin a much faster and more accurate diffusion sampling. Our method is applicable\nregardless of the parameterization and setting (i.e., VE, VP). Notably, we\nachieve state-of-the-art reconstruction quality on challenging real-world\nmedical inverse imaging problems, including multi-coil MRI reconstruction and\n3D CT reconstruction. Moreover, our proposed method achieves more than 80 times\nfaster inference time than the previous state-of-the-art method.\n","authors":["Hyungjin Chung","Suhyeon Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2303.05754v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2303.04150v2","updated":"2023-03-10T07:21:10Z","published":"2023-03-07T01:38:42Z","title":"Evolutionary Reinforcement Learning: A Survey","summary":"  Reinforcement learning (RL) is a machine learning approach that trains agents\nto maximize cumulative rewards through interactions with environments. The\nintegration of RL with deep learning has recently resulted in impressive\nachievements in a wide range of challenging tasks, including board games,\narcade games, and robot control. Despite these successes, there remain several\ncrucial challenges, including brittle convergence properties caused by\nsensitive hyperparameters, difficulties in temporal credit assignment with long\ntime horizons and sparse rewards, a lack of diverse exploration, especially in\ncontinuous search space scenarios, difficulties in credit assignment in\nmulti-agent reinforcement learning, and conflicting objectives for rewards.\nEvolutionary computation (EC), which maintains a population of learning agents,\nhas demonstrated promising performance in addressing these limitations. This\narticle presents a comprehensive survey of state-of-the-art methods for\nintegrating EC into RL, referred to as evolutionary reinforcement learning\n(EvoRL). We categorize EvoRL methods according to key research fields in RL,\nincluding hyperparameter optimization, policy search, exploration, reward\nshaping, meta-RL, and multi-objective RL. We then discuss future research\ndirections in terms of efficient methods, benchmarks, and scalable platforms.\nThis survey serves as a resource for researchers and practitioners interested\nin the field of EvoRL, highlighting the important challenges and opportunities\nfor future research. With the help of this survey, researchers and\npractitioners can develop more efficient methods and tailored benchmarks for\nEvoRL, further advancing this promising cross-disciplinary research field.\n","authors":["Hui Bai","Ran Cheng","Yaochu Jin"],"pdf_url":"https://arxiv.org/pdf/2303.04150v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.07227v2","updated":"2023-03-10T07:12:32Z","published":"2022-08-15T14:32:10Z","title":"DM-NeRF: 3D Scene Geometry Decomposition and Manipulation from 2D Images","summary":"  In this paper, we study the problem of 3D scene geometry decomposition and\nmanipulation from 2D views. By leveraging the recent implicit neural\nrepresentation techniques, particularly the appealing neural radiance fields,\nwe introduce an object field component to learn unique codes for all individual\nobjects in 3D space only from 2D supervision. The key to this component is a\nseries of carefully designed loss functions to enable every 3D point,\nespecially in non-occupied space, to be effectively optimized even without 3D\nlabels. In addition, we introduce an inverse query algorithm to freely\nmanipulate any specified 3D object shape in the learned scene representation.\nNotably, our manipulation algorithm can explicitly tackle key issues such as\nobject collisions and visual occlusions. Our method, called DM-NeRF, is among\nthe first to simultaneously reconstruct, decompose, manipulate and render\ncomplex 3D scenes in a single pipeline. Extensive experiments on three datasets\nclearly show that our method can accurately decompose all 3D objects from 2D\nviews, allowing any interested object to be freely manipulated in 3D space such\nas translation, rotation, size adjustment, and deformation.\n","authors":["Bing Wang","Lu Chen","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2208.07227v2.pdf","comment":"ICLR 2023. Our data and code are available at:\n  https://github.com/vLAR-group/DM-NeRF"},{"id":"http://arxiv.org/abs/2303.05744v1","updated":"2023-03-10T07:08:24Z","published":"2023-03-10T07:08:24Z","title":"QVRF: A Quantization-error-aware Variable Rate Framework for Learned\n  Image Compression","summary":"  Learned image compression has exhibited promising compression performance,\nbut variable bitrates over a wide range remain a challenge. State-of-the-art\nvariable rate methods compromise the loss of model performance and require\nnumerous additional parameters. In this paper, we present a\nQuantization-error-aware Variable Rate Framework (QVRF) that utilizes a\nunivariate quantization regulator a to achieve wide-range variable rates within\na single model. Specifically, QVRF defines a quantization regulator vector\ncoupled with predefined Lagrange multipliers to control quantization error of\nall latent representation for discrete variable rates. Additionally, the\nreparameterization method makes QVRF compatible with a round quantizer.\nExhaustive experiments demonstrate that existing fixed-rate VAE-based methods\nequipped with QVRF can achieve wide-range continuous variable rates within a\nsingle model without significant performance degradation. Furthermore, QVRF\noutperforms contemporary variable-rate methods in rate-distortion performance\nwith minimal additional parameters.\n","authors":["Kedeng Tong","Yaojun Wu","Yue Li","Kai Zhang","Li Zhang","Xin Jin"],"pdf_url":"https://arxiv.org/pdf/2303.05744v1.pdf","comment":"7 pages, 6 figures"},{"id":"http://arxiv.org/abs/2210.08185v2","updated":"2023-03-10T06:52:39Z","published":"2022-10-15T04:07:39Z","title":"GFlowCausal: Generative Flow Networks for Causal Discovery","summary":"  Causal discovery aims to uncover causal structure among a set of variables.\nScore-based approaches mainly focus on searching for the best Directed Acyclic\nGraph (DAG) based on a predefined score function. However, most of them are not\napplicable on a large scale due to the limited searchability. Inspired by the\nactive learning in generative flow networks, we propose a novel approach to\nlearning a DAG from observational data called GFlowCausal. It converts the\ngraph search problem to a generation problem, in which direct edges are added\ngradually. GFlowCausal aims to learn the best policy to generate high-reward\nDAGs by sequential actions with probabilities proportional to predefined\nrewards. We propose a plug-and-play module based on transitive closure to\nensure efficient sampling. Theoretical analysis shows that this module could\nguarantee acyclicity properties effectively and the consistency between final\nstates and fully-connected graphs. We conduct extensive experiments on both\nsynthetic and real datasets, and results show the proposed approach to be\nsuperior and also performs well in a large-scale setting.\n","authors":["Wenqian Li","Yinchuan Li","Shengyu Zhu","Yunfeng Shao","Jianye Hao","Yan Pang"],"pdf_url":"https://arxiv.org/pdf/2210.08185v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05729v1","updated":"2023-03-10T06:22:13Z","published":"2023-03-10T06:22:13Z","title":"Explaining Model Confidence Using Counterfactuals","summary":"  Displaying confidence scores in human-AI interaction has been shown to help\nbuild trust between humans and AI systems. However, most existing research uses\nonly the confidence score as a form of communication. As confidence scores are\njust another model output, users may want to understand why the algorithm is\nconfident to determine whether to accept the confidence score. In this paper,\nwe show that counterfactual explanations of confidence scores help study\nparticipants to better understand and better trust a machine learning model's\nprediction. We present two methods for understanding model confidence using\ncounterfactual explanation: (1) based on counterfactual examples; and (2) based\non visualisation of the counterfactual space. Both increase understanding and\ntrust for study participants over a baseline of no explanation, but qualitative\nresults show that they are used quite differently, leading to recommendations\nof when to use each one and directions of designing better explanations.\n","authors":["Thao Le","Tim Miller","Ronal Singh","Liz Sonenberg"],"pdf_url":"https://arxiv.org/pdf/2303.05729v1.pdf","comment":"AAAI 2023 Main Track. arXiv admin note: substantial text overlap with\n  arXiv:2206.02790"},{"id":"http://arxiv.org/abs/2303.05725v1","updated":"2023-03-10T06:12:36Z","published":"2023-03-10T06:12:36Z","title":"CVT-SLR: Contrastive Visual-Textual Transformation for Sign Language\n  Recognition with Variational Alignment","summary":"  Sign language recognition (SLR) is a weakly supervised task that annotates\nsign videos as textual glosses. Recent studies show that insufficient training\ncaused by the lack of large-scale available sign language datasets becomes the\nmain bottleneck for SLR. The majority of SLR works thereby adopt pretrained\nvisual modules and develop two mainstream solutions. The multi-stream\narchitectures extend multi-cue visual features, yielding the current SOTA\nperformances but requiring complex designs and might introduce potential noise.\nAlternatively, the advanced single-cue SLR frameworks using explicit\ncross-modal alignment between visual and textual modalities are simple and\neffective, potentially competitive with the multi-cue framework. In this work,\nwe propose a novel contrastive visual-textual transformation for SLR, CVT-SLR,\nto fully explore the pretrained knowledge of both the visual and language\nmodalities. Based on the single-cue cross-modal alignment framework, we propose\na variational autoencoder (VAE) for pretrained contextual knowledge while\nintroducing the complete pretrained language module. The VAE implicitly aligns\nvisual and textual modalities while benefiting from pretrained contextual\nknowledge as the traditional contextual module. Meanwhile, a contrastive\ncross-modal alignment algorithm is proposed to further enhance the explicit\nconsistency constraints. Extensive experiments conducted on the two most\npopular public datasets, PHOENIX-2014 and PHOENIX-2014T, demonstrate that our\nproposed SLR framework not only consistently outperforms existing single-cue\nmethods but even outperforms SOTA multi-cue methods.\n","authors":["Jiangbin Zheng","Yile Wang","Cheng Tan","Siyuan Li","Ge Wang","Jun Xia","Yidong Chen","Stan Z. Li"],"pdf_url":"https://arxiv.org/pdf/2303.05725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05724v1","updated":"2023-03-10T06:08:23Z","published":"2023-03-10T06:08:23Z","title":"3D Cinemagraphy from a Single Image","summary":"  We present 3D Cinemagraphy, a new technique that marries 2D image animation\nwith 3D photography. Given a single still image as input, our goal is to\ngenerate a video that contains both visual content animation and camera motion.\nWe empirically find that naively combining existing 2D image animation and 3D\nphotography methods leads to obvious artifacts or inconsistent animation. Our\nkey insight is that representing and animating the scene in 3D space offers a\nnatural solution to this task. To this end, we first convert the input image\ninto feature-based layered depth images using predicted depth values, followed\nby unprojecting them to a feature point cloud. To animate the scene, we perform\nmotion estimation and lift the 2D motion into the 3D scene flow. Finally, to\nresolve the problem of hole emergence as points move forward, we propose to\nbidirectionally displace the point cloud as per the scene flow and synthesize\nnovel views by separately projecting them into target image planes and blending\nthe results. Extensive experiments demonstrate the effectiveness of our method.\nA user study is also conducted to validate the compelling rendering results of\nour method.\n","authors":["Xingyi Li","Zhiguo Cao","Huiqiang Sun","Jianming Zhang","Ke Xian","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2303.05724v1.pdf","comment":"Accepted by CVPR 2023. Project page:\n  https://xingyi-li.github.io/3d-cinemagraphy/"},{"id":"http://arxiv.org/abs/2303.05689v1","updated":"2023-03-10T03:44:01Z","published":"2023-03-10T03:44:01Z","title":"Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing\n  Mistake Severity","summary":"  There is a recently discovered and intriguing phenomenon called Neural\nCollapse: at the terminal phase of training a deep neural network for\nclassification, the within-class penultimate feature means and the associated\nclassifier vectors of all flat classes collapse to the vertices of a simplex\nEquiangular Tight Frame (ETF). Recent work has tried to exploit this phenomenon\nby fixing the related classifier weights to a pre-computed ETF to induce neural\ncollapse and maximize the separation of the learned features when training with\nimbalanced data. In this work, we propose to fix the linear classifier of a\ndeep neural network to a Hierarchy-Aware Frame (HAFrame), instead of an ETF,\nand use a cosine similarity-based auxiliary loss to learn hierarchy-aware\npenultimate features that collapse to the HAFrame. We demonstrate that our\napproach reduces the mistake severity of the model's predictions while\nmaintaining its top-1 accuracy on several datasets of varying scales with\nhierarchies of heights ranging from 3 to 12. We will release our code on GitHub\nin the near future.\n","authors":["Tong Liang","Jim Davis"],"pdf_url":"https://arxiv.org/pdf/2303.05689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03908v2","updated":"2023-03-10T03:28:39Z","published":"2023-02-08T06:54:55Z","title":"Syntax and Domain Aware Model for Unsupervised Program Translation","summary":"  There is growing interest in software migration as the development of\nsoftware and society. Manually migrating projects between languages is\nerror-prone and expensive. In recent years, researchers have begun to explore\nautomatic program translation using supervised deep learning techniques by\nlearning from large-scale parallel code corpus. However, parallel resources are\nscarce in the programming language domain, and it is costly to collect\nbilingual data manually. To address this issue, several unsupervised\nprogramming translation systems are proposed. However, these systems still rely\non huge monolingual source code to train, which is very expensive. Besides,\nthese models cannot perform well for translating the languages that are not\nseen during the pre-training procedure. In this paper, we propose SDA-Trans, a\nsyntax and domain-aware model for program translation, which leverages the\nsyntax structure and domain knowledge to enhance the cross-lingual transfer\nability. SDA-Trans adopts unsupervised training on a smaller-scale corpus,\nincluding Python and Java monolingual programs. The experimental results on\nfunction translation tasks between Python, Java, and C++ show that SDA-Trans\noutperforms many large-scale pre-trained models, especially for unseen language\ntranslation.\n","authors":["Fang Liu","Jia Li","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.03908v2.pdf","comment":"Accepted by International Conference on Software Engineering\n  (ICSE-2023)"},{"id":"http://arxiv.org/abs/2303.05203v2","updated":"2023-03-10T03:19:20Z","published":"2023-03-09T12:13:39Z","title":"RMMDet: Road-Side Multitype and Multigroup Sensor Detection System for\n  Autonomous Driving","summary":"  Autonomous driving has now made great strides thanks to artificial\nintelligence, and numerous advanced methods have been proposed for vehicle end\ntarget detection, including single sensor or multi sensor detection methods.\nHowever, the complexity and diversity of real traffic situations necessitate an\nexamination of how to use these methods in real road conditions. In this paper,\nwe propose RMMDet, a road-side multitype and multigroup sensor detection system\nfor autonomous driving. We use a ROS-based virtual environment to simulate\nreal-world conditions, in particular the physical and functional construction\nof the sensors. Then we implement muti-type sensor detection and multi-group\nsensors fusion in this environment, including camera-radar and camera-lidar\ndetection based on result-level fusion. We produce local datasets and real sand\ntable field, and conduct various experiments. Furthermore, we link a\nmulti-agent collaborative scheduling system to the fusion detection system.\nHence, the whole roadside detection system is formed by roadside perception,\nfusion detection, and scheduling planning. Through the experiments, it can be\nseen that RMMDet system we built plays an important role in vehicle-road\ncollaboration and its optimization. The code and supplementary materials can be\nfound at: https://github.com/OrangeSodahub/RMMDet\n","authors":["Xiuyu Yang","Zhuangyan Zhang","Haikuo Du","Sui Yang","Fengping Sun","Yanbo Liu","Ling Pei","Wenchao Xu","Weiqi Sun","Zhengyu Li"],"pdf_url":"https://arxiv.org/pdf/2303.05203v2.pdf","comment":"The version is wrong, we need to review"},{"id":"http://arxiv.org/abs/2302.05678v2","updated":"2023-03-10T03:05:27Z","published":"2023-02-11T12:23:38Z","title":"CatAlyst: Domain-Extensible Intervention for Preventing Task\n  Procrastination Using Large Generative Models","summary":"  CatAlyst uses generative models to help workers' progress by influencing\ntheir task engagement instead of directly contributing to their task outputs.\nIt prompts distracted workers to resume their tasks by generating a\ncontinuation of their work and presenting it as an intervention that is more\ncontext-aware than conventional (predetermined) feedback. The prompt can\nfunction by drawing their interest and lowering the hurdle for resumption even\nwhen the generated continuation is insufficient to substitute their work, while\nrecent human-AI collaboration research aiming at work substitution depends on a\nstable high accuracy. This frees CatAlyst from domain-specific model-tuning and\nmakes it applicable to various tasks. Our studies involving writing and\nslide-editing tasks demonstrated CatAlyst's effectiveness in helping workers\nswiftly resume tasks with a lowered cognitive load. The results suggest a new\nform of human-AI collaboration where large generative models publicly available\nbut imperfect for each individual domain can contribute to workers' digital\nwell-being.\n","authors":["Riku Arakawa","Hiromu Yakura","Masataka Goto"],"pdf_url":"https://arxiv.org/pdf/2302.05678v2.pdf","comment":"Accepted by ACM CHI Conference on Human Factors in Computing Systems\n  (CHI '23)"},{"id":"http://arxiv.org/abs/2303.05676v1","updated":"2023-03-10T03:03:32Z","published":"2023-03-10T03:03:32Z","title":"Rearrange Indoor Scenes for Human-Robot Co-Activity","summary":"  We present an optimization-based framework for rearranging indoor furniture\nto accommodate human-robot co-activities better. The rearrangement aims to\nafford sufficient accessible space for robot activities without compromising\neveryday human activities. To retain human activities, our algorithm preserves\nthe functional relations among furniture by integrating spatial and semantic\nco-occurrence extracted from SUNCG and ConceptNet, respectively. By defining\nthe robot's accessible space by the amount of open space it can traverse and\nthe number of objects it can reach, we formulate the rearrangement for\nhuman-robot co-activity as an optimization problem, solved by adaptive\nsimulated annealing (ASA) and covariance matrix adaptation evolution strategy\n(CMA-ES). Our experiments on the SUNCG dataset quantitatively show that\nrearranged scenes provide an average of 14% more accessible space and 30% more\nobjects to interact with. The quality of the rearranged scenes is qualitatively\nvalidated by a human study, indicating the efficacy of the proposed strategy.\n","authors":["Weiqi Wang","Zihang Zhao","Ziyuan Jiao","Yixin Zhu","Song-Chun Zhu","Hangxin Liu"],"pdf_url":"https://arxiv.org/pdf/2303.05676v1.pdf","comment":"7 pages, 7 figures; Accepted by ICRA 2023"},{"id":"http://arxiv.org/abs/2303.05670v1","updated":"2023-03-10T02:52:13Z","published":"2023-03-10T02:52:13Z","title":"Logic Against Bias: Textual Entailment Mitigates Stereotypical Sentence\n  Reasoning","summary":"  Due to their similarity-based learning objectives, pretrained sentence\nencoders often internalize stereotypical assumptions that reflect the social\nbiases that exist within their training corpora. In this paper, we describe\nseveral kinds of stereotypes concerning different communities that are present\nin popular sentence representation models, including pretrained next sentence\nprediction and contrastive sentence representation models. We compare such\nmodels to textual entailment models that learn language logic for a variety of\ndownstream language understanding tasks. By comparing strong pretrained models\nbased on text similarity with textual entailment learning, we conclude that the\nexplicit logic learning with textual entailment can significantly reduce bias\nand improve the recognition of social communities, without an explicit\nde-biasing process\n","authors":["Hongyin Luo","James Glass"],"pdf_url":"https://arxiv.org/pdf/2303.05670v1.pdf","comment":"Accepted by EACL 2023"},{"id":"http://arxiv.org/abs/2303.05668v1","updated":"2023-03-10T02:43:36Z","published":"2023-03-10T02:43:36Z","title":"UNFUSED: UNsupervised Finetuning Using SElf supervised Distillation","summary":"  In this paper, we introduce UnFuSeD, a novel approach to leverage\nself-supervised learning and reduce the need for large amounts of labeled data\nfor audio classification. Unlike prior works, which directly fine-tune a\nself-supervised pre-trained encoder on a target dataset, we use the encoder to\ngenerate pseudo-labels for unsupervised fine-tuning before the actual\nfine-tuning step. We first train an encoder using a novel self-supervised\nlearning algorithm (SSL) on an unlabeled audio dataset. Then, we use that\nencoder to generate pseudo-labels on our target task dataset via clustering the\nextracted representations. These pseudo-labels are then used to guide\nself-distillation on a randomly initialized model, which we call unsupervised\nfine-tuning. Finally, the resultant encoder is then fine-tuned on our target\ntask dataset. Through UnFuSeD, we propose the first system that moves away from\ngeneric SSL paradigms in literature, which pre-train and fine-tune the same\nencoder, and present a novel self-distillation-based system to leverage SSL\npre-training for low-resource audio classification. In practice, UnFuSeD\nachieves state-of-the-art results on the LAPE Benchmark, significantly\noutperforming all our baselines. Additionally, UnFuSeD allows us to achieve\nthis at a 40% reduction in the number of parameters over the previous\nstate-of-the-art system. We make all our codes publicly available.\n","authors":["Ashish Seth","Sreyan Ghosh","S. Umesh","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2303.05668v1.pdf","comment":"Under review at ICASSP 2023 SASB Workshop"},{"id":"http://arxiv.org/abs/2303.03387v2","updated":"2023-03-10T02:09:29Z","published":"2023-03-02T17:30:43Z","title":"CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a\n  Context Synergized Hyperbolic Network","summary":"  The tremendous growth of social media users interacting in online\nconversations has also led to significant growth in hate speech. Most of the\nprior works focus on detecting explicit hate speech, which is overt and\nleverages hateful phrases, with very little work focusing on detecting hate\nspeech that is implicit or denotes hatred through indirect or coded language.\nIn this paper, we present CoSyn, a user- and conversational-context synergized\nnetwork for detecting implicit hate speech in online conversation trees. CoSyn\nfirst models the user's personal historical and social context using a novel\nhyperbolic Fourier attention mechanism and hyperbolic graph convolution\nnetwork. Next, we jointly model the user's personal context and the\nconversational context using a novel context interaction mechanism in the\nhyperbolic space that clearly captures the interplay between the two and makes\nindependent assessments on the amounts of information to be retrieved from both\ncontexts. CoSyn performs all operations in the hyperbolic space to account for\nthe scale-free dynamics of social media. We demonstrate the effectiveness of\nCoSyn both qualitatively and quantitatively on an open-source hate speech\ndataset with Twitter conversations and show that CoSyn outperforms all our\nbaselines in detecting implicit hate speech with absolute improvements in the\nrange of 8.15% - 19.50%.\n","authors":["Sreyan Ghosh","Manan Suri","Purva Chiniya","Utkarsh Tyagi","Sonal Kumar","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2303.03387v2.pdf","comment":"Under review at IJCAI 2023"},{"id":"http://arxiv.org/abs/2303.05652v1","updated":"2023-03-10T02:08:01Z","published":"2023-03-10T02:08:01Z","title":"GATOR: Graph-Aware Transformer with Motion-Disentangled Regression for\n  Human Mesh Recovery from a 2D Pose","summary":"  3D human mesh recovery from a 2D pose plays an important role in various\napplications. However, it is hard for existing methods to simultaneously\ncapture the multiple relations during the evolution from skeleton to mesh,\nincluding joint-joint, joint-vertex and vertex-vertex relations, which often\nleads to implausible results. To address this issue, we propose a novel\nsolution, called GATOR, that contains an encoder of Graph-Aware Transformer\n(GAT) and a decoder with Motion-Disentangled Regression (MDR) to explore these\nmultiple relations. Specifically, GAT combines a GCN and a graph-aware\nself-attention in parallel to capture physical and hidden joint-joint\nrelations. Furthermore, MDR models joint-vertex and vertex-vertex interactions\nto explore joint and vertex relations. Based on the clustering characteristics\nof vertex offset fields, MDR regresses the vertices by composing the predicted\nbase motions. Extensive experiments show that GATOR achieves state-of-the-art\nperformance on two challenging benchmarks.\n","authors":["Yingxuan You","Hong Liu","Xia Li","Wenhao Li","Ti Wang","Runwei Ding"],"pdf_url":"https://arxiv.org/pdf/2303.05652v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.05648v1","updated":"2023-03-10T01:49:56Z","published":"2023-03-10T01:49:56Z","title":"Pacos: Modeling Users' Interpretable and Context-Dependent Choices in\n  Preference Reversals","summary":"  Choice problems refer to selecting the best choices from several items, and\nlearning users' preferences in choice problems is of great significance in\nunderstanding the decision making mechanisms and providing personalized\nservices. Existing works typically assume that people evaluate items\nindependently. In practice, however, users' preferences depend on the market in\nwhich items are placed, which is known as context effects; and the order of\nusers' preferences for two items may even be reversed, which is referred to\npreference reversals. In this work, we identify three factors contributing to\ncontext effects: users' adaptive weights, the inter-item comparison, and\ndisplay positions. We propose a context-dependent preference model named Pacos\nas a unified framework for addressing three factors simultaneously, and\nconsider two design methods including an additive method with high\ninterpretability and an ANN-based method with high accuracy. We study the\nconditions for preference reversals to occur and provide an theoretical proof\nof the effectiveness of Pacos in addressing preference reversals. Experimental\nresults show that the proposed method has better performance than prior works\nin predicting users' choices, and has great interpretability to help understand\nthe cause of preference reversals.\n","authors":["Qingming Li","H. Vicky Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.05648v1.pdf","comment":"29 pages, 12 figures"},{"id":"http://arxiv.org/abs/2105.11115v2","updated":"2023-03-10T01:23:57Z","published":"2021-05-24T06:42:58Z","title":"Self-Attention Networks Can Process Bounded Hierarchical Languages","summary":"  Despite their impressive performance in NLP, self-attention networks were\nrecently proved to be limited for processing formal languages with hierarchical\nstructure, such as $\\mathsf{Dyck}_k$, the language consisting of well-nested\nparentheses of $k$ types. This suggested that natural language can be\napproximated well with models that are too weak for formal languages, or that\nthe role of hierarchy and recursion in natural language might be limited. We\nqualify this implication by proving that self-attention networks can process\n$\\mathsf{Dyck}_{k, D}$, the subset of $\\mathsf{Dyck}_{k}$ with depth bounded by\n$D$, which arguably better captures the bounded hierarchical structure of\nnatural language. Specifically, we construct a hard-attention network with\n$D+1$ layers and $O(\\log k)$ memory size (per token per layer) that recognizes\n$\\mathsf{Dyck}_{k, D}$, and a soft-attention network with two layers and\n$O(\\log k)$ memory size that generates $\\mathsf{Dyck}_{k, D}$. Experiments show\nthat self-attention networks trained on $\\mathsf{Dyck}_{k, D}$ generalize to\nlonger inputs with near-perfect accuracy, and also verify the theoretical\nmemory advantage of self-attention networks over recurrent networks.\n","authors":["Shunyu Yao","Binghui Peng","Christos Papadimitriou","Karthik Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2105.11115v2.pdf","comment":"ACL 2021. 19 pages with extended appendix. v2 fixed a small typo in\n  the formula at the end of page 5 (thank to Gabriel Faria). Code:\n  https://github.com/princeton-nlp/dyck-transformer"},{"id":"http://arxiv.org/abs/2206.02967v2","updated":"2023-03-10T01:15:56Z","published":"2022-06-07T02:03:06Z","title":"Masked Unsupervised Self-training for Label-free Image Classification","summary":"  State-of-the-art computer vision models are mostly trained with supervised\nlearning using human-labeled images, which limits their scalability due to the\nexpensive annotation cost. While self-supervised representation learning has\nachieved impressive progress, it still requires a second stage of finetuning on\nlabeled data. On the other hand, models pre-trained with large-scale text-image\nsupervision (e.g., CLIP) have enabled zero-shot transfer to downstream image\nclassification tasks. However, the zero-shot performance of CLIP-like models\nare often insufficient for real-world adoption. In this paper, we aim to\nleverage the abundant unlabeled data from a target domain to improve the\nperformance of a pre-trained zero-shot classifier, by unsupervised finetuning\nof the pre-trained model. We propose Masked Unsupervised Self-Training (MUST),\na new unsupervised adaptation method which leverages two different and\ncomplementary sources of training signals: pseudo-labels and raw images. MUST\njointly optimizes three objectives to learn both class-level global feature and\npixel-level local feature and enforces a regularization between the two. We\ndemonstrate the efficacy of MUST on a variety of downstream tasks, where it\nimproves upon CLIP by a large margin. MUST also outperforms supervised few-shot\nadaptation methods. It achieves a top-1 accuracy of 77.7% on ImageNet using\nViT-B, +9.4% higher than CLIP, and +6.2% higher than 16-shot CLIP adaptation.\nOur code is available at https://github.com/salesforce/MUST.\n","authors":["Junnan Li","Silvio Savarese","Steven C. H. Hoi"],"pdf_url":"https://arxiv.org/pdf/2206.02967v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05641v1","updated":"2023-03-10T01:09:04Z","published":"2023-03-10T01:09:04Z","title":"Efficient Real Time Recurrent Learning through combined activity and\n  parameter sparsity","summary":"  Backpropagation through time (BPTT) is the standard algorithm for training\nrecurrent neural networks (RNNs), which requires separate simulation phases for\nthe forward and backward passes for inference and learning, respectively.\nMoreover, BPTT requires storing the complete history of network states between\nphases, with memory consumption growing proportional to the input sequence\nlength. This makes BPTT unsuited for online learning and presents a challenge\nfor implementation on low-resource real-time systems. Real-Time Recurrent\nLearning (RTRL) allows online learning, and the growth of required memory is\nindependent of sequence length. However, RTRL suffers from exceptionally high\ncomputational costs that grow proportional to the fourth power of the state\nsize, making RTRL computationally intractable for all but the smallest of\nnetworks. In this work, we show that recurrent networks exhibiting high\nactivity sparsity can reduce the computational cost of RTRL. Moreover,\ncombining activity and parameter sparsity can lead to significant enough\nsavings in computational and memory costs to make RTRL practical. Unlike\nprevious work, this improvement in the efficiency of RTRL can be achieved\nwithout using any approximations for the learning process.\n","authors":["Anand Subramoney"],"pdf_url":"https://arxiv.org/pdf/2303.05641v1.pdf","comment":"Published as a workshop paper at ICLR 2023 Workshop on Sparsity in\n  Neural Networks"},{"id":"http://arxiv.org/abs/2210.03629v3","updated":"2023-03-10T01:00:17Z","published":"2022-10-06T01:00:32Z","title":"ReAct: Synergizing Reasoning and Acting in Language Models","summary":"  While large language models (LLMs) have demonstrated impressive capabilities\nacross tasks in language understanding and interactive decision making, their\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\naction plan generation) have primarily been studied as separate topics. In this\npaper, we explore the use of LLMs to generate both reasoning traces and\ntask-specific actions in an interleaved manner, allowing for greater synergy\nbetween the two: reasoning traces help the model induce, track, and update\naction plans as well as handle exceptions, while actions allow it to interface\nwith external sources, such as knowledge bases or environments, to gather\nadditional information. We apply our approach, named ReAct, to a diverse set of\nlanguage and decision making tasks and demonstrate its effectiveness over\nstate-of-the-art baselines, as well as improved human interpretability and\ntrustworthiness over methods without reasoning or acting components.\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\nReAct overcomes issues of hallucination and error propagation prevalent in\nchain-of-thought reasoning by interacting with a simple Wikipedia API, and\ngenerates human-like task-solving trajectories that are more interpretable than\nbaselines without reasoning traces. On two interactive decision making\nbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\nreinforcement learning methods by an absolute success rate of 34% and 10%\nrespectively, while being prompted with only one or two in-context examples.\nProject site with code: https://react-lm.github.io\n","authors":["Shunyu Yao","Jeffrey Zhao","Dian Yu","Nan Du","Izhak Shafran","Karthik Narasimhan","Yuan Cao"],"pdf_url":"https://arxiv.org/pdf/2210.03629v3.pdf","comment":"v3 is the ICLR camera ready version with some typos fixed. Project\n  site with code: https://react-lm.github.io"},{"id":"http://arxiv.org/abs/2303.05628v1","updated":"2023-03-10T00:11:18Z","published":"2023-03-10T00:11:18Z","title":"On the Unlikelihood of D-Separation","summary":"  Causal discovery aims to recover a causal graph from data generated by it;\nconstraint based methods do so by searching for a d-separating conditioning set\nof nodes in the graph via an oracle. In this paper, we provide analytic\nevidence that on large graphs, d-separation is a rare phenomenon, even when\nguaranteed to exist, unless the graph is extremely sparse. We then provide an\nanalytic average case analysis of the PC Algorithm for causal discovery, as\nwell as a variant of the SGS Algorithm we call UniformSGS. We consider a set\n$V=\\{v_1,\\ldots,v_n\\}$ of nodes, and generate a random DAG $G=(V,E)$ where\n$(v_a, v_b) \\in E$ with i.i.d. probability $p_1$ if $a<b$ and $0$ if $a > b$.\nWe provide upper bounds on the probability that a subset of $V-\\{x,y\\}$\nd-separates $x$ and $y$, conditional on $x$ and $y$ being d-separable; our\nupper bounds decay exponentially fast to $0$ as $|V| \\rightarrow \\infty$. For\nthe PC Algorithm, while it is known that its worst-case guarantees fail on\nnon-sparse graphs, we show that the same is true for the average case, and that\nthe sparsity requirement is quite demanding: for good performance, the density\nmust go to $0$ as $|V| \\rightarrow \\infty$ even in the average case. For\nUniformSGS, while it is known that the running time is exponential for existing\nedges, we show that in the average case, that is the expected running time for\nmost non-existing edges as well.\n","authors":["Itai Feigenbaum","Huan Wang","Shelby Heinecke","Juan Carlos Niebles","Weiran Yao","Caiming Xiong","Devansh Arpit"],"pdf_url":"https://arxiv.org/pdf/2303.05628v1.pdf","comment":null}]}}